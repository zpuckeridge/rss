{
  "sources": [
    {
      "title": "Release notes from osmosfeed",
      "feedUrl": "https://github.com/osmoscraft/osmosfeed/releases.atom",
      "siteUrl": "https://github.com/osmoscraft/osmosfeed/releases",
      "articles": []
    },
    {
      "title": "CSS-Tricks",
      "feedUrl": "https://css-tricks.com/feed/",
      "siteUrl": "https://css-tricks.com",
      "articles": [
        {
          "id": "https://css-tricks.com/?p=375486",
          "author": "Geoff Graham",
          "description": "You know, this is the time of year where Chris normally publishes a big ol’ reflection of the past year. The first one was published in 2007, the same year CSS-Tricks began, and it continued all the way through 2021…\nThank You (2022 Edition) originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/thank-you-2022-edition/",
          "publishedOn": "2022-12-28T15:46:15.000Z",
          "wordCount": 2951,
          "title": "Thank You (2022 Edition)",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375486"
        },
        {
          "id": "https://css-tricks.com/?p=375869",
          "author": "Geoff Graham",
          "description": "We’ve started making a tradition of rounding up the latest front-end research at the end of each year. We did it in 2020 and again in 2021. Reports are released throughout the year by a bunch of different companies …\n2022 Roundup of Web Research originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/2022-roundup-of-web-research/",
          "publishedOn": "2022-12-21T15:03:50.000Z",
          "wordCount": 6054,
          "title": "2022 Roundup of Web Research",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375869"
        },
        {
          "id": "https://css-tricks.com/?p=376319",
          "author": "Geoff Graham",
          "description": "CSS Nesting is making the rounds yet again. Remember earlier this year when Adam and Mia put three syntax options up for a vote? Those results were tallied and it wasn’t even even close.\nNow there’s another chance …\nHelp choose the syntax for CSS Nesting originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/help-choose-the-syntax-for-css-nesting/",
          "publishedOn": "2022-12-20T16:04:54.000Z",
          "wordCount": 835,
          "title": "Help choose the syntax for CSS Nesting",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/376319"
        },
        {
          "id": "https://css-tricks.com/?p=376297",
          "author": "Geoff Graham",
          "description": "Being able to quickly spin up a WordPress instance has been the strength of WordPress ever since its famous “five-minute install”. Upload a few files, configure a few settings, and you’re off.\nThe friction of uploading files has gotten …\nWordPress Playground: Running WordPress in the Browser originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/wordpress-playground-run-in-browser/",
          "publishedOn": "2022-12-19T16:52:45.000Z",
          "wordCount": 1012,
          "title": "WordPress Playground: Running WordPress in the Browser",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/376297"
        },
        {
          "id": "https://css-tricks.com/?p=375621",
          "author": "Temani Afif",
          "description": "In this series, we’ve been making image sliders with nothing but HTML and CSS. The idea is that we can use the same markup but different CSS to get wildly different results, no matter how many images we toss …\nCSS Infinite 3D Sliders originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/css-infinite-3d-sliders/",
          "publishedOn": "2022-12-16T14:58:08.000Z",
          "wordCount": 2796,
          "title": "CSS Infinite 3D Sliders",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375621"
        },
        {
          "id": "https://css-tricks.com/?p=375714",
          "author": "Geoff Graham",
          "description": "The CSS Working Group gave that a thumbs-up a couple weeks ago. The super-duper conceptual proposal being that we can animate or transition from, say, display: block to display: none.\nIt’s a bit of a brain-twister to reason …\nSo, you’d like to animate the display property originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/so-youd-like-to-animate-the-display-property/",
          "publishedOn": "2022-12-15T15:41:06.000Z",
          "wordCount": 1269,
          "title": "So, you’d like to animate the display property",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375714"
        },
        {
          "id": "https://css-tricks.com/?p=376201",
          "author": "Geoff Graham",
          "description": "Every so often, I find that the links I save to read later fall into natural groups or patterns that reveal common threads of interest. The past couple of weeks have produced a lot of thoughts about ChatGPT, an …\nSome Links on AI-Related Stuff originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/some-links-on-ai-related-stuff/",
          "publishedOn": "2022-12-14T21:34:06.000Z",
          "wordCount": 1292,
          "title": "Some Links on AI-Related Stuff",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/376201"
        },
        {
          "id": "https://css-tricks.com/?p=375952",
          "author": "Geoff Graham",
          "description": "Suzy Naschansky from the HTMHell Advent Calendar:\n<h2 id=\"article1-heading\"All About Dragons</h2<pI like dragons. Blah blah blah blah blah.</p<p<a id=\"article1-read-more\" aria-labelledby=\"article1-read-more article1-heading\"Read more</a</p\nSee that aria-labelledby attribute? It chains two IDs from the …\nUnchain My Inaccessibly-Labelled Heart originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/unchain-my-inaccessibly-labelled-heart/",
          "publishedOn": "2022-12-14T14:08:20.000Z",
          "wordCount": 1173,
          "title": "Unchain My Inaccessibly-Labelled Heart",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375952"
        },
        {
          "id": "https://css-tricks.com/?p=376229",
          "author": "Geoff Graham",
          "description": "We’ve got ourselves a real holiday treat! Join host Alex Trost from the Frontend Horse community for the Holiday Snowtacular 2022 this Friday, December 16.\nThere’s a lineup of 12 awesome speakers — including Chris Coyier, Cassidy Williams, Kevin …\nHoliday Snowtacular 2022 originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/holiday-snowtacular-2022/",
          "publishedOn": "2022-12-13T23:03:49.000Z",
          "wordCount": 796,
          "title": "Holiday Snowtacular 2022",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/376229"
        },
        {
          "id": "https://css-tricks.com/?p=375728",
          "author": "Dan Christofi",
          "description": "CSS Container Queries are still gaining traction and many of us are getting our hands wet with them, even if it’s for little experiments or whatnot. They’ve got great, but not quite full, browser support — enough to justify using …\nA Few Times Container Size Queries Would Have Helped Me Out originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/a-few-times-container-size-queries-would-have-helped-me-out/",
          "publishedOn": "2022-12-13T13:53:56.000Z",
          "wordCount": 2299,
          "title": "A Few Times Container Size Queries Would Have Helped Me Out",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375728"
        },
        {
          "id": "https://css-tricks.com/?p=375722",
          "author": "Geoff Graham",
          "description": "Sara Soueidan with everything you need, from what screen reading options are out there all the way to setting up virtual machines for them, installing them, and confguring keyboard options. It’s truly a one-stop reference that pulls together disparate …\nSetting up a screen reader testing environment on your computer originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/setting-up-a-screen-reader-testing-environment-on-your-computer/",
          "publishedOn": "2022-12-12T20:56:58.000Z",
          "wordCount": 807,
          "title": "Setting up a screen reader testing environment on your computer",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375722"
        },
        {
          "id": "https://css-tricks.com/?p=375577",
          "author": "Manoj Kumar",
          "description": "We’ve accomplished a bunch of stuff in this series! We created a custom WordPress block that fetches data from an external API and renders it on the front end. Then we took that work and extended it so the data …\nSaving Settings for a Custom WordPress Block in the Block Editor originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/saving-settings-for-a-custom-wordpress-block-in-the-block-editor/",
          "publishedOn": "2022-12-12T14:06:39.000Z",
          "wordCount": 1565,
          "title": "Saving Settings for a Custom WordPress Block in the Block Editor",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375577"
        }
      ]
    },
    {
      "title": "Articles on Smashing Magazine — For Web Designers And Developers",
      "feedUrl": "https://www.smashingmagazine.com/feed/",
      "siteUrl": "https://www.smashingmagazine.com/",
      "articles": [
        {
          "id": "https://smashingmagazine.com/2023/01/guide-getting-data-visualization-right/",
          "author": "hello@smashingmagazine.com (Sara Dholakia)",
          "description": "In this article, Sara Dholakia presents a guide on how to choose just the right type of data visualization, with guidelines and things to keep in mind.",
          "link": "https://smashingmagazine.com/2023/01/guide-getting-data-visualization-right/",
          "publishedOn": "2023-01-05T09:00:00.000Z",
          "wordCount": 5474,
          "title": "A Guide To Getting Data Visualization Right",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/38409b65-d922-486a-8db9-0adb09194016/guide-getting-data-visualization-right.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/38409b65-d922-486a-8db9-0adb09194016/guide-getting-data-visualization-right.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2023/01/usability-2023/",
          "author": "hello@smashingmagazine.com (Vitaly Friedman)",
          "description": "That’s how people behave on the web in 2023. Some observations from real usability testing on what people do and what they don’t do on the web. From disabled copy-paste to magic link sign-in.",
          "link": "https://smashingmagazine.com/2023/01/usability-2023/",
          "publishedOn": "2023-01-02T09:00:00.000Z",
          "wordCount": 3539,
          "title": "The State Of Usability In 2023 🎊",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/892f360a-dc33-44c0-aba8-478b1edc7357/usability-2023.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/892f360a-dc33-44c0-aba8-478b1edc7357/usability-2023.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/desktop-wallpaper-calendars-january-2023/",
          "author": "hello@smashingmagazine.com (Cosima Mielke)",
          "description": "Let’s start into the new year with a little inspiration boost: wallpapers created with love by the community for the community. Happy 2023!",
          "link": "https://smashingmagazine.com/2022/12/desktop-wallpaper-calendars-january-2023/",
          "publishedOn": "2022-12-31T09:00:00.000Z",
          "wordCount": 4562,
          "title": "Opening The Doors To 2023 (January Wallpapers Edition)",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ea4019d5-9870-41a3-9646-a68895c59a3d/jan-23-bird-bird-bird-bird-preview-opt.png",
            "length": "0",
            "type": "image/png"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ea4019d5-9870-41a3-9646-a68895c59a3d/jan-23-bird-bird-bird-bird-preview-opt.png"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/fluid-typography-predict-problem-users-zoom-in/",
          "author": "hello@smashingmagazine.com (Ruslan Yevych)",
          "description": "In this article, Ruslan Yevych will show you an easy way how to predict the appearance of a problem known as WCAG Failure Under 1.4.4 Resize Text (AA) while zooming the page. You will have a clear understanding of the possible risks of using responsive typography at the stage of development.",
          "link": "https://smashingmagazine.com/2022/12/fluid-typography-predict-problem-users-zoom-in/",
          "publishedOn": "2022-12-30T15:00:00.000Z",
          "wordCount": 4664,
          "title": "Fluid Typography: Predicting A Problem With Your User’s Zoom-In",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e896f9f1-7437-48c5-9481-483ae087a622/fluid-typography-predict-problem-users-zoom-in.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e896f9f1-7437-48c5-9481-483ae087a622/fluid-typography-predict-problem-users-zoom-in.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/guide-sizing-spacing-grids-layout-web-ui-ux-design/",
          "author": "hello@smashingmagazine.com (Paul Matvienko)",
          "description": "Space is one of the core elements in design that is often overlooked. Proper spatial organization helps to achieve consistency between screens, pages, or even products. It also creates visual rhythm, limits decision-making, and helps to achieve better readability and scannability. In this guide, Paul Matvienko discusses the basics of defining a spatial system.",
          "link": "https://smashingmagazine.com/2022/12/guide-sizing-spacing-grids-layout-web-ui-ux-design/",
          "publishedOn": "2022-12-29T13:00:00.000Z",
          "wordCount": 4978,
          "title": "An Ultimate Guide On Sizing, Spacing, Grids And Layout In Web And UI/UX Design",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/492d4955-5970-4ea0-ae9a-10414d7afad2/guide-sizing-spacing-grids-layout-web-ui-ux-design.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/492d4955-5970-4ea0-ae9a-10414d7afad2/guide-sizing-spacing-grids-layout-web-ui-ux-design.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/guide-command-line-data-manipulation-cli-miller/",
          "author": "hello@smashingmagazine.com (Alvin Bryan)",
          "description": "No more random scripts in Python and JavaScript to transform CSV or JSON data. In this article, Alvin Bryan shows you how to use Miller, a small and powerful CLI tool, to do all your data processing.",
          "link": "https://smashingmagazine.com/2022/12/guide-command-line-data-manipulation-cli-miller/",
          "publishedOn": "2022-12-27T11:00:00.000Z",
          "wordCount": 4990,
          "title": "A Guide To Command-Line Data Manipulation",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9865d051-a600-4de7-a961-8b39a9226757/guide-command-line-data-manipulation-cli-miller.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9865d051-a600-4de7-a961-8b39a9226757/guide-command-line-data-manipulation-cli-miller.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/deploying-css-logical-properties-on-web-apps/",
          "author": "hello@smashingmagazine.com (Nicolas Hoffmann)",
          "description": "You may have already heard of CSS logical properties or RTL adaptations but are still deciding whether to deploy them widely. To help raise your awareness of their possibilities, Nicolas Hoffmann shares his experience of how he and his team at Proton carried out a massive move from CSS logical props to production and how you can consider them from a different perspective in your very own projects.",
          "link": "https://smashingmagazine.com/2022/12/deploying-css-logical-properties-on-web-apps/",
          "publishedOn": "2022-12-23T13:00:00.000Z",
          "wordCount": 4365,
          "title": "Deploying CSS Logical Properties On Web Apps",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/dd6913e4-e4eb-4bc9-8b51-0f8d596ee839/deploying-css-logical-properties-on-web-apps.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/dd6913e4-e4eb-4bc9-8b51-0f8d596ee839/deploying-css-logical-properties-on-web-apps.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/useful-accessibility-usability-examples-help-improve-your-designs/",
          "author": "hello@smashingmagazine.com (Thomas Bohm)",
          "description": "In this article, Thomas Bohm shares strategies and methods to tackle some common graphic communication problems and gives you insights into how to improve accessibility and usability and make your designs much better.",
          "link": "https://smashingmagazine.com/2022/12/useful-accessibility-usability-examples-help-improve-your-designs/",
          "publishedOn": "2022-12-20T12:00:00.000Z",
          "wordCount": 8297,
          "title": "Useful Accessibility And Usability Examples To Help Improve Your Designs",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6d616de6-54bc-44cd-b63b-271cc7d5f3be/useful-accessibility-usability-examples-help-improve-your-designs.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6d616de6-54bc-44cd-b63b-271cc7d5f3be/useful-accessibility-usability-examples-help-improve-your-designs.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/taking-stress-out-design-system-management/",
          "author": "hello@smashingmagazine.com (Masha Shaposhnikova)",
          "description": "In this article, Masha goes over five tips that make it easier to manage a design system while increasing its effectiveness. This short guide is aimed at smaller teams.",
          "link": "https://smashingmagazine.com/2022/12/taking-stress-out-design-system-management/",
          "publishedOn": "2022-12-19T13:00:00.000Z",
          "wordCount": 5486,
          "title": "Taking The Stress Out Of Design System Management",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/bd9f560b-bc0f-49d0-8b82-c9fbaf8d3915/taking-stress-out-design-system-management.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/bd9f560b-bc0f-49d0-8b82-c9fbaf8d3915/taking-stress-out-design-system-management.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/optimizing-design-workflow-tools/",
          "author": "hello@smashingmagazine.com (Ashish Bogawat)",
          "description": "In this article, Ashish Bogawat shares some of his favorite ways how to boost productivity and do things faster, better, and probably more fun by using efficient tools and workflows.",
          "link": "https://smashingmagazine.com/2022/12/optimizing-design-workflow-tools/",
          "publishedOn": "2022-12-16T10:00:00.000Z",
          "wordCount": 5651,
          "title": "Optimizing Your Design Workflow With Tools",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fea883cf-c97a-43dc-b537-bc2147183cde/optimizing-design-workflow-tools.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fea883cf-c97a-43dc-b537-bc2147183cde/optimizing-design-workflow-tools.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/prioritize-user-security-collecting-offline-data/",
          "author": "hello@smashingmagazine.com (Suzanne Scacca)",
          "description": "Concerns over online privacy and security are nothing new. In this article, Suzanne Scacca explores how the right CSV importer can help businesses better prioritize user security.",
          "link": "https://smashingmagazine.com/2022/12/prioritize-user-security-collecting-offline-data/",
          "publishedOn": "2022-12-15T13:30:00.000Z",
          "wordCount": 4234,
          "title": "How To Prioritize User Security When Collecting Offline Data",
          "enclosure": {
            "url": "http://res.cloudinary.com/indysigner/image/upload/v1670867131/prioritize-user-security-collecting-offline-data_nozcsc.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://res.cloudinary.com/indysigner/image/upload/v1670867131/prioritize-user-security-collecting-offline-data_nozcsc.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/understanding-privacy-protect-your-users-protect-yourself/",
          "author": "hello@smashingmagazine.com (Heather Burns)",
          "description": "All of us want to create inclusive, safe, and privacy-aware digital experiences, but where to begin? Our brand new Smashing Book, “Understanding Privacy,” written by Heather Burns, can help you lay the ground for future developers, designers, and project managers to build a better web for tomorrow. [Jump to the details](https://www.smashingmagazine.com/2022/12/understanding-privacy-new-smashing-book/#about-the-book) or [get the book right away](https://www.smashingmagazine.com/printed-books/understanding-privacy/).",
          "link": "https://smashingmagazine.com/2022/12/understanding-privacy-protect-your-users-protect-yourself/",
          "publishedOn": "2022-12-13T17:30:00.000Z",
          "wordCount": 4423,
          "title": "Understanding Privacy: Protect Your Users, Protect Yourself",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d490bcc4-aa79-4b19-a39c-6ed3a8ae815c/understanding-privacy-protect-your-users-protect-yourself.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d490bcc4-aa79-4b19-a39c-6ed3a8ae815c/understanding-privacy-protect-your-users-protect-yourself.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/accessible-front-end-patterns-responsive-tables-part2/",
          "author": "hello@smashingmagazine.com (Adrian Bece)",
          "description": "There is no universal solution for making every kind of table responsive and usable on smaller screens, so we have to rely on various patterns, which Adrian explains in this two-part series.",
          "link": "https://smashingmagazine.com/2022/12/accessible-front-end-patterns-responsive-tables-part2/",
          "publishedOn": "2022-12-13T15:00:00.000Z",
          "wordCount": 5614,
          "title": "Accessible Front-End Patterns For Responsive Tables (Part 2)",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ef4ceadc-3a08-4ff7-ae9e-4e44b1054feb/accessible-front-end-patterns-responsive-tables-part2.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ef4ceadc-3a08-4ff7-ae9e-4e44b1054feb/accessible-front-end-patterns-responsive-tables-part2.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/future-design-human-powered-ai-driven/",
          "author": "hello@smashingmagazine.com (Keima Kai)",
          "description": "In this article, Keima Kai provides a brief history of AI in web design, explores its current implications for creativity, and offers suggestions for how web designers can stay ahead of the curve.",
          "link": "https://smashingmagazine.com/2022/12/future-design-human-powered-ai-driven/",
          "publishedOn": "2022-12-12T13:00:00.000Z",
          "wordCount": 5849,
          "title": "The Future Of Design: Human-Powered Or AI-Driven?",
          "enclosure": {
            "url": "http://res.cloudinary.com/indysigner/image/upload/v1670850655/future-design-human-powered-ai-driven_jn1p6k.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://res.cloudinary.com/indysigner/image/upload/v1670850655/future-design-human-powered-ai-driven_jn1p6k.jpg"
        }
      ]
    },
    {
      "title": "freeCodeCamp.org",
      "feedUrl": "https://www.freecodecamp.org/news/rss/",
      "siteUrl": "https://www.freecodecamp.org/news/",
      "articles": [
        {
          "id": "https://www.freecodecamp.org/news/javascript-post-request-how-to-send-an-http-post-request-in-js/",
          "author": "Joel Olawanle",
          "description": "HTTP requests allow your front-end application to interact successfully with a back-end server or database. One of the five popular HTTP methods for making requests and interacting with your servers is the POST method, which you can use to send data to a server. In this article, you will learn",
          "link": "https://www.freecodecamp.org/news/javascript-post-request-how-to-send-an-http-post-request-in-js/",
          "publishedOn": "2023-01-06T23:40:43.000Z",
          "wordCount": 1818,
          "title": "JavaScript Post Request – How to Send an HTTP Post Request in JS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/cover-template--7-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/the-ternary-operator-in-javascript/",
          "author": "Dillion Megida",
          "description": "There are many operators in JavaScript, one of which is the ternary operator. In this article, I'll explain what this operator is, and how it can be useful when building applications. I have a video version of this topic [https://youtu.be/MmwtZ0AwN9A] you can check out as well to supplement your learning.",
          "link": "https://www.freecodecamp.org/news/the-ternary-operator-in-javascript/",
          "publishedOn": "2023-01-06T23:30:48.000Z",
          "wordCount": 1759,
          "title": "JavaScript Ternary Operator – Syntax and Example Use Case",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/13.-ternary-operator.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-css-create-the-microsoft-logo-version-1/",
          "author": "Jennifer Bland",
          "description": "One of the best ways to learn CSS is by creating something useful while you learn. In this article I will show you two ways that you can create the Microsoft logo.  What We Will Be Creating We will create the Microsoft logo in pure CSS. It will look",
          "link": "https://www.freecodecamp.org/news/learn-css-create-the-microsoft-logo-version-1/",
          "publishedOn": "2023-01-06T23:22:38.000Z",
          "wordCount": 1590,
          "title": "Learn CSS by Building the Microsoft Logo 2 Different Ways in Pure CSS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Learn-CSS-Create-The-Microsoft-Logo.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/dictionary-iteration-in-python/",
          "author": "Kolade Chris",
          "description": "In Python, a dictionary is one of the built-in data structures (the others are tuples, lists, and sets). A dictionary is a collection of key:value pairs and you can use them to solve various programming problems. Dictionaries are very flexible to work with. You can get the keys and values",
          "link": "https://www.freecodecamp.org/news/dictionary-iteration-in-python/",
          "publishedOn": "2023-01-06T23:16:43.000Z",
          "wordCount": 1536,
          "title": "Dictionary Iteration in Python – How to Iterate Over a Dict with a For Loop",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/pexels-stas-knop-1194723.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/laravel-logging/",
          "author": "Sule-Balogun Olanrewaju Ganiu",
          "description": "Logs are records of the events happening with your application. Laravel, by default, writes log information into the laravel.log file that ships with a fresh Laravel installation. The file is housed within the storage > logs  directory.  In this tutorial, you'll learn the following:  * Introduction to",
          "link": "https://www.freecodecamp.org/news/laravel-logging/",
          "publishedOn": "2023-01-06T19:38:55.000Z",
          "wordCount": 1817,
          "title": "How Logging Works in Laravel Applications",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/how-logging-works-laravel.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/react-hooks-every-project-should-use/",
          "author": "Reed Barger",
          "description": "Hooks are one of the most powerful features of React.  They enable us to easily reuse functionality across our application's components. What's best about hooks is their reusability – you can reuse your hooks both across components and your projects. Here are seven of the most important React hooks",
          "link": "https://www.freecodecamp.org/news/react-hooks-every-project-should-use/",
          "publishedOn": "2023-01-06T19:23:16.000Z",
          "wordCount": 2836,
          "title": "React Hooks You Can Use in Every Project – Explained with Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/7-react-hooks.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-css-create-the-youtube-logo/",
          "author": "Jennifer Bland",
          "description": "One of the best ways to learn CSS is by creating something useful while you learn. I will show you how to use the following CSS concepts by creating the YouTube logo:  * Flexbox  * The border-radius property  * How to create a triangle in CSS What",
          "link": "https://www.freecodecamp.org/news/learn-css-create-the-youtube-logo/",
          "publishedOn": "2023-01-06T18:39:00.000Z",
          "wordCount": 1311,
          "title": "Learn CSS by Building the YouTube Logo in Pure CSS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Learn-CSS-Create-The-YouTube-Logo.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-are-solidity-modifiers/",
          "author": "Chigozie Oduah",
          "description": "In this article, we will explore the various ways you can use modifiers in Solidity to modify the behavior of functions.  We will cover topics such as the syntax for defining and using modifiers, the _;  symbol, using multiple modifiers on a single function, modifiers with arguments, enum-based",
          "link": "https://www.freecodecamp.org/news/what-are-solidity-modifiers/",
          "publishedOn": "2023-01-06T18:18:52.000Z",
          "wordCount": 1930,
          "title": "What Are Solidity Modifiers? Explained with Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/shubham-dhage-UxDU0Gg5pqQ-unsplash.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/understanding-digital-security/",
          "author": "David Clinton",
          "description": "Whatever your connection to technology, security should play a prominent role in the way you think and act.  Technology, after all, amplifies the impact of everything we do with it. The things we say and write using communication technologies can be read and heard by many, many more people",
          "link": "https://www.freecodecamp.org/news/understanding-digital-security/",
          "publishedOn": "2023-01-06T18:09:40.000Z",
          "wordCount": 3429,
          "title": "A Beginner's Guide to Digital Security – How to Keep Yourself Safe Online",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/pexels-pixabay-207580--2-.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-to-code-book/",
          "author": "Quincy Larson",
          "description": "If you want to learn to code and get a job as a developer, you're in the right place. This book will show you how. And yes this is the full book – for free – right here on this webpage. A few years back, one of the Big 5",
          "link": "https://www.freecodecamp.org/news/learn-to-code-book/",
          "publishedOn": "2023-01-06T00:52:11.000Z",
          "wordCount": 27156,
          "title": "How to Learn to Code & Get a Developer Job in 2023 [Full Book]",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/Learn-to-Code-and-Get-a-Developer-Job-Book.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-make-a-file-in-linux-from-the-command-line-create-a-file-in-terminal/",
          "author": "Zaira Hira",
          "description": "Managing files from the command line is one of the most common tasks for a Linux user.  Files are created, edited, deleted, and used by many of the background OS processes. Files are also used by regular users to accomplish daily tasks such as taking notes, writing code, or",
          "link": "https://www.freecodecamp.org/news/how-to-make-a-file-in-linux-from-the-command-line-create-a-file-in-terminal/",
          "publishedOn": "2023-01-05T18:58:23.000Z",
          "wordCount": 1176,
          "title": "How to Make a File in Linux from the Command Line – Create a File in the Terminal",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/Copy-of-Copy-of-read-write-files-python--3-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/perfect-html-input/",
          "author": "Austin Gil",
          "description": "Today I'm going to show you all the things to consider when building the perfect HTML input. Despite its seemingly simple nature, there's actually a lot that goes into it. How to Make the Control  Well, we need to start somewhere. Might as well start with the control itself.",
          "link": "https://www.freecodecamp.org/news/perfect-html-input/",
          "publishedOn": "2023-01-05T17:43:37.000Z",
          "wordCount": 1915,
          "title": "How to Build Great HTML Form Controls",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/HTML-Blog-Cover.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-check-if-a-file-exists-in-python/",
          "author": "Dionysia Lemonaki",
          "description": "When working with files in Python, there may be times when you need to check whether a file exists or not. But why should you check if a file exists in the first place? Confirming the existence of a specific file comes in handy when you want to perform particular",
          "link": "https://www.freecodecamp.org/news/how-to-check-if-a-file-exists-in-python/",
          "publishedOn": "2023-01-05T17:23:20.000Z",
          "wordCount": 1908,
          "title": "How to Check if a File Exists in Python with isFile() and exists()",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/pexels-francis-seura-802412.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-convert-integer-to-string-in-java/",
          "author": "Ihechikara Vincent Abba",
          "description": "You can convert variables from one data type to another in Java using different methods.  In this article, you'll learn how to convert integers to strings in Java in the following ways:  * Using the Integer.toString() method.   * Using the String.valueOf() method.   * Using",
          "link": "https://www.freecodecamp.org/news/how-to-convert-integer-to-string-in-java/",
          "publishedOn": "2023-01-05T15:57:29.000Z",
          "wordCount": 1416,
          "title": "Int to String in Java – How to Convert an Integer into a String",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/marcel-eberle-rendLSpkDtY-unsplash--1-.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/python-set-vs-list/",
          "author": "Kolade Chris",
          "description": "In Python, set and list are both data structures for storing and organizing any values. Those values could be numbers, strings, and booleans. In this article, we'll look at the differences between set and list. But before that, let's take a look at what both set and list are. What",
          "link": "https://www.freecodecamp.org/news/python-set-vs-list/",
          "publishedOn": "2023-01-05T15:52:53.000Z",
          "wordCount": 1279,
          "title": "Python Set VS List – Sets and Lists in Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/setvlist.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-produce-music-with-fl-studio/",
          "author": "Beau Carnes",
          "description": "FL Studio is a powerful digital audio workstation (DAW) used by music producers all over the world. It has a wide range of features that allow users to create, produce, and mix music with ease. Whether you are a beginner or an experienced producer, this course is designed to help",
          "link": "https://www.freecodecamp.org/news/how-to-produce-music-with-fl-studio/",
          "publishedOn": "2023-01-05T15:44:29.000Z",
          "wordCount": 925,
          "title": "How to Produce Music with FL Studio",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/flstudio.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-implement-infinite-scroll-in-next-js/",
          "author": "Divine Orji",
          "description": "Creators and developers continually come up with new ways to enhance apps and provide value to users.  One feature that's useful for social media and ecommerce apps in particular is infinite scroll. It provides a seamless and intuitive browsing experience by reducing the time it takes to see new",
          "link": "https://www.freecodecamp.org/news/how-to-implement-infinite-scroll-in-next-js/",
          "publishedOn": "2023-01-05T15:38:08.000Z",
          "wordCount": 1624,
          "title": "How to Implement Infinite Scroll in Next.js with Intersection Observer",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/pexels-ahmed-aqtai-63572.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-use-python-for-web-development/",
          "author": "Beau Carnes",
          "description": "Python is a popular programming language that is widely used in the development of web applications. It is easy to learn, has a large and active community, and is supported by a wealth of libraries and frameworks. We just published a crash course on the freeCodeCamp.org YouTube channel that will",
          "link": "https://www.freecodecamp.org/news/how-to-use-python-for-web-development/",
          "publishedOn": "2023-01-05T15:33:56.000Z",
          "wordCount": 938,
          "title": "How to Use Python for Web Development",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/pythonwebdev.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-clear-formatting-in-excel/",
          "author": "Eamonn Cottrell",
          "description": "In this article I will show you how to clear formatting from a cell in Excel. If you want the quick and dirty version, it's first up and will require you to simply click a couple times.  If you want to become a spreadsheet speedrunner, read this whole, brief",
          "link": "https://www.freecodecamp.org/news/how-to-clear-formatting-in-excel/",
          "publishedOn": "2023-01-05T01:17:19.000Z",
          "wordCount": 1574,
          "title": "How to Clear Formatting in Excel – Remove Format From a Cell",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/12.30.22-Clear-Formatting-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/react-projects-to-improve-your-skills/",
          "author": "Reed Barger",
          "description": "If you want to be good at React, building projects is one of the best ways to do it.  I have put together eight different projects that will not only show you what's possible to make with React, but give you some inspiration on what apps to make.",
          "link": "https://www.freecodecamp.org/news/react-projects-to-improve-your-skills/",
          "publishedOn": "2023-01-05T00:22:40.000Z",
          "wordCount": 2827,
          "title": "8 React Projects to Build in 2023",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/8-react-projects.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/free-online-programming-cs-courses/",
          "author": "Dhawal Shah",
          "description": "Twelve years ago, universities like Stanford and MIT opened up free online courses [https://www.classcentral.com/] to the public. Today, over 1,200 schools [https://www.classcentral.com/universities] around the world have created thousands of free online courses. To welcome the new year, I’ve compiled this list of 860+ such free online courses that you can",
          "link": "https://www.freecodecamp.org/news/free-online-programming-cs-courses/",
          "publishedOn": "2023-01-04T17:00:00.000Z",
          "wordCount": 9477,
          "title": "860+ Free Online Programming & Computer Science Courses You Can Start This New Year",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/programming-courses-banner.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/format-compact-numbers-with-javascript/",
          "author": "Gerard Hynes",
          "description": "Sometimes it can be difficult to fit large numbers into your site or app's layout, especially if you have to display several of them together.  As a result, a lot of modern sites and apps use the same format to display large numbers in a compact way. For example,",
          "link": "https://www.freecodecamp.org/news/format-compact-numbers-with-javascript/",
          "publishedOn": "2023-01-04T15:39:17.000Z",
          "wordCount": 1706,
          "title": "How to Format Compact Numbers with the JavaScript Internationalization API",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Format-Compact-Numbers.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-build-a-ghost-cms-theme/",
          "author": "Rajdeep Singh",
          "description": "Ghost CMS is a platform specifically designed for bloggers and writers. Using Ghost, you can quickly get a blog website up and running.  Ghost targets primarily writers and all the features are specifically built for writing.  Ghost's new dashboard gives you a user-friendly interface, and beginners can easily",
          "link": "https://www.freecodecamp.org/news/how-to-build-a-ghost-cms-theme/",
          "publishedOn": "2023-01-04T15:20:24.000Z",
          "wordCount": 5486,
          "title": "How to Build a Custom Ghost CMS Theme",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/08/ghost-theme-development-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-automate-call-graph-creation/",
          "author": "Daniel García Solla",
          "description": "Have you ever found yourself staring at lines of code, trying to wrap your head around how all the different functions fit together and interact with each other?  It can be a daunting task, especially in larger, more complex programs.  But fear not! There is a way to",
          "link": "https://www.freecodecamp.org/news/how-to-automate-call-graph-creation/",
          "publishedOn": "2023-01-03T23:58:02.000Z",
          "wordCount": 4065,
          "title": "What is a Call Graph? And How to Generate them Automatically",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Untitled2-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/higher-order-functions-in-javascript-explained/",
          "author": "Sobit Prasad",
          "description": "As a web developer, you should always strive to learn new techniques and discover ways to work smarter with JavaScript.  One such technique is using higher order functions. Higher order functions are functions that take one or more functions as arguments, or return a function as their result. In",
          "link": "https://www.freecodecamp.org/news/higher-order-functions-in-javascript-explained/",
          "publishedOn": "2023-01-03T22:11:58.000Z",
          "wordCount": 3489,
          "title": "Higher Order Functions in JavaScript – Explained with Practical Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/higher-order-functions-in-javascript-2.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/format-dates-with-ordinal-number-suffixes-javascript/",
          "author": "Joel Olawanle",
          "description": "Many online resources teach you how to format dates. But it's hard to find any that explain how to format dates with an ordinal number suffix (like 1st) in JavaScript – without using a library. In this short article, you will learn how to format dates in JavaScript with ordinal",
          "link": "https://www.freecodecamp.org/news/format-dates-with-ordinal-number-suffixes-javascript/",
          "publishedOn": "2023-01-03T21:57:47.000Z",
          "wordCount": 1207,
          "title": "How to Format Dates with Ordinal Number Suffixes (-st, -nd, -rd, -th) in JavaScript",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-template--4-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/python-join-how-to-combine-a-list-into-a-string-in-python/",
          "author": "Suchandra Datta",
          "description": "join() is one of the built-in string functions in Python that lets us create a new string from a list of string elements with a user-defined separator.  Today we'll explore join() and learn about:  * join() syntax  * how to use join() to combine a list into",
          "link": "https://www.freecodecamp.org/news/python-join-how-to-combine-a-list-into-a-string-in-python/",
          "publishedOn": "2023-01-03T20:11:53.000Z",
          "wordCount": 1493,
          "title": "Python join() – How to Combine a List into a String in Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/pexels-francesco-ungaro-96081.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/create-a-react-app-with-a-dot-net-backend/",
          "author": "Beau Carnes",
          "description": "ASP.NET Core can work well as a backend for your React apps. We just published a course on the freeCodeCamp.org YouTube channel that will teach you how to to create a basic React application that leverages a .NET Web API Component written in C#. In order to integrate React with",
          "link": "https://www.freecodecamp.org/news/create-a-react-app-with-a-dot-net-backend/",
          "publishedOn": "2023-01-03T19:57:42.000Z",
          "wordCount": 911,
          "title": "Create a React App With a .NET Core Backend",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/webapi.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-protect-against-dom-xss-attacks/",
          "author": "Andrej Kovacevic",
          "description": "Website security issues and vulnerabilities are a global problem as cyber security vulnerabilities are increasing. We have seen a major rise in the average number of these cases in the past few years, and 2021 saw an all-time high. So in this tutorial, we are going to talk about DOM",
          "link": "https://www.freecodecamp.org/news/how-to-protect-against-dom-xss-attacks/",
          "publishedOn": "2023-01-03T19:51:56.000Z",
          "wordCount": 2339,
          "title": "What is XSS? How to Protect Your Website from DOM Cross-Site Scripting Attacks",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/09/xss-code-case.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-setup-user-authentication-in-flask/",
          "author": "Ashutosh Krishna",
          "description": "User authentication is important for protecting sensitive information and resources from unauthorized access. It helps ensure that only authorized users can access and make changes to data, and helps prevent unauthorized users from gaining access to sensitive information. There are different methods for implementing user authentication, including password-based authentication, token-based",
          "link": "https://www.freecodecamp.org/news/how-to-setup-user-authentication-in-flask/",
          "publishedOn": "2023-01-03T14:57:06.000Z",
          "wordCount": 5996,
          "title": "How to Set Up Basic User Authentication in a Flask App",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/basic-auth.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/speed-up-performance-in-laravel-valet/",
          "author": "Sule-Balogun Olanrewaju Ganiu",
          "description": "Last week, I decided to install Laravel Valet on my Mac. But after the installation, the performance of the microservice architecture application I had it on was quite slow.  I wondered if it was an M1 issue or because I had yet to shut the machine down. I shut",
          "link": "https://www.freecodecamp.org/news/speed-up-performance-in-laravel-valet/",
          "publishedOn": "2023-01-02T23:12:30.000Z",
          "wordCount": 1638,
          "title": "Laravel Valet Performance – How to Prevent 504 Errors and Speed Up Valet",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/pexels-jonathan-petersson-399636.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-learn-react-in-2023/",
          "author": "Reed Barger",
          "description": "As the most popular JavaScript library for building frontend applications, there has never been a better year to learn React than 2023.  In this guide, I'm going to show you the most valuable resources and tips that I believe will help you learn React faster. You'll also save a",
          "link": "https://www.freecodecamp.org/news/how-to-learn-react-in-2023/",
          "publishedOn": "2023-01-02T22:59:24.000Z",
          "wordCount": 2431,
          "title": "How to Learn React in 2023",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/learn-react-2023.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-css-by-creating-the-figma-logo-in-pure-css/",
          "author": "Jennifer Bland",
          "description": "One of the best ways to learn CSS is by creating something useful while you learn. I will show you how to use the following CSS concepts by creating the Figma logo:  * flex-wrap  * multiple classes  * border-radius What We Will Be Creating We will create",
          "link": "https://www.freecodecamp.org/news/learn-css-by-creating-the-figma-logo-in-pure-css/",
          "publishedOn": "2023-01-02T22:39:24.000Z",
          "wordCount": 1328,
          "title": "Learn CSS by Building the Figma Logo in Pure CSS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Learn-CSS-Create-The-Figma-Logo-3.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-protect-your-privacy-online/",
          "author": "Manish Shivanandhan",
          "description": "In today’s growing cyber threat landscape, it is important to learn how to protect yourself. In this article, I'll share my five favorite tools you can use to protect your privacy online. Why Online Privacy is Important Have you ever wondered how valuable your data is? Every app, website, and",
          "link": "https://www.freecodecamp.org/news/how-to-protect-your-privacy-online/",
          "publishedOn": "2023-01-02T22:33:08.000Z",
          "wordCount": 2042,
          "title": "How to Protect Your Privacy Online – Five Useful Tools",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2023/01/security-tools.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-add-custom-network-to-metamask/",
          "author": "Joshua Omobola",
          "description": "As a developer, you can enhance the user experience of your decentralized applications (DApps) by allowing users to easily add your network to their Metamask wallet with just one click.  This simplifies the process of onboarding users to your application, since they don't have to manually add the network",
          "link": "https://www.freecodecamp.org/news/how-to-add-custom-network-to-metamask/",
          "publishedOn": "2023-01-02T22:17:22.000Z",
          "wordCount": 1188,
          "title": "How to Add a Custom Network to Metamask with JavaScript",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Frame-1--3--1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/file-permissions-in-linux-chmod-command-explained/",
          "author": "Arunachalam B",
          "description": "Just as with other operating systems, multiple users can create user accounts and share the same machine running Linux OS.  But whenever different users share a system, problems of privacy can easily arise. The first user may not wish the next user to view, edit, or delete their files,",
          "link": "https://www.freecodecamp.org/news/file-permissions-in-linux-chmod-command-explained/",
          "publishedOn": "2023-01-02T22:17:02.000Z",
          "wordCount": 2637,
          "title": "File Permissions in Linux – How to Use the chmod Command",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Banner---File-permission-blog-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-to-code-rpg-1-5-update/",
          "author": "Lynn Zheng",
          "description": "Hello from the Learn to Code RPG dev team! We are Lynn, KayLa, and Nielda. And we've been hard at work building out new adventures for our characters. I'm excited to announce the launch of Learn to Code RPG v1.5, a year after the launch of Learn to Code RPG",
          "link": "https://www.freecodecamp.org/news/learn-to-code-rpg-1-5-update/",
          "publishedOn": "2022-12-23T02:43:43.000Z",
          "wordCount": 2134,
          "title": "Learn to Code RPG Version 1.5 is Now Playable with Hours of New Gameplay",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/splash-2-lowres-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/serverless-caching-for-your-web-applications/",
          "author": "Andrew Brown",
          "description": "When to Use a Cache When you are building a web-application, you'll need to fetch data from a database. As your traffic and the size of your database grows, you will find that querying your database gets slower and slower. In order to return requests to users quickly, a cache",
          "link": "https://www.freecodecamp.org/news/serverless-caching-for-your-web-applications/",
          "publishedOn": "2022-12-22T20:45:05.000Z",
          "wordCount": 1830,
          "title": "How to Cache Expensive Database Queries Using the Momento Serverless Cache",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-tiger-lily-4483610.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/string-equality-in-javascript-how-to-compare-strings-in-js/",
          "author": "Joel Olawanle",
          "description": "When writing code or building a solution, you might need to compare two strings to see if they are the same before proceeding with an operation. For example, when a user signs in, you'll want to compare the username the provide to the one in your database to see if",
          "link": "https://www.freecodecamp.org/news/string-equality-in-javascript-how-to-compare-strings-in-js/",
          "publishedOn": "2022-12-22T18:57:16.000Z",
          "wordCount": 1396,
          "title": "String Equality in JavaScript – How to Compare Strings in JS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-template--3-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/adding-to-a-dict-in-python-how-to-add-to-a-dictionary/",
          "author": "Kolade Chris",
          "description": "A Python dictionary is like a JavaScript object – it’s a sequence of key:value  pairs. So, you can create them like this: stack_dict = {     \"frontend\": \"JavaScript\",     \"backend\": \"Node JS\",     \"markup\": \"HTML and JSX\", } To access",
          "link": "https://www.freecodecamp.org/news/adding-to-a-dict-in-python-how-to-add-to-a-dictionary/",
          "publishedOn": "2022-12-22T18:04:49.000Z",
          "wordCount": 1315,
          "title": "Adding to a Dict in Python – How to Add to a Dictionary",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/addToDict.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-javascript-works-behind-the-scene-javascript-execution-context/",
          "author": "Rwitesh Bera",
          "description": "Have you ever wondered how JavaScript works behind the scenes? It's actually quite fascinating! And that's what you'll learn about here. JavaScript is a single-threaded interpreted language. Every browser has its own JavaScript engine. Google Chrome has the V8 engine, Mozilla Firefox has SpiderMonkey, and so on. They all are",
          "link": "https://www.freecodecamp.org/news/how-javascript-works-behind-the-scene-javascript-execution-context/",
          "publishedOn": "2022-12-22T17:50:05.000Z",
          "wordCount": 1733,
          "title": "JavaScript Execution Context – How JS Works Behind the Scenes",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Dark-Blue-Illustrated-Techno-Daily-Smore-Header--1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-enumerate-in-python/",
          "author": "Suchandra Datta",
          "description": "The enumerate() function is one of the built-in functions in Python. It provides a handy way to access each item in an iterable, along with a count value that specifies the order in which the item was accessed.  In this article you will learn all that you need to",
          "link": "https://www.freecodecamp.org/news/what-is-enumerate-in-python/",
          "publishedOn": "2022-12-22T15:56:07.000Z",
          "wordCount": 2336,
          "title": "What is enumerate() in Python? Enumeration Example",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-yan-krukov-8612931.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/filtering-in-csharp-how-to-filter-a-list-with-code-examples/",
          "author": "Edeh Israel Chidera",
          "description": "Filtering through a data set is one of the most basic operations a developer should know how to perform.  Filtering [https://learn.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/filtering-data]  refers to the process of restricting the result set to contain only those elements that satisfy a specified condition. It is also known as selection.  To",
          "link": "https://www.freecodecamp.org/news/filtering-in-csharp-how-to-filter-a-list-with-code-examples/",
          "publishedOn": "2022-12-21T21:45:12.000Z",
          "wordCount": 1636,
          "title": "Filtering in C# – How to Filter a List with Code Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/ferenc-almasi-tvHtIGbbjMo-unsplash.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/typeerror-cant-multiply-sequence-by-non-int-of-type-float-solved-python-error-3/",
          "author": "Kolade Chris",
          "description": "Most times when you encounter errors while coding, you can discover the reason why the error is occurring and how you can fix it in the error message. The Python error, \"TypeError: can't multiply sequence by non-int of type float\" is no exception to that. I have prepared this article",
          "link": "https://www.freecodecamp.org/news/typeerror-cant-multiply-sequence-by-non-int-of-type-float-solved-python-error-3/",
          "publishedOn": "2022-12-21T21:13:46.000Z",
          "wordCount": 1312,
          "title": "TypeError: can't multiply sequence by non-int of type float [Solved Python Error]",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-polina-zimmerman-3747132.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-use-scapy-python-networking/",
          "author": "Omer Rosenbaum",
          "description": "In this post you will learn about an amazing tool named Scapy. Scapy is a Python library that enables us to send, sniff, and dissect network frames.  It is useful in a variety of use cases, one of which is to actually get some hands-on experience when you learn",
          "link": "https://www.freecodecamp.org/news/how-to-use-scapy-python-networking/",
          "publishedOn": "2022-12-21T21:02:17.000Z",
          "wordCount": 2004,
          "title": "How to Use Scapy – Python Networking Tool Explained",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Computer-Networks-Hub-Switch--1-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/concurrent-programming-in-go/",
          "author": "Rwitesh Bera",
          "description": "Concurrency refers to a programming language's ability to deal with lots of things at once. A good way to understand concurrency is by imagining multiple cars traveling on two lanes. Sometimes the cars overtake each other, and sometimes they stop and let others pass by. Another good example is when",
          "link": "https://www.freecodecamp.org/news/concurrent-programming-in-go/",
          "publishedOn": "2022-12-21T19:02:59.000Z",
          "wordCount": 2014,
          "title": "Concurrent Programming in Go – Goroutines, Channels, and More Explained with Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/2-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/download-trim-mp3-from-youtube-with-python/",
          "author": "Otavio Ehrenberger",
          "description": "Everybody's different, but I believe that nearly all of us enjoy listening to music. If you want to keep a local version of audio streams you often listen to, you'll need to download these files. Sometimes you'll also want to clip a portion of this audio file instead of having",
          "link": "https://www.freecodecamp.org/news/download-trim-mp3-from-youtube-with-python/",
          "publishedOn": "2022-12-21T18:57:27.000Z",
          "wordCount": 2932,
          "title": "How to Download and Trim MP3s from YouTube with Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-pixabay-164821.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-abstraction-in-programming-for-beginners/",
          "author": "Ryan Michael Kay",
          "description": "This article will not be a dry and boring explanation of abstract classes, interfaces, protocols, or similar software entities. I will explain what they are in simple terms, but my main goal is to change how you think about abstractions in general. All of this is in service of helping",
          "link": "https://www.freecodecamp.org/news/what-is-abstraction-in-programming-for-beginners/",
          "publishedOn": "2022-12-21T18:08:21.000Z",
          "wordCount": 3678,
          "title": "What is Abstraction in Programming? Explained for Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/smartphone-g7993a9917_1280-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-build-a-santa-tracker-app-with-next-js-react-leaflet/",
          "author": "Colby Fayock",
          "description": "It's the holiday season and Santa's coming! But just like he watches all of us, we can build a map-based tracking app to keep an eye on him and find out when he'll come on Christmas night with Next.js and React Leaflet.  *  How can we track Santa?",
          "link": "https://www.freecodecamp.org/news/how-to-build-a-santa-tracker-app-with-next-js-react-leaflet/",
          "publishedOn": "2022-12-21T16:42:06.000Z",
          "wordCount": 3480,
          "title": "How to Build a Santa Tracker App with Next.js and React Leaflet",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/santa-tracking-map-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/database-normalization-1nf-2nf-3nf-table-examples/",
          "author": "Kolade Chris",
          "description": "In relational databases, especially large ones, you need to arrange entries so that other maintainers and administrators can read them and work on them. This is why database normalization is important. In simple words, database normalization entails organizing a database into several tables in order to reduce redundancy. You can",
          "link": "https://www.freecodecamp.org/news/database-normalization-1nf-2nf-3nf-table-examples/",
          "publishedOn": "2022-12-21T16:40:26.000Z",
          "wordCount": 1653,
          "title": "Database Normalization – Normal Forms 1nf 2nf 3nf Table Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/normalization.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-create-stunning-qr-codes-with-python/",
          "author": "Shittu Olumide",
          "description": "A quick response (QR) code is a barcode that a digital device can easily scan. It encodes data as a series of pixels in a square grid.  Tracking information about supply chains using QR codes is very useful in marketing and advertising campaigns. The International Organization for Standardization certified",
          "link": "https://www.freecodecamp.org/news/how-to-create-stunning-qr-codes-with-python/",
          "publishedOn": "2022-12-21T15:40:05.000Z",
          "wordCount": 1751,
          "title": "How to Create Stunning QR Codes with Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/How-to-create-stunning-QR-codes-with-python-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-build-your-own-saas-pagerduty-clone/",
          "author": "Beau Carnes",
          "description": "One of the best ways to learn software development is to create a slimmed-down version of software you use every day to get a better understanding of how it might work. This process helps you understand the problem space constraints and techniques required to build a real-world use-case. We just",
          "link": "https://www.freecodecamp.org/news/how-to-build-your-own-saas-pagerduty-clone/",
          "publishedOn": "2022-12-20T13:47:49.000Z",
          "wordCount": 11135,
          "title": "How to Build Your Own SaaS – PagerDuty Clone",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/maxresdefault.jpeg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-get-your-first-job-in-infosec/",
          "author": "Megan Kaczanowski",
          "description": "Getting your first job in information security (infosec, or cybersecurity) can be tough.  It's (still) a relatively new industry, and job roles and descriptions aren't always consistent. Plus, it can be hard to figure out where to get started, what skills you need, and how you can acquire them.",
          "link": "https://www.freecodecamp.org/news/how-to-get-your-first-job-in-infosec/",
          "publishedOn": "2022-12-19T23:32:44.000Z",
          "wordCount": 3410,
          "title": "How to Get Your First Job in InfoSec",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-tima-miroshnichenko-5380665.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/have-fun-building-react-apps/",
          "author": "Reed Barger",
          "description": "Building React apps can either be a very fun experience or a very difficult and tedious one, based off of the tools you choose. React is a JavaScript library that, unlike frameworks like Angular, leave us to making a lot of decisions on our own. You have to choose which",
          "link": "https://www.freecodecamp.org/news/have-fun-building-react-apps/",
          "publishedOn": "2022-12-19T21:41:26.000Z",
          "wordCount": 2389,
          "title": "How to Have Fun Building React Apps",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/mugshotbot.com_customize_color-teal-discounted_price--image-fa229fca-mode-light-pattern-charlie_brown-price--theme-e_commerce-url-https___gifcoins.io.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/build-your-own-wireguard-vpn-in-five-minutes/",
          "author": "David Clinton",
          "description": "You may already understand how important a good VPN can be for maintaining the security and privacy of your mobile communications.  Whether you need to use your phone for banking over a public airport or coffee shop WiFi connection, or you're worried about the wrong people listening in on",
          "link": "https://www.freecodecamp.org/news/build-your-own-wireguard-vpn-in-five-minutes/",
          "publishedOn": "2022-12-19T20:46:15.000Z",
          "wordCount": 2246,
          "title": "How to Build Your Own Wireguard VPN in Five Minutes",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-ibrahim-boran-339814.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-speed-up-your-software-development-pipeline/",
          "author": "Andrej Kovacevic",
          "description": "If you've ever managed a software development pipeline—or have plans to do so—there's one thing you'll need to prioritize above almost all else: speed.  No matter the type of software you're working on, you'll always be under pressure to speed up your team's deliverables. Some of that pressure might",
          "link": "https://www.freecodecamp.org/news/how-to-speed-up-your-software-development-pipeline/",
          "publishedOn": "2022-12-19T17:51:06.000Z",
          "wordCount": 2086,
          "title": "How to Speed up Your Software Development Pipeline",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/software-development-team.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/rules-of-api-testing-for-beginners/",
          "author": "Hillary Nyakundi",
          "description": "In this digital age, APIs have become the cornerstone of how data is shared and processed. But many users are often unaware of the fact that they are putting their trust in an API and not a person. This is why it's important to leverage API testing techniques to ensure",
          "link": "https://www.freecodecamp.org/news/rules-of-api-testing-for-beginners/",
          "publishedOn": "2022-12-16T21:25:46.000Z",
          "wordCount": 1908,
          "title": "API Testing Best Practices – How to Test APIs for Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/OOP--2-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/accessibility-best-practices-to-make-web-apps-accessible/",
          "author": "Shruti Kapoor",
          "description": "Anyone should be able to use your websites and apps - both people with disabilities and those without. This will make your website accessible. Think about the last site you built, or your favorite site. Are you confident that anyone can use your site and perform the critical actions it",
          "link": "https://www.freecodecamp.org/news/accessibility-best-practices-to-make-web-apps-accessible/",
          "publishedOn": "2022-12-16T21:01:26.000Z",
          "wordCount": 1765,
          "title": "Accessibility Best Practices – What to Remember When Building Accessible Web Apps",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/ben-kolde-bs2Ba7t69mM-unsplash-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/pair-programming-with-the-chatgpt-ai-how-well-does-gpt-3-5-understand-bash/",
          "author": "David Clinton",
          "description": "We've been hearing a lot about artificial intelligence and natural language processing – and in particular about the latest version of OpenAI's GPT – for weeks.  The recent release of GPT 3.5, and specifically the very new ChatGPT tool, is definitely a huge leap forward. You may have read",
          "link": "https://www.freecodecamp.org/news/pair-programming-with-the-chatgpt-ai-how-well-does-gpt-3-5-understand-bash/",
          "publishedOn": "2022-12-16T17:51:07.000Z",
          "wordCount": 1896,
          "title": "Pair Programming with the ChatGPT AI – Does GPT-3.5 Understand Bash?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-pavel-danilyuk-8438951.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-create-a-telegram-bot-using-python/",
          "author": "Ashutosh Krishna",
          "description": "Automated chatbots are quite useful for stimulating interactions. We can create chatbots for Slack, Discord, and other platforms.  In this article, I'll teach you how to build a Telegram chatbot that will tell you your horoscope. So, let’s get started! How to Get Your Bot Token To set up",
          "link": "https://www.freecodecamp.org/news/how-to-create-a-telegram-bot-using-python/",
          "publishedOn": "2022-12-16T17:42:10.000Z",
          "wordCount": 1988,
          "title": "How to Create a Telegram Bot using Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Telegram-Bot.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-a-rom-price-and-cost-estimate-2/",
          "author": "Eamonn Cottrell",
          "description": "ROM stands for Rough Order of Magnitude. It is a project management guideline to determine the estimated range of costs for a project. This article will explain:  1. Who should use a ROM  2. When to use a ROM  3. How to calculate a ROM  4.",
          "link": "https://www.freecodecamp.org/news/what-is-a-rom-price-and-cost-estimate-2/",
          "publishedOn": "2022-12-16T17:27:32.000Z",
          "wordCount": 1151,
          "title": "What is a ROM? ROM Price and Cost Estimate",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/12.15.22-What-is-a-ROM.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/css-display-none-and-visibility-hidden-the-difference/",
          "author": "Dillion Megida",
          "description": "display:none and visibility:hidden are two style declarations you can use to hide elements on the screen with CSS. But what are the differences between them? When building applications, there are times that you want to hide elements visually (not deleting them from the DOM, just the screen). You can do",
          "link": "https://www.freecodecamp.org/news/css-display-none-and-visibility-hidden-the-difference/",
          "publishedOn": "2022-12-15T23:13:53.000Z",
          "wordCount": 1707,
          "title": "CSS display:none and visibility:hidden – What's the Difference?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/11.-display-visibility-2.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-select-the-right-ec2-instance/",
          "author": "Daniel Adetunji",
          "description": "EC2 (Elastic Compute Cloud) is the most widely-used compute service from AWS. It's also one of the oldest services launched by AWS, as it was started in 2006.  In this article, I will go through some things you should consider when selecting an EC2 instance.  You can think",
          "link": "https://www.freecodecamp.org/news/how-to-select-the-right-ec2-instance/",
          "publishedOn": "2022-12-15T19:08:27.000Z",
          "wordCount": 2720,
          "title": "How to Select the Right EC2 Instance – A Guide to EC2 Instances and Their Capabilities",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-photo.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/javascript-get-request-tutorial/",
          "author": "Joel Olawanle",
          "description": "When building applications, you will have to interact between the backend and frontend to get, store, and manipulate data. This interaction between your frontend application and the backend server is possible through HTTP requests. There are five popular HTTP methods you can use to make requests and interact with your",
          "link": "https://www.freecodecamp.org/news/javascript-get-request-tutorial/",
          "publishedOn": "2022-12-15T19:05:24.000Z",
          "wordCount": 1593,
          "title": "JavaScript Get Request – How to Make an HTTP Request in JS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-template--2-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/build-an-ai-for-two-player-turn-based-games/",
          "author": "Houssein Badra",
          "description": "Two-player turn-based games are games where two players play against each other, turn after turn, until one of them wins. Examples of these types of games are Tic-Tac-Toe, Backgammon, Mancala, Chess, and Connect 4. In this tutorial we will learn about the Minimax algorithm. It is a backtracking algorithm that",
          "link": "https://www.freecodecamp.org/news/build-an-ai-for-two-player-turn-based-games/",
          "publishedOn": "2022-12-15T18:24:15.000Z",
          "wordCount": 2369,
          "title": "How to Build an AI for Two-Player Turn-based Games",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/2825132-637490944552534550-16x9-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/solve-your-math-equation-on-terminal/",
          "author": "Arunachalam B",
          "description": "Can you solve the below math expression on your own without using any device? Take as much time as you need – but no tools allowed: ( ( 11 + 97 ) + ( 2 * 63 ) - ( 7 / 93 ) * ( 8 - 25 )",
          "link": "https://www.freecodecamp.org/news/solve-your-math-equation-on-terminal/",
          "publishedOn": "2022-12-15T17:40:54.000Z",
          "wordCount": 2273,
          "title": "How to Solve Math Equations in the Linux Terminal",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/FreeCodeCamp---Evaluate-expression-on-Terminal.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/independent-variable-vs-dependent-variable/",
          "author": "Kolade Chris",
          "description": "The meaning of the word \"variable\" depends on the field where it's being used. In programming, a variable is a particular piece of data that holds a value. Depending on the configuration, that value can change or remain fixed. For instance, in JavaScript, you can implement a variable to change",
          "link": "https://www.freecodecamp.org/news/independent-variable-vs-dependent-variable/",
          "publishedOn": "2022-12-15T17:32:36.000Z",
          "wordCount": 1461,
          "title": "What is the Difference Between an Independent Variable and a Dependent Variable?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/snowy-4689675_1280.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/javascript-range-create-an-array-of-numbers-with-the-from-method/",
          "author": "Joel Olawanle",
          "description": "The .from() method is a static method of the Array object in JavaScript ES6. It creates a new, shallow-copied Array instance from an array-like or iterable object like map and set. This method returns an array from any object with a length property. You can use it to create an",
          "link": "https://www.freecodecamp.org/news/javascript-range-create-an-array-of-numbers-with-the-from-method/",
          "publishedOn": "2022-12-14T21:15:06.000Z",
          "wordCount": 1466,
          "title": "JavaScript Range – How to Create an Array of Numbers with .from() in JS ES6",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-template--1-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/improve-your-javascript-skills-by-coding-a-card-game/",
          "author": "Beau Carnes",
          "description": "Building projects is a great way to improve your programming skills. We just published a course on the freeCodeCamp.org YouTube channel that will teach you how to create a digital card game with JavaScirpt, HTML, and CSS. This tutorial not only covers creating a basic card game using JavaScript but",
          "link": "https://www.freecodecamp.org/news/improve-your-javascript-skills-by-coding-a-card-game/",
          "publishedOn": "2022-12-14T18:56:08.000Z",
          "wordCount": 759,
          "title": "Improve Your JavaScript Skills by Coding a Card Game",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/jsgavin.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-next-js-tutorial/",
          "author": "Beau Carnes",
          "description": "Next.js is a popular framework for building server-rendered JavaScript applications. We just published a full course on the freeCodeCamp.org YouTube channel that will help you learn how to use Next.js. Next.js is built on top of React, which is a popular JavaScript library for building user interfaces. Next.js makes it",
          "link": "https://www.freecodecamp.org/news/learn-next-js-tutorial/",
          "publishedOn": "2022-12-14T18:35:12.000Z",
          "wordCount": 811,
          "title": "Learn Next.js for Scalable Web Apps",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Next.js-Course.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-read-a-file-line-by-line-in-python/",
          "author": "Dionysia Lemonaki",
          "description": "When coding in Python, there may be times when you need to open and read the contents of a text file. Luckily enough, there are several ways to do this in Python. The language has many built-in functions, methods, and keywords that you can use to create, write, read and",
          "link": "https://www.freecodecamp.org/news/how-to-read-a-file-line-by-line-in-python/",
          "publishedOn": "2022-12-14T17:58:48.000Z",
          "wordCount": 1795,
          "title": "How to Read a File Line by Line in Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-mateusz-dach-450035.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-solidity-handbook/",
          "author": "Zubin Pratap",
          "description": "When I changed careers from lawyer to software engineer [/news/from-lawyer-to-google-engineer/] in 2018, I never imagined that I’d enjoy being a developer as much as I do. I also never thought I'd end up working for amazing organizations like Google [/news/coding-interview-prep-for-big-tech/]  and Chainlink labs.  After 15 years in law",
          "link": "https://www.freecodecamp.org/news/learn-solidity-handbook/",
          "publishedOn": "2022-12-14T15:45:30.000Z",
          "wordCount": 19072,
          "title": "Learn Solidity – A Handbook for Smart Contract Development",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-pixabay-417173--2-.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/linux-shells-explained/",
          "author": "Anthony Behery",
          "description": "When you open up your terminal, chances are that it uses Bash as its UNIX shell environment. But other \"shell\" environments exist. There are other environments such as the C Shell, Korn Shell, Z Shell, and even the Fish Shell. All of these different shell environments have their own pros",
          "link": "https://www.freecodecamp.org/news/linux-shells-explained/",
          "publishedOn": "2022-12-13T21:55:05.000Z",
          "wordCount": 1526,
          "title": "Linux Shells for Beginners – Bash, Zsh, and Fish Explained",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-oleksandr-pidvalnyi-320260.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-calculate-percentage-differences-between-two-numbers-in-excel-cell-percentage-change-tutorial/",
          "author": "Eamonn Cottrell",
          "description": "Spreadsheets are powerful and awesome. 💪  In this tutorial I will show you four ways to find the percentage difference between two numbers in Excel. I'll also show you how to use custom functions in Google Sheets. 👍 The four techniques (and one bonus) we'll use are:  1.",
          "link": "https://www.freecodecamp.org/news/how-to-calculate-percentage-differences-between-two-numbers-in-excel-cell-percentage-change-tutorial/",
          "publishedOn": "2022-12-13T21:49:00.000Z",
          "wordCount": 2081,
          "title": "How to Calculate Percentage Differences Between Two Numbers in Excel - Cell Percentage Change Tutorial",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/12.13.22-Percent-Change2.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-protect-against-sql-injection-attacks/",
          "author": "Manish Shivanandhan",
          "description": "Databases are the backbone of any application. They give us a way to store and organize large amounts of data in a way that we can easily access, manage, and update it. From small businesses to large-scale enterprises, databases play a critical role in keeping the systems up and running.",
          "link": "https://www.freecodecamp.org/news/how-to-protect-against-sql-injection-attacks/",
          "publishedOn": "2022-12-13T00:40:15.000Z",
          "wordCount": 1884,
          "title": "SQL Injection Attacks – How to Use SQLMap to Find Database Vulnerabilities",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Stealth-Security---Blog-Banner--27-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-an-algorithm-definition-for-beginners/",
          "author": "Kolade Chris",
          "description": "If you’re a student and want to study computer science, or you’re learning to code, then there’s a chance you’ve heard of algorithms. Simply put, an algorithm is a set of instructions that performs a particular action. Contrary to popular belief, an algorithm is not some piece of code that",
          "link": "https://www.freecodecamp.org/news/what-is-an-algorithm-definition-for-beginners/",
          "publishedOn": "2022-12-13T00:38:26.000Z",
          "wordCount": 1577,
          "title": "What is an Algorithm? Algorithm Definition for Computer Science Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/laptop-gfe4d4bfc0_1280.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-remove-an-item-from-a-list-in-c/",
          "author": "Edeh Israel Chidera",
          "description": "While building your application in C#, you might need to store and manipulate sets of data. The List class is a member of the System.Collections.Generic  namespace and you use it to store multiple objects of the same datatype. The List class represents a collection of strongly typed lists of",
          "link": "https://www.freecodecamp.org/news/how-to-remove-an-item-from-a-list-in-c/",
          "publishedOn": "2022-12-13T00:28:02.000Z",
          "wordCount": 1137,
          "title": "How to Remove an Item from a List in C#",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/bernd-dittrich-d_3EKbSg1tg-unsplash.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/overview-of-cyber-security-certifications/",
          "author": "Megan Kaczanowski",
          "description": "Certifications aren't strictly necessary in order to get hired as a cybersecurity analyst (with the notable exception of many government jobs). But they can help you demonstrate to an HR recruiter or hiring manager that you have a specific skillset via a third party's assessment of your skills. The process",
          "link": "https://www.freecodecamp.org/news/overview-of-cyber-security-certifications/",
          "publishedOn": "2022-12-13T00:22:54.000Z",
          "wordCount": 2299,
          "title": "Cyber Security Certifications – What Certs to Get for a Career in Infosec",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-martijn-adegeest-633565.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-programming-tutorial-for-beginners/",
          "author": "Estefania Cassingena Navone",
          "description": "Welcome to the amazing world of programming. This is one of the most useful and powerful skills that you can learn and use to make your visions come true.  In this handbook, we will dive into why programming is important, its applications, its basic concepts, and the skills you",
          "link": "https://www.freecodecamp.org/news/what-is-programming-tutorial-for-beginners/",
          "publishedOn": "2022-12-12T17:10:03.000Z",
          "wordCount": 8117,
          "title": "What is Programming? A Handbook for Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/what-is-programming.png"
        }
      ]
    },
    {
      "title": "Self-Hosted Alternatives to Popular Services",
      "feedUrl": "https://www.reddit.com/r/selfhosted.rss",
      "siteUrl": "https://www.reddit.com/r/selfhosted",
      "articles": [
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106zift/nginx_reverse_proxy_game_hosting/",
          "author": null,
          "description": "Okay, so I've seen other posts related to this, but not quite covering what I am trying to figure out.\n I am hosting multiple game servers for a group of friends, and I am setting up a reverse proxy to allow subdomains to resolve to different servers. I am running into an issue with one game server, though, as it uses three ports. One for the game itself, one for query, and one for beacon. I have my own domain name, a DDNS service with A records set up and subdomains. What I am trying to figure out is how to configure Nginx to forward game.example.com to three different ports so the beacon and query don't have issues.\n My understanding is that the request will hit my router, trigger the port forwarding to the proxy but still pass through the subdomain then the proxy will redirect that subdomain and ports to the proper server. So like this:\n game.example.com\n V\n Proxy\n V\n XX.XX.XX.XX:game-port\n XX.XX.XX.XX:query-port\n XX.XX.XX.XX:beacon-port\n To make this even more complicated, I am looking at hosting two of the same game servers on the same network and will need to redirect the query and beacon port from game2.example.com to XX.XX.XX.YY instead. I cannot change the beacon and query ports afaik. I am also going to need to know how to do this for other servers as well. Right now everything is set up as port forwarding, but I want to reduce open ports and complexity on my poor router. Bonus points if I can use the same ports for each additional server and have to open fewer ports.\n All these servers, including the reverse proxy, are VMs and everything is locally hosted behind my router. I do have a way to connect from a different connection to test whether or not it works without having to enlist a friend.\n I initially did this as port forwarding, but that won't continue to work as I grow the server.\n    submitted by    /u/EllemNovelli  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106zift/nginx_reverse_proxy_game_hosting/",
          "publishedOn": "2023-01-09T00:35:46.000Z",
          "wordCount": 19318,
          "title": "Nginx Reverse Proxy game hosting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106zb3q/pubkey_ssh_authentication_on_guacamole/",
          "author": null,
          "description": "Hey everyone, I just setup Guacamole on docker. The app seems to be working fine for remote connections. However I am facing issues with SSH via PubKey authentication.\n SSH with password authentication works alright. I have generated a key in the PEM format since guacamole does not support the newer formats. However, adding the Private Key and password for the key file does not seem to complete SSH authentication.\n ​\n https://preview.redd.it/mvrqz88jwwaa1.png?width=2650&format=png&auto=webp&s=7355cce563b316ca353edbd2226628c808563125\n Been getting the following errors within the guacd container logs,\n guacd[667]: INFO: Auth key successfully imported. guacd[667]: ERROR: Host key not found for <hostname>. guacd[667]: ERROR: Host key did not match any provided known host keys. \n Not sure how guacamole checks for the Host Key and compares it with the SSH server. I also tried adding Public HostKey values in there but it still does not work. Wondering if someone could help me with getting PubKey working for SSH connections. Appreciate any assistance in advance !!\n    submitted by    /u/koolboy145  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106zb3q/pubkey_ssh_authentication_on_guacamole/",
          "publishedOn": "2023-01-09T00:26:57.000Z",
          "wordCount": 19553,
          "title": "PubKey SSH authentication on Guacamole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106z9oz/question_using_authentik_npm_can_i_require/",
          "author": null,
          "description": "I've set up a recipe book (Tandoor) which I'd like to share with others outside my network. My goal is to not have to authenticate to authentik when on the LAN, but force WAN users to authenticate to view anything. Anyone know how to make this happen? Thanks!\n Edited to clarify: right now when I access the subdomain recipe.example.com, it redirects to the authentik login screen, no matter if I access that locally or externally. Even though my home DNS resolves that domain to 192.168.x.y (the NPM server) while on the LAN. I would like to continue to access thru NPM because it keep the certificates working without browser annoyances. I'd also like to use authentik because I don't like the basic auth with NPM.\n    submitted by    /u/jschwalbe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106z9oz/question_using_authentik_npm_can_i_require/",
          "publishedOn": "2023-01-09T00:25:13.000Z",
          "wordCount": 19532,
          "title": "Question: Using Authentik + NPM, can I require authentication ONLY for external access?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106z7xr/is_anyone_is_self_hosting_solidproject_cnn_is/",
          "author": null,
          "description": "submitted by    /u/xanderdad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106z7xr/is_anyone_is_self_hosting_solidproject_cnn_is/",
          "publishedOn": "2023-01-09T00:23:08.000Z",
          "wordCount": 19278,
          "title": "Is anyone is self hosting solidproject? CNN is running a fresh story today on Inrupt.com - the commercial and Tim Berners Lee backed start up - that provides an enterprise version of the solidproject.org. Looks very interesting.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106ywte/is_there_something_like_keycloak_or_authelia_that/",
          "author": null,
          "description": "I'd like to secure some services that don't have a login, like simple websites, or tools whose login I don't trust. I could of course use basic auth but managing passwords, especially on mobile or when I want to give access to others, is a bit cumbersome. So I'd like to use existing identity providers like GitLab or Google instead of a purely local user database.\n To integrate the webserver/reverse proxy with the authentication service I would normally use HTTP forward auth.\n Keycloak can use identity providers, but Keycloak doesn't support forward auth. Authelia supports forward auth, but it doesn't seem to support external identity providers.\n    submitted by    /u/AndreKR-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106ywte/is_there_something_like_keycloak_or_authelia_that/",
          "publishedOn": "2023-01-09T00:10:00.000Z",
          "wordCount": 18606,
          "title": "Is there something like Keycloak or Authelia that supports both forward auth and identity providers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106xy5u/grafana_dashboards/",
          "author": null,
          "description": "submitted by    /u/CoolGaM3r215  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106xy5u/grafana_dashboards/",
          "publishedOn": "2023-01-08T23:29:53.000Z",
          "wordCount": 19319,
          "title": "Grafana dashboards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106x4pw/this_may_have_been_asked_here_already_but_whats/",
          "author": null,
          "description": "submitted by    /u/InvaderDoom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106x4pw/this_may_have_been_asked_here_already_but_whats/",
          "publishedOn": "2023-01-08T22:57:33.000Z",
          "wordCount": 19548,
          "title": "This may have been asked here already, but whats the preferred OS for everyone’s homelab applications and servers? I’ve personally been running Ubuntu mainly for a while and recently started making the switch to Debian instead as I’ve gotten more fluent with the command line.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106uizy/backing_up_emails_locally/",
          "author": null,
          "description": "I like the idea of using TutaNota, but its 10gb limit makes me weary. Is there a means you guys use to back emails up, so I can access them in the case I need them in the long future?\n    submitted by    /u/kittywrastler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106uizy/backing_up_emails_locally/",
          "publishedOn": "2023-01-08T21:15:34.000Z",
          "wordCount": 20452,
          "title": "Backing up Emails Locally?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106tcll/resources_to_learn_more/",
          "author": null,
          "description": "I am on my 3rd NAS, but only recently in the past year have I started using docker. I am windows at work and at home all Mac/iOS family. I no absolutely no linux and everything that I do with my synology and docker is via the GUI.\n I am looking for resources to learn, preferably book/ebook formats. Aka what textbooks might you recommend to learn, with my focus being learning more that I can do with synology. I do currently had a few dockers setup with reverse proxy, but topics I would like to learn would be:\n - Linux\n - Security\n - Networking\n - Any other topics that you can recommend a selfhoster.\n TIA.\n    submitted by    /u/Jmanko16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106tcll/resources_to_learn_more/",
          "publishedOn": "2023-01-08T20:29:14.000Z",
          "wordCount": 19441,
          "title": "Resources to Learn More",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106smzu/selfhosting_library/",
          "author": null,
          "description": "Is there a way to digitalize my books and self hosting them? And how would I go about doing it?\n    submitted by    /u/Lukiluke159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106smzu/selfhosting_library/",
          "publishedOn": "2023-01-08T20:00:57.000Z",
          "wordCount": 18936,
          "title": "Selfhosting library?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106sb5p/need_help_setting_up_dashboard_for_smart/",
          "author": null,
          "description": "I've been building a smart arduino-based thermostat and it's been working pretty well, and I've gotten to the point of data/event logging to a raspberry pi via wifisocket (via python).\n I'd like to have a data visualization dashboard hosted locally where I can view data (temp/humidity min/max per room, A/C uptime, heat uptime, etc.) over the past few days/weeks.\n tipboard looked very promising but I haven't been able to get it to successfully run anything on either windows or raspberry pi. If anyone has any success with tipboard, I'd love some help debugging this because it looks pretty slick. If not, I'd appreciate any alternatives.\n ​\n I've got some coding knowhow, but I'm pretty new to this entire space. Because I've written the logging code myself (python), I can be pretty flexible with interfaces/storage methods\n    submitted by    /u/AinulindaleSlacker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106sb5p/need_help_setting_up_dashboard_for_smart/",
          "publishedOn": "2023-01-08T19:47:48.000Z",
          "wordCount": 18619,
          "title": "Need help setting up dashboard for smart thermostat",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106q9de/looking_for_simple_messagingcall_app/",
          "author": null,
          "description": "My parents are in Iran and the situation with government blocking all communication means like WhatsApp and … is just awful. We can’t even have a proper call without them having to struggle connecting to VPNs that constantly get blocked too. I am in search for a alternative for WhatsApp or telegram that I can host easily and have an android and iOS client. I’ve checked matrix and element but to be honest it seemed a bit overkill and complicated especially the element client. Do u know any other open source solution that I can host for my family to be in touch?\n    submitted by    /u/manofnibiru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106q9de/looking_for_simple_messagingcall_app/",
          "publishedOn": "2023-01-08T18:26:08.000Z",
          "wordCount": 19190,
          "title": "Looking for simple messaging/call app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106pddg/mount_samba_network_share_on_cockpit/",
          "author": null,
          "description": "Hi, I'm using Cockpit to manage my Ubuntu server and I want to mount a network share (Synology NAS) through the web interface. Under the \"Storage\" page it is possible to mount a NFS share with options such as auto-mount at boot and such, and this is exactly what I need for Samba. I found a third-party plugin to manage Samba shares (link), but it can only create new and manage shares and not mount existing network shares (I think, I haven't tried it yet). Does anyone know how to mount SMB shares using Cockpit? Thanks in advance. \n https://preview.redd.it/zortt2h9xuaa1.png?width=1804&format=png&auto=webp&s=a5b3e39421931983ce52e788bf602875b76de112\n    submitted by    /u/sirajuddin97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106pddg/mount_samba_network_share_on_cockpit/",
          "publishedOn": "2023-01-08T17:51:09.000Z",
          "wordCount": 17640,
          "title": "Mount Samba network share on Cockpit",
          "imageUrl": "https://external-preview.redd.it/6fh_MMhANR5UMSCIQERDyvfNLfDskOdTviD3Vm6gCoI.jpg?auto=webp&s=09ae1b98f5197dc58e2028ad367585b73169ab4f"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106o0b1/owncloud/",
          "author": null,
          "description": "Running a Dell R520 server with ESXi and probably Ubuntu server. looking at Owncloud for wife and 2 kids running android phones and windows and mac laptops. Any gotcha's I should know about or alternatives I should look at. I am aware that I will need to purchase the mobile version.\n    submitted by    /u/midasza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106o0b1/owncloud/",
          "publishedOn": "2023-01-08T16:57:21.000Z",
          "wordCount": 20101,
          "title": "Owncloud",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106n3m4/looking_for_a_photo_storage_for_home_server/",
          "author": null,
          "description": "Hey guys. I am looking for a self hosted photo pool service in which it is easy to transfer photos from my iPhone and can be viewed on any device. I want to sort images into Albums from our different trips and all. Is there anything like that?\n    submitted by    /u/sdevrajchoudhary  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106n3m4/looking_for_a_photo_storage_for_home_server/",
          "publishedOn": "2023-01-08T16:19:52.000Z",
          "wordCount": 18524,
          "title": "Looking for a Photo Storage for Home Server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106n2cm/evernote_alternative_with_sharing_function/",
          "author": null,
          "description": "Hi there,\n I use Joplin as an Evernote alternative. For synching between my phone and my PC, I use my Nextcloud installation within my web server.\n For shared notes, I still use Evernote with my wife. I really dislike Evernote in general. Especially the maximum number of devices in the free account, as well as the WYSIWYG editors and how they format differently on different clients.\n Unfortunately, Joplin doesn't have a sharing function. Because I have a shared website without the possibility to use Docker, I can't install Joplin server and I don't want to use Joplin cloud.\n Therefore, I probably need a different alternative to Joplin which allows sharing.\n I have a basic shared web server where I already run Nextcloud and where I can run other PHP based software.\n I either need really good browser clients for mobile and desktop. Alternatively, I need clients for Android, IOS, MacOS and Linux.\n Thank you in advance.\n    submitted by    /u/Antihero89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106n2cm/evernote_alternative_with_sharing_function/",
          "publishedOn": "2023-01-08T16:18:24.000Z",
          "wordCount": 18322,
          "title": "Evernote alternative with sharing function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106m19i/recommendation_how_to_build_a_simple_web/",
          "author": null,
          "description": "I want to backup some Calendars and Adress-Books via Caldav/Carddav and built in python to pull those backups. Since I dont want to store my passwords in plain-text in the script they are polled from the user via the CLI when executing the script. \n Is there an easy (dockerized?) Way to build a simple webinterface to perform this task? I.e. Clicking on start, entering the PW and having the script run its course?\n    submitted by    /u/cmdr_cathode  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106m19i/recommendation_how_to_build_a_simple_web/",
          "publishedOn": "2023-01-08T15:35:10.000Z",
          "wordCount": 19944,
          "title": "Recommendation how to build a simple web interface to trigger a python/bash script",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106lbil/anyone_have_a_guide_to_putting_wger_gym_app_on/",
          "author": null,
          "description": "Hi there,\n Trying to get wger gym self hosted app onto portainer but having issues.\n Does anyone have a guide to putting wger gym app on portainer that could be used?\n Let me know anyone who has done this or is close to it.\n Thanks,\n    submitted by    /u/Nath2125  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106lbil/anyone_have_a_guide_to_putting_wger_gym_app_on/",
          "publishedOn": "2023-01-08T15:04:15.000Z",
          "wordCount": 17711,
          "title": "Anyone have a guide to putting wger gym app on portainer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106kijz/alternative_to_joplin_that_is_webbased_based/",
          "author": null,
          "description": "Hello,\n I have been testing Joplin and it is pretty good, has web-clipping functionality and good clients.\n I have realised however that it is all client side, with storage self-hosted.\n Is there an alternative to Joplin that is web based? Ideally can OCR, and search attached PDFs and web-clippings.\n Thanks!\n    submitted by    /u/ikukuru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106kijz/alternative_to_joplin_that_is_webbased_based/",
          "publishedOn": "2023-01-08T14:28:02.000Z",
          "wordCount": 18865,
          "title": "Alternative to Joplin that is web-based based?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106jp0q/hosting_a_basic_readonly_browse_of_an_mysql/",
          "author": null,
          "description": "I want to be able to host a MySQL database I have that can be browsed online, including the ability to click between records that are related. Is there any tool like this? I have tried searching online but haven't come up with anything.\n PHPmyadmin won't work because I don't want it to have a login and I want to be able to click through related records.\n I am hoping there's a script that can point to a mysql database with username and password and it will just display the tables via php or something similar that can be browsed. This is text-only.\n I tried just importing into Airtable to share that way, but there is over one million records so that won't work as they cap at around 50,000 for the Pro account. The database is 1GB when uncompressed.\n Thanks!\n    submitted by    /u/SangieRedwolf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106jp0q/hosting_a_basic_readonly_browse_of_an_mysql/",
          "publishedOn": "2023-01-08T13:49:34.000Z",
          "wordCount": 18592,
          "title": "Hosting a basic read-only browse of an mysql database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106goqb/selfhosted_ottiptv_solution_part_code_in/",
          "author": null,
          "description": "submitted by    /u/FastoGt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106goqb/selfhosted_ottiptv_solution_part_code_in/",
          "publishedOn": "2023-01-08T11:07:12.000Z",
          "wordCount": 18193,
          "title": "Self-hosted OTT/IPTV solution, part code in opensource",
          "imageUrl": "https://preview.redd.it/czml4h3oxsaa1.png?auto=webp&s=3148db57516c32b7d471f8a38720f52f20a9b0b3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106funj/is_there_a_self_hosted_social_manager/",
          "author": null,
          "description": "Hi everyone,\n I am looking for a social manager, where I can plan social posts in advanced.\n I am mainly looking for linkedin Instagram and Facebook.\n I saw a lot of SaaS solution, but none was open-source. Does anyone use one?\n    submitted by    /u/AccountSuspicious621  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106funj/is_there_a_self_hosted_social_manager/",
          "publishedOn": "2023-01-08T10:16:11.000Z",
          "wordCount": 20644,
          "title": "Is there a self hosted social manager?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/106fthx/simple_personal_knowledgebase/",
          "author": null,
          "description": "I have a folder with all of my notes in markdown that I edit in nvim and sync to the server with Syncthing.\n I am looking for a way to generate html wiki everytime time the files are updated.\n I need to the app to:\n  \nnot enforce folder structure\n be simple (I don't need most of the features of wiki solutions)\n be nice looking out of the box\n have a tree of my files on the side\n a very simple builtin editor is nice but not required\n have an authentication system, so that only I can access it\n  \n   submitted by    /u/petalised  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/106fthx/simple_personal_knowledgebase/",
          "publishedOn": "2023-01-08T10:14:24.000Z",
          "wordCount": 20853,
          "title": "Simple personal knowledgebase",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1069k94/how_do_you_guys_handle_server_automation/",
          "author": null,
          "description": "I've been really getting into self-hosting world and this sub has played a large part. Initially, I was screwing around with a VPS on Hetzner, just installing packages and hosting containers. This works really great, but I wanted to be able to destroy the env and replicate it on another server with ease.\n This became a pain as I'd forget steps to set things up, etc. Fast forward, I setup Ansible, made a bunch of roles and playbooks and version controlled all my docker config, packages, etc. These playbooks automatically run and deploy from a private Github action over SSH. It's pretty neat because I can setup a fresh VPS with just a couple commands in less than 60 seconds. \n The downside is I feel the setup is a tad complicated, but not terrible. I chose Ansible because I used in the past and Saltstack (which we use at work) is a massive pain in the ass. Would love to hear how you guys automate things!\n    submitted by    /u/FeedMeAnAlgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1069k94/how_do_you_guys_handle_server_automation/",
          "publishedOn": "2023-01-08T04:22:30.000Z",
          "wordCount": 18642,
          "title": "How do you guys handle server automation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10661pz/jellyfin_and_nextcloud_on_truenas_or_proxmox/",
          "author": null,
          "description": "My home lab is setup as follows currently. Both servers are in a proxmox cluster. I don’t believe it’s most optimal but it was more for learning experience Server 1: Running Proxmox as Bare Metal OS Hosting Pihole, Portainer, Homer, Cloudflare tunnel VM, and test Windows VMs. Server 2: Running Proxmox as Bare Metal OS Hosting TrueNAS Core TrueNAS is barely configured, only have a test SMB share\n I’m replacing Server2 soon where I want to have TrueNAS scale running as the bare metal OS.\n I want to get into hosting a jellyfin server with radar and BitTorrent. I wanted to know if it’s best practice to host jellyfin, radarr, sonar, and BitTorrent on TrueNAS and use the local pools or is it better to run those on proxmox server 1 and use shared nfs drives from server 2 TrueNAS?\n    submitted by    /u/arrinh1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10661pz/jellyfin_and_nextcloud_on_truenas_or_proxmox/",
          "publishedOn": "2023-01-08T01:35:31.000Z",
          "wordCount": 20094,
          "title": "Jellyfin and Nextcloud on TrueNAS or Proxmox?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1065atb/rocketchat_file_uploads/",
          "author": null,
          "description": "when I try to upload a profile photo or upload and mp3 or mp4 in chat it acts like it's uploading...but then it stays still nothing happens.\n ​\n everytime users even me wanna change our profile pic we click save and we get the error shown below\n I even changed to amazon S3 to see if it helped and nothing works. \n the settings in Rocketchat are ok \n https://preview.redd.it/vqh658a9xpaa1.png?width=463&format=png&auto=webp&s=627bff1d2aee7910b24ba762a0b127d1825f6c59\n ​\n ​\n https://preview.redd.it/lvpajqtsxpaa1.png?width=607&format=png&auto=webp&s=cdcec96606a5fd223c8f21f25b1acff10a0cbdf7\n    submitted by    /u/MitsuruMiyata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1065atb/rocketchat_file_uploads/",
          "publishedOn": "2023-01-08T01:01:47.000Z",
          "wordCount": 18967,
          "title": "Rocketchat file uploads",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1061xyw/interface_with_several_capabilities/",
          "author": null,
          "description": "Hello, I’ve looked at numerous self hosted applications for music streaming. I’m looking for some advice on a platform that’s self hosted where users can sign up and register and/ or have a monthly subscription they pay for access. This is for an independent artist platform I’m building. Is there anything out there like that.\n    submitted by    /u/KangarooClassic7052  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1061xyw/interface_with_several_capabilities/",
          "publishedOn": "2023-01-07T22:40:29.000Z",
          "wordCount": 20560,
          "title": "Interface with several capabilities",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1060u60/heimdall_dashboard/",
          "author": null,
          "description": "Is there a way I can change “heimdall” to something of my own choosing?\n Screenshot\n    submitted by    /u/janisemzins  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1060u60/heimdall_dashboard/",
          "publishedOn": "2023-01-07T21:54:46.000Z",
          "wordCount": 19833,
          "title": "Heimdall dashboard",
          "imageUrl": "https://external-preview.redd.it/faf8Kat_QQeqKl1ea_T-MqkuL0TqlM9WejcYS5rb7Oc.jpg?auto=webp&s=b36936ba7bff74dd4b23ad4b91749842ea29cff5"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10602vi/going_crazy_with_wireguard/",
          "author": null,
          "description": "Hello Guys,\n I am trying to access my home network from outside. I am behind a CGNAT. To resolve the issue I have a VPS from Digital Ocean running Wireguard server and another VM in my home lab running Wireguard client.\n The configuration is as follows:\n Server Config:\n [Interface] PrivateKey = Address = 192.168.69.1/24 ListenPort = 51820 PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE [Peer] # This is the local VM in my network that initiates the connection (Peer 1) PublicKey= AllowedIps=0.0.0.0/0 PersistentKeepalive=25 [Peer] # My Phone PublicKey= AllowedIPs=192.168.69.3/32,10.116.1.0/24 [Peer] # My laptop PublicKey= AllowedIPs=192.168.69.4,10.116.1.0/24 \n Configuration of Peer 1:\n [Interface] PrivateKey = Address=192.168.69.2/32 [Peer] PublicKey = Endpoint = mypublicserverIP:51820 AllowedIPs = 0.0.0.0/0 \n Configuration of Laptop is almost the same as Peer 1\n - My issue is that I cannot access the internal LAN (10.116.1.0) from my laptop. I am going crazy. Can someone explain what is wrong with my configuration?\n Thank you\n    submitted by    /u/Geek77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10602vi/going_crazy_with_wireguard/",
          "publishedOn": "2023-01-07T21:22:46.000Z",
          "wordCount": 21306,
          "title": "Going crazy with Wireguard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105yi77/domain_register_porkbun_or_cloudflare/",
          "author": null,
          "description": "Hi, I want to register my first domain and I want to know what is better.\n ​\n What if I register with porkbun, can I use DNS and other services from cloudflare with this domain?\n ​\n It's only for personal use \n Update:\n Thanks for the fast answers! At the end I decided by Porkbun because on reddit have better customer service and I found a porkbun coupon that made 1 usd cheaper, hence, more cheap than Cloudflare.\n    submitted by    /u/maxtrix7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105yi77/domain_register_porkbun_or_cloudflare/",
          "publishedOn": "2023-01-07T20:16:54.000Z",
          "wordCount": 18492,
          "title": "Domain register Porkbun or Cloudflare?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105yeu7/self_hosted_security_system_with_no_internet/",
          "author": null,
          "description": "I'd like to setup a security camera system somewhere without internet. It does have phone lines I could tap into, and I have a secondary location with internet. I can assume there'll always be someone with Internet if I can get a message out. Even if I can just send out a text I'd be happy. \n I know dial up is a thing, I could go that route. I could get internet at this location, but I'm wondering what my options are without doing that.\n    submitted by    /u/justabadmind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105yeu7/self_hosted_security_system_with_no_internet/",
          "publishedOn": "2023-01-07T20:12:59.000Z",
          "wordCount": 18819,
          "title": "Self hosted security system with no internet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105vqr0/hardware_choice_for_beginner/",
          "author": null,
          "description": "I am interested in starting self hosting and am in the process of buying a gaming pc. My idea was to fulfill both needs with one machine running Windows. Is this a bad idea? I understand that performance may be affected which is fine with me since I rarely game to begin with. Is it realistic / a good idea to build a server running Windows?\n PS : I want to run Nexcloud, Plex or Jellyfin, and Radarr and Sonarr etc...\n EDIT : Would you recommend a Raspberry Pi?\n    submitted by    /u/hapaanon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105vqr0/hardware_choice_for_beginner/",
          "publishedOn": "2023-01-07T18:21:26.000Z",
          "wordCount": 19421,
          "title": "Hardware choice for beginner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105um0u/i_need_the_right_advice_from_you_guys/",
          "author": null,
          "description": "Hi there, I want to use a free hosting control panel, And I searched on Google and YouTube for the free/Open source hosting control panel.and I got so many options like CWP Web Panel, Vista Panel, OpenLiteSpeed panel, ISP config and many more.\n So I watched some videos and leaned that the CWP Web Panel is best as a free panel, But I'm not very sure about that, So need your help to select the best for me.\n I want secure and durable system that can host CMS like WordPress, Presta, And custom PHP web apps and have good security system.\n    submitted by    /u/shinchangupta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105um0u/i_need_the_right_advice_from_you_guys/",
          "publishedOn": "2023-01-07T17:35:07.000Z",
          "wordCount": 19547,
          "title": "I need the right advice from you guys 😃",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105uaw1/multiple_lxcs_or_all_services_in_one_lxc/",
          "author": null,
          "description": "I have jellyfin inside an LXC on a proxmox node. I'm setting up sonarr/radar and a few related services. I plan to install them alongside jellyfin in the same LXC (Ubuntu server in this case). But the thought occurred to me that I could add another LXC on the same node and put the new services there, or even spin up a new LXC for each individual service.\n I don't fully understand why you'd use one method over the other, except that using only one LXC has less overhead. But why might you want to use multiple LXCs? Please help this beginner understand.\n    submitted by    /u/mentalflux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105uaw1/multiple_lxcs_or_all_services_in_one_lxc/",
          "publishedOn": "2023-01-07T17:22:21.000Z",
          "wordCount": 19720,
          "title": "Multiple LXCs or all services in one LXC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105tvgf/what_best_to_do_with_8tb_sas_35_wd_blacks/",
          "author": null,
          "description": "My work has a couple of the above mentioned drives that they no longer use after moving to vxrails and larger/ faster storage options.\n I’ve found a few enclosures that support SAS backplane I’m just not sure if Its the optimal solution. Just wanted to see if someone has a better idea or If anyone else has tried using sas drive enclosures? Pros/cons?\n TIA\n    submitted by    /u/WickedIT2517  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105tvgf/what_best_to_do_with_8tb_sas_35_wd_blacks/",
          "publishedOn": "2023-01-07T17:04:11.000Z",
          "wordCount": 19646,
          "title": "What best to do with 8tb SAS 3.5 WD blacks.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105tl5c/utility_for_keeping_track_of_used_ports/",
          "author": null,
          "description": "My apologies in advance if this has been asked before, nothing turned up in my search...\n As I continue to expand my homelab with Docker, I am starting to run into different containers that expose their User Interfaces on the same TCP port. \n ​\n Is there some utility that I can use to keep track of the used exposed ports on my host? I know that I can query Docker, but that list does not get returned in a nice sorted table. I've started a quick Google Doc spreadsheet, but this seems clumsy too, as I have to manually tell it to sort when I'm looking for a candidate port to expose on the host.\n By the way, all this is internal, nothing exposed outside my home network.\n Does anyone have some suggestions? I was thinking Netbox, but it seems a little overkill....\n Thanks!\n    submitted by    /u/RedPhule  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105tl5c/utility_for_keeping_track_of_used_ports/",
          "publishedOn": "2023-01-07T16:52:29.000Z",
          "wordCount": 19057,
          "title": "Utility for keeping track of used ports",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105tejx/jellyfin_january_is_going_well_over_at_selfhosted/",
          "author": null,
          "description": "submitted by    /u/Ironicbadger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105tejx/jellyfin_january_is_going_well_over_at_selfhosted/",
          "publishedOn": "2023-01-07T16:44:37.000Z",
          "wordCount": 20921,
          "title": "Jellyfin January is going well over at Self-Hosted podcast HQ! Jellyfin is now my #1 recommended app!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105plr8/what_can_an_i3530_and_8gb_of_ram_handle/",
          "author": null,
          "description": "as the title says haha! just want to know since im having a pc to use as a server with those specs\n    submitted by    /u/Wookie_104  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105plr8/what_can_an_i3530_and_8gb_of_ram_handle/",
          "publishedOn": "2023-01-07T13:57:01.000Z",
          "wordCount": 19656,
          "title": "What can an i3-530 and 8gb of RAM handle?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105n4ie/increasing_bootdisk_size_linux_image/",
          "author": null,
          "description": "Hi all,\n I have a small issue, I ran out of bootdisk space on a DietPi VM image I imported in Proxmox (Following the offical guide for DietPi in Proxmox).\n This happened to me before and I (somehow) managed to increase it in the shell of my VM... The thing is, it took me ages to do because I'm no expert and did not have a proper explanation on how to do it.\n Is there someone which can help me which some links to the commands I have to type or a guide of some sort ?\n Disk size is 16gb and I woul like to increase to 50gb.\n Thanks a lot!\n Kevin\n    submitted by    /u/Kevin68300  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105n4ie/increasing_bootdisk_size_linux_image/",
          "publishedOn": "2023-01-07T11:42:15.000Z",
          "wordCount": 17992,
          "title": "Increasing bootdisk size linux image",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105n16v/wiki_software_with_embedded_databases/",
          "author": null,
          "description": "I'm running all of my services in docker containers, managed by portainer as a web GUI for convenience. What are my options for selfhosted wiki software that can run with an embedded database or no database in a docker container?\n So far, I've found: * gollum * dokuwiki * wiki.js w/ sqlite\n    submitted by    /u/Absozero0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105n16v/wiki_software_with_embedded_databases/",
          "publishedOn": "2023-01-07T11:36:50.000Z",
          "wordCount": 18690,
          "title": "Wiki software with embedded databases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105mjnm/self_hosted_tool_to_store_mange_all_my_product/",
          "author": null,
          "description": "Hi, \n Can anyone recommend a self hosted tool (docker ideally) that is best placed to store and manage all of my product manuals / user guides , tech documents etc. \n I’m sure like many of you, I’ve accrued numerous pdfs over the years for the various appliances I’ve acquired, and so far I’ve looked at paperless-ngx and Komga which both seem possible but I’m curious what other might use (or recommend). \n Everything is currently stored in a basic folder/file structure `Manufacturer > Product` which is functional, but I’m thinking the addition of OCR could help, especially if I want to find specific terms, error messages etc. Please let me know what you use for this or recommend .. \n Many thanks ..\n    submitted by    /u/parkercp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105mjnm/self_hosted_tool_to_store_mange_all_my_product/",
          "publishedOn": "2023-01-07T11:07:14.000Z",
          "wordCount": 18608,
          "title": "Self hosted tool to store / mange all my product manuals, user guides etc.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105m34a/authentik_plex_sso/",
          "author": null,
          "description": "So I'm starting to setup Authentik, as it can integrate into a lot of different services unlike Authelia, and I was wondering if anybody has been able to setup SSO for Plex and 3rd party Plex services such as Tautulli/Overseerr and the like. From this issue and this Github repo it seems that at the very least some people have presumably managed to make it work, and I was wondering if any of you knew how?\n    submitted by    /u/SuperGamer1337  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105m34a/authentik_plex_sso/",
          "publishedOn": "2023-01-07T10:38:08.000Z",
          "wordCount": 19043,
          "title": "Authentik Plex SSO",
          "imageUrl": "https://external-preview.redd.it/LU4DAZGKoAH6mpO5EHk8dK5TTIlSR4NSvX92jac33eM.jpg?auto=webp&s=0043c659a3405a327136872773e8acc4302c2494"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105leoh/looking_for_a_good_music_playlist_generator/",
          "author": null,
          "description": "submitted by    /u/Kidwellj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105leoh/looking_for_a_good_music_playlist_generator/",
          "publishedOn": "2023-01-07T09:55:21.000Z",
          "wordCount": 18588,
          "title": "Looking for a good music playlist generator",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105k3jm/how_are_you_archiving_websites_you_visit/",
          "author": null,
          "description": "Hello,\n I have been looking at some popular options like Wallabag, Linkding, Shiori, Cherry. etc\n It seems like either you have a useful management interface for thousands of bookmarks like Cherry, or you have the function of saving pages offline manually with something like Shiori.\n One key feature I am looking for is full text search of archived pages.\n Can you share with me which solution you use?\n Thanks!\n    submitted by    /u/ikukuru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105k3jm/how_are_you_archiving_websites_you_visit/",
          "publishedOn": "2023-01-07T08:33:06.000Z",
          "wordCount": 20815,
          "title": "How are you archiving websites you visit?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105jvui/how_can_i_solve_the_issue_that_the_characters_are/",
          "author": null,
          "description": "I mount samba with docker-compose as like below\n  mount-volume1: driver_opts: type: \"cifs\" device: \"//host-IP/sharedfolder\" o: username=sampleuser,password=samplepassword \n The samba share is mounted correctly, and I can access shared from the container, but the folders and files which written in Japanese are showns as \"?????\".\n And I did googled, and I found iocharset=utf8 is the key, so I have tried add o: iocharset=utf8 but the system shows\n Error response from daemon: error while mounting volume '/var/lib/docker/volumes/mount-volume1/_data': failed to mount local volume: mount //host-IP/sharedfolder:/var/lib/docker/volumes/mount-volume1/_data, data: iocharset=utf8: invalid argument \n I have no idea how to solve this issue, can anybody help me? Thank you for reading.\n    submitted by    /u/kabereddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105jvui/how_can_i_solve_the_issue_that_the_characters_are/",
          "publishedOn": "2023-01-07T08:19:47.000Z",
          "wordCount": 19199,
          "title": "How can I solve the issue that the characters are garbled in samba cifs mount on docker-compose?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105avro/modern_public_wiki_software/",
          "author": null,
          "description": "Hello, I'm writing with my friends our own universe as a wiki site. I currently use dockerized Dokuwiki and It's very nice but good and I like its simplicity but got few issues. The biggest problem I found is lack of SEO customization and manual html tagging ovverride create mess that some socials read, some don't, also search engines got problems.\n So I'm looking for alternative. I need: - Metatags customization for each pages. - High theme/looks customization - SEO support - Something modern with active development/community \n Any suggestions -^ ?\n (Already tested and rejected the XWiki (niceurl don't work) and WikiJS(lack of theme customization and manual css is messed up because of lots of !important)\n    submitted by    /u/Arturitu_12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105avro/modern_public_wiki_software/",
          "publishedOn": "2023-01-07T00:41:27.000Z",
          "wordCount": 20885,
          "title": "Modern public wiki software?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105agsi/redis_backups/",
          "author": null,
          "description": "I have a few dockers using a mixture of Mariadb, Postgres and REDIS. \n I didn’t get the memo about separate db instances per docker and to be honest I’m not sure my aging NUC would benefit from multiple db instances either. \n I’ve been working on a backup strategy, and I can group the dockers with the db so I can update each app (Nextcloud, photoprism, various random php systems, phpmyadmin) as needed, \n However I have two apps using a REDIS instance. Nextcloud (as above) and paperless. \n When I look back at the REDIS docker there are no volumes defined. So I’m not sure what I need to actually backup with REDIS. \n Maybe it’s loaded as values on client docker startup so it doesn’t need backups? \n Or there is something permanent I should be backing up and my docker should be updated to create those files as permanent files which I can then backup. \n Does anyone have any knowledge of REDIS and how I should handle this?\n Thanks in advance\n    submitted by    /u/bigrup2011  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105agsi/redis_backups/",
          "publishedOn": "2023-01-07T00:23:50.000Z",
          "wordCount": 21493,
          "title": "REDIS backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/105aeuh/how_can_i_make_a_permanent_url_from_magnet_links/",
          "author": null,
          "description": "submitted by    /u/wyntrson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/105aeuh/how_can_i_make_a_permanent_url_from_magnet_links/",
          "publishedOn": "2023-01-07T00:21:31.000Z",
          "wordCount": 20793,
          "title": "How can I make a permanent URL from magnet links? To stream at any time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1058xfb/allow_friends_to_dj_while_driving/",
          "author": null,
          "description": "My friends and I go on roadtrips pretty frequently, and the other day I had the idea that it would be great if one of us could hook our phone up to the radio, and everyone else use their phones to connect and add music to the queue, maybe even vote music up to listen sooner. I've been looking into mopidy, but I'm not sure if its possible the way i want it. I dont mind using local music, as I have quite a few songs, but I like that mopidy can use other sources as well. \n  \n Can anyone tell me if what I seek is possible, if not with mopidy, possible something else?\n    submitted by    /u/mattague  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1058xfb/allow_friends_to_dj_while_driving/",
          "publishedOn": "2023-01-06T23:20:20.000Z",
          "wordCount": 21575,
          "title": "Allow friends to DJ while driving",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1058j57/tunnels_ports_vps_and_wildcard_dns/",
          "author": null,
          "description": "I currently have a port open at home to a reverse proxy with a wildcard dns and services behind sso. This made sense as I was advised to not make a cert for each application as they can be enumerated. However I am left with an open port. \n I was thinking well maybe I’ll use cloudflared for all of these subdomains but if I’m not mistaken I’d then have to have each as a cname in the dns to the tunnels record which means they’re all listed. Although I’d keep the wildcard dns, and no extra hardware and no open port to the house. \n If I go the vps route I can have wildcard dns, no ports open internally (through con connectivity from vpn to home) but is it really any different to having a local port open, having one open to another machine that I now pay for and have to keep updated etc outside the house. \n Which of these things can I safely ignore, given I want these services to be available without vpn to people?\n    submitted by    /u/pheellprice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1058j57/tunnels_ports_vps_and_wildcard_dns/",
          "publishedOn": "2023-01-06T23:04:22.000Z",
          "wordCount": 21322,
          "title": "Tunnels, ports, vps and wildcard dns",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10586d0/trying_to_install_outline_but_the_setup_process/",
          "author": null,
          "description": "So i \"was\" really excited about Outline but given the endless issues with standing up the docker image, I'm looking for an alternative.\n I know there is Appflowy but that does not meet my needs either\n    submitted by    /u/ithakaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10586d0/trying_to_install_outline_but_the_setup_process/",
          "publishedOn": "2023-01-06T22:50:30.000Z",
          "wordCount": 20637,
          "title": "trying to install outline but the setup process is crazy and with official docker-compose fails",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1057ilx/automation_rename_and_organize_files/",
          "author": null,
          "description": "Is there an app that can automatically rename and move files based on RegEx rules? If it can merge PDF files would be even more awesome. Something like Hazel for Mac but for a server (docker-compose).\n    submitted by    /u/slyfoxreddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1057ilx/automation_rename_and_organize_files/",
          "publishedOn": "2023-01-06T22:24:23.000Z",
          "wordCount": 20110,
          "title": "Automation - Rename and Organize Files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1057g6t/qbittorrent_stuck_on_downloading_metadata_through/",
          "author": null,
          "description": "I have made sure my ports are forwarded and connection settings and Authentication settings say they are correct through this link from nord: https://support.nordvpn.com/Connectivity/Proxy/1087802472/Proxy-setup-on-qBittorrent.htm\n But when I download anything it just sits at downloading metadata. I have attempted to restart qBittorrent container since I'm utilizing docker. I have also attempted random port a few times.\n Compose file:\n qbittorent: image: 'linuxserver/qbittorrent:latest' container_name: qbittorrent restart: unless-stopped environment: - PUID=1000 - PGID=1000 volumes: - '/home/user/serverfiles/configs/qbittorrent:/config' - '/mnt/user/data/torrents:/torrents' ports: - '8080:8080' - '6881:6881' \n Has anyone had any luck getting this working / experience with the issue I'm having?\n Thanks\n    submitted by    /u/tagelthebagel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1057g6t/qbittorrent_stuck_on_downloading_metadata_through/",
          "publishedOn": "2023-01-06T22:21:43.000Z",
          "wordCount": 23069,
          "title": "qBittorrent stuck on \"downloading metadata\" through Nord Proxy SOCK5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1056pg0/hosting_a_simple_static_website/",
          "author": null,
          "description": "I want to host a small and simple website on my server. I've built it in Hugo and got a new domain name. Got the ports forwarded and redirected the domain to my IP. Works fine so far.\n So my question is how can I make that the path doesn't change to the IP address and stays as a domain's name? Also do I need to get a SSL cert for a static website?\n    submitted by    /u/Geksaedr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1056pg0/hosting_a_simple_static_website/",
          "publishedOn": "2023-01-06T21:52:57.000Z",
          "wordCount": 21040,
          "title": "Hosting a simple static website",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1056fg9/what_is_the_best_way_to_set_up_a_oneway_tunnel/",
          "author": null,
          "description": "submitted by    /u/ChrisMillerBooklo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1056fg9/what_is_the_best_way_to_set_up_a_oneway_tunnel/",
          "publishedOn": "2023-01-06T21:41:48.000Z",
          "wordCount": 23462,
          "title": "What is the best way to set up a \"one-way\" tunnel between a home server and a VPS?",
          "imageUrl": "https://preview.redd.it/vwjrtu8rshaa1.png?auto=webp&s=03fd49978223d3e175a478476ee8c08c0e8777c2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1055e9c/nec_nextcloud_command_line_tool_for_sharing_files/",
          "author": null,
          "description": "submitted by    /u/Nojus297  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1055e9c/nec_nextcloud_command_line_tool_for_sharing_files/",
          "publishedOn": "2023-01-06T21:01:13.000Z",
          "wordCount": 20728,
          "title": "nec - Nextcloud command line tool for sharing files",
          "imageUrl": "https://external-preview.redd.it/CJ93bDmXTl5D6eCQoDshzmieLYB__ux2eZEP5a-UYC0.jpg?auto=webp&s=156f9fd56b101579259096e93dc15086ab5c9ef7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10549e9/how_to_expose_local_network_services_behind/",
          "author": null,
          "description": "Hello! I'm fairly new to home networking, and I've had a hard time solving this one myself. I'd love if someone could help me out.\n I have a few http services running locally:\n  \nSplunk on port X\n An API on port Y (using Python)\n A website on port Z (using Node)\n  \nI want to reach them from:\n  \nMy local network\n My AWS servers\n My phone when I'm on cellular data\n  \nI forwarded their ports and hid them behind an IP whitelist. This works for 1 & 2, but it breaks for 3. When my cell's IP changes I lose access to these services.\n Is it possible to protect them with BasicAuth so that I don't need an IP whitelist?\n And before anyone suggests it: I don't want to use a VPN. I hate having to toggle it on before accessing a service, then toggle it off afterwards.\n    submitted by    /u/serg06  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10549e9/how_to_expose_local_network_services_behind/",
          "publishedOn": "2023-01-06T20:16:29.000Z",
          "wordCount": 21806,
          "title": "How to expose local network services behind BasicAuth?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1053yc1/a_solution_for_managing_supermarket_receipts/",
          "author": null,
          "description": "Hello all,\n About two years ago I created a very simple Excel sheet for my mum to keep track of the grocery shopping receipts. Now time has passed on and the end-user (mum) is asking for more features :)\n Instead of turning the Excel sheet into an application I decided to look around for what may exist.\n Requirements\n  \nAdd different supermarkets (e.g. as categories)\n Add entries per day or receipt\n Support for negative values e.g. discount\n Search function across entries to find the same product prices across supermarkets\n Optional: Create a graph showing expenditures per supermarket per time-period\n  \nNot all too fancy if you ask me. So I looked around and found a few options but none really fulfill the needs, In random order what I looked at:\n  \nGrocy\n I already use this for myself as shopping and recipe keeper. Not really fit for tracking receipts as you require the products to be added.\n Paperless-ngx\n This is really a DMS rather than comparing supermarket receipts\n Firefly iii\n This looked the most promising but is too strict from an accounting point of view as it works on debit/credit basis and in my case there is no bankaccount. Still keeping it in the back of my mind just in case.\n Smart receipts\n This is more for tracking full receipts rather than itemised\n Receipt Parser Web\n This lacks search and looks unmaintained. My Python skills are non-existent to extend it :) In its essence it comes closest to what I have in mind\n  \nPerhaps this is all out there but would love to hear if anybody has other ideas.\n If all else fails I might code something myself :)\n Thank you for your input\n    submitted by    /u/roland-d  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1053yc1/a_solution_for_managing_supermarket_receipts/",
          "publishedOn": "2023-01-06T20:04:25.000Z",
          "wordCount": 21794,
          "title": "A solution for managing supermarket receipts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10521ci/any_tool_to_check_the_security_of_my_server/",
          "author": null,
          "description": "I started exposing my server over internet, I think I did everything correctly, only exposing port 443 and protecting all the service with authelia and 2FA. \n But still, I'm worried that someone may have access to a shell (I host also code-server) and jump around in my private lan.\n Can you suggest a tool that I can run to run sort of penetration test?\n    submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10521ci/any_tool_to_check_the_security_of_my_server/",
          "publishedOn": "2023-01-06T18:48:36.000Z",
          "wordCount": 21531,
          "title": "Any tool to check the security of my server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1051w8y/rocketchat_css/",
          "author": null,
          "description": "I just installed my own private rocket chat for me and some friends and I have customized the CSS to my liking, I visited another rocket chat server and their users had colors in their usernames and roles as shown here\n Colored usernames and roles\n Even more complex things like username with gradient colors\n I tried asking the admin of that chat but they never responded. Other people told me it wasn't possible but... Clearly, it is. would love some help with this. I'm fairly new to HTML and CSS\n The only thing I managed on an older version was to add this to CSS and it would give color to the role name but not the username:\n [title=\"Admin\"],[data-role=\"Admin\"]{color:red !important;background:#202020 !important}\n    submitted by    /u/MitsuruMiyata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1051w8y/rocketchat_css/",
          "publishedOn": "2023-01-06T18:42:59.000Z",
          "wordCount": 20416,
          "title": "Rocketchat CSS",
          "imageUrl": "https://external-preview.redd.it/D9_-1cDmMmdCpox6bUxyX9aHt-1IqjuddXcowRJGoV0.png?auto=webp&s=dd72ed03668b8435bf8b03b4ccd539d1ad39a409"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1051snh/sync_photos_from_android_to_pc_automatically/",
          "author": null,
          "description": "Hello \n I'm looking for an app that automatically syncs images from android to PC. If I delete a photo from android it should also be reflected/deleted on backup folder in PC. I did some research and came across Syncthing and Nextcloud but I'm not sure which one to go for\n Your help will appreciated, thanks\n    submitted by    /u/FlatDistance3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1051snh/sync_photos_from_android_to_pc_automatically/",
          "publishedOn": "2023-01-06T18:39:10.000Z",
          "wordCount": 19813,
          "title": "Sync photos from android to PC automatically",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104zmxx/paperlessngx_alternatives/",
          "author": null,
          "description": "For those who have found paperless-ngx lacking, which alternatives have you wound up using? I'm finding the lack of grouping and versioning to be problematic for me.\n It looks like i may want to give papermerge or mayan a try. wondering what the pros/cons are against one another and against paperless-ngx.\n    submitted by    /u/flying_unicorn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104zmxx/paperlessngx_alternatives/",
          "publishedOn": "2023-01-06T17:14:44.000Z",
          "wordCount": 20323,
          "title": "paperless-ngx alternatives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104z6dc/how_to_setup_authentik_with_cloudflare_zero_trust/",
          "author": null,
          "description": "Hello folks,\n i want to give external access through Cloudflare tunnel & zero trust to my internal services. I've managed to setup a whole cf tunnel and everything seems working, i know how to setup zero trust etc. I even managed to setup authentik as OpenId provider, BUUUT...\n  \nIt stopped working after few days? I'm logging in, authentik redirect user back to cf, but cf shows error Authentication Error Failed to fetch user/group information from the identity provider.\n Is it even possible to set ONE app/provider on authentik side and use it with multiple apps on cf side? Or i would have to setup multiple providers/apps in authentik? For each cf app?\n  \n   submitted by    /u/AducitcHan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104z6dc/how_to_setup_authentik_with_cloudflare_zero_trust/",
          "publishedOn": "2023-01-06T16:57:12.000Z",
          "wordCount": 19971,
          "title": "How to setup Authentik with Cloudflare zero trust?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104yfax/newbie_here_what_are_security_measures_do_i_need/",
          "author": null,
          "description": "I have a self hosted server at my home with various services. This proxmox server hosts many VM, LXC containers and Dockers. I need to access over internet a few of them like nextcloud and HomeAssistant portals. I have a domain and dns server setup through AWS route53 service and tested as trial basis, it works fine over internet.\n But before opening these services over internet for 24X7 serious usage, I would like to know what are the network security measures I need to do to manage network attacks and data theft. The target users are just my family members.\n    submitted by    /u/user0user  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104yfax/newbie_here_what_are_security_measures_do_i_need/",
          "publishedOn": "2023-01-06T16:27:04.000Z",
          "wordCount": 21780,
          "title": "Newbie here, what are security measures do I need to care on my self hosted Server which is accessed through public IP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104y3vc/inline_power_meter/",
          "author": null,
          "description": "Looking for maybe a wifi plug i can use to record power usage? Nothing to fancy i just want to see a accurate log of how much juice my server is sipping on. I have a old acp ups that use powerchute but that doesn't show me the actual usage rather it gives me cost. I would rather have the raw data I can figure cost later.\n What do you all use that won't break the bank?\n    submitted by    /u/Suspicious_Dig_5684  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104y3vc/inline_power_meter/",
          "publishedOn": "2023-01-06T16:14:33.000Z",
          "wordCount": 21193,
          "title": "Inline power meter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104wjs0/self_hosted_roundup_22/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104wjs0/self_hosted_roundup_22/",
          "publishedOn": "2023-01-06T15:11:11.000Z",
          "wordCount": 20383,
          "title": "Self Hosted Roundup #22",
          "imageUrl": "https://external-preview.redd.it/zsutPyibse3s1MJADzWWenjrxBuRxZL2Qd6rkAtLI-c.jpg?auto=webp&s=622c050a779cb4294880929d2f84012eab65753b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104u20w/opposite_of_ssotax/",
          "author": null,
          "description": "Hi all,\n anybody interested in collecting / building an so-to-say opposite to sso.tax?\n A community effort listing those projects and services (and their respective usecase) that feature a delightful, free and enterprise ready SSO (SAML / OIDC) implementation.\n Preferably free - but also those vendors and projects demanding reasonable prices & good implementations.\n I hope something like this does not already exist. At least I wasn't able to find something comprehensive. But if it does, I will gladly take your recommendations :)\n    submitted by    /u/_badger7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104u20w/opposite_of_ssotax/",
          "publishedOn": "2023-01-06T13:21:14.000Z",
          "wordCount": 20539,
          "title": "Opposite of sso.tax",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104iwp7/namecheap_demanding_purpose_for_registering_domain/",
          "author": null,
          "description": "Namecheap has recently suspended my domain for \"abuse\" even though I have just been using it to access photos on my nas at home. Now they are demanding that I give them a reason for registering the domain. Is this a Namecheap thing or do all registrars require you to provide a reason. Are there other registrars that just sell you the domain and leave you alone without wasting your time over bs like this?\n They also locked my account for \"suspicion\" a day earlier and asked for sensitive info like SSN and DOB to prove my identity. They did not give a proper reason for doing so and threatened to delete my account in 24 hours.\n Edit: For those wondering the TLD is .xyz\n Edit 2: I told them that I was using it for \"accessing a NAS\" and they unsuspended the domain. However, I asked them in two different replies to provide me with a reason for suspension, or a copy of the abuse report. They completely ignored that part of the email twice, and replied as though those words were invisible. So now I am left in the dark as to what really happened behind the scenes and can only speculate.\n    submitted by    /u/Glome495  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104iwp7/namecheap_demanding_purpose_for_registering_domain/",
          "publishedOn": "2023-01-06T03:04:43.000Z",
          "wordCount": 24254,
          "title": "Namecheap demanding purpose for registering domain",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104ige5/introducing_homelabapi_v01_a_selfhosted_api_that/",
          "author": null,
          "description": "Long story short, I have my own personal API I use for various things, and I realized one day that a whole bunch of my endpoints were homelab related. For organization sake, I thought it might be good to split the homelab endpoints out to their own API. I then thought, \"I wonder if any other homelabbers would be interested in this?\", and here we are.\n Some more information from the README...\n ---\n What is HomelabAPI?\n HomelabAPI is a self-hosted API that you can use to consolidate all of your homelab notifications and other outputs. This allows you to use HomelabAPI as your central input/output hub, and if you ever want to change where your homelab outputs go, it's just a matter of updating your HomelabAPI configuration.\n For example, let's say that you have all of your Home Assistant, Syn…",
          "link": "https://www.reddit.com/r/selfhosted/comments/104ige5/introducing_homelabapi_v01_a_selfhosted_api_that/",
          "publishedOn": "2023-01-06T02:43:44.000Z",
          "wordCount": 21475,
          "title": "Introducing HomelabAPI v0.1 - A self-hosted API that you can use to consolidate all of your homelab notifications and other outputs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104gr0h/introducing_homelabapi_v01_a_selfhosted_api_that/",
          "author": null,
          "description": "submitted by    /u/gregLTS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104gr0h/introducing_homelabapi_v01_a_selfhosted_api_that/",
          "publishedOn": "2023-01-06T01:28:25.000Z",
          "wordCount": 21454,
          "title": "Introducing HomelabAPI v0.1 - A self-hosted API that you can use to consolidate all of your homelab notifications and other outputs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104eutv/custom_dns_resolver_to_map_cname_to_cloudflare/",
          "author": null,
          "description": "I have an internally hosted DNS resolver running on my network. Everything is great aside from one thing, which is I cannot load my root domain when connected over VPN. The reasoning is obvious because the zonefile maps my domain name to the internal IP of NGINX which has a ton of subdomain entries for my domain. \n thing1.mydomain.com <- works thing2.mydomain.com <- works mydomain.com <- does not work. Specifically want to load this website from outside my network. \n Ideally, I have a CNAME entry in the Zonefile that routes traffic, even on VPN to my site hosted externally by Cloudflare. How can I achieve this? \n Here is my zonefile\n $ORIGIN mydomain.com. @ 3600 IN SOA sns.dns.icann.org. noc.dns.icann.org. ( 2017042746 ; serial 7200 ; refresh (2 hours) 3600 ; retry (1 hour) 1209600 ; expire (2 weeks) 3600 ; minimum (1 hour) ) * 3600 in A 172.16.0.2 # this is private static IP I assigned to NGINX on internal network mydomain.com. 3600 IN CNAME proxy.mydomain.com. \n The A record is good. I just added this CNAME but it does a loopback into NGINX and loads the wrong site. \n proxy.mydomain.com is a CNAME record in Cloudflare DNS that points to mydomain.com. Doesn't work when connecting over VPN though. Maybe someone with some solid networking knowledge can explain this one to me.\n    submitted by    /u/FeedMeAnAlgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104eutv/custom_dns_resolver_to_map_cname_to_cloudflare/",
          "publishedOn": "2023-01-06T00:07:53.000Z",
          "wordCount": 20719,
          "title": "Custom DNS resolver to map CNAME to Cloudflare?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104em0n/looking_for_a_little_advice_on_options_to_go_with/",
          "author": null,
          "description": "So, I have been running a couple applications behind a reverse proxy. I have been using NPM and it's worked well. I never did implement fail2ban or Authelia into my current setup. I do plan on implementing fail2ban this weekend when I do my server move but I have a couple questions. \n  \nWhen it comes to Authelia, am I correct to assume it's mainly to secure applications which may not have it's own authentication method? I mean, I know you can have a double login (one for Authelia + one for the app) but that seems like maybe it's a little overkill. Am I missing anything else about Authelia?\n I saw at least one post when I was searching which suggested using CF Tunnels to protect the nGinx login. This got me thinking if there is any benefit for using Tunnels in some fashion along with my reverse proxy? Id prefer to not use Tunnels completely because I don't want CF to have unfettered access to everything coming and going from the site so Ill stick with using the reverse proxy with my own cert from lets encrypt. \n  \nAnything else Im missing? I guess since Im doing this move I want to increase the security if I can. At a minimum it seems like fail2ban is a no brainer. \n I'll also add in closing that these apps need to be publicly accessible to the wider internet so something like tail scale is not an option for this.\n    submitted by    /u/jstanaway  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104em0n/looking_for_a_little_advice_on_options_to_go_with/",
          "publishedOn": "2023-01-05T23:58:05.000Z",
          "wordCount": 21189,
          "title": "Looking for a little advice on options to go with my reverse proxy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104ekif/selfhosted_code_hosting_with_code_output_embed/",
          "author": null,
          "description": "Hi all,\n Deepnote offers to share your code + the output as an embedded html (iframe) object. Examples of these embedded objects can be seen, for example, in this medium post under 4. I am looking for a self-hosted app that offers the that functionality. \n To clarify, I am not looking for just embedded code blocks, like Github and Gitlab offer with Gists and Snippets, but also, or even only, where you can see code output. I mainly use Python. So code output in Python would be a must.\n Does anybody know of such a selfhosted app?\n Thanks alot!\n    submitted by    /u/DukeOfBerlin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104ekif/selfhosted_code_hosting_with_code_output_embed/",
          "publishedOn": "2023-01-05T23:56:18.000Z",
          "wordCount": 19708,
          "title": "Self-hosted code hosting with code output embed functionality (or self-hosted alternative to deepnote)?",
          "imageUrl": "https://external-preview.redd.it/lDJhkwbLFThJEf4dmCpG6-bY0PkiAF9M80rKb8etDVI.jpg?auto=webp&s=277fdc473b0ea26d6bf712d5b5cad0f35c67fcb9"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104e7n3/where_should_i_run_my_dockers/",
          "author": null,
          "description": "I have several lightweight containers (Ad guard, Vaultwarden, etc). Does It make a difference if I install and run them in let's say my Home Assistant or True NAS. Or should I run them on Ubuntu server? \n And If I were to go with Ubuntu, what is a good way to integrate it with my current setup? Using something like Proxmox to run my TrueNas and then also the Ubuntu server? Thanks for any help!\n    submitted by    /u/Philthyzz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104e7n3/where_should_i_run_my_dockers/",
          "publishedOn": "2023-01-05T23:41:38.000Z",
          "wordCount": 21034,
          "title": "Where should I run my Dockers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104du8e/my_reverse_proxy_doesnt_work/",
          "author": null,
          "description": "I have a server that is running youtrack on port 8080 and an Apache server on 80\n A subdomain with an A record is bound to the server‘s IP address, so when I open subdomain.domain.com, the index.html of Apache shows up. \n When I access subdomain.domain.com:8080, i am facing the youtrack dashboard\n Now I want to access the youtrack dashboard by entering subdomain.domain.com/youtrack and I think I need a reverse proxy for this. \n However I‘ve tried many things and nothing worked so far. It’s either a times out connection or a 404 url not found.\n I’ve tried ProxyPass with a Proxy Module and Virtualhost with ProxyPass so far. Tried so many code snippets that it’s pointless to mention all. Can you guys help?\n    submitted by    /u/LordQuantumKeks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104du8e/my_reverse_proxy_doesnt_work/",
          "publishedOn": "2023-01-05T23:26:36.000Z",
          "wordCount": 20633,
          "title": "My reverse proxy doesn’t work!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104d8j5/os_setup_and_dockers_newb/",
          "author": null,
          "description": "Hi I am currently running proxmox but think I want to use things in docker containers instead. Ultimately I want to run the following -\n  \nHome Assistant\n Frigate\n Some NAS OS like OMV/Truenas\n  \nAny recommended base OS that I can just switch between dockers or something, I am a newb and don't quite get it... and then run some of these other apps/OS in containers. I was thinking to have ubuntu gui but I feel like I could find a better OS as a base, if a base is even needed.\n    submitted by    /u/h0va4life  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104d8j5/os_setup_and_dockers_newb/",
          "publishedOn": "2023-01-05T23:03:20.000Z",
          "wordCount": 21833,
          "title": "OS setup and dockers newb",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/104ckjz/remote_administration_with_guacamole/",
          "author": null,
          "description": "I've talked about guacamole a lot in my posts, so I decided to write a blog guide on how to set up guacamole in docker.\n Apache guacamole is a remote administration tool that lets you access servers via the browser (ala citrix, but better). Guacamole is used in enterprise remote access solutions around the world and is a fantastic tool!\n    submitted by    /u/Reverent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/104ckjz/remote_administration_with_guacamole/",
          "publishedOn": "2023-01-05T22:37:47.000Z",
          "wordCount": 21353,
          "title": "Remote Administration with Guacamole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1047phc/owncast_whats_an_adequate_linode_plan/",
          "author": null,
          "description": "Hi all,\n I just installed OwnCast (install is a bit strong, I had Linode Marketplace do it) on Linode. \n On my first go, I didn't use the Marketplace. I used Ubuntu on a Shared Nanoode 1 GB plan with Docker. When I ran my stream test, the CPU was at 100%. I didn't think that was good, so I deleted that and noticed I could use MarketPlace to install Owncast's version. \n This time I went with the SHared Linode 2 GB. It has 1 CPU like the Nanode but has twice the ram. This time the CPU was at 60%.\n My question is, what would be the \"most\" adequate plan? I'd love to do this for $5/mo, but not if it's going to push the node too much. Also, would the 1cpu/2gig be enough?\n Thanks for any insights!!\n    submitted by    /u/damullens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1047phc/owncast_whats_an_adequate_linode_plan/",
          "publishedOn": "2023-01-05T19:29:15.000Z",
          "wordCount": 20789,
          "title": "Owncast - What's an adequate Linode Plan?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1046pjr/can_you_propose_any_self_hosted_kvm_manager_which/",
          "author": null,
          "description": "Looking for web based solution. Currently using virt-manager.\n    submitted by    /u/orneo1212  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1046pjr/can_you_propose_any_self_hosted_kvm_manager_which/",
          "publishedOn": "2023-01-05T18:49:57.000Z",
          "wordCount": 18398,
          "title": "Can you propose any self hosted KVM manager? Which one is good to try?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1046525/hdd_andor_ssd_to_use_with_a_raspberry_pi_4b/",
          "author": null,
          "description": "I am looking to start some self hosting services on a Raspberry Pi 4B 8gb (currently being shipped to me as we speak). I am planning on having following services to start the journey: - Jellyfin: movies/shows and maybe also music streaming to home and outside - arr stack + torrent client: to automate downloads - Some cloud storage to maybe backup pictures from phone\n Now from what I read on this sub it would be better to have the OS installed on a separate SSD instead of the SD card. Do you have any suggestions of an SSD that would be suitable? \n Same questions for an external HDD. I'm thinking that 8tb would be more than enough at this time.\n I am looking for the lower priced SSD and HDD..\n Thanks!\n    submitted by    /u/CheckCheckOneTwo1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1046525/hdd_andor_ssd_to_use_with_a_raspberry_pi_4b/",
          "publishedOn": "2023-01-05T18:27:19.000Z",
          "wordCount": 20513,
          "title": "HDD and/or SSD to use with a Raspberry Pi 4B",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1045b78/anyone_still_uses_seafile_while_it_still_has/",
          "author": null,
          "description": "1.https://github.com/haiwen/seafile/issues/350\n 2. just wonder why we need to signup for the pro version, but free version, (not trying to be rude, would like to learn more about the logic behind it.\n and comment /tips is appreciated.\n    submitted by    /u/Icy_Confusion_3766  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1045b78/anyone_still_uses_seafile_while_it_still_has/",
          "publishedOn": "2023-01-05T17:54:42.000Z",
          "wordCount": 20234,
          "title": "Anyone still uses seafile while it still has these two \"issues\", and how do you guys address them?",
          "imageUrl": "https://external-preview.redd.it/A60RI91HR1TntJ9D_XXrwZBiCitM1tFHP-3CFfzLBgk.jpg?auto=webp&s=323525f9d6b37225a0658f03a0d835673d569691"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1044shk/does_apache_guacamole_require_vnc_servers_on_each/",
          "author": null,
          "description": "Hello everyone,\n I've recently installed Apache Guacamole through Cloudron in a Proxmox VM running Ubuntu server. I'm trying to set up SSH and VNC connections to my VMs and a Raspberry Pi so I can manage my servers remotely, but I've been stuck on VNC connectivity for the last few days. I can SSH into every device fine, but VNC never works no matter what I've tried.\n Some things I've noticed when troubleshooting is that the VNC servers are extremely inconsistent when it comes to connectivity. From my desktop running EndeavourOS, I can connect to both my Raspberry Pi and a Proxmox Debian VM, but only the Pi can be interacted with as the Debian VM connects, but has no display on any VNC client software I've tried.\n However, when it comes to Guacamole, I can't connect to either of them whatsoever. I've seen dozens of forum posts and Reddit posts telling me to create vncpasswds and how to configure that in the settings, but nothing works.\n Would any of you have any insight as to why my set up isn't working as intended? Would something like RPort be a better alternative?\n    submitted by    /u/BicBoiSpyder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1044shk/does_apache_guacamole_require_vnc_servers_on_each/",
          "publishedOn": "2023-01-05T17:33:37.000Z",
          "wordCount": 21416,
          "title": "Does Apache Guacamole require VNC servers on each machine for VNC connections?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1044m2i/minimalist_self_hosted_apps/",
          "author": null,
          "description": "I recently stumbled upon Miniflux and it felt like a breath of fresh air after using FreshRSS (pun unintended).\n I am looking for other apps that follow the same minimalist elegant philosophy. Perhaps some alternatives to Nextloud, Firefly 3, Wallabag or anything else you can think of.\n    submitted by    /u/petalised  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1044m2i/minimalist_self_hosted_apps/",
          "publishedOn": "2023-01-05T17:26:23.000Z",
          "wordCount": 23183,
          "title": "Minimalist self hosted apps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1044dpf/traefik_ipwhitelist_and_wireguardserver_in_same/",
          "author": null,
          "description": "I am currently trying to setup various IP-whitelist middlewares with Traefik. One thing that i would like to do is allow connections to certain services only through a VPN connection. I run the Wireguard server using wg-easy and the container is also connected to the traefik-proxy network. My subnets look like this:\n  \nVPN: 172.20.0.0/24\n Traefik-Proxy: 172.16.1.0/24\n docker0: 172.16.0.0/24\n  \nNow i would like to setup my VPN whitelist like this:  http: middlewares: ipwhitelist-vpn: ipWhiteList: sourceRange: - \"172.20.0.0/24\"  When i am connected to my VPN and access a service, i get a 403 forbidden, with the Traefik access log looking this: {\"ClientAddr\":\"172.16.1.1:36904\", \"DownstreamStatus\":403, ...}\n Looking at the routing table of the container, this does indeed make sense:\n  default via 172.16.1.1 dev eth0 172.16.1.0/24 dev eth0 proto kernel scope link src 172.16.1.19 172.20.0.0/24 dev wg0 proto kernel scope link src 172.20.0.1 \n So traffic gets routed through eth0 (the traefik network) by default, which results in the Traefik proxy seeing it's own gateway ip address as the source. However, i would like the incoming source ip address to be my VPN gateway (172.20.0.1). Is there a way to accomplish this? Thanks!\n    submitted by    /u/Torrew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1044dpf/traefik_ipwhitelist_and_wireguardserver_in_same/",
          "publishedOn": "2023-01-05T17:16:53.000Z",
          "wordCount": 24511,
          "title": "Traefik IP-Whitelist and Wireguard-Server in same network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1043sag/notification_setup/",
          "author": null,
          "description": "Currently, I'm running a private discord server. I've created different channels such as \"plex-notifications\", \"automation-notifications\", \"homelab-status\", etc. I have webhooks set up in Discord connected with different services like Tautulli, *arr's, Uptime Kuma, and many others. Unfortunately, not everything supports webhooks so there's a service here and there that I can't set up with Discord. Despite that, this set up has worked relatively well for me over the last year ish.\n However, as a homelabber, I feel compelled to try new things out and mess with things that aren't necessarily broken. So I want to see what systems you guys have put in place to send you notifications about things going on in your network. Interested in things like how quickly you receive notifications from the time of an event, how many services have you come across that don't incorporate into your notification system, and things of that nature.\n Looking forward to hear what you all are doing. Thanks!\n    submitted by    /u/BleepsSweepsNCreeps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1043sag/notification_setup/",
          "publishedOn": "2023-01-05T16:53:15.000Z",
          "wordCount": 20529,
          "title": "Notification Setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10432qv/synchronized_desktop_backup/",
          "author": null,
          "description": "My work has our laptops set up to automatically sync files between our VMware Horizon VD's and our physical machines when we're on the work network. Is there a similar solution that can be implemented between a VM at home and a Fedora laptop?\n    submitted by    /u/Jbnels2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10432qv/synchronized_desktop_backup/",
          "publishedOn": "2023-01-05T16:24:01.000Z",
          "wordCount": 19701,
          "title": "Synchronized Desktop Backup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1042zyw/host_your_obsidian_notes_with_mkdocs_nginx/",
          "author": null,
          "description": "submitted by    /u/akenfoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1042zyw/host_your_obsidian_notes_with_mkdocs_nginx/",
          "publishedOn": "2023-01-05T16:20:42.000Z",
          "wordCount": 20070,
          "title": "Host your Obsidian notes with MkDocs & Nginx",
          "imageUrl": "https://external-preview.redd.it/n0Sz3FF5mHofihnc8PWvJh5ZQVkJyZi0TW2-X3JhnPE.jpg?auto=webp&s=053e58a42d74a4cfafdf2446a7a54d6358bed8fe"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1041cz9/i_am_writing_a_free_opensource_music_server_and/",
          "author": null,
          "description": "I am writing a music server and a client to go along with it. Because I am sick of the best experience being a paid or proprietary solution I am trying my hardest to make an experience as good as PlexAmp and a UI as good as Roon but free and open source. \n It's going to be a long and hard journey and it make takes years for me to get a v1.0 release but I am determined. \n Server: https://github.com/Ortygia/Deaftone Written in Rust using SeaORM. And SQLx in the scanner\n Client: https://github.com/Ortygia/Orpheus Written in JS. Using Vue+Tailwind and Tauri for desktop and eventually mobile\n ​\n I am looking to get features for both the server and the client from people. Features that would make you switch to it if and when it eventually releases.\n ​\n I am currently having a big discussion in https://github.com/Ortygia/Deaftone/issues/7 about multi-user support and how it would be done.\n ​\n So I have a question would you rather have the same library as all users? Separate libraries each kinda like Plex/Jellyfin or a common library and a user-specific library. Where you can browse the common and user-specific libraries at the same time\n    submitted by    /u/112madgamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1041cz9/i_am_writing_a_free_opensource_music_server_and/",
          "publishedOn": "2023-01-05T15:14:12.000Z",
          "wordCount": 21992,
          "title": "I am writing a free open-source Music Server and Client. What are features missing from Software such as Navidrome PlexAmp, Roon",
          "imageUrl": "https://external-preview.redd.it/QP2pYN-XQ5OGHC_okYV_J0Hd57CXpuz9y5jNLNg2Aj0.jpg?auto=webp&s=9c9fec6dd07def8bbe6e1e68b4d4a81cf36957a1"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103zs6z/recommended_to_host_forgejo_and_drone_cicd_on/",
          "author": null,
          "description": "Been looking into selfhosting an own Git repository through Forgejo and would like to combine this with Drone for CI/CD.\n Would a single 12$ Droplet (2GB / 1CPU, 50GB SSD) suffice, or is it better to still split them up (into two 6$ Droplets of each 1GB RAM)?\n I'd not be worried if both go down at the same time instead of either one, as both services would be tightly integrated after all.\n    submitted by    /u/TopHatHipster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103zs6z/recommended_to_host_forgejo_and_drone_cicd_on/",
          "publishedOn": "2023-01-05T14:07:38.000Z",
          "wordCount": 19904,
          "title": "Recommended to host Forgejo and Drone CI/CD on separate DO Droplets, or together on one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103x8b5/unifi_controller_ui_behind_nginx_proxy_manager/",
          "author": null,
          "description": "I have the the UniFi Controller (linuxserver/unifi-controller) running in a Docker container on one VM connected to a one (management) VLAN and NPM running in a Docker container on another VM connected to a another (dmz) VLAN.\n I can reach the UniFi UI just fine from a browser on the dmz VLAN when using the IP address (https://192.168.10.111:8443), but not through the reverse proxy.\n I can ping the UniFi IP from the NPM Docker host and it seems I can even curl the UniFi UI from within the NPM Docker container (although it is complaining about the certificate).\n [root@docker-npm:/app]# curl https://192.168.10.111:8443 curl: (60) SSL certificate problem: self signed certificate More details here: https://curl.haxx.se/docs/sslcerts.html curl failed to verify the legitimacy of the server and therefore could not establish a secure connection to it. To learn more about this situation and how to fix it, please visit the web page mentioned above. \n This is the NPM configuration I have been using for the UniFi UI. Anyone know what I might be missing here?\n https://preview.redd.it/8l2d5u1zq7aa1.png?width=496&format=png&auto=webp&s=956bdd4726ad55b5c69b37fcfd2c4b6c7a69a3ad\n Edit: I forgot to mentioned that I am proxying a whole bunch of other services the same way. The difference is that they are on the same VLAN as the NPM, but I do not see how that is an issue as the UniFi application is clearly reachable from the VLAN NPM is on.\n SOLVED: Never mind! I forgot to add it (unifi.at.home) as a Host Override Alias for the NPM host IP. (This is what makes the internal domain name resolution work).\n    submitted by    /u/norsemanGrey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103x8b5/unifi_controller_ui_behind_nginx_proxy_manager/",
          "publishedOn": "2023-01-05T11:59:04.000Z",
          "wordCount": 20590,
          "title": "UniFi Controller UI Behind Nginx Proxy Manager Not Working",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103wnbz/beginners_questions_to_performance_costs_and_data/",
          "author": null,
          "description": "Hi Reddit,\n so I am currently considering buying an old used PC to then self-host Nextcloud on it. But as this is the first time I ever self hosted something I have a few questions:\n ​\n  \nHow good (RAM, CPU) does a PC need to be to host just Nextcloud within let's say Fedora Linux?\n  How good should the PC be if I one day decide to also host a small Minecraft Server (just for me and friends so nothing big) on it\n How are the energy costs resulting from running a Computer all day compared to just getting a subscription from some server provider?\n If the hard drive (ssd or hdd) one day breaks is it than possible for a noob like me to recover the data? How would I ensure that I definitely do not lose any data without buying a second hard drive just to copy all the content?\n How long can I expect a old Computer to work as a server?\n What do you think are the main advantages (except from data ownership) from self-hosting instead of buying a subscription?\n  \n​\n Please feel free to answer any of the questions if you know answers to only some of them. Also feel free to just send a link without context if some of the questions have been asked here before and then angrily down vote the post :) .\n Thank you for your help and time\n    submitted by    /u/Lordofhisownroom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103wnbz/beginners_questions_to_performance_costs_and_data/",
          "publishedOn": "2023-01-05T11:24:05.000Z",
          "wordCount": 23815,
          "title": "Beginners questions to performance, costs and data security",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103tbd3/nextcloud_installation_choice/",
          "author": null,
          "description": "I have Nextcloud installation on ubuntu directly as now, but I plan to migrate to Docker based on my new home server as it is more flexible. I checked there two choices,\n 1. Nextcloud has an All-in-One docker image\n  \nUse Nextcloud official docker images(s)\n Could I know which might be the better one for long term running as I used Nextcloud in home for years, I might have lot of files to import after I settle the new server.\n Hope to hear others experience with Nextcloud with docker. \n  \nThanks.\n    submitted by    /u/Appropriate-Till-146  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103tbd3/nextcloud_installation_choice/",
          "publishedOn": "2023-01-05T07:57:17.000Z",
          "wordCount": 20944,
          "title": "Nextcloud installation choice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103kdy4/unable_to_reverse_proxy_nextcloud_behind_nginx/",
          "author": null,
          "description": "I have an existing NGINX container that proxies a lot of my self-hosted applications, so I simply added a Nextcloud route into the config and deployed.\n I can install and browser around, but things are not configured correctly and I an error saying I'm serving untrusted URLs over HTTPs.\n I currently use lets encrypt to do TLS termination at the nginx layer.\n edit: Sorry about formatting. Classic Reddit is terrible for MD formatting and I'm in the car. \n  nextcloud: depends_on: - db image: nextcloud:24-apache restart: always networks: core_net: ipv4_address: 172.16.0.10 ports: - 8080:80 volumes: - ./nextcloud-docroot:/var/www/html environment: - NEXTCLOUD_DATA_DIR=/var/www/html/data - POSTGRES_PASSWORD=nextcloud - POSTGRES_DB=nextcloud - POSTGRES_USER=nextcloud - POSTGRES_HOST=172.16.0.11 - LETSENCRYPT_HOST=nextcloud.customdomain.com - VIRTUAL_HOST=nextcloud.customdomain.com - NEXTCLOUD_TRUSTED_DOMAINS=nextcloud.customdomain.com - NEXTCLOUD_TRUSTED_PROXIES=172.16.0.2 \n From what I can tell looking at the config.php, I don't even think these env variables are doing anything. The whole setup is pretty confusing IMO. \n Would anyone know how to setup these hops? I only am interested in using NGINX and ideally I want to just proxy requests through NGINX I already have running. \n ``` server { listen 443 ssl; server_name nextcloud.customdomain.com;\n  client_max_body_size 50M; ssl_certificate cert.pem; ssl_certificate_key key.pem; location / { proxy_pass http://172.16.0.10; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } \n ```\n    submitted by    /u/FeedMeAnAlgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103kdy4/unable_to_reverse_proxy_nextcloud_behind_nginx/",
          "publishedOn": "2023-01-05T00:36:34.000Z",
          "wordCount": 19236,
          "title": "Unable to reverse proxy Nextcloud behind NGINX",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103jvbx/ideal_setup_for_a_home_media_server/",
          "author": null,
          "description": "I recently setup my first Kubernetes node to run a home media server, and have been a bit obsessed about creating the perfect setup. I want to eventually scale up from a single node cluster, to a dedicated media server, transcoding/download server, as well as a separate NAS with RAID to store all the files.\n On a very high level I'm wondering what kind of hardware would be ideal for a home media server, without going too crazy about it. I don't want to spend too much, but am willing to put down an appropriate amount, to optimize the machines for their purpose.\n My current server is fairly straightforward, a Ryzen 7 3700X, with 32GB RAM and a RX560 for HEVC decoding/H.264 encoding. It's where everything runs at the moment, but I'm wondering if this setup would be more suitable for transcodi…",
          "link": "https://www.reddit.com/r/selfhosted/comments/103jvbx/ideal_setup_for_a_home_media_server/",
          "publishedOn": "2023-01-05T00:14:38.000Z",
          "wordCount": 20733,
          "title": "Ideal setup for a home media server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103jds0/anyone_running_photoprism_in_proxmox_with_mariadb/",
          "author": null,
          "description": "Is anyone successfully running Photoprism in Proxmox with MariaDB and not with the default SQLlite?\n    submitted by    /u/Deckony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103jds0/anyone_running_photoprism_in_proxmox_with_mariadb/",
          "publishedOn": "2023-01-04T23:55:01.000Z",
          "wordCount": 19455,
          "title": "Anyone running Photoprism in Proxmox with MariaDB?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103irj8/xpost_helm_secure_from_mail_server_to_docker_host/",
          "author": null,
          "description": "submitted by    /u/Flaky_Reach_8342  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103irj8/xpost_helm_secure_from_mail_server_to_docker_host/",
          "publishedOn": "2023-01-04T23:29:51.000Z",
          "wordCount": 19522,
          "title": "X-post: Helm Secure - From Mail Server to Docker Host",
          "imageUrl": "https://external-preview.redd.it/nuHqGGv43ADpS-8OKtoHtCRgGGelwUgXPfyH6L35goM.jpg?auto=webp&s=0b2708c269ed77f69cb25889929bc7eb9bb5edce"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103i0bc/my_nuc_just_died_how_should_i_replace_it/",
          "author": null,
          "description": "So yeah ...as the title says my NUC 7i5 died today.\n After a few hours of testing, troubleshooting and even disassembling it I'm sure it's the mainboard and not the SSDs, RAM or any other \"lose\" component. \n This was my first \"real\" server, before I was hosting on my NAS and since I'm hosting a lot of personal stuff it really hurts atm ... \n I bought this NUC used and I guess I had bad luck, after disassembling it I found lots of proof that someone before me did something to it (scratches, burnt soldering, etc.). \n Before just looking for a replacement NUC I'm curious what kind of hardware you guys would recommend. Since the SSDs (1x M.2 and 1x 2,5\") and the RAM (DDR4 SODIMM) are fine I of course want to reuse them in the new system.\n Price should be around 300€ if possible, the hardware should be available in EU (quick delivery time) and I'd prefer a Intel CPU with Quick Sync for Plex hardware acceleration (not a must-have tho),\n Any idea is appreciated, thanks for your help.\n    submitted by    /u/mztiq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103i0bc/my_nuc_just_died_how_should_i_replace_it/",
          "publishedOn": "2023-01-04T23:00:20.000Z",
          "wordCount": 20007,
          "title": "My NUC just died ...how should I replace it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103htyg/searching_for_a_pastebin/",
          "author": null,
          "description": "Hi fellow selfhosters, Does anybody know a Pastebin, where I can share simple text and also files (and maybe also a URL shortener)? Ideally it would be a docker container.\n Thanks all of you.\n    submitted by    /u/ItsYuuNoo_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103htyg/searching_for_a_pastebin/",
          "publishedOn": "2023-01-04T22:53:33.000Z",
          "wordCount": 19555,
          "title": "Searching for a Pastebin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103gq4e/music_server_that_can_write_to_the_file_tags/",
          "author": null,
          "description": "Navidrome seems to be currently one of the best in town, but it's designed to not write to file tags [1].\n I listen to my local music and modify the tags (star-rating, genre, etc.) on the fly, either on desktop (macOS) or mobile (Android). i'd like to do the same for the music on my server.\n Does anyone know of a music server that allows editing the file tags on the client? TIA\n [1] https://www.navidrome.org/docs/faq/#how-can-i-edit-my-music-metadata-id3-tags-how-can-i-renamemove-my-files\n    submitted by    /u/Digital_Voodoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103gq4e/music_server_that_can_write_to_the_file_tags/",
          "publishedOn": "2023-01-04T22:10:37.000Z",
          "wordCount": 19660,
          "title": "Music server that can write to the file tags",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103gk75/ecc_vs_ddr5_for_zfs_raid/",
          "author": null,
          "description": "Hello. I'm building a NAS that will run ZFS raid. I've heard that ECC is important to prevent corruption. But ECC isn't officially supported on desktop hardware. My options are either to try to get a Ryzen build working with unofficial ECC support or use a DDR5 system, since DDR5 has a form of ECC as well. Does anyone have any idea how DDR5's ECC compares against true ECC memory?\n    submitted by    /u/Granete  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103gk75/ecc_vs_ddr5_for_zfs_raid/",
          "publishedOn": "2023-01-04T22:04:39.000Z",
          "wordCount": 18863,
          "title": "ECC vs DDR5 for ZFS Raid",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103ghtd/os_for_newly_purchased_home_server/",
          "author": null,
          "description": "Hello guys,\n Sorry for the newbie question but I bought a mini PC to act as a home server at my house. The main use would be to deploy some docker containers that would be accessible from outside...It came with a Windows 11.\n After searching this subreddit, everyone recommended installing Proxmox.\n Can you kindly explain what is the benefit of Proxmox? especially vs ESXI or Windows + VMware workstation?\n Last \"noobie\" question: Can I run a wireless adapter under linux? since it is very hard to connect the PC via cable.\n Thanks\n    submitted by    /u/Geek77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103ghtd/os_for_newly_purchased_home_server/",
          "publishedOn": "2023-01-04T22:02:07.000Z",
          "wordCount": 19262,
          "title": "OS for newly purchased \"Home Server\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103fduj/postfix_smtp_relay_add_users/",
          "author": null,
          "description": "Does anyone have a good guide on how to protect postfix with a user, that is, I am going to use postfix as a relay and I need to add users so that they can identify themselves when I connect via smtp\n thank you\n    submitted by    /u/armando0000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103fduj/postfix_smtp_relay_add_users/",
          "publishedOn": "2023-01-04T21:19:34.000Z",
          "wordCount": 20281,
          "title": "postfix smtp relay add users",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103f737/help_uploading_files_greater_than_100mb/",
          "author": null,
          "description": "I'm currently using Nginx Proxy Manager to handle the reverse proxy for my Unraid server. I'm trying to upload large files, such as videos, to my PhotoPrism instance over the reverse proxy but I'm unable to upload anything over 100MB. I've done somewhat extensive research and found that Cloudflare limits uploads to 100MB, so I tried setting my PhotoPrism subdomain to DNS only (gray cloud) and still cannot upload large files to my server. I've also tried modifying my php.ini file to allow larger uploads and still see no change. I've also tried adding advanced parameters inside NPM but when I do that the reverse proxy fails to resolve.\n ​\n Would someone be able to help me diagnose why these uploads fail over reverse proxy but work very quickly when I connect to my server locally? It would really help with uploading my pictures and videos from my phone when I'm away from the house. Thanks!\n    submitted by    /u/nrgbistro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103f737/help_uploading_files_greater_than_100mb/",
          "publishedOn": "2023-01-04T21:12:10.000Z",
          "wordCount": 19974,
          "title": "[Help] Uploading files greater than 100MB",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103f63k/can_no_longer_connect_to_vps_after_enabling/",
          "author": null,
          "description": "The problem here is that after enabling cloudflare warp on my ovh VPS, It seems to have prevented it from connecting to the internet? Everything istalled correctly, and I enabled it successfully, but as soon as I did that, the ssh connection timed out and I haven't been able to connect at all since then?\n What I've already tried: rebooting the vps from the ovh manager (it didn't work, and I dont even think it rebooted at all)\n ​\n Anyone know what's going on and how to fix it? Thanks.\n ​\n EDIT: Fixed by re-installing ubuntu (vps --> OS/distribution --> reinstall vps)\n    submitted by    /u/Maximum_Studio5147  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103f63k/can_no_longer_connect_to_vps_after_enabling/",
          "publishedOn": "2023-01-04T21:11:03.000Z",
          "wordCount": 19714,
          "title": "Can no longer connect to vps after enabling cloudflare warp!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103ed14/issues_with_gitea_lfs/",
          "author": null,
          "description": "Hey guys,\n We're self hosting GItea on Ubuntu and have LFS for some of the repos.\n Recently we had to move the LFS folder from 'system drive' to another volume due to storage issues on the droplet. We've updated .ini config for Gitea to account for the new folder location on another volume. \n Ever since we have an issue with LFS files for repos (plz see attached error log):\n https://easyupload.io/4mjwr6\n Are we missing something? Should we have done smth else besides setting a new LFS folder location in the .ini config file for Gitea?\n Thanks for your help in advance.\n    submitted by    /u/avsn99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103ed14/issues_with_gitea_lfs/",
          "publishedOn": "2023-01-04T20:40:11.000Z",
          "wordCount": 19686,
          "title": "Issues with Gitea + LFS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103ea62/how_do_i_set_up_access_to_a_vpn_through_nginx/",
          "author": null,
          "description": "So I have a webserver on my home network, along with a VPN server (OpenVPN Access Server). The VPN server uses post 443 over TCP, and so does my webserver. So I tried to create a stream from that server to the domain for the VPN, and while the server's admin interface shows up, I can't connect to it.\n    submitted by    /u/null_rm-rf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103ea62/how_do_i_set_up_access_to_a_vpn_through_nginx/",
          "publishedOn": "2023-01-04T20:37:06.000Z",
          "wordCount": 19152,
          "title": "How do I set up access to a VPN through Nginx Proxy Manager?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103dgbx/self_hosted_tide_tables/",
          "author": null,
          "description": "Maybe twenty years ago (I know) Ubuntu had a package that was an Apache-served tide tables package where, after the appropriate data packages were downloaded and installed, the user could select a location and it would show low and high tide times for that location.\n A fair bit of search engine work hasn't been fruitful, so I'm hoping that someone in this community might know if it or something similar still exists for self hosting.\n I appreciate the help.\n    submitted by    /u/SplendidMagnificence  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103dgbx/self_hosted_tide_tables/",
          "publishedOn": "2023-01-04T20:05:07.000Z",
          "wordCount": 18679,
          "title": "Self hosted tide tables",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103dfmv/is_there_a_way_to_automate_a_watch_later_workflow/",
          "author": null,
          "description": "I'm not sure how to phrase that, but I use Jellyfin and ytdl-material.\n Is there a way I can automatically download videos I add to my watch later list in YT (mostly from revanced on my phone) and have these videos copied in a folder of my choice for Jellyfin to play ?\n I guess I'll have to use something else than ytdl-material.\n Can someone point me to the right direction ?\n    submitted by    /u/Tiritibambix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103dfmv/is_there_a_way_to_automate_a_watch_later_workflow/",
          "publishedOn": "2023-01-04T20:04:21.000Z",
          "wordCount": 19793,
          "title": "Is there a way to automate a \"watch later\" workflow ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103cr3i/passwordprotected_video_sharing/",
          "author": null,
          "description": "I'd like to share a video with just a few people, password-protect it, and if possible prevent easy downloading (I know it's impossible to entirely prevent downloading of course).\n I self-host Jellyfin as my home media server, but I'm reluctant to expose it to the internet (I use Tailscale to access it remotely).\n What would be a good option for password-protected video sharing? Ideally I'd want something that can be played smoothly in a browser, at 1080p.\n    submitted by    /u/KindPace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103cr3i/passwordprotected_video_sharing/",
          "publishedOn": "2023-01-04T19:37:49.000Z",
          "wordCount": 19657,
          "title": "Password-protected video sharing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103alcg/bookmarks_for_teams/",
          "author": null,
          "description": "hey r/selfhosted:\n I am searching for a bookmark tool which can be selfhosted (bacause of privacy concerns) an be used by multiple team members. I tried fluccus already, but we ran into sync issues which wiped the changes which were done by one team member earlier. \n We established a workaround for this, that we set the agent to read-only and enable read-write to the database only when we do actual changes, but maybe someone has a better solution for this. \n Also tried xbrowsersync which didn't work either.\n Thanks for helping and happy new year!\n zmbgcn\n    submitted by    /u/zmbcgn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103alcg/bookmarks_for_teams/",
          "publishedOn": "2023-01-04T18:15:13.000Z",
          "wordCount": 20689,
          "title": "Bookmarks for Teams",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/103887y/best_strategy_for_mullvad_pihole_using_docker/",
          "author": null,
          "description": "Hi all. I've been lurking here a while but since I am relatively new at this stuff please let me know if this is the wrong place to ask. I am just starting my journey creating a local network. I have set up Plex and pi-hole on Dockers in my server running OMV (old laptop), and a very close friend gave me a license for Mullvad. It would be awesome to add this vpn to my whole network instead of one device, specially if I can turn it on and off easily. Is this even possible? What I have found online so far ranges from people saying it is not possible to people saying it is and I should use Wireguard on a rPie, but in my case it feels like using docker is the best way to go. I already route everything in my network to the pi-hole in the server through my router... Would it work to just route pi-hole to the VPN or send everything to Mullvad in my router config and then send mullvad to the pi-hole? If this is too confusing please lemme know\n    submitted by    /u/betodaviola  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/103887y/best_strategy_for_mullvad_pihole_using_docker/",
          "publishedOn": "2023-01-04T16:44:16.000Z",
          "wordCount": 20845,
          "title": "Best strategy for Mullvad + pi-hole using docker",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1037ee4/my_yearly_praise_for_bookstack_post/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1037ee4/my_yearly_praise_for_bookstack_post/",
          "publishedOn": "2023-01-04T16:11:23.000Z",
          "wordCount": 19335,
          "title": "My yearly \"Praise for Bookstack\" Post",
          "imageUrl": "https://external-preview.redd.it/b5BviVziwBSdFmYiRhI29r3w-ijasTdkGhZ9eN-0NH0.jpg?auto=webp&s=88f275713a0db920087d3dda1b9d15b7e00c43d6"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10364mt/keeping_virtual_servers_isolated_from_eachother/",
          "author": null,
          "description": "Hi. I tried to search for this topic but couldn't find anything that matched my setup.\n I have a VMware ESXi server running both internal and external servers. External servers are isolated on a single VLAN that has only access to internet, so they are isolated from the rest of the internal network.\n Now I want to isolate each server from the others on this \"external\" VLAN, so that each of the webservers (for example) can only talk to the reverse proxy server, but not with each other.\n What would be the best, easiest (and cheapest) way to accomplish this?\n I would like to...\n  \navoid using a local firewall on each server (Ubuntu), unless it can be centrally managed somehow.\n avoid using multiple VLANs in order to keep network traffic on the host. So traffic doesn't have to go from the router, to the reverse proxy, back to the router and then to the VM.\n  \nHow do/would you do it, to keep public facing servers safe from each other?\n    submitted by    /u/magnuswerner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10364mt/keeping_virtual_servers_isolated_from_eachother/",
          "publishedOn": "2023-01-04T15:19:13.000Z",
          "wordCount": 20740,
          "title": "Keeping virtual servers isolated from eachother",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1035t39/just_got_my_linux_stardust_vps_1_core_1gb_ram_for/",
          "author": null,
          "description": "From Scaleway, was only available in \"Amsterdam 1\" today via the web front-end (although also managed to create one in Paris via the cli).\n Without an IP v4 address, cost is:\n  \nAvailability Zone: AMSTERDAM 1\n Server: STARDUST1-SStardust- 1 X86 64bit - 1 GB Memory - €0.11\n Image: Ubuntu 22.04 Jammy Jellyfish - €0.00\n Local Storage: 10 GB - €0.32\n Flexible IP: No - €0.00 (only IPv6)\n  \nTotal per month: €0.43\n    submitted by    /u/TedBob99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1035t39/just_got_my_linux_stardust_vps_1_core_1gb_ram_for/",
          "publishedOn": "2023-01-04T15:05:47.000Z",
          "wordCount": 20788,
          "title": "Just got my Linux Stardust VPS 1 core 1GB RAM for €0.43...a month",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1031chv/simple_way_to_centralize_my_server_logs/",
          "author": null,
          "description": "I'm currently receiving across many emails, a ton of logs from multiple services, like cron daemons. I would like to know if there is a way to centralize my server logs in one place, with, possible, a web view or something like that. \n Something simple if possible. I've seen some solutions that are absolutely madness in terms of configuration. Maybe this is a requirement but if someone has been able to find something neat, I would like to hear :)\n    submitted by    /u/SirLouen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1031chv/simple_way_to_centralize_my_server_logs/",
          "publishedOn": "2023-01-04T11:29:23.000Z",
          "wordCount": 21083,
          "title": "Simple way to centralize my server logs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102z3ks/alternatives_to_hetzner_or_netcup_on_the_european/",
          "author": null,
          "description": "At least here in germany it feels like 99% of self-hosted services are running on hardware/servers from Hetzner or Netcup. While I am actually satisfied with both of them, I am wondering if there are some other players with good hardware for a good price. I am not unhappy or disappointed in any way. Just trying to get an overview.\n I tried Contabo but wasn't happy. Feels like their higher tiers are somewhat okay, but once the server is running to many instances your VPS is slowing down more and more.\n I am really just looking for older and established companies that will most likely not stop their business next week due to miscalculation or other problems. So non of those reseller-reseller-resellers^^\n    submitted by    /u/Stardenver  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102z3ks/alternatives_to_hetzner_or_netcup_on_the_european/",
          "publishedOn": "2023-01-04T09:23:31.000Z",
          "wordCount": 23111,
          "title": "Alternatives to Hetzner or Netcup on the european market?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102xq3m/very_lightweight_monitoring_of_various/",
          "author": null,
          "description": "Hi,\n I would like to achieve the following:\n  \nVarious servers I have to send data at regular intervals to a central server/website (cloud hosted or hosted by me). I don't want the reverse to happen (server to contact the various hosts, and having to open ports)\n Send \"heartbeat\" data (\"I am alive\") and the central server alerting if something is down (no \"alive\" message detected after x minutes)\n Send very basic data like CPU usage over the last minute, 5 minutes, RAM, storage. Maybe 5 or 10 data metrics\n  \nI need the \"agent\" to be very lightweight, as some of those servers are low spec (like 1GB of RAM, or even 512MB).\n I have tried to install NetData but it brought several servers to their knees during the install. I have tried Prometheus, which seems fine but overkill for the task (and also it seems that the server is contacting the hosts).\n I could also do my own version (running a Python script every few minutes to post data to a website), or maybe have Python use MQTT to send messages to a MQTT server, but I would prefer to have an already built solution.\n Thanks\n    submitted by    /u/TedBob99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102xq3m/very_lightweight_monitoring_of_various/",
          "publishedOn": "2023-01-04T07:57:36.000Z",
          "wordCount": 21054,
          "title": "Very lightweight monitoring of various Ubuntu/Debian Servers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102pih9/how_to_make_my_little_nuc_more_resilient_to/",
          "author": null,
          "description": "I started out self hosting on a little NUC (4-core, 32 GB RAM, SSD+HD+USB HD) running Ubuntu in my closet, and have now grown to hosting quite a few apps on it, some of which are \"mission critical\". Also, the prospect of spending a day reconfiguring everything if the machine goes down is quite scary. I'm running docker for apps that are come dockerized, but I haven't invested in learning to dockerize individual apps on my own to make them easier to backup and restore.\n Bottom line, I'm looking to make the hardware more fault tolerant (RAID array?) and the software easier to restore (Proxmox with VMs and Docker containers?). Right now, I'm worried about even upgrading Ubuntu, which has given me headaches before.\n I'm currently running:\n  \nzoneminder (want to move to frigate) (apt install)\n homeassistant (pip install)\n paperless-ngx (docker)\n jellyfin (docker)\n nextcloud (docker)\n offlineimap + notmuch + netviel (offline searchable IMAP archive) (manual install)\n kopia (manual install)\n  \nOption #1: More hardware + Proxmox - Upgrade machine to full tower supporting RAID (also requires upgrading my UPS and maybe installing an exhaust fan in my closet)\n Option #2: Same hardware + Migrate to Proxmox (temporarily moving all services to somewhere else)\n Option #3: Move less critical services (homeassistant, etc.) to raspberry pi, etc to reduce monolith risk\n Option #4: Simpler disaster recovery (is there some way to easily image the entire machine regularly?)\n Suggestions?\n    submitted by    /u/desertcroc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102pih9/how_to_make_my_little_nuc_more_resilient_to/",
          "publishedOn": "2023-01-04T01:07:13.000Z",
          "wordCount": 20260,
          "title": "How to make my little NUC more resilient to failure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102ntok/gluetune_error_when_starting_over_console_but_not/",
          "author": null,
          "description": "I can start Gluetune in Portainer as Stack via my compose file and it works perfectly fine, the Container is healthy.\n But when I try the command the following command with the same compose.yml file:\n docker compose up\n then it doesn't work and I get the error:\n WARN [dns over tls] cannot update files: Get \"https://www.internic.net/domain/named.root\" \n dial tcp: lookup www.internic.net on 1.1.1.1:43 i/o timeout \n INFO [dns over tls] attempting restart in 40s \n Here is the docker compose file:\n version: \"3\" services: gluetun: image: qmcgaw/gluetun:latest cap_add: - NET_ADMIN environment: - VPN_SERVICE_PROVIDER=custom - VPN_TYPE=wireguard # For Wireguard - VPN_ENDPOINT_IP=1.2.3.4 - VPN_ENDPOINT_PORT=51820 - WIREGUARD_PUBLIC_KEY=xxxx - WIREGUARD_PRIVATE_KEY=xxxx - WIREGUARD_ADDRESSES=1.2.3.4/1 - TZ=xxxx \n Does anybody know what the issue could be here, that it works via portainer but not when i start it via console?\n    submitted by    /u/LuposX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102ntok/gluetune_error_when_starting_over_console_but_not/",
          "publishedOn": "2023-01-03T23:56:22.000Z",
          "wordCount": 20070,
          "title": "Gluetune error when starting over console but not when starting via portainer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102nplv/how_to_setup_all_vms_in_a_lan_to_use_a_single/",
          "author": null,
          "description": "I've setup a debian VM with postfix smtp relay using my gmail account.\n I'd like all my other VMs within my LAN to also send email but I don't want to set it up again on every VM. Can it be done so that I'd just point my other VMs to that one postfix smtp relay server? What do I need to setup on the other VMs this way?\n    submitted by    /u/_clapclapclap  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102nplv/how_to_setup_all_vms_in_a_lan_to_use_a_single/",
          "publishedOn": "2023-01-03T23:51:39.000Z",
          "wordCount": 19516,
          "title": "How to setup all VMs in a LAN to use a single postfix smtp relay to send email?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102mm7b/ubuntu_docker_nas_for_storage/",
          "author": null,
          "description": "Hey Guys\n Apologies if this is the wrong place to ask.\n Fairly new to Ubuntu, but as an IT guy, I've had enough exposure to it to be comfortable working with it, and I'd like to think I can pick it up pretty quickly, so feel free to nerd out on me!\n I'm creating myself a home media server, I've got a little NUC (i5, 16gb RAM, 256 SSD) which I'd like to make my usenet box, using Ubuntu, and ultimately Docker to get it going, my plex server is going to run on a different box too, but that's currently setup anyways and working fine, I just want to add a bunch of automation to it\n I've followed this guide - Docker Media Server Ubuntu 22.04 with 23 Awesome Apps | SHB (smarthomebeginner.com) - Which is amazing, but, I can't see my NAS (i have added NFS mount points and can upload into it from Ubuntu directly, just SABNZD doesn't see it at all, I did a few permission changes, but nothing changed.\n I've found this link, is this going to allow me to see my NAS from the Containers in Docker? \n NFS Docker Volumes: How to Create and Use | phoenixNAP KB \n I'm going to start again, I'd like to stick to Ubuntu purely for the benefit of more exposure to another OS. I can't find any guides on setting up with a NAS as Storage, but I imagine it's just my lack of understanding of the OS and Docker for how it works rather than it not being possible\n TIA\n    submitted by    /u/-Lord-of-the-Pings-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102mm7b/ubuntu_docker_nas_for_storage/",
          "publishedOn": "2023-01-03T23:07:26.000Z",
          "wordCount": 19538,
          "title": "Ubuntu - Docker - NAS for Storage",
          "imageUrl": "https://external-preview.redd.it/nCgjb1sB1GmkbG4Q2Ki9PPFFXZd9vxA7C-m3q3woNNU.jpg?auto=webp&s=2d3e892ebde80e5cc65c9d85ea0a1ff7e680b2c7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102mctl/i_just_set_up_tubesync_and_its_working_how_do_i/",
          "author": null,
          "description": "I have TubeSync download into a separate folder for each channel. It's downloading thumbnails and a json file. Is there a way to get those channels to show up as TV shows?\n    submitted by    /u/ItWorkedLastTime  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102mctl/i_just_set_up_tubesync_and_its_working_how_do_i/",
          "publishedOn": "2023-01-03T22:57:36.000Z",
          "wordCount": 19978,
          "title": "I just set up TubeSync and it's working. How do I get a channel to show up as a TV show, or at least have a nice way to browse things in Kodi?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102krp8/could_i_get_a_recommendation_for_a_recording_baby/",
          "author": null,
          "description": "I already have a server running (an old Dell workstation) which is essentially just a NAS with a few Docker containers running on it\n I have a spare Pi4, Pi2B and a couple of Pi Zeros\n I would like a CCTV setup to be running 24/7 in the baby's room. Must have night vision. Ideally I'd like it to record something like 3-4 days worth of footage at 720p, 15fps\n I would also like to be able to tune in live on my phone using something like tinyCam Monitor\n Local LAN is fine. No need for remote access\n Could a Pi Zero power an IR USB webcam? Could I record straight to my server and still tune in to view live? Which software would you recommend?\n Thanks for any pointers!\n    submitted by    /u/Surbiglost  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102krp8/could_i_get_a_recommendation_for_a_recording_baby/",
          "publishedOn": "2023-01-03T21:57:16.000Z",
          "wordCount": 19913,
          "title": "Could I get a recommendation for a recording baby monitor? Details below",
          "imageUrl": "https://external-preview.redd.it/S90jdgDH27C_agLzCVnZEtSh024Xaw9e_Q9vGBUVGJI.jpg?auto=webp&s=bd727da6be06c4c535946d681c61ee9cdd752416"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102icav/non_profit_healthcare_clinic_looking_for_self/",
          "author": null,
          "description": "Good Afternoon r/selfhosted,\n I had a small non profit Healthcare clinic that is looking for either a self hosted (free) or low cost cloud employee shift scheduling software. Something similar to hotschedules.\n Mainly we are hoping to find one that has a phone companion app (Android and iPhone) with web access also available.\n The main concern is they have mostly open schedules and want employees to sign up for the open slots. (Ala picking up free shifts) however I am finding it really hard to find a self hosted or even cloud hosted that allows the employees to pick up shifts.\n Please let me know if you have any suggestions or recommendations!\n Thank you!\n    submitted by    /u/Badgerized  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102icav/non_profit_healthcare_clinic_looking_for_self/",
          "publishedOn": "2023-01-03T20:23:29.000Z",
          "wordCount": 20196,
          "title": "Non profit Healthcare clinic looking for self hosted or cheap cloud alternative employee shift scheduling app?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102i152/onprem_open_source_software_for_selling_to_staff/",
          "author": null,
          "description": "Like many places we end up with a lot of old tech that we need to get rid of. \n Currently the process goes,\n Hold an auction for staff with the money going to charity (this is all done by emails).\n Anything not sold sits in a store room until we either hold another auction or get some tech recyclers to come and get it. \n So I figured there must be an easier way, someone must have posted some open source site to be able to do something like these? \n A lot of what I've seen so far doesn't seem great, has anyone got any recommendations?\n    submitted by    /u/thebluemonkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102i152/onprem_open_source_software_for_selling_to_staff/",
          "publishedOn": "2023-01-03T20:11:17.000Z",
          "wordCount": 19831,
          "title": "On-Prem Open source software for selling to staff?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102h2dj/self_hosted_tool_to_show_status_of_downloads_from/",
          "author": null,
          "description": "Hi all! \n I am looking for a self-hosted web interface that shows the status of current downloads in both Radarr and Sonarr. I do not want to expose Radarr and Sonarr to the web but I want sort of a frontend that can let users check the status of the downloads. Let me know if such a thing exists! Thanks!\n    submitted by    /u/joe9624  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102h2dj/self_hosted_tool_to_show_status_of_downloads_from/",
          "publishedOn": "2023-01-03T19:32:38.000Z",
          "wordCount": 20649,
          "title": "Self Hosted tool to show status of downloads from Sonarr and Radarr.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102h06y/strange_behaviour_of_my_wireguard_installation/",
          "author": null,
          "description": "I'm having a strange behaviour with Wireguard. Traffic through VPN is ok, if I connect to external servers it connects via SSH flawlessly, servers with IP inside the VPN are unreachable, also with a simple ping. If I disconnect from VPN I can't reach anything via SSH. I don't understand where is the problem.\n This is the configuration of a Peer (a proxmox machine) https://pastebin.com/b9LWfcFd\n This is the conf of VPN on wireguard server https://pastebin.com/rnqh2k3C\n Any help to understand where is the problem?\n    submitted by    /u/ziriuz84  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102h06y/strange_behaviour_of_my_wireguard_installation/",
          "publishedOn": "2023-01-03T19:30:14.000Z",
          "wordCount": 21198,
          "title": "Strange behaviour of my wireguard installation",
          "imageUrl": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&s=07c121a0180003f7373863af66192b6ff6a937da"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102gfg4/selfhosted_web_scraper/",
          "author": null,
          "description": "Does anyone know something similar like Octoparse but free and selfhosted ? I tried changedetection but it is not the same. \n Thank you very much for help.\n    submitted by    /u/Sinclairxer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102gfg4/selfhosted_web_scraper/",
          "publishedOn": "2023-01-03T19:07:18.000Z",
          "wordCount": 19999,
          "title": "Self-hosted web scraper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102enkn/simplex_chat_the_1st_messenger_without_user/",
          "author": null,
          "description": "Happy New Year!\n SimpleX Chat now supports disappearing messages – the most frequent request from the users.\n To use them both conversation parties should agree to it, unlike in most other messengers that allow to send disappearing messages without recipients' agreement. Our logic here is the same as for irreversible deletion of sent messages (this feature was added in 4.3).\n What do you think about it?\n This version also added:\n  \nconnection security code verification – it allows to confirm that the connection keys/addresses were not substituted (man-in-the-middle attack).\n \"live\" messages – they update to all recipients as you type them, every several seconds.\n French language interface - thanks to users community and Weblate.\n  \nSee more details in this post and download the apps via the links here.\n Please ask any questions about SimpleX Chat in the comments! Some common questions:\n Why user IDs are bad for privacy?\n How SimpleX delivers messages without user profile IDs?\n How SimpleX is different from Session, Matrix, Signal, etc.?\n    submitted by    /u/epoberezkin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102enkn/simplex_chat_the_1st_messenger_without_user/",
          "publishedOn": "2023-01-03T17:59:25.000Z",
          "wordCount": 19981,
          "title": "SimpleX Chat – the 1st messenger without user profile IDs (not even random numbers) – v4.4 released with disappearing messages and connection verification!",
          "imageUrl": "https://external-preview.redd.it/QMWhSzZAe2ZP_lmjUkJILrtwHz0MZyxoMbFHcXKSHD4.jpg?auto=webp&s=170a30eb077fa54ff9517dd4cd9d5f728dc29857"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102e5lp/how_should_i_structure_my_first_media_server/",
          "author": null,
          "description": "Beginner to self hosting here. My first server is a Beelink Mini S micro PC. I have an 8TB external HDD on it for now. Looking to start with Jellyfin for media and then add other apps from there if resources allow. Adding more micro PCs may be in my future. Should I jump in and install TrueNAS as the OS right away? Or is that overkill for now?\n    submitted by    /u/mentalflux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102e5lp/how_should_i_structure_my_first_media_server/",
          "publishedOn": "2023-01-03T17:40:08.000Z",
          "wordCount": 20618,
          "title": "How should I structure my first media server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102dugh/video_server_with_embedding_function/",
          "author": null,
          "description": "Hi everyone I'm looking for a solution, preferably on docker, that lets me share videos to embed on a webpage for example in iFrame.\n I own the videos and I just need to share them internally for a wiki solution made with Obsidian.\n Thank you all and happy new year 😉\n    submitted by    /u/alephtaph  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102dugh/video_server_with_embedding_function/",
          "publishedOn": "2023-01-03T17:27:45.000Z",
          "wordCount": 18541,
          "title": "Video server with embedding function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102dil0/paperlessngx_mail_rule_regex/",
          "author": null,
          "description": "hi, i'm trying to get more flexible rule with regex but i cannot make it working.\n can i use regex inside of \"filter body or subject\" or use few separate sentences to fetch emails?\n fe. \"invoice Shop1\" and \"invoice shop2\" in one rule? or simple regex \"invoice.* Bank1|vat Invoice\"\n    submitted by    /u/gm_84  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102dil0/paperlessngx_mail_rule_regex/",
          "publishedOn": "2023-01-03T17:14:27.000Z",
          "wordCount": 20153,
          "title": "paperless-ngx mail rule regex",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102dano/notionlike_selfhosting_alternative_for_project/",
          "author": null,
          "description": "Hey guys,\n I love notion. But I love self-hosting more. I'm going to need to switch soon to a self-hosting alternative and I can't find the perfect replacement. I love notion's databases, freedom of customizing properties and views. In summary, I'd really love a self-hosting project management tool that allows me to: Create a task database that allows me too see in a list, board and timeline views\n ​\n Does someone recommend me a good alternative? I've checked outline but it seems lacking a lot of these features, plus they over rely on google and slack... And I'm also planning on creating a rocket.chat server for a self-hosted slack alternative.\n ​\n Thanks in advance\n    submitted by    /u/francis2tm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102dano/notionlike_selfhosting_alternative_for_project/",
          "publishedOn": "2023-01-03T17:05:28.000Z",
          "wordCount": 20314,
          "title": "Notion-like self-hosting alternative for project management?",
          "imageUrl": "https://external-preview.redd.it/5sTnGdLnNdNtgn4BiGJ--3EeUxKl9xH7qQRvYj4fEtA.jpg?auto=webp&s=bc044135352daef64679a61d0bcbf675de6558e7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102d1w4/ai_content_detection_for_labellingtagging_nsfw/",
          "author": null,
          "description": "So I'm looking for a photo management solution to label/tag NSFW pictures.\n I've been messing with Photoprism and Librephotos but their NSFW detection is only for flagging rather than content detection.\n I'm open to an external API or custom labelling solution, but haven't really found a means to do that either with those apps.\n To be clear, I'm not looking for something like Stash. I'm looking to automatically label/tag and sort nudes.\n Sorry if this isn't the place for this, but any suggestions are appreciated.\n    submitted by    /u/just_for_saving_porn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102d1w4/ai_content_detection_for_labellingtagging_nsfw/",
          "publishedOn": "2023-01-03T16:56:03.000Z",
          "wordCount": 19687,
          "title": "AI content detection for labelling/tagging NSFW photos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102b2cc/can_i_replace_radarr_with_dockerradarrextended/",
          "author": null,
          "description": "I came across docker-radarr-extended when I was looking into a way to download trailers alongside my movie files, and this image seems to be what I'm looking for. It uses custom scripts to configure Radarr, as well as provides one that downloads the trailers, so I'm curious to know if I can just plug-and-play replace my current Radarr container with this image.\n At the moment I'm using the Radarr image from LinuxServer, which this is based off of, and have a custom configuration for the way Radarr should name and organize movies, so I would be disabling the enableAutoConfig which will hopefully avoid it from overriding my configuration.\n Besides that, I have volumes set-up in K3s for Radarr, and already a large collection of movies that its tracking as well as indexers from Prowlarr and download clients. I just want to make sure that this image won't change any of that setup, which I don't expect it to, since it should just be the same LinuxServer image with additional scripts, but was wondering if anyone has had the situation where they migrated from Radarr to this extended image.\n Thanks in advance for any input!\n    submitted by    /u/WherMyEth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102b2cc/can_i_replace_radarr_with_dockerradarrextended/",
          "publishedOn": "2023-01-03T15:34:36.000Z",
          "wordCount": 19897,
          "title": "Can I replace Radarr with docker-radarr-extended?",
          "imageUrl": "https://external-preview.redd.it/nnfoOSnvHgJ6H7CsmBoTffYFz9JoUsAHp4evZYuj_Ek.jpg?auto=webp&s=faeeab4b9b9e0faa49afbb795d3beb274a72ee45"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/102aroh/selfhosted_bookmark_manager_what_would_you_suggest/",
          "author": null,
          "description": "My current bookmark/read-later solution combines Papaly, Raindrop, and Joplin. I was not able to find a solution to combine them all together, so I have given up on that option. Joplin will stay as a read-later solution. Dashy, which I have chosen as a locally hosted dashboard will host a few links from Papaly's quick access bar that I access multiple times a day. There is still the choice for an app that will host the bulk of links currently residing in Papaly pages, Raindrop, and Google bookmarks.\n I have searched through Selfhosed listings, searched the web for solutions, and cut the choice down to three options: \n  \nLinkding, \n Linkace,\n Servas. \n  \nI cannot avoid running each one of them for a few days and seeing the solution for myself. That was the way I have found that I do not like Wallabag, while from reading about it it seemed like a perfect solution. But, when one runs a solution for a few days one can miss some options or characteristics.\n So, before I start my test run, I want to hear from those of you who have chosen not to use one of those three, what made you choose to avoid them, and I want to hear from those of you who are using one of those three, what made you choose them and do you have any regrets you found about later while using it.\n Thank you\n    submitted by    /u/SaleB81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/102aroh/selfhosted_bookmark_manager_what_would_you_suggest/",
          "publishedOn": "2023-01-03T15:21:49.000Z",
          "wordCount": 21817,
          "title": "Self-hosted bookmark manager, what would you suggest?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1028omb/my_completely_automated_homelab_featuring/",
          "author": null,
          "description": "submitted by    /u/onedr0p  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1028omb/my_completely_automated_homelab_featuring/",
          "publishedOn": "2023-01-03T13:47:47.000Z",
          "wordCount": 18774,
          "title": "My completely automated Homelab featuring Kubernetes",
          "imageUrl": "https://external-preview.redd.it/n1zhndzTM3A0LEcBbiEl89PQ5FjTMpF9hFFbXeDBkgo.png?auto=webp&s=c5ef12786f99a0dbb6042143bd02a5677d733eb2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1027oi3/homepage_dashboard_api_error_portainer_hi_i_tried/",
          "author": null,
          "description": "submitted by    /u/KRPX_TH  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1027oi3/homepage_dashboard_api_error_portainer_hi_i_tried/",
          "publishedOn": "2023-01-03T13:03:18.000Z",
          "wordCount": 19837,
          "title": "Homepage dashboard API error (Portainer) Hi, I tried to fix this API error but I don’t know how. If anyone has encounter the same problem and know how to fix, please let me know. I am using Docker on Synology NAS",
          "imageUrl": "https://preview.redd.it/0ht9pfajbv9a1.jpg?auto=webp&s=b860788b9859e72f021de192ec88a3bf9318a845"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1025z4u/new_budibase_release_build_internal_tools_even/",
          "author": null,
          "description": "Happy new year, self-hosters!\n For those who don't know about Budibase, it's an open-source low-code platform (GUI) that saves you time and effort building internal tools.\n To kickstart 2023, we have a new release that will speed up the dev process when building internal tools:\n New side panel (total CRUD in 1 screen)\n You can now view records in a side panel. What's also super cool is you can continue to navigate records whilst the side panel is active. This reduces the number of screens you have to use and creates a smooth and faster experience for end-users.\n https://preview.redd.it/3l1woytfet9a1.png?width=1200&format=png&auto=webp&s=fd8a0073bde61f1f51aa5131d84fcf7e721991a3\n Sample data for quicker onboarding\n When creating apps with Budibase, you can now choose if you would like to add…",
          "link": "https://www.reddit.com/r/selfhosted/comments/1025z4u/new_budibase_release_build_internal_tools_even/",
          "publishedOn": "2023-01-03T11:41:51.000Z",
          "wordCount": 19389,
          "title": "New Budibase release: Build internal tools even faster!",
          "imageUrl": "https://external-preview.redd.it/i3QFOu3x9V3zC1E6VIpmK4-LMTzCt34Aicltg7WmxyA.jpg?auto=webp&s=7f1c9cfff33b3fbe1a5af1dcfc3cc3b8ca879def"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1024w4g/cloudflare_tunnels_vs_vpsnginxvpn/",
          "author": null,
          "description": "Hi all.\n I try to collect some pro/con thoughts on following scenarios:\n  \nRunning some services at home in docker environment and exposing them to the internet using cloudflare tunnels.\n \nRunning some services at home in docker environment and having a (free) VPS which is connected as a VPN client to my local network, running a reverse proxy (nginx proxy manager) and exposing my services to the internet over this VPN. \n \n What do you think should be preferred and why?\n Thanks & cheers. :)\n    submitted by    /u/yannbros  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1024w4g/cloudflare_tunnels_vs_vpsnginxvpn/",
          "publishedOn": "2023-01-03T10:43:39.000Z",
          "wordCount": 21502,
          "title": "Cloudflare Tunnels vs VPS/Nginx/VPN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1023n5t/self_hosted_document_management/",
          "author": null,
          "description": "I’ve got a weird request from a friend. There’s a googledocs front end called Spaceli. I’ve been asked if I know of any self hosted similar front end documentation management that backs onto a cloud storage system like Spaceli & Google Drive/Docs\n    submitted by    /u/ella_bell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1023n5t/self_hosted_document_management/",
          "publishedOn": "2023-01-03T09:33:37.000Z",
          "wordCount": 20674,
          "title": "Self hosted document management",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101skab/how_do_you_manage_upss_for_selfhosting/",
          "author": null,
          "description": "So, I self-host a lot of services and I’ve never felt the need to purchase a UPS. But since I’ve invested a lot of money into hardware, now I’m having second thoughts. When googling UPSs, most I’ve found can only signal a safe shutdown to a single machine, and therein lies my conundrum. I don’t know how to go about solving this problem and it’s looking like it will cost a fortune to solve this problem. \n This is what my home lab looks like, hardware wise (all of these machines are in a single small room):\n * 2 x NUC Ubuntu servers. These are the workhorses and my priority.\n * A Synology DS920. I invested a lot of money on this thing and would be devastating if a power outage would corrupt the drives.\n * Motorola MG8702 modem/router. Would be nice to keep internet in the event of an outage, but meh.\n * 1 x Gaming Windows PC. It was a $3k investment, but I turn it off when I’m not gaming. I’m not so worried.\n * 2 x Macbook Pros. These don’t need the UPS.\n * 2 x Ultrawide gaming monitors. These don’t need the UPS. \n Do I have to get multiple UPS machines, 1 per machine, to safely shutdown all of that in an event of a power outage? Or is there a single UPS I can buy that can signal all of them? What are my options? What do you do?\n    submitted by    /u/RommelTJ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101skab/how_do_you_manage_upss_for_selfhosting/",
          "publishedOn": "2023-01-03T00:19:26.000Z",
          "wordCount": 22903,
          "title": "How do you manage UPSs for self-hosting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101qior/web_based_tool_to_automate_scraping_the_web_and/",
          "author": null,
          "description": "submitted by    /u/abumreghaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101qior/web_based_tool_to_automate_scraping_the_web_and/",
          "publishedOn": "2023-01-02T22:56:24.000Z",
          "wordCount": 19928,
          "title": "Web based tool to automate scraping the web and send results via SMS api?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101ps1a/paperless_ngx_vs_papermerge/",
          "author": null,
          "description": "I am a total newb but I did an install of papermerge and paperless to compare. I found paperless-ngx to be much slower than papermerge. Does that make sense or is there something wrong with my install of paperless-ng (x)?\n    submitted by    /u/thehig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101ps1a/paperless_ngx_vs_papermerge/",
          "publishedOn": "2023-01-02T22:26:52.000Z",
          "wordCount": 20793,
          "title": "Paperless -ngx vs Papermerge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101oygn/crossposting_from_docker_because_i_cant_seem_to/",
          "author": null,
          "description": "I cannot seem to get a good take on this and just keep faltering. I have tried many takes from others but I don't see how adding PUID/PGID solves my problems when trying to add a container (Radarr).\n All the steps say these docker compose containers are so easy and just add 1000 for PUID and PGID and permissions problems will be solved.\n But I have two problems even when I do this\n Lets take my docker compose file for example:\n services: radarr: container_name: radarr image: 'linuxserver/radarr:latest' environment: - PUID=1000 - PGID=1000 - UID=1000 - GID=1000 - TZ=America/New_York volumes: - '/home/USER/serverfiles/configs/radarr:/config' - '/mnt/data/media/movies:/movies' - '/mnt/data/torrents/movies:/downloads' ports: - '7878:7878' restart: unless-stopped \n So once I do compose up it creates a config folder with an ownership and group ID of 10999. Or something in that realm in the 10,000s. So I have read up on sudo chowning folders and utilizing but then once I take control of the folder the program no longer is accessible.\n Also the program never has access to my external mnt or doesn't have permissions to access it.\n I am not the root user on the computer Ubuntu. I don't want to run the webservice as root. So trying to be protective I want to run it as my user. User 1000. But I don't know how to get the docker to be able to interact with my host machine in a good way it seems.\n I'm using Ubuntu and Docker Desktop\n What is weird is my NGINX / Jellyfin / AdGuard Home work 100% fine and I didn't even specify the PUID on those. I have that hosted and working correctly.\n Any help would be appreciated because I'm almost certain this is me just not understanding docker and permissions about them.\n    submitted by    /u/tagelthebagel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101oygn/crossposting_from_docker_because_i_cant_seem_to/",
          "publishedOn": "2023-01-02T21:55:04.000Z",
          "wordCount": 21268,
          "title": "Crossposting from Docker because I can't seem to solve a permissions issue on my server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101o7ua/problems_with_searx/",
          "author": null,
          "description": "So I came here with a couple problems.\n First of all it seems what I try, a Searx install, in docker or a docker install in SearXNG I keep getting only html and the backend stuff. What should I try?\n Second I have this problem with running the docker version of both Searx and SearXNG. What should I do?\n And third it seems that I can't run it in docker in background so basically I need to keep both laptop and VPS running and it's useless of me keeping the search engine on. What do I do?\n    submitted by    /u/Bogdan54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101o7ua/problems_with_searx/",
          "publishedOn": "2023-01-02T21:26:13.000Z",
          "wordCount": 20558,
          "title": "Problems with Searx",
          "imageUrl": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&s=07c121a0180003f7373863af66192b6ff6a937da"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101nbri/do_you_know_of_any_solutions_to_convert/",
          "author": null,
          "description": "Currently, my newsletters are arriving in my email, and they get buried in the mailbox (because, yes, it's not organized) and I never read them. So I'm looking for a solution to convert them into Blog posts. \n I guess it wouldn't be too hard to automate converting EMLs to file-based blog posts with something like a PicoCMS, but I'm just wondering if there is any ready solution.\n    submitted by    /u/lakimens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101nbri/do_you_know_of_any_solutions_to_convert/",
          "publishedOn": "2023-01-02T20:51:56.000Z",
          "wordCount": 20399,
          "title": "Do you know of any solutions to convert newsletters to blog posts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101mx2d/web_based_videoaudio_chat_solution_with_high/",
          "author": null,
          "description": "I'm looking for something I can use to host movie nights etc... where anyone with a private invite can connect to a web page and share a single video stream with voice chat. Things I'm looking for include connecting without downloading a client, and ability to adjust volume of individual speakers on the receiving side. Does anything like this exist?\n    submitted by    /u/SimplifyAndAddCoffee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101mx2d/web_based_videoaudio_chat_solution_with_high/",
          "publishedOn": "2023-01-02T20:35:58.000Z",
          "wordCount": 20859,
          "title": "Web based Video/audio chat solution with high quality single presenter video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101mm5z/sharing_my_fully_automated_home_cluster_setup/",
          "author": null,
          "description": "Hi everyone. I have just published all the ansible + terraform code that manages my entire home cluster. Everything is fully automated and it should work (hopefully) for anybody. I hope this is useful for some and/or might give some inspiration for others. Currently I have a 4 nodes + 2 storage solutions + ~20 docker containers + ~ 5 external and free Cloud services. Hopefully this README explains it well:\n https://gitlab.com/sergiojvg/home-media\n    submitted by    /u/Several-Cattle8690  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101mm5z/sharing_my_fully_automated_home_cluster_setup/",
          "publishedOn": "2023-01-02T20:24:14.000Z",
          "wordCount": 21198,
          "title": "Sharing my fully automated home cluster setup based on kubernetes with a different services",
          "imageUrl": "https://external-preview.redd.it/ZquPAU8cZhn0mo04ZhRduLjfjWqLtXZZPPqxxp1O98E.jpg?auto=webp&s=e2e2a035683b076a2e9c6ed930d86f533801fc00"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101mhbq/web_portal_lite_v11_fast_minimal_dashboard_app/",
          "author": null,
          "description": "Web Portal Lite V1.1 is now released, bringing an enhanced ui. Image and more below.\n What Is Web Portal Lite\n Web Portal Lite is a web dashboard to manage a page of links. It offers a minimal feature set to the feature rich Web Portal. Designed for users who just want to create a fancy looking links page and not worry about the advanced features. Unlike Web Portal which features a full ui editor, this \"lite\" version uses a basic yaml file for configuration.\n Why Another Dashboard App?\n Due to my eye condition, I wanted something that was easier to see. So I built one. I have made it customizable by using CSS variables and config options such as the link colors and size. It also has no need for JavaScript since everything is configured by a single yaml file, making it fast to load on slow devices.\n What's Changed\n  \nStyle improvements\n Now arm64 compatible\n Ability to generate template config from CLI\n  \nFeatures\n  \nBuilt in Rust\n Access a grid of beautiful links to your web services\n Works without JavaScript, to provide a lightning fast experience\n Customise dashboard through a basic yaml file (no database needed)\n Wide range of link colors (or no color)\n Provide your own app icons for links\n Create groups of links\n Optionally secure the portal with user accounts\n Icon based theme\n Dark/Light mode\n Lightweight Docker image\n  \nShowcase Image\n https://preview.redd.it/0ysb9h1suo9a1.png?width=1280&format=png&auto=webp&s=5117e4935dd8c99f8fe0bcf987e2aff06e172196\n Links\n  \nRepository: https://github.com/enchant97/web-portal-lite\n Docs: https://enchantedcode.co.uk/web-portal-lite/\n  \nIf you wanted something with more features, I have a non-lite version called Web Portal, available here: https://github.com/enchant97/web-portal\n Feel free to write any comments for suggestions and queries. You can also reach me on the community servers/rooms:\n  \nhttps://discord.gg/avVQxbWAHg\n https://matrix.to/#/#enchanted-people:matrix.org\n  \n   submitted by    /u/enchant97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101mhbq/web_portal_lite_v11_fast_minimal_dashboard_app/",
          "publishedOn": "2023-01-02T20:18:58.000Z",
          "wordCount": 20646,
          "title": "Web Portal Lite V1.1 - Fast & minimal dashboard app",
          "imageUrl": "https://external-preview.redd.it/C_eRK7OqE8oi06yIrBb9N8_kjJkvYpA1Uo2pprVAorA.jpg?auto=webp&s=dd7e3e255c18e0d88d344063807dab91b84e5506"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101me4q/selfhosting_a_website/",
          "author": null,
          "description": "Are there any real benefits to self-hosting your own web-server on hardware or on a VPS besides just being \"independent\"? I'm planning to just have a simple blog website.\n    submitted by    /u/PrettyExpensiveCoat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101me4q/selfhosting_a_website/",
          "publishedOn": "2023-01-02T20:15:24.000Z",
          "wordCount": 21491,
          "title": "Self-hosting a website",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101lgga/duplicati_has_crossed_me_for_the_last_time/",
          "author": null,
          "description": "System:\n  \nSix core ryzen 5 with 64gb ram\n open media vault 6 (debian 11)\n boot and os on SSD\n databases on SSD\n configs and ~/torrent/incomplete on SSD (3 SSD total)\n zraid array with my media, backups, and ~/torrents/complete\n  \nI have a pi4 that's always on for another task; I'm going to be setting up syncthing to mirror the backup dir in my zraid.\n Duplicati has crossed me for the last time. Thus ,I'm looking for other options. I started looking into this a while back but injury recovery came up. I understand that there are many options however I'd love to hear from there community.\n I'm very comfortable with CLI and would be comfortable executing recovery options that way. I run the servers at my mom's and sisters houses, so I already do maintenance for them that way via Tailscale.\n I'm looking for open-source or free options, and my concerns orbit around two points:\n  \nbacking up container data: I'm looking at a way to fully automate the backup process of a) shutting down each app or app+database prior to backup, b) completing a backup, and c) restarting app(s).\n \nbacking up my system so that I if my boot/os SSD died I could flash another and off I go.\n \n Amy advice it opinions would be warmly recieved. Thank you.\n    submitted by    /u/cribbageSTARSHIP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101lgga/duplicati_has_crossed_me_for_the_last_time/",
          "publishedOn": "2023-01-02T19:38:42.000Z",
          "wordCount": 22097,
          "title": "duplicati has crossed me for the last time; looking for other recovery options to back up my system and docker containers (databases + configs)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101lc30/powertop_to_optimize_server_power_consumption/",
          "author": null,
          "description": "Did anyone use PowerTop on your home servers to optimize power consumption? Or any other software?\n Аny benefits of this?\n    submitted by    /u/Voklav  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101lc30/powertop_to_optimize_server_power_consumption/",
          "publishedOn": "2023-01-02T19:33:56.000Z",
          "wordCount": 20605,
          "title": "PowerTop to optimize server power consumption?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101kjmm/docker_networking_homelab_postgres/",
          "author": null,
          "description": "Fairly new to Docker and the whole homelab/self-hosted world. I'm a backend developer (Django) and always preferred to have my dev environments hosted on Ubuntu VMs using VirtualBox. Been resisting Docker for almost 4 years now, but I think it's about time I started this venture.\n One of the common practices when spinning up a new environment is to have both the DB and Django in one docker-compose file, and a docker file for Django. I find this tedious in a homelab environment and would prefer to have one Postgres server for all the local apps I work on.\n When I tried this, I was faced with the issue of my apps not able to connect to the centrally hosted Postgres server. Further experimentation revealed to me that it's because my containers are hosted on different networks. Took me about 2 days to notice that, but I'm enjoying the unravelling of the homelab \"mysteries\" so far.\n My question is how do you go about configuring such an environment? Do you usually host a separate DB server for each app or do you centralize your DB server? If I were to go with the latter, and without adding the complexities of VLANs for now (isolating the DB server, firewalls, etc), what is my best option to allow traffic in/out on port 5432 for my main Postgres server? Is it host networking?\n I know to some this might seem 101, but some guidance would be highly appreciated.\n    submitted by    /u/Hsaade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101kjmm/docker_networking_homelab_postgres/",
          "publishedOn": "2023-01-02T19:02:50.000Z",
          "wordCount": 21299,
          "title": "Docker networking / homelab -- Postgres",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101jolk/personal_time_tracking_how_i_spend_my_days/",
          "author": null,
          "description": "Is there any selfhosted app which allows me to track what I am doing during the day? Including the (approx) times/duration of them (and generate those awesome charts like a few post on r/dataisbeautiful).\n A simple spreadsheet on nextcloud would work ig, but if there's an app you recommend please tell me. It must have an android app or webapp.\n    submitted by    /u/robinschreddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101jolk/personal_time_tracking_how_i_spend_my_days/",
          "publishedOn": "2023-01-02T18:27:50.000Z",
          "wordCount": 20307,
          "title": "personal time tracking - how I spend my days",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101iyu4/anyone_know_of_a_selfhosted_version_of_board_game/",
          "author": null,
          "description": "I'm looking for a self-hosted alternative to the board game stats tracker app Board Game Stats.\n    submitted by    /u/orangetruth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101iyu4/anyone_know_of_a_selfhosted_version_of_board_game/",
          "publishedOn": "2023-01-02T17:59:46.000Z",
          "wordCount": 20550,
          "title": "Anyone know of a selfhosted version of Board Game Stats?",
          "imageUrl": "https://external-preview.redd.it/6MPrq-IxAmKHNJapjG0zG5mEfQs3EgPGappw1vOmp3A.jpg?auto=webp&s=dd3634fbd867d96a32b2186c96a0fd76559babdb"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101iv00/please_dont_laugh_at_my_newbieness/",
          "author": null,
          "description": "I have a small \"integrated\" transport activity. I looked on CodeCanyon for a Uber like solution, that would actually allow my customers to be able to see when their freight/packages arrive. Basically clients register and put order in, driver closest aknowledges that he can pick-up and deliver the freight/package, when pick-up scans the BOL ( Bill of Lading ) into the system, drives, delivers, scans signed BOL into the system ( maybe even scan directly the PDF on phone/tablet ). What I have seen in CodeCanyon is 2 or even 3 things combined, on separate systems (PHP/Firebase/Android), it will be costly to implement and not 100% sure it will work as intended.\n Seeing I work between 1-5 trucks at the moment, it does not make sense to me to invest too much into it ( 6% margin in transport in great economy ). I also have a NAS I can use to host ( WD MyCloud Home ), or cloud hosting available. And not really needed dedicated Android/IOS apps, as I understand PWA ( progressive web app ) might do the same function.\n What do you guys think? Am I crazy, or am I crazy?\n I am also not a programmer. I dabble in PHP installs, but that is about all ...\n Hit me like a rolling ball!\n    submitted by    /u/radujohn75  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101iv00/please_dont_laugh_at_my_newbieness/",
          "publishedOn": "2023-01-02T17:55:28.000Z",
          "wordCount": 20544,
          "title": "Please don't laugh at my newbieness 😁",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101i850/best_way_to_put_multiple_servers_behind_a_single/",
          "author": null,
          "description": "I have 3 different machines hosting different things:\n  \nServer #1 nginx reverse proxy, vaultwarden, gitea, etc.\n Server #2 jellyfin\n Server #3 adguard\n  \nI have a wildcard certificate for the reverse proxy and I don't want to have to distribute that certificate to every server. All the things on server #1 are easy to set up, just proxy_pass the appropriate port and you're good to go. The other servers are a little trickier. I could proxy_pass with their IP and port, however nothing is stopping a user from accessing IP:port of that server directly. I could use UFW to only allow traffic from the IP of the reverse proxy, but with ARP spoofing I can sit between the proxy and the server and see all the unencrypted traffic. \n I've never used VLANs, I don't own a switch or a router which allows for them, and I'm not entirely sure what features they provide but I've seen them used to isolate local networks. Would using VLANs be the right way to solve this issue?\n    submitted by    /u/TheStormsFury  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101i850/best_way_to_put_multiple_servers_behind_a_single/",
          "publishedOn": "2023-01-02T17:30:12.000Z",
          "wordCount": 21574,
          "title": "Best way to put multiple servers behind a single reverse proxy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101hudl/backing_up_media_filesis_kopia_appropriate/",
          "author": null,
          "description": "I've been using rsync to mirror media drives (primarily media files) for manual backups for years. It's straightforward but it's lacking:\n  \nRenaming is treated as a whole different file, so renaming files make backing up extremely inefficient.\n \nI use a wrapper script to keep a list of rsync logs as well as list of files on the drive after the last backup. Actually, I create a empty placeholder files on my filesystem and use fsearch to quickly search all files on the system including these placeholder files to quickly find if I have an existing file of that name.\n \n I know there are some rsync-based wrappers that might handle the filename change limitation, but I'm wondering if a dedicated backup software like Restic/Kopia/Borg is appropriate. I'm particularly interested in Kopia as it seems to be performant and modern in design (I know Borg is tried and true but it's been 7 years since multithreading was requested but it's still not supported).\n Are features like builtin encryption (previously I have e.g. ext4 on LUKS), deduplication, and snapshoting particularly important for large media files? None of these seem too relevant given I don't change the media files often, just add and delete (though it would be nice to be able to use such files on e.g. text files). More importantly, does the usage require you to be more involved? Nothing beats a single backup (rsync) command and also being able to access the files directly on the filesystem, viewing the contents like any other file. I believe you can mount the filesystems on such software, but on Youtube, everyone seems to always highlight the fact that you can list the files and open them with none showing that you can mount it as a filesystem, which seems to be way more intuitive and useful. \n Much appreciated. I plan on moving the external HDDs to the Pi and backing up to it to remove clutter from my workspace.\n    submitted by    /u/seductivec0w  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101hudl/backing_up_media_filesis_kopia_appropriate/",
          "publishedOn": "2023-01-02T17:15:03.000Z",
          "wordCount": 22206,
          "title": "Backing up media files--is Kopia appropriate?",
          "imageUrl": "https://external-preview.redd.it/msIirkMr39DrlbRMgpCENxK__6XBVtGiFLw_CRLZs3Q.jpg?auto=webp&s=e0d9ee26f3aa7e0797dc3506407ebfa92995d8d4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101hm04/supporting_projects/",
          "author": null,
          "description": "FOSS is what fuels this community, and most of us here (me included) are \"consumers\" of these great projects, and contributing is somewhat hard.\n I wonder if the projects that we share here would use a platform like https://bookmytime.dev/, would we all see this as beneficial?\n I'm mainly posting this so that the community as well as those contributing to it with their awesome projects will know that this option exists, and that I personally think, given the opportunity - something like this would go a long way.\n Heck, even allowing teams of people to chip in to pay for a developer's time to fix some issue that as a community we would like to see fixed.\n Hope projects here adopt this model (don't care if they use this particular framework, but I do like the model).\n    submitted by    /u/LifeLocksmith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101hm04/supporting_projects/",
          "publishedOn": "2023-01-02T17:05:41.000Z",
          "wordCount": 20836,
          "title": "Supporting projects",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101dzs6/how_does_everyone_organise_their_mounts_for/",
          "author": null,
          "description": "It seems like I have three common volumes mounted onto my raid. I have all the container configs in one location, all the databases in another, and then all shared media in the third (movies, tv, music, etc).\n I'm thinking the other way would be to have my media in one share (and that's the only forward facing share for normies), then I could put configs and databases in one dir by container name.\n I was thinking about moving my databases onto an SSD as well.\n What are you guys doing? I want to have the most subscriber system possible. Also want to make duplicati backups to be more straight forward\n    submitted by    /u/cribbageSTARSHIP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101dzs6/how_does_everyone_organise_their_mounts_for/",
          "publishedOn": "2023-01-02T14:32:52.000Z",
          "wordCount": 22682,
          "title": "how does everyone organise their mounts for docker; configs/databases/media",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101dtqq/looking_for_a_pantry_recipe_grocery_app/",
          "author": null,
          "description": "I'm looking for a pantry / grocery / recipe app capable of: - barcode scanning (phone camera) - barcode lookup against publicly available databases to add (& subtract) products from Inventory - import recipe (web scraping) - meal planning - add meal plan ingredients to shopping list - integration with Google home assistant to add groceries outside of meal plan - mobile app\n Are you aware of an app who has it all? Anything that comes close? Or a combination of apps that can hopefully be connected somehow?\n Selfhosted is prefered but not required for me\n    submitted by    /u/wokkieman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101dtqq/looking_for_a_pantry_recipe_grocery_app/",
          "publishedOn": "2023-01-02T14:25:39.000Z",
          "wordCount": 22775,
          "title": "looking for a pantry / recipe / grocery app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101csgm/isp_dont_provide_public_ip_anymore_how_to_access/",
          "author": null,
          "description": "My previous setup is port forwarding a wireguard server to tunnel into my home network, this works because ISP assigns a dynamic public address. Now the ISP doesn't do that anymore, the public IP the router uses is not the actual internet facing IP. There is another router at the ISP level. What do I do?\n    submitted by    /u/jarvis-linx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101csgm/isp_dont_provide_public_ip_anymore_how_to_access/",
          "publishedOn": "2023-01-02T13:36:28.000Z",
          "wordCount": 23757,
          "title": "ISP dont provide public IP anymore, how to access home LAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/101a2zm/placement_of_servers_selfhosted_services_in_vlan/",
          "author": null,
          "description": "submitted by    /u/norsemanGrey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/101a2zm/placement_of_servers_selfhosted_services_in_vlan/",
          "publishedOn": "2023-01-02T11:08:07.000Z",
          "wordCount": 20928,
          "title": "Placement of Servers / Self-Hosted Services in vLAN Network",
          "imageUrl": "https://external-preview.redd.it/wQr1r19mHnfb91f4bn8ktZEm8vQUG7wLBrvGo0yKydc.png?auto=webp&s=442e4082c4bdbf35b1f103b98ebe80216779b519"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10175n5/new_release_rei32_selfhosted_low_code/",
          "author": null,
          "description": "Hello everyone,\n I am a contributor to REI3, a selfhosted low code platform. Its an open source alternative to tools like Ninox, Retool, Mendix and the like.\n Our latest major release just dropped - some highlights:\n  \nMulti factor authentication\n Major redesign of the application builder user interfaces\n Better form layouts with tabbed fields\n Integrated backups for all types of hosting/systems\n  \nWe´ve been hard at work processing feedback and expanding the capabilities of what you can build with REI3.\n For those new to low code: The idea is that you can create your own custom software without the need for programming. You can create user interfaces, store data, send and process mails, and so on.\n We hope you like the new update.\n    submitted by    /u/NetrasFent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10175n5/new_release_rei32_selfhosted_low_code/",
          "publishedOn": "2023-01-02T08:05:11.000Z",
          "wordCount": 22176,
          "title": "New release: REI3.2 - Selfhosted low code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1013ya6/i_want_to_start_my_own_server_but_cant_figure_out/",
          "author": null,
          "description": "I've been looking and learning about self hosting, and can't figure out if my best option is to build a dyi server or buy a NAS. I'm a video editor so I will be needing a lot of storage, but I will also want to run some apps on the server(personal website, some bots, bitwarden and home assistant in the future). \n I also been having some problems picking parts for a possible dyi, cause I don't want sometime that will consume much electricity.\n Edit: I just want to say that I don't plan to edit on my server, since most of you are taking that into consideration.\n    submitted by    /u/ItzRaphZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1013ya6/i_want_to_start_my_own_server_but_cant_figure_out/",
          "publishedOn": "2023-01-02T05:05:26.000Z",
          "wordCount": 24675,
          "title": "I want to start my own server, but can't figure out the best solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100xrqg/paperless_ngx_ocr_and_amazon_s3/",
          "author": null,
          "description": "Is there any documentation on Paperless having OCR or integration with Amazon S3? I just found out about Paperless today- and it may be exactly what I need.\n Edit, found it uses Tesseract, so yes, OCR.\n    submitted by    /u/ericksonPM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100xrqg/paperless_ngx_ocr_and_amazon_s3/",
          "publishedOn": "2023-01-02T00:09:01.000Z",
          "wordCount": 20642,
          "title": "Paperless NGX: OCR and Amazon S3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100vehr/where_to_start/",
          "author": null,
          "description": "I really want to get into self hosting but I’m not entirely sure where to start. I’m very tech savvy and do dabble in home-labbing. My primary reason why I want to start is to save money. Here are some things I’m looking for: \n  \n Microsoft Office alternative (with up to 5 users), similar to what I have with O365 Family - I was thinking of OnlyOffice?\n  Cloud Storage: to get away from Google Drive\n  Possible separate photo storage: I like the iPhone photos app how it organizes by people/place. Are there any tools like that?\n  \nI currently have a Raspberry Pi 3 that I’m using to host Home Assistant. I think in order for me to do what I want, I’d need something beefier than that. So am I better off keeping the PI for Home Assistant and hosting everything with like GCP, Digital Ocean, or Linode? \n Thanks in advance for your advice/suggestions!\n    submitted by    /u/mr_techy616  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100vehr/where_to_start/",
          "publishedOn": "2023-01-01T22:27:25.000Z",
          "wordCount": 22362,
          "title": "Where to start?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100vdru/stepping_up_my_selfhosted_game/",
          "author": null,
          "description": "Hi there,\n over the last two-three years I just used duckdns + nginx proxy manager(npm) to expose the Nextcloud and Home Assistant instances on my home server for me and my family. To access all the other services I just used a wireguard connection back home whenever needed.\n Than a good friend asked if he could have access to my audiobookshelf(abs) and I opened up that too. After that more services got exposed for other friends too. (Till I hit the duckdns limit) So I decided to separate things again, and got a oracle free tier VPS and bought an domain last week. \n On the VPS I installed npm and opened up the ports it needed to work. And here comes the first question. What's the best practice to deal with the port for the UI? Right now I block the port and whenever something needs to be done on the UI I open up the port in Oracle. So the connection to the UI during the changes is always unsecure. Maybe there are even better ways than using npm?\n After that I spinned up the docker container and added the subdomains for them to cloudflare. Where my second question evolved. When proxying traffic through cloudflare I am using their bandwidth are there any limitations regarding traffic? Would it be better to disable the proxy and just use it as a DNS? Now regarding SSL. I set the SSL to \"Full (strict)\" got one *.mydomain.xyz let's encrypt certificate with a DNS challenge in npm. But somehow the cloudflare certificate is being used instead the let's encrypt one. And assigned the wildcard cert to the proxies in npm. Everything works but I am not sure if it the correct way to set it up.\n So the public facing apps are now on oracle servers and I am now only my family is using my server back home.\n Any suggestions to improve things to be more secure? Maybe other suggestions too.\n Thanks for your time\n Cheers\n    submitted by    /u/haeth189  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100vdru/stepping_up_my_selfhosted_game/",
          "publishedOn": "2023-01-01T22:26:32.000Z",
          "wordCount": 22976,
          "title": "\"Stepping up\" my selfhosted game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100shrq/i_cant_access_docker_containers_over_lan/",
          "author": null,
          "description": "Hi all, I just started my journey with homelab, and unfortunately I have been unable to solve the problem with access to the Docker containers over the LAN. Every time I try to ping the hostIP:DockerContainerPort using my PC the results is the same - timeout error. However, when I tried the same thing, but on the host machine itself, I received a status of 200 (OK). Why I'm unable to reach the docker containers from other devices? Any idea what I'm doing wrong?\n Here is example docker-compose.yml:\n version: \"3.3\" services: homepage: image: ghcr.io/benphelps/homepage:latest container_name: homepage ports: - 3000:3000 volumes: - /opt/homepage-dashboard/config:/app/config # Make sure your local config directory exists - /var/run/docker.sock:/var/run/docker.sock # (optional) For docker integrations \n docker ps:\n CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES x nginx \"/docker-entrypoint.…\" 2 hours ago Up 2 hours 0.0.0.0:8080->80/tcp some-nginx x ghcr.io/benphelps/homepage:latest \"docker-entrypoint.s…\" 3 hours ago Up 3 hours (healthy) 0.0.0.0:3000->3000/tcp homepage \n ​\n    submitted by    /u/SadorusZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100shrq/i_cant_access_docker_containers_over_lan/",
          "publishedOn": "2023-01-01T20:25:10.000Z",
          "wordCount": 20216,
          "title": "I can't access docker containers over LAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100qnuu/what_hardware_equipment_should_i_have_for_a_local/",
          "author": null,
          "description": "Hey,\n I have a pc + router + external HDD, I want to setup my external HDD as a network drive. Is there any hardware requirements for this?\n How can I setup it as network drive?\n    submitted by    /u/ArgyleDiamonds  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100qnuu/what_hardware_equipment_should_i_have_for_a_local/",
          "publishedOn": "2023-01-01T19:06:41.000Z",
          "wordCount": 20025,
          "title": "What hardware equipment should I have for a local network drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100pf36/options_for_remote_backup_to_cloud_with/",
          "author": null,
          "description": "Hi All, \n Please share with me some ideas on how to tackle this.\n I woud like to auto-upload Blueiris JPEGs to Mega as they are being created. I would also like to monitor the space available and delete the oldest so that I can stay under my 20GB max.\n Requirements:\n  \nUpload JPEGs in real-time (5 second delay max)\n Be aware of max storage cap and auto-delete the oldest\n Encrypt on the fly\n \nI'm not married to Mega so I'm happy to use other options with 15+ GB of free storage \n No Google Drive \n Protocol/platform is flexible (SFTP and Object Storage is fine too)\n \n Host machine is capped at 10GB while remote will have 20GB, so host machine will delete oldest before remote\n  \n​\n I know that I can do this with Rclone with some scripting, but I wanted to know if there was other better options. Ex: Restic? duplicity? borg? Rsync? I haven't used these myself. Thank you for your help!\n    submitted by    /u/anebulam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100pf36/options_for_remote_backup_to_cloud_with/",
          "publishedOn": "2023-01-01T18:12:21.000Z",
          "wordCount": 20901,
          "title": "Options for remote backup to cloud with delete-the-oldest to stay under storage cap",
          "imageUrl": "https://external-preview.redd.it/sJ0y7m0qj29VGLYWMWnmEYBfzO8qLhnSPqQrPqDN6f4.jpg?auto=webp&s=ff22ff8c7822c75d80940107544f03ca9f0fe6db"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100nvmc/securely_ingressing_into_bare_metal_kubernetes/",
          "author": null,
          "description": "submitted by    /u/mmontes11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100nvmc/securely_ingressing_into_bare_metal_kubernetes/",
          "publishedOn": "2023-01-01T17:03:29.000Z",
          "wordCount": 19855,
          "title": "Securely Ingressing into Bare Metal Kubernetes Clusters with Traefik and Gateway API ☸️🔌🔒",
          "imageUrl": "https://external-preview.redd.it/Sqjb1sZhAaVfkNF3sod6EAOEt43HOcXtzALm7NXR4YM.jpg?auto=webp&s=678854098b3b58f00b98da373c97f50e73201517"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100mryj/answer_the_self_hosted_qa_community_portal_review/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100mryj/answer_the_self_hosted_qa_community_portal_review/",
          "publishedOn": "2023-01-01T16:11:02.000Z",
          "wordCount": 22084,
          "title": "Answer - The Self Hosted Q&A Community Portal - Review",
          "imageUrl": "https://external-preview.redd.it/697IHfqdQ6kmpTdOqb0oIHjPeuezo9jSAdEdWiYLpyE.jpg?auto=webp&s=998bf3fdbc25ac4eec420aa8f1e09bb22515a367"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100lvas/logto_oss_auth_identity_new_year_release_web_hook/",
          "author": null,
          "description": "submitted by    /u/Formal_Tree2535  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100lvas/logto_oss_auth_identity_new_year_release_web_hook/",
          "publishedOn": "2023-01-01T15:26:41.000Z",
          "wordCount": 20573,
          "title": "Logto (OSS auth & identity) New Year Release: Web hook, advanced search API, OAuth and OIDC connectors",
          "imageUrl": "https://external-preview.redd.it/4cocCHbvtY8sHghNOgogzHkEm3Yd6MVie1Jk8rg5pkI.jpg?auto=webp&s=1cc84112bfa0d6f1198d5ab645c5a2e775007755"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100kwbm/looking_for_selfhosted_music_and_ebook_servers/",
          "author": null,
          "description": "I've browsed this subreddit and others quite a bit on this topic, but I'm in search of a few specific things and it's pretty time-consuming trying out different options, I'm hoping someone with experience can help. I've been running both my music and ebook libraries from my desktop and I'd like to move them to my home server.\n Music: currently I'm running MediaMonkey on my desktop, adding specific songs to a \"Phone\" playlist to sync with my Android via MediaMonkey's app. This works okay but it'd be nice to be able to access my large library remotely when I'm on wifi and not be reliant on sitting at my desktop for adding new songs to my phone.\n Features: \n  \nable to stream library from my local desktop \n able to download select songs/albums/artists to my Android for playing remotely without data\n also be able to stream songs to my Android when on wifi (remotely)\n 95% of my music listening is from my phone with no data available, and my full library is enormous - so it'd be nice if most of the time only the downloaded songs are shown so that I don't need to sift through the rest of my unavailable library \n  \nA Jellyfin server + S2 android app seems like a good option here - but I haven't had a chance to test this combo out yet.\n Books: currently I have Calibre on my desktop and upload books to BookFusion for reading via Android and web. BookFusion is great but I'd like something selfhosted and not limited to X books in my library. \n Features: \n  \naccessible via Android app, which allows downloading for reading offline\n accessible via web \n syncs/remembers progress between platforms\n allows annotations (highlighting and notes) with the ability to export them \n  \nIf I can't find something selfhosted I'll probably switch to Google Play Books.\n Thanks for any help you can provide - and thanks for all the help this subreddit has already given, it's been a great resource as I've built up my home server.\n    submitted by    /u/cbrian13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100kwbm/looking_for_selfhosted_music_and_ebook_servers/",
          "publishedOn": "2023-01-01T14:35:05.000Z",
          "wordCount": 21561,
          "title": "Looking for self-hosted music and ebook servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100k60u/jellyfinradarrjackettsonarr_eating_up_all_the_ram/",
          "author": null,
          "description": "Hi everyone \n I've been running my own media stack, at first in an LXC, but after a mishap with kernel update on the host machine and data being corrupted I've decided to migrate all of it into a VM\n And now I'm seeing massive usage in terms of ram, basically it'll eat up everything no matter what I'll throw at it.\n I've gathered some initial investigation data here: https://docs.google.com/document/d/1juwCpedw5cn2c_2mA944Lt6hfw3uF6Dp7bAWR5Dpl30/edit?usp=sharing\n I'll be updating the docs as we go, but I'll really appreciate some help here as now it results in jellyfin running like shit unfortunately :/\n    submitted by    /u/wbrydak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100k60u/jellyfinradarrjackettsonarr_eating_up_all_the_ram/",
          "publishedOn": "2023-01-01T13:54:02.000Z",
          "wordCount": 21065,
          "title": "jellyfin+radarr+jackett+sonarr eating up all the ram - memleak or something else?",
          "imageUrl": "https://external-preview.redd.it/FwkIZd9gxmd1SlLloUBv8cijBJ5mb-4o8wzQhXmYwus.jpg?auto=webp&s=4c4ac9a04af85b9e3fc3731386bc6d9da2acd54c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100jwfe/pbsexporter_script_for_uploading_pbs_api_info_to/",
          "author": null,
          "description": "submitted by    /u/rare-magma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100jwfe/pbsexporter_script_for_uploading_pbs_api_info_to/",
          "publishedOn": "2023-01-01T13:39:23.000Z",
          "wordCount": 21236,
          "title": "pbs-exporter: script for uploading PBS API info to prometheus's pushgateway.",
          "imageUrl": "https://external-preview.redd.it/RKxn2wvm_xsS3Cgq90WkpG2megVg1VooLlAxSS_f0hU.jpg?auto=webp&s=91533cff4d27856972342f43be219b7d59d6fffd"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100jn07/ldap_vs_oauth2_and_others/",
          "author": null,
          "description": "I've been seeing a lot of posts lately about OAuth providers like Authentik and Authelia. I decided to try out Authentik (using Windows AD as the backend) and I've been really impressed with it so far. \n However, I've been having a bit of an issue. I can't seem to figure out how to pass group information to the application through OAuth. Some applications don't support LDAP, so it's not an option for me to use it to get permissions through groups. I'm trying to decide whether I should use LDAP as much as possible to get permissions through groups, or if I should consider every user a regular user and use application-specific local admin accounts. \n Any advice on this would be appreciated. Thanks!\n    submitted by    /u/Evolvz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100jn07/ldap_vs_oauth2_and_others/",
          "publishedOn": "2023-01-01T13:25:12.000Z",
          "wordCount": 21155,
          "title": "Ldap vs oauth2 and others",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100jlzd/help_google_flagged_my_vaultwarden_for_phishing/",
          "author": null,
          "description": "submitted by    /u/root0777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100jlzd/help_google_flagged_my_vaultwarden_for_phishing/",
          "publishedOn": "2023-01-01T13:23:40.000Z",
          "wordCount": 22224,
          "title": "Help, Google flagged my vaultwarden for phishing",
          "imageUrl": "https://preview.redd.it/cgoi48lc5h9a1.png?auto=webp&s=f2f880404e9024e0b3335d40e9add8a16856e799"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100hrne/how_do_you_monitor_your_incoming_traffic_of/",
          "author": null,
          "description": "I got lots of valuable input regarding exposing some of my services here and i am experimenting with some of the approaches now.\n One of the things i want to set up is proper monitoring. All my services are behind a Traefik Reverse Proxy. I would like to avoid going through the access log every now and then and manually check it and instead have some kind of dashboard. The following metrics are something i would be interested in:\n  \nCrowdSec/Fail2ban metrics (number of blocked requests / banned IPs, ...)\n Number of requests grouped by return code, endpoint , ...\n IP geolocations\n ...\n  \nI was thinking about the ELK stack, however it seems to be quite heavy for a small homeserver. As far as i am aware a slightly more lightweight solution would be Promtail + Loki + Grafana. However i couldn't really find a lot of information/guides on how to use this stack in combination with Traefik/Fail2ban/CrowdSec to setup a monitoring dashboard.\n Another project i've found is GoAccess, which ticks many of the boxes, but i'm not quite sure how to integrate CrowdSec and Fail2ban metrics (or if it's possible at all).\n Whats your setup when it comes to monitoring your exposed services and trying to detect the worst case of an successful attack?\n    submitted by    /u/Torrew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100hrne/how_do_you_monitor_your_incoming_traffic_of/",
          "publishedOn": "2023-01-01T11:28:11.000Z",
          "wordCount": 21135,
          "title": "How do you monitor your incoming traffic (of exposed services) ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100ggn1/can_i_use_an_existing_nextcloud_folder_with/",
          "author": null,
          "description": "When I connected librephotos with nextcloud it just synced the whole file system and now I've got a duplicate database. Can I just point librephotos to the same folder?\n (which would be a nice live backup at another location but that's not how my servers work :D)\n    submitted by    /u/biberflann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100ggn1/can_i_use_an_existing_nextcloud_folder_with/",
          "publishedOn": "2023-01-01T09:52:35.000Z",
          "wordCount": 20529,
          "title": "Can I use an existing nextcloud folder with librephotos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100g8j8/cast_youtube_audio_to_dlna_renderers/",
          "author": null,
          "description": "I've written something to scratch a personal itch, and it might perhaps be useful to others since there doesn't seem to be anything else available to do it.\n It allows you to cast audio from the YouTube app on Android (and I presume iOS too) to a DLNA renderer (wifi speaker, streaming receiver etc.).\n You run it on any device on your network and each renderer you have will show up in the Cast menu in the app.\n Pause, play, stop and volume controls in the app are mapped through to the renderer. (Seek doesn't work. Maybe I'll fix it one day.)\n It's pretty basic but I find it very useful. I hope others may get some use out of it - let me know if you do, and/or if you hit problems. It hasn't had a great deal of long-term testing - at the moment I just run it up (on Ubuntu 22.04) when I need it. It's also the first real thing I've written in Javascript so there could well be rookie mistakes.\n It's called upnpTube.\n    submitted by    /u/Spanky_Pantry  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100g8j8/cast_youtube_audio_to_dlna_renderers/",
          "publishedOn": "2023-01-01T09:35:19.000Z",
          "wordCount": 23516,
          "title": "Cast YouTube audio to dlna renderers",
          "imageUrl": "https://external-preview.redd.it/mS3o3zDxu4wk3WIuRs31ieAH5yGLJCbSQJLDvUJs8_I.jpg?auto=webp&s=56d4d6121f066f2cfdc95d45ffb0ffcba48c4c9d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100g899/why_does_immich_create_a_new_file_structure/",
          "author": null,
          "description": "Wouldn't it make much more sense to use an existing structure? With an existing structure I could just work on the images and save them on my computer and it would update them in immich but currently you would need to export them from immich, delete them in immich and reupload them to immich.\n    submitted by    /u/biberflann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100g899/why_does_immich_create_a_new_file_structure/",
          "publishedOn": "2023-01-01T09:34:46.000Z",
          "wordCount": 21995,
          "title": "Why does immich create a new file structure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100fb4s/i_built_haystack_selfhosted_google_for_workplace/",
          "author": null,
          "description": "I built haystack - natural language search engine for workplace technical knowledge.\n My name is Yuval I've been a software engineer for a few years now,\n A few weeks ago I was scrolling through confluence pages trying to find ssh connection details to our jenkins second integration machine for 40 minutes straight, later I discovered my co-worker slack'ed me the ssh connection string two months ago.\n A week later I started working on haystack - a search engine for workplace apps.. It enables you to search slack, confluence, jira, teams, jfrog, github, and email in one place.\n It supports natural language queries so a query like: \"how to connect to integ2 machine?\" yields:\n ssh -i private.pem ubuntu@ec2-integration2.eu-est-1.compute.amazonaws.com \n Privacy?\n haystack is self hosted and stores user data locally, and is totally client-side - only you have access to internal docs, I didn't want to deal with security compliance headaches caused from storing user data in the cloud + I don’t want your internal docs/messages.\n Rolled it out to my co-workers a week ago and they thought it's a hit, so I'm planning on releasing it publicly on March 2023.\n Early access\n If you want to try it out before March 2023 - Available here\n    submitted by    /u/yuvalsteuer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100fb4s/i_built_haystack_selfhosted_google_for_workplace/",
          "publishedOn": "2023-01-01T08:28:01.000Z",
          "wordCount": 23805,
          "title": "I built haystack - self-hosted google for workplace knowledge",
          "imageUrl": "https://external-preview.redd.it/-doAFuGgfDN0zDiSVzqZLMAoRlHvvjSQFBWfRjUQEQE.jpg?auto=webp&s=1a977a681caa5e7cdfe41ba39b4b0bd9712a6031"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100e7dp/e_reader_kavita_dictionary_support/",
          "author": null,
          "description": "Do the Kavita App support Dictionary or does it have plugin to add a pop up dictionary support to it?\n    submitted by    /u/aarshmajmudar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100e7dp/e_reader_kavita_dictionary_support/",
          "publishedOn": "2023-01-01T07:09:37.000Z",
          "wordCount": 20434,
          "title": "e Reader - Kavita (Dictionary Support)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100e3he/how_long_does_it_take_truesnas_installed_on/",
          "author": null,
          "description": "submitted by    /u/JuggernOtt81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100e3he/how_long_does_it_take_truesnas_installed_on/",
          "publishedOn": "2023-01-01T07:02:09.000Z",
          "wordCount": 22207,
          "title": "how long does it take? truesnas installed on proxmox 6 cores 32GB ram passthrough 4x4TB HDDs - is it stuck? or just a super long process? (first boot after install)",
          "imageUrl": "https://preview.redd.it/xfxr3va9rd9a1.png?auto=webp&s=3af70e2800f1595b2be87814e84e7de6217fc463"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/100dd53/paperlessngx_match_based_on_file_name_or_title/",
          "author": null,
          "description": "I am learning how to use Paperless-ngx and it looks like there is no way to setup an automatic match based on the file name or title? Only the content of the PDF?\n    submitted by    /u/slyfoxreddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/100dd53/paperlessngx_match_based_on_file_name_or_title/",
          "publishedOn": "2023-01-01T06:12:13.000Z",
          "wordCount": 20427,
          "title": "Paperless-ngx - Match Based on File Name or Title?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1006526/ktoys_alternative_vps_hosting_dedicated_server/",
          "author": null,
          "description": "Hello,\n ​\n I stumbled across https://github.com/KuJoe/KToYS and thought it would be good to help track different VPS etc, but it's not been updated in 7 years. Could you let me know if there are any alternatives?\n ​\n I have run https://github.com/domainmod/domainmod in the past which was perfect for domains, just a shame it doesn't have a section for VPS / hosting accounts.\n ​\n Thanks,\n Zachary\n    submitted by    /u/r_hcaz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1006526/ktoys_alternative_vps_hosting_dedicated_server/",
          "publishedOn": "2022-12-31T23:08:49.000Z",
          "wordCount": 20043,
          "title": "KToYS alternative? (VPS, Hosting, Dedicated server tracker)",
          "imageUrl": "https://external-preview.redd.it/Fv3JaHJCTo8-3u1Mjy9slJhvRpe4_lYNtjLcMnfLzIU.jpg?auto=webp&s=06dc5a8607d60f6f6ab9627b82ca91baebff6b9f"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10063x6/container_updating_strategies/",
          "author": null,
          "description": "Okay; so, what are you guys doing to update your containers? \n  \nAre you manually updating the containers? \n Have you got a CRON job running and scripting the redeployment of a new image? \n Do you have a tool taking care of this?\n Do you have a set of containers you manually update, and others you auto update?\n  \nRight now, I manually update containers as I see fit (or when I can be bothered), however, I'm going to spend some time automating this over the next few days and wanted to get a feel for what others are doing.\n View Poll\n    submitted by    /u/Master-Variety3841  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10063x6/container_updating_strategies/",
          "publishedOn": "2022-12-31T23:07:06.000Z",
          "wordCount": 20782,
          "title": "Container Updating Strategies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1004dtx/ai_question/",
          "author": null,
          "description": "has anyone combined something like https://github.com/robgon-art/InventorBot with user specification via a builtin chatbot based input window/panel thats selfhosted?\n    submitted by    /u/565gta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1004dtx/ai_question/",
          "publishedOn": "2022-12-31T21:40:23.000Z",
          "wordCount": 20736,
          "title": "ai question",
          "imageUrl": "https://external-preview.redd.it/0ySff3GQeKLkL7VYmEQgCePvlohb3iFg_2y0ZpoVFUQ.jpg?auto=webp&s=d87fd0b3f5a5910de219ef98cfe294f5230859e9"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/10030cp/trouble_with_proxy_for_game_server_awssslh/",
          "author": null,
          "description": "I'm trying to follow this guide to better protect my network while running some game servers on my Dell T440 for our Discord server. \n Guide: https://www.howtogeek.com/440752/protect-your-home-minecraft-server-from-ddos-attacks-with-aws/\n I've gotten most of the way through without issue until it comes to configuring SSLH. Not only is the config file not in the location as stated in the guide it seems to be missing quite a few lines towards the end of the file. \n I found a thread where someone else had the same issue, but the fix in this thread doesn't work for me either. https://forum.level1techs.com/t/configure-sslh/151892/13 \n Both the guide and thread could be outdated, or I could still just be screwing it up, but I'm unsure of what to try next. \n I have set the AWS port forward settings as \"Inbound, custom UDP, Range: 16261-16262, Source 0.0.0.0/0. (Note: For some reason when I added the port rules for the game it blocked me out of SSH until I added another rule to allow my home IP to connect via port 22. Idk if I did something wrong here as well.)\n Should I keep at this method or is there a better way? Thanks in advance!\n ​\n (Server: Dell T440, Proxmox VE, VM: LinuxGSM.)\n (Note: The game server is working just using my public IP)\n    submitted by    /u/DotJata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/10030cp/trouble_with_proxy_for_game_server_awssslh/",
          "publishedOn": "2022-12-31T20:33:58.000Z",
          "wordCount": 22902,
          "title": "Trouble with proxy for game server (AWS/SSLH)",
          "imageUrl": "https://external-preview.redd.it/q2um0whGk9w4pPqKQH6y2uXz8HDlPNYhPl70nDfT0XE.jpg?auto=webp&s=c37cb422d50decf2a7c6d9c9ec5f3789d68d2692"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/1001vb1/how_to_disable_access_to_my_service_via_ipport/",
          "author": null,
          "description": "happy new year guys \n I am new to networking so i need some advice currently i have a vps in which has tailscale vpn and is in locked down state by following this guide, thus i can ssh only when i am connected to vpn but if i host uptimekuma using docker i am able to access it via vpsip:port combo (ex 10.10.10.10:999) is there any way for me to block this from happening, apart from this i also want cloudflare tunnel to tunnel my uptimekuma instance to my subdomain which will be public is this doable??\n Note- both cloudflared and tailsale are installed in baremetal\n my current ufw status is \n ``` Status: active Logging: on (low) Default: deny (incoming), allow (outgoing), deny (routed) New profiles: skip\n To Action From\n  \nAnywhere on tailscale0 ALLOW IN Anywhere\n Anywhere (v6) on tailscale0 ALLOW IN Anywhere (v6)\n ``` What i have tried so far \n 1- tried blocking all outgoing connection (this results in me unable t login to vps even after connecting to vpn had to manually deny it using hoster's web console )\n 2- tried to host cloudflared and uptime kuma in same network but this also not works described in this post\n Am currently lost\n    submitted by    /u/DadOfLucifer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/1001vb1/how_to_disable_access_to_my_service_via_ipport/",
          "publishedOn": "2022-12-31T19:39:10.000Z",
          "wordCount": 21539,
          "title": "How to disable access to my service via ip:port combo",
          "imageUrl": "https://external-preview.redd.it/Ssi9-rid5q7xGFCN14pVfBNoJ21mwxgsCRQLdmGD3dA.jpg?auto=webp&s=a0b8114216605dd0b3a3bbf4f848eefbd0cad8b2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzzpld/how_to_install_openwrt_wireguard_docker_on_a_x86/",
          "author": null,
          "description": "submitted by    /u/TorGuardVPN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzzpld/how_to_install_openwrt_wireguard_docker_on_a_x86/",
          "publishedOn": "2022-12-31T17:57:28.000Z",
          "wordCount": 20733,
          "title": "How to Install OpenWRT, WireGuard & Docker on a x86 PC",
          "imageUrl": "https://external-preview.redd.it/1qmlRr-9YIw9YTxz9NQW4s336w97hgjOHuPQxqedw0Y.jpg?auto=webp&s=21b8d0ef39778a475c5bd7a5085d018432ee1380"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzyabr/nginx_proxy_manager_local_vs_external_access/",
          "author": null,
          "description": "I have been using npm mostly due to its ease of use and integration with lets encrypt, and it’s been working quite well!\n I have a wildcard cert with duckdns and using (quite easy to guess) subdomains for the different services. Recently I set up home assistant Alexa integration which required a port forward to the npm. To lock the internal services I used access list and get a nice 403 forbidden .\n is this good enough? Should I setup a new instance of npm to handle local vs external request and port forward 443 from router only to the external ? Any cleaner approaches?\n    submitted by    /u/dky1e  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzyabr/nginx_proxy_manager_local_vs_external_access/",
          "publishedOn": "2022-12-31T16:52:07.000Z",
          "wordCount": 22545,
          "title": "Nginx proxy manager - local vs external access",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzxoss/paperlessng_to_ngx/",
          "author": null,
          "description": "Just migrated from Paperless-ng to -ngx on my RPi4 and wanted to say how smoothly it all went. It really was as simple as changing one line in the docker compose file. \n I'd been running -ng 1.5 but felt it time to change to the -ngx fork just to be current. After reading a few posts here I was expecting perhaps a problem or two but thankfully everything just went as documented, without any hiccups.\n So thanks to the -ngx team and long may Paperless-ngx continue\n    submitted by    /u/lostlogik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzxoss/paperlessng_to_ngx/",
          "publishedOn": "2022-12-31T16:24:40.000Z",
          "wordCount": 21000,
          "title": "Paperless-ng to -ngx",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzvu06/is_this_normal_usage_for_proxmox/",
          "author": null,
          "description": "So I just got my system up and running on Proxmox tonight. Love the interface and overall experience. But I have just two VMs running but so much of the system memory is being used outside of those VM allocations. \n Just curious to see if I missed something or potentially did something wrong.\n Thanks in advance :)\n    submitted by    /u/YourAverageVillager  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzvu06/is_this_normal_usage_for_proxmox/",
          "publishedOn": "2022-12-31T14:57:17.000Z",
          "wordCount": 19995,
          "title": "Is this normal usage for Proxmox ?",
          "imageUrl": "https://preview.redd.it/2abwh3z4ha9a1.jpg?auto=webp&s=e8d892a557ca4680864cba6a0ac86698a1c13c01"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzvewx/cant_open_the_syncthing_gui_of_a_remote_server/",
          "author": null,
          "description": "I have a fedora server, a windows laptop and an android smartphone\n I installed synching on all 3 devices and I want to access the server syncthing GUI on my laptop, how can I do this?\n Btw, my server is an old laptop and I want to be able to close the screen without it going automatically into stand-by mode, what can I do?\n I posted this in r/syncthing too. If there is a better sub to get my answers please share it.\n    submitted by    /u/_NOKE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzvewx/cant_open_the_syncthing_gui_of_a_remote_server/",
          "publishedOn": "2022-12-31T14:36:05.000Z",
          "wordCount": 19631,
          "title": "Can't open the Syncthing GUI of a Remote Server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzum2t/building_a_tunnel_using_a_vps_wireguard_and/",
          "author": null,
          "description": "Hello selfhosted!\n For the past 2 weeks Ive been trying to expose my Jellyfin instance to the internet so I am able to stream my content over when I am visiting friends. I want to use wireguard and my own VPS for this to go the fully selfhosted route and not rely on third party DNS services.\n I dont want to use wireguard directly because chromecast wouldn't work that way. Also every user would need wireguard installed on their devices.\n First off, let me show you what I am trying to do: https://i.imgur.com/8tvKW4w.jpeg\n Explanation:\n - I want to have a wireguard tunnel between my VPS and my local docker network to route my services to the internet.\n  \nUser requests my website via mydomain.com.\n Mydomain is pointed at my VPS.\n The VPS has an active wireguard connection to my home network to…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzum2t/building_a_tunnel_using_a_vps_wireguard_and/",
          "publishedOn": "2022-12-31T13:54:30.000Z",
          "wordCount": 25903,
          "title": "Building a tunnel using a VPS, Wireguard and Traefik",
          "imageUrl": "https://external-preview.redd.it/G6s4k-djINDSBDFXp_ju90Voax4Lv7ro9w4tlznjCBo.jpg?auto=webp&s=7461c438560461de1ddf207c9bbf05a7627e0e66"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzuk65/looking_for_a_private_search_engine_for/",
          "author": null,
          "description": "Hi, I recently stumbled upon a bookmarking “search-engine” called historio.us. It essentially indexes every webpage you want and adds it to your own search index, which you can then search using full-text search. No tag management, no summary or title management needed. \n As I do not want to depend on a third party service for keeping all my bookmarks, as I never could be safe, they are not just closing doors one day, I al searching for a self hosted solution, to do something like this.\n Does anyone know a simple service, I could spawn locally in my home network (I don’t need access outside of it), to archive the same. All my internet searches on this unfortunately did not yield any results.\n    submitted by    /u/Weary_Occasion1351  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzuk65/looking_for_a_private_search_engine_for/",
          "publishedOn": "2022-12-31T13:51:33.000Z",
          "wordCount": 20438,
          "title": "Looking for a “private” search engine for bookmarking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zztrkg/does_anyone_know_a_way_to_unset_the_http_and/",
          "author": null,
          "description": "I want to use mailcow with nginx-proxy-manager as a reverse proxy and have added the nginx-mailcow container to my custom docker network so it can be accessed from the reverse proxy. How can I configure the nginx-mailcow container to have no port bindings added to it (I don't need them if i can access the container via hostname directly and use port 80)?\n The only way I can see so far is to directly edit the docker-compose file, which is discouraged in the documentation. I can't even create a docker-compose.override.yml file becuase for some reason, override files in docker compose don't actually override arrays (https://github.com/docker/compose/issues/3729), so I can't remove the entries already present in the \"ports\" list for the nginx-mailcow service!\n    submitted by    /u/DoUhavestupid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zztrkg/does_anyone_know_a_way_to_unset_the_http_and/",
          "publishedOn": "2022-12-31T13:08:33.000Z",
          "wordCount": 19726,
          "title": "Does anyone know a way to unset the HTTP and HTTPS port bindings for mailcow?",
          "imageUrl": "https://external-preview.redd.it/Ckh-N-vw4zKfkl7zSWKcIQU2L4yG3OLRRS1srXCZ8M4.jpg?auto=webp&s=1e4fb140fa813111ea55de6bc7cf156a15f703f1"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzscih/self_hosted_internal_communicator_without_any_dns/",
          "author": null,
          "description": "I am looking for a self hosted internal LAN communicator without the requirement to setup complicated domains and in general having to access to WAN in order to set it up. \n Up until recently Rocket.Chat was just fine but since Android requires SSL by default I cannot run it without getting a domain, on mobile phones. Are there any other options out there running on Raspberry, Windows, Android?\n    submitted by    /u/Itsonlyme233  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzscih/self_hosted_internal_communicator_without_any_dns/",
          "publishedOn": "2022-12-31T11:44:18.000Z",
          "wordCount": 20233,
          "title": "Self hosted internal communicator WITHOUT any DNS requirements",
          "imageUrl": "https://external-preview.redd.it/5sTnGdLnNdNtgn4BiGJ--3EeUxKl9xH7qQRvYj4fEtA.jpg?auto=webp&s=bc044135352daef64679a61d0bcbf675de6558e7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzs7wu/how_are_you_thinking_of_supporting_your_free/",
          "author": null,
          "description": "This is sort of an open ended rant. I am a 20+ year unintentional freerider on open source increasingly reflective on on the people and systems that support my ability to self-host. I gladly buy hardware or rent a vps to support my services, but never give to the people/orgs investing time to research, code, bugfix, document, support, and package. I could package, but don't have skills (fixable) or free time (not-fixable). Similarly, I could code but don't have skills (fixable) or free time (not-fixable). I've always been content letting it be someone else's problem. \n Conversely, I see several open source projects either asking for resources or operating on a shoestring budget. OpenSSL underpinned the internet and was operated on peanuts - makes you wonder what other projects need help. M…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzs7wu/how_are_you_thinking_of_supporting_your_free/",
          "publishedOn": "2022-12-31T11:35:30.000Z",
          "wordCount": 24805,
          "title": "How are you thinking of supporting your free tools and applications in 2023?",
          "imageUrl": "https://external-preview.redd.it/rWbfKTf9o19xQGhwZ5pJynJiQo4Z_fac8-FtOiCawkg.jpg?auto=webp&s=4c0ee24c9845ae109c87308ef8f96d0ae7514937"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzqrv6/energy_consumption_monitoring/",
          "author": null,
          "description": "I ordered a few smartplugs the other day which are supposed to be flashable with Tasmota. Any recommendations for a simple solution to capture the data? I don't really want to run a fullblown HomeAssistent installation to get a single graph.\n My plan so far:\n Tasmota -> Mosquitto -> Telegraf -> InfluxDB\n    submitted by    /u/Sarcism  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzqrv6/energy_consumption_monitoring/",
          "publishedOn": "2022-12-31T10:04:53.000Z",
          "wordCount": 21552,
          "title": "Energy consumption monitoring",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzm2wv/sonarrradarr_media_management/",
          "author": null,
          "description": "Hey guys,\n Got a newbie question about media management and hard links.\n Stack: Sonarr, Radarr, Jackett, qBittorrent\n I've got Sonarr/Radarr working with Jackett and qBittorrent. Hardlinks are working fine between qBittorrent's download folder and Sonarr/Radarr root folder. \n My question is, am I suppose to periodically clean up the qBittorrent's download folder and leaving the other copies in Sonarr/Radarr?\n    submitted by    /u/layzor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzm2wv/sonarrradarr_media_management/",
          "publishedOn": "2022-12-31T05:09:02.000Z",
          "wordCount": 20293,
          "title": "Sonarr/Radarr Media Management",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzhebu/crowdsec_vaultwarden_i_sleep/",
          "author": null,
          "description": "I did set up a whole CrowdSec, everything works perfectly with Nextcloud for example but not with Vaultwarden? Did anyone succeed to block an IP with Dominic-Wagner/vaultwarden collection? It just sleeps... \"no real shit\" moment for it, in the opposite of Nextcloud who is super reactive.\n  \nYes, I did make sure vaultwarden.log is readable.\n  \nMy acquis.yaml file: https://pastebin.com/7JmWXJ7X (yes, pastebin because Reddit can't hold 5 bloody lines of code formatting).\n Thanks\n    submitted by    /u/Tours-Petronas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzhebu/crowdsec_vaultwarden_i_sleep/",
          "publishedOn": "2022-12-31T01:16:19.000Z",
          "wordCount": 19261,
          "title": "CrowdSec -- Vaultwarden: I sleep?",
          "imageUrl": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&s=07c121a0180003f7373863af66192b6ff6a937da"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzgtld/mergerfs_first_disk_in_pool_is_full_but_every/",
          "author": null,
          "description": "Hey Guys,\n I'm having a bit of an issue with MergerFS and I am not sure how to correct it. I have a MergerFS pool consisting of a 4tb HBB, 1tb HDD, 750GB HDD, and a 500GB HDD with an 8TB HDD for snapraid backup. The first disk in my pool (4TB) is at 99% capacity but all of the other disks read as 0%. For some reason it appears as though everything is saving to just the 4TB disk and then making the entire MergerFS pool appear to be \"full\". Any help or suggestions?\n ​\n Thanks\n    submitted by    /u/PrettyDumbITGuy_87  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzgtld/mergerfs_first_disk_in_pool_is_full_but_every/",
          "publishedOn": "2022-12-31T00:50:30.000Z",
          "wordCount": 18771,
          "title": "MergerFS - First Disk in Pool is Full but Every Other Disk is Empty",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzfr53/looking_to_build_myself_a_new_homeserver_does_it/",
          "author": null,
          "description": "Hello! I currently run a few self hosted services (a nextcloud, invidious, nitter, home assistant, jellyfin, and minecraft server) all off the same old Dell Optiplex server i got off eBay a few years back. I want to upgrade my server because it's starting to show its age with some of the services i'm running (particularly jellyfin and minecraft) and I'm wondering if cheaping out with a Ryzen is an okay option, or if it'd be better for me to fork over a little more for an Intel Xeon? Any other tips are appreciated as I plan to build this server from new parts instead of a pre-built off ebay\n    submitted by    /u/JameUwU  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzfr53/looking_to_build_myself_a_new_homeserver_does_it/",
          "publishedOn": "2022-12-31T00:03:14.000Z",
          "wordCount": 19395,
          "title": "Looking to build myself a new homeserver, does it matter if I choose a Xeon over a Ryzen processor?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzf8ns/has_anyone_ever_used_readarr_and_lazylibrarian/",
          "author": null,
          "description": "Can't find much information on this except that LL is more unweildy to set up. Both seem reasonably active, although I see that LL is more in active development comparatively.\n I mostly need it to track my reading-list, read books list etc. I have a calibre-web instance well loved by friends and family so not looking to really move away from that.\n    submitted by    /u/lannistersstark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzf8ns/has_anyone_ever_used_readarr_and_lazylibrarian/",
          "publishedOn": "2022-12-30T23:41:25.000Z",
          "wordCount": 19379,
          "title": "Has anyone ever used Readarr and lazyLibrarian both? If so, how do they compare?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzdwrj/newish_bitwarden_unified_beta_image/",
          "author": null,
          "description": "Supports mssql, MySQL/Mariadb, and postgresql now!\n Just spun it up using Postgres and nginx as reverse proxy and it’s working like a charm.\n https://bitwarden.com/help/install-and-deploy-unified-beta/\n    submitted by    /u/onicrom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzdwrj/newish_bitwarden_unified_beta_image/",
          "publishedOn": "2022-12-30T22:45:02.000Z",
          "wordCount": 19296,
          "title": "Newish Bitwarden unified beta image",
          "imageUrl": "https://external-preview.redd.it/XDXll0uU8yFjiJsa0Fnhl6t3wA7Lt3NKI4sokcrslvA.jpg?auto=webp&s=28692d339912d81aa64fccfa4263b5ca89686fbd"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzc9gk/after_installing_pivpn_i_can_no_longer_access_the/",
          "author": null,
          "description": "submitted by    /u/ToTheXtreme64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzc9gk/after_installing_pivpn_i_can_no_longer_access_the/",
          "publishedOn": "2022-12-30T21:36:32.000Z",
          "wordCount": 19325,
          "title": "After installing PiVPN I can no longer access the internet on my server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzbzfd/unable_to_use_wireguard/",
          "author": null,
          "description": "I have been trying for several weeks now to utilize Wireguard with no luck. I set it up, what I believe to be correctly in docker, and when I turn on the VPN, I cannot load anything through the connection. \n I recently have tried to use wg-easy with similar results. I connect to the VPN but cannot load anything.\n Where should I start to try and get this working? Could there be an issue with router settings that would be blocking something?\n    submitted by    /u/colorfularchipelago  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzbzfd/unable_to_use_wireguard/",
          "publishedOn": "2022-12-30T21:25:10.000Z",
          "wordCount": 19609,
          "title": "Unable to use Wireguard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzbe4s/complete_manual_install_of_zabbix/",
          "author": null,
          "description": "I am trying to do a complete manual install of zabbix from source. Not looking for a script. I was using the arch aur but it failed me and it was not missing some features. I got the whole complete package placed, the database working with the db templates imported. I was able to setup the front end working with nginx. But i could not find any explicit instructions to manual create the service for the server or agent to get the ball rolling. \n I already looked at the zabbix manual. Not enough detailed info about the services and creating the systemctl files. Any one mind pointing my into the right direction.\n I will be retrying the aur to extract any info about the services i need.\n Please and thank you\n    submitted by    /u/Mabizle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzbe4s/complete_manual_install_of_zabbix/",
          "publishedOn": "2022-12-30T21:01:05.000Z",
          "wordCount": 19379,
          "title": "Complete manual install of zabbix",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zzalx6/are_there_any_nas_hosted_solutions_for_inplace/",
          "author": null,
          "description": "I'm looking for a solution that does a few things:\n  \nProvide full-text search for documents that contain text\n Provide metadata search/filtering on all documents\n (bonus) Provide OCR capabilities for PDFs/Images\n  \nThe kicker is that I want my folder structure to continue being a disorganized mess. All I want to do is point the the thing at the root directory of the share, and have it make the files searchable.\n Is there anything that can do this?\n I searched everywhere for this, and the common suggestion is Paperless-ngx. Paperless seems like a good solution, but it insists on reorganizing everything into it's own folder structure. It sounds like they do this to avoid checking document hashes on each crawl, but none the less.\n I also heard Ambar suggested, but it looks like it's now abandonware.\n    submitted by    /u/WholesomeCirclejerk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zzalx6/are_there_any_nas_hosted_solutions_for_inplace/",
          "publishedOn": "2022-12-30T20:28:21.000Z",
          "wordCount": 18767,
          "title": "Are there any NAS hosted solutions for in-place full-text search on documents (not document management, not paperless-ngx)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zza7pr/totally_local_web_server_on_https/",
          "author": null,
          "description": "So I am trying to do exactly that. It has been years since I have tried, and things seem to have changed. I see bits and peices of what I need here but no clear answer. What is the easists way to get https working on a LOCAL web server with NO internet dependence??? I see references to nginx, lets encrypt, and some other tools. But all of the solutions I read into, so far, had some kind of internet dependence. Others have browser issues. Has anyone gone down this road and found a solution that they really like??? I am not a complete newb, but the last time I did this, I was creating my own certs in a local tool for vm's. I am not sure that works with current browsers based on what I am reading. TIA!!!\n    submitted by    /u/avgjoetx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zza7pr/totally_local_web_server_on_https/",
          "publishedOn": "2022-12-30T20:12:15.000Z",
          "wordCount": 21079,
          "title": "Totally local web server on HTTPS.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz7y7a/what_are_your_top_self_hosted_services_that_you/",
          "author": null,
          "description": "submitted by    /u/Sugardaddy_satan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz7y7a/what_are_your_top_self_hosted_services_that_you/",
          "publishedOn": "2022-12-30T18:39:39.000Z",
          "wordCount": 18133,
          "title": "What are your top self hosted services that you are very satisfied with?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz7wtj/redirects_like_pihole/",
          "author": null,
          "description": "I would like to have a general redirect for some urls like youtube to invidious, twitter to nitter, …\n And a server application like pi-hole is checking for domainnames, so I was asking myself if there’s an application where I can set redirects and every device using this one will profit of these redirects.\n Is there anything like that?\n Thank you.\n    submitted by    /u/-happy2go  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz7wtj/redirects_like_pihole/",
          "publishedOn": "2022-12-30T18:37:58.000Z",
          "wordCount": 21048,
          "title": "Redirects like „pi-hole“?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz7vlj/self_hosted_car_and_bike_maintenance/",
          "author": null,
          "description": "Hi, is anyone aware of a selfhosted solution that helps keep track of car/motorbike/campervan maintenance?\n    submitted by    /u/magnatrilobite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz7vlj/self_hosted_car_and_bike_maintenance/",
          "publishedOn": "2022-12-30T18:36:31.000Z",
          "wordCount": 18409,
          "title": "Self hosted car and bike maintenance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz7t4n/self_hosted_library_for_books_courses_comics_etc/",
          "author": null,
          "description": "I use Jellyfin for my music, TV, and movies, and it's perfect. However, I also collect lots of courses, such as Udemy, CBT Nuggets, and YouTube playlists, as well as books and comics. Is there any solution that can help with the organisation and playback of these types of media? I don't mind manually adding everything to it, just a nicer way to organise them and play them back\n Courses I could probably handle with Jellyfin, but it'd be cool if there was something else designed specifically for them, especially as many courses are both videos and text based\n    submitted by    /u/KoolKarmaKollector  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz7t4n/self_hosted_library_for_books_courses_comics_etc/",
          "publishedOn": "2022-12-30T18:33:31.000Z",
          "wordCount": 18582,
          "title": "Self hosted \"library\" for books, courses, comics, etc.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz6cc3/anonaddy_docker_compose/",
          "author": null,
          "description": "Hey all, \n trying to spool up my own instance of anonaddy. I was able to get it running, but am having trouble sending and receiving mail through it. Here is the run down.\n - Port 25 is enabled through my ISP and port forwarded on my router to my servers IP using TCP.\n - I setup some DNS records through my cloudflare. See redacted screen shot:\n DKIM is using selector in compose file and p value is the public key generated by anonaddy\n - MXtoolbox shows all good signs using several checks, no syntax errors or heavy mistakes.\n - Redacted Docker-compose as follows: \n APP_KEY & ANONADDY_SECRET use different long string values. POSTFIX_RELAYHOST is using my ISP's relay server.\n - I do not have a static IP and cannot get one because of limitations of my ISP (I think). Also, I do not think I can alter reverse DNS info either. Help needed here if possible.\n - I get logs (redacted) as follows when the server tries to send email verification:\n  mail postfix/smtp[1022]: to=<mypersonalgmail@gmail.com>, relay=POSTFIX_RELATHOST VALUE[00.00.00.0]:25, delay=2, delays=0.11/0.03/1.2/0.63, dsn=2.0.0, status=sent (250 <> Mail accepted) \n - My initial guess is that I am getting filtered my other mail servers for reverse DNS reasons and do not want to push it too hard and end up on some ban list. \n - check.spamhaus.org stated that my ISP blocks port 25 and that I should use a relay which they provided (currently this is my POSTFIX_RELAYHOST value) \n I feel like I am so close. If someone could shine some light or just let me know if this is impossible to setup with my ISP. At least I could get some closure.\n    submitted by    /u/The-Ultimate-Insult  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz6cc3/anonaddy_docker_compose/",
          "publishedOn": "2022-12-30T17:34:56.000Z",
          "wordCount": 19164,
          "title": "AnonAddy docker compose?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz5842/what_are_your_thoughts_about_podman_rpmostree_and/",
          "author": null,
          "description": "So recently, I was eventually able to install Nextcloud, Gitlab, Nginx Proxy Manager and Portainer on my personal server partially due to your help. Everything is working perfectly, but now I really enjoy learning new stuff about servers.\n I'm currently using Fedora Server with docker containers, and I was wondering if any of you are using Fedora IoT (based on RPM-ostree) with Podman since it is \"marketed\" as the future of servers. More generally, I would like to know what are the tools (like Nix, snap, ...) you are using and/or plan/want to use and WHY. \n I have a bit of free time right now, and I might spend it trying out new tools just for fun.\n Thx and happy holidays.\n    submitted by    /u/IgnaceMenace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz5842/what_are_your_thoughts_about_podman_rpmostree_and/",
          "publishedOn": "2022-12-30T16:49:54.000Z",
          "wordCount": 19617,
          "title": "What are your thoughts about Podman, rpm-ostree and other \"new\" tools that could be useful for servers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz4urp/application_to_update_software/",
          "author": null,
          "description": "Over the past years I've gradually my LAN to other family members. I got about 1-4 more family members to hookup to my DMVPN but regardless. Its becoming difficult to manage software at this point so I wanted to reach out and see if anyone knows of a selfhosted software to manage software repo/updates for linux, mac, and windows aside from buying an RMM or PDQ deploy type software.\n    submitted by    /u/athornfam2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz4urp/application_to_update_software/",
          "publishedOn": "2022-12-30T16:34:48.000Z",
          "wordCount": 18828,
          "title": "Application to update software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz4h7h/firefox_account_server_and_firefox_sync_how/",
          "author": null,
          "description": "I have tried many times to get FXA set up but always gave up because there's not a clear guide on how to actually get it working. I don't want to use docker for it either. I use firefox on all of my devices, and wanted to have a central login for everything so my bookmarks and such can sync up between them all. \n Are there any good resources that may help me get it set up, or should I Just give up on it and look for something else to easily sync up my stuff between browsers?\n    submitted by    /u/ShittyExchangeAdmin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz4h7h/firefox_account_server_and_firefox_sync_how/",
          "publishedOn": "2022-12-30T16:19:09.000Z",
          "wordCount": 19756,
          "title": "Firefox account server and firefox sync, how?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz1bb2/share_my_open_source_music_server_diosic/",
          "author": null,
          "description": "Diosic is an open source web-based music collection server and streamer. Mainly suitable for users who need to deploy on servers with low hardware specifications.\n Highlights\n  \nSuitable for deployment on low configuration servers.\n Simple and practical.\n Diosic can categorize subfolders in your music folder. For example, if there are English, Chinese\n  \n, Japanese subfolders under your music folder, they will be automatically classified into three lists. This is also my original intention to develop Diosic.\n I'm new to Rust. Thank You.\n Diosic - GitHub\n Overview and screenshots\n    submitted by    /u/JinkerJK  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz1bb2/share_my_open_source_music_server_diosic/",
          "publishedOn": "2022-12-30T14:04:08.000Z",
          "wordCount": 19953,
          "title": "Share my open source music server - Diosic.",
          "imageUrl": "https://external-preview.redd.it/9orbHRT73t9-fr0GBniZzoz7Th2CpgecgcxynK-5c_M.jpg?auto=webp&s=3bd66f29f8201a221518b10304ebc999bbffca71"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zz0yvr/protonmail_selfhosted_imap_bridge_for_local/",
          "author": null,
          "description": "Hi all,\n Im using Office 365 Business in the moment for 5€/month.\n However, as I switched to self-hosting von Calender/Contacts/Files, it seems not to be the ideal solution anymore (especially privacy).\n So I'm thinking to get a Protonmail Premium Subscription (2 years for 7,19€ per month).\n I will use my own domain, so it's not about anonymity, I just want my mails be stored encrypted so that not even the provider can access it.\n Protonmail is using a bridge (for Linux, PC, Mac) to encrypt the mails and server a local IMAP server via 127.0.0.1.\n However, as it's binding to 127.0.0.1, you would need to install it on every device, and it's not possible on smartphones.\n Because of this, I want to create a virtual machine so that I can reach the local IMAP server via VPN also on my smartphones.\n How can I open the localhost IMAP-port to my local network? Maybe NGINX is a solution? \n And besides of this: Do you think switching from Outlook to Protonmail is a good decision?\n Is their infrastructure safe enough and is it ensured they will exist the full 2 years?\n    submitted by    /u/Simplixt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zz0yvr/protonmail_selfhosted_imap_bridge_for_local/",
          "publishedOn": "2022-12-30T13:48:26.000Z",
          "wordCount": 19298,
          "title": "Protonmail - Self-Hosted IMAP Bridge for local network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zyzv07/i_rent_a_vps_technically_can_my_provider_login_to/",
          "author": null,
          "description": "Hello,\n I have a VPS with an encrypted virtual drive and RSA key-pair authentification.\n Technically speaking, can my provider somehow login to my VPS (by changing the rsa key for example or something) and therefore have access to my data ?\n EDIT : More info about my setup :\n Password authentification is disabled, I only use keys to login with SSH.When creating the VPS I generated the keys on my local computer and only gave my provider the public key.Cloud-init is disabled and I'm running vanilla Ubuntu server.I never used web console to login.\n EDIT 2 : I came to the conclusion it's nearly impossible to prevent them from reading my data.\n 1 - They can get my password from the RAM\n 2 - The data is decrypted when the system is running anyway. \n I guess the only way to prevent them is to encrypt my data on my local machine before uploading it.\n Thank you all, I learned so much from your answers.\n Thanks\n    submitted by    /u/StillAffectionate991  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zyzv07/i_rent_a_vps_technically_can_my_provider_login_to/",
          "publishedOn": "2022-12-30T12:54:42.000Z",
          "wordCount": 21155,
          "title": "I rent a VPS. Technically can my provider login to my server ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zyykqk/gitea_1180/",
          "author": null,
          "description": "submitted by    /u/Sarcism  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zyykqk/gitea_1180/",
          "publishedOn": "2022-12-30T11:43:34.000Z",
          "wordCount": 20856,
          "title": "Gitea 1.18.0",
          "imageUrl": "https://external-preview.redd.it/-zBUXUei5mNWHzOdVs9C7pYZfJuKBABYdqX7GjgJ2cI.jpg?auto=webp&s=8c3ed38c71455615beda0cbfb468f3c1a26bc3ac"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zysdl2/your_favorite_type_1_hypervisor_and_why/",
          "author": null,
          "description": "Hey all!\n I'm having lots of fun with proxmox and got curious what other hypervisors people are using and what made you choose it!\n Thanks in advance and happy hosting!\n    submitted by    /u/Realestaste  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zysdl2/your_favorite_type_1_hypervisor_and_why/",
          "publishedOn": "2022-12-30T05:42:16.000Z",
          "wordCount": 21524,
          "title": "Your Favorite Type 1 Hypervisor and Why",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zyn8n5/upscayl_free_and_open_source_ai_image_upscaler/",
          "author": null,
          "description": "submitted by    /u/NayamAmarshe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zyn8n5/upscayl_free_and_open_source_ai_image_upscaler/",
          "publishedOn": "2022-12-30T01:37:53.000Z",
          "wordCount": 19501,
          "title": "Upscayl - Free and Open Source AI Image Upscaler for Linux, Mac and Windows",
          "imageUrl": "https://external-preview.redd.it/X37Rh-QnhNXPkvWCRLXS3TRTXe6sVCgo6y_9Ae8drqc.jpg?auto=webp&s=495017603b785065fe8cfa3c9df6be8bfca0e6a3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zym4l3/qbittorrentvpn_stalled_and_errored/",
          "author": null,
          "description": "hello all, I'm having a problem downloading my linux isos through qbittorrentvpn. I used dockstarter to set up everything, and I'm using ivpn. Wireguard files are in the right directory and everything as far as that goes is working just fine - using torguard my IP shows as exactly where it should after being routed through ivpn. When attempting to download ISOs from *arr apps, they almost immediately change to the 'stalled' status then change to 'errored'. Has anyone successfully set up qbittorrentvpn webui utilizing ivpn before? A little guidance would be nice, I think I've exhausted all the keywords I can think of to figure out this problem myself\n    submitted by    /u/Cascodius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zym4l3/qbittorrentvpn_stalled_and_errored/",
          "publishedOn": "2022-12-30T00:51:00.000Z",
          "wordCount": 20315,
          "title": "qbittorrentvpn stalled and errored",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zylyxi/backup_solution/",
          "author": null,
          "description": "Hi, I have many different servers with normal folders or bindings to backup. I'd like to use the same application and send each one on its own bucket (same provider is fine). No problem using cli on these remote servers. \n Then I'd like to be able to connect with a GUI from my desktop to these remote repositories on the provider just to look or download backups.\n Which app would you suggest that is able to do that? I was looking at kopia but it seems it can have only one repository and didn't find any download button on the gui.\n Thanks!\n    submitted by    /u/somebodyknows_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zylyxi/backup_solution/",
          "publishedOn": "2022-12-30T00:44:14.000Z",
          "wordCount": 20342,
          "title": "Backup solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zylk8u/self_hosted_user_management_solutions_with_ldap/",
          "author": null,
          "description": "I've been looking to set up a centralised user management system for a while, but I've been struggling to find the right solution. My main concern is that many applications seem to just prefer to only use LDAP. As a systems administrator in my day job, I have plenty of experience with Windows Server and Active Directory on there, but I'm keen to not use Windows at home for such purpose\n So naturally, there's OpenLDAP and Samba AD, neither of which I've ever used (save for Samba for my NAS). Then there's these big and complex solutions like Authentik and Keycloak, but I'm not sure either of these have their own LDAP solution, and just sync from an existing LDAP server\n    submitted by    /u/KoolKarmaKollector  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zylk8u/self_hosted_user_management_solutions_with_ldap/",
          "publishedOn": "2022-12-30T00:26:29.000Z",
          "wordCount": 20239,
          "title": "Self hosted user management solutions with LDAP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zyklp8/anyway_to_selfhost_or_otherwise_engineer_a_google/",
          "author": null,
          "description": "I'm looking for a way to park my number such that I can forward it to any other number, make calls from my downstream numbers but have it appear to the receiver as if it comes from my parked number, make web/VOIP calls (from any device) from said number, send/receive SMS and MMS messages with the number and have \"visual voicemail\" transcriptions of my voice mail on mobile devices as well as computers (any device). I'm finding the current google voice apps (and browser integration) to be too limiting, buggy and frustrating. I would also like to diminish my overall use of google as time goes by.\n Any suggestions?\n    submitted by    /u/chmedly020  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zyklp8/anyway_to_selfhost_or_otherwise_engineer_a_google/",
          "publishedOn": "2022-12-29T23:48:23.000Z",
          "wordCount": 19932,
          "title": "Anyway to selfhost or otherwise engineer a Google Voice alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zyjfyd/need_something_for_saving_links_google_keep/",
          "author": null,
          "description": "Hello,\n I'm searching for a google keep alternative that i can selfhost.I save lots of links and small memos from my phone/tablet and pc.The easiest way for me is to just share what i need to google keep and read after.\n What good alternatives do you reccomend,it needs to have a mobile app.\n    submitted by    /u/t1nk3rz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zyjfyd/need_something_for_saving_links_google_keep/",
          "publishedOn": "2022-12-29T23:02:33.000Z",
          "wordCount": 19772,
          "title": "Need something for saving links ,Google Keep alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zyf6tp/question_about_ssl_google_domains_registrar/",
          "author": null,
          "description": "Hello everyone,\n I apologize in advanced as I feel this question has been asked many times before, but after reading a ton of different docs and pages I just want to keep myself honest and make sure I understand everything I've read/researched/gathered.\n TL;DR: I registered a domain with Google Domains and want to use that domain for my self hosted services that only accessible behind an VPN. I want to create a wildcard SSL cert for added security using Lets Encrypt and Certbot.\n So I registered a domain with Google Domains. I want to use it for my self hosted services which are behind a VPN (wireguard), and only accessible to those connected to it.\n While I know SSL isn't necessary for my use case given nothing is accessible outside of the VPN, I just want to be more safe than sorry. In a…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zyf6tp/question_about_ssl_google_domains_registrar/",
          "publishedOn": "2022-12-29T20:15:12.000Z",
          "wordCount": 20985,
          "title": "Question about SSL: Google Domains (registrar), Cloudflare DNS, and Certbot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zyehru/no_port_forwarding_looking_for_suggestions/",
          "author": null,
          "description": "The local ISP has decided that 100mbps should now cost $200 usd, 200mpbs $300 and so on. They are the only wired provider that provides anything over 10 mbps. So, I switched to the tmobile home internet and get 300mbps for an amazing deal of free for the next 5 months then 25/month after that. The only problem is I can't pass traffic to my synology as it does not have nat. They claim it's a IPV6 problem. I researched into different products and found Packetriot. They are using a external server and having a tunnel between it and whatever you install it on. Well, I have an external server in a free oracle instance, arm processor. So, Could I use the oracle box, and have my synology nas tunnel into it? What software would I need on both ends? Anyone done anything like this before?\n ​\n Update: I have tailscale up and running. My desktop and my cloud are talking and I am able to pass traffic between the two. Now, i need to figure out how to have a external domain name pass through the tailscale to the synology. Will update with more information. \n Cloud Install Link: https://tailscale.com/kb/1156/install-ubuntu-2010/ \n    submitted by    /u/randomadhdman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zyehru/no_port_forwarding_looking_for_suggestions/",
          "publishedOn": "2022-12-29T19:48:30.000Z",
          "wordCount": 19688,
          "title": "No port forwarding. Looking for suggestions",
          "imageUrl": "https://external-preview.redd.it/Ssi9-rid5q7xGFCN14pVfBNoJ21mwxgsCRQLdmGD3dA.jpg?auto=webp&s=a0b8114216605dd0b3a3bbf4f848eefbd0cad8b2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zydzyx/best_free_affordable_nvr_software_i_have_tried_a/",
          "author": null,
          "description": "Looking for something with a good mobile app and fairly easy to use, I don’t mind paying a one time fee if the product works well.\n BlueIris had choppy video playback for me, possibly due to transcoding caused by no direct write in the demo version.\n Shinobi mobile app sucks badly\n iSpy works well, but monthly subscription for mobile access is dumb.\n xProtect works great, but mobile app has no direct streaming in the free version, and the transcoding causes stuttering playback.\n Luxriot is no longer free\n Frigate looks a bit more in depth then I need.\n Only other real option is zoneminder?\n Would love some input on this!\n    submitted by    /u/MostDubs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zydzyx/best_free_affordable_nvr_software_i_have_tried_a/",
          "publishedOn": "2022-12-29T19:29:23.000Z",
          "wordCount": 20645,
          "title": "Best free / affordable NVR software? I have tried a few",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zydxd2/passbolt_vs_bitwarden/",
          "author": null,
          "description": "Hey Guys,\n I'm looking into self-hosted password managers and saw these two.\n I wanted to know if anyone has any experience or knowledge about the differences between these.\n They both run docker (especially with bitwarden new unified installer) and on ubuntu server.\n Otherthann the installer, Any recommendations, tips etc? Any special aspect that gives one the edge over the other?\n    submitted by    /u/SecureCPU  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zydxd2/passbolt_vs_bitwarden/",
          "publishedOn": "2022-12-29T19:26:31.000Z",
          "wordCount": 20532,
          "title": "Passbolt vs Bitwarden",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zyc8r8/portainer_container_sharing_ports_problem/",
          "author": null,
          "description": "Hello! Was just lurking here, thats my first post - Maybe the worst or easiest question of the year but i have to try. Kinda new to docker, portainer and doing some practises.\n I have 2 container on my portainer, which want to use port 8080 redirected to 80.\n The first One works, the second one (of course?) not. Whats the easiest way to change that ports for the second container? Is that a thing in the image, or @portainer? \n I tried the portainer option for ports redirect in the container deployment like 8181 -->> 8080 but that doesnt work for me.\n Thanks in advance\n    submitted by    /u/Bubbleqq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zyc8r8/portainer_container_sharing_ports_problem/",
          "publishedOn": "2022-12-29T18:21:28.000Z",
          "wordCount": 18843,
          "title": "Portainer: Container sharing ports problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zya1ro/i_built_a_discord_bot_for_controlling_docker/",
          "author": null,
          "description": "submitted by    /u/Panda_of_power  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zya1ro/i_built_a_discord_bot_for_controlling_docker/",
          "publishedOn": "2022-12-29T16:52:57.000Z",
          "wordCount": 18748,
          "title": "I built a Discord bot for controlling docker containers.",
          "imageUrl": "https://external-preview.redd.it/KFuBLnOisgtLZIKtiV32Kl55vBiEPvmzLFrmYKDrN7g.jpg?auto=webp&s=232d2043a48c6bb9ba15f6dd12f1c01bf9cfcd11"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zy97qc/is_there_any_way_to_get_insights_of_opensource/",
          "author": null,
          "description": "Hello guys,\n I'm trying to find out if there is an existing way (website, app, tricks, or whatever) to get good statistics about open source projects like to see what the trending open source projects whatever the area of technology.\n Thank you:)\n    submitted by    /u/fantasimy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zy97qc/is_there_any_way_to_get_insights_of_opensource/",
          "publishedOn": "2022-12-29T16:18:23.000Z",
          "wordCount": 21252,
          "title": "Is there any way to get insights of open-source projects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zy8b3h/how_does_standard_notes_native_file_upload_work/",
          "author": null,
          "description": "I don't know if I missed this feature before, but it seems Standard Notes has a feature for uploading files now: https://docs.standardnotes.com/self-hosting/file-uploads\n I'm failing to understand how that works. I'm failing to understand the security requirements for that as the documentation I linked to is way too vague.\n Do I have to create a reverse proxy to that port, which defaults to 3125? Or is it secure by default?\n The docs say the api_gateway won't be used. But then in docker-compose I see that the api_gateway uses the variable FILES_SERVER_URL... why? What is it used for? And how does that relate to EXPOSED_FILES_PORT? Do I just have to set EXPOSED_FILES_PORT considering I'm using docker, and forget about the URL and let tcp forwarding do its magic? Well, then more questions pop up.\n How does Standard Notes know where to send the file requests? How does standard notes know whether they're proxied with a reverse-proxy to decide on the communication protocol? Does it try both http and https? If there's no reverse proxy, how is the end-to-end encryption done? Where's the encryption key?\n Way too many questions in my head about this thing... I'd really appreciate explaining anything you can about this. Especially how you set this up.\n Also, one more bonus thing, can I store the files in the database instead of in a separate file-storage? That'd be really nice.\n    submitted by    /u/TheQuantumPhysicist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zy8b3h/how_does_standard_notes_native_file_upload_work/",
          "publishedOn": "2022-12-29T15:40:06.000Z",
          "wordCount": 20119,
          "title": "How does Standard Notes Native File Upload work?",
          "imageUrl": "https://external-preview.redd.it/JXxE4-F0GqaypasVj77JvNN5eAkjEXu4ljqvaadNHIw.jpg?auto=webp&s=63c0a8ff0152a46d25906cd6dbd08000ce64dba5"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zy7yaf/hardware_suggestions_upgrade_or_start_fresh/",
          "author": null,
          "description": "Hi guys, I've been lurking here for a while now and I've started going down the rabbit hole of self hosting.\n I'm currently running a RPi4 with 3xHDDs that previously was just managing backups, handling remote torrenting (DelugeD), and hosting an Emby server (recently switched to Jellyfin). \n I've recently added a few other things to the mix (Navidrome, Audiobookshelf, Changedetection.io) and I'm wanting to go further (Photoprism, which seemed too heavy for the Pi when I tried it out, RSS, etc.) I'm thinking I should probably move a lot of this to another machine. I've got an old (c. 2015?) Gateway desktop with Linux Mint Mate installed and I'm wondering if this machine either sounds good as is, could use some upgrades, or even shouldn't be used as a long-term solution.\n Motherboard: Acer IPISB-VR Rev 1.01 (Supports Intel (Socket Type – LGA 1155): Core i7 (Quad Core), Core i5, Core i3)\n CPU: 2.8GHz Intel Core i5 2300 Quad Core\n RAM: 8GB DDR3 (16GB Max)\n GPU: GeForce GTX 950\n PSU: EVGA 700B\n 1.5TB HDD\n 802.11b/g/n Wi-Fi and Gigabit Ethernet\n I've been thinking it could use some new thermal paste (the fans go wild and temps have random spikes), maybe a $20 upgrade to 16GB RAM, and maybe even a CPU upgrade of some sort.\n Thoughts and suggestions appreciated!\n    submitted by    /u/ORRAgain  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zy7yaf/hardware_suggestions_upgrade_or_start_fresh/",
          "publishedOn": "2022-12-29T15:24:33.000Z",
          "wordCount": 19480,
          "title": "Hardware Suggestions, upgrade or start fresh?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zy6fef/heimdall_does_not_allow_logging_in_remotely/",
          "author": null,
          "description": "So long story short, for the longest time i had heimdall as my dashboard and used it locally. Today i decided to make a cloudflare tunnel (say what you will its works the best for me) and all went well until i set a password once i do that i am able to login no problem using my local ip but from my domain even if i type the right password it just gives me the prompt again. Sometimes it loads the main page but not fully. I tried multiple accounts and made sure that the box for allowing public access t o front is checked. What should i do the fact that on my local ip works is weird, any tips?\n    submitted by    /u/Master_Gamer64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zy6fef/heimdall_does_not_allow_logging_in_remotely/",
          "publishedOn": "2022-12-29T14:16:03.000Z",
          "wordCount": 19701,
          "title": "Heimdall does not allow logging in remotely.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zy5xvy/media_library_catalog/",
          "author": null,
          "description": "Hello all,\n TL.DR: I'm looking for a self-hosted media library solution that is able to catalog various media. Serving media is not a requirement.\n What I actually mean with that, I have movies that I've ripped from Blu-Rays, Blu-Rays themselves, DVDs, Audio CDs and a lot other media that I'd like to catalog to basically just see what movies or music I have and on what media. Ideally it would also go over my collection, recognise it and download metadata, like album art, release date, etc.\n I've already looked at Jellyfin and other media servers, but neither of them were the one (I'm not looking at Plex for various reasons). I've found a macOS app, Movie Explorer (https://betamagic.nl/products/movieexplorer.html) that would be perfect, but it's a macOS app and it can only be used by one person. I'd prefer something with a web GUI where users (family members) can enter and/or look up data. I'm not looking for a solution that would also stream it (though it's a nice-to-have, I already have a solution for that), just pure cataloging is enough to get started.\n Can anyone point me to the right direction?\n Thank you very much!\n    submitted by    /u/Equal_Water_5432  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zy5xvy/media_library_catalog/",
          "publishedOn": "2022-12-29T13:53:24.000Z",
          "wordCount": 20235,
          "title": "Media Library (catalog)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zy5agy/any_suggestion_for_cmmscomputerized_maintenance/",
          "author": null,
          "description": "Any suggestion for CMMS software that automatically create repetitive tasks(weekly, montly tasks) and can send message over telegram ?\n    submitted by    /u/Correct-Employee-376  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zy5agy/any_suggestion_for_cmmscomputerized_maintenance/",
          "publishedOn": "2022-12-29T13:22:00.000Z",
          "wordCount": 19722,
          "title": "Any suggestion for CMMS(Computerized maintenance management system) software ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zy4byz/tvhstats_an_activity_monitor_history_tracker_for/",
          "author": null,
          "description": "This is a tool similar to what Tautulli does for Plex, but for TVHeadend. I know not many of you are self hosting an instance of TVHeadend, but for those who are, I want to share it.\n For now its somewhat limited, it just displays top stats for some categories, and a history, but it does work pretty stable.\n I plan on adding charts and stuff when I have some spare time.\n It is written in elixir and of course, it's free and open source. I have some docker images ready, so it's easy to get it running. \n Repo:\n https://github.com/jbonet/tvhstats\n ​\n Screenshots:\n Home\n ​\n History\n    submitted by    /u/rySeeR4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zy4byz/tvhstats_an_activity_monitor_history_tracker_for/",
          "publishedOn": "2022-12-29T12:33:00.000Z",
          "wordCount": 20267,
          "title": "TVHStats: An activity monitor / history tracker for TVHeadend",
          "imageUrl": "https://external-preview.redd.it/sCss0V_z43TVxcKaVXnhXD90C0URRmwCHT5K4LXbqVM.jpg?auto=webp&s=65c7776ec4e37493b74c12b60622b013c53408c3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zy3xzp/is_it_possible_to_self_host_mobile_network/",
          "author": null,
          "description": "submitted by    /u/Mateleo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zy3xzp/is_it_possible_to_self_host_mobile_network/",
          "publishedOn": "2022-12-29T12:11:42.000Z",
          "wordCount": 19995,
          "title": "Is it possible to self host mobile network ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zy23xs/looking_for_recommendations_for_a_imagedocument/",
          "author": null,
          "description": "My company provides a hosted SaaS product that our customers use to create web pages - actually much more involved than that but irrelevant for the purposes of this. The problem is that often clients want to include images or PDFs in the pages or as links on the pages which is not a problem but I've resisted allowing clients to upload all of this stuff to our servers for a variety of reasons - partly because I know they'd never get cleaned up but also because our application runs in a docker container and with a set of ansible scripts I can build a server with a very complex setup from a vanilla OS to fully deployed in around 8 minutes so if I did provide a way for clients to upload files then it would have to be stored in our database layer rather than in the file system so that it doesn't matter which server the request goes to. Currently, we tell the clients to upload images to any image hosting service and to use a public link but I would like to improve our offering without putting the burden into our SaaS application. There';s nothing sensitive or that needs to not be publicly accessible other than not serving a directory listing.\n I started looking at nextcloud the other day just out of interest and that made me wonder if there is something with a web interface where I can allow clients to upload their own files to a web server but with a single domain for all files on the server with each client being seen as a subdirectory so I can get away without having to manage multiple certificates for https.\n I realise it's a very specific question and that there may not be anything that'll do what I want but I'm wondering if anyone knows of something before I start looking at building our own solution?\n TIA\n    submitted by    /u/undersidebounce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zy23xs/looking_for_recommendations_for_a_imagedocument/",
          "publishedOn": "2022-12-29T10:26:25.000Z",
          "wordCount": 20275,
          "title": "Looking for recommendations for a image/document serving solution with a web interface for a lot of different users",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxze35/a_selfhosted_mirotalks_webrtc_rooms_scheduler/",
          "author": null,
          "description": "GitHub: https://github.com/miroslavpejic85/mirotalkwebrtc\n Demo: https://webrtc.mirotalk.com\n    submitted by    /u/mirotalk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxze35/a_selfhosted_mirotalks_webrtc_rooms_scheduler/",
          "publishedOn": "2022-12-29T07:41:44.000Z",
          "wordCount": 19024,
          "title": "A self-hosted MiroTalk's WebRTC rooms scheduler server.",
          "imageUrl": "https://preview.redd.it/eok6mgxl1u8a1.jpg?auto=webp&s=4383a747b55eef26c2c14448f9ef783777ad9861"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxx0qv/selfhosted_musicbrainz_server_as_source_for/",
          "author": null,
          "description": "I've got a self-hosted Musicbrainz server up and running on a machine on my network (using Docker) and I can access the website it serves, run manual searches for releases, etc.\n However when I point Picard at it and try to tag tracks, Picard's Authentication dialogue pops up. The self-hosted server tells me it can't provide an authentication code for Picard, and codes generated by the musicbrainz.org site don't work.\n Has anyone got this working? It sounds like an obvious use case for the self-hosted server and I have 70,000 tracks I'd like to tag!\n EDIT - I've got it working - it's because I was logged into my musicbrainz.org account in Picard and didn't log out before changing the server address to my local IP.\n EDIT 2 - I used the Installation instructions for Metabrainz's own musicbrainz-docker github repo to get this working, rather than Linuxserver.io's image (which I've never been successful with!)\n    submitted by    /u/infinitejones  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxx0qv/selfhosted_musicbrainz_server_as_source_for/",
          "publishedOn": "2022-12-29T05:34:33.000Z",
          "wordCount": 19971,
          "title": "Self-hosted Musicbrainz server as source for tagging in Picard - has anyone got it working?",
          "imageUrl": "https://external-preview.redd.it/eljA5C_l9hB7Z1dOjAOLUmMd5FQX2UzZDJSs3RgGpo4.jpg?auto=webp&s=82c281eaeda26b82163235099a3947d38685a96f"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxvsnw/strategy_for_backing_up_vaultwarden_database/",
          "author": null,
          "description": "I have managed to set up a selfhosted Vaultwarden instance on my Proxmox server. Now, what is the best way to take regular encrypted backups of my vault? So, in case I lose my instance, my vault could be restored in another Vaultwarden instance or temporarily in a bitwarden account?\n    submitted by    /u/fredflintstone88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxvsnw/strategy_for_backing_up_vaultwarden_database/",
          "publishedOn": "2022-12-29T04:35:06.000Z",
          "wordCount": 21073,
          "title": "Strategy for backing up Vaultwarden database?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxpn5j/unable_to_connect_to_selfhosted_minecraft_server/",
          "author": null,
          "description": "Hello, today I attempted to host my own minecraft server on my router so I wouldn't have to pay for one as I was under the asssumption this would be easy. It was not.\n What is strange is that I was able to connect 1 time with no issues and then never again.\n When I attempt to connect with my public IP address I get the error \"Connection timed out: no further information.\"\n When I attempt to connect with \"localhost\" I get the error \"Connection refused: no further information\"\n To my knowledge have set up my port forwarding properly with the proper IPv4 address, type (TCP/UDP) and start & end port.\n I have the most updated versions of Java\n I have enabled the setting “Enable the operating system’s restricted environment” in the Java Control Panel Advanced Settings\n I have changed my network settings\n I tried a network reset\n I restarted my computer & router many times\n I have allowed Java through my firewall (I even attempted to connect with Windows Defender disabled and it still didn't work)\n I feel as if I could have possibly made a mistake when port forwarding as I do not have much knowledge on the subject but I am pretty confident that I set it up correctly.\n Please let me know if there is a possible solution. Thank you.\n    submitted by    /u/vxah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxpn5j/unable_to_connect_to_selfhosted_minecraft_server/",
          "publishedOn": "2022-12-29T00:06:57.000Z",
          "wordCount": 20063,
          "title": "Unable to connect to self-hosted minecraft server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxp19h/considering_switch_to_self_hosted_music_plexamp/",
          "author": null,
          "description": "I'd like to switch away from paid Google music but I'm not sure if I'll be happy with not having instant access to whatever I want as well as no easy way to discover new music.\n My typical way I listen is on the curated radio playlists that are automatically created. \n Is there a self hosted equivalent to this?\n    submitted by    /u/MeYaj1111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxp19h/considering_switch_to_self_hosted_music_plexamp/",
          "publishedOn": "2022-12-28T23:43:02.000Z",
          "wordCount": 20809,
          "title": "Considering switch to self hosted music (Plexamp). What are our options for new music discovery?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxnqsf/is_there_a_spot_because_i_was_told_not_to_ask_to/",
          "author": null,
          "description": "I pretty much summed up the question in the title; I'm available tonight - and then not again until next Tuesday. I'd love to have some of this configuration understood at least so I can work on it. I primarily want to know how others are managing it; as from what I can gather it will be primarily config document based, but I am wanting to encompass a rather large amount of subdomains.\n I am available only tonight; else I'll take down the post.\n ramble ramble; I just don't want to say it all here, so, I ask to ask (while that's not wanted).\n edit: link to prior post for context, but I am really either way with Traefic or Caddy2; I really just need the metrics and ease of keycloak. https://www.reddit.com/r/selfhosted/comments/zwya8g/hoping_to_connect_with_someone_who_is_comfortable/\n    submitted by    /u/Fimeg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxnqsf/is_there_a_spot_because_i_was_told_not_to_ask_to/",
          "publishedOn": "2022-12-28T22:52:40.000Z",
          "wordCount": 20596,
          "title": "Is there a spot (because I was told not to ask to ask) where I could commission someone who knows Traefic (particularly how to add a non-docker reverse proxy) for a small bit of assistance for some beer money (as this is OUR hobby)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxn5v7/to_virtualize_truenas_or_not/",
          "author": null,
          "description": "Good day everyone,\n I have been running truenas core on bare metal for quite some time now, however for multiple reasons I wanted to see what people’s opinion were about running it on a proxmox vm. \n I recently came into possession of a fairly powerful server and am thinking about changing how my home infrastructure is run. \n Any or all input would be appreciated, thanks!\n    submitted by    /u/cnrdvdsmt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxn5v7/to_virtualize_truenas_or_not/",
          "publishedOn": "2022-12-28T22:30:13.000Z",
          "wordCount": 20030,
          "title": "To virtualize truenas or not",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxmmme/thoughts_on_new_setup/",
          "author": null,
          "description": "Gday all. It’s time for a rebuild of things, so I thought I’d sit down and hammer this all out, and started questioning the path forward. Wanted to know your suggestions, and thoughts on it.\n Up until now, things have been a mix of HyperV, which I want to move away from, and into Proxmox. Proxmox has been great for me, but sometimes doesn’t feel like the right fit for me. I generally run about 6-8 little servers, and feel like im pounding my head against the wall setting up LXC containers or even full out VM’s and compiling or installing programs from scratch when there is a docker/podman alternative sitting there waiting for me.\n I started playing a bit with the Turnkey machines in Proxmox, and while it worked, there seemed to be some issues with a few of the images, and googling around, others have some full on hate for them, so maybe thats not where I want to spend my time either.\n So I go back to maybe I should dabble (never have) in Docker or Podman. Ok…but in that case, I will need to manage a base OS. What does everyone do here? One comment I saw was running Proxmox, and then a VM inside that runs Docker…which just seems weird to me, but maybe thats ok?\n Where should I spend my time learning here? Open to suggestions\n    submitted by    /u/jdlnewborn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxmmme/thoughts_on_new_setup/",
          "publishedOn": "2022-12-28T22:09:36.000Z",
          "wordCount": 21109,
          "title": "Thoughts on new setup.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxl9d4/selfhosting_gitea_with_ssh_support_on_port_22/",
          "author": null,
          "description": "I have a self-hosted domain, let's say mydomain.com\n I have port forwarding setup so that I can ssh to mydomain.com\n On the same server hosting that domain is a gitea instance. I want to enable ssh cloning, but I would like it to be on port 22 also so that the clones aren't cluttered with non-standard ports.\n But it looks like when I attempt to clone I get:\n Cloning into 'repo': git@mydomain.com: Permission denied (publickey)\n I have verified that my ssh keys in gitea are correct and valid. I think maybe it's because git clone is just hitting port 22 and that may or may not hit gitea or the native ssh port?\n Is it possible to run both services on port 22 in this way?\n    submitted by    /u/DickCamera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxl9d4/selfhosting_gitea_with_ssh_support_on_port_22/",
          "publishedOn": "2022-12-28T21:16:20.000Z",
          "wordCount": 20074,
          "title": "Self-hosting gitea with ssh support on port 22",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxl5d9/which_vps_provider_are_you_using_if_any/",
          "author": null,
          "description": "Hi everyone, \n I'm hosting all my services in a DigitalOcean droplet for the past three years and was using an $12/month droplet with 1vCPU and 2GB RAM. However lately I tried to add new self hosted stuff to my stack and the I need more memory.\n I tried to upgrade to 2vCPU 4GB RAM instances and they cost $24-28/month.\n My questions is, do you use these cloud VPS providers, if so, which ones do you recommend? I'd love to host the services in my machine, but this is too convenient for me for the time being, but rather costly.\n    submitted by    /u/redditguy486  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxl5d9/which_vps_provider_are_you_using_if_any/",
          "publishedOn": "2022-12-28T21:11:58.000Z",
          "wordCount": 22111,
          "title": "Which VPS provider are you using (if any)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxis5z/oci_support_for_ptr_record_vs_me/",
          "author": null,
          "description": "Current score: Brian -4, OCI +1000.\n I spun up a new tenancy in OCI with a single host in the free tier (Ampere 4 CPU, 24GB RAM) to host a mail server for my domain. I have no problem configuring my own DNS records via Cloudflare. It was working just fine with Vultr, but I wanted to try OCI and hey, it's free. With Vultr I was able to configure my reverse PTR record for my external IP (Vultr owned) in my dashboard. It worked great.\n With OCI I submitted a limits request to get TCP/25 inbound unblocked. No problem. Now I need to submit a support request to get a PTR record configured for my OCI owned external IP and I'm hitting nothing but assholes and brick walls. I've tried to submit my support request via the OCI portal about a million times. It tells me I have to provision my support account. Entering my information in that screen tells me that I need to go to support.oracle.com to submit a request for my account admin to authorize my account to submit a ticket. It provides me with my Customer Support ID that I need to provide as well. When I go to support.oracle.com to submit that request to myself it won't accept my CSI that was provided to me by the cloud portal. (The same number found under the tenancy details) The error says my CSI is not valid or doesn't allow registration.\n I've called support for help, one person told me that I need to talk to sales. Another person told me that my support account hasn't been provisioned yet. I left a message for sales who just got back to me telling me to talk to my sales rep. I don't have a sales rep. I don't need guidance on finding my CSI. I just need a human being to pay attention to what I'm saying long enough to understand the issue at hand. \n Any ideas from the group here? I'm about out of ideas to try and get this figured out.\n    submitted by    /u/curlybrian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxis5z/oci_support_for_ptr_record_vs_me/",
          "publishedOn": "2022-12-28T19:39:31.000Z",
          "wordCount": 20932,
          "title": "OCI Support for PTR record vs me",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxia7c/kodi_via_vpn_vs_plexjellyfin/",
          "author": null,
          "description": "At the moment, my house has a NAS set up (QNAP TS-453D) and Kodi streaming on our TV, with no special media software running on the NAS. Just Kodi accessing the shared files. I also various services set up (portainer, home assistant, transmission, etc) on the local network, but nothing is accessible from outside the network because I just wanted to keep things simple.\n My girlfriend wants to be able to access our videos while travelling, however, and specifically asked if we could set up a Plex server. I'm not sure if it'd be worth the trouble to set up just for the occasions when we're travelling (which is usually to see friends and family, but sometimes while doing that we want to watch movies from our NAS together - right now we just copy those movies to her laptop in advance).\n I figure I could just set up a local VPN server (wireguard?) on the NAS so we can tunnel into the local network and use Kodi to play files that way. But, I'm curious, is there any advantage (or disadvantage) to using Plex remote play instead, or setting up Jellyfin? Would it be more/less secure? Easier/harder to set up? Provide better/worse video quality or performance? Anything else I should know?\n Thanks!\n    submitted by    /u/AuthorX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxia7c/kodi_via_vpn_vs_plexjellyfin/",
          "publishedOn": "2022-12-28T19:20:08.000Z",
          "wordCount": 19488,
          "title": "Kodi via VPN vs Plex/Jellyfin?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxi5dy/questions_about_virtualization_simplicity_and/",
          "author": null,
          "description": "tl;dr: what are best practices or tips simplicity and security wise for running many vs fewer Containers for many services on a single machine?\n ​\n Hi,\n some months ago I started self-hosting some things on my home server (a simple PC with an Intel i3 10th Gen. (4 x 3.7 GHz), 8 GB RAM, 256 GB SSD, external HDD).\n The hosted services include Nextcloud, Gitea, a Minecraft-Server, Vaultwarden, Heimdall, WikiJS, and NGINX as a reverse proxy, many of them as Docker Containers.\n I just tried things out, followed tutorials, and \"hacked\" the things together without thinking too much about the overall structure of my build.\n Now that I have quite some services running I'm thinking about the pros and cons of different methods of running these things. Right now I have Proxmox installed on the server and one LXC for each single service (so e.g. 5 LXC's for 5 services) that I'm running, thinking that if I \"destroy\" one Container, the rest will be still intact, so I don't have to repair too much.\n What do you think are good ways to host the services? One LXC with Docker and all the Docker-based services on that single LXC? Or rather one service per LXC like I do right now, although that means I have to create an LXC, install Docker, ... for every single service? What about security? Is more virtualization really more secure or just more work?\n Personally I don't think VMs are a good choice for me because of resource constraints. That's why I use LXCs.\n I know there might not be the one right way to do it, but I'd like to get some insights so I can make an informed decision.\n ​\n Thanks :)\n    submitted by    /u/Grumpy_Refrigerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxi5dy/questions_about_virtualization_simplicity_and/",
          "publishedOn": "2022-12-28T19:15:03.000Z",
          "wordCount": 21993,
          "title": "Questions about virtualization, simplicity, and security",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxhm02/is_this_setup_secure/",
          "author": null,
          "description": "So I have my server at my house using tailscale lets say its tailscale ip is 2.2.2.2\n I have my a record for my domain pointing to 2.2.2.2 which is then getting caught by nginx proxmanager and pointing portainer.mydomain.cloud to 2.2.2.2:9443 \n ​\n I only am going to use it for services that cant work well with cloudflare tunnels, and makes my family be on the tailscale vpn to access it. With vpn off and it pointing to the tailscale IP of my server it just gives you an error page. Any issues doing it this way?\n    submitted by    /u/Fission455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxhm02/is_this_setup_secure/",
          "publishedOn": "2022-12-28T18:54:06.000Z",
          "wordCount": 20271,
          "title": "Is this setup secure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxfqgl/if_you_have_a_fritzbox_you_can_easily_monitor/",
          "author": null,
          "description": "Hi everyone!\n Some weeks ago I discovered (maybe from a dashboard posted here?) ntopng: a self-hosted network monitor tool.\n Ideally these systems work by listening on a \"mirrored port\" on the switch, but mine doesn't have a mirrored port, so I configured the system in another way: ntopng listens on some packet-capture files grabbed as streams from my Fritz!Box.\n Since mirrored ports are very uncommon on home routers but Fritz!Boxes are quite popular, I've written a short post on my process, including all the needed configuration/docker-compose/etc, so if any of you has the same setup and wants to quickly try it out, you can within minutes :)\n Thinking it would be beneficial to the community, I posted it here.\n    submitted by    /u/idkorange  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxfqgl/if_you_have_a_fritzbox_you_can_easily_monitor/",
          "publishedOn": "2022-12-28T17:41:02.000Z",
          "wordCount": 22435,
          "title": "If you have a Fritz!Box you can easily monitor your network's traffic with ntopng",
          "imageUrl": "https://external-preview.redd.it/Pl5nCWaC51iwNCt7P52YxcqNK30X2Yedyg_KzwBrB-8.jpg?auto=webp&s=2492e99926741813b443a5aea7c7951e178643fb"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxf4ns/is_it_possible_to_enable_tls_without_a_domain/",
          "author": null,
          "description": "I’m slowly growing my homelab and I’m keeping everything private on my own network. This works great. I have a custom DNS record at the router level that I can use. I would like to start branching out and enabling https. However my understanding is that to get a cert from a CA this would require some of my information to be publicly exposed. I would like to avoid this. The only way I use my self hosted apps from my homelab are via my home network or by tunneling into my network via a vpn or tailscale. Any suggestions on how I can achieve this without exposing my info to the public?\n I understand that this might not be possible, but thanks in advance\n    submitted by    /u/throwawayacc201711  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxf4ns/is_it_possible_to_enable_tls_without_a_domain/",
          "publishedOn": "2022-12-28T17:17:15.000Z",
          "wordCount": 19020,
          "title": "Is it possible to enable TLS without a domain?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxf44y/orb_v016_has_been_released/",
          "author": null,
          "description": "Version 0.16 of the free and open source web desktop Orb has been released. Orb simulates a Windows-like desktop in a web browser. You can use it to access files on a server or a NAS in an easy and secure way. It uses jQuery, Bootstrap and a PHP backend.\n With the release of the previous version, you asked for a code editor. So, a code editor is what you get. It's built with the Ace editor, so it has code highlighting, themes, auto indent, validation checks and other code editing stuff.\n This version also allows users to have their own static website and change their password.\n Download at Gitlab or try the online demo. \n Orb v0.16\n    submitted by    /u/Shendryl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxf44y/orb_v016_has_been_released/",
          "publishedOn": "2022-12-28T17:16:40.000Z",
          "wordCount": 19279,
          "title": "Orb v0.16 has been released",
          "imageUrl": "https://external-preview.redd.it/wajxetWeTxMdfvPC89VcILkUpEEeO6SQzCpTDSIKMBo.jpg?auto=webp&s=5c8c335085e1dd04a09eea8c0462bc24821dc947"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxe8gb/how_do_you_expose_some_of_your_services_to_the/",
          "author": null,
          "description": "I currently have about 30 services running on my small homeserver. When i access them from outside of my home network, i use my Wireguard VPN. None of the services is exposed to the internet at the moment.\n Now i would like expose some of my services (like Nextcloud, Jellyfin, Jellyseerr, Vaultwarden, ...), so that my family and some friends can use them without using a VPN on their devices.\n All my services are currently behind a Traefik Reverse Proxy. My initial idea was to use an IPWhiteList for all services that i don't want to be accessible from the internet, so that only local IP-adresses and the VPN subnet would be on the whitelist. I assume i could do something similar with Authelia and increase security a bit by using 2FA.\n What other tools or approaches (CrowdSec?, Fail2ban?, Cloudflare Tunnels?, ...) do you recommend when exposing a subnet of services to the public internet?\n    submitted by    /u/Torrew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxe8gb/how_do_you_expose_some_of_your_services_to_the/",
          "publishedOn": "2022-12-28T16:42:04.000Z",
          "wordCount": 22678,
          "title": "How do you expose some of your services to the internet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxct0n/access_home_server_via_wireguard_or_any_other/",
          "author": null,
          "description": "Hello guys,\n my goal is to publish my home server (which mainly includes some applications running on docker compose)\n I have been researching about this topic and I came across few possibilities\n  \nSelf hosted gateway (the issue is that tunnels are established for each application). I was not able to publish only my Nginx Proxy Manager which would route traffic towards local containers.\n  \n2)Netmaker... I wasn't really able to understand how it works\n 3) Any easy method via Wireguard? Like a connection initiated from the client side (home server) towards a VPS?\n Note: I am aiming for a free open source self hosted solution (FOSS)\n Thanks\n    submitted by    /u/Geek77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxct0n/access_home_server_via_wireguard_or_any_other/",
          "publishedOn": "2022-12-28T15:45:16.000Z",
          "wordCount": 20633,
          "title": "Access Home Server via Wireguard or any other alternative (CGNAT)",
          "imageUrl": "https://external-preview.redd.it/rN1XMXtbLAJQHbQFM8Cq4EXVUadpO48dlcIp9IDts-0.jpg?auto=webp&s=c4b70b1f4b1a2205b0ddd69e306e9b487ae97c53"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxbzef/alternatives_to_boxcryptor_for_predominantly/",
          "author": null,
          "description": "I currently use BoxCryptor to manage my files on a local NAS (Synology DS918+). Given Boxcryptor is shutting down since they have sold their tech assets to Dropbox, so I'm having to move to a new platform. I've got some prior experience with Cryptomator which has been OK, but not entirely positive - albeit it was a few years ago.\n Key considerations:\n  \nMacOS (M1) is my main machine and I would like good filesystem integration - I currently use Forklift alongside Finder.\n I only need remote access, no local mirroring, no sync. Ability to selectively mark files to be mirrored locally on my laptop would be a bonus.\n Approx 15tb data - files from 1kb to 25gb.\n Ability to search, see thumbnails, doc previews etc across the encrypted share.\n 90% of my data will be on the Synology, but I will also use some remote cloud storage - integration with such services is a plus.\n Versioning and such a further plus.\n  \nIn doing a bit of reading around the topic, it seems that installing something on the Synology itself is an option - for example, there seems to be a NextCloud docker image and I believe I can access Nextcloud via WebDav through Finder/Forklift. However similarly, I've not always had great performance with web-dav and I'm not sure if will let me index/search/preview files efficiently.\n Grateful for any suggestions. \n I have a MountainDuck license should that be a relevant part of the solution.\n Thanks!\n    submitted by    /u/ReadyJeff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxbzef/alternatives_to_boxcryptor_for_predominantly/",
          "publishedOn": "2022-12-28T15:12:29.000Z",
          "wordCount": 20167,
          "title": "Alternatives to BoxCryptor for predominantly local NAS storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxa71s/how_to_setup_a_reverse_proxy_only_for_lan/",
          "author": null,
          "description": "Ive been googling around for more than an hour but am still not sure how to do this.\n I don’t really want to expose any of my services to the internet. Maybe someday I will, but for now only I use them and I would rather VPN in everytime instead of exposing anything to the outside.\n The main reason why I even want to setup a reverse proxy is because vaultwarden only works when I have one because it needs HTTPS. Also its great if all of my services use https, even if my only point of entry is my VPN and no one should be able to access them anyways. Don’t worry, I don’t plan on actually using vaultwarden until Im sure everything’s secure.\n But whenever I find guides or questions about making a local reverse proxy, people still talk about me needing a (bought) domain. Why do I still need one when I am local anyways? \n I would like to do either of this, preferring the latter. 1. Enter my IP with the specific services port and just be redirected so https is used 2. Enter a domain like jellyfin.example.local and I get redirected to the ip:port for that specific subdomain. Surely it is possible to „make up“ a domain and tell whatever resolves domains at the lowest level to redirect this to a specific ip:port? Maybe this also isnt possible, thats why I am asking.\n Thanks in advance for any help!\n    submitted by    /u/Generic_User48579  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxa71s/how_to_setup_a_reverse_proxy_only_for_lan/",
          "publishedOn": "2022-12-28T13:56:56.000Z",
          "wordCount": 21385,
          "title": "How to setup a reverse proxy only for Lan?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zxa5q7/fundock_a_simple_faas/",
          "author": null,
          "description": "I was looking for a FaaS (function-as-a-service, like AWS Lambda) to host on my home server, but I found the popular options to be either complex or require Kubernetes. So, I decided to make my own.\n This is in very initial stages. Currently, it only has a web interface (without authentication), which allows you to register functions and invoke them from the web UI (including providing input to it). There is a brief demo on the Github page. I have also included a docker-compose.yml to make it easier to try out. Also, I have only written 1 (example) function so far.\n Link: https://github.com/sparkymat/fundock\n I'd love for people to try it out and give me some feedback. Some of my top priorities currently include:\n  \nAdd API for registering and invoking functions (authenticated using long-lived API tokens)\n Asynchronous execution (and post-execution web hook)\n Terminate containers after timeout\n Some form of concurrent execution limit\n Ability to disable/delete functions\n  \n   submitted by    /u/foobarlivesmatter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zxa5q7/fundock_a_simple_faas/",
          "publishedOn": "2022-12-28T13:55:14.000Z",
          "wordCount": 20494,
          "title": "fundock - a simple FaaS",
          "imageUrl": "https://external-preview.redd.it/3gMlUsJ0VxosbNJl9i6AM5Aztwn7qvyOaK1kexoTiqc.jpg?auto=webp&s=316e023b1a68fec6c3a4b5c918f139c74a870a4c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zx9qp1/singleboard_computer_with_builtin_ipmi/",
          "author": null,
          "description": "Hi, I'm looking into building a low power baremetal server for a few unicorn use cases at my place. Nothing too demanding, but I'd like (need) for this machine to have some out-of-band management capabilities.\n I'm was thinking of trying to find some mini-ITX motherboard (nothing in mind yet), but was wondering if any single-board computer, à la Raspberry Pi, would exist for such an use case on the market. Would you know of any company selling a single-board computer with built-in IPMI (remote power on/off, remote view, kb/m, mounting ISO / USD…)?\n Thanks,\n    submitted by    /u/TheWildPastisDude82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zx9qp1/singleboard_computer_with_builtin_ipmi/",
          "publishedOn": "2022-12-28T13:35:45.000Z",
          "wordCount": 19707,
          "title": "Single-board computer with built-in IPMI functionalities",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zx921r/server_upgrade_should_i_go_xeon/",
          "author": null,
          "description": "I have a old \"server\" with OVH, it's a i5-2400. It has served me well, but it's single 2TB spinner , 16gb ram and CPU are now being a problem.\n I was thinking of upgrading to one of those Kimsufi dedicated servers, either a E3-1231v3 or a E5-1620v2.\n Issue is, those CPUs don't have Quicksync. How much of a problem will that be for transcoding ? It's mostly 1/2 1080p streams at a time, usually h264 (since the i5 doesn't support h265).\n Would you advise against such cpu for this kind of tasks ?\n In the end i will be using Proxmox, with Deluge, the Arrsuite, mailcow and few more apps here and there.\n    submitted by    /u/daedric  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zx921r/server_upgrade_should_i_go_xeon/",
          "publishedOn": "2022-12-28T13:02:57.000Z",
          "wordCount": 21033,
          "title": "Server upgrade: should i go Xeon ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zx7yea/is_there_a_selfhosted_software_for_hifi_music/",
          "author": null,
          "description": "Hello there.\n I'm currently using Tidal as my music app on my phone and my pc. I like it because it allows me to stream high quality music to my phone, my pc, and my car with android auto, and it allows me to chromecast to my smart speaker.\n What I don't like is its limited library. I would like to listen to my CD-ripped music.\n I would like to avoid to pay a monthly fee and instead buy CDs and high quality music online, like qobuz.\n So I was wondering if there is a server software to run on my Raspberry Pi 4, that allows me to play music the way I do with Tidal?\n I've found something interesting in \"mStream\", but it lacks of the chromecast functionality.\n Do you have any experience with this? What do you use for high quality music streaming?\n    submitted by    /u/chicowolf_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zx7yea/is_there_a_selfhosted_software_for_hifi_music/",
          "publishedOn": "2022-12-28T12:06:26.000Z",
          "wordCount": 22237,
          "title": "Is there a self-hosted software for hifi music streaming?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zx5ztb/automatically_stop_containers_when_not_in_use/",
          "author": null,
          "description": "Is there any tool which would do the task mentioned below, \n 1) Let us say that i am having a personal notes taking web app, when there is no request came to the site for a particular time the container should be stopped.\n 2) when the container is stopped and a request came to the web app automatically the container should be started.\n Solved:) Overall Conclusion:\n Container Nursery, this project helped me to achieve my requirement. Thanks to the community for all valuable suggestions.\n I need this kind of solution since i am self hosting multiple web apps with only 6GB of RAM.\n    submitted by    /u/SivaMst  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zx5ztb/automatically_stop_containers_when_not_in_use/",
          "publishedOn": "2022-12-28T10:07:43.000Z",
          "wordCount": 20759,
          "title": "Automatically Stop containers when not in use.",
          "imageUrl": "https://external-preview.redd.it/dxVOx_1nVoPCzE6YtqAPT7EE_2XUu4DexxqTA0dzDtg.jpg?auto=webp&s=934e768a67127fb2fde8f3faa30546a0fcc505bf"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zx29hv/iaac_through_cloudflare_zero_trust_proxmox/",
          "author": null,
          "description": "Hi.\n I started building my homelab the way I can provision all stuff from one place.\n The part I am proud of:\n Right now I manage docker mule with ansible. Traefik and dashboard is autopopulated with labels ( homepage is great, ansible-nas is sometimes outdated but can be easily fixed ) . \n Pihole works as conditional DNS in this setup to provide internal domain resolution for services (alongside with traefik as internal proxy too) \n The part I am struggle with (right now): \n I have to set up public hostname manually for every external service. (Via Cloudflare zero trust dashboard) Looking for a advice how to add those automagically. How to tell cloudflared docker container to push new services if needed. Or I got this idea wrong\n ​\n The part I have to have done in next iterations:\n  \nPopulate pihole local dns automagically based on xxx_available_internally var in ansible-nas (this should not be that hard except for putting lot of code for every single service)\n Git gud with virtualisation idea (how to proper set up resources for VM because right now its by trial and mostly errors)\n Set up proxmox, and those VM's with code (I still trying to avoid rewrite everything to terraform) \n Automate generating/provisioning api keys for services I would like to have widget in homepage dashboard \n Prepare backup plan\n Publish code\n Add UPS and resolve hdd fan issue on host (HP Elitedesk 800 g2 mini 65w, i5-6500, 8GB, 512GB ssd)\n Think about android phones ignore DHCP settings for DNS (or maybe its just Brave browser)\n  \n​\n Idea of what I am trying to achieve?\n    submitted by    /u/kamilloi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zx29hv/iaac_through_cloudflare_zero_trust_proxmox/",
          "publishedOn": "2022-12-28T06:16:19.000Z",
          "wordCount": 23513,
          "title": "IaaC through Cloudflare Zero trust, proxmox, traefik and pihole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zww23t/a_remote_media_server_an_alternative_to_plex/",
          "author": null,
          "description": "I have a \"server\" with about 30 TB of storage that is placed at my mom's house, that runs win11, and a plex server. I watch my content recently via Infuse on my Apple TV and everything is working well. But I kinda wanna remove plex from my setup, since it feels kinda redundant, and I don't like the way they are heading. \n I'm somewhat tech savvy, but above all I just want my setup to be reliable and work all the time. Hence why I have gone with just win11 and plex, since that is something I find myself extremely comfortable with. \n Do you guys have some suggestions on how I can improve my setup? Windows 11 tends to update from time to time and get stuck on the \"setup screen\" which causes some annoyance, and plex just feels redundant now and more like someone snooping on anything I do more than anything else since Infuse is serving the FE. Any answers or input is greatly appreciated\n    submitted by    /u/Pat-Roner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zww23t/a_remote_media_server_an_alternative_to_plex/",
          "publishedOn": "2022-12-28T01:08:45.000Z",
          "wordCount": 20442,
          "title": "A Remote Media Server - An Alternative to Plex?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwveso/need_help_setting_up_a_website/",
          "author": null,
          "description": "I have Verizon FiOS internet (w/ a Verizon router) with a dedicated server to run what I'd want at home. Ideally I'd like to have a bitwarden (vaultwarden actually) instance, a nextcloud instance, and maybe 1-2 other things like that. How would I go about this? I've been trying for hours all day today to figure this out but I'm losing my shit since I do not ever deal w/ web stuff and hate it. \n Note: I am quite an experienced programmer and know my way around Linux very well, but this shit is bonkers to me. So, please help me out! And yes, a docker container w/ nginx running on ports 80/443 (https please!) would be ideal. I also have a lot of ports forwarding to my home server, including 80 and 443. I have DNS records with cloudflare's free tier pointing to my home ip but it **never** goes to my damn server itself. It either fails or goes to the router's page. Thanks for the help/advice!!\n    submitted by    /u/gottagetthatdlore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwveso/need_help_setting_up_a_website/",
          "publishedOn": "2022-12-28T00:39:42.000Z",
          "wordCount": 19778,
          "title": "Need help setting up a website",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwuwq2/starwind_san_and_nas_free/",
          "author": null,
          "description": "Anyone here use it? How does it compare to omv unraid rockstor and truenas?\n I’m looking for something like unraid with the apps and btrfs but free without having to configure something and hope for the best if there is a failure.\n    submitted by    /u/Steeler_Train  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwuwq2/starwind_san_and_nas_free/",
          "publishedOn": "2022-12-28T00:17:51.000Z",
          "wordCount": 19522,
          "title": "Starwind San and nas free",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwujqv/windows_server_album_creator/",
          "author": null,
          "description": "I'm looking for something to host via windows, something that will only be accessed via the LAN. I'm just looking for something that is similar to the Android album system, where I can categorize my images/videos and add custom tags to them and if needed just view them all in something like \"View All\" not really needed but would be cool.\n Not sure if there's anything like this out there for Windows, I haven't really been messing around with it much compared to Ubuntu, which is hosting other stuff for me. And I have space on Windows. :) \n Any help would be greatly appreciated. <3\n ~Blood\n    submitted by    /u/bloodshotpico  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwujqv/windows_server_album_creator/",
          "publishedOn": "2022-12-28T00:02:14.000Z",
          "wordCount": 19644,
          "title": "Windows Server - Album Creator?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwsvbq/trying_to_see_an_option_to_self_host_my_gaming/",
          "author": null,
          "description": "I'm using playnite to centralize my gaming library.\n I was wondering if there's a way to host the games on a server so I can have access to them or when I want to play remotely.\n Does anyone have any experience with such an endeavor?\n    submitted by    /u/Nightchanger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwsvbq/trying_to_see_an_option_to_self_host_my_gaming/",
          "publishedOn": "2022-12-27T22:53:13.000Z",
          "wordCount": 19139,
          "title": "Trying to see an option to self host my gaming library.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwse5j/an_app_that_checks_reddit_fb_marketplace_ebay_etc/",
          "author": null,
          "description": "So the concept is really simple I just don't know the name of it. I am a part of a couple buy/sell subreddits as well as FB and eBay and such and I wanted a little server of sorts that pulls info from these different sources with my parameters and just kind of scrolls it out into a simple ongoing live feed I can reference at any point. I basically want to be able to be on top of new posts as soon as they hit. \n Anything like that exist? What I envision is basically like a chat room except it's reddit posts, FB Marketplace posts and eBay posts. Have it running on a separate monitor, on the TV, while I take a shit, anywhere in the house if I like. Or even like a stock ticker display!\n    submitted by    /u/ronmfnjeremy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwse5j/an_app_that_checks_reddit_fb_marketplace_ebay_etc/",
          "publishedOn": "2022-12-27T22:34:16.000Z",
          "wordCount": 20095,
          "title": "An app that checks Reddit, FB Marketplace, Ebay etc for new posts and outputs it to somewhere.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwrh4p/selfhosting_friendly_mesh_wifi_systems/",
          "author": null,
          "description": "Kind of a mixed bag topic, but figured I'd ask - does anyone have recommendations for a mesh WiFi system (preferably WiFi 6/6e capable) that is friendly towards self hosters? What I mean by that is either DD-WRT can be installed on it, or the interface allows for an appropriate level of tweaking (opening/forwarding ports, DDNS, etc.)?\n Budget is up to $300 but can do more if a product absolutely ticks every box, coverage area is a 2-floor 2500 sqft house and a few wireless cameras on the corners of the house, and I'd not mind having a wired backhaul for each puck. Total device count right now is just shy of 50, with only 10 of those permanently wired and the rest WiFi. Device count may increase to as many as 75 once I replace some WiFi light bulbs and my girlfriend moves in with me in a few months.\n Some nice-to-haves would be:\n  \nCompatible with Let's Encrypt for SSL cert on the config page\n WAN accessibility, preferably not dependent on a proprietary app\n Can be configured for DDNS for the self-hosting aspect of things\n I wouldn't mind being able to further modify WiFi-specific settings - antenna-specific transmit power, encryption type (WPA3 would be awesome), etc.\n Guest network is cool, but not a strict requirement\n  \nI'm asking in this sub, as opposed to others, as I'm specifically seeking guidance on the customization/features that self hosters need from their network equipment.\n Appreciate any advice or feedback, thanks!\n    submitted by    /u/radakul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwrh4p/selfhosting_friendly_mesh_wifi_systems/",
          "publishedOn": "2022-12-27T21:58:05.000Z",
          "wordCount": 19243,
          "title": "Self-hosting friendly mesh Wi-Fi systems?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwrdjb/synology_or_something_better/",
          "author": null,
          "description": "I have an old desktop computer that is starting to fail. I currently use it to run a Plex media server and a Milestone surveillance system for 4 cameras. My first thought was to replace the old desktop with a Synology NAS (and switch from Milestone to Synology's Surveillance software) however it looks like the newer Synology devices don't do transcoding as well due to the lack of GPU. Can someone recommend a replacement solution please? I would prefer something smaller than a desktop and relatively quiet.\n    submitted by    /u/Background-Donut6425  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwrdjb/synology_or_something_better/",
          "publishedOn": "2022-12-27T21:54:06.000Z",
          "wordCount": 19921,
          "title": "Synology or something better?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwpxv9/problem_with_self_hosted_rss_feeds_ttrss/",
          "author": null,
          "description": "I'm creating RSS Feeds with RSSHUB but I can't use it on ttrss.\n It says \"Couldn't download the specified URL\"\n But I can use them with Newsblur, Feedly etc.\n What can be the issue?\n Can you help me with that?\n    submitted by    /u/yasirbilgic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwpxv9/problem_with_self_hosted_rss_feeds_ttrss/",
          "publishedOn": "2022-12-27T20:57:04.000Z",
          "wordCount": 18461,
          "title": "Problem With Self Hosted RSS Feeds (ttrss)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwpvmg/deep_dive/",
          "author": null,
          "description": "Anyone else feel like they need to take their lessons learned in Linux programming and apply them to life as of late?\n Mine pertain to setting up a fire wall for shitty people. Lolz\n    submitted by    /u/fArside617  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwpvmg/deep_dive/",
          "publishedOn": "2022-12-27T20:54:31.000Z",
          "wordCount": 19078,
          "title": "Deep dive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwpnde/privacy_on_oracle_cloud_free_tier/",
          "author": null,
          "description": "I never gave much thought to using Oracle Cloud Free Tier as I assumed there were as little resources offered as with AWS/Google Cloud, but recently researched it after reading it a lot on this sub and am now thinking about moving my self-hosting there from Hetzner.\n But, in the past I've read negative things about Oracle privacy-wise, and unlike Hetzner it is not based in the EU (the company not the servers). On Google Cloud I noticed once that it's possible to encrypt your VM with your own encryption keys. Does someone know if something like this is available with Oracle Cloud as well, I didn't quite find anything regarding this.\n    submitted by    /u/Intelligent-Clerk370  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwpnde/privacy_on_oracle_cloud_free_tier/",
          "publishedOn": "2022-12-27T20:45:16.000Z",
          "wordCount": 25506,
          "title": "Privacy on Oracle Cloud Free Tier",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwpgte/looking_for_the_right_email_product/",
          "author": null,
          "description": "I am looking for a way to have email at my domain. The requirements are must be less than $5 a month for the relay or service. Must have a customizable login page that I can have at mail.mydomain.com. Must have a mobile client as I am going to migrate my wife to this as well. I am currently using zoho mail and it's perfect in every way for free except the login page issue. I will probably only have three emails using this at first but will have more down the line so a good user limit would be nice. Please let me know of any if you all can this group is killer for this focus grouped information. Thanks ahead for any responses!\n    submitted by    /u/Squanchy2112  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwpgte/looking_for_the_right_email_product/",
          "publishedOn": "2022-12-27T20:38:03.000Z",
          "wordCount": 17338,
          "title": "Looking for the right email product.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwp352/need_help_to_map_windows_drive_in_docker_compose/",
          "author": null,
          "description": "I am very new to self hosting and docker. I have a windows machine at home which has couple of drives attached to it and running win11. I am using it to self host. already installed jellyfin on it and its working great and was able to sync my videos, now i am trying to install a photo viewer for all the photos i have. I have tried few options like, photoviewer, piwigo, photoprsim but the only issue i have is how to map my drives so these software's can read them in album. \n Eg: how to map C:/Home/Users/Name/Pictures to map in piwigo so all my albums i can see in app and web interface. I have tried watching some videos on docker volume mounts but not getting hang of it yet.\n ​\n I am also looking at Immich as my backup self host software and its looking great.\n    submitted by    /u/Thick-Profit8742  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwp352/need_help_to_map_windows_drive_in_docker_compose/",
          "publishedOn": "2022-12-27T20:22:23.000Z",
          "wordCount": 18892,
          "title": "Need Help to map Windows Drive in docker compose",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwn1my/help_using_cloudflare_tunnel_with_selfhosted/",
          "author": null,
          "description": "I am using WordPress manually installed on a Synology NAS. I also have a bunch of other services I self-host, like radarr, sonarr, VaultWarden, etc. \n For the latter, I have everything set up over CloudFlare tunnels, so I can easily access them via, for example, https://radarr.example.com\n I am trying to get my Wordpress instance to work over tunnels. I want to be able to access Wordpress via, for example, www.example.com/wordpress. I tried tunnelling www.example.com to localhost:80 and this works, but only for the main Apache landing page (that is index.html in the root of my web server). Any Wordpress pages (using the sub folder of /wordpress) otherwise display a local IP rather than example.com/wordpress/some_page.php\n I think there is some nuance I am missing to get this to work. Any help would be much appreciated! Thanks.\n    submitted by    /u/Ok-Snow48  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwn1my/help_using_cloudflare_tunnel_with_selfhosted/",
          "publishedOn": "2022-12-27T18:57:44.000Z",
          "wordCount": 19151,
          "title": "Help using CloudFlare tunnel with self-hosted WordPress instance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwm05d/self_hosted_webbased_diagram_maker/",
          "author": null,
          "description": "I'm looking for something like this https://app.diagrams.net/ that I can self host on a Linux webserver. I do a lot of electrical circuit designing, and network architecture work, and I want piece of mind if my internet goes out, or I need to take diagrams with me remotely. Preferably it would be hosted on a Linux webserver (Apache, NGINX, etc). Does anyone know any good sources? I would really appreciate it!\n    submitted by    /u/iRustock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwm05d/self_hosted_webbased_diagram_maker/",
          "publishedOn": "2022-12-27T18:13:02.000Z",
          "wordCount": 17732,
          "title": "Self hosted web-based diagram maker?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwktf6/should_i_switch_away_from_synology/",
          "author": null,
          "description": "As I get more into selfhosting I have replaced more and more of the Synology Apps I used to use with different selfhosted applications, which I either run directly on the Synology or in docker containers. I use the Synology Apps less and less.\n The positives I have is easy backups and general management of the server. I was thinking about buying another Synology solely as an off-site backup.\n But Im thinking, before I get even more entrenched in the Synology space, should I maybe just get these used enterprise servers or something like that and try to switch away from Synology?\n How hard is it to setup RAID, backup to another remote server, general management of the server, like firewall etc.?\n I am also thinking about upgradeability. I don’t know how much the enterprise servers are upgradeable, but I assume far better than Synologys, where you can only add RAM, and even that is limited.\n    submitted by    /u/Generic_User48579  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwktf6/should_i_switch_away_from_synology/",
          "publishedOn": "2022-12-27T17:22:59.000Z",
          "wordCount": 19625,
          "title": "Should I switch away from Synology?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwjtvl/vpn_provided_static_ip_how_to_set_up_on_router_so/",
          "author": null,
          "description": "​\n Hi guys,\n A bit of a newbie here, so bear with me.\n I'm currently running openvpn on my wrt router and it has been working just fine, but due to my needs of hosting a server at home and accessing it remotely, I have purchased a dedicated IP address from my VPN provider, but I am quite confused on how I am supposed to set it up, they literally only provided the IP address that was assigned to me, is that all I need to configure it? and if so, where do I plug it in, in my .ovpn file somewhere?\n Sorry if it's a dumb question but I cannot find any info on google, maybe I'm googling the wrong words. \n Thanks in advance\n    submitted by    /u/No_Mycologist4938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwjtvl/vpn_provided_static_ip_how_to_set_up_on_router_so/",
          "publishedOn": "2022-12-27T16:41:03.000Z",
          "wordCount": 18427,
          "title": "VPN provided static IP, how to set up on router so server can use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwi3sk/crochet_pattern_storage/",
          "author": null,
          "description": "Is there a crochet- or craft-focused app available? Obviously could use a wiki or ArchiveBox, but I'm wondering if there is something more specialized.\n    submitted by    /u/IAmNotABartender  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwi3sk/crochet_pattern_storage/",
          "publishedOn": "2022-12-27T15:24:42.000Z",
          "wordCount": 19478,
          "title": "Crochet pattern storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwgzbp/what_ip_range_to_use_for_your_services/",
          "author": null,
          "description": "Ive been using 192.168.178.x for everything because it was in the factory settings of my router and I slowly set everything up like this. I would like to change it, and possibly make it simpler. What ranges are good for this? \n I read that avoiding 192.168.x.x altogether is a good idea? \n What to use then? Something like 10.25.50.x? I also like 19.168.50.x but the avoiding 192.168. stops me, also 192.168 is also quite chaos.\n Edit: Thanks everyone! I chose 10.0.50.x, as it suits my purposes for now and is quite simple. If I decide to use VLANs or anything in the future I can expand easily.\n    submitted by    /u/Generic_User48579  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwgzbp/what_ip_range_to_use_for_your_services/",
          "publishedOn": "2022-12-27T14:34:34.000Z",
          "wordCount": 21232,
          "title": "What IP range to use for your services?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwg2gf/selfhosted_alternative_to_dakboard_other_than/",
          "author": null,
          "description": "I'm wondering if there are any decent self-hosted alternatives to DAKBoard. I've tried Smashing but it was a bit of a nuisance having to deploy a new config to the client (a Raspberry Pi) and reload the browser every time I wanted to make a little tweak. It also seems to have been in minimal maintenance mode for a while now, getting only dependency updates and a couple fixes.\n    submitted by    /u/tonygoold  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwg2gf/selfhosted_alternative_to_dakboard_other_than/",
          "publishedOn": "2022-12-27T13:49:40.000Z",
          "wordCount": 18298,
          "title": "Self-hosted alternative to DAKBoard (other than smashing)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwfy9r/bitwarden_selfhosted_instance_lessons_learned/",
          "author": null,
          "description": "After reading of the most recent and particularly unpleasant LastPass data breach (tl;dr: the metadata, like URLs, wasn't encrypted and is now in the hands of lord-knows-who), I decided to move to a self-hosted instance of Bitwarden so that I can keep control of the data and have a bit more peace of mind.\n Bitwarden's on-prem setup instructions are good, if a little brief and lacking in detail, and I got there in the end, but it wasn't an easy deployment. I thought I'd write some lessons I learned on the way to help anyone considering this. Hope this helps someone on the same journey!\n Things to think about before starting\n  \nMost important: think carefully about backups and recovery. We're talking about your own personal crown jewels: the keys to everything you have. All my backups are do…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwfy9r/bitwarden_selfhosted_instance_lessons_learned/",
          "publishedOn": "2022-12-27T13:43:38.000Z",
          "wordCount": 21565,
          "title": "Bitwarden self-hosted instance -- lessons learned",
          "imageUrl": "https://external-preview.redd.it/D1j9qSIkJ89iIX0WIQGIkgivtNPxuBbZqtTyQTHZJWY.jpg?auto=webp&s=c6a0c95f3bf7592e630ae0b23dc5f46e418460ed"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwfwja/hardware_queries/",
          "author": null,
          "description": "Hello Reddit, \n I am currently in India and have been waiting to get my hands on a Raspberry Pi 4 since over a year to starting my self-hosting journey. Sadly, they are never in stock or just been sold at double the normal price. So, I came across this piece of hardware which I found to be more worth than a Raspberry Pi in my country i.e Dell Optiplex 3040 - Core i3 6th gen 3.2ghz, 8 GB ram & 240gb SSD storage(Renewed). \n The things I want to host:-\n -Bitwarden\n -Simplelogin\n -NextCloud\n -Notes\n -PiHole\n -PiVPN\n -5 single page static websites\n -And a few more things I'll come across in my self-hosting journey \n I wanted to know If I could run those on the device mentioned.\n    submitted by    /u/No_Surprise_401  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwfwja/hardware_queries/",
          "publishedOn": "2022-12-27T13:41:10.000Z",
          "wordCount": 19804,
          "title": "Hardware Queries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zwcns3/most_used_selfhosted_services_in_2022/",
          "author": null,
          "description": "As the year comes to a close, I'm curious to know which self-hosted apps Redditors have used the most in 2022 (excluding utility services like reverse proxies or something like Coolify, Dokku, Portainer). So more something like Nextcloud, Rocket.chat, Gitlab.\n For me, i think the five most important were (in alphabetical order) AdGuard Home, Mailcow, Onedev, Paperless, Plausible. They all have their own unique features and benefits. \n Adguard: Adguard Home is a self-hosted ad blocker that can be used to block ads and tracking scripts on your home network. It works by acting as a local DNS server, which allows it to intercept and block requests to known ad and tracking servers before they reach your device. \n Mailcow: Mailcow is a self-hosted mail server that provides a full-featured email solution for small to medium-sized organizations. It includes features such as spam and virus protection, and support for multiple domains. \n Onedev: Onedev is a self-hosted Git repository management platform that includes features for code review, project management, and continuous integration. It is designed to be lightweight and easy to use.\n Paperless: Paperless is a self-hosted document management system that allows you to store, organize, and access your digital documents from anywhere. In 2022 the fork paperless-ngx was released. \n Plausible: Plausible is a self-hosted web analytics platform that provides simple, privacy-friendly tracking for your website. It allows you to see how many people are visiting your site, where they are coming from, and which pages they are viewing.\n What about you? What are your top five self-hosted apps of the year? Were there new ones that you started using in 2022? Share your experiences with them and why you think they stand out from the rest.\n Edit: Forgot AdGuard Home, so swapped it for WordPress.\n    submitted by    /u/ExoWire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zwcns3/most_used_selfhosted_services_in_2022/",
          "publishedOn": "2022-12-27T10:31:48.000Z",
          "wordCount": 25672,
          "title": "Most used selfhosted services in 2022?",
          "imageUrl": "https://external-preview.redd.it/J3MqooxXl3byerNa81yl3k63YGKw0pnqjMgT1EHrQoM.jpg?auto=webp&s=a8fdf9e695984b609e1d7f9234bff9fff57c049b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zw4k2h/what_has_plex_done_lately_that_you_didnt_like/",
          "author": null,
          "description": "Please try and keep the commentary civil and respectful. \n I'm curious as to what Plex has done (or hasn't done) of late that has been frustrating for you? In the interests of fairness if you think Plex are doing a great job, tell us too!\n This is in anticipation of my latest hair-brained scheme, Jellyfin January over at Jupiter Broadcasting! I'll read the best comments from this thread in the next episode of https://selfhosted.show and provide details of the Jellyfin January challenge. Thanks in advance!\n    submitted by    /u/Ironicbadger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zw4k2h/what_has_plex_done_lately_that_you_didnt_like/",
          "publishedOn": "2022-12-27T02:47:30.000Z",
          "wordCount": 20960,
          "title": "What has Plex done lately that you didn't like?",
          "imageUrl": "https://external-preview.redd.it/e8xWzKX8SEKbq_34Jc_GRciGq-Ebw6ZiDwkiKEkun5c.jpg?auto=webp&s=4bc7f80fd8c116fa7f079b8d8578f456dae920ce"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zw0vfd/anonfiles/",
          "author": null,
          "description": "Hey there r/selfhosted 👋 \n We're an anonymous, database-less, pure PHP-based solution for hosting your files online. Suggestions? Bugs? Leave an issue on our GH repo! You may also reply here, if you wish. Anonfiles is built for docker, however for a non-docker installation you are provided with a installer.php file.\n I am ready to answer any question(s) you may have.\n    submitted by    /u/Coolness1234567894  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zw0vfd/anonfiles/",
          "publishedOn": "2022-12-26T23:58:06.000Z",
          "wordCount": 18153,
          "title": "Anonfiles",
          "imageUrl": "https://external-preview.redd.it/tMjLGNuR_tNjvkVs_-5Uc0Fr2-r8nzvnE8YrsxAZnVI.jpg?auto=webp&s=02035603c3118fa32d3e63af676ab4a036d78f85"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zw0l1y/i_have_created_a_self_hosted_job_board_that_uses/",
          "author": null,
          "description": "submitted by    /u/joanmiro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zw0l1y/i_have_created_a_self_hosted_job_board_that_uses/",
          "publishedOn": "2022-12-26T23:45:02.000Z",
          "wordCount": 17622,
          "title": "I have created a self hosted job board that uses airtable. Link is under the video.",
          "imageUrl": "https://external-preview.redd.it/IPX9oNglInVGXQDuH7t-UjGPUhMv0LJQlSS9rFLM1IU.jpg?auto=webp&s=aecb384794109a819978dbe06cb93b4d27c9216d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zw0i1l/alternatives_to_icloud_drive/",
          "author": null,
          "description": "Is there anything similar to iCloud Drive, where it’s synced across devices, yet if I delete it, it’s only removed locally? It's symmetrical syncing, but at the same time it’s not.\n    submitted by    /u/ALCF98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zw0i1l/alternatives_to_icloud_drive/",
          "publishedOn": "2022-12-26T23:41:07.000Z",
          "wordCount": 17345,
          "title": "Alternatives to iCloud Drive.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zw0fdq/does_noip_create_dns_records_for_me_on_inbound/",
          "author": null,
          "description": "Hello. I plan on transferring some of my domains from GoDaddy to NOIP. I read through their FAQ and also the Inbound Domain Transfer page but it does not mention this. Anyone know if they create the DNS records for me automatically? I tried calling their support but apparently they're closed (?).... until JAN 2nd.\n    submitted by    /u/fairbanks142reddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zw0fdq/does_noip_create_dns_records_for_me_on_inbound/",
          "publishedOn": "2022-12-26T23:37:46.000Z",
          "wordCount": 17678,
          "title": "Does NOIP create DNS records for me on inbound domain transfers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvzn00/email_notifications_delivery_with_postfix/",
          "author": null,
          "description": "https://simplycreate.online/update/2022/12/26/postfix_mail.html\n The guide I wish I had when I had my hair pulling out. Posted here for your critique.\n ​\n It's biased towards a Gitlab instance but can be adopted to anything else...\n    submitted by    /u/ntn8888  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvzn00/email_notifications_delivery_with_postfix/",
          "publishedOn": "2022-12-26T23:03:16.000Z",
          "wordCount": 17604,
          "title": "Email notifications delivery with postfix",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvyz3r/paperless_ngx_file_names_of_the_downloaded/",
          "author": null,
          "description": "Hi all, I noticed that although my default file names (from the docker config) are corrspondent_yymmdd (doctor_20220501), and the documents are also stored that way, when exporting (downloading or the eye symbol) a different name is always used. Instead of doctor_20220501_doctor.pdf the downloaded pdf is called 2022-05-01-doctor.pdf. \n Do you have an idea where to set the download document name?\n    submitted by    /u/marneusc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvyz3r/paperless_ngx_file_names_of_the_downloaded/",
          "publishedOn": "2022-12-26T22:34:53.000Z",
          "wordCount": 18436,
          "title": "Paperless ngx - file names of the downloaded documents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvyy48/make_proper_albums_out_of_folder_full_of_mp3s/",
          "author": null,
          "description": "I’m not sure if this is possible, but i have a load of random mp3 files in a directory and was wondering if there was an app/program out there that could sort them into proper off the shelf type albums (or as close to full albums as possible) ? I couldn’t see this capability within Beets, but maybe someone knows of something out there.\n    submitted by    /u/parkercp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvyy48/make_proper_albums_out_of_folder_full_of_mp3s/",
          "publishedOn": "2022-12-26T22:33:42.000Z",
          "wordCount": 17841,
          "title": "Make proper albums out of folder full of MP3s",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvyxel/first_forgejo_monthly_update_december_2022/",
          "author": null,
          "description": "submitted by    /u/testus_maximus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvyxel/first_forgejo_monthly_update_december_2022/",
          "publishedOn": "2022-12-26T22:32:49.000Z",
          "wordCount": 17286,
          "title": "First forgejo monthly update - December 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvxv54/incoming_email_ticketing_system_options/",
          "author": null,
          "description": "Im looking for some suggestions for an email ticketing system. I have looked on here and I am aware of options like freescout but Im looking for feedback for my situation and hope someone who has been down this road can tell me what might be a good option. \n Here's what I am looking for:\n I have 3-4 email boxes which receive emails which I would like to assign a ticket number to and have an agent accept responsibility for the ticket and then have a thread between the user and the agent about said ticket number. It would be nice if these were able to be archived. Currently I am using a shared inbox and each of the current agents have their own email boxes. A website chat widget would be a huge bonus. \n Something self hosted would be nice but Id be open to something freeium if need be. Just curious if someone could give me insight on a similar situation and what the setup looks like etc. \n Thanks!\n    submitted by    /u/choff5507  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvxv54/incoming_email_ticketing_system_options/",
          "publishedOn": "2022-12-26T21:47:36.000Z",
          "wordCount": 18345,
          "title": "Incoming email ticketing system options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvx1tc/virola_chat/",
          "author": null,
          "description": "Hello, I am looking into different self hosted chat options. I'm gonna share my story here a bit to explain what my community is looking for. \n ​\n We are a huge Roleplay community. Roleplay means, multiple accounts and profiles for the characters and identities my users use. \n Currently we use XenForo. It's amazing, we don't use the forum part we just use an addon they have called Chat by Siropu 2. everything works great but we have a lot of complaints that it's not that good on mobile. and theres no app either. they have to get on a browser and visit the site. \n ​\n We tried Discord. but many of our users get locked out after they have 5-10 accounts for their characters because discord begins asking for phone numbers etc. \n ​\n we moved to Rocket chat hosted in a site called cloud jiffy. worked well but we were paying $50 a month and 1 day.......the whole chat just vanished. so we went back to Xenforo. \n ​\n We've now found Virola chat. This service is PERFECT because we admins can create as many user profiles and accounts as we want directly from the admin panel and hand over the login to our roleplayers. https://virola.io/\n there's also an app for the phones which makes things a lot better. \n however where should I host this? what host do you recommend? we are about 9 or 10 REAL people with around 60-70 profiles/accounts in total inside the chat, so it's not like in Real people we're a ton and need a ton of resources for a server.\n    submitted by    /u/MitsuruMiyata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvx1tc/virola_chat/",
          "publishedOn": "2022-12-26T21:12:29.000Z",
          "wordCount": 17790,
          "title": "Virola Chat",
          "imageUrl": "https://external-preview.redd.it/mBNLK9O0NSxP-DtvIFPwzGBB12hWYae2QpZu1ewtavI.jpg?auto=webp&s=d8ed2de2367cd882b04be427f73ea0980f81bc4b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvwzis/this_might_be_the_fastest_nextcloud_setup_that/",
          "author": null,
          "description": "Hi guys,\n I've been testing and watching NextCloud for a while. I see that it brings a LOT of benefits(you can have your own google suit with 100% of privacy and it's FREE!) but I always had an issue with NextCloud being so slow.\n After trying several setups (apache + php fpm, nginx + php fpm and openlitespeed with lsphp) I think I found the fastest way to host and to use NextCloud. I made a guide step-by-step that is free and you can check it right now: https://theselfhosting.art/how-to-setup-the-fastest-nextcloud-ever-on-debian-11/ \n Benefits of this setup:\n  \nThe webserver virtual host and php for NextCloud are running on a low permission user. That means that even if your server gets hacked for some reason, your server is still fine since they can't touch the root user.\n LSPHP seems to be faster than php-fpm by default and we are using it.\n APCU and redis are being used to boost the performance to the best\n Debian 11 was used to stability and security\n I show you how to easily use occ commands with this setup in the end\n This guide is 100% free.\n I doubt that you will ever find a faster NextCloud. I feel that this setup may be faster than some managed NC hosts out there\n  \nHope you enjoy it. Feel free to ask me any questions here or on the comments section :)\n    submitted by    /u/askelam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvwzis/this_might_be_the_fastest_nextcloud_setup_that/",
          "publishedOn": "2022-12-26T21:09:50.000Z",
          "wordCount": 18929,
          "title": "This might be the fastest NextCloud setup that you will ever see [GUIDE]",
          "imageUrl": "https://external-preview.redd.it/TYzKAscWGHCKbIwKiXV8P44E-xWlGjiyFfoOV3jTrQ4.jpg?auto=webp&s=f6f587f476e4cbe72feef6fafa3ec3ef4b25bc06"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvwv6c/backing_up_docker_with_kopia/",
          "author": null,
          "description": "Hi all, as a Christmas gift I decided to write a guide on using Kopia to create offsite backups. This uses kopia for the hard work, btrfs for the snapshotting, and a free backblaze tier for the offsite target.\n Note that even if you don't have that exact setup, hopefully there's enough context includes for adaptation to your way of doing things.\n    submitted by    /u/Reverent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvwv6c/backing_up_docker_with_kopia/",
          "publishedOn": "2022-12-26T21:04:25.000Z",
          "wordCount": 18497,
          "title": "Backing up Docker with Kopia",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvwsg1/clientserver_backup_solution/",
          "author": null,
          "description": "Hi, does anyone know of a backup solution for Docker which allows several different users to backup their computers to the server?\n It would also be helpful if there was a GUI for the client as we have some less tech-literate people in our household. \n I tried UrBackup, however it was having major issues with macOS as their client is still in beta.\n    submitted by    /u/Batman123579  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvwsg1/clientserver_backup_solution/",
          "publishedOn": "2022-12-26T21:01:10.000Z",
          "wordCount": 17790,
          "title": "Client/Server Backup Solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvwgs0/looking_for_a_collaborative_notetaking_solution/",
          "author": null,
          "description": "I am a member of an online-only Dungeons and Dragons group. We - the players - need to organize our campaign notes in a searchable, categorized, and user-friendly way. \n Currently I store all of my own notes in Vimwiki, and another player uses Notepad. A third won't take notes at all as it's too much work. \n I've considered things like mediaWiki but that seems like a lot. I've looked at Joplin, but, again, a lot. Again, I discounted these almost entirely because they seem like way too much for what I'm trying to do. I'm still willing to consider them if there's a good reason to.\n I'd ideally like something that:\n  \ncan be reverse proxied\n only requires one container\n either supports multiple users or has no concept of users\n has a dark more or Dark Reader doesn't make it look terrible\n has edit history\n has multiple pages/categories/something; one page per area in the campaign or something\n  \nIn a perfect world it would fit all these criteria, but I think I'd bargain down to it fitting three.\n Any ideas?\n    submitted by    /u/sheeH1Aimufai3aishij  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvwgs0/looking_for_a_collaborative_notetaking_solution/",
          "publishedOn": "2022-12-26T20:46:46.000Z",
          "wordCount": 18126,
          "title": "Looking for a collaborative note-taking solution for a very specific purpose.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvvupx/about_to_do_my_very_first_ubuntu_headless_server/",
          "author": null,
          "description": "It’s for home use, with Homebridge, Home Assistant, Pi-Hole, Plex, and NextCloud to be run in Docker containers. \n The box is my old 2012 Mac mini with a 3rd-gen Core i5, 16GB of RAM, and SATA SSD that is currently running the first two apps in containers, and Pi-Hole running bare on Pop!_OS.\n Pi-Hole doesn’t play nice with Pop!_OS, so I’m switching to Ubuntu Server.\n NextCloud and Plex storage will be on an external array once I get the funding together.\n I’ve heard that Pi-Hole can have issues in a container, so I may just run it bare.\n If any Linux admins here have any tips, tricks, or best practices to follow to help make setting things up as smooth and easy as possible, I’d appreciate it! \n I’m a little fuzzy on migrating the Homebridge and Home Assistant containers, but I welcome any useful suggestions!\n    submitted by    /u/RockyCarr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvvupx/about_to_do_my_very_first_ubuntu_headless_server/",
          "publishedOn": "2022-12-26T20:19:42.000Z",
          "wordCount": 18267,
          "title": "About to do my very first Ubuntu headless server install. Care to share some tips?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvut4z/heimdall_cant_reverse_proxy_properly_into/",
          "author": null,
          "description": "Hello,\n Disclaimer: I'm very new to docker.\n I'm trying to set up an Nginx reverse proxy that redirects my domain to my docker Heimdall container, I've done it before with containers such as Jellyfin but with Heimdall and Nextcloud it doesn't redirect properly I just get a blank screen with some text. Not sure what I'm doing wrong but would appreciate some help. I will leave some images down below of what's happening and my Nginx file and Yacht file.\n ​\n https://preview.redd.it/8qamqur3oa8a1.png?width=1887&format=png&auto=webp&s=68a5358395b164528a2abdeaa3833063a8944048\n https://preview.redd.it/8mhmbvr3oa8a1.png?width=672&format=png&auto=webp&s=dfe8b84441719545b1119a67abd4d0d5f1c800fd\n https://preview.redd.it/v9l27z94oa8a1.png?width=769&format=png&auto=webp&s=cafc555c857e0057ba265e8dbad789e09a3aedfb\n    submitted by    /u/TightEfficiency8615  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvut4z/heimdall_cant_reverse_proxy_properly_into/",
          "publishedOn": "2022-12-26T19:32:43.000Z",
          "wordCount": 17659,
          "title": "Heimdall can't reverse proxy properly into container? (Using Yacht)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvul2l/docker_swarm_and_nfs_mounts/",
          "author": null,
          "description": "Hi there.\n I am running a small Docker Swarm with 4 RPi. I really love all the services I am able to run at home.\n But I have encountered some issues in the past and today as well. But I didn't understand exactly what the issue is.\n I have a Synology NAS and a NFSv4 Share which is mounted on each RPi. Usually I create BIND mounts when I set up a service. I had this issue with Nextcloud and today with a Ghost container: During preparation phase, I checked the logs and always found: \"changing ownership: permission denied\" for the BIND mounts I've defined.\n Can someone explain me what's the issue here? \n Big THX!\n    submitted by    /u/yannbros  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvul2l/docker_swarm_and_nfs_mounts/",
          "publishedOn": "2022-12-26T19:22:46.000Z",
          "wordCount": 19212,
          "title": "Docker Swarm and NFS mounts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvth9f/web_server_provisioner_like_cleavrio/",
          "author": null,
          "description": "I use Cleavr.io now for a lot of my live sites and I really enjoy using it, but I also want to use it on my personal VMs that I spin up to make managing those web sites/projects easier on me. Especially for dev sites that I am just quickly spinning up and testing.\n Does anyone know of an alternative that I could use self-hosted? I'd also be willing to explore a way for a server like Cleavr to connect to my internal server.. I setup Cloudflare tunnel at first and then remembered that it doesn't support inbound connections through SSH hahah\n    submitted by    /u/failcookie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvth9f/web_server_provisioner_like_cleavrio/",
          "publishedOn": "2022-12-26T18:34:03.000Z",
          "wordCount": 17065,
          "title": "Web server provisioner - like cleavr.io?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvsavq/donating_to_mailcow_why_so_many_personal/",
          "author": null,
          "description": "I recently wanted to donate a small amount to the Mailcow project (the SAL package) because it is a awesome project and I use it without any problems for the last two years.\n Then on the last step of registering an account they want pretty much all of my details, like home address, full name, tax ID, phone number and so on ...\n Is that really necessary?\n I would want to register with my e-mail and password then checkout with Paypal. I do donate from time to time to open source devs for their hard work, but this is just ridiculous.\n Maybe I missed something like a legal obligation in the country they operate?\n    submitted by    /u/Malaclypse5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvsavq/donating_to_mailcow_why_so_many_personal/",
          "publishedOn": "2022-12-26T17:42:05.000Z",
          "wordCount": 17300,
          "title": "Donating to Mailcow: why so many personal informations needed?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvrktx/selfhosted_tool_for_oral_dialogue_with_chatgpt/",
          "author": null,
          "description": "Hello, is anyone aware of some kind of client tool that might be selfhosted to interact orally with chatgpt ? I would love to host such a tool, but it seems unavaliable for now ...\n    submitted by    /u/Eirikr70  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvrktx/selfhosted_tool_for_oral_dialogue_with_chatgpt/",
          "publishedOn": "2022-12-26T17:08:48.000Z",
          "wordCount": 16978,
          "title": "Selfhosted tool for oral dialogue with Chatgpt",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvqz7w/private_ca_and_reverse_proxy/",
          "author": null,
          "description": "Like the title says I have a private CA and I want to use a reverse proxy to access all my services within my own network, I don't mind using any reverse proxy.\n I don't know if I need to provide any other info but if there's anything else then you guys can ask me and I'll reply.\n I'm sorry if I'm mixing up proxy and reverse proxy because I'm not really well versed with the difference between them\n    submitted by    /u/XenoDan_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvqz7w/private_ca_and_reverse_proxy/",
          "publishedOn": "2022-12-26T16:40:46.000Z",
          "wordCount": 17720,
          "title": "Private CA and reverse proxy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvn8ev/browser_video_game_emulation/",
          "author": null,
          "description": "Have any of you tried this? https://www.linuxserver.io/blog/self-hosted-web-based-emulation\n    submitted by    /u/deepdivered  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvn8ev/browser_video_game_emulation/",
          "publishedOn": "2022-12-26T13:34:21.000Z",
          "wordCount": 19969,
          "title": "browser video game emulation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvl4m0/silver_bullet_selfhostable_personal_knowledge/",
          "author": null,
          "description": "I have been recently enjoing this software.\n Homepage is https://silverbullet.md that also doubles as a test instance.\n It is a markdown system, sort of a wiki, that can be edited live.\n What in my opinion sets it apart is the possibility to do some nice and structured queries on the content, like \"list all the open tasks I have in all my notes\".\n Reminds me of org.mode in emacs.\n Can be selfhosted easily (through docker) and is really lightweight.\n    submitted by    /u/dedioste  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvl4m0/silver_bullet_selfhostable_personal_knowledge/",
          "publishedOn": "2022-12-26T11:15:59.000Z",
          "wordCount": 17140,
          "title": "Silver bullet: selfhostable personal knowledge management system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvl2zk/any_sirialexa_offline_alternative/",
          "author": null,
          "description": "I would like to set-up some sort of alexa/siri type virtual assistant on my phone.\n I would like it to have a bank of knowledge, for example say I downloaded a Wikipedia article bundle on biology, I could a say \"computer, what is the purpose of RNA\". I would also like it to do normal functions like calling people, setting reminders etc\n How would one set something like this up with minimal effort (I don't have extensive knowledge on coding so I don't think I could code one from scratch) on my phone? Perhaps something like this already exists?\n Thanks\n    submitted by    /u/onlyalexicon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvl2zk/any_sirialexa_offline_alternative/",
          "publishedOn": "2022-12-26T11:12:47.000Z",
          "wordCount": 16237,
          "title": "Any siri/alexa offline alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvh40m/minmon_v031_an_opinionated_minimal_monitoring_and/",
          "author": null,
          "description": "Today I'm releasing MinMon v0.3.1. I used some of the feedback I got from you guys (thanks!) for the first release not too long ago.\\ Contributions and feedback are very welcome!\n There are two new checks: - PressureAverage which checks Linux Pressure Stall Information (PSI) for CPU, I/O, and memory. - ProcessExitStatus which runs a process and checks its exit status code. This gives a lot of flexibility to implement custom checks. \n There are a few incompatible changes: - The default value for \"memory\" in the MemoryUsage check config was changed from true to false. - The placeholder alarm_id has been renamed to check_id for more consistent naming.\n Happy holidays!\n    submitted by    /u/flo-at  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvh40m/minmon_v031_an_opinionated_minimal_monitoring_and/",
          "publishedOn": "2022-12-26T06:40:55.000Z",
          "wordCount": 17531,
          "title": "MinMon v0.3.1 - an opinionated minimal monitoring and alarming tool",
          "imageUrl": "https://external-preview.redd.it/JiEc28PcFKPAHudNCQ-W5ogFjrmWNf67N9n2cRn-VYs.jpg?auto=webp&s=1570eab00021abe2233f591a373448406985c0e7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvapyw/looking_for_some_advice_pointers_encouragement_etc/",
          "author": null,
          "description": "So hey guys, I've been running something very simple and have been thinking about doing some other stuff. I'm honestly not sure if this is something I can pull off to be quite honest. For several years I've been running a few things on a Synology NAS (DS920+). Basically right now I'm running Jellyfin and Omada controller in Docker on the Synology. I've read a lot of interesting stuff about other stuff like Proxmox. I got some crazy idea I wanted to do that so I got a Dell T5810 workstation with a 24c/48t processor and (so far) 64 GB RAM. The DS920+ is getting re-homed so what I want to do is use my old Synology, the DS413, as network storage with my T5810 running Proxmox. So far I think I have it set up properly with I think its called NFS.\n (A) Also, right now, I'm running OPNsense on a d…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvapyw/looking_for_some_advice_pointers_encouragement_etc/",
          "publishedOn": "2022-12-26T00:30:48.000Z",
          "wordCount": 20178,
          "title": "Looking for some advice, pointers, encouragement, etc...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv9rhk/yunohost_alternative/",
          "author": null,
          "description": "Hi!\n I'm currently using yunohost and I am happy with it. I like this system because it is easy to use but still allows for a fair amount of flexibility. It's a system that I feel is complete and mature and works well.\n But I would like to try something else. What do you suggest that is as good or better and also allows to use docker?\n Thx\n    submitted by    /u/zwnrsx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv9rhk/yunohost_alternative/",
          "publishedOn": "2022-12-25T23:40:30.000Z",
          "wordCount": 18898,
          "title": "Yunohost alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv9odo/whats_the_prettiest_yet_most_lightweight/",
          "author": null,
          "description": "I’ve tried docsify and PineDocs; however, docisfy is incredibly slow for me over Cloudflare Tunnels for some reason\n I like PineDocs, but the mobile UI kinda sucks\n I’ve also tried wikiJS and BookStack, but didn’t really care for them either\n Any recommendations?\n    submitted by    /u/kvpop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv9odo/whats_the_prettiest_yet_most_lightweight/",
          "publishedOn": "2022-12-25T23:35:48.000Z",
          "wordCount": 18583,
          "title": "What’s the prettiest yet most lightweight self-hosted wiki service out there?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv6nhb/remote_desktop_containers/",
          "author": null,
          "description": "In the past I have used Guacamole with Docker. Now that I have switched to Kubernetes for hosting in my home lab, I have been getting weird errors when trying to use it.\n Is there any good alternatives to Guacamole? Or any recommendations?\n    submitted by    /u/BinaryNexus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv6nhb/remote_desktop_containers/",
          "publishedOn": "2022-12-25T21:04:19.000Z",
          "wordCount": 18323,
          "title": "Remote Desktop Containers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv65rm/any_google_photos_alternative_that_can_also/",
          "author": null,
          "description": "I installed Photoprism but it seems that I can't have it organize my \"Originals\" folder on the actual disk? Does anyone have any alternatives that can help moving files/organization? Example: select a bunch of photos from time range and \"move to new folder photos/My2022Trip\"\n    submitted by    /u/Intelg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv65rm/any_google_photos_alternative_that_can_also/",
          "publishedOn": "2022-12-25T20:39:33.000Z",
          "wordCount": 18342,
          "title": "Any Google Photos alternative that can also \"organize\" (create folders and move photos to new folder) from same web UI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv63er/bitwarden_app_and_cloudflare_access_integration/",
          "author": null,
          "description": "Did anyone manage to get both running together without excluding IPs etc?\n    submitted by    /u/GelosSnake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv63er/bitwarden_app_and_cloudflare_access_integration/",
          "publishedOn": "2022-12-25T20:36:16.000Z",
          "wordCount": 18423,
          "title": "Bitwarden app and cloudflare access integration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv4bu2/backup_windows_pc_to_minios3/",
          "author": null,
          "description": "I have quite a bit of open space on my home server and recently had two scares with family members having failing drives. \n I have minio running perfectly fine on my home server, and would like to setup my grandparents and parents PCs to backup to my home minio. \n Is there any good, easy to use utility for windows that would allow backup to minio? I am a good distance away and something that can run in the background would give me peace of mind for their data. \n The minio/unraid server is also backed up to cloud. So 3 separate locations should mean the data is fairly safe from loss. \n Any advice would be greatly appreciated!\n    submitted by    /u/WesBur13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv4bu2/backup_windows_pc_to_minios3/",
          "publishedOn": "2022-12-25T19:07:20.000Z",
          "wordCount": 18525,
          "title": "Backup Windows PC to Minio/S3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv40ss/thin_clients_lowend_chips_how_to_compare_what_to/",
          "author": null,
          "description": "Hello! Apologies in advance if this is not the right place to post.\n Tl;dr: how to compare low consumption chips? How does a Via vx855 or vx900 compare to a Marvell ARMADA PXA 510 v7? \n I'm only getting started with self-hosting, etc and after trying to get a rpi, I read a few posts around here recommending a thin client instead, which could potentially be cheaper, more efficient and at least as powerful (if not more) than a pi3.\n For info, my intention is to set a very simple home server so I can automate backup of my several devices, potentially self hosting nextcloud or equivalent.\n Now, my question: after reading a few posts, I went and bought off ebay (I'm in the UK in case that matters) a wyse 3010 (T10). I think it's this: https://www.wysechoice.co.uk/epages/BT4858.mobile/en_GB/?ObjectID=18010786\n Now, I haven't tested yet (Christmas and all that...) but I realised (too late, maybe?) that it's a 32bit processor, and the wyse comes without any flash storage! I know I can install Linux in a pen-drive so that's not an issue, but using the internal flash memory would be a nice addition.\n On the other hand, looking a bit more on ebay, I've found a few igel m310/320/330 for a reasonable price. They come with a chip Via Eden x2 (vx855 or vx900). All this info i found in parkytowers, which is extremely helpful but also a huge rabbit hole... And now I don't know anything anymore!\n In brief: how does a Via vx855 or vx900 compare to a Marvell ARMADA PXA 510 v7? How do these compare to an Atom e3815?\n Again, sorry if this is the wrong place to post (or the wrong way to ask!) and thanks in advance for reading and helping out!\n Ps: and merry christmas/happy new year if you celebrate in any way ;)\n    submitted by    /u/metronomme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv40ss/thin_clients_lowend_chips_how_to_compare_what_to/",
          "publishedOn": "2022-12-25T18:51:59.000Z",
          "wordCount": 19627,
          "title": "Thin clients, low-end chips: how to compare, what to buy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2uu9/personal_email_address_using_my_domain/",
          "author": null,
          "description": "I have this domain first-last.com and wanted to use it for daily personal and professional use. Just wondering if this seems like a sensical decision.\n ​\n Account logins:\n [account+twitter@first-last.com](mailto:account+twitter@first-last.com): password\n [account+reddit@first-last.com](mailto:account+reddit@first-last.com): password\n ​\n Professional/Personal emails:\n Professional [contact@first-last.com](mailto:contact@first-last.com)\n Personal [hello@first-last.com](mailto:hello@first-last.com)\n    submitted by    /u/Ok-Move-803  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2uu9/personal_email_address_using_my_domain/",
          "publishedOn": "2022-12-25T17:52:05.000Z",
          "wordCount": 21645,
          "title": "Personal email address using my domain",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2uqw/simple_linux_command_web_gui/",
          "author": null,
          "description": "Hey, I'm looking for a program that might exist that i've heard of ( or maybe i've dreamt hearing of it).\n Basically, all im looking for is a simple web app that i can configure commands for that i can run in my local network so when my partner yells \"IS PLEX DOWN?!?!\", they can just hit a button to send a \"docker container plex restart\" command to my server.\n I can probably achieve this in home assistant, but I'm trying to avoid that. I'd prefer a standalone solution of some sort.\n EDIT: Resolved. OliveTin worked perfectly and its already up and running. Took about 30 minutes to going. Thanks again to /u/alphafalcon\n    submitted by    /u/Offbeatalchemy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2uqw/simple_linux_command_web_gui/",
          "publishedOn": "2022-12-25T17:51:57.000Z",
          "wordCount": 19016,
          "title": "Simple linux command web gui?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2t4s/selfhosted_paas_no_dokku_pls/",
          "author": null,
          "description": "What do you use to host small Go/TypeScript/Python... etc. projects in your home lab? Had a look on Dokku, but it has no UI and works in single-node only.\n    submitted by    /u/Minimum-Dig3986  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2t4s/selfhosted_paas_no_dokku_pls/",
          "publishedOn": "2022-12-25T17:49:45.000Z",
          "wordCount": 19591,
          "title": "Selfhosted PaaS? (No dokku pls)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2kp0/best_backup_solution_with_encryption/",
          "author": null,
          "description": "All my main drives are luks encrypted. I have a couple Android phones I'd also like to backup + images/videos on external drives.\n I was thinking of using rsync to backup my computer drives? But I still don't know how to do encryption with that, otherwise the luks encryption is pointless?\n For android/images/videos/files I've seen that nextcloud is decent? I don't mind them not being encrypted but ideally they would be. And that nextcloud has an encryptuion addon\n I have a hetzner vps and hetzner storage box so far\n    submitted by    /u/Any-Bread2113  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2kp0/best_backup_solution_with_encryption/",
          "publishedOn": "2022-12-25T17:37:36.000Z",
          "wordCount": 21280,
          "title": "Best backup solution with encryption",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2cn2/need_help_on_volumes_in_portainer/",
          "author": null,
          "description": "Hello all and merry Christmas! \n I installed Turnkey-core in Proxmox on a Dell server and then installed Docker and Portainer. So far so good. Only thing I don't really get is how volumes work in Portainer. So let's say I install Qbittorrent and I want it to download everything to a NFS folder on my NAS, do I have to mount that folder in Turnkey? Or do I have to add that volume in Portainer? Or do I have to do both? Please help me on this.\n Thanks!\n    submitted by    /u/babsenfred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2cn2/need_help_on_volumes_in_portainer/",
          "publishedOn": "2022-12-25T17:26:16.000Z",
          "wordCount": 17704,
          "title": "Need help on volumes in Portainer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv1t1o/building_a_personal_arm_server_cluster/",
          "author": null,
          "description": "Hi everyone. Does anyone have resource links to how I can build an a server cluster/farm. Got my own development. I am tired of posting cloud fees. But I am willing to pay and as an investment for my own personal learning and development server. In the long run. I know it will be less hassle to run a cluster server and it might even be cheaper but I’ll not learn anything but their own version of the tools. I have read the initial intro notes on this sites and they are useful. I am looking for additional 101 step by step materials. Thanks so much.\n    submitted by    /u/Mikefoong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv1t1o/building_a_personal_arm_server_cluster/",
          "publishedOn": "2022-12-25T16:58:49.000Z",
          "wordCount": 18313,
          "title": "Building a personal arm server cluster",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv0zyi/i_wrote_a_script_that_automatically_sends_unread/",
          "author": null,
          "description": "I had been searching for a way to read articles through Kindle. I found a few solution but they were either too complicated or required paid services, so I decided to write my own script with the help of ChatGPT that\n  \n(i) Checks for new wallabag articles every X seconds\n (ii) Emails them to my kindle's email address as epub/mobi\n (iii) Marks the sent articles as read.\n  \nHere's the script:\n # Set your kindle's email adress EMAIL_ADDRESS='username_kindleid@kindle.com' # Log file LOG_FILE='/tmp/kindle-log.log' while true; do # Get the list of articles from Wallabag articles=$(wallabag list -n) # Check if there are any new articles article_list=($articles) for article_info in \"${article_list[@]}\"; do article_info_split=($article_info) id=${article_info_split[0]} # Check if id is valid if [[…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv0zyi/i_wrote_a_script_that_automatically_sends_unread/",
          "publishedOn": "2022-12-25T16:15:22.000Z",
          "wordCount": 18655,
          "title": "I wrote a script that automatically sends unread wallabag articles to Kindle",
          "imageUrl": "https://external-preview.redd.it/o52OrngMF3ebGloWnpXeFqXgekVacj5nwX4g68XgZQA.jpg?auto=webp&s=6ecbed07a2a8dcdbc945ec4f9070d0cc603ec071"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv0tb4/audio_streaming_receiver_volumio_alternative/",
          "author": null,
          "description": "Hi,\n ​\n I'm looking for a selfhosted Windows or Linux service that includes a web-based GUI and supports CD-ROM playback. I looked up Volumio however many people have had issues with it being a bit buggy and it is also requires a paid subscription to support CD playback. Preferably with Airplay support so I could stream lossless to my speakers through a DAC plugged into the streaming machine.\n ​\n Hardware at my disposal is:\n Dell Thin client with a Celeron, 2GB RAM and 4GB eMMC storage.\n Or a Late 2014 Mac Mini that is already running Windows in bootcamp, due to it being used as a low-power personal Minecraft server machine through AMP instance manager.\n ​\n Any suggestions? Anything I've found is usually Raspberry Pi - ARM based, and I don't have a spare one on hand, all of them are running their duties already.\n    submitted by    /u/jakubperhac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv0tb4/audio_streaming_receiver_volumio_alternative/",
          "publishedOn": "2022-12-25T16:05:44.000Z",
          "wordCount": 18971,
          "title": "Audio streaming receiver - Volumio alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv0c20/selfhosted_you_photography_portal_for_clients/",
          "author": null,
          "description": "Hi guys, is there a self-hosted solution that could be use for hosting pictures and provide access/download them, once client pays for them? Doesn’t need to have payment feature. Just need to have an admin and client portal\n Thanks\n    submitted by    /u/Allferry  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv0c20/selfhosted_you_photography_portal_for_clients/",
          "publishedOn": "2022-12-25T15:39:49.000Z",
          "wordCount": 18366,
          "title": "Self-hosted you photography portal for clients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv08og/smtp_login_attempts/",
          "author": null,
          "description": "To those that host their own email/smtp server are you seeing an increase in SMTP login attempts over the past few weeks? Any one have an idea which breach/attack started this?\n It Just makes the logs a real pain to go through.\n Edit: This is not a new server and I have been running my smtp server for a while (decades). I am just asking if everyone is being hit (maybe just usa ips?) and/or if anyone knows the cause.\n    submitted by    /u/prshaw2u  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv08og/smtp_login_attempts/",
          "publishedOn": "2022-12-25T15:34:23.000Z",
          "wordCount": 19121,
          "title": "SMTP login attempts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv082c/besy_way_to_automate_epubs_for_kavita/",
          "author": null,
          "description": "What is the best and most simple way of automating the process of \n Download Book -> Edit embeded metadata in Epub -> Send to Kavita\n As far as I know, currently there are 3 programs that can edit the metadata of an epub file. Readarr, Lazylibrarian, Calibre. I want to use Calibre but I think the the GUI looks not great and can be a pain to work with.\n    submitted by    /u/AlphaShiro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv082c/besy_way_to_automate_epubs_for_kavita/",
          "publishedOn": "2022-12-25T15:33:23.000Z",
          "wordCount": 18198,
          "title": "Besy way to automate epubs for Kavita?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv04p7/intranet_caself_signed_ssl_certificate/",
          "author": null,
          "description": "Hello, don't know if this is the right place to ask this but i will try. \n I would like to to create a self signed CA to sign certificates for websites on my local network only as for anything outside is behind my reverse proxy with Lets encrypt certbot. The problem is if i import my self signed certificate on Win11 machine all browsers return that website has no trusted certificate. Am i doing it wrong or is there some sort of trick to this? Certificates/CA generation is a bit confusing for me from the technical side of things. \n Is there a tool that would help me generate a CA/self signed ssl certificates and import them or do i need to do everything by hand?\n    submitted by    /u/Dymas-CZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv04p7/intranet_caself_signed_ssl_certificate/",
          "publishedOn": "2022-12-25T15:28:09.000Z",
          "wordCount": 19884,
          "title": "Intranet CA/self signed ssl certificate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuzlba/ssh_vs_vpn/",
          "author": null,
          "description": "Hello, I would like to access my local server at home from anywhere. \n Are there some advantages / disadvantages of opening port for SSH or using VPN server?\n What’s the best choice to provide the best security as could?\n    submitted by    /u/PatrikKnizka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuzlba/ssh_vs_vpn/",
          "publishedOn": "2022-12-25T14:57:41.000Z",
          "wordCount": 19572,
          "title": "SSH vs VPN?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuy39q/looking_for_a_selfhosted_markerio_alternative/",
          "author": null,
          "description": "Hey :)\n I'm looking for a free and/or open source self-hosted alternative to marker.io for visual bug tracking/reporting.\n On a website users can click on an element and write comments about a visual bug - mainly what marker.io does.\n It should be running in Docker and got webhooks to connect it to project management tools.\n Thanks for your suggestions!\n    submitted by    /u/ynomel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuy39q/looking_for_a_selfhosted_markerio_alternative/",
          "publishedOn": "2022-12-25T13:26:21.000Z",
          "wordCount": 20050,
          "title": "Looking for a self-hosted marker.io alternative (FOSS) - Open Source Visual Feedback and Bug Tracking / reporting tool for websites",
          "imageUrl": "https://external-preview.redd.it/OAKGuc-f5IxKIaBO6aCMxgiGiSnwk1aVZf1O4hcfTkE.jpg?auto=webp&s=d9ad46efcbf012233db482a1d3f339c348856c57"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuxv1t/simple_selfhosted_s3compatible/",
          "author": null,
          "description": "Hi all,\n I'm building an app to manage some files, and I've determined it makes the best sense to use object storage.\n I would like to host internally on my home k8s cluster to start/while I'm developing, using my NFS NAS as the actual storage backend.\n Are there any self-hostable solutions out there that can slap an S3 API in front of some NFS? Minio seems really heavyweight for my use case, plus they explicitly don't support network filesystem backends. The only other potential solution I've found is Zenko Cloudserver, and frankly, it looks like a development mess. \n Would appreciate any insight if anybody has discovered other solutions.\n //edit: to clarify, when I say simple, ideally I’m looking for something that just maps the API to files on the filesystem. Minio is great, don’t get me wrong, but I don’t need the whole HA/duplication/everything else it provides for my local needs. I just need to be able to make API calls and retrieve files. \n Thanks!\n    submitted by    /u/e3b0c442  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuxv1t/simple_selfhosted_s3compatible/",
          "publishedOn": "2022-12-25T13:10:44.000Z",
          "wordCount": 20608,
          "title": "Simple self-hosted S3-compatible",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zumi6j/my_christmas_lights/",
          "author": null,
          "description": "submitted by    /u/PovilasID  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zumi6j/my_christmas_lights/",
          "publishedOn": "2022-12-25T00:20:46.000Z",
          "wordCount": 17897,
          "title": "My Christmas lights",
          "imageUrl": "https://external-preview.redd.it/8wF-Yhb7zn_DgTRAUzS7PUxlvHwD0iwE81JMDQEHnjk.png?format=pjpg&auto=webp&s=43966f44f359ca404f3fbbcc21cc05836e7d59e7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zul0vb/gluetun_authentication_with_pia/",
          "author": null,
          "description": "I've been unable to start a Docker container with gluetun using Private Internet Access. The logs show an authentication error, but I'm positive the credentials are correct. I assume I've done something else incorrectly.\n Does anybody have a VPN set up using gluetun and PIA? I've tried most versions of the image with the same result.\n The error in the gluetun container is: \n 12/24/2022 2:58:53 PM2022-12-24T22:58:53Z ERROR [openvpn] AUTH: Received control message: AUTH_FAILED 12/24/2022 2:58:53 PM 12/24/2022 2:58:53 PMYour credentials might be wrong 🤨 \n The compose file I am using is:\n version: \"3.8\" services: qbittorrent: container_name: qbittorrent image: linuxserver/qbittorrent restart: unless-stopped network_mode: \"service:gluetun\" depends_on: - gluetun volumes: - /home/docker/qbittorrent/config:/config - /home/docker/data/torrents:/downloads environment: - PUID=1000 - PGID=1000 gluetun: image: qmcgaw/gluetun container_name: gluetun cap_add: - NET_ADMIN devices: - /dev/net/tun:/dev/net/tun ports: - 8888:8888/tcp # HTTP proxy - 8388:8388/tcp # Shadowsocks - 8388:8388/udp # Shadowsocks # qbittorrent ports - 8080:8080 - 6881:6881 - 6881:6881/udp restart: unless-stopped volumes: - /home/docker/gluetun:/gluetun environment: # See https://github.com/qdm12/gluetun/wiki - VPN_SERVICE_PROVIDER=private internet access - VPN_TYPE=openvpn - OPENVPN_USER=redacted - OPENVPN_PASSWORD=redacted - SERVER_REGIONS=US California \n    submitted by    /u/spiderguy33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zul0vb/gluetun_authentication_with_pia/",
          "publishedOn": "2022-12-24T23:00:53.000Z",
          "wordCount": 18786,
          "title": "gluetun authentication with PIA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zujp7u/should_i_switch_from_1password_to_the_self_hosted/",
          "author": null,
          "description": "The Lastpass incident woke me up and really made me think about what I was doing and why I was entrusting my passwords to others.\n Now I have come to the decision to switch to a self-hosted password manager.\n I am currently a little afraid that my current one might be hit at some point.\n I currently use 1Password and would like to switch to the self-hosted version of Bitwarden.\n What do you think, is it worth it and do I have to worry about security?\n I know a lot about securing Linux servers, so I think I'm relatively safe, but what do you think?\n Where should I host, can you recommend a secure hoster that is also trustworthy?\n I am currently thinking about using Hetzner, Ionos or AWS.\n If possible the hoster should be located in Germany.\n    submitted by    /u/MaximilianGT500  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zujp7u/should_i_switch_from_1password_to_the_self_hosted/",
          "publishedOn": "2022-12-24T21:52:08.000Z",
          "wordCount": 20575,
          "title": "Should I switch from 1Password to the Self Hosted alternative Bitwarden?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuijs2/hosting_a_windows_vm_on_a_linux_server/",
          "author": null,
          "description": "I would like to host a windows vm on my intel nuc, that you can connect via a web browser. Its for my dad that wants to run some windows software where wine will not work. So my question is, what would be good foss software, or combination of software, that could make this work. Help would be appreciated merry Christmas\n    submitted by    /u/Nartapok  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuijs2/hosting_a_windows_vm_on_a_linux_server/",
          "publishedOn": "2022-12-24T20:54:08.000Z",
          "wordCount": 21594,
          "title": "Hosting a windows vm on a linux server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuif4o/is_it_better_to_host_vpn_on_a_server_or_router/",
          "author": null,
          "description": "This is a follow up to my previous post. Is it also possible to allow certain websites to pass through outside of the VPN, like Netflix for example? Not sure if that would put the server at risk though.\n    submitted by    /u/ALCF98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuif4o/is_it_better_to_host_vpn_on_a_server_or_router/",
          "publishedOn": "2022-12-24T20:47:32.000Z",
          "wordCount": 18126,
          "title": "Is it better to host VPN on a server or router?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuidbk/access_jellyfin_through_google_compute_with/",
          "author": null,
          "description": "Hey Folks,\n So I have Jellyfin and Tailscale installed on my home desktop. I also have Tailscale installed on a Google Compute Free Tier VM and have enabled it as subnet router. The home machine with Jellyfin installed is set as an exit node. I am able to ping my Google VM Tailscale IP from home machine and ping home machine from the VM.\n My question is, how do I access Jellyfin through the internet using my VM? Basically, I want to access without using Tailscale client(because there may be instances where I cant install the client on a device)..\n I have verified I can access my Jellyfin server through other devices on my home LAN.\n    submitted by    /u/Rakeen70210  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuidbk/access_jellyfin_through_google_compute_with/",
          "publishedOn": "2022-12-24T20:45:00.000Z",
          "wordCount": 18765,
          "title": "Access Jellyfin Through Google Compute with Tailscale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zugob3/self_hosted_roundup_21/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zugob3/self_hosted_roundup_21/",
          "publishedOn": "2022-12-24T19:19:42.000Z",
          "wordCount": 18455,
          "title": "Self Hosted Roundup #21",
          "imageUrl": "https://external-preview.redd.it/rdm70f9IX6spqpg8Uh0FpFsaWjUNeyqzhMDa4K33PRQ.jpg?auto=webp&s=8a3a055f3e19f26b77d5397d54701bc3bee07e70"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zufdix/id_like_to_get_into_privately_selfhosting_for_my/",
          "author": null,
          "description": "I'd like to turn my server in the other room into a simple file hosting cloud that functions pretty much exactly like Onedrive.\n I've tried looking around but all I've found are monthly charges or just not what I'm looking for. \n My close friends and family game together, record moments, draw art and share/edit them. \n I would super appreciate any suggestions or advice you guys have. Please keep the topic on what software would be the best for what I'm looking for and not patronizing about security or judgment of character.\n Features I'd really like:\n  \nAbility to use it through File Explorer like OneDrive.\n Free.\n Fancy bells and whistles like profiles, monitoring, passwords(?), history and ability to Quota the storage into sections, etc.\n  \n​\n Features that're a must:\n  \nUsers are able to upload, download, delete, edit any files & pictures/text documents and what not as well as stream and play clips FROM my server without having to download them.\n  \nI am also open to huge one-time payment but I'm not looking for anything with monthly payments.\n The server has windows 11 pro, 128GB of dedotated WAM and 10TB of ssd storage.\n    submitted by    /u/ZaneyHD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zufdix/id_like_to_get_into_privately_selfhosting_for_my/",
          "publishedOn": "2022-12-24T18:16:13.000Z",
          "wordCount": 20303,
          "title": "I'd like to get into privately selfhosting for my close friends and family.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zudy4n/2fa_on_arr_and_jellyfin/",
          "author": null,
          "description": "Hello family,\n Merry christmas!\n I am looking to setup 2FA on Radarr, Sonarr and Jellyfin. I think I can ise authelia for Radarr and Sonarr (Not yet tested). But I could bot find anyway to implement same in jellyfin.\n Have you implemented 2FA on jellyfin and Radarr ? Please help me.\n Thanks\n    submitted by    /u/leostic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zudy4n/2fa_on_arr_and_jellyfin/",
          "publishedOn": "2022-12-24T17:06:08.000Z",
          "wordCount": 18919,
          "title": "2FA on *arr and jellyfin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuduct/can_you_recommend_any_good_calendar_todo_list/",
          "author": null,
          "description": "I am currently using Google Calendar and Trello, but it always feels a bit awkward. I'd like to write down events (and event series, ideally) and have a bit of automation with the todo list, like creating a certain todo list element at the start of the month or stuff like that.\n Is there anything good?\n    submitted by    /u/SendMeOrangeLetters  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuduct/can_you_recommend_any_good_calendar_todo_list/",
          "publishedOn": "2022-12-24T17:01:01.000Z",
          "wordCount": 19484,
          "title": "Can you recommend any good calendar + todo list software?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zub6wh/alternatives_to_myid/",
          "author": null,
          "description": "Are there any other similar services to this? It lets you use it's domain for other self-hosted services besides just static web hosting but I don't actually speak the language of the site and I just wanted to see if there were any other alternatives that didn't involve giving my phone number.\n The Service: https://www.my.id/\n Examples:\n Website: https://nekoweb.my.id/\n XMPP: https://im6.nekoweb.my.id/cakap/\n Retrowars: https://rwr.nekoweb.my.id\n    submitted by    /u/PrettyExpensiveCoat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zub6wh/alternatives_to_myid/",
          "publishedOn": "2022-12-24T14:44:26.000Z",
          "wordCount": 18087,
          "title": "Alternatives to my.id",
          "imageUrl": "https://external-preview.redd.it/w4-6gGMLuRKS8r-zDKXYJIYtq83iNAy8AGQ3YMdAyMQ.jpg?auto=webp&s=f124224d3cfc2d321900ac9f59b1838c3cc495cc"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuaqgh/help_with_storage_server/",
          "author": null,
          "description": "I have a vps server with 1tb storage and 1 cpu and 2 gb ram. What softwares are there to securely access this on Android, pc and an android tv//fire stick\n    submitted by    /u/artremist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuaqgh/help_with_storage_server/",
          "publishedOn": "2022-12-24T14:19:11.000Z",
          "wordCount": 18853,
          "title": "help with storage server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuagad/what_would_you_love_to_see_as_self_hosted_service/",
          "author": null,
          "description": "It's almost Christmas, and if you could ask Santa a self-hosted service, what would It be?\n I'm curious to know what would you would want/need, but no solution currently exists because It's too specific/a niche.\n    submitted by    /u/Tours-Petronas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuagad/what_would_you_love_to_see_as_self_hosted_service/",
          "publishedOn": "2022-12-24T14:03:38.000Z",
          "wordCount": 20545,
          "title": "What would you love to see as self hosted service?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuaewg/selfhosted_file_download_site_in_intranet_no/",
          "author": null,
          "description": "Hi,\n I’m currently looking for a software solution to host a file download site on a companies Intranet. I noticed that searching for the phrase “Download” on the Internet is a bit tricky ^^\n My requirements are:\n  \nThe Server will have no connection to the Internet\n No Sync option like a cloud is required\n All visitors can download all released files from a web page\n Registered users can upload and manage their files via a web interface\n User can create groups and sub-groups and assign files to this groups\n Files cannot downloaded directly. Instead, the download has to be conducted via a Page for the File on which predefined text fields are shown (e.g., License, Creator, Uploader, Version-No, Contact Data etc.). Also, one or more preview pictures can be displayed.\n The download page allows to download different files (e.g. the same Bitmap in different file formats).\n  \nI hope for some advice on this, because finding software for this is really a pain in the neck. Thanks, in advanced.\n    submitted by    /u/Adzorn76  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuaewg/selfhosted_file_download_site_in_intranet_no/",
          "publishedOn": "2022-12-24T14:01:31.000Z",
          "wordCount": 19955,
          "title": "Self-hosted File Download Site in Intranet (No Internet connection)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu91uw/first_nas_build/",
          "author": null,
          "description": "I was looking at hard drives for my first nas build and saw that many people seem to be using Ironwolf Pro drives. Since I plan on using the nas as a media drive only for movies and such, should the basic Ironwolf be enough or should I opt for the Ironwolf Pro? I would like to clarify that I’ll be getting a 2 bay unit only since I’m just starting out and only intend to use it for movies atm. I can always upgrade the unit later but I was wondering if I’ll see a significant difference between the Ironwolf and Ironwolf Pro with the differences in transfer rate, cache, etc.\n    submitted by    /u/Typical-Ad-491  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu91uw/first_nas_build/",
          "publishedOn": "2022-12-24T12:39:39.000Z",
          "wordCount": 18485,
          "title": "First NAS build",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu89r5/visionfive2_instead_of_raspberry_pi_4/",
          "author": null,
          "description": "Hi, I've been thinking about setting up my own Raspberry Pi 4 server. I want to use those services: pihole (certainly), duplicati2 (or something similar, certainly), FreeNAS/Nextcloud/Syncthing (one or two of them certainly), OpenVPN/WireGuard (maybe). I wanted to buy Raspberry Pi4 and connect 2 HDDs by USB3 to provide needed storage. I was quite certain Raspberry Pi 4 is a good idea, but the prices of 4 and 8GB editions are very high.\n Now there is those VisionFive2 that has better specs and much lower prices, but uses RISC-V processor. It's going to support Debian. Will the soft I mentioned work on it? Is it a good idea to use VisionFive2 instead of Raspberry Pi4 for such usecases?\n    submitted by    /u/Entrapped_Fox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu89r5/visionfive2_instead_of_raspberry_pi_4/",
          "publishedOn": "2022-12-24T11:46:06.000Z",
          "wordCount": 18618,
          "title": "VisionFive2 instead of Raspberry Pi 4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu7xax/ebook_library_server_with_editingannotations/",
          "author": null,
          "description": "What I would like....\n I have a relatively large academic text library in PDF, as well as the typical mobi (have kindle), epub, and even .lit (from my old surface pro days) ebook library. I would like a server that has persistent read state and ability to highlight/annotate/export annotations from the file. I would also like multi-user access.\n ​\n What I have tried.....\n Have been running calibre with calibre-web front end, which I don't mind and find the UI ok. The ability to track read status and custom column support in calibre-web is great. It's really only single user however when it comes to read states, etc. Also there is not persistent position in place.\n I have downloaded Kavita and it seems a lot closer to what I want (decide readers, syncs states, multiple user), but the metadata is horrible to non-existent for PDFs. Also when updating the container it wants to try to re-create the database each time for some reason.\n I have also tried audiobookshelf (have moved to this for audiobooks from plex/prologue). The audiobookshelf interface is great. They have ebook support in experimental which puts it beside/embedded with the audiobook, but the readers are horrible. I can just download the epub and send to my kindle or download the pdf (from web, not iOS app unfortunately), and could just upload the pdf back to audiobookshelf when completed.\n ​\n Are there any other options out there that I am missing? I have seen Koodo-reader but seems a bit early. Audiobookshelf or Kavita are developing but still not quite there yet. Calibre-web is closest (but really only single user), but still locked into calibre backend for sorting which I hate.\n Honestly considering just scrapping it and using a folder of sorted files for the time being.\n    submitted by    /u/Jmanko16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu7xax/ebook_library_server_with_editingannotations/",
          "publishedOn": "2022-12-24T11:20:40.000Z",
          "wordCount": 18697,
          "title": "Ebook library server with editing/annotations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu4xxn/convoy_v08_open_source_webhooks_proxy/",
          "author": null,
          "description": "Hey Friends, \n To close out the year, we shipped Convoy v0.8. This is such an exciting update for us; we shipped many updates we are proud of and excited to share with the community. You can just read on to learn more.\n Subscriptions Filtering\n Subscriptions Filtering is the act of subscribing for events based on the structure of the payload. It is one of our most exciting features. With this, webhook consumers can filter events they receive based on the payload. This includes two types of filters, from simple filters (exact object match) to complex matches (like $or, $in etc.) It would be best if you headed over to our docs to see a complete reference. See sample in action:\n Building a query with a sample payload\n Portal Links\n After deprecating applications, the \"app portal\" automaticall…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu4xxn/convoy_v08_open_source_webhooks_proxy/",
          "publishedOn": "2022-12-24T07:49:34.000Z",
          "wordCount": 19416,
          "title": "Convoy (v0.8) - Open Source Webhooks Proxy - Subscriptions Filtering, Static IPs, Portal Links, and much more! 🥳 🎉",
          "imageUrl": "https://external-preview.redd.it/Qf4a9s1R15F98D-YZaY17ZFeGbbNMsrx6W7n2LMyxpQ.jpg?auto=webp&s=4a8093af4e66d4060b1a707044ada1de6315a663"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu4lwu/wikijs_now_supports_asciidoc/",
          "author": null,
          "description": "https://github.com/requarks/wiki/releases/tag/v2.5.295\n    submitted by    /u/Farsighted-Chef  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu4lwu/wikijs_now_supports_asciidoc/",
          "publishedOn": "2022-12-24T07:27:16.000Z",
          "wordCount": 17874,
          "title": "Wikijs now supports AsciiDoc!",
          "imageUrl": "https://external-preview.redd.it/EBHioAUda2P5eczXBy6uZImOBgIJr9jaGA4sCQp3Duw.jpg?auto=webp&s=7b29250733539e4617f876aff759422ee0242b89"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu2nmy/any_caldav_web_client/",
          "author": null,
          "description": "I have a self hosted Baikal server and use jtx board as a client on the android phone. The android client supports \"Journals, Notes & Tasks\". I was wondering if there exists a web based client that supports all three features. I am particularly looking for the VJOURNAL and VTODO support. Thanks!\n    submitted by    /u/aadoop6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu2nmy/any_caldav_web_client/",
          "publishedOn": "2022-12-24T05:25:21.000Z",
          "wordCount": 18366,
          "title": "Any CalDAV web client ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu256e/why_should_you_self_host/",
          "author": null,
          "description": "submitted by    /u/io-x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu256e/why_should_you_self_host/",
          "publishedOn": "2022-12-24T04:56:09.000Z",
          "wordCount": 20593,
          "title": "Why should you self host?",
          "imageUrl": "https://preview.redd.it/8ppsm73r2s7a1.jpg?auto=webp&s=719c1563bc9ea9cc49d6dbde82aecdf61613c2d2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztx5y2/selectablesync_folder_from_my_headless_raspberry/",
          "author": null,
          "description": "I'm looking for something (possibly FOSS but I will check also paid software) that allow me to sync my external hard drive (mounted with open media vault) to google drive.\n I tried owncloud but it doesn't do it server side (and their client doesn't allow me to mount network attached storage on windows).\n Tried Rclone with Rsync as well but I need to select some folders and it's not so easy to manage through script. \n any solution is welcome. \n Sorry for any typo or error, english is not my mothertongue.\n Thanks\n    submitted by    /u/Novocaine85  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztx5y2/selectablesync_folder_from_my_headless_raspberry/",
          "publishedOn": "2022-12-24T00:32:28.000Z",
          "wordCount": 17459,
          "title": "Selectable-sync folder from my headless raspberry pi server to google drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztx59g/my_experience_standing_up_a_mastodon_instance/",
          "author": null,
          "description": "Currently stuck battling the Rona over the holidays so thought I'd write up my experience self-hosting something I didn't ever expect to - social media!\n Definitely an interesting journey - I started with the new Linuxserver.io Mastodon image, set up media storage in Backblaze, and stood up an instance of \"BirdsiteLive\" so I can still follow the twitter users I care about.\n https://eric-pierce.com/moving-to-mastodon/\n Hoping this is useful for someone, my full docker-compose is on github as well.\n    submitted by    /u/eric-pierce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztx59g/my_experience_standing_up_a_mastodon_instance/",
          "publishedOn": "2022-12-24T00:31:33.000Z",
          "wordCount": 17685,
          "title": "My experience standing up a Mastodon Instance, media hosting, and following Twitter accounts",
          "imageUrl": "https://external-preview.redd.it/zOg08DF9BYGQehZ24OsJ6TgTbJ14DQKHrCO0CsNzFX8.jpg?auto=webp&s=47d5e568c1fcf2874df02a06b13174e5a8f59a96"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztwirx/private_mastodon_or_other_alternative/",
          "author": null,
          "description": "Hi there,\n Since the borth of my daughter, I am searching a way to easily share news and photo of her with close friends and familly.\n I have a strict policy of no photos of my child on public social media.\n I was thinking making a private hosting of Mastodon but I fear that It may be overkill.\n What are your experiences managing it ?\n Is there some cool alternative out the that could be lighter ? :)\n Happy holidays everyone ;)\n    submitted by    /u/Stammfrei  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztwirx/private_mastodon_or_other_alternative/",
          "publishedOn": "2022-12-24T00:01:19.000Z",
          "wordCount": 17862,
          "title": "Private Mastodon, or other alternative ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztwgwd/self_hosting_as_a_christmas_gift/",
          "author": null,
          "description": "I’m kicking around the idea of giving “the gift of self-hosting” for next Christmas. The recipients, my nephews, are not super techy but intelligent and young enough to be relatively tech savvy. Even so, I want to streamline the setup process and minimize the amount of brainery required to use them. Here’s my thinking so far (I’d appreciate your input)…\n The giftees would receive: * An SBC-based server (inexpensive, small footprint, low power consumption) with… * An Ethernet cable to connect it to their router and… * A 4TB external storage drive * A personalized domain name * A personal website (something super simple that they could subsequently customize) or maybe a simple (i.e. TextPress) blog * Preconfigured (ImprovMX) forwarding for all their [wildcard]@mynewdomain.com email * A varie…",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztwgwd/self_hosting_as_a_christmas_gift/",
          "publishedOn": "2022-12-23T23:59:12.000Z",
          "wordCount": 20487,
          "title": "Self hosting - as a Christmas gift?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztvg9z/is_this_website_registrar_legit/",
          "author": null,
          "description": "Hey r/selfhosted,\n I'm unsure if this is the right subreddit to ask this but I'm trying to buy a domain and see one that I want available on this registrar for quite a bit cheaper than other registrars. The one I wanted was taken on other registrars but available on this one. I dont see much bad reviews or site claiming its a scam so I dont know what to think. Any thoughts? The site is regery.com\n    submitted by    /u/bIoodc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztvg9z/is_this_website_registrar_legit/",
          "publishedOn": "2022-12-23T23:11:11.000Z",
          "wordCount": 17762,
          "title": "Is this website registrar legit?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztvdvn/is_there_any_solution_available_to_backup_my_file/",
          "author": null,
          "description": "Looking for something like auto upload my photo from phone and auto sync in my home hdd.\n Also creat a two way sync for specific folder.\n    submitted by    /u/robertniro1980  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztvdvn/is_there_any_solution_available_to_backup_my_file/",
          "publishedOn": "2022-12-23T23:08:16.000Z",
          "wordCount": 16926,
          "title": "Is there any solution available to backup my file in cloud or object storage and play video or picture from there",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztvby2/strange_issue_with_nginx_proxy_manager/",
          "author": null,
          "description": "I'm not sure if my Google-Fu isn't working right or maybe I am asking the wrong question. \n I've not used NPM ever, and I am not super familiar with Nginx. I created some self-signed certificates, uploaded them in to NPM. When I access the a website it displays the error that the certificate is not valid. I do have the certificate in my trusted root, and my browsers do see it. I can't figure out why its doing this. For fun... I setup a copy of a docker container I am proxying traffic to through to NPM but, instead of using NPM with the copy I modified the local web server and added my self-signed and that works. No more errors. I didn't change the certificate in my trusted certs on my PC to make this work just didn't use NPM.\n I have no idea what I am missing. I've turned on all the radio buttons as needed ET CETRA.. Really kind of lost at this point.\n Any help?\n    submitted by    /u/AirItsWhatsForDinner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztvby2/strange_issue_with_nginx_proxy_manager/",
          "publishedOn": "2022-12-23T23:05:53.000Z",
          "wordCount": 17648,
          "title": "Strange issue with Nginx Proxy Manager??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv9vg/suggestions_for_selfhosted_cannabis_grow_journal/",
          "author": null,
          "description": "Anyone done this or alternatively have any experience running any self-hosted journals/diaries/logs that might also serve as a good grow log? \n I’ve used GrowDiaries on web as well as the GrowWithJane app, but I prefer not to have to upload all of my grow data/media in order to keep track. \n I would much rather have a self-hosted, private grow journal. I’m 100% legal, but also distrusting of other entities holding my data. Thanks for any suggestions!\n    submitted by    /u/DirtMetazenn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv9vg/suggestions_for_selfhosted_cannabis_grow_journal/",
          "publishedOn": "2022-12-23T23:03:15.000Z",
          "wordCount": 18320,
          "title": "Suggestions for Self-hosted Cannabis grow journal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv9el/simple_selfhosted_messaging_and_videocalls/",
          "author": null,
          "description": "Hi all,\n I have been working for a while in deploying a communitarian network in the rural region of Gandiol, Senegal, and I have been looking for a self-hosted messaging app like Whatsapp or Telegram. The main goal would be to have the following features:\n  \nText message exchange among individuals and groups.\n Image/Video exchange.\n  Audio/Video call support.\n  \nA solution I already found, looked promising but does not really end up working well, is to use rocket chat + jitsi. Instead of fighting to make this work properly, does anyone have some knowledge of any application that covers the features I mentioned before? Ideally would be an application that only do that, would like to avoid something more complex like Mattermost.\n Thanks everyone in advance and any idea is welcome :)\n    submitted by    /u/shunas6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv9el/simple_selfhosted_messaging_and_videocalls/",
          "publishedOn": "2022-12-23T23:02:38.000Z",
          "wordCount": 18634,
          "title": "Simple Self-hosted messaging and videocalls whatssapp/telegram like",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv877/diy_nas_truenas_scale_vs_proxmox_with_vms/",
          "author": null,
          "description": "I'm currently building a small NAS/Server to store my files and in the future host some docker containers (Tandoor, Bitwarden, Jellyfin, maybe the *arr-suite, etc.). I am using an asrock h370m itx that I plann to pair with an i3 9100 in a Jonsbo N1 with 5 HDDs for storage and 1 Sata SSD as a boot drive. In the future I could also add an nvme as a cache.\n As I understand, TrueNAS Core does not support docker as it is based on FreeBSD. TrueNAS Scale, however, does. So now I am torn between using Proxmox to setup a TrueNAS VM for my NAS use and a Linux VM for my docker/home server use.\n What option makes more sense? This is my first time building a home server that isn't just running Linux so I'm a little lost.\n    submitted by    /u/EmiMaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv877/diy_nas_truenas_scale_vs_proxmox_with_vms/",
          "publishedOn": "2022-12-23T23:01:10.000Z",
          "wordCount": 17539,
          "title": "DIY NAS - TrueNAS Scale vs Proxmox with VMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv7fe/access_a_single_file_via_nginx/",
          "author": null,
          "description": "Hi,\n I want to host a single file on my Raspberry Pi 4 using docker and nginx, such that when I go to subdomain.domain.tld it can retrieve the file contents stored on the local SD card on the RPi4. The file is an RSS file in XML format.\n How can I do this in the easiest way possible?\n    submitted by    /u/seriouslyfun95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv7fe/access_a_single_file_via_nginx/",
          "publishedOn": "2022-12-23T23:00:17.000Z",
          "wordCount": 17621,
          "title": "Access a single file via Nginx",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv14i/help_with_mediawiki_behind_nginx_proxy_manager/",
          "author": null,
          "description": "Hi all,\n Spun up a Mediawiki install on a Debian server today, and I'm absolutely stumped trying to get this to work behind a reverse proxy. If I go to the IP of the server/wiki, it works fine, but if I go to the subdomain that I configured for this - pointed at my nginx proxy manager docker container that is handling SSL for me - it loads the default apache page instead.\n I tried specifying a custom location in the proxy host of \"/\" with the forward being 192.168.1.54/wiki/, and that just gives me the Apache 404 page.\n I've changed the $wgServer parameter in LocalSettings.php to be wiki.mydomain.com.\n I'm not sure if I should be looking at the apache configuration on my server, or additional parameters in nginx...\n I also tried editing the default config file in /etc/apache2/sites-enabled/ to point to /var/www/html/wikias that's where the PHP files are located for Mediawiki, and restarted apache. No luck.\n Does anyone have a similar setup?\n    submitted by    /u/skooterz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv14i/help_with_mediawiki_behind_nginx_proxy_manager/",
          "publishedOn": "2022-12-23T22:52:20.000Z",
          "wordCount": 17829,
          "title": "Help with Mediawiki behind Nginx Proxy Manager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztu3t4/receiving_blog_replies_from_anywhere_on_the_web/",
          "author": null,
          "description": "submitted by    /u/spcbfr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztu3t4/receiving_blog_replies_from_anywhere_on_the_web/",
          "publishedOn": "2022-12-23T22:10:53.000Z",
          "wordCount": 17541,
          "title": "Receiving blog replies from anywhere on the web, including this very reddit post!",
          "imageUrl": "https://external-preview.redd.it/b3u2xqcox6NdwPu3zn4jeBEyjyrGfKNGkUjKM_2JH0Q.jpg?auto=webp&s=f521f534e8f1ec65a428c03419872316b02916d4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zttfal/need_getting_a_mastodon_server_up_im_so_close_i/",
          "author": null,
          "description": "I've followed this tutorial and gotten to the end but it's not quite working, I'm getting a 502 Bad Gateway error. But the reason I think I'm almost there is that the Favicon is loading correctly. https://social.pogo.community/ is where it's located at. \n I'm guessing this may be related to the fact I'm using \"Nginx Proxy Manager\" to make it so I can use this alongside my smarthome system I'm self hosting. Home Assistant. I'm not super confident I've set up that correctly. I followed a different tutorial to get that set up and I'm guessing there's just a minor configuration difference. \n During the mastodon tutorial I did skip the SSL Certbot step, since the Nginx proxy manager was already handling the SSL part, and I'm guessing this is where I screwed up. \n Here's the configuration options I tried in the Nginx proxy manager and what happened each time.\n What I did first, what I thought was correct based on the Nginx Proxy Manager I followed previously:\n ​\n When I did this, I'd get \\\"TOO MANY REDIRECTS\\\" error in the browser.\n As a test, I tried to set the scheme for https, with the forward port 443, I got this instead. Notice the mastodon favicon, that did not happen last time.\n And just for completion sake, here is the nginx configuration file on the server that's running mastodon: https://pastebin.com/aJZLKnhE\n    submitted by    /u/forte_the_infamous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zttfal/need_getting_a_mastodon_server_up_im_so_close_i/",
          "publishedOn": "2022-12-23T21:41:29.000Z",
          "wordCount": 18013,
          "title": "Need getting a Mastodon Server up, I'm so close I can taste it",
          "imageUrl": "https://external-preview.redd.it/AL7Kpmm2feaiR21UKcmKue0uX15GRyhyRZSw7Pcu-LI.jpg?auto=webp&s=96cc8cedf2f283289688ca05fe2220b0b6116b7a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zttcgu/docker_in_addition_to_scriptscode/",
          "author": null,
          "description": "I’ve lots of code on my server, mainly python and bash. A collection of them is running regularly by cronjob.\n Can I install docker and do some experiments with it without any disadvantages for my code folders?\n Thank you.\n    submitted by    /u/-happy2go  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zttcgu/docker_in_addition_to_scriptscode/",
          "publishedOn": "2022-12-23T21:38:00.000Z",
          "wordCount": 17434,
          "title": "Docker in addition to scripts/code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztsyjm/what_server_management_software_do_you_recommend/",
          "author": null,
          "description": "I have several VPSs and a homelab, it starts to be a small pain to monitor everything one-by-one so I would like to host some sort of dashboard (with controls) on one machine and aggregate information from all of my servers there.\n I know that there are solutions like pulseway, but I would like to use something selfhosted and free.\n    submitted by    /u/InkognetoInkogneto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztsyjm/what_server_management_software_do_you_recommend/",
          "publishedOn": "2022-12-23T21:20:47.000Z",
          "wordCount": 17440,
          "title": "What server management software do you recommend?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztr3ib/time_to_build_my_own_setup/",
          "author": null,
          "description": "Hey everybody! \n I have been working as a software developer for almost 10 years, and, for work stuff we always almost use cloud services.\n I love server less approaches etc, when it comes to handing a client an solution.\n But sometimes I do projects of my own, and in those cases I feel that the work becomes too much..\n Imagine just having the ability to run a Redis that allows my services to communicate, and then expose an Web App to show some data.\n So, here I am, I want to fix a home setup! \n The main goal is running small pieces of software that I build at home, and then often expose an Web App using Node to communicate with my Services.\n Where should I start? \n I have been looking at Synology and Qnap NAS as options, very cheap and seems really easy to get started with.\n Any recommendations and or guides to follow for this? \n Basically my goals are\n  \nRun Services through Docker (Only Locally)\n Expose WebApps running Node to reach the local services\n Attach Domain Names, I guess something needs to be done for DNS, or would a simple Redirect from my DomainProvider to my IP be enough? \n  \nMarry Christmas and Happy new Year\n    submitted by    /u/percybolmer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztr3ib/time_to_build_my_own_setup/",
          "publishedOn": "2022-12-23T19:58:08.000Z",
          "wordCount": 17513,
          "title": "Time to build my own setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztr2ev/festive_fun_christmas_present_checker/",
          "author": null,
          "description": "Hi r/selfhosted,\n I have created my own self hosted app (docker/python) to fill a gap in the market! A niche gap but a gap!\n Github Link : https://github.com/benkey0/ChristmasPresentChecker\n I love to make repeitive tasks slighlty easier like most of us do! Christmas presents involve lots of writing tags and lets face it tags arent fun!\n I have created a application to decode barcodes (using hardware scanner or device camera) and provide a front end solution for Christmas morning.\n You simply add sticky barcodes (printed with a thermal printer or ordered online for cheap!) onto your presents and add them into the Christmas Present Checker using the front end interface.\n Please see the below video.\n ​\n Scanning Video\n Essentialy this is my first time making something \"semi-useful\". I would appreciate some feedback and although its not as useful as most things shared here it may be something festive to play around with over this period!\n Merry Christmas!\n Ben\n    submitted by    /u/Diligent_Patience242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztr2ev/festive_fun_christmas_present_checker/",
          "publishedOn": "2022-12-23T19:56:45.000Z",
          "wordCount": 17464,
          "title": "Festive Fun ! - Christmas Present Checker",
          "imageUrl": "https://external-preview.redd.it/owXUdrMI8Fnr0hY4z_zciCLaA6tED9YDWY1i9zmFYME.jpg?auto=webp&s=35ea07721d9ad7f1fdf10c6dde8dd2c499f1f4e9"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztqzq7/a_simple_ansible_playbook_to_set_up_a_vps_with_a/",
          "author": null,
          "description": "I'm no sysadmin but I play around a lot with my VPS just for the heck of it and as a learning experience.\n I ended up automating part of my setup with Ansible.\n Host your stuff provides (among other things):\n  \nNextcloud instance (snap)\n \nVaultwarden instance (docker)\n \nSearxNG instance (docker)\n \nfail2ban\n \nBunkerweb\n \nRegular updates and backups for these services\n \nCerts using certbot\n \n This is born from my personal use case so it's pretty much a WIP and might have some rough edges here and there.\n However I though I'd share it around in case its of use for someone else.\n There are probably 100 better ways of doing this, any feedback is welcome.\n    submitted by    /u/not_real_user123321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztqzq7/a_simple_ansible_playbook_to_set_up_a_vps_with_a/",
          "publishedOn": "2022-12-23T19:53:20.000Z",
          "wordCount": 23747,
          "title": "A simple Ansible playbook to set up a VPS with a bunch of (hopefully) useful stuff",
          "imageUrl": "https://external-preview.redd.it/urlbXMSR7Sien89htGi0W1zLY4JofT-NM1BdZbrU9-A.jpg?auto=webp&s=1330c65281546f9fddab778066ef7a42aad6c10b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztphti/integrated_file_bookmark_and_note_storage_solution/",
          "author": null,
          "description": "I have been using my browsers bookmark manager to manage all of my bookmarks, but as the number of bookmarks that I have grows it is more difficult to manage them along with some problems with the manager itself. I have been trying to manage a growing number of local files, notes (notion).\n All of this has led me on a search for what I am calling an integrated storage solution, or a tool that will keep all of my files, bookmarks, and things of that nature organized. I would like to have a single file tree to manage files bookmarks notes and media. I currently use notion for my notes, and I am working on finding a way to integrate that.\n Next cloud has most of the functionality I believe I will need, and I may set up a server for it soon, but I want to see if there are any better options. I am ok with non self-hosted apps and self-hosted apps, and would prefer the software to not be a subscription (free option or one time purchase)\n Thanks for the suggestions and comments!\n    submitted by    /u/shalamander6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztphti/integrated_file_bookmark_and_note_storage_solution/",
          "publishedOn": "2022-12-23T18:47:32.000Z",
          "wordCount": 18761,
          "title": "Integrated file, bookmark, and note storage solution.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztjwce/folder_based_paperlessngx_alternative/",
          "author": null,
          "description": "I like paperless but cannot work with it without folder structure. \n Anyone knows if there is any alternative can organize files by traditional folder structure?\n    submitted by    /u/lyerx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztjwce/folder_based_paperlessngx_alternative/",
          "publishedOn": "2022-12-23T15:45:56.000Z",
          "wordCount": 18978,
          "title": "Folder based paperless-ngx alternative ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zthlti/vpn_solution_for_pesky_internet_connection/",
          "author": null,
          "description": "Hi,\n I''m spending more time than I want in some countries I don't want to name (somewhere in Asia), where the internet is sometimes problematic to use. I'll just say that they tried to use fake ssl certs on gov level before, and from my experience they are still trying to get access to peoples data.\n There are times when Wireguard works fine, then stop connecting at all. PPTP and L2TP are the most reliable (in term of creating a tunnel) but sometimes they also won't work. OVPN the same.\n Tried tailscale and netmaker, results vary.\n What do you recommend to set up on my home server (in EU) to reliably access?\n    submitted by    /u/ztardik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zthlti/vpn_solution_for_pesky_internet_connection/",
          "publishedOn": "2022-12-23T14:45:25.000Z",
          "wordCount": 18320,
          "title": "VPN solution for pesky internet connection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztabho/critical_security_flaw_reported_in_passwordstate/",
          "author": null,
          "description": "The selfhosted password manager (Passwordstate) we use at work just released patches for multiple critical vulnerabilities.\n \"Successful exploitation allows an unauthenticated attacker to exfiltrate passwords from an instance, overwrite all stored passwords within the database, or elevate their privileges within the application\"\n    submitted by    /u/SteppkenPislmick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztabho/critical_security_flaw_reported_in_passwordstate/",
          "publishedOn": "2022-12-23T08:32:20.000Z",
          "wordCount": 19111,
          "title": "Critical Security Flaw Reported in Passwordstate Enterprise Password Manager",
          "imageUrl": "https://external-preview.redd.it/uH26yve5W7BAGzo69LC2GTQqlYRtfPPHHfMg6rlSv_g.jpg?auto=webp&s=e6584d7afd8eb207398ca81bb444d56e74bb7e01"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt4b0m/lastpass_says_hackers_stole_customers_password/",
          "author": null,
          "description": "LastPass has issued an update about their security incident, in which apparently backups of customer vaults were accessed. I'm linking the techcrunch article as it summarizes what's new. You can read the security incident summary in its entirety here \n For those of you migrating from LastPass, note that their export tool is unreliable\n    submitted by    /u/DistractionRectangle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt4b0m/lastpass_says_hackers_stole_customers_password/",
          "publishedOn": "2022-12-23T02:39:03.000Z",
          "wordCount": 20225,
          "title": "LastPass says hackers stole customers' password vaults",
          "imageUrl": "https://external-preview.redd.it/XvgPeXQRCbjdZX0ubqq0KW7J1RjEyq_iOTYmhlHh3A8.jpg?auto=webp&s=e14c8afb5ffa7a6acd66d2c534b8e6d322eb3fd2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt2zke/minecraft_hosting/",
          "author": null,
          "description": "Hi, so I've look at the rates of minecraft server hosting providers and most are obscured but some are fair. Come to look at it, I could save a lot more by self hosting. So I've put together a list of specifications that would be amazing for my server! \n 128 GB of DDR4 RAM\n DUAL (2) CPU Slots\n 1 CPU with 3.5+ GHZ and 10+ Cores with multi threading\n NO GPU (its not needed, its just hosting)\n 200-400 GB of storage \n ​\n My budget is around 300-400, I've looked and found multiple parts just I can't find any that together. \n Thanks, Nicc\n    submitted by    /u/Nicholas_or_Nick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt2zke/minecraft_hosting/",
          "publishedOn": "2022-12-23T01:31:12.000Z",
          "wordCount": 17637,
          "title": "Minecraft Hosting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt2twd/traefik_vs_npm_vs_alternative_for_multiple/",
          "author": null,
          "description": "I'm currently hosting all my services on my Synology NAS. I've used the built in Synology reverse proxy (which uses nginx under the hood I believe) but was beginning the transition to traefik as I needed some more customizability as I was onboarding Authentik.\n I realized that one of the main advantages of Traefik is it's docker integration. Most of my services are running via docker on my NAS. I use portainer to manage my containers.\n I've got some additional machines on order which I'm intending to move several of my services to in order to lighten the load on my NAS and increase performance.\n With the use of multiple machines, Traefik docker integration may have less of an advantage. I still intend to user docker, just will be on multiple machines. Some x86 and some ARM. Should I continue with my Traefik migration or should I switch into setting up NPM or a different alternative instead?\n    submitted by    /u/speedhunter787  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt2twd/traefik_vs_npm_vs_alternative_for_multiple/",
          "publishedOn": "2022-12-23T01:23:18.000Z",
          "wordCount": 17721,
          "title": "Traefik vs NPM vs alternative for multiple machines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt26f3/pihole_dns_accessible_outside_of_network/",
          "author": null,
          "description": "Hello all, \n Just trying to educate myself and get experience with some projects and now that I have set up PiHole on my home network, I have configured a few of my devices to use the Pi’s IP for its DNS. If I were to take these said devices outside my home network, would they still be able to reach my Pi’s DNS? Or is that where I’d need to VPN in?\n Anything helps, thank you all\n    submitted by    /u/Dramatic-Ocelot-8024  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt26f3/pihole_dns_accessible_outside_of_network/",
          "publishedOn": "2022-12-23T00:51:06.000Z",
          "wordCount": 17616,
          "title": "PiHole DNS accessible outside of network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt1h49/apple_watchos_apps_with_offline_playback_for_self/",
          "author": null,
          "description": "As the title suggests, I'm looking for an Apple WatchOS app which supports offline playback for a self-hosted music streaming service. Unfortunately Plex (PlexAmp) has no interest in this despite many users requesting it.\n Other than Plex/PlexAmp, I currently have Navidrome as my streamer and substreamer client apps on Android/iOS devices. This works great for offline caching & online streaming. The only thing missing for me and family is offline playback on WatchOS for use without phone. (Think going for a run, working out in the gym etc).\n The only subsonic API compatible app that I have come across which has Apple WatchOS support for offline playback is AVSub - unfortunately the app is quite buggy and music playback on the Watch actually stops as soon as the watch screen turns off, so basically useless.\n Is there anything else out there or do I just need to pay the man and get a Tidal subscription?\n    submitted by    /u/Radiant_Armadillo489  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt1h49/apple_watchos_apps_with_offline_playback_for_self/",
          "publishedOn": "2022-12-23T00:17:05.000Z",
          "wordCount": 17012,
          "title": "Apple WatchOS apps with Offline Playback for Self Hosted music streaming.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt19wi/how_to_access_private_services_behind_vpn/",
          "author": null,
          "description": "Hello,\n I run multiple services on a VPS, as well as a VPN.\n All of the services are exposed to the Internet and can be publically reached. Now, I would like to have certain services behind a VPN, so they are not exposed.\n How to do this?\n What do I have to do in my docker config, so that it works? And what link would I have to use to access it? Given that I am connected with my VPN, would I be able to use localhost:port?\n ​\n I am using for example the glances service. I used the following docker compose:\n version: '3' services: glances: image: nicolargo/glances:latest-full container_name: glances ports: - \"61208:61208\" - \"61209:61209\" volumes: - /var/run/docker.sock:/var/run/docker.sock:ro restart: always environment: - \"GLANCES_OPT=-w -u user\" pid: host \n For me it is clear that I should not expose any ports. But I also dont know what else to do :)\n So all help is welcome!\n    submitted by    /u/nkls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt19wi/how_to_access_private_services_behind_vpn/",
          "publishedOn": "2022-12-23T00:07:53.000Z",
          "wordCount": 17792,
          "title": "How to access private services behind VPN?",
          "imageUrl": "https://external-preview.redd.it/Ee4t6QQ6KnWDzW2bBo7hPfjIdK9_PIV0ya97sSgVrYo.jpg?auto=webp&s=909021084bd9b9562679a27949ab6aa845520a22"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsxchw/docker_app_with_pdf_search_engine/",
          "author": null,
          "description": "So: I have accumulated lots of PDF Books, Spec sheets etc over the years. I want toto host a docker APP, wich enables me to look up a something, in multiple PDF files. A big plus would also be, text recognition for pdf files that have the \"text as photos\"(??hope you understand??) i know nextcloud has similar funkcionality, but i would perefer Docker APP´S specificly made for this.\n I hope i made you understand what i want... Thanks!\n ​\n Edit: Is Paperless-NGX a good idea for what i want?\n    submitted by    /u/TheRealFAG69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsxchw/docker_app_with_pdf_search_engine/",
          "publishedOn": "2022-12-22T21:27:20.000Z",
          "wordCount": 17328,
          "title": "Docker APP with PDF \"Search engine\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zswv8k/webmail_client_with_desktopmobile_apps/",
          "author": null,
          "description": "Hello, I am looking for a webmail client to selfhost, to which I can connect with a desktop and/or mobile app.\n The idea would be to centralize my email connections into the hosted webmail instance, and then stream the mails into my laptops and phones. Something like having a roundcube instance, with all my emails (that I can connect to on the browser), and then a desktop app (like thunderbird) that would get all that data.\n I tried cypht and roundcube, but I didn't find any way to.\n Any idea on a specific setup that could work?\n    submitted by    /u/redditubvco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zswv8k/webmail_client_with_desktopmobile_apps/",
          "publishedOn": "2022-12-22T21:06:54.000Z",
          "wordCount": 17239,
          "title": "Webmail client with desktop/mobile apps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zswi8f/homepage_kubernetes_support_a_christmas_gift/",
          "author": null,
          "description": "Having played around with a number of homepage/dashboard options, I finally came to settle on Ben Phelp's Homepage. It's fast, customisable and well implemented.\n The only problem I have with it is that it doesn't natively support Kubernetes Ingress discovery, and required me to duplicate all my ingress config in to homepage config.\n My solution? To build a sidecar process to scan my Kubernetes cluster and build a configuration file automatically.\n Current features:\n  \nIngress Discovery\n Hide/Show by default and override.\n Simple Config: \n Name\n Groups\n Descriptions\n Icons\n Ping/Healthcheck config\n \n Widget Config: \n Type\n `key` secret from kubernetes secret\n \n  \nYou can find it on GitHub here: https://github.com/uatec/homepagesc\n    submitted by    /u/uatec  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zswi8f/homepage_kubernetes_support_a_christmas_gift/",
          "publishedOn": "2022-12-22T20:51:50.000Z",
          "wordCount": 16878,
          "title": "Homepage Kubernetes Support - A Christmas Gift",
          "imageUrl": "https://external-preview.redd.it/9u6ims4xeHX3k5ec1aAYVnCtG6VyU_yuW4oDfSVdAYM.jpg?auto=webp&s=a44f7abe43d5c5f2324cce70b32988b096fdc99b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zswc7o/nextcloud_mail_sieve/",
          "author": null,
          "description": "Hello.\n Anybody is using with success the Sieve function in Nextcloud Mail (webmail) ?\n I can connect without errors but Sieve filter rules box is empty.\n Not sure how should it look since I did not use Sieve.\n Please advise.\n Thanks.\n    submitted by    /u/wideace99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zswc7o/nextcloud_mail_sieve/",
          "publishedOn": "2022-12-22T20:44:30.000Z",
          "wordCount": 17465,
          "title": "Nextcloud Mail Sieve",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsw9j6/nextcloud_on_nas_or_proxmox/",
          "author": null,
          "description": "I'm looking at setting up NextCloud on my home LAN, strictly for personal use (at this point). I have a Synology DS920 with a handful of Docker containers on, and I have Proxmox running on a 1L USFF PC that I can put a VM, container, etc. on as needed. Both are on the same gigabit LAN. \n The backend storage would probably end up being on the NAS either way, given the relative storage available between the two.\n Would I be better off setting up NC in Docker on the Synology, or in a VM or LXC container on the proxmox host, and why?\n Thanks!\n    submitted by    /u/memilanuk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsw9j6/nextcloud_on_nas_or_proxmox/",
          "publishedOn": "2022-12-22T20:41:10.000Z",
          "wordCount": 18412,
          "title": "NextCloud - on NAS or Proxmox?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsvn1h/cant_decide_between_ovh_or_hetzner_any_help/",
          "author": null,
          "description": "I run a few discord bots and some backend services such as user credentials and they require SQL server, this is not for work but rather for private usage and i also run a Pihole dns server aswell.\n ​\n I have per now:\n 3 vcore 4GB ram VPS from Hetzner and i love their hour billing and easy to scale and downscale and that you can simply delete and spin up and down servers using snapshots i really love it, however it get's more expensive in the long run and it's a VPS so the cpu will be a bottleneck in the long run.\n ​\n I also have a kimsufi\n CPU\n Intel Xeon E3-1245v2 - 4c/8t - 3.4 GHz/3.8 GHz\n RAM\n 32 GB 1333 MHz\n Data disks\n 2×800 GB SSD SATA\n ​\n However there is no RAID and a old cpu from 2012 and some slow disks that should have been replaced, i don't like that i have to monitor my disk …",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsvn1h/cant_decide_between_ovh_or_hetzner_any_help/",
          "publishedOn": "2022-12-22T20:14:14.000Z",
          "wordCount": 20490,
          "title": "Can't decide between OVH or Hetzner any help?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsvfl5/turning_my_old_pc_into_a_server_thoughts_and/",
          "author": null,
          "description": "Hi guys,\n Maybe I should start with that I'm almost a complete noob at this and I'm learning it on the go so I would be grateful if you can spare me your sarcastic comments and mockery. Thanks//\n So, I have some thoughts about turning my old PC into a server. What would I need for running it smoothly? It has a 1TB SSD, i5 3.2 processor, and 16 Gb RAM. I have 2 external HDDs so I can place my data there - music, movies, etc. I can run Docker for the servers. I'm thinking about one music server - maybe Airsonic-Advanced - to remotely access my library, one movies server - maybe Jellyfin, because I can install it on my android TV, and some proxy or VPN - maybe Tailscale, because it's easy for me to set it up.\n Right now, I've installed WSL and Docker on Windows 11 (my current PC) to run my servers, but my old PC is collecting dust and laying in the closet so I'm thinking about making it like a personal server and moving my containers there. The thing is that those VM are much RAM consuming (maybe like 40%) and I have 32 Gb. Right now I'm running Tailscale on PC so the connection with the server wouldn't be much of a problem - local and remote. I've worked all my life on Windows, but I'm eager to learn new things and I think that Linux is more appropriate for those types of stuff(or at least what I'm reading from people guides and comments).\n So my question is should I continue to work on Windows - install it on my old PC and run my Docker containers on WSL again or should I install Linux and try learning it on the go? Also, what about FreeNas or OpenMediaVault? Are those systems better for the things which I want to run and would be hard for me to configure them and access them from my PC?\n Please, tell me your thoughts about this, because I'm in a dilemma about which path I should go to. Thanks in advance!\n    submitted by    /u/No_Breakfast9359  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsvfl5/turning_my_old_pc_into_a_server_thoughts_and/",
          "publishedOn": "2022-12-22T20:05:17.000Z",
          "wordCount": 19441,
          "title": "Turning my old PC into a server - thoughts and opinions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsuy8v/open_source_webhooks_as_a_service/",
          "author": null,
          "description": "Ken from Svix here.\n We help our customers send webhooks by offering them a full webhook sending solution. We have a hosted version which is based on the Svix open source project.\n The open source project can be self-hosted (and many people do!), so I thought I'd share it here.\n I'd also love to take this opportunity to ask for feedback. What can we do to make it even easier to self-host Svix? You can check out the instructions on the README. I think things are fairly simple, but we would always like to improve.\n Here's the repo if you want to check it out: https://github.com/svix/svix-webhooks\n    submitted by    /u/SvixKen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsuy8v/open_source_webhooks_as_a_service/",
          "publishedOn": "2022-12-22T19:44:55.000Z",
          "wordCount": 17627,
          "title": "Open Source Webhooks as a Service",
          "imageUrl": "https://external-preview.redd.it/fGbRUOwzM00KeJ9qJN9CqW6kop-ZLQUSnKT0hJyx9o0.jpg?auto=webp&s=439cf3a6a66e1301f35620d36f2aa96b3b02408a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zstrjq/beginner_looking_for_more_to_self_host/",
          "author": null,
          "description": "Hi self-hosters,\n I've been silently following this subreddit for a really long time. First of all, thanks a ton to everyone out here. You guys have inspired me and motivated me to self-host.\n Cutting things short, my current set up looks like:\n An old Sony VAIO Laptop (i3 330m, 2+4GB RAM, 1TB 5400RPM HDD) as a Proxmox server with the following Ubuntu 22.04 LTS CT(s):\n  \nAdGuard Home : Primary DNS Resolver\n Radarr + Prowlarr + qBitTorrent + JellyFin : Media Server\n SnapDrop : Useful LAN File Share Utility\n ArchiveBox : Useful Web Archiving Utility\n  \nA Raspberry Pi 3B+ with Raspberry Pi OS Lite as a Backup AdGuard Home DNS Resolver (synced from Primary)\n These two together are currently serving my purposes really well, while not adding up electricity bills significantly.\n I used to host Vaultwarden and FreshRSS as well. For Vaultwarden, I do not benefit from the client-server synced up model as although I tried convincing my family, none of them uses a Password Manager. Provided it's just me and I don't really need my passwords on phone a lot, I prefer KeePassXC on my one and only Linux laptop. Same reason for FreshRSS. I used to use it with the self hosted instance of http://ftr.fivefilters.org to get Full Text RSS feeds but, I ended up feeling better with QuiteRSS. I read feeds on a single machine and full text feed isn't really a must-to-have. \n My family is really happy with Adblocking DNS, Archiving and LAN File Share utilities and mainly because of the Jellyfin media server. \n I'm really looking forward to add more useful tools/utilities. Please recommend some services that you self host yourself and are very useful/utilitarian in nature for you and your family. \n (No dashboard. No Reverse Proxy like Caddy. Already considered but I'm fine without them. I've also considered the Awesome Self-Host and Sysadmin Github repositories.)\n Thanks in advance. Peace!\n    submitted by    /u/itsmypc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zstrjq/beginner_looking_for_more_to_self_host/",
          "publishedOn": "2022-12-22T18:54:36.000Z",
          "wordCount": 18876,
          "title": "Beginner looking for more to Self Host.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zssh2o/movary_self_hosted_web_app_to_track_and_rate_your/",
          "author": null,
          "description": "Hey community!\n For years I was only a user of open source projects, now I want to give a little bit back.\n I have created movary, a self-hosted web application to track and rate watched movies, similar to services like trakt.tv or letterboxd.com. After years of tracking my watch history with commercial services I was getting afraid what would happen if one of these services would stop providing their website or if they \"lose\" their databases. What about my watch history and ratings? I wanted access to this data in an easy and reliable way, so I started working on this project. It stores all used (meta)data locally, provides third party api integrations with e.g. plex and a few things more (check the README of the project).\n I think I want to release the first stable version soon and would be happy over any feedback.\n    submitted by    /u/sysLee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zssh2o/movary_self_hosted_web_app_to_track_and_rate_your/",
          "publishedOn": "2022-12-22T18:00:41.000Z",
          "wordCount": 18155,
          "title": "Movary - Self hosted web app to track and rate your watched movies",
          "imageUrl": "https://external-preview.redd.it/ELLlB2owlf60O4F3GhOmzLoeB11JlkjPBckZBELvKmE.jpg?auto=webp&s=1afa79a78be61de84224e49d08cc6c061bfb4deb"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zss61q/introducing_nmctl/",
          "author": null,
          "description": "submitted by    /u/mesh_enthusiast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zss61q/introducing_nmctl/",
          "publishedOn": "2022-12-22T17:48:46.000Z",
          "wordCount": 17576,
          "title": "Introducing NMCTL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsqx9y/unifiedpush_a_decentralized_opensource_push/",
          "author": null,
          "description": "submitted by    /u/Routing8493  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsqx9y/unifiedpush_a_decentralized_opensource_push/",
          "publishedOn": "2022-12-22T16:59:34.000Z",
          "wordCount": 19272,
          "title": "UnifiedPush: a decentralized, open-source push notification protocol",
          "imageUrl": "https://external-preview.redd.it/buEgLaGtEpA7L6P4KxL_DpMC0HyFvA0df4c0TaIe3nc.jpg?auto=webp&s=e6e1be3f7a5c79287971bbb0e6850ced50442fff"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsqg2w/different_docker_instances_of_browser_per_user/",
          "author": null,
          "description": "Hi.\n I have synology nas server, firefox browser in docker and openvpn-client in docker as well. Firefox works via openvpn-client.\n But now i need different instances of firefox per user; the openvpn-client container better to be the global single instance for all firefoxes, but it doesn't have to be. Also i can switch to another browser if necessary, this is not a problem.\n So, when the user connects, a new browser container should be created and then deleted when the user's session is over.\n What is the best way to do it?\n    submitted by    /u/EvgeniyDoctor317  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsqg2w/different_docker_instances_of_browser_per_user/",
          "publishedOn": "2022-12-22T16:39:37.000Z",
          "wordCount": 17564,
          "title": "Different docker instances of browser per user",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zspzfx/kasm_rdp_need_some_help/",
          "author": null,
          "description": "After reading the post from yesterday about Kasm Workspaces, I've decided to try it.\n I have issues with RDP connections, none of them is working.\n Tried three different Windows machines (Win 10 variants), one local on the same VM host, one connected via LTE, 20-30 ms away (wireguard), and the third about 180 ms away (L2TP) from the KASM server.\n All of them are sitting on the loading screen, \"Creating a secure connection...\"\n At the same time if I fire up the Remmina workspace I can connect to all three without issues.\n Any hint what I'm doing wrong?\n Edit: I am running Kasm behind Nginx Proxy Manager, the Zone settings a set according to the manual.\n Edit 2: Made a short test. Connected with Remmina to the local Windows VM, then started the Workspace linked to the same machine.\n The expected result is to kick away Remmina client and accept the new one. After starting the Kasm client Remmina is still connected and stays like that.\n    submitted by    /u/ztardik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zspzfx/kasm_rdp_need_some_help/",
          "publishedOn": "2022-12-22T16:20:53.000Z",
          "wordCount": 17301,
          "title": "KASM RDP - need some help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zso6bu/a_simple_ansible_playbook_to_setup_a_self_hosted/",
          "author": null,
          "description": "submitted by    /u/GHOST__ROX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zso6bu/a_simple_ansible_playbook_to_setup_a_self_hosted/",
          "publishedOn": "2022-12-22T15:05:46.000Z",
          "wordCount": 17418,
          "title": "A simple Ansible playbook to setup a self hosted wireguard server with a web GUI to add and remove clients.",
          "imageUrl": "https://external-preview.redd.it/m2Zw83T9od5ED7MKQlgbUZ7X_1Qr4b1Olrb9TedORIg.jpg?auto=webp&s=8bc290b0c1f76e4a5584d5cecdfb8178e95a9fe5"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsnh1p/phone_system_for_small_business/",
          "author": null,
          "description": "Hi Selfhosted,\n I do not know much about VOIP/PBX systems so I aplogize if I have some information incorrect in my request. I will try to keep it in plain english.\n I am looking to have a self hosted solution that will allow me to make and receive phone call using my cell phone. I want to have a separate phone number from my personal cell number. I don't mind if the call is forwarded to my personal cell. I just do not want to give out my personal phone number. \n ​\n Are there any self hosted PBX systems available that would provide me with a phone number as well as have ability to push the calls to my cell phone or ability to take calls from my cell phone?\n    submitted by    /u/Quick_Parsley_6482  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsnh1p/phone_system_for_small_business/",
          "publishedOn": "2022-12-22T14:34:16.000Z",
          "wordCount": 19264,
          "title": "Phone system for Small Business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsmbxt/forwarding_docker_container_ports_to_subfolders/",
          "author": null,
          "description": "I am trying to get all my services as docker containers to be accessible through subfolders of the same domain.\n E.g., I have a text matching service running at the port 8080 and picoshare at 4001. I want to access these like this -> mydomain.com/text-matching and mydomain.com/picoshare. \n I can sort of do this with just nginx (without nginx proxy manager) using the conf file which looks similar to this ->\n ​\n upstream picoshare { server picoshare:4001; } server { server_name mydomain.com; listen 443 ssl; ssl_certificate ./fullchain.pem; ssl_certificate_key ./privkey.pem; ssl_dhparam ./dhparam.pem; include ./options-ssl-nginx.conf; location /text-matcher { include uwsgi_params; uwsgi_pass text_matcher:8080; } location /picoshare { proxy_pass https://picoshare; } } \n However I want to use nginx proxy manager to achieve this. I also need to redirect all HTTP calls to HTTPS.\n    submitted by    /u/nerzid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsmbxt/forwarding_docker_container_ports_to_subfolders/",
          "publishedOn": "2022-12-22T13:41:04.000Z",
          "wordCount": 18635,
          "title": "Forwarding docker container ports to subfolders under the same domain with nginx proxy manager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zshygu/web_browser_testing_tool/",
          "author": null,
          "description": "Hey, I'm looking for a secure way to host different web browsers through a portal such as Windows Remote Desktop Services or other similar alternatives. I know Remote Desktop Services wouldn't be the best way to achieve this, so I'm hoping there exists a solution specifically made for this purpose.\n I'm looking to set up something similar to Browserling.com but running locally in my network. I want a secure way to open links that may be malicious without fears of infecting my system, or just a way to test different web services with a clean browser each time.\n Are there any self hosted alternatives out there that i can set up on my VMware esxi machine? What setup would be the most secure for this?\n Any leads would be much appreciated :)\n    submitted by    /u/Benjameenn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zshygu/web_browser_testing_tool/",
          "publishedOn": "2022-12-22T09:33:12.000Z",
          "wordCount": 17135,
          "title": "Web Browser testing tool",
          "imageUrl": "https://external-preview.redd.it/hm6mn33X7woJjE5kbq9d2vK_t7H1MIILoHDErDfa2vM.jpg?auto=webp&s=01c584068e056ac294cd774a2a8b5962a85a07c7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsf2zf/is_there_any_self_hosted_apps_available_for/",
          "author": null,
          "description": "I would like to get all the update for all people i follow? Like rss reader.\n Is any software available for that?\n    submitted by    /u/robertniro1980  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsf2zf/is_there_any_self_hosted_apps_available_for/",
          "publishedOn": "2022-12-22T06:52:29.000Z",
          "wordCount": 16689,
          "title": "Is there any self hosted apps available for twitter like rss reader?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs7846/website_and_network_device_ping_status/",
          "author": null,
          "description": "Looking for something to replace Uptime robot now they have changed their pricing. Preferably a windows based tool that I can run on one of my internal servers that can then send an email when something goes down. Dont mind paying for a tool and have been baying $84 a year\n    submitted by    /u/Bear_Hardy_DD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs7846/website_and_network_device_ping_status/",
          "publishedOn": "2022-12-22T00:51:24.000Z",
          "wordCount": 18441,
          "title": "Website and network device ping status recommendation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs6109/is_it_ok_if_my_custom_domain_used_for_applying/",
          "author": null,
          "description": "For example, if I'm applying a role at Reddit my email will be [\"reddit@bobsmith.com](mailto:\"reddit@bobsmith.com)\".\n I personally love it, it looks cool, clean, neat and helps me track which company is spamming me. And if I don't want anymore communication from certain company I could just turn that alias off in Simple Login.\n It's the setup for my other general purpose domain which doesn't contain my name, don't know how companies considering my job application will like it.\n If this is a bad idea, how about [\"contact25@firstlast.com](mailto:\"contact1@firstlast.com)\"? So instead of company name, I'm assigning a unique number to each company.\n    submitted by    /u/JustARandomPerson135  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs6109/is_it_ok_if_my_custom_domain_used_for_applying/",
          "publishedOn": "2022-12-22T00:02:57.000Z",
          "wordCount": 19070,
          "title": "Is it ok if my custom domain used for applying for jobs looks like \"companyname@firstlast.tld\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs5qv0/engineering_a_thumbprint_in_a_digital_certificate/",
          "author": null,
          "description": "Hello everyone,\n I have seen several VoIP apps use self signed certificate thumbprints as a form of verification during key exchange. \n Two certificates cannot have the same thumbprint. However, can a certificate be engineered/coded to have the same thumbprint as the original certificate? \n If this is not, how is it not possible? \n Additionally, what is a digital signature? \n Thank you.\n    submitted by    /u/Striker0073  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs5qv0/engineering_a_thumbprint_in_a_digital_certificate/",
          "publishedOn": "2022-12-21T23:51:54.000Z",
          "wordCount": 18167,
          "title": "Engineering a thumbprint in a digital certificate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs5aac/xxxx999tld_or_xxxx24365tld_for_my_custom_domain/",
          "author": null,
          "description": "The domain that I wanted (for email only) was taken so I'm adding numbers to the end of it, like \"@xxxx999.tld\" or \"@xxxx24365.tld\". 999 is short and consists of 3 repeating numbers but could be mixed up with other numbers?? 24365 is unique because it stands for 24 hours 365 days but it's kinda long and looks bit random at first sight.\n Better ones like 123, 101, 24, 365 etc were taken so these two are the best I can come up with. Also available are 000, 222, 444, 555, 888.\n If I were to give my email to you, which one do you think looks better and is easier for you to rememer? Like it sticks and less likely to be confused with something else etc. Just like I'm not going for 3650 because people might forget the 0 at the end.\n    submitted by    /u/JustARandomPerson135  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs5aac/xxxx999tld_or_xxxx24365tld_for_my_custom_domain/",
          "publishedOn": "2022-12-21T23:34:10.000Z",
          "wordCount": 18322,
          "title": "@xxxx999.tld or @xxxx24365.tld for my custom domain?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs54wr/do_you_need_vlans_if_you_use_vpn/",
          "author": null,
          "description": "I am new to homelabbing, and I am trying to figure out networking and security. I found out that it is better to have separate subnets or vlans for your home devices and your homelab, in case the latter gets compromised. I am hosting services only for myself, so I do not really need public access to anything, but I would like to have remote access to my self-hosted services.\n I saw different solutions, like cloudflare tunnelling, port forewarding, and more, but they all \"require\" you to have the homelab at least on a different vlan to be truly \"secure\". Anyway, it is not clear for me how then the home devices will have access to the services. Do they connect to the server as if they would remotely? In any case, this is not truly important because the route I would like to follow is differe…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs54wr/do_you_need_vlans_if_you_use_vpn/",
          "publishedOn": "2022-12-21T23:28:42.000Z",
          "wordCount": 18848,
          "title": "Do you need vlans if you use vpn?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs4sq1/photo_hosting_photoprisim_alternative/",
          "author": null,
          "description": "Hey I have Photo Library with over 10k+ photos (.cr2 +Jpg). i am searching for a PhotoPrisim alternative because i does not support Multiuser login. i need \n  \nRaw suppport\n Multi user login\n Use existing library\n Share photos with Other users (without scanning the library for every user)\n Users can change their own password or some kind of signup solution inbuilt.\n  \n   submitted by    /u/Snoo_66088  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs4sq1/photo_hosting_photoprisim_alternative/",
          "publishedOn": "2022-12-21T23:15:51.000Z",
          "wordCount": 17732,
          "title": "Photo Hosting (photoprisim alternative)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs4d27/tool_to_help_me_organizing_tools_and_supplies/",
          "author": null,
          "description": "Well as having a workshop full of tools and spare parts is useful, but only useful when you actually know where the tools are, nothing worse then\n I am investing full on the millwakee packout system, and taking the time to invetory everything. I am wondering if there is a self hosted tool for this, or is a libreoffice calc spreadsheet is my best choice.\n Something web based, which good cache or offline support, and a decent mobile interface (either app, or a web that mobile friendly) would be me.\n    submitted by    /u/masterkorp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs4d27/tool_to_help_me_organizing_tools_and_supplies/",
          "publishedOn": "2022-12-21T22:59:33.000Z",
          "wordCount": 18068,
          "title": "Tool to help me organizing tools and supplies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs3qym/connecting_radarr_and_sonarr_to_my_own_seedbox/",
          "author": null,
          "description": "Hi there!\n My apologies if this seems like a lot of text. I'm trying to provide as much detail as possible! Also, I consider myself a noob, I'm just good at following the docs :)\n I have an unraid server, in location A, running all the -arrs in docker. On location B, there's a raspberry pi running transmission.\n Since both of these locations are behind a CGNAT, I'm trying to use Tailscale to connect them. However, when I try to add transmission to the -arrs using its Tailscale IP, I get this error: \"Unable to connect to transmission (Sonarr)\" or \"Unknown exception: A task was canceled. (Radarr)\"\n ​\n My setup:\n Unraid server running each -arr in a separate container, on the brigde network mode, and one container running Tailscale on the host network. I can successfully access the web dashbo…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs3qym/connecting_radarr_and_sonarr_to_my_own_seedbox/",
          "publishedOn": "2022-12-21T22:37:04.000Z",
          "wordCount": 19502,
          "title": "Connecting Radarr and Sonarr to my own seedbox through Tailscale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs258n/question_about_how_to_get_media_on_plexjellyfish/",
          "author": null,
          "description": "I’m extremely new to all this but I was wondering how people add media like movies or tv shows onto Plex or Jellyfish. I’m still deciding between the two but I’m having trouble understanding how people download the movies and shows. Do people buy the movies/shows from somewhere? Do they pirate it? Where do people download their media from? I’ve seen YouTube videos where someone said some people turn their CDs to digital versions (onto Plex, Jellyfish, etc). But I’m not interested in owning the physical and digital copy. I do have services like Disney+, Hulu, etc. Do people somehow download the movies on there onto Plex/Jellyfish? I apologize if this sounds really dumb.\n    submitted by    /u/Typical-Ad-491  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs258n/question_about_how_to_get_media_on_plexjellyfish/",
          "publishedOn": "2022-12-21T21:52:32.000Z",
          "wordCount": 18723,
          "title": "Question about how to get media on Plex/Jellyfish",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrzchc/npm_authentik_qbittorrent/",
          "author": null,
          "description": "I have a domain with 3 subdomains; each pointing to an app.\n Current setup: - npm.domain.com - auth.domain.com - qbittorrent.domain.com\n I managed to deploy qBittorrent behind Authentik, but what I'd like to enhance this by preventing second login page of qBittorrent.\n My current flow is: qbittorrent.domain.com -> auth.domain.com -> qbittorrent.domain.com (with second login page)\n I have a user in authentik with the same username/password for qBittorrent. So is it possible to forward the username/password given to authentik to qBittorrent.\n Thanks in advance!\n    submitted by    /u/Wils93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrzchc/npm_authentik_qbittorrent/",
          "publishedOn": "2022-12-21T20:08:44.000Z",
          "wordCount": 18466,
          "title": "NPM + Authentik + qBittorrent",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zry99b/is_it_possible_to_connect_to_a_home_server/",
          "author": null,
          "description": "I would like to have a Raspberry Pi server with a VPN so I can access it outside of my network. \n The VPN will have to be on the raspberry pi along with the server because I’m unable to instal it on a router. It’s a shared router, and other users watch Netflix, which won’t work with the VPN.\n I only want to use the VPN on client devices when outside of my network. When I connect back to my network, will I still be able to access the server without connecting to the VPN?\n    submitted by    /u/ALCF98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zry99b/is_it_possible_to_connect_to_a_home_server/",
          "publishedOn": "2022-12-21T19:28:07.000Z",
          "wordCount": 19694,
          "title": "Is it possible to connect to a home server without a VPN when at home but use one only when outside of the network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zruxhk/looking_for_a_selfhosted_management_and_patching/",
          "author": null,
          "description": "Hello, \n I am looking for a self-hosted low-cost or free solution to potentially replace Pulseway for me. I would like to find something that is along the lines of Pulseway I have tested tacticalrmm but the Linux agents are not free. I have also tried MeshCentral & Rport but they do not offer app installation or system monitoring. \n Here are things that I would like to do :\n Windows & Linux agents .. mac optional not really needed. \n Remote desktop access\n Remote file storage access\n Software management\n System recourse logging ( CPU, memory, storage, network )\n Powershell, CMD, Linux terminal to run scripts\n Patch management\n Notifications for events - high CPU / ram usage / offline device. \n I do not mind running 2 solutions so long as they can be run and remote systems can communicate without the need for VPN.\n    submitted by    /u/sesipod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zruxhk/looking_for_a_selfhosted_management_and_patching/",
          "publishedOn": "2022-12-21T17:26:14.000Z",
          "wordCount": 18942,
          "title": "Looking for a self-hosted management and patching software.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zru2ps/threshold_skill_levels_to_set_up_home_security/",
          "author": null,
          "description": "Hello, apologies in advance for formatting and also capitalization, doing this on mobile.\n I am new to this community and the concept of self hosting. I’m trying to decide if it is better to hire a local company to setup or if this is something I can or should learn to handle myself. \n I would rate my own skills between low and medium. i’ve built a couple gaming computers, i like to run mods on most games. i have a vpn on my phone, but honestly couldn’t tell you the technical side of what it does. i know i should have it on my router but i don’t. pretty basic stuff. I know very little about network architecture if that’s even the right term. Im reading through a couple DIY guides that seem to makes sense conceptually, but i am rapidly becoming overwhelmed with the technical jargon.\n The end goal is an outdoor surveillance that i can view from my phone and will give me notifications when movement is detected. i’ve been using nest but have not been impressed. Essentially that’s all the functionality i need, but might want some room to grow into automation.\n So my question is, is this worth it to push through this barrier to entry and learn or is this something best left to trusted professional? \n what does something like this even cost in terms of hardware?\n are there any recommendations for a place to start? videos? Hell, i’ll even take book recommendations. \n thanks for reading\n    submitted by    /u/Whiskey_Elemental  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zru2ps/threshold_skill_levels_to_set_up_home_security/",
          "publishedOn": "2022-12-21T16:57:26.000Z",
          "wordCount": 19073,
          "title": "threshold skill levels to set up home security system and associated questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrqxuz/what_next/",
          "author": null,
          "description": "I bought a ThinkCentre to use as a server a while back, but I'm not sure I'm ready yet. I feel like I have a decent grasp on Linux, I can vaguely understand how the internet works, I can follow installation guides for self-hosted stuff and look things up when I get stuck. But I still feel like a beginner, y'know? I don't know enough to start leaving holes in my firewall with 100% confidence that I won't get DDOSed or hacked or doxxed, so I don't. Everything I've made so far has either stayed in my private network or only been left open for a few hours at most. \n Ideally I'd like to run a simple blog website, a VPN, maybe a Minecraft server, and maaaaybe a private Mastodon instance if I can handle it. I know all of this would have to be publicly exposed, so how do I go about publicly exposing servers safely? If this is still too advanced for the level I'm at (which I imagine it is), what's the best learning path for me to get there? Books, websites, tutorials, etc?\n Thanks for your help!\n    submitted by    /u/camel-cultist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrqxuz/what_next/",
          "publishedOn": "2022-12-21T15:35:25.000Z",
          "wordCount": 19453,
          "title": "What next?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrqaeq/looking_for_a_client_server_dms_for_home_use/",
          "author": null,
          "description": "Hey everyone,\n I'm a total newbee when it comes to DMS and I am looking for a little open source DMS that I can host in my home network with proxmox.\n The idea is to use the new scanner I just got that allows my to scan to 5 different network folders that I can predefine.\n What I want\n  \npdfs should automatically be saved/converted to OCRed pdfs\n pdfs should be renamed yyyy_mm_dd (file created date)_FoldernameSomeNumber\n Client-Server DMS that let's me search for text fragments, ideally automatically reads the date from letters and puts in in a field, maybe the same for the title and idealy I can pre-configure some attributed that reoccruing letters have in order to apply certain tags, maybe even rename the documents etc.\n  \nIs that doable? Is it a reasonable approach?\n    submitted by    /u/HerrLux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrqaeq/looking_for_a_client_server_dms_for_home_use/",
          "publishedOn": "2022-12-21T15:20:41.000Z",
          "wordCount": 18608,
          "title": "Looking for a client server DMS for home use",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrogt8/folks_as_an_indie_i_have_to_pay_multiple/",
          "author": null,
          "description": "submitted by    /u/Abishek_Muthian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrogt8/folks_as_an_indie_i_have_to_pay_multiple/",
          "publishedOn": "2022-12-21T14:37:44.000Z",
          "wordCount": 17699,
          "title": "Folks, As an indie I have to pay multiple commissions for selling digital items on payments hosts like Gumroad. So I have built a self-hosted, Minimalist, FOSS(MIT), Dockerized payments host. Introducing Open Payment Host! Feedback and feature suggestions are much appreciated",
          "imageUrl": "https://external-preview.redd.it/RnN-OFnDKGDDQw2j9kKJUUfIbkubiRvR0FmqtW6jWnk.png?format=pjpg&auto=webp&s=b3f83d4fe479cbf158fd22afe116db4dee1dfb8a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrmt1t/serpbear_v02_adds_google_search_console/",
          "author": null,
          "description": "submitted by    /u/towfiqi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrmt1t/serpbear_v02_adds_google_search_console/",
          "publishedOn": "2022-12-21T13:49:20.000Z",
          "wordCount": 18536,
          "title": "SerpBear v0.2 , Adds Google Search Console Integration",
          "imageUrl": "https://external-preview.redd.it/CAkPucYOJ7xJlRyzCitYG6QuSMCiISwRB7PpjLcf08Q.png?format=pjpg&auto=webp&s=b6114440d13cc55e3cc1184a9d9764c54d54aac4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrl9xg/good_cron_gui/",
          "author": null,
          "description": "Are there any good cron WEB UI? Or some dedicated script runner?\n I want to run scripts/cli utilities and preserve their output and examine each separate run in some sort of web page\n    submitted by    /u/dmzkrsk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrl9xg/good_cron_gui/",
          "publishedOn": "2022-12-21T13:09:06.000Z",
          "wordCount": 18892,
          "title": "Good Cron GUI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrkokx/immich_and_ldap/",
          "author": null,
          "description": "I am planning to switch to Immich because it seems to be the simplest photo manager to use for my family. I am currently using Photoprism and none of my family wants to use it. Also, Immich supports multi-user which is what I after. I use FreeIPA to centralize my users (family and friends). I deploy Immich and don't see an option to do LDAP. The docs says to use OAuth. \n  \nDoes OAuth involved 3rd party service? \n Has anyone got LDAP working with Immich?\n  \nI really don't want to use the local account due to too many usernames/passwords to maintain and update.\n    submitted by    /u/forwardslashroot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrkokx/immich_and_ldap/",
          "publishedOn": "2022-12-21T12:53:35.000Z",
          "wordCount": 18724,
          "title": "Immich and LDAP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrh8bh/switching_to_promox/",
          "author": null,
          "description": "Good day\n I have a Linux machine as my server, it's currently running with a few Docker images and Linux services. And 1 VM(home assistant)\n My question is, how easy would it be to migrate to promox with my services and docker images as they are\n    submitted by    /u/Lanten101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrh8bh/switching_to_promox/",
          "publishedOn": "2022-12-21T11:09:20.000Z",
          "wordCount": 21430,
          "title": "switching to promox",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrftql/selfhosted_desktop_and_gui_application_containers/",
          "author": null,
          "description": "submitted by    /u/justin_kasmweb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrftql/selfhosted_desktop_and_gui_application_containers/",
          "publishedOn": "2022-12-21T09:45:08.000Z",
          "wordCount": 23883,
          "title": "Self-Hosted Desktop and GUI Application Containers Launched Instantly and Delivered to Your Browser with Kasm Workspaces - New Release 1.12: Windows RDP Workspaces / Gamepad Passthrough / Steaming Improvements / Updated UI",
          "imageUrl": "https://external-preview.redd.it/_7UCl5SpxbrISZOy0EsWOXCHh5kZ0CHm0RaJLpLi8D0.png?format=pjpg&auto=webp&s=a00966d40078388de5eaff3068545f16601ecd49"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrfpc8/how_do_you_remember_all_your_local_ips/",
          "author": null,
          "description": "Between all my ipcameras, switches, computers? How to you guys keep up with your ips Spreadsheet?\n    submitted by    /u/Anooj2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrfpc8/how_do_you_remember_all_your_local_ips/",
          "publishedOn": "2022-12-21T09:37:15.000Z",
          "wordCount": 19134,
          "title": "How do you remember all your local ips?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zr5xkc/looking_for_a_recomendation/",
          "author": null,
          "description": "Is there any way to sync my firefox profile on a self hosted server?\n    submitted by    /u/SaggingLeftNut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zr5xkc/looking_for_a_recomendation/",
          "publishedOn": "2022-12-21T01:07:11.000Z",
          "wordCount": 18662,
          "title": "Looking for a recomendation.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zr1qtw/a_twitterlike_app_for_ios_that_uses_s3compatible/",
          "author": null,
          "description": "submitted by    /u/lowonkarmaz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zr1qtw/a_twitterlike_app_for_ios_that_uses_s3compatible/",
          "publishedOn": "2022-12-20T22:27:30.000Z",
          "wordCount": 17791,
          "title": "A Twitter-like app for iOS that uses S3-compatible services (Minio support soon) as the backend",
          "imageUrl": "https://external-preview.redd.it/3FMbRj3VCqZiJU4LL1kK8mcCKoet72rC0HLjte7-Mts.jpg?auto=webp&s=3087e165a5eca657a1d885485905f655a397ac8d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zr13zi/cant_access_my_server_using_reverse_proxy_and/",
          "author": null,
          "description": "So, let me paint you a picture. :) So, I have an OpenMediaVault 6 server in the house, with some services like radarr, sonarr and so on, all in docker, with swag+duckdns for the reverse proxy setup, and that worked great, until a few days ago. In a thunderstorm, my modem and router died. I have my own modem, I don't use my ISP's modem. But now I have to, until I buy something new. So, now, with this modem I can't access my services outside the house. Not even from the house, I get this error when I test it from my PC:\n The connection has timed out\n The ports are forwarded. The weird thing is, my friend has the same setup, exept he has his own router, but he uses the same ISP modem, we are on the same ISP. I set up his OMV, everything, opened ports, all of it. And it works fine with him.\n I thought maybe the issue is because I'm using only the modem, without a router, because that's the only difference, but I had the same issue whenever I tried to swap modems, while I still had the router, during some testings and stuff.\n I've just checked the settings in his modem via AnyDesk, and they are literally the same. I can access his services from my house without issues.\n The modem is ZTE ZXHN H168N V3.1 .\n I don't know what else to post here, if you ask me I can post some screenshots or settings.\n Any ideas guys?\n    submitted by    /u/Nabukodonosor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zr13zi/cant_access_my_server_using_reverse_proxy_and/",
          "publishedOn": "2022-12-20T22:02:23.000Z",
          "wordCount": 18568,
          "title": "Can't access my server using reverse proxy and ISP's modem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zr0g8l/what_are_all_these_random_tunnel_names_that/",
          "author": null,
          "description": "submitted by    /u/CrispyBegs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zr0g8l/what_are_all_these_random_tunnel_names_that/",
          "publishedOn": "2022-12-20T21:36:21.000Z",
          "wordCount": 18630,
          "title": "What are all these random tunnel names that cloudflared keeps creating??",
          "imageUrl": "https://preview.redd.it/jez7g63kg47a1.png?auto=webp&s=584d36a18f0b36cb4fc35cb1d8a18db1c17d6d6a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqzu3v/gcloud_cloudvpn_vs_openvpn_ac/",
          "author": null,
          "description": "hello for thousands of users i will set up vpn server for vpc network on a google cloud. Do you think I should use cloudvpn or openvpn, what are the differences?\n    submitted by    /u/Eastern-Narwhal3169  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqzu3v/gcloud_cloudvpn_vs_openvpn_ac/",
          "publishedOn": "2022-12-20T21:12:22.000Z",
          "wordCount": 19258,
          "title": "gcloud cloudvpn vs openvpn ac",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqzr3i/monica_crm_install_help_it_is_working_but_not/",
          "author": null,
          "description": "I believe all my settings are correct. When I access monica from the localhost, everything works fine. When I put it behind a proxy (swag with its preconfigured conf) it strips out all the styling and says things about some content not being secure, and basically doesn't work. Any advice? Thanks.\n    submitted by    /u/superRedditer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqzr3i/monica_crm_install_help_it_is_working_but_not/",
          "publishedOn": "2022-12-20T21:09:11.000Z",
          "wordCount": 17907,
          "title": "monica CRM install help. It is working, but not behind proxy. Settings implemented following the instructions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqyire/seafile_plex_pihole_on_an_old_laptop/",
          "author": null,
          "description": "I am looking to set up a server with the following requirements-\n  \nBackup and serve my files (documents, photos and videos) across various computers and iPhone \n Serve my local movie library to my living room tv using Kodi on android tv and iOS device \n Auto backup photos from my iOS device camera roll\n View all my old photos on my iOS device in a nice gallery, by efficiently downloading just what I’m viewing and deleting after to maintain low storage usage on my phone \n Block ads on my home network \n Maybe also run a vpn to get adblocking on my iPhone when I’m on the mobile network through the pihole?\n  \nWhat’s the best way to achieve this? Based on my current research it seems like seafile + plex + pihole should do the trick. But is there a better way?\n Will running all this on an old laptop work well?\n Is there any benefit to running pihole on a standalone pi zero instead of on the laptop with all this other stuff?\n Thanks for your help!\n    submitted by    /u/Deep-Thought6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqyire/seafile_plex_pihole_on_an_old_laptop/",
          "publishedOn": "2022-12-20T20:19:48.000Z",
          "wordCount": 19514,
          "title": "Seafile + Plex + PiHole on an old laptop?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqyg79/i_created_a_library_of_fullcolor_svg_icons_of/",
          "author": null,
          "description": "TL;DR:\n 300+ full-color SVG icons of homelab-related software, products, and brands for use in dashboards, network diagrams, etc...\n https://github.com/loganmarchione/homelab-svg-assets\n See a preview of all icons here\n  \nIn my dashboards and network diagrams, I was using the already existing SVG icon sets (Simple Icons, Bootstrap Icons, Font Awesome, etc...), as well as random PNG/JPG files I found online. However, I always wanted consistently-sized full-color SVGs (instead of black/monotone or random PNG/JPG files).\n I gathered 300+ SVGs so far, and wanted to share them here.\n https://github.com/loganmarchione/homelab-svg-assets.\n I don't intend to replace any existing icon sets. Instead, I'm focused on homelab-related software, products, and brands ONLY.\n I have the following features so far:\n  \nConsistent viewbox (48x48)\n Optimized with SVGO\n Diagrams.net library (this is the reason I created this project)\n CDN (via jsDelivr)\n PHP (via Packagist)\n Node (via NPM)\n Hugo (via module)\n  \nThings I'm working on:\n  \nAdding more icons\n Gathering brand usage guidelines\n Gathering registered trademark (®) or trademark (™) symbols to be added\n Creating more automation for deployments\n  \nI created this for myself, but figured it might be useful here!\n    submitted by    /u/lmm7425  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqyg79/i_created_a_library_of_fullcolor_svg_icons_of/",
          "publishedOn": "2022-12-20T20:16:54.000Z",
          "wordCount": 17840,
          "title": "I created a library of full-color SVG icons of homelab-related software, products, and brands that I'm using in my network diagrams. It was going to be a personal project, but I thought I'd share it here.",
          "imageUrl": "https://external-preview.redd.it/Od6c8m8c_j8U4QXiuxTc9RQ89Dg-YjJ11M9dES3lZeM.jpg?auto=webp&s=05cbf4b3b987a4f32e59bc2bad7f25b5bebbdfd3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqy8q2/appsmith_selfhosted_solution_for_building/",
          "author": null,
          "description": "Hello there,\n I'm Vihar from Appsmith, and I'm here to share a major update on Appsmith's release (1.8.11).\n Introducing Auto-height for Appsmith widgets—A top requested feature, Auto-height now flexes your Appsmith apps to dynamic changes in content, conditional visibility, and end-user screens.\n With this update,\n 1️⃣ Text widgets now fold around the content inside. Smooth!\n  \n👌 unstructured content from databases like Snowflake, Redshift, and Firebase.\n 😍 for social media dashboards, consumer survey analyses, and store reviews.\n  \nAuto-height for text\n 2️⃣ Triggering the 𝚒𝚜𝚅𝚒𝚜𝚒𝚋𝚕𝚎 widget prop conditionally? Let’s take your white-space worries away.\n  \nfor apps with sidebars, as shown in our example ↓.\n  \nAuto-height for conditionally visible blocks\n 3️⃣ Auto-height-enabled widgets also change their size to change screen sizes.\n  \nfor stock inventory updates, on-site checks, and forms for field teams.\n  \nAuto-height for the mobile-layouts\n 4️⃣ What you see when building apps is what you get when viewing it, say, with Containers and the Canvas.\n Auto-height for the canvas\n What's next?\n  \n𝚖𝚒𝚗-𝚖𝚊𝚡 heights in widget props\n  \nOn by default for all widgets with 𝙻𝚊𝚋𝚎𝚕 props\n Computing auto-height when dragging a widget for better performance\n \n  \nTrack it all and comment ↓\n https://github.com/appsmithorg/appsmith/pull/18341\n P.S.: Appsmith can be run on Docker and K8s. The entire code is open-sourced under Apache-2.0 license. For more details, visit our GitHub.\n    submitted by    /u/vihar_kurama3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqy8q2/appsmith_selfhosted_solution_for_building/",
          "publishedOn": "2022-12-20T20:08:32.000Z",
          "wordCount": 19962,
          "title": "Appsmith - Self-hosted solution for building Internal Tools, CRUD Apps, Dashboards, and more - Now ships auto-height for Widgets 🎉",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqxev2/what_to_do_about_nextclouds_missing_two_way_sync/",
          "author": null,
          "description": "I've been using a managed instance of Nextcloud for some time and it's worked quite well for me so far. But since I switched to Obsidian for notetaking, the lack of two-way sync in the Android client is a huge annoyance. \n The corresponding issue on Github has been open since 2016 and even though there are a few hundred dollars bounty exposed, nothing is moving there.\n I don't even want to talk about the fact that two-way sync is the most basic feature of a cloud service.\n What can I do about it?\n  \nUsing a third-party app like folder sync contradicts the whole privacy idea of having your own Nextcloud instance\n Switching to OneDrive together with an encryption app isn't really an option since I'd like to be able to access my files for example on my work machine where I can't install any encryption apps.\n Is there an alternative to Nextcloud which is able to do two way sync on Android and Windows?\n Any other ideas...?\n  \n   submitted by    /u/wmrch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqxev2/what_to_do_about_nextclouds_missing_two_way_sync/",
          "publishedOn": "2022-12-20T19:35:13.000Z",
          "wordCount": 18518,
          "title": "What to do about Nextclouds missing two way sync?",
          "imageUrl": "https://external-preview.redd.it/b3_8daR0WBu4-TKcVtWrO6RIWUcmHrLaHF9MtGa6laY.jpg?auto=webp&s=428c9d4ba0ee05a981fc74952b01511275b40e9e"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqvzz1/i_miss_having_users/",
          "author": null,
          "description": "I ran dialup bbs's in the 90's, and I built and admin'd an \"online university\" that had a pretty decent student count, and now years later I just do back end. I kind of miss having users. What could I self host and actually have some users? I've got servers collecting dust and gigabit up/down, but I've just got no actual motivating ideas. Does anyone still know what a bbs is/was? What is the modern day equivalent? Infotainment, messagey, with games. Can run on window, linux, most databases, anything. Mastodon was fun for like a day. Fun enough to pay 11 bucks for a domain to test it, but nah, too specific. Something that can still be fun without a ton of users, couple hundred might be nice.\n    submitted by    /u/ScuzzyUltrawide  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqvzz1/i_miss_having_users/",
          "publishedOn": "2022-12-20T18:39:26.000Z",
          "wordCount": 20379,
          "title": "I miss having users",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqveqk/why_are_my_some_of_my_heimdall_tiles_sometimes/",
          "author": null,
          "description": "submitted by    /u/CrispyBegs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqveqk/why_are_my_some_of_my_heimdall_tiles_sometimes/",
          "publishedOn": "2022-12-20T18:15:50.000Z",
          "wordCount": 17855,
          "title": "Why are my some of my Heimdall tiles sometimes unresponsive? (details in comments)",
          "imageUrl": "https://external-preview.redd.it/RDyphlliu2eQTh5EQXbJvJejI8SgO9mJ4maO-Vur0oQ.png?format=pjpg&auto=webp&s=8e5e5b87f22fd6dba6366401aa0e43bcc018a3f3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqun0x/nextcloud_vs_syncthings/",
          "author": null,
          "description": "Currently using syncthings to back my phone up to storage at home and its doing the job wonderfully. A friend of mine and I were disgusting our setups and he was telling me about nextcloud doing the same thing but with more features. Neither of us had used the other so we couldn't properly compare pros and cons.\n Those who have used both, which did you end up with and why?\n    submitted by    /u/29Top  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqun0x/nextcloud_vs_syncthings/",
          "publishedOn": "2022-12-20T17:45:12.000Z",
          "wordCount": 18014,
          "title": "Nextcloud vs syncthings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqujp8/dashboard_suggestions/",
          "author": null,
          "description": "I see there are a lot of different Dashboard options. Homer, Homepage, Heimdall etc. What are the key differences between them and what do you guys use?\n    submitted by    /u/pivotpixels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqujp8/dashboard_suggestions/",
          "publishedOn": "2022-12-20T17:41:28.000Z",
          "wordCount": 18408,
          "title": "Dashboard suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqu16l/content_management_software/",
          "author": null,
          "description": "Hello, I am the tech guy of an indie game team and we are working on a game similar to Dance Central and we have songs, avatars, playlists, DLC store etc. in game.\n I am looking for a self hosted content management website where we can control mentioned content above, I have some requirements.\n  \nNo SSO behind a stupid paywall (LDAP can work too)\n A good REST API\n Ability to customize the software so I can hook it up with a custom library I made in Node that connects to our cloud service and creates folders for those songs/avatars/playlists (basically a way to hook it up when a content gets CMUD)\n  \nI have tried Strapi, it was an OK solution but not having an SSO and not being able to customize the routes to add my library was a minus.\n I tried PayloadCMS for a while and the team used it but I had to implement my own SSO which would get erased by each update to come. I like how it had a good REST API and how customizable it was but it looked very unfinished and the GUI was really empty.\n Ability to use the software in Docker compose would be a plus.\n    submitted by    /u/btt79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqu16l/content_management_software/",
          "publishedOn": "2022-12-20T17:20:37.000Z",
          "wordCount": 18809,
          "title": "Content Management Software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqtt1m/possible_to_host_podsync_on_android/",
          "author": null,
          "description": "I really want to convert YouTube channels to podcast feeds in a simple uncomplicated way. Podsync seems to tick all the boxes but I was wondering if I could host it on my android device?\n    submitted by    /u/adamjturner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqtt1m/possible_to_host_podsync_on_android/",
          "publishedOn": "2022-12-20T17:11:38.000Z",
          "wordCount": 17660,
          "title": "Possible to host podsync on android?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqrnn0/how_to_automatically_recreate_dockercompose/",
          "author": null,
          "description": "So I have a Synology NAS running docker, and a bunch of containers, that I start with sudo docker-compose up -d . \n The docker file is located in /volume/docker/docker-compose.yml and that folder is available to me on the local network, so I can just edit it directly on my PC.\n I'd like to have the containers automatically restart whenever I save changes without having to ssh into the nas to rerun the command myself. \n I could probably just write a script that will monitor the file, but is there an off the shelf solution to this that I can use?\n    submitted by    /u/Asalas77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqrnn0/how_to_automatically_recreate_dockercompose/",
          "publishedOn": "2022-12-20T15:43:13.000Z",
          "wordCount": 19336,
          "title": "How to automatically recreate docker-compose containers whenever a change is made to the YAML file?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqq86o/cannot_access_aaaa_domain_outside_of_home_network/",
          "author": null,
          "description": "Hello guys.\n I am trying to set up a self hosted server on my rasp. My Nginx server is running on docker and listening on port 80 and [::]:80 with a simple index. I bought a domain name too in which I used an AAAA record type to use the IPv6 address of the raspberry itself as my provider is using cgnat and I don't have a unique public ip for port forwarding etc. I can access the domain from all devices in my local network without a problem, my index page is showing up fine. However when I try to access it from the public, for example using my network data or from another network, chrome either doesn't load (from mobile data) or throws DNS_PROBE_FINISHED_NXDOMAIN (at least to the network my friend tried).\n I have enabled ufw in my server with opening port 80 to the public as well as allowing forwarding to docker and adding the rules found in https://github.com/chaifeng/ufw-docker. Dns seems to be completely propagated. Even if I disable ufw, the situation remains the same and no log is showing up when I access it from outside when the firewall is enabled.\n My nginx conf:\n server {\n listen 80;\n listen [::]:80;\n server_name example.com www.example.com;\n root /usr/share/nginx/html/;\n index index.html; }\n and firewall rules related to port 80:\n 80 on eth0 ALLOW Anywhere\n 80 (v6) on eth0 ALLOW Anywhere (v6)\n 80/tcp ALLOW FWD 192.168.1.0/24\n 80/tcp ALLOW FWD Anywhere\n 80/tcp (v6) ALLOW FWD Anywhere (v6)\n Even when I try to get a certificate from LetsEncrypt I get The Certificate Authority failed to download the temporary challenge files created by Certbot.\n Do you have any idea what misconfiguration could be on my side or what the problem could be?\n    submitted by    /u/UnluckyPr0gr4mm3r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqq86o/cannot_access_aaaa_domain_outside_of_home_network/",
          "publishedOn": "2022-12-20T14:41:14.000Z",
          "wordCount": 19768,
          "title": "Cannot access AAAA domain outside of home network",
          "imageUrl": "https://external-preview.redd.it/KPHRMitYZCNWtmWl2FTLICyH_UhbeuEOXK6CNV190vI.jpg?auto=webp&s=f634f819655867502f4a94eac54cb285890ab145"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqpb6w/survey_bandwidth_offerings_in_cloud_computing/",
          "author": null,
          "description": "Hey fellow Selfhosters!\n Apologies if this is the wrong place or way to ask for this help, but I need help from here for my college project, please take 3-5 mins from your time if you can :)\n I'm writing a research paper about a Fixed Cost Cloud service model where initially the user will be allotted 1Gbps as is the norm, and after 1TB (or whatever the plan might be), the user will be throttled to 50Mbps, but they won't be billed for the Transfer.\n I'm empathizing with needs of a self hosted community, a small business or a student professional whose bandwidth needs might not be a lot and the traffic is in small chunks, but they're paying the cloud providers for their Bandwidth Over usage.\n I need your advice for this project. I know it cannot work for everyone, Hence I need your response and suggestions for this.\n We (me and my batchmate) have also launched a Google Form and we'll be glad if you could take the small time to fill that.\n https://docs.google.com/forms/d/e/1FAIpQLSfBLf8M4uIy4SwSbFZkCKfEhjp49-BPeCX6IlFikfhGUqAu0g/viewform\n Any advice would be appreciated. Thank you :))\n    submitted by    /u/_diamondzxd_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqpb6w/survey_bandwidth_offerings_in_cloud_computing/",
          "publishedOn": "2022-12-20T14:01:35.000Z",
          "wordCount": 23980,
          "title": "[Survey] - Bandwidth Offerings in Cloud Computing",
          "imageUrl": "https://external-preview.redd.it/S_fx0DIFtMDmvQ_BkNiCmqnKD9E4E7Wwp-fG86u_NBU.jpg?auto=webp&s=5a43f8d566a45922586cd6827d241cb5b875babb"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqp7el/security_of_wgeasy/",
          "author": null,
          "description": "I recently installed wg-easy on my home network to be able to safely remote into my network. However, to be able to add new clients, while not being at home, I exposed the dashboard of wg-easy to the public, which is only protected by a password. \n I don't have any concerns regarding the complexity and length of my chosen password, but is it safe to exposed said dashboard to the public?\n    submitted by    /u/Inety  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqp7el/security_of_wgeasy/",
          "publishedOn": "2022-12-20T13:57:42.000Z",
          "wordCount": 18820,
          "title": "Security of wg-easy",
          "imageUrl": "https://external-preview.redd.it/ONGBEJKiR7JFRJ4ZTcLf9dOXODm0OnsZiNq5v7gapsY.jpg?auto=webp&s=c4484645a9be927cfaddce222ea4e095c4b19515"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqobcu/your_spotify/",
          "author": null,
          "description": "Hi there everyone I have been looking into Your Spotify (https://github.com/Yooooomi/your_spotify) have set everything up according to the documentation but after the redirect from the Spotify login page it won't log in and load the dashboard is there anyone that has successfully installed it and got it to work? would really love some help with this one\n    submitted by    /u/MethDonut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqobcu/your_spotify/",
          "publishedOn": "2022-12-20T13:19:45.000Z",
          "wordCount": 18529,
          "title": "Your Spotify",
          "imageUrl": "https://external-preview.redd.it/ldFRVs8-iasXgTgrs3ugXJnOiQt-pEhMlwM0CSxh89M.jpg?auto=webp&s=3714283bdc0a6f9c248ecd86e9e18e54caaaca48"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqnn4b/bypassing_university_internet_restrictions_for/",
          "author": null,
          "description": "Hey everyone,\n I'm a student at a university that's located a bit far from the city, and the WiFi and mobile data connections here are really spotty. On a good day, we might get 10-15 Mbps at best, and it's really inconsistent, especially in the dorms. The university library does have a wired fiber connection that gives us 200 Mbps+ on average, but the issue is that they have a Sophos Proxy/Firewall setup that blocks a lot of entertainment websites like Netflix, Prime Video, and Disney+. YouTube is still accessible, though.\n I have a problem where I need to update Microsoft Flight Simulator (40 GB worth of updates!) and work with my personal NextCloud Drive, which would sync a lot faster with the faster internet connection at the library. I use Tailscale and an Nginx Proxy Manager to manag…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqnn4b/bypassing_university_internet_restrictions_for/",
          "publishedOn": "2022-12-20T12:50:37.000Z",
          "wordCount": 19904,
          "title": "Bypassing University Internet Restrictions for Legal Purposes (to access my homeservers/raspberry Pis/VPS)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqmvkj/free_and_opensource_js_form_builder_with_support/",
          "author": null,
          "description": "https://surveyjs.io/form-library/documentation/get-started\n https://preview.redd.it/9nlgxix9o17a1.png?width=1372&format=png&auto=webp&s=3aa66b677485e974150b174d8687e87e27345ffa\n    submitted by    /u/SurveyJS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqmvkj/free_and_opensource_js_form_builder_with_support/",
          "publishedOn": "2022-12-20T12:15:08.000Z",
          "wordCount": 17860,
          "title": "Free and Open-Source JS Form Builder with support for React, Angular, Vue.js, jQuery, and Knockout. It's also server- and database agnostic. You can install the npm package and run surveys, polls, quizzes, and other web forms in your app for free. Follow the getting started link for details.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq81xm/do_you_guys_use_mealie_or_tandor_recipes/",
          "author": null,
          "description": "i have currently set up Mealie but i am wondering whether Tandoor would be something worth trying out\n    submitted by    /u/Neon_44  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq81xm/do_you_guys_use_mealie_or_tandor_recipes/",
          "publishedOn": "2022-12-20T00:01:55.000Z",
          "wordCount": 17959,
          "title": "do you guys use Mealie or Tandor Recipes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq7i0j/centralized_email_client/",
          "author": null,
          "description": "Hey Guys,\n I am not sure if this is the right subreddit to ask in, but I give it a go.\n I’m soonly deploying a truenas scale server with a couple of petabytes with data. On this server, unrelated to the data, I want to host a centralized email client. Primarily client. It maybe sounds weird, but it makes sense for my situation. To make a long story short, in bullet points what I am searching for:\n — Self hosted centralized email client\n - Readily available apps on different platforms (android, ios, ipados and preferable ubuntu/windows/etc)\n - The client has to have compatibility with exchange, google mail, smtp/imap/pop3 mailservers located elsewhere and the client also needs a server attached to serve some domain names with a mail server itself.\n ​\n The idea, in more practical terms, is to have really all the email en adresses in one place that can be accessed from anywhere. For example: if I grab a new device somewhere (shared pc, new phone on the airport, a borrowed ipad on a site somewhere, etc); I just want to be able to grab the accompanying app or use the web interface and have access to all my mails and mail adresses (from and for very different sources).\n ​\n I have looked at quite a few solutions, but nothing I found until now did have everything I need. For now I just manage many different adresses and some are loaded in some devices, some aren’t; some I just only use the web gui for the specific purpose it has. I just want to centralize everything and be able to use whatever device I can grab wherever I am to get the work done that needs to be done.\n ​\n Sorry for the long post and let me know if I overlooked some service or result or if I missed something in the rules of this sub reddit.\n ​\n Ps. Things like 2 auth and sorting/categorizing/GTD and so forth are also nice to have, and probably important. But these things pale in comparison to the functionality I‘m looking for described as above\n    submitted by    /u/Axoridex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq7i0j/centralized_email_client/",
          "publishedOn": "2022-12-19T23:39:41.000Z",
          "wordCount": 19109,
          "title": "Centralized Email Client",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq6otu/selfhosted_alternative_to_trakt/",
          "author": null,
          "description": "Hi all,\n Not sure if you know about what's been happening with Trakt these last couple of days. They had some sort of database crash and it's taking several days to recover (and it seems that data's been lost).\n Now, with the service offline, I noticed how dependent I am of it. So I was thinking about possible similar selfhosted solutions. What I'm looking for is something that:\n  \nMay import my current history from Trakt (in fact not being a VIP user I still don't know if Trakt allow history export).\n Allow Kodi scrobbling (that's important, since I manage all my media library through Kodi and it has a Trakt addon, making it trivial to automatically sync everything I watch).\n  \nI found this project (MediaTracker) that I installed a couple of days ago and seems very promising, but it apparently has no way to automatically sync from Kodi.\n Do any of you could suggest any alternative?\n    submitted by    /u/xleonardox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq6otu/selfhosted_alternative_to_trakt/",
          "publishedOn": "2022-12-19T23:08:21.000Z",
          "wordCount": 19398,
          "title": "Selfhosted alternative to Trakt",
          "imageUrl": "https://external-preview.redd.it/f8mBIANTOYw_QJZTYuFGE2WKg9L1WnVcIz67ffQMVcw.jpg?auto=webp&s=6665c93350f0c7b4117c28f9fa5e390cf3d9eee2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq3s4g/diy_router_hardware_suggestions/",
          "author": null,
          "description": "our ancient NetGear router looks like it's finally shitting the bed.\n I really would like to get a small PC/SBC with 2-4 ethernet ports and 2.4GHz WiFi with a decent range to load OPNSense on. Something like the ODroid H3+ is attractive, but it seems like overkill for JUST a router (I'd definitely reach for it if I were building a combo router-NAS), and I was wondering if anyone had any suggestions that had a lower price-point and/or more ethernet ports.\n I don't need massive range, mesh network BS, and I'd rather use as much FLOSS as possible.\n    submitted by    /u/donotlearntocode  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq3s4g/diy_router_hardware_suggestions/",
          "publishedOn": "2022-12-19T21:15:14.000Z",
          "wordCount": 18529,
          "title": "DIY Router hardware suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq2wax/anyone_have_two_instances_of_photoprisim_going/",
          "author": null,
          "description": "I come to you again Beaten and begging =_=. you all helped me once, once more i ask for support \n on my unraid server I'm running PhotoPrisim it's working fine using (MariaDB over the sqlite). I'm trying to start a second instance and it will not launch. I'm using Adminer to create a new user changed the port of the new instance and followed the same instruction that i did for the first. When\n i use the build in DB it launches so i think it's something to do with Maria DB. I'm using the same format for pointing to the Data base. DBUSER:DBPASSWORD@tcp(DBIP:DBPORT)/photoprism?parseTime=true \n ​\n The logs don't actually say anything \n started 221118-jammy as root (amd64-prod)\n init: updating filesystem permissions\n PHOTOPRISM_DISABLE_CHOWN=\"true\" disables permission updates\n Problems? Our Troubleshooting Checklists help you quickly diagnose and solve them:\n https://docs.photoprism.app/getting-started/troubleshooting/\n file umask....: \"0002\" (u=rwx,g=rwx,o=rx)\n home directory: /photoprism\n assets path...: /opt/photoprism/assets\n storage path..: /photoprism/storage\n config path...: default\n cache path....: default\n backup path...: /photoprism/storage/backups\n import path...: /photoprism/import\n originals path: /photoprism/originals\n switching to uid 99:100\n /opt/photoprism/bin/photoprism start\n I'm at a loss\n    submitted by    /u/SkittlesX9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq2wax/anyone_have_two_instances_of_photoprisim_going/",
          "publishedOn": "2022-12-19T20:40:48.000Z",
          "wordCount": 19196,
          "title": "Anyone have two instances of photoprisim going through mariaDB in unraid?",
          "imageUrl": "https://external-preview.redd.it/BOd8eK-D4w1PldDQUI-5GJRSPfNz-lhDp6n1DCmWzDQ.jpg?auto=webp&s=d35ab62013babd521aca95e2859b07b92f03ee2b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq2kni/immich_highperformance_selfhosted_backup/",
          "author": null,
          "description": "Hi all,\n Happy Holiday! \n Alex here, and I am back with another progress update on Immich (v1.39). \n Before jumping into the update, we collect feedback on integrating the directory scanning feature into Immich. Please share your feedback and thoughts in this active discussion thread https://github.com/immich-app/immich/discussions/1006\n This Christmas special update includes more customization for the application. Here are some significant features we have added since the last update. \n  \nOIDC Support\n LivePhotos Support\n User-defined Storage Structure\n  \nApplication setting and User-defined storage structure\n We have implemented a setting page for the admin, which can access on the web. This allows the admin to fine-tune the Immich instance and add support for OIDC configuration from her…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq2kni/immich_highperformance_selfhosted_backup/",
          "publishedOn": "2022-12-19T20:28:05.000Z",
          "wordCount": 23291,
          "title": "Immich - High-performance self-hosted backup photos/videos from your mobile phone (kinda like a Google Photos replacement) Dec-19-2022 - Christmas Special Release - User-defined storage structure is here 🎉",
          "imageUrl": "https://external-preview.redd.it/vHToFeAQA0ur8rMWYqiFhyaYyerEYVDeRn-YWI8oSoE.jpg?auto=webp&s=4bbfe6e78164f40ac0d7098b0153333ba7be041c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq22r8/need_help_for_alerts_in_grafana_using/",
          "author": null,
          "description": "So I am running prometheus and displaying the results in grafana.\n I use prometheus-podman-exporter, to export my prodman container metrics.\n I visualize them in grafana. \n But now i want to get alerts when for example a container is not in the running state.\n But i have no idea how to set this up. \n anyone else here using prometheus-podman-exporter?\n Who can help me with some specific questions?\n    submitted by    /u/UinguZero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq22r8/need_help_for_alerts_in_grafana_using/",
          "publishedOn": "2022-12-19T20:08:22.000Z",
          "wordCount": 19783,
          "title": "need help for alerts in grafana, using prometheus-podman-exported",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq1hk9/reccomendationsadvice_request_on/",
          "author": null,
          "description": "Hi All,\n I've made a diagram illustrating what I am preparing to set up this week to try and make my thoughts clearer. I'm new to network diagrams so please be forgiving where I've missed obvious conventions & if possible let me know so I can work on this in future.\n My aim:\n  \nBack up my synology to a remote site (friends house) (as part of 321 backups) onto my Truenas Server\n  \nOn my network side:\n  \nRun a wireguard docker container on my server\n Using IPTables, add a route to dynamicDNS setup for Friends network (\"superprivate\".duckdns.com) to go via wireguard docker network. I will be broadly following this guide: https://www.linuxserver.io/blog/routing-docker-host-and-container-traffic-through-wireguard\n All other connectivity will be routed out to the internet without this VPN in place\n  \nOn friends side:\n  \nRun WG-easy inside Truenas docker app to run as VPN server\n Run duckdns inside Truenas docker app to share dynamic IP\n Run piVPN on raspberry pi as backup VPN server should something go majorly wrong with my Truenas primary VPN server\n  \nQuestions:\n  \nPlease can you comment on my design above and let me know any shortcomings/improvements?\n My biggest unknown in the above is probably the IPTables changes to NAT, to control what connections end up where.\n The Raspberry Pi will run PiVPN as a backup for my truenas container. I'll be several thousand miles away for a few years so want to ensure I can access my truenas just incase things go very wrong. Any issue running two vpns on the same network?\n I've written some bash scripts utilising rsync to push from my synology to the truenas. As my bash scripting is a bit rusty, is it reccomended to use rsync *service* to push directly to my truenas rather than relying on my scripting?\n  \nMany thanks if you've read through this far :)\n home-network.png\n    submitted by    /u/Maximum-Warning-4186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq1hk9/reccomendationsadvice_request_on/",
          "publishedOn": "2022-12-19T19:46:07.000Z",
          "wordCount": 19292,
          "title": "Reccomendations/advice request on application/design for 321 offsite backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq1e7z/raspberry_pi_2b_for_tailscale_vpn/",
          "author": null,
          "description": "I want to run a vpn to connect to my house while im away from home, and i can get a cheap pi 2b with 1gb ram, on the local marketplace. Would it be fast enough to use as exit node? We have 100/20 internet speeds. \n    submitted by    /u/PurplePandaYT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq1e7z/raspberry_pi_2b_for_tailscale_vpn/",
          "publishedOn": "2022-12-19T19:42:34.000Z",
          "wordCount": 21059,
          "title": "Raspberry pi 2b for Tailscale vpn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpzmei/cross_platform_gallery_management_with_delete/",
          "author": null,
          "description": "Hi all,\n I'm after a solution to my dire photo management skills. I've got 20k photos on a server. Lots of crud. I'd like to thin the herd a bit.\n I'm looking for a way to go through them on the phone and delete as I swipe through. Ideally it would be swipe->delete->swipe->keep->swipe->delete etc. The process has been surprisingly difficult to come across.\n On the desktop, it's fine. I can use the file manager, but with kids, work, etc, i might not get to the desktop as often as i'd like which is where the phone would come in. I'm after an android app that can see the photos on the server amd delete/keep as is my wont. I don't require organisational tools, or AI, or tagging, or sharing or anything like that. \n Simple delete/keep->next, repeat ad nauseum. It doesn't have to be a gallery app, maybe a file manager would work, but the thumbnail/preview caching might be problematic.\n I don't know. There are plenty of photo management apps, but really i'm looking for an image previewer and delete button without having to confirm every single time.\n The photos themselves can be in a samba share/ftp/nextcloud instance, doesn't matter, but access from the phone to quickly delete would be incredibly helpful.\n Any ideas appreciated. Thanks.\n Afterthought: I'd be aiming for something from fdroid, but at this point I may have to forego the opensourceness.\n    submitted by    /u/gxvicyxkxa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpzmei/cross_platform_gallery_management_with_delete/",
          "publishedOn": "2022-12-19T18:36:27.000Z",
          "wordCount": 19013,
          "title": "Cross platform gallery management (with delete)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpz9ki/looking_for_a_readytoextendanddeploy_openid/",
          "author": null,
          "description": "I feel like I wasted my whole weekend. All I wanted to do is create a REST API I could develop a mobile app against. This is the first programming work I’ve done for myself in ages and is widely outside the scope of the kind of work I do for clients. I’m interested in spring because the overtime I’ve been doing has been on a spring project. \n I found this example by Baeldung after running into dead-ends with other tutorials:\n https://github.com/Baeldung/spring-security-oauth\n It’s not setup for SSL or running outside of local dev environment. So that’s where I spent my Sunday. \n I eventually got everything besides actually being able to log out to work. Also technically still have to figure out how disable the management console being reachable from outside the host. \n Surely there must be a secure, ready to deploy default that can be extended, right? \n Am I expecting too much to be done for me?\n    submitted by    /u/YouDontKnowMyLlFE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpz9ki/looking_for_a_readytoextendanddeploy_openid/",
          "publishedOn": "2022-12-19T18:23:26.000Z",
          "wordCount": 19707,
          "title": "Looking for a ready-to-extend-and-deploy OpenID + Spring REST solution.",
          "imageUrl": "https://external-preview.redd.it/6Uueggn5pcnavx68ygIRvrrAzcfgfatEedunJvIQun8.jpg?auto=webp&s=b648866b2153a6ca5902ae3525f4ecb3ee2cf2cb"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpz6jz/selfhosted_vpn_solution/",
          "author": null,
          "description": "I have finally completed my first home lab. I have a UDM Pro am running a few dockers in a Raspberry Pi4 (4GB):\n  \nPlex\n Memos\n AdGuard\n Homepage\n  \nIt took me a while to understand and set up the whole thing as this was my first time, but it is all up and running.\n I would like to make some docker containers accessible from outside of my home. After some Googling, it seems that hosting a VPN seems the way to go. I wanted to double check if that is the best path forward:\n  \nddclient for Dynamic DNS (would you use a free service like afraid.org?)\n wireguard for the actual VPN\n  \n​\n Am I missing anything else? I will be running both of those servers in docker.\n ​\n Thanks!\n    submitted by    /u/m4mazzotti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpz6jz/selfhosted_vpn_solution/",
          "publishedOn": "2022-12-19T18:20:24.000Z",
          "wordCount": 18915,
          "title": "Selfhosted VPN Solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpy2mh/what_would_insert_your_name_here_do/",
          "author": null,
          "description": "I recently bought 3 identical machines with the initial idea of running SeaweedFS or maybe CEPH or some other type of distributed filesystem.\n Now I'm doubting if I should make more use of the hardware and also add them as docker nodes in my swarm. What would the performance impact be on my filesystem? Could docker somehow get in the way of the filesystem? What are the security implications of running docker containers alongside my filesystem?\n It seems like a waste of resources to only use the 3 machines as filesystem, doesn't it? I am planning to host quite a lot of mini-websites in docker in the future, it's something to keep in mind, but they can be migrated quite easily provided there is shared storage.\n What would you do in this case?\n    submitted by    /u/Stitch10925  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpy2mh/what_would_insert_your_name_here_do/",
          "publishedOn": "2022-12-19T17:40:06.000Z",
          "wordCount": 18798,
          "title": "What would <insert your name here> do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpunzh/answer_an_opensource_go_based_qa_community/",
          "author": null,
          "description": "submitted by    /u/Bassfaceapollo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpunzh/answer_an_opensource_go_based_qa_community/",
          "publishedOn": "2022-12-19T15:32:29.000Z",
          "wordCount": 18286,
          "title": "Answer - An open-source Go based Q&A community software.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpuh3j/can_someone_explain_why_do_people_seem_to_prefer/",
          "author": null,
          "description": "Hi everyone, I'm relatively new to self hosting, and I've read lots of guides and there is something I can't get my head around. Usually people have a reverse proxy for most of their services, so they can be accessed outside of the home network. What I don't understand is - say you have something like radarr.yourdomain.com - it doesn't seem to difficult for someone to guess that URL. If they do, then all that's left stopping them from accessing your services is the authentication from each service. I have been using wireguard for accessing my services outside my home, and it works quite well, and it seems more secure given how big the private keys are etc? I understand using a reverse proxy for a media server, in case you want to share with others or on devices that you can't use a VPN client, but why have it for the other more \"private\" services?\n Thank you very much!\n Edit: Thank you everyone, that makes sense. As for reverse proxies, is it considered secure to use the services own single authentication, like radarr and sonarr, or is it recommended to set up something more complex like authelia? Of course running with SSL.\n    submitted by    /u/jpbragatti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpuh3j/can_someone_explain_why_do_people_seem_to_prefer/",
          "publishedOn": "2022-12-19T15:25:10.000Z",
          "wordCount": 22842,
          "title": "Can someone explain why do people seem to prefer Reverse Proxy instead of VPN?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpt4jm/nvr_suggestions_experienceany_decent_alternatives/",
          "author": null,
          "description": "I have a simple setup and 2 cameras connected to MotionEye docker on Raspberry Pi 4B. It's running fine except a continuous error about unable to generate thumbnail for recorded videos. I only use it to store camera feeds 24x7 to a server.\n MotionEye is great but development has been slow and current armhf docker image is 2 years old. I tried creating new image from source but some platform dependencies are not met I feel hence failing to run despite successful image creation.\n What alternatives do you suggest for motioneye? I am looking for simple NVR which just records camera streams. No object detection, motion detection etc. required.\n    submitted by    /u/hum8lefool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpt4jm/nvr_suggestions_experienceany_decent_alternatives/",
          "publishedOn": "2022-12-19T14:31:19.000Z",
          "wordCount": 18786,
          "title": "NVR Suggestions & Experience...Any decent alternatives for MotionEye?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zps9be/mounting_a_nas_folder_to_linux_raspberry_pi/",
          "author": null,
          "description": "Hi all,\n as my NAS is a bit dumb (ie Synology locked it down to only install something from their package manager), I was hoping to use my Raspberry Pi as a Jellyfin server.\n I am however having issues mounting the shared folder on Raspbian.\n I followed the instructions at https://www.gavingreer.com/2020/03/06/synology-nfs-mount but when I try to mount the drive, I don't get the expected results:\n $ sudo mount 192.168.178.69:/volume1/video /media/nas/video $ df -h | grep /media/nas/video/ $ ls /media/nas/video/ ls: cannot open directory '/media/nas/video/': Permission denied \n Anyone any idea what I might be missing?\n    submitted by    /u/stringlesskite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zps9be/mounting_a_nas_folder_to_linux_raspberry_pi/",
          "publishedOn": "2022-12-19T13:56:55.000Z",
          "wordCount": 19362,
          "title": "Mounting a NAS folder to linux (Raspberry Pi)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpr3j6/vocaroo_selfhosted_alternatives/",
          "author": null,
          "description": "As the title suggests, I’m wondering if there is anything similar to Vocaroo that I can spin up?\n    submitted by    /u/Nicnivian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpr3j6/vocaroo_selfhosted_alternatives/",
          "publishedOn": "2022-12-19T13:06:42.000Z",
          "wordCount": 18672,
          "title": "Vocaroo self-hosted alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpquz5/viseron_200_selfhosted_local_only_nvr_and_ai/",
          "author": null,
          "description": "Viseron is a self-hosted NVR deployed via Docker, which utilizes machine learning to detect objects and start recordings.\n v2.0.0 was just released which features a lot of improvements, including a fresh new frontend interface\n Check out the release notes: https://github.com/roflcoopter/viseron/releases/tag/v2.0.0\n Viserons features include, but not limited to the following:\n  \nObject detection via: \n YOLOv3, YOLOv4 and YOLOv7 Darknet using OpenCV\n Tensorflow via Google Coral EdgeTPU\n DeepStack\n \n Motion detection\n Face recognition via: \n dlib\n DeepStack\n CompreFace\n \n Image Classification\n Responsive, mobile friendly Web UI written in TypeScript React\n MQTT support\n Home Assistant MQTT Discovery\n Lookback, buffers frames to record before the event actually happened\n Supports hardware acceleration on different platforms \n CUDA for systems with a supported GPU\n OpenCL\n OpenMax and MMAL on the RaspberryPi 3B+\n video4linux on the RaspberryPi 4\n Intel QuickSync with VA-API\n NVIDIA video4linux2 on Jetson Nano\n \n Multiplatform, should support any amd64, aarch64 or armhf machine running Linux. Specific images are built to support: \n RaspberryPi 3B+\n RaspberryPi 4\n NVIDIA Jetson Nano\n \n Zones to limit detection to a particular area to reduce false positives\n Masks to limit where object and motion detection occurs\n Stop/start cameras on-demand over MQTT\n  \nCheck out the documentation here: https://viseron.netlify.app/\n https://github.com/roflcoopter/viseron\n I am really interested in feedback and features that you would like to see implemented. I respond to all comments here on Reddit, the Home Assistant forum thread or GitHub issues. \n I hope you'll find this useful!\n Some screenshots:\n ​\n Cameras\n Recordings\n Built in Configuration editor\n    submitted by    /u/roflcoopter1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpquz5/viseron_200_selfhosted_local_only_nvr_and_ai/",
          "publishedOn": "2022-12-19T12:56:20.000Z",
          "wordCount": 21039,
          "title": "Viseron 2.0.0 - Self-hosted, local only NVR and AI Computer Vision software.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpq7dq/encrypted_caldavcarddav_solution/",
          "author": null,
          "description": "I'm searching for a encrypted carddav/caldav server options.\n I have a simple vultr vps and atm am using Radicale as my solution with Davx5 on my phone with simple calendar and thunderbird on my pc.\n What I'm meaning to ask is is there any way to add encryption with radicale or if there are any opensource solutions with encryption.\n The reason for encryption is that this is a vultr vps, not my hardware. If it was I wouldn't mind with radicale as a solution but as it isn't I would like if there is something if possible. If not will have to continue with radicale.\n    submitted by    /u/CronyAkatsuki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpq7dq/encrypted_caldavcarddav_solution/",
          "publishedOn": "2022-12-19T12:25:08.000Z",
          "wordCount": 19117,
          "title": "Encrypted caldav/carddav solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpp9hc/legita_selfhosted_web_frontend_for_git_written_in/",
          "author": null,
          "description": "submitted by    /u/Icyphox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpp9hc/legita_selfhosted_web_frontend_for_git_written_in/",
          "publishedOn": "2022-12-19T11:38:32.000Z",
          "wordCount": 18523,
          "title": "legit—a self-hosted web frontend for git, written in go",
          "imageUrl": "https://external-preview.redd.it/2M0GH5nXFtZK75OaW0RzxP7fqqwaVd2kWrbywuYL1wE.jpg?auto=webp&s=ac10c3b6c2e45308bf2789f8caacd5cda9bfa71e"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpnhvc/help_with_fake_google_safe_browsing_reports/",
          "author": null,
          "description": "Hey selfhosters, \n I've recently had a problem with some apps that I'm selfhosting for our company being reported to google as phishing, including our website. This caused some issues last week as our website is listed in our signatures and Gmail flagged all our outgoing mails as phishing attempts.\n Additionally, one of the domains that has been reported is nothing more than a Bookstack wiki protected with Cloudflare Zero Trust, even if you get past Zero Trust, you'll still need to login to Bookstack. There's definitely no phishing or even anything to download there. I suspect we're being fake report bombed by someone for reasons unknown to me.\n It's causing some issues with my colleagues accessing the necessary tools we need to use if they happen to be using Chrome as their browser. Has anyone had experience with such a situation before? Apart from submitting an Incorrect Phishing Warning report, is there anything else I can do? I seriously doubt our servers have been compromised, I've looked at the logs and there's nothing that would hint at suspicious activity.\n Thanks in advance.\n    submitted by    /u/dashrandom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpnhvc/help_with_fake_google_safe_browsing_reports/",
          "publishedOn": "2022-12-19T09:57:43.000Z",
          "wordCount": 18774,
          "title": "Help with fake Google Safe Browsing reports",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpjwur/my_current_mood_when_i_had_a_drive_in_a_degraded/",
          "author": null,
          "description": "submitted by    /u/razenet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpjwur/my_current_mood_when_i_had_a_drive_in_a_degraded/",
          "publishedOn": "2022-12-19T06:16:52.000Z",
          "wordCount": 1949,
          "title": "My current mood when I had a drive in a degraded state for proxmox. Plugged the old drive back in and it seemed to chill out… for now but hot spare is in.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpaoku/torrent_downloader/",
          "author": null,
          "description": "I'm searching for a selfhosted web app that do the front end for Jackett where I can search some keywords and it shows me the details about all the torrent found, I could choose which one I want (Not fully automated like Sonarr) and when I click on it, it's sent to Transmission or qBittorrent to be downloaded.\n    submitted by    /u/Armeclemes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpaoku/torrent_downloader/",
          "publishedOn": "2022-12-18T22:46:15.000Z",
          "wordCount": 17097,
          "title": "Torrent downloader ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpa8tp/my_journey_so_far_in_selfhosting/",
          "author": null,
          "description": "https://preview.redd.it/4vgfgf8svq6a1.png?width=1167&format=png&auto=webp&s=999ad06c0e558dc7b518d93183981a92457f3def\n One year after getting into selfhosting\n I just wanted to share my path to selfhosting so far!My first intention was to host a secure passwordmanager for myself and my family (Vaultwarden).Well I got kind of addicted to selfhosting services and replace comercial services like Google Photos, OneDrive and PasteBin.\n So I want to share my current setup, consisting of some VPS's and home equipment.I'll go through everything I am running on each machine.Maybe I can inspire some of you and if you have questions, just ask away!\n I almost exclusively use Docker / Docker Compose and LXC containers to host services.\n https://preview.redd.it/g2q8sq0shq6a1.png?width=2166&format=png&aut…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpa8tp/my_journey_so_far_in_selfhosting/",
          "publishedOn": "2022-12-18T22:26:41.000Z",
          "wordCount": 18926,
          "title": "My journey so far in selfhosting!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpa8su/with_the_k8sathome_helm_chart_repository_no/",
          "author": null,
          "description": "I have half a dozen helm charts I've deployed from the k8s-at-home chart repo - they've been issue free. Today I noticed the project has been effectively abandoned as of early november.\n I've cloned the existing git repo, so I can be sure I'll have the charts I'm using right now. That said, what sources are people using for their favorite helm charts?\n Obviously there are repos like Bitnami, but they're more component services (mysql, rabbitmq, postgres, etc) vs applications.\n    submitted by    /u/Double_Intention_641  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpa8su/with_the_k8sathome_helm_chart_repository_no/",
          "publishedOn": "2022-12-18T22:26:39.000Z",
          "wordCount": 17537,
          "title": "With the k8s-at-home helm chart repository no longer being maintained, what are people using instead?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp9quj/running_fail2ban_synology_cloudflare_help/",
          "author": null,
          "description": "I've used various guides to configure fail2ban on a Synology in Docker, for a service (VaultWarden) running on a Synology that is using Synology's reverse proxy and also behind Cloudflare proxy DNS.\n When Fal2Ban kicks in, it bans the Cloudflare IPS and therefor, I am still able to authenticate from my TEST IPs....\n Anyone know why this is happening? I am assuming in my reverse proxy I need *something* so that it passes the real IP through, yes? I have tried various settings in the Synology GUI to no avail..\n I am using a special cloudflare.conf file in Fail2Ban to pass it the data it needs to automatically put in the bans...which works, but it ends up banning IPS belonging to Cloudflare... Any guidance appreciated. In Vaultwarden.log it is seeing cloudflare's IP and not the true IPS.\n    submitted by    /u/sqlallstar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp9quj/running_fail2ban_synology_cloudflare_help/",
          "publishedOn": "2022-12-18T22:04:16.000Z",
          "wordCount": 17181,
          "title": "Running Fail2Ban, Synology, Cloudflare - help - Fail2Ban sends Cloudflare IPS to Cloudflare",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp8xwp/dashy_multiple_pages_broken/",
          "author": null,
          "description": "I figured I'd ask here since a few of you are using Dashy. \n I've only found 1 issue on the GitHub describing this issue and there's not a lot of traction on it. \n I am resetting up Dashy on a new server (dockerized) and found that I can't get multiple pages working. When adding a secondary page and clicking it, the dashboard breaks. The best way to describe it is the theme breaks and the new page doesn't load. \n I've tried using the sample pages from the Dashy docs in case my yml was broken, but I experience the same issue. \n In the docker compose, I've declared my /opt/dashy/public dir and also the specific config files and nada. \n  volumes: - /opt/dashy/public/mainpage.yml:/app/public/conf.yml - /opt/dashy/public/testpage.yml:/app/public/testpage.yml - /opt/dashy/item-icons:/app/public/item-icons \n On the original server, it works great. Second and third pages load, but on this new instance, it's broken. \n Both instances are on the same version (2.1.1)\n Just not sure why multiple pages started giving me such an issue and was wondering if others were having the same issue.\n    submitted by    /u/iC0nk3r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp8xwp/dashy_multiple_pages_broken/",
          "publishedOn": "2022-12-18T21:29:20.000Z",
          "wordCount": 17676,
          "title": "Dashy - Multiple Pages Broken?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp8wjl/nginx_proxy_manager_vs_traefik/",
          "author": null,
          "description": "I've been using Npm for about 4 years now and never had any complaints or issues with it! However I've read alot about people having trouble with it. Are there any benefits by using traefik?\n    submitted by    /u/MethDonut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp8wjl/nginx_proxy_manager_vs_traefik/",
          "publishedOn": "2022-12-18T21:27:43.000Z",
          "wordCount": 17394,
          "title": "NginX Proxy Manager vs Traefik?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp8v13/i_have_a_server_and_a_raspberry_pi_my_server_runs/",
          "author": null,
          "description": "I started my self hosting journey with a Raspberry Pi with Pihole installed. Now that I have a server going with a bunch of docker containers, I'm wondering if I need my Raspberry Pi anymore for Pihole. I still see people mentioning their Pihole + Raspberry Pi combo so just want to make sure.\n Can I move Pihole to my server?\n Thanks\n    submitted by    /u/Melodic_Walk_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp8v13/i_have_a_server_and_a_raspberry_pi_my_server_runs/",
          "publishedOn": "2022-12-18T21:25:47.000Z",
          "wordCount": 18095,
          "title": "I have a server and a Raspberry Pi. My server runs all of my home automation and *arr stuff. The Pi runs Pihole. Can I simplify things by moving Pihole to my server? Are there any issues doing that?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp7cmu/can_i_use_ubuntu_as_router_with_one_physical/",
          "author": null,
          "description": "I have simple set up - ISP router (can be switched to modem mode), switch and multiple deviced connected to this switch via ethernet. One of these devices in ubuntu server with one physical network interface.\n With the above setup, can I use Ubuntu as a router, define new subnet for the rest of my home, etc.? Maybe with vitual NIC? Where do I start, any guidance I can follow?\n    submitted by    /u/luckylemon33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp7cmu/can_i_use_ubuntu_as_router_with_one_physical/",
          "publishedOn": "2022-12-18T20:20:13.000Z",
          "wordCount": 20046,
          "title": "Can I use ubuntu as router with one physical network interface?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp6k4a/a_self_hosted_home_inventory_management_solution/",
          "author": null,
          "description": "Hello everyone.\n I want to do a small stock of stuff I buy regularly for my home. To be able to never forget what to buy every week, I want to generate a dynamic list every X days. \n I am looking for a inventory management solution. Usage: home / personal \n Requirements : - home inventory management - manage available products with price, quantity and details (such as consumption time, that means in how many days is each product consumed) - manage list of recursive stuff to buy - access to an overview of the quantity of the products that I have in my stock and when I will have to renew them. - set notifications (emails or push) to notify me when a product inventory is lower than a certain quantity - creates automatically s list of products I need to rebuy every fix time (ex. Every week). - responsive design -self hosted\n I know that a lot of solutions exist for inventory management, but I can't try them all and I am sure that some of you have some propositions.\n Thank you for your help.\n    submitted by    /u/NotABiene  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp6k4a/a_self_hosted_home_inventory_management_solution/",
          "publishedOn": "2022-12-18T19:45:58.000Z",
          "wordCount": 17792,
          "title": "a self hosted home inventory management solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp6afv/have_you_found_your_ideal_network_setup_mine_is/",
          "author": null,
          "description": "submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp6afv/have_you_found_your_ideal_network_setup_mine_is/",
          "publishedOn": "2022-12-18T19:33:53.000Z",
          "wordCount": 18473,
          "title": "Have you found your ideal network setup? Mine is ok-ish",
          "imageUrl": "https://preview.redd.it/dm9oya53lp6a1.png?auto=webp&s=7bd6ce9c43053c6503333961f808552f20391c11"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp65by/cloudflare_tunnel_split_dns_not_working_correctly/",
          "author": null,
          "description": "Yesterday I ended up setting up a cloudflare tunnel. Previously I had been utilizing nginx proxy manager and exposed ports 80 & 443 to the internet. It was working fine, but after reading about cloudflares tunnel I determined why continue to expose ports to the internet.\n Tunnel works great, I can go to ha.mydoman.com and it brings me to home assisstant. Did the same thing with jellyfin. Then I realized when using the domain name internally it was being treated as if I was connecting externally and forcing jellyfin to transcode the videos when on my local network. This makes sense since the dns is now being routed to cloudflare back home. Previously with nginx i used hairpin nat to keep all traffic local.\n I setup dns override in unbound to point to the IP address of NGINX (using Opnsense firewall). I flushed my dns and when I ping that domain it shows the IP. In NGINX I still have setup to use the host ha.mydomain.com . \n ​\n However, when on my internal network when I go to ha.mydomain.com I get a connection refused. So I suspect the domain or something isn't properly getting passed to nginx? Therefore it can't resolve properly. When I do ha.mydomain.com:8989/sonarr I can get to sonarr (it requires the port to be specified - otherwise connection refused) via NGINX so something odd is going on. What is the best place to look? Bit stumped at this point.\n    submitted by    /u/ImperatorPC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp65by/cloudflare_tunnel_split_dns_not_working_correctly/",
          "publishedOn": "2022-12-18T19:27:41.000Z",
          "wordCount": 17796,
          "title": "Cloudflare Tunnel / Split DNS Not working correctly",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp3jkf/best_notion_selfhosted_alternative/",
          "author": null,
          "description": "Looking for a notion alternative since apparently staff at notion can look at your stuff willy nilly. And it’s not secure. \n Not the biggest fan of Joplin, and trillium can’t have multiple users. Or even if you know of a more secure option that maybe isn’t even self hosted?\n    submitted by    /u/Fission455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp3jkf/best_notion_selfhosted_alternative/",
          "publishedOn": "2022-12-18T17:25:13.000Z",
          "wordCount": 18008,
          "title": "Best notion selfhosted alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp3gal/new_a_better_plex_exporter_for_prometheus/",
          "author": null,
          "description": "There are a few Plex exporters out there to track metrics in Prometheus but they have some deficiencies: not differentiating between playing, paused, buffering streams, audio vs. video transcoding, tracking media downloads, and more.\n I decided to roll my own exporter to address these and have been running it in production for a few weeks. Please give it a try if this sounds like something that would improve your Plex dashboards — pull requests are welcome (Ruby)!\n https://github.com/axsuul/plex-media-server-exporter\n    submitted by    /u/Axsuul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp3gal/new_a_better_plex_exporter_for_prometheus/",
          "publishedOn": "2022-12-18T17:20:51.000Z",
          "wordCount": 16965,
          "title": "New: A better Plex exporter for Prometheus",
          "imageUrl": "https://external-preview.redd.it/jCn6IAeoLCOLlc9-4gUlDz5_0TPW3-X69CfPATeo0Pc.jpg?auto=webp&s=368191378aa0f4d55b4169d201c203c40c4d70df"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp2vsf/how_to_use_the_real_ip_header_in_nginx_proxy/",
          "author": null,
          "description": "I run all of my services behind cloudflare, and to stop non-cloudflare-proxied traffic reaching them, I created an access list of the cloudflare endpoints, and added the rule to all of my services. It worked before, but I then wanted to see the real client IP in my logs, so I added:\n real_ip_header CF-Connecting-IP; \n to them, in the advanced tab. Now, the requests get blocked, presumably because it uses the real-ip to filter traffic. Is there any way to get the real client IP, while still filtering non-cloudflare traffic?\n    submitted by    /u/DoUhavestupid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp2vsf/how_to_use_the_real_ip_header_in_nginx_proxy/",
          "publishedOn": "2022-12-18T16:53:43.000Z",
          "wordCount": 17932,
          "title": "How to use the real_ip_header in Nginx Proxy Manager, whilst using still using access lists for Cloudflare?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp1p9l/how_to_migrate_from_miniflux_apt_installation_to/",
          "author": null,
          "description": "Hello recently I have got into selfhosting and have selfhosted an miniflux instance on debian using their apt repo.\n Couple weeks later I have tried to use docker containers and decided to move my miniflux instance to a docker one.\n So how would I go about moving the data from the apt hosted postgres miniflux database over to the docker one?\n    submitted by    /u/CronyAkatsuki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp1p9l/how_to_migrate_from_miniflux_apt_installation_to/",
          "publishedOn": "2022-12-18T15:59:12.000Z",
          "wordCount": 20410,
          "title": "How to migrate from miniflux apt installation to docker-compose miniflux installation.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp1gza/swag_reverse_proxy_for_guacamole/",
          "author": null,
          "description": "Hey I want to set up a reverse proxy with swag for guacamole. I already set up a couple, but this one does not want to work. I used the nginx/proxy-confs/guacamole.subdomain.conf.sample and modified it to adhere to the guacamole documentation found here: https://guacamole.apache.org/doc/gug/reverse-proxy.html#nginx\n ​\n this is my conf file:\n server { listen 443 ssl; listen [::]:443 ssl; server_name guac.*; include /config/nginx/ssl.conf; client_max_body_size 0; # enable for ldap auth (requires ldap-location.conf in the location block) #include /config/nginx/ldap-server.conf; # enable for Authelia (requires authelia-location.conf in the location block) #include /config/nginx/authelia-server.conf; location /guacamole/ { # enable the next two lines for http auth #auth_basic \"Restricted\"; #aut…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp1gza/swag_reverse_proxy_for_guacamole/",
          "publishedOn": "2022-12-18T15:47:54.000Z",
          "wordCount": 18432,
          "title": "Swag reverse Proxy for guacamole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp0ctj/alternatives_to_rss_reader/",
          "author": null,
          "description": "I want a desktop software similar to an RSS Feed Reader. The articles are found by subscribing to a page or service (like copying an RSS link in a client software) or by keywords. The articles are displayed on a reader on the user’s side. \n RSS seems to be dying (see Google Reader). What are applications for this? \n It seems nextcloud has an RSS Reader. But I don’t know how it works. \n Mobile support would be nice.\n Any suggestions?\n    submitted by    /u/chaplin2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp0ctj/alternatives_to_rss_reader/",
          "publishedOn": "2022-12-18T14:53:35.000Z",
          "wordCount": 18182,
          "title": "Alternatives to RSS reader",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp0bpb/paperless_ngx_tag_by_filename/",
          "author": null,
          "description": "Hi all, is it possible that paperless-ngx also searches the file name for keywords? I also scan documents with my cell phone (Android Genius Scan) and here the scan is now and then not scanable with OCR ( text is like \"t e x t\" instead of \"text\" and so not searchable). So rework is necessary. Now it would be good if paperless would automatically tag all scans from Genius Scan. Only I can only specify the filename when scanning, but paperless doesn't seem to search it. Do you guys know a solution? Thanks.\n    submitted by    /u/marneusc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp0bpb/paperless_ngx_tag_by_filename/",
          "publishedOn": "2022-12-18T14:52:01.000Z",
          "wordCount": 20223,
          "title": "Paperless ngx - Tag by filename",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp089g/comparison_of_ui_options_for_bulk_email_sending/",
          "author": null,
          "description": "Listmonk\n Free and open source, but the most unpolished. You may spend lots of time trying to get certain things to work and fail in the end. \n As far as I can tell, it's a \"simpler and possibly slightly more user-friendly\" version of Mautic. \n Some things are better than Sendy, others worse. Overall I prefer Listmonk, especially since it's free and open source. \n The most detailed guide: https://github.com/knadh/listmonk/issues/120#issuecomment-1314110010\n Limitations:\n As of Dec 2022. \n  \nSpam complaints are treated the same as bounces: https://github.com/knadh/listmonk/issues/497 -https://github.com/knadh/listmonk/issues/489 \n \nThere's no option to view all unsubbed or complained; both the total or per-campaign. https://github.com/knadh/listmonk/issues/391#issuecomment-1312779279\n \nYou …",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp089g/comparison_of_ui_options_for_bulk_email_sending/",
          "publishedOn": "2022-12-18T14:47:26.000Z",
          "wordCount": 17812,
          "title": "Comparison of UI options for bulk email sending with Amazon SES and other SMTP providers. Review of Sendy, Mailwizz, and Listmonk.",
          "imageUrl": "https://external-preview.redd.it/zbBR07CbK4wq64--32apqgHTVkb1owDBE46TAm8MjFs.jpg?auto=webp&s=9e6c1bfbe3351fa7ebc1c3ea3d7eb886d969aa2d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zozmiw/cockroachdb_for_selfhosted_services/",
          "author": null,
          "description": "Hi, I have recently redoing my selfhosted architecture and wanted to migrate all of my services to CockroachDB for for easy cluser and replication setup (in docker) and PostgreSQL compatibility but so far, none of the services I wanted to deploy worked :\n  \nNextcloud ( using linuxserver.io image ) doesn't work (despite connecting to the database and creating table) but I think it's due to my configuration so ¯\\_(ツ)_/¯\n Coder use some PostgreSQL specific function not implemented in CockroachDB\n Wakapi doesn't work for the migration ( an issue is opened if you want to take a look) \n  \nI may be out of luck and I will revert back to a simple PostgreSQL container but does any of you use CockroachDB for his selfhosted environnement or have an alternative more compatible ?\n    submitted by    /u/cfouche  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zozmiw/cockroachdb_for_selfhosted_services/",
          "publishedOn": "2022-12-18T14:17:53.000Z",
          "wordCount": 16597,
          "title": "CockroachDB for selfhosted services",
          "imageUrl": "https://external-preview.redd.it/mtDoFYYQ9TIYo8dpb9emvmQt0yneoTONw4YKGT4QWzA.jpg?auto=webp&s=849871716211d34d12859e43dabc7052c42b3646"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zovbb3/small_factor_cheap_server/",
          "author": null,
          "description": "Hi all!\n I am looking for something that is small factory (like NUC), not too expensive and capable of running pfSense, Home Assistant and Kodi. I was thinking of running Proxmox and virtualizing all of that.\n Any suggestions what would be the best for this? I was looking at Intel NUCs but decieded to ask here if you have any better ideas.\n Also it would have to be pretty quiet, since I live in the apartment where the living room and bedroom are the same room 😅\n    submitted by    /u/GiantMoose216  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zovbb3/small_factor_cheap_server/",
          "publishedOn": "2022-12-18T10:07:48.000Z",
          "wordCount": 17667,
          "title": "Small factor cheap server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zov3r3/selfhosted_livestreaming_with_dvr_features_pause/",
          "author": null,
          "description": "I am looking for a self-hostable service that I can send live video to (with OBS for example) that has seamless pause and rewind. By this I mean very specifically, I want to be able to watch the live stream in real time and be able to pause or rewind the live stream and be able to go back to real-time. I use a browser extension called Video Speed Controller, and with this if I ever need to pause or rewind a stream I can increase playback speed and slowly work my way back to real-time. Hopefully that makes sense.\n My use for this would be to capture live Twitch streams with streamlink, then re-stream it via OBS to this self-hosted stream so that I can pause and rewind, because Twitch's player does not offer these very basic features. Currently I can achieve exactly the functionality I desire with YouTube's live streaming service, but I feel kinda icky about broadcasting someone else's Twitch live stream onto my own YouTube, even if it is a private/unlisted stream intended exclusively for my own use.\n It would also be ideal if it works with a reverse proxy so that I can use it away from home securely.\n I've briefly looked into Owncast but it does not appear to have the DVR functionality. I haven't set up an Owncast server yet to actually investigate, but I figure if it doesn't advertise that feature then it's unlikely to have it.\n Does anyone know of anything like this? Thank you.\n    submitted by    /u/Coalbus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zov3r3/selfhosted_livestreaming_with_dvr_features_pause/",
          "publishedOn": "2022-12-18T09:54:01.000Z",
          "wordCount": 17444,
          "title": "Self-hosted livestreaming with DVR features (pause and rewind)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zostpm/first_release_minmon_an_opinionated_minimal/",
          "author": null,
          "description": "Alright guys, get your xkcds ready! I programmed yet another monitoring and alarming tool because I couldn't find one I like for the use case I'm targeting. It's pretty basic right now as it only has two types of checks (filesystem and memory usage) and a bunch of actions (e-mail, log, process and webhook). As the (not very creative) name suggests, it's quite minimal in terms of configuration and code. It's also super easy to extend (which I will do; see the roadmap). It's only for Linux (for now..).\n Feedback and contributions are very welcome!\n https://github.com/flo-at/minmon\n    submitted by    /u/flo-at  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zostpm/first_release_minmon_an_opinionated_minimal/",
          "publishedOn": "2022-12-18T07:22:44.000Z",
          "wordCount": 16998,
          "title": "First release: MinMon - an opinionated minimal monitoring and alarming tool",
          "imageUrl": "https://external-preview.redd.it/Xptuo8_OiHXPLIP5jPC3s5JTdhC9k0WNDnb7nku8bwA.jpg?auto=webp&s=d7357889f65b99c72bfec9d8908fcb18a0e1d445"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zor7b4/suggest_any_selfhosted_family_games/",
          "author": null,
          "description": "Its holiday times and my fam likes board games, quizes and souch stuff.\n So I am looking for something in domain of:\n  \nKahoot\n GooseChase\n Some kind of murder mystery game\n etc\n  \nIs there any such self-hosted stuff?\n    submitted by    /u/the_kovalski  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zor7b4/suggest_any_selfhosted_family_games/",
          "publishedOn": "2022-12-18T05:40:35.000Z",
          "wordCount": 1864,
          "title": "Suggest any self-hosted family games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoldpp/huginns_ip_keeps_getting_blocked_by_kickstarter/",
          "author": null,
          "description": "Twice now I’ve had Kickstarter block the IP of the machine I have Huginn running on. I’ve had to move my Huginn instance to another hosting platform already once. How can I keep Kickstarter from blocking my IP?\n    submitted by    /u/fireshaper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoldpp/huginns_ip_keeps_getting_blocked_by_kickstarter/",
          "publishedOn": "2022-12-18T00:42:27.000Z",
          "wordCount": 16703,
          "title": "Huginn’s IP keeps getting blocked by Kickstarter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zokpn7/is_there_any_service_that_i_can_host_videos/",
          "author": null,
          "description": "I want to upload videos on my website like youtube embed.\n What can i use?\n    submitted by    /u/w0fs2aka9v6g6k9y3aac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zokpn7/is_there_any_service_that_i_can_host_videos/",
          "publishedOn": "2022-12-18T00:16:50.000Z",
          "wordCount": 17352,
          "title": "Is there any service that i can host videos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoj1fl/minimum_specs_for_nas_using_omv/",
          "author": null,
          "description": "Hi everyone! I would like to buy a low end PC to use as a NAS. Building a new rig is expensive AF but buying a workstation from a few years ago is cheaper.\n But, what would be the “minimum specs” for a NAS? I would like to use Openmediavault as the OS, but having Plex in a Docker container.\n    submitted by    /u/donrafiki25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoj1fl/minimum_specs_for_nas_using_omv/",
          "publishedOn": "2022-12-17T23:05:39.000Z",
          "wordCount": 17326,
          "title": "Minimum Specs for NAS using OMV",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoitec/what_would_it_take_to_host_chatgpt_35/",
          "author": null,
          "description": "my resources are 8TB of storage\n 32 gigs of ram total 7 - 12 to allocate\n latest i7 intel CPU\n RTX 2070 \n and the average power in and output of a gaming computer\n do i have the resources to run chatgpt if it was opensource\n    submitted by    /u/Avocado_Express  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoitec/what_would_it_take_to_host_chatgpt_35/",
          "publishedOn": "2022-12-17T22:56:05.000Z",
          "wordCount": 17157,
          "title": "what would it take to host chatgpt 3.5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoh8ab/linuxwindows_question_regarding_sharing_folders/",
          "author": null,
          "description": "So I have Hyperv running on my windows computer. Running a linux server of sorts. Lots of different dockerized services. I've been wanting to share an external Drive I have (Drobo) connected to my windows machine with the linux side. Just a few folders to be able to read/write/ and execute from both OS's and the regular user. \n Here's the rub and mind you I'm still learning linux and getting these services running is just part of my learning process.\n I've been running:\n \"sudo mount.cifs //ip/Downloads /home/user/Downloads -o user=username\"\n to share a Downloads folder on my Drobo with the one I specify on linux but everytime I run it, though it does allow me to read the content I cannot write. Despite attempting to chmod permissions it will only write for the root user. I've attempted to change to permissions at the root level and still keep running into a road block. I'm not sure if there's something I'm missing here but figured I'd throw it out to the the ether and see if I got some kind of idea.\n ​\n Thanks!\n    submitted by    /u/geoguy89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoh8ab/linuxwindows_question_regarding_sharing_folders/",
          "publishedOn": "2022-12-17T21:48:18.000Z",
          "wordCount": 16816,
          "title": "Linux/Windows Question Regarding Sharing Folders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zofpyh/memos_a_fun_twitter_like_notes_app/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zofpyh/memos_a_fun_twitter_like_notes_app/",
          "publishedOn": "2022-12-17T20:44:03.000Z",
          "wordCount": 18227,
          "title": "Memos - A fun Twitter like Notes app",
          "imageUrl": "https://external-preview.redd.it/Ua3_6I0dj_4E3rfaJ2WgdD638oDoS_V88hNzR-JRHQc.jpg?auto=webp&s=f63f30b80641d2b1a9cf07c88cb774d7de1fd17e"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zod1ik/docker_container_cant_access_another_one_via_host/",
          "author": null,
          "description": "I have two containers running on my server. One is mariadb with an opened port to the host - it's working perfectly with my IDE. The other one is a tomcat server.\n When I try to deploy a .war-file (which is also working well) inside the tomcat container it tells me, that the connection to the DB could not be established.\n What can I add to my compose-file so that the tomcat container will be able to connect to the public IP:Port of the host (regarding the DB container)?\n    submitted by    /u/Bl4ckF4k3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zod1ik/docker_container_cant_access_another_one_via_host/",
          "publishedOn": "2022-12-17T18:46:47.000Z",
          "wordCount": 19328,
          "title": "docker container can't access another one via host domain and port",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zobfbq/looking_for_bandwidth_monitoring_app/",
          "author": null,
          "description": "Hi, I'm looking for a self hosted app that can monitor how much bandwidth the server is using. My main objective is to know how much internet I used on a monthly basis.\n I don't need all the bells and whistles like intrusion detection, etc.\n Ideally with a simple web UI.\n Any advice? Thanks!\n    submitted by    /u/Issam2204  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zobfbq/looking_for_bandwidth_monitoring_app/",
          "publishedOn": "2022-12-17T17:34:28.000Z",
          "wordCount": 16976,
          "title": "Looking for bandwidth monitoring app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zob9dp/using_cfs_free_edge_certs_for_reserved_ips/",
          "author": null,
          "description": "I'm probably missing something, but I'd like:\n  \nuse tailscale as my \"VPN\" into my network\n use simple hosts like bitwarden.home.mydomain.com to access resources\n protect my bitwarden_rs instance with https (hopefully be able to use the native apps instead of the website)\n make it simple to manage (no self-hosted certs installed on end devices)\n not expose my proxy to the public web (egress is fine)\n and do it for free (other than the purchase of the domain)\n  \nMy thought was to create a DNS record in CF that points to a reserved IP, \"10.5.5.14\". Then on \"10.5.5.14\", setup a reverse proxy entry with the cert provided by CF.\n I'm guessing this isn't possible as the edge certs can only be used if you proxy requests through CF network, which isn't possible because I'm within a reserved IP range.\n Is there another way to achieve what I want to do?\n    submitted by    /u/pro547  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zob9dp/using_cfs_free_edge_certs_for_reserved_ips/",
          "publishedOn": "2022-12-17T17:26:53.000Z",
          "wordCount": 17239,
          "title": "Using CFs free edge certs for reserved IPs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoabzj/nextcloud_alternative_for_filesharing/",
          "author": null,
          "description": "Is there a good alternative to nextcloud that offers GDrive-style folder sharing via links? \n I like Nextcloud in principle but it's tendency to constantly break without any useful error messages is getting on my nerves...\n    submitted by    /u/Komari  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoabzj/nextcloud_alternative_for_filesharing/",
          "publishedOn": "2022-12-17T16:44:51.000Z",
          "wordCount": 20398,
          "title": "Nextcloud alternative for filesharing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoa6n4/how_to_manage_multiple_port_with_adguard_personal/",
          "author": null,
          "description": "Hello i'm currently running my own server on a raspberry. But i am struggling with the port management. I can't understand. \n If i have Adguard runnning on port 80 , i need this port to have my DNS working on Adguard, but i want that my dashboard to run also on this port, like i want to just type myaddress.com or 192.168.1.20 to display my dashboard without my dns not working. \n How can i do that ? I tried reading some documentation but i couldn't understand.\n I know you can use ngninx port forwarding, but will my dns work if 80 is not the port for my dns ?\n    submitted by    /u/Biaumax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoa6n4/how_to_manage_multiple_port_with_adguard_personal/",
          "publishedOn": "2022-12-17T16:38:06.000Z",
          "wordCount": 18192,
          "title": "How to manage multiple port with Adguard, Personal sites, Ngninx port forwarding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo9kzg/running_on_raspberry_pi_with_tailscale/",
          "author": null,
          "description": "Hi, just got Nextcloud working on my Raspberry Pi. Currently can access with http or self signed https.\n I want to make sure I access this securely from outside my LAN. Can I just use Tailscale to access it from another network?\n I’ve seen people create SSL certificates and set up reverse proxies to access their web server from outside their LAN, but couldn’t they just use Tailscale?\n    submitted by    /u/spazzyjazzy7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo9kzg/running_on_raspberry_pi_with_tailscale/",
          "publishedOn": "2022-12-17T16:11:28.000Z",
          "wordCount": 18618,
          "title": "Running on Raspberry Pi with Tailscale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo9arx/virtual_router_for_a_device_on_my_network/",
          "author": null,
          "description": "I want to have a device on my network to have its outside traffic go through a commercial VPN. \n To be more precise. I have NordVPN and want the Chromecast on my network to have its traffic go via NordVPN.\n The chromecast doesn’t support VPN settings as far as I know. My router (TP Link ER605) supports policy routing and VPN. But not NordVPN. \n Is there a way to have a very simple virtual router that supports NordVPN ? Preferably as a docker container. \n My idea would be to create a second wireless network on my ubiquity AP with this virtual router as a gateway. Not sure if it would work.\n    submitted by    /u/kouignamann_kingdom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo9arx/virtual_router_for_a_device_on_my_network/",
          "publishedOn": "2022-12-17T15:59:10.000Z",
          "wordCount": 18513,
          "title": "Virtual router for a device on my network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo88wq/recommendation_for_a_selfhosted_plex_server/",
          "author": null,
          "description": "Hello,\n I've been using Plex for a very long time. Starting with my PC as the server, then moved to a hosted VPS, and currently I'm using a Seedbox.\n The Seedbox is extremely powerful and meets all my needs, but it's getting fairly expensive upgrading storage to a higher capacity.\n I would like your opinions about self hosted solutions. I'm open to using Nas devices, or even building another PC to support it. I currently have an nVidia 1080 that I can utilize for that purpose. The only thing I need, is a solution / device that would do the transcoding on its own, because I don't want to use my PC for that. \n I'm currently serving about 4 users and max simultaneously transcoding is 2-3. Also serving 4k content so I need a device that's powerful enough.\n I'm also looking for the cheapest solution that can be used for this purpose.\n Greatly appriciate your input!!!\n    submitted by    /u/MetallicAchu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo88wq/recommendation_for_a_selfhosted_plex_server/",
          "publishedOn": "2022-12-17T15:09:12.000Z",
          "wordCount": 18013,
          "title": "Recommendation for a self-hosted Plex server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo6ojn/scraper_and_match_price/",
          "author": null,
          "description": "Hello,\n I dont know if exist but i'm looking for an app where I upload a csv file with 100 products and match price with 2 website.\n Do you think exist this? \n ​\n Thank you for your help\n    submitted by    /u/Elemis89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo6ojn/scraper_and_match_price/",
          "publishedOn": "2022-12-17T13:49:52.000Z",
          "wordCount": 17565,
          "title": "Scraper and match price",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo6860/is_there_any_self_hosted_journaling_app_you_are/",
          "author": null,
          "description": "submitted by    /u/seeking_facts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo6860/is_there_any_self_hosted_journaling_app_you_are/",
          "publishedOn": "2022-12-17T13:24:25.000Z",
          "wordCount": 17240,
          "title": "Is there any self hosted journaling app you are using and can recommend ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo6852/is_there_a_virtual_cinema_app_that_exists/",
          "author": null,
          "description": "Not a Netflix style software, like Plex or Jellyfin, but something where a user can log on, pick a \"screen\", and a movie is just playing, kind of like a virtual cinema\n It seems like a pretty niche and silly idea, so might be something I have to try and build myself, but if there's something that already exists, that'd be awesome\n    submitted by    /u/KoolKarmaKollector  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo6852/is_there_a_virtual_cinema_app_that_exists/",
          "publishedOn": "2022-12-17T13:24:23.000Z",
          "wordCount": 16680,
          "title": "Is there a \"virtual cinema\" app that exists?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo3iup/calibre_web_ldap_auth_is_anyone_able_to_point_me/",
          "author": null,
          "description": "submitted by    /u/licidil95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo3iup/calibre_web_ldap_auth_is_anyone_able_to_point_me/",
          "publishedOn": "2022-12-17T10:28:16.000Z",
          "wordCount": 19645,
          "title": "Calibre Web LDAP Auth - Is anyone able to point me in the right direction of what I'm doing wrong? Trying to setup LDAP Auth for my Calibre Web instance, and something isn't liking me. Apologies if r/Selfhosted turns out to be the wrong subreddit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo2t1j/what_lightweight_opensource_word_processor_task/",
          "author": null,
          "description": "submitted by    /u/apompon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo2t1j/what_lightweight_opensource_word_processor_task/",
          "publishedOn": "2022-12-17T09:38:47.000Z",
          "wordCount": 17047,
          "title": "What lightweight open-source word processor, task, and data management tool(s) for personal use would you advise?",
          "imageUrl": "https://external-preview.redd.it/ZqwAwrTwSZaImA5ODfHEfSMybVDV2Jaw9BvyiXcKX0Y.png?auto=webp&s=bc572284ee8ed4b6406e648ee04848679b73689c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo0802/feature_suggestion_for_a_personal_finance_app/",
          "author": null,
          "description": "submitted by    /u/dev_reez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo0802/feature_suggestion_for_a_personal_finance_app/",
          "publishedOn": "2022-12-17T06:41:13.000Z",
          "wordCount": 1869,
          "title": "Feature suggestion for a personal finance app.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zny6tb/from_asking_is_there_a_fing_network_monitor/",
          "author": null,
          "description": "submitted by    /u/jokob  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zny6tb/from_asking_is_there_a_fing_network_monitor/",
          "publishedOn": "2022-12-17T04:36:52.000Z",
          "wordCount": 20037,
          "title": "From asking: Is there a Fing network monitor alternative? To: Maintaining a docker image of Pi.Alert for 1 year and 100k pulls later - it's been fun 😉",
          "imageUrl": "https://external-preview.redd.it/tIOInfPaGODJBD1WZuOxbs6bftrFl6crlrwF7H6iKbM.jpg?auto=webp&s=58dd30bc1fcb57b25cb7dec7a640d745407bc1ae"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znungq/docker_secrets_without_swarm/",
          "author": null,
          "description": "I'm finding myself having to hard code passwords in docker-compose files. I'm looking for a way to have secrets for the dozen or so services I run in docker containers without having to go with Docker Swarm or Kubernetes. Using .env files is not an option either.\n Anyone have suggestions or am I going to have to go full blown Kubernetes?\n    submitted by    /u/Ohsbar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znungq/docker_secrets_without_swarm/",
          "publishedOn": "2022-12-17T01:21:29.000Z",
          "wordCount": 17563,
          "title": "Docker secrets without Swarm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znugtz/can_i_use_an_old_wireless_router_to_isolate_my/",
          "author": null,
          "description": "submitted by    /u/Melodic_Walk_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znugtz/can_i_use_an_old_wireless_router_to_isolate_my/",
          "publishedOn": "2022-12-17T01:12:07.000Z",
          "wordCount": 16919,
          "title": "Can I use an old wireless router to isolate my wireless cameras from the internet? And how do I connect my server to my infrastructure so that I can access the camera feeds (saved to my server) via my PC?",
          "imageUrl": "https://preview.redd.it/g66bp6zkzc6a1.png?auto=webp&s=8d01e91e81015c07406852eb70af9d598a7922b0"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znue1e/opensource_docker_management/",
          "author": null,
          "description": "I see products like Portainer, and unraid, are there any open source tools with a webui for managing docker containers?\n    submitted by    /u/kittywrastler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znue1e/opensource_docker_management/",
          "publishedOn": "2022-12-17T01:08:02.000Z",
          "wordCount": 17521,
          "title": "Opensource Docker Management?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znt97g/laptop_as_a_personal_home_server/",
          "author": null,
          "description": "Is a laptop (Ryzen 7 4800H) a good option if energy consumption is my main concern? I'm not sure but isn't a laptop designed to consume less energy while in idle? Also, I'm thinking about disabling CPU boost to increase energy efficiency. Any thoughts on that?\n    submitted by    /u/Rotwildus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znt97g/laptop_as_a_personal_home_server/",
          "publishedOn": "2022-12-17T00:11:37.000Z",
          "wordCount": 18223,
          "title": "Laptop as a personal home server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znsiby/any_help_on_how_to_make_an_oracle_cloud_account/",
          "author": null,
          "description": "I really need a oracle cloud account to host a videogames server, and the free tier is more than enough for me. Although the only payment method I've got in my hands is Paypal. \n Could you guys help me? I really planed to host it on my old PC, but it's not enough. Otherwise I'll have to rent a server..\n    submitted by    /u/super_probably-user  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znsiby/any_help_on_how_to_make_an_oracle_cloud_account/",
          "publishedOn": "2022-12-16T23:36:41.000Z",
          "wordCount": 16595,
          "title": "any help on how to make an oracle cloud account with Paypal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znrdx5/selfhosted_opensource_chatgpt_alternative/",
          "author": null,
          "description": "Are they any selfhosted/ open-source ChatGPT alternatives?\n    submitted by    /u/TheRealCaptCrunchy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znrdx5/selfhosted_opensource_chatgpt_alternative/",
          "publishedOn": "2022-12-16T22:45:50.000Z",
          "wordCount": 16496,
          "title": "selfhosted/ open-source ChatGPT alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znp2c2/self_hosted_voice_server_with_good_a_mobile_app/",
          "author": null,
          "description": "I'm looking to self host a 20 person audio chat server for an event. \n Normally we would Discord for something like this, but we don't have a ton of bandwidth, want to reduce lag, and everyone will be on premise.\n The server is almost beside the point here because we need a system that has a good mobile app interface. We need an app available with the following:\n  \nAndroid and iOS versions\n Push to talk, and auto mute settings\n Multiple channels\n Works with Bluetooth headsets and Airpods\n  \n   submitted by    /u/Jam3Sandwich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znp2c2/self_hosted_voice_server_with_good_a_mobile_app/",
          "publishedOn": "2022-12-16T21:04:08.000Z",
          "wordCount": 16626,
          "title": "Self hosted voice server with good a mobile app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znp1yz/best_file_system_and_backup_type_for_a_simple_4tb/",
          "author": null,
          "description": "I'm trying to share 2x 4tb NAS type hard disks for all my home computers. Right now due to limitations I'm not able to put together a NAS type of PC, but maybe in the future I will properly set it up. So the idea is to use them in my main desktop computer using samba share.\n I will store important data (precious personal stuff) and movies, so my main concern is to reduce the possibility of corruption or loss of data. I don't care too much for the speed of the share. What is the most robust configuration for this?\n I firstly thought to use them as RAID1, but as I'm reading more forums, the more I get the idea that maybe it's overkill. Maybe it's better to make a backup once a week for example and leave the possible problems of RAID missconfigurations? I'm a newbie for RAID configs.\n The other thing is the hard disk file system. Right now I'm between ZFS and EXT4. Same as before, I heard that there is not much difference between them for my size and tasks, but any little improvement over data integrity is appreciated.\n Just in case it's important, my PC has 16gb ram ddr4 and it has a mid modern cpu.\n    submitted by    /u/NavirAur  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znp1yz/best_file_system_and_backup_type_for_a_simple_4tb/",
          "publishedOn": "2022-12-16T21:03:39.000Z",
          "wordCount": 16928,
          "title": "best file system and backup type for a simple 4tb samba share in Ubuntu (2x4tb disk)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znopo2/docker_nginx_proxy_manager_real_ips_for_crowdsec/",
          "author": null,
          "description": "I have all of my services set up in docker on a Synology NAS. NPM is currently running (also in a docker) and handling all traffic wonderfully. I'm still struggling with Authentic LDAP, but I have OIDC and plex authentication working, so I feel well on my way there.\n Now I want to add crowdsec to secure NPM..... I got crowdsec up and running, but once I ingested the NPM logs, I found out that NPM sees all traffic originating from 127.24.0.1.\n I tried setting up macvlan and when I put NPM on there I could hit the management interface on its new IP from my PC, but my router couldn't see it to set the port forwards, so I revered to the bridge network.\n I've seen several guides saying this can be achieved by setting real IP headers in nginx.conf, but NPM doesn't have (at least mine doesn't) that file. ./data/nginx/default_host/site.conf is the closest thing I can find in my set-up following the official NPM install docs.\n Any pointers on how to log real IPs in a docker NPM would be greatly appreciated. \n Or if anyone knows a better way to set up crowdsec on synology, I'd love to hear those suggestions as well.\n Thanks!\n    submitted by    /u/thegreatincognitum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znopo2/docker_nginx_proxy_manager_real_ips_for_crowdsec/",
          "publishedOn": "2022-12-16T20:49:07.000Z",
          "wordCount": 19528,
          "title": "Docker Nginx Proxy Manager real IPs for Crowdsec",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znojvn/can_you_use_ocserv_with_cloudflare_proxy/",
          "author": null,
          "description": "hello\n is there anyway to use anyconnect with cloudflare proxy ? ( or any other proxy )\n    submitted by    /u/pixibooy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znojvn/can_you_use_ocserv_with_cloudflare_proxy/",
          "publishedOn": "2022-12-16T20:42:06.000Z",
          "wordCount": 17566,
          "title": "Can you use ocserv with cloudflare proxy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znnjkz/money_manager_with_iphone_app_or_mobile_friendly/",
          "author": null,
          "description": "I use an old version of YNAB (and absolutely love it) but hate the idea of only being computer based so I am in the hunt for a money manager that can be self hosted and also mobile friendly.\n Does the above exist?\n    submitted by    /u/chench0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znnjkz/money_manager_with_iphone_app_or_mobile_friendly/",
          "publishedOn": "2022-12-16T19:59:44.000Z",
          "wordCount": 16495,
          "title": "Money manager with iPhone app? (Or mobile friendly)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znmlg2/fireshare_a_simple_solution_to_self_hosting_your/",
          "author": null,
          "description": "I last posted here ~5 months ago about Fireshare, a project that I have been working on to quickly and easily share my game clips via unique links. \n It got a lot of positive feedback so I thought I would share it again since I've seen a number of people in comments and post since then asking about video sharing solutions. \n Core Features\n  \nShare h264 encoded mp4, mov and webm files via unique links\n Set videos as either public vs private. Public videos can be seen by anyone who visits your Fireshare instance. Private videos can only be seen by those with the unique link.\n Public and private upload capabilities.\n Simple setup requires basic knowledge of Docker.\n  \nYou can see it for yourself on my demo site: https://v.fireshare.net \n The github project: https://github.com/ShaneIsrael/fireshare\n I also have a complete tutorial on self hosting it which you can find here\n You can find other well put together tutorials on setting it up on YouTube and other websites that users have put together as well.\n  \nLet me know if you have questions and/or if you've used it I would love to hear your feedback. :)\n    submitted by    /u/Shane75776  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znmlg2/fireshare_a_simple_solution_to_self_hosting_your/",
          "publishedOn": "2022-12-16T19:17:04.000Z",
          "wordCount": 18148,
          "title": "Fireshare - A simple solution to self hosting your own videos / game clips via unique links.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znmj5v/which_option_to_use_to_create_a_private_network/",
          "author": null,
          "description": "So I have a macbook, PC, synology NAS, iPhone, some laptops and some raspberry pis.\n I work outside my house quite a lot from my windows laptop or run simple tasks using termius on my iphone. My macbook is always on at home so I usually ssh into it and do my work, sometimes my iphone as well.\n There are some things I cannot do with this, for example if I want to turn on my nas remotely, I can't use my iphone as the app requires you to be on the same network. Also I don't feel safe that I have exposed my devices to the internet like that.\n I want to connect all my devices onto the same network so I can access them anywhere as if they were on the same LAN network. I was looking around at options such as zerotier, nebula, tailscale, headscale, yggdrasil, innernet, openziti, tinc and wireguard and I think wireguard might be my best option as I read that it uses the least amount of resource. Also I want a free and open source and self hosted option.\n I found some of the following tools on github:\n https://github.com/psyhomb/wireguard-tools\n https://github.com/netbirdio/netbird\n https://github.com/gravitl/netmaker\n https://github.com/tonarino/innernet\n I have zero experience setting up networks like this.\n Can I get a recommendation on a good guide and/or which tools I should use to set up the network I desire so any of my devices can be used from anywhere.\n I also understand that some setups require a server to be always on, is there any way around that? I am planning to run the wireguard server from my raspberry pi 3 that also has vaultwarden running. Also must I have a static IP address? My IP address changes sometimes / every few months. If it does, will I be able to easily modify wireguard?\n Also, if there is a better alternative, please let me know.\n    submitted by    /u/areyouhourly-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znmj5v/which_option_to_use_to_create_a_private_network/",
          "publishedOn": "2022-12-16T19:14:24.000Z",
          "wordCount": 20311,
          "title": "Which option to use to create a private network (VPN) for all my devices which I can connect to from anywhere",
          "imageUrl": "https://external-preview.redd.it/CXiZYS8_48h6T-d9EHiYz4eSRlMfXEWU1VQD7wTOHdM.jpg?auto=webp&s=c51b0d297636439646b2c8b1d04e25c0decf3531"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znm7vt/cant_forward_ports_in_nginx_proxy_manager/",
          "author": null,
          "description": "The nginx proxy manager is running in docker and listening to port 80. \n I set it up so that, at the end, the source is http://example.com and the destination (a web app running in the same server) is http://example.com:5000. In terms of the diagram here \n https://forums.unraid.net/topic/110245-support-nginx-proxy-manager-npm-official/\n The “Domain name” and “Forward host to” are http://example.com, the port is 5000, and scheme is http. \n The domain http://example.com:5000 correctly resolves to the expected destination web page. The expectation is that, when I enter http://example.com, it will be forwarded to http://example.com:5000, but it doesn’t. I get a page from NPM that you have successfully set up NPM, but your destination is not correctly set up. \n What could be wrong? How to troubleshoot?\n Initially I suspected docker networking might be the issue. I thought the destination resolves inside docker, which is not defined. But the NPM docker network is a bridge, so the destination DNS query should be able to get out of the docker and resolve in host. \n The application in destination also runs in docker, but with ports mapped in the host. As noted, http://example.com:5000 is indeed accessible.\n I tried other destinations also: localhost, internal IP address of the host, docker interface Ip, etc.\n    submitted by    /u/chaplin2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znm7vt/cant_forward_ports_in_nginx_proxy_manager/",
          "publishedOn": "2022-12-16T19:00:44.000Z",
          "wordCount": 18678,
          "title": "Can’t forward ports in Nginx proxy manager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znjmpt/looking_for_a_tool/",
          "author": null,
          "description": "Hi,\n I'm looking for a solution/tool in which I can put a script, scheduled it to run on particular time/day (preferably cron), execute it and send the results to my email.\n Something similar to Jenkins, but simpler. Jenkins seems overkill for such task.. I know I can build it myself using s-nail/cron/bash, but I was looking for something ready-to-go in a container if possible.\n    submitted by    /u/luxlucius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znjmpt/looking_for_a_tool/",
          "publishedOn": "2022-12-16T17:08:28.000Z",
          "wordCount": 19270,
          "title": "Looking for a tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znjgj1/alternative_to_google_contacts/",
          "author": null,
          "description": "I'm looking for alternative to Google Contacts both the web version as well as Android. On Android I can use any phonebook but I'm expecting sync client that will sync all my contacts with the server. Any suggestions?\n    submitted by    /u/a_sugarcane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znjgj1/alternative_to_google_contacts/",
          "publishedOn": "2022-12-16T17:01:07.000Z",
          "wordCount": 16585,
          "title": "Alternative to Google Contacts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zngryi/is_there_any_best_self_hosted_service_youre_using/",
          "author": null,
          "description": "submitted by    /u/seeking_facts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zngryi/is_there_any_best_self_hosted_service_youre_using/",
          "publishedOn": "2022-12-16T15:07:03.000Z",
          "wordCount": 17108,
          "title": "Is there any Best self hosted service you're using for music ? Any Suggestion ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znglcq/self_hosted_roundup_20/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znglcq/self_hosted_roundup_20/",
          "publishedOn": "2022-12-16T14:59:12.000Z",
          "wordCount": 17851,
          "title": "Self Hosted Roundup #20",
          "imageUrl": "https://external-preview.redd.it/rDCbV6tRIvHl73_s4OAeOEF_HU5OSJK1BFMZuzIcUQk.jpg?auto=webp&s=67f0de5afb7bb7b7a6ed5b0d9f89e6b3e7ad3773"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znep9y/pikvm_v4_nextgen_open_source_kvm_over_ip_on/",
          "author": null,
          "description": "submitted by    /u/Liksys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znep9y/pikvm_v4_nextgen_open_source_kvm_over_ip_on/",
          "publishedOn": "2022-12-16T13:29:03.000Z",
          "wordCount": 19862,
          "title": "PiKVM V4 - nextgen open source KVM over IP on Kickstarter",
          "imageUrl": "https://external-preview.redd.it/mggCHtVDAGBVhVFfvlhlF53GbuO_AjgU3JQ0Rgwncy0.jpg?auto=webp&s=347863f79c7f3d772275e0fdd66d9ffe780c17ee"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zne2bc/emotions_on_self_hosting/",
          "author": null,
          "description": "When I self-host something and I feel proud, should I be proud? I am a newbie. And what I'm doing would sound trivial to an expert. So can I feel proud of the fact that I'm self-hosting things? And can I show off the docker containers to people who are less tech-savvy than me? I want to show them this server that I made. I want to show them how cool it is. But when I think more about it, it is nothing big at all...\n This is some sort of philosophical thing that I don't understand.\n Sorry to bother anyone. \n A weird topic for sure.\n    submitted by    /u/lightningdashgod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zne2bc/emotions_on_self_hosting/",
          "publishedOn": "2022-12-16T12:56:54.000Z",
          "wordCount": 19811,
          "title": "Emotions on self hosting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zndd0n/codeberg_forks_gitea_with_forgejo/",
          "author": null,
          "description": "I've just read the news that Codeberg launches Forgejo I wasn't even aware that Gitea was being turned into a for-profit organization!\n    submitted by    /u/kakamiokatsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zndd0n/codeberg_forks_gitea_with_forgejo/",
          "publishedOn": "2022-12-16T12:18:59.000Z",
          "wordCount": 18196,
          "title": "Codeberg forks Gitea with Forgejo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zncjgv/new_40_tb_nas_server_selfhosted_help/",
          "author": null,
          "description": "Hello to all, \n briefly about my environment:\n Main Server:\n i5-8600 CPU\n 32 GB RAM 1 TB SSD\n With Proxmox running my main VM's/Container's.\n Main NAS:\n Qnap TS-451D2\n 4x 8TB WD Purple \n Raid 10\n I am planning a new NAS with 4x 10 TB WD RED, Ryzen 7 2700X and 16 GB RAM And don't know exactly how to implement it.\n Either I would set up a Nextcloud VM in Proxmox, since the hardware is a bit more powerful, and I might want to run other VMs afterwards or even shut down my other compute server.\n Now the question is what is better Proxmox, Unraid or TrueNas?\n In the end, I only want the most stable and failsafe solution, because I am afraid of data loss. Backups will be made, of course.\n A ready-made NAS solution always gives me security, but I need a more powerful NAS, which can also AI image detection.\n Personally, AI image recognition is most important to me as I am looking for a strong tool to manage my images.\n Does anyone have any ideas?\n Thank you for all comments.\n    submitted by    /u/Katze_Mau  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zncjgv/new_40_tb_nas_server_selfhosted_help/",
          "publishedOn": "2022-12-16T11:31:54.000Z",
          "wordCount": 17545,
          "title": "New 40 TB NAS server self-hosted | help :(",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zncays/how_do_you_manage_your_deployments/",
          "author": null,
          "description": "Hi folks,\n I am working on the next version of the PoeticMetric (privacy-first Google Analytics alternative), and I am going to make it free and open source. However, I would like to learn how people manage their deployments nowadays, so I can provide easy deployment options. For now, I am thinking of shipping with a production-ready docker-compose.yaml, and kubernetes manifests or helm chart is the only other option I can think of. So, how do you manage your deployments?\n View Poll\n    submitted by    /u/th0th  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zncays/how_do_you_manage_your_deployments/",
          "publishedOn": "2022-12-16T11:17:36.000Z",
          "wordCount": 19050,
          "title": "How do you manage your deployments?",
          "imageUrl": "https://external-preview.redd.it/qbDe7e4LrPEldaZvdR06QhOpj7HenQQyTl7-gLiMHOc.jpg?auto=webp&s=4c4dfdcbafcef6e71c0f0509cb268d610cbb1a73"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znca61/new_release_of_an_opensource_selfhosted_feature/",
          "author": null,
          "description": "https://github.com/featbit/featbit\n Change logs:\n  \nhttps://github.com/featbit/featbit/releases/tag/1.1.0\n https://github.com/featbit/featbit/releases/tag/1.1.1\n  \nNext milestones:\n Milestone🚀Happy new year 2023 · Discussion #129 · featbit/featbit (github.com)\n Previous post:\n Launchdarkly self-host alternative - open source feature management platform : selfhosted (reddit.com)\n    submitted by    /u/hu-beau  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znca61/new_release_of_an_opensource_selfhosted_feature/",
          "publishedOn": "2022-12-16T11:16:11.000Z",
          "wordCount": 18378,
          "title": "New release of an open-source & selfhosted feature flags platform",
          "imageUrl": "https://external-preview.redd.it/clSFF2iTaRGZIbQfMcTAG_mh_lOnDCak0or_0CFbL2E.jpg?auto=webp&s=d6de336ffc05632aee9b2a5741299deeb6bee5ee"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn2327/move_to_bookstack_from_wikijs/",
          "author": null,
          "description": "I am currently using WikiJS for my documentation and such.\n Things I like about WikiJS:\n - Plenty of customization/administration\n - Syncs plain text to S3 storage (using Cloudflare R2)\n Things I don't like about it:\n - Clunky UI, interface, and editor\n - Pages are slow to render\n - Half of the features are \"coming soon\"\n - Directory structure/hierarchy/navigation is difficult to use properly (at least for me)\n ​\n I was thinking of moving to Bookstack. I already have this installed from when I was testing a few other solutions.\n I've heard issues with Bookstack breaking URL's, is that still an issue I should be worried about?\n I've also heard that if the Bookstack docker/OS dies/corrupts, the data is useless because it uses a database and not plain text. If I sync my docs to S3 storage, are they stored in plain text there or will I need the database? My goal is to be able to have access to all of my documentation if my entire environment collapses. Having plain text files in Cloudflare R2 achieves that goal.\n ​\n *Please do not suggest Obsidian, Joplin, Trilium, etc. as I've tried them all. The only one I still want to try is Outline Wiki, but the setup is too complex just to set up for testing purposes.\n    submitted by    /u/cjchico  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn2327/move_to_bookstack_from_wikijs/",
          "publishedOn": "2022-12-16T01:07:44.000Z",
          "wordCount": 17655,
          "title": "Move to BookStack from WikiJS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn0z56/homelab_desktop_choices/",
          "author": null,
          "description": "submitted by    /u/MrJwan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn0z56/homelab_desktop_choices/",
          "publishedOn": "2022-12-16T00:15:37.000Z",
          "wordCount": 17470,
          "title": "Homelab Desktop Choices ..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn0sg6/is_there_any_way_i_could_expose_some_docker/",
          "author": null,
          "description": "I need him to be able to connect to GitLab CE, and PostgreSQL, but I dont want him to be able to access other containers.\n    submitted by    /u/FredericoDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn0sg6/is_there_any_way_i_could_expose_some_docker/",
          "publishedOn": "2022-12-16T00:07:29.000Z",
          "wordCount": 18211,
          "title": "Is there any way I could expose some docker containers for my friend safely and live?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn0dhx/self_hosted_crm_options_apart_from_vtiger/",
          "author": null,
          "description": "I've been using vTiger for almost 20 years now but I have to say that I've never liked it too much, but since it was the well known I've never been prone to switch \n I remember back in 2014 I was using one cloud CRM called Highrise from the guys from Basecamp, and it was utterly awesome: very simple CRM with the basic functions, all I needed for my use, but this project end closed (and also the project I was conducting and using this CRM with)\n And now I have the opportunity to see new options and I was wondering if you could recommending me anything but vTiger.\n    submitted by    /u/SirLouen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn0dhx/self_hosted_crm_options_apart_from_vtiger/",
          "publishedOn": "2022-12-15T23:49:26.000Z",
          "wordCount": 17971,
          "title": "Self hosted CRM options apart from vtiger?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn04jp/best_smtpmailserver_option_for_beginners/",
          "author": null,
          "description": "Hello everyone,\n selfhost/docker Beginner here. I already got some applications running, yay!\n But I´m currently stuck with hosting a mail/smtp application. I already tried the docker-mailserver, mailcow and as webinterfaces rainloop and sogo. But to be quite honest I am a little bit stunned by the complexity (a lot of services, ports,...) and amount of errors I am getting. I got not a single option to run correctly. I don´t know where to start.\n For me the topic selfhosted mail is the next logical step, because a lot of applications require an smtp server.\n So, had anyone a similar experience? Can someone recommend a proper, simple image or guide? What would you do?\n    submitted by    /u/Inevitable_Flight_48  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn04jp/best_smtpmailserver_option_for_beginners/",
          "publishedOn": "2022-12-15T23:38:25.000Z",
          "wordCount": 18078,
          "title": "Best SMTP/Mailserver option for beginners",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmywy8/cloudflare_tunnel_github_authentication_limit/",
          "author": null,
          "description": "Hi Folks,\n I appreciate this isn't really a self hosted product, but if any sub on reddit knows the answer to my question, it's going to be you guys!\n I've managed to fumble my way through cloudflare zero tier to add GitHub as an identity provider, but how do I restrict which github accounts can access my tunnel - at the minute every account can log in. Is this even possible?\n Edit: Solution in the comments\n    submitted by    /u/valkyre09  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmywy8/cloudflare_tunnel_github_authentication_limit/",
          "publishedOn": "2022-12-15T22:52:33.000Z",
          "wordCount": 17454,
          "title": "Cloudflare Tunnel - GitHub Authentication - limit users?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmxo4o/sftpgo_recycle_bin_using_the_event_manager/",
          "author": null,
          "description": "Hi together. In my search for a self-hosted file server I stumbled across SFTPGo. From the documentation I see that there is an Event Manager which should make it possible to realize a recycle bin. Does anyone have experience with this and can help me out? Thanks!\n    submitted by    /u/_patrickap  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmxo4o/sftpgo_recycle_bin_using_the_event_manager/",
          "publishedOn": "2022-12-15T22:09:30.000Z",
          "wordCount": 16888,
          "title": "SFTPGo recycle bin using the Event Manager",
          "imageUrl": "https://external-preview.redd.it/VLlV3-7ARpYCY7aM7F6_un4Z-UlvDKBF_z6uqGlJTuE.jpg?auto=webp&s=e1ac44181895912fc1bf98136d5bc04ffbcdfc8f"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmx8ru/oracle_cloud_cloudflare_nginx_proxy_manager_issues/",
          "author": null,
          "description": "I have a very basic server with Oracle Cloud free tier, and I managed to use Cloudflare and Nginx Proxy Manager to reroute my subdomains with the certifications and everything. However, the only way I get it to work is to expose each container port in my ingress rules on the Oracle server. \n To my understanding (noob here), the idea of using Nginx is to be able just to expose the usual ports (80, 443) and let the rerouting to go behind that, without the need to expose rest of ther ports. Am I correct?\n I'm not sure what additional information I could give to help solve the issue, let me know if there is anything I can add.\n Thanks in advance for the support.\n    submitted by    /u/carlossgv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmx8ru/oracle_cloud_cloudflare_nginx_proxy_manager_issues/",
          "publishedOn": "2022-12-15T21:53:41.000Z",
          "wordCount": 18230,
          "title": "Oracle Cloud / Cloudflare / Nginx Proxy Manager issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmx0op/free_crm_for_small_business/",
          "author": null,
          "description": "Hi all. Pretty much as per the title. Need a CRM to handle VERY simple tasks for software tech support. Basically need to be able to create some customers, associate them to incoming email addresses from our support address (simple SMTP/IMAP), create support items specific to them (usually stemming from said emails), assign to a team member, flag them as complete, etc, etc. Nothing too crazy, small 3-5 person team. Played with self-hosted Oodo but looks like way overkill and only one \"app\" for free version so that looks to end that scheme. PLayed with SuiteCRM but I seemed to be getting random errors, lag, etc (this was on a Windows install with XAMPP).\n Any thoughts, even if cloud based but free (if that exists) I suppose would work. Thanks in advance.\n    submitted by    /u/spg01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmx0op/free_crm_for_small_business/",
          "publishedOn": "2022-12-15T21:44:20.000Z",
          "wordCount": 16896,
          "title": "Free CRM for small business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmuw21/is_there_a_ytdlp_service_that_prompts_the_user_to/",
          "author": null,
          "description": "Essentially, don't want to define a volume for videos to download, but would rather have the program prompt the user with the save-dialog. This is basically going to serve as a frontend for family for example to download videos.\n I couldn't find anything after a cursory search, but maybe I missed something. Most seem to have the feature of defining a docker volume where the vids get downloaded to.\n    submitted by    /u/lannistersstark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmuw21/is_there_a_ytdlp_service_that_prompts_the_user_to/",
          "publishedOn": "2022-12-15T20:16:36.000Z",
          "wordCount": 17771,
          "title": "Is there a yt-dlp service that prompts the user to download and save the video/playlist instead of downloading in a pre-defined DIR?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmut5p/id_like_to_share_my_selfmade_dashboard/",
          "author": null,
          "description": "Python and Django, running in docker container on my nas.\n Anime episodes are tracked daily.\n Whats the opinion on coding stuff like this?\n I know its basic as hell. But its mine :)\n ​\n https://preview.redd.it/neggy56hd46a1.png?width=925&format=png&auto=webp&s=812e1074364f35ce684bf41c2f5ba5268f7651f1\n    submitted by    /u/kidz94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmut5p/id_like_to_share_my_selfmade_dashboard/",
          "publishedOn": "2022-12-15T20:13:23.000Z",
          "wordCount": 17133,
          "title": "Id like to share my selfmade dashboard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmu59u/nextcloud_all_in_one_updated_for_v25_not_mine/",
          "author": null,
          "description": "submitted by    /u/jogai-san  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmu59u/nextcloud_all_in_one_updated_for_v25_not_mine/",
          "publishedOn": "2022-12-15T19:46:15.000Z",
          "wordCount": 17269,
          "title": "Nextcloud All In One updated for v25 [not mine]",
          "imageUrl": "https://external-preview.redd.it/ULQUMvEp-Ud3QFakG1E6-tzDLlu_Q0PQhSS5ACKUa_Y.jpg?auto=webp&s=89ad726cad77c362f2646101f887d8fa3b2d6f8b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmtkh1/ntfy_android_app_v1160_persubscription_soundsdnd/",
          "author": null,
          "description": "submitted by    /u/binwiederhier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmtkh1/ntfy_android_app_v1160_persubscription_soundsdnd/",
          "publishedOn": "2022-12-15T19:22:32.000Z",
          "wordCount": 19178,
          "title": "ntfy Android app v1.16.0 🥳 - per-subscription sounds/DND, insistent alert-style notifications, adaptive launcher icons",
          "imageUrl": "https://external-preview.redd.it/-oJd03D-zX1SXDY7BanxD1beWfmbOZVR_AIvCXns8uI.jpg?auto=webp&s=5419349fb68e9d3eb21128fabc93bb06e2193723"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmscje/nginx_proxy_manager_timezone_incorrect_how_to/",
          "author": null,
          "description": "I've setup NPM in Docker and the creation time (for SSL certs, hosts etc) is not the correct time.\n How can I change this? Any one have a clue?\n    submitted by    /u/Panja0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmscje/nginx_proxy_manager_timezone_incorrect_how_to/",
          "publishedOn": "2022-12-15T18:32:06.000Z",
          "wordCount": 17958,
          "title": "Nginx Proxy Manager - Timezone incorrect; how to change?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmr54x/medusa_the_os_shopify_alternative_just_made_a/",
          "author": null,
          "description": "I am one of the co-founders behind Medusa, a composable commerce platform built in TS/JS with a headless architecture.\n It is built out of frustration with current proprietary platforms that always forced us to build hacky workarounds whenever we tried to customize our setup.\n As devs frequently use this Selfhosted sub at Medusa, we wanted to start making our larger releases a bit more public here. Today, we'll make the first of such updates - happy to hear feedback if there are more things you'd like to hear more / less about.\n ​\n THE UPDATES\n  \n250x performance improvement: With our latest release of Medusa, we just made a huge breakthrough with a >250x performance improvement. This is obviously significant, and we will publish a comprehensive deep-dive on it soon. For now, you can enjoy…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmr54x/medusa_the_os_shopify_alternative_just_made_a/",
          "publishedOn": "2022-12-15T17:42:49.000Z",
          "wordCount": 19465,
          "title": "Medusa, the OS Shopify alternative, just made a 250x performance improvement",
          "imageUrl": "https://external-preview.redd.it/RYedSa4fwAU6dB8eGzq3D-g5e66KjCzHeNNtzqdn9vY.jpg?auto=webp&s=4f97ebdaa4a44e63c8111f0c4055ddfb006b6ff4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmqr79/help_a_newbie_to_set_up_domain_with_tailscale/",
          "author": null,
          "description": "I went through Tailscale's documentation, but they needed to be more precise about setting up the domain and mapping it to the device.\n Here is a brief about my condition - \n  \nI have hosted my services on a raspberry pi.\n \nI got a static IP with tailscale.\n \nI am using Nginx-proxy-manager to manage domains and mapping.\n \nGoal is to map my domain (purchased off go daddy) to be mapped with my tailscale account/device so that I can set up multiple sub-domains for my different services.\n \n I apologise if this question sounds a bit noob. I am fairly new to the Selfhosting side of the world!\n    submitted by    /u/shubhank1912  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmqr79/help_a_newbie_to_set_up_domain_with_tailscale/",
          "publishedOn": "2022-12-15T17:26:42.000Z",
          "wordCount": 19925,
          "title": "Help a newbie to set up domain with Tailscale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmq7x8/loving_frigate_nvr/",
          "author": null,
          "description": "Just wanted to take some time and rave about Frigate NVR. I just installed it a couple days ago on home assistant and wow. For my personal use, It blows Agent DVR (Which I had been using for several months) out of the water. Here are some of my favorite points:\n  \nAccuracy is phenomenal for AI detections. This was always an issue with Agent DVR for me. It would detect my oil tank and christmas lights as people with up to 80% confidence level. Even sunset shadows it would be up to 70% confident it was people. By the time I masked these out almost 1/2 of the screen was gone. Zero false positives so far with Frigate and no masks.\n Clips are so smooth.\n CPU (Not using Coral) usage is extremely low and getting 15 to 19ms inference times on Snapdragon 8cx Gen 3 (Running HAOS Arm64 as a Hyper-V VM on Windows Dev Kit 2023). This is something I could not have said when I was running Agent DVR. AI detection with CodeProject.AI was usually hitting 40-60% CPU utilization on a 12 core i5 1240p. Agent DVR always idled at around 12% CPU utilization.\n  \n​\n https://preview.redd.it/f5yt4y35w26a1.png?width=965&format=png&auto=webp&s=0aaaa5dbca2383c6fff63f3774b7e7ceba9e4059\n https://preview.redd.it/vscbalu2436a1.png?width=1097&format=png&auto=webp&s=9f8b63a1d47e8d3d2f76675998cfc4ead9782246\n    submitted by    /u/dro159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmq7x8/loving_frigate_nvr/",
          "publishedOn": "2022-12-15T17:05:04.000Z",
          "wordCount": 17433,
          "title": "Loving Frigate NVR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmpp74/authentik_npm_how_to_disable_authentication_for/",
          "author": null,
          "description": "I have Nginx Proxy Manager + authentik set up, authentication works great but I cannot find how to disable authentication for my own local network. I watched Cooptonioan's video but that only covers disabling MFA for the local network whereas my goal would be to trust anyone that connects from the local network (thus disabling authentication) which is absolutely needed for the wife acceptance factor. How can this be achieved?\n PS setup was done based on GeeksCircuit guide.\n Edit: typo\n    submitted by    /u/gogglesmurf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmpp74/authentik_npm_how_to_disable_authentication_for/",
          "publishedOn": "2022-12-15T16:44:21.000Z",
          "wordCount": 18600,
          "title": "Authentik + NPM: how to disable authentication for local network?",
          "imageUrl": "https://external-preview.redd.it/hMY1CAYCh37uQ-meQ_5acXRX8Q6iO-5s4wGDhcH74bQ.jpg?auto=webp&s=d682dcf765b0b999b9dc6cba495523acdd6f9a79"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmodzb/selfhosted_seo_tools_ahrefs_free_alternative/",
          "author": null,
          "description": "The free version of Ahrefs is very, very limited. Are any Self-Hosted Alternative SEO Tools like that?\n    submitted by    /u/intelligent-idiot-2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmodzb/selfhosted_seo_tools_ahrefs_free_alternative/",
          "publishedOn": "2022-12-15T15:50:45.000Z",
          "wordCount": 18879,
          "title": "Self-Hosted SEO Tools? Ahrefs Free Alternative.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmo9nm/picking_an_os_for_storage_array/",
          "author": null,
          "description": "I have an old phenom II based system that I intend to fill up with drives and leave in a corner. \n I have a few os options, originally i was going to install proxmox ve, truenas, home assistant, ubuntu for docker containers, windows ect. I would like to just run windows server as a host os because if there is an issue in windows there is a much higher chance of me being able to fix it on my own without hours of googleing. I would like to have a standard smb share for my files, raid 10 6 hdd probably, but i would also like some sort of web interface that i can upload or download files from if i can't use smb for whatever reason. I have been told by people that storage spaces in windows is a nightmare though.\n Any advice will be greatly appreciated.\n    submitted by    /u/Peewee_Doggi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmo9nm/picking_an_os_for_storage_array/",
          "publishedOn": "2022-12-15T15:45:57.000Z",
          "wordCount": 18995,
          "title": "picking an os for storage array",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmi1kf/what_kind_of_storage_bay_are_you_using/",
          "author": null,
          "description": "Hi, \n I am selfhosting a lot of services like plex, nextcloud, adguard, ... and I would like to have good perf for R/W for the services.\n Specs: - I have multiple proxmox host for HA (like Dell optiplex) - I use the ZFS features (so this storage will be on ZFS). - Storage should be on 10Gb \n I think all the virtual disks would be on this new storage but there is a problem because I need : - SSD (good perf) for virtual disks of VMs - HDD for data (like movies, doc, pic, ...)\n --> So I think I would go with 2 zfs pools\n My questions are : - Which bay storage (with ECC Ram) should I use for my case ? SAN, NAS, DAS ? - What's the size of your pool and what kind of disk? - Where are your virtual disk, host side or dedicated storage reachable via NFS ? \n Thanks\n    submitted by    /u/hafx_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmi1kf/what_kind_of_storage_bay_are_you_using/",
          "publishedOn": "2022-12-15T10:36:48.000Z",
          "wordCount": 17255,
          "title": "What kind of storage bay are you using ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmdc1c/dropin_replacement_for_xbrowsersync_api_that_is_a/",
          "author": null,
          "description": "submitted by    /u/mrusme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmdc1c/dropin_replacement_for_xbrowsersync_api_that_is_a/",
          "publishedOn": "2022-12-15T05:38:25.000Z",
          "wordCount": 18634,
          "title": "Drop-in replacement for xBrowserSync API that is a single binary and supports SQLite3, PostgreSQL and MySQL",
          "imageUrl": "https://external-preview.redd.it/sZmmj54DsGYpxa6WEj1VgxjnY67zc1nEgK9wSd5hcPQ.jpg?auto=webp&s=7b204c4546c710a598716c130856fb8186795129"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm9725/favorite_web_based_apps_that_are_not_plex_or_emby/",
          "author": null,
          "description": "What’s your favorite self hosted web browser based apps that are not media related? Like notes, productivity… ect…\n    submitted by    /u/Fission455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm9725/favorite_web_based_apps_that_are_not_plex_or_emby/",
          "publishedOn": "2022-12-15T02:05:15.000Z",
          "wordCount": 19310,
          "title": "Favorite web based apps that are not plex or emby?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm8jeo/automotive_forum_archiving/",
          "author": null,
          "description": "I've been poking around trying to find a solution for archiving threads from various automotive forums. For anyone who doesn't use these forums, they have been dying over the years as people move to other social media platforms and with the decline in usage comes a decline in maintenance. Sometimes all the images disappear, videos get removed, or whole forum domains go down. Most of what's on these forums isn't super useful but there's a handful of threads showing highly custom stuff that is relevant to my own projects.\n I would like to be able to archive a thread in its entirety for later reference to include images, videos, and other links. I played around with ArchiveBox some and archiving with a link depth of 1 seems to gather all that, but also grabs all the other irrelevant links that are on a forum page that I don't care for. I also can only archive a thread one page at a time using ArchiveBox, which doesn't work for threads that might go on for hundreds of pages.\n I did some research and I think what I am looking for is a web scraper tool that can snag all the thread posts and associated links on a page, then cycle to the next page in the thread and repeat until all the pages have been archived....so with all that being said I am looking for recommendations for tools that might fit this use case.\n Since I don't think there's much overlap between self hosters and people who frequent the forums (though I might be wrong) here are two links of example threads that I would love to make sure I have indefinite access to (so long as I maintain my homelab).\n  \nExample 1\n Example 2\n  \n   submitted by    /u/Blackhawk706  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm8jeo/automotive_forum_archiving/",
          "publishedOn": "2022-12-15T01:34:39.000Z",
          "wordCount": 17158,
          "title": "Automotive Forum Archiving",
          "imageUrl": "https://external-preview.redd.it/otFsC595e7JriWlRKBRpl16-sLXjaC4MXGmjZkY03Q0.jpg?auto=webp&v=enabled&s=09be11fbaa68ff2a3025af1a732df282e787e4dc"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm8cd4/no_access_to_clipboard_for_nextcloud/",
          "author": null,
          "description": "I wonder if anybody else is having this problem: I'm one of the hosts of mintCast, I also manage the mintCast.org web server on a raspberry pi in my basement. In addition to that I host a Nextcloud instance that we use for our infrastructure. Though I've got Nextcloud running on bare metal, I've got the collabora server running in a docker container on the same machine. All of this is sitting behind and Nginx reverse proxy manager which itself is running in a docker container. The problem I'm having is when I try to embed calendars from next cloud onto the WordPress site I get an error on next cloud saying it cannot copy the HTML code to the clipboard. All of the SSL is sorted. Everything behind the reverse proxy has a self-signed certificate which the proxy trusts and then Nginx handles the external stuff with let's encrypt. I've also noted that I cannot copy and paste directly onto next cloud office documents. At least not with the mouse I have to use control v etc. I'm wondering if there's something I need to pass to the reverse proxy to give stuff like next cloud behind the rivers proxy access to the clipboard. If anybody knows anything about this I would greatly appreciate it\n    submitted by    /u/wchouser3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm8cd4/no_access_to_clipboard_for_nextcloud/",
          "publishedOn": "2022-12-15T01:25:37.000Z",
          "wordCount": 17024,
          "title": "no access to clipboard for nextcloud",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm796e/run_your_own_raspberry_pi_based_translation/",
          "author": null,
          "description": "submitted by    /u/smarxx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm796e/run_your_own_raspberry_pi_based_translation/",
          "publishedOn": "2022-12-15T00:36:06.000Z",
          "wordCount": 16611,
          "title": "Run Your Own Raspberry Pi Based Translation Service With LibreTranslate",
          "imageUrl": "https://external-preview.redd.it/NoOess-o2TuKcg8yF8X3-Da5GTSzMi9wE8lycP6wLmY.jpg?auto=webp&v=enabled&s=0235ca79b7ce84d7e9372746b22e1d4bb406a08c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm78om/adguard_home_breaks_steam_connection_sometimes/",
          "author": null,
          "description": "Hey there. I am very sure that my self-hosted AdGuard Home container is causing problems for me.\n I am currently often playing Modern Warfare 2 in the evening / night and I am playing and the Steam connection is randomly lost. First I thought of the Steam servers of course but I'm the only one with problems. It happens every day or at least every second day. And then the connection is lost and won't reconnect for at least 5 minutes I guess. Then it often works again.\n I tried to change the DNS server in the settings of my ethernet adapter on Windows 11 (to 8.8.8.8 e.g. instead of the local server) where I have my server 192.168.178.xx and as second 1.1.1.1 and flushed the DNS and it instantly worked again. So it seems to be that it has something to do with my DNS by AdGuard Home. But how the hell I am I supposed to really validate it or better fix it?\n The internet stays online while this disconnect in Steam is happening. Everything keeps working. Only Steam is not.\n Does anybody have an idea? I am pretty sure its caused by the DNS...\n    submitted by    /u/CptDayDreamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm78om/adguard_home_breaks_steam_connection_sometimes/",
          "publishedOn": "2022-12-15T00:35:29.000Z",
          "wordCount": 16337,
          "title": "AdGuard Home breaks Steam connection sometimes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm6l61/zabbix_on_oci_arm_instance/",
          "author": null,
          "description": "Hi All\n I'm curious, is anybody running Zabbix on a OCI ARM instance? \n If so, do you have a docker-compose you could kindly share, I'm having no luck with it.\n Thanks\n    submitted by    /u/Fluffer_Wuffer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm6l61/zabbix_on_oci_arm_instance/",
          "publishedOn": "2022-12-15T00:06:45.000Z",
          "wordCount": 16826,
          "title": "Zabbix on OCI ARM instance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm5qym/one_large_disk_nas_set_up_unraid/",
          "author": null,
          "description": "I love unRAID I have 2 setups. I've got a dedicated HP-109a with VMs and about 30 dockers. and I've had an HP microserver N40L running for over 10 years, most of it running on unRAID. It's got about 7 disks in It. Some 4TB, 3TB, 2TB etc.. About 15TB in total. N40L is getting a bit old now.. it for the most part shares out large media files over jellyfin. \n Was thinking of just getting 1 x 20TB disk in the HP-109a and having that as my NAS and container server & VMs.. it should handle the load OK.. i Can keep the N40L as an offline backup... I can live with loosing a week or so of data without parity. Don't think I need the RAID performance.. any other considerations?\n    submitted by    /u/matda59  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm5qym/one_large_disk_nas_set_up_unraid/",
          "publishedOn": "2022-12-14T23:30:18.000Z",
          "wordCount": 16860,
          "title": "One large disk NAS set up (unRAID)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm5f01/databasespreadsheet_for_logging_and_rating_movies/",
          "author": null,
          "description": "I used to do this in spreadsheets, then I switched over to doing it in obsidian, now I'm wondering if there is a good selfhosted option for it?\n Most googling/searching brought me to baserow, which does accomplish these feet, but seems kinda overkill and resource heavy for this use.\n I was about to dive into NocoDB next, but since I'm struggling, figured I'd chime in here to see if anyone had any recommendations.\n    submitted by    /u/rectal_rocket  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm5f01/databasespreadsheet_for_logging_and_rating_movies/",
          "publishedOn": "2022-12-14T23:16:22.000Z",
          "wordCount": 16430,
          "title": "Database/spreadsheet for logging and rating movies, games, etc",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm50up/host_crashes_when_vm_puts_load_on_hardware/",
          "author": null,
          "description": "submitted by    /u/caffeineshock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm50up/host_crashes_when_vm_puts_load_on_hardware/",
          "publishedOn": "2022-12-14T23:00:14.000Z",
          "wordCount": 17198,
          "title": "Host crashes when VM puts load on hardware",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm4lv0/backups_pre_and_postcommandaware_backup_solution/",
          "author": null,
          "description": "I am looking at Restic, BackupPC and Borg right now and trying to figure out if either of them support pre- and post-commands.\n The reason is that I would like to run a few exporters first, like so:\n ``` sysupgrade -b $outname.tar.gz # Also supports printing to STDOUT, but its always .tar.gz mysqldump ... # To dump all tables, users, ...\n ... others ...\n rsync serve $type wasabi-crypt:/backups ```\n After that, I might want to run cleanup commands.\n I will be running this on: - GNU/Linux, Debian 11 - linux, OpenWrt\n As for my windows maschines, it's quite straight forward: just a directory list and possibly LudoSavi... but thats a worry for another day. First, I need to get my cruicial infrastructure (router, servers) backed up.\n As for the backend: I am using Wasabi with an encryption setup - I want to use it as my off-site backup, purely. Hence rclone mount .... I did see Restic can do that on it's own (making me believe it might just consume the RClone API) but I am not sure if Borg can.\n In the end, I am also not sure if I want to use multiple repositories or not; probably depends on the program.\n Would love if you could give me some input on this! Thanks so much :)\n    submitted by    /u/IngwiePhoenix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm4lv0/backups_pre_and_postcommandaware_backup_solution/",
          "publishedOn": "2022-12-14T22:42:52.000Z",
          "wordCount": 17017,
          "title": "Backups: Pre- and Post-command-aware backup solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm3unm/plex_app_on_samsung_required_internet_connection/",
          "author": null,
          "description": "Yesterday , my internet connection was down and also cable tv, same company etc etc , and i have configure plex both in the app and in the server that you can look up for servers in the same network , but , when internet is down ... it can ... Why ? the samsung app is bad ?\n    submitted by    /u/HauteDense  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm3unm/plex_app_on_samsung_required_internet_connection/",
          "publishedOn": "2022-12-14T22:12:00.000Z",
          "wordCount": 16245,
          "title": "Plex app on samsung required internet connection , is there any way avoiding this ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm338f/im_really_struggling_to_install_vikunja/",
          "author": null,
          "description": "I would rather self -host on my own computer. So from my understanding i need two things\n  \nBack-end service (the one that has vikunja-unstable-windows-4.0-386.exe in the folder)\n Front-end service such as the desktop client\n  \nStandard ports are already taken by XAMPP and i haven't configured \"config.yml.sample\" BUT for the sake of testing I don't have xampp running.\n I tried running it out of the box but the last line of code is:\n 2022-12-14T16:38:02.8258504-05:00: INFO ▶ [EVENTS] 093 Starting handler, subscriber_name=namespace.created.namespace.counter.increase, topic=namespace.created \n Meanwhile it says at the first lines\n 2022/12/14 16:38:02 No config file found, using default or config from environment variables. 2022-12-14T16:38:02.8222434-05:00: INFO ▶ migration/Migrate 04e Ran all migrations successfully. \n I'm pretty sure to configure the yaml file i need to remove .sample but it should work out of the box without configuring it right? Mind you during this test i'm not running any server on localhost.\n I run the client and the prompt says\n An error occurred: TypeError: Failed to construct 'URL': Invalid URL Please check if the api url is correct. \n After inserting the default port in the address:\n Could not find or use Vikunja installation at \"localhost\". Please try a different url. \n What do i do now?\n    submitted by    /u/Eriane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm338f/im_really_struggling_to_install_vikunja/",
          "publishedOn": "2022-12-14T21:41:27.000Z",
          "wordCount": 16969,
          "title": "I'm really struggling to install vikunja",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm2gsn/ssl_cert_on_an_iis_intranet/",
          "author": null,
          "description": "Trying to follow the steps on this page and am stuck at the \"http://{certserver}/certsrv\" step. Not sure what I should be putting in the \"certserver\" spot. Any ideas? \n Preventing browser security warnings for an Intranet site using an SSL Certificate generated by a Windows Domain CA | Sid's FishNet (wordpress.com)\n    submitted by    /u/ITAccount17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm2gsn/ssl_cert_on_an_iis_intranet/",
          "publishedOn": "2022-12-14T21:16:41.000Z",
          "wordCount": 16652,
          "title": "SSL Cert On An IIS Intranet",
          "imageUrl": "https://external-preview.redd.it/BW0OA2q2KiuraOrkTX_bo_GiSIFzr4xx08xVrQpGEJ4.jpg?auto=webp&v=enabled&s=595bde87e50ee81e8ec9fa754f81be1d4df0f5cd"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm1tc7/introducing_tailnet_lock_use_tailscale_without/",
          "author": null,
          "description": "submitted by    /u/bik1230  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm1tc7/introducing_tailnet_lock_use_tailscale_without/",
          "publishedOn": "2022-12-14T20:49:37.000Z",
          "wordCount": 17209,
          "title": "Introducing tailnet lock: use Tailscale without trusting our infrastructure!",
          "imageUrl": "https://external-preview.redd.it/qkp17_YDpdrBD4w-Z5hK5jxhFlLk9CVMWFOl3-jwicc.jpg?auto=webp&v=enabled&s=9310f6d4228dec3a51e13138cdc76c09a3cd41b4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm1rty/network_file_share_with_sso/",
          "author": null,
          "description": "I currently have an instance of authentik on my server which I use for SSO with my other apps, I'm now looking to add a network file share but I'd like to use the same SSO. incant seem to find anything that fits this, initially I thought that samba would be configurable enough to point at authentik but Ive not been able to find any info on doing that.\n    submitted by    /u/samishal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm1rty/network_file_share_with_sso/",
          "publishedOn": "2022-12-14T20:47:52.000Z",
          "wordCount": 16804,
          "title": "Network File Share with SSO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlxwm9/do_you_use_one_dashboard_for_each_host_or_a/",
          "author": null,
          "description": "I love flame because is minimal and automatically creates the link based on labels defined on the docker-compose.yml...but at the moment I have 6 different server with 6 different Flame dashboards and is becoming a bit annoying.\n I could create a single one, but then I have to maintain up to date manually...\n View Poll\n    submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlxwm9/do_you_use_one_dashboard_for_each_host_or_a/",
          "publishedOn": "2022-12-14T18:07:39.000Z",
          "wordCount": 17055,
          "title": "Do you use one dashboard for each host? or a single dashboard for everything?",
          "imageUrl": "https://external-preview.redd.it/8vnUwnFRO5ECAUz8AJOLHiHh_Z3idaJVa4Z6trtPSpI.jpg?auto=webp&v=enabled&s=469edcce33c172712b2c0d46b2d1aa75ae67ef44"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlx3yo/what_are_the_benefits_and_drawbacks_of_self/",
          "author": null,
          "description": "Absolute noob and extremely clueless and I’m been thinking of trying to self host my own cloud server, maybe vpn or ad block and financial and privacy benefits I was curious curious what made you embark on this journey\n    submitted by    /u/cursedblueberries  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlx3yo/what_are_the_benefits_and_drawbacks_of_self/",
          "publishedOn": "2022-12-14T17:36:53.000Z",
          "wordCount": 20570,
          "title": "What are the benefits and drawbacks of self hosting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlx3lq/youtube_monitor/",
          "author": null,
          "description": "Hey guys, I'm looking for a self-hosted solution that can monitor multiple youtube channels and/or playlists for uploads and notifies the user/sends an API request to an existing youtube-dl server to download them.\n    submitted by    /u/neptune909  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlx3lq/youtube_monitor/",
          "publishedOn": "2022-12-14T17:36:28.000Z",
          "wordCount": 16307,
          "title": "YouTube monitor",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlsz3i/christmas_gift_ideas_for_someone_involved_in/",
          "author": null,
          "description": "I have a family member super into Self-hosting and has their own server in their house.\n Was just wondering if there was any good christmas present ideas which someone involved in self-hosting would want but wouldn't invest time/money into as I know its already a very budget-orientated passion!\n Thanks for any of your help!\n    submitted by    /u/TylerWebb_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlsz3i/christmas_gift_ideas_for_someone_involved_in/",
          "publishedOn": "2022-12-14T14:51:53.000Z",
          "wordCount": 18124,
          "title": "Christmas Gift Ideas for someone involved in SelfHosting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlsxns/run_your_own_selfhosted_transcription_and/",
          "author": null,
          "description": "I just wrote up some docs for my generate-subtitles project which is a wrapper around OpenAI's Whisper and includes Libretranslate for automatic translation.\n You can run your own server using the instructions here: https://github.com/mayeaux/generate-subtitles\n Or test it out on my instance which is open for free use online at https://freesubtitles.ai, cheers!\n    submitted by    /u/meddit_app  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlsxns/run_your_own_selfhosted_transcription_and/",
          "publishedOn": "2022-12-14T14:50:16.000Z",
          "wordCount": 18346,
          "title": "Run your own self-hosted transcription and automatic translation service powered by OpenAI's Whisper",
          "imageUrl": "https://external-preview.redd.it/uEEDj0fgmPN-zpcjSmtDa1lp9szymoxz2BjkTvNRRj4.jpg?auto=webp&v=enabled&s=aa3a77b5304408c9436175c02b096f0dfff4e757"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlr4ek/finally_setup_my_homepage_dashboard/",
          "author": null,
          "description": "submitted by    /u/The_Dogg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlr4ek/finally_setup_my_homepage_dashboard/",
          "publishedOn": "2022-12-14T13:36:25.000Z",
          "wordCount": 17839,
          "title": "Finally setup my Homepage dashboard",
          "imageUrl": "https://preview.redd.it/yg0eur9n9v5a1.png?auto=webp&v=enabled&s=e2ea5d26a9e7bc368385c31dff431f4bc1265137"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlp0ml/lets_talk_thermostats/",
          "author": null,
          "description": "Any thermostats for my house that have an API that I can use to pull data for things like current temperature, heat/AC on/off status? \n Im not really familiar with IoT devices or other small network connected things. I'd like to stay away from anything that requires a 3rd party \"cloud\" service as a requirement to use.\n    submitted by    /u/krakah293  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlp0ml/lets_talk_thermostats/",
          "publishedOn": "2022-12-14T11:54:23.000Z",
          "wordCount": 16320,
          "title": "Let's talk thermostats.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlo463/ultimate_docker_to_podman_migration_guide/",
          "author": null,
          "description": "Hello Selfhosters! \n Many of you have probably followed or are familiar with my Docker Media Server guide. Recently, we published a comparison of Docker vs Podman and since then we received a few requests for a guide to move from Docker to Podman.\n So here is our detailed guide on moving from Docker to Podman - written by u/krair3\n Feel free to check it out and share your thoughts.\n    submitted by    /u/htpcbeginner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlo463/ultimate_docker_to_podman_migration_guide/",
          "publishedOn": "2022-12-14T11:02:18.000Z",
          "wordCount": 23858,
          "title": "Ultimate Docker to Podman Migration Guide",
          "imageUrl": "https://external-preview.redd.it/nCgjb1sB1GmkbG4Q2Ki9PPFFXZd9vxA7C-m3q3woNNU.jpg?auto=webp&v=enabled&s=10255c6392be995e812815e39ee4d1747a4b037d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlmpej/framasoft_which_develops_peertube_and_promote/",
          "author": null,
          "description": "submitted by    /u/raybb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlmpej/framasoft_which_develops_peertube_and_promote/",
          "publishedOn": "2022-12-14T09:35:30.000Z",
          "wordCount": 17456,
          "title": "Framasoft, which develops PeerTube and promote FLOSS from France are hosting an AMA!",
          "imageUrl": "https://external-preview.redd.it/75rSLWh_2hGrROPlm7aU7Gr0PJ7ZFSmtpOlTC1FahGY.jpg?auto=webp&v=enabled&s=55dec15d22a3af99deed3c0c17972c643db1439a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlg3q2/wanjohiryanqwantify_play_games_with_your_friends/",
          "author": null,
          "description": "submitted by    /u/Evil__Maid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlg3q2/wanjohiryanqwantify_play_games_with_your_friends/",
          "publishedOn": "2022-12-14T03:25:21.000Z",
          "wordCount": 22002,
          "title": "wanjohiryan/qwantify: Play games, with your friends right from the browser. No installation needed.",
          "imageUrl": "https://external-preview.redd.it/rRmz2x7-K-PzxgamlDhhdDtQsdsmarjkHTbYbwNQ638.jpg?auto=webp&v=enabled&s=ed60e324fd58ccd6c1829ef215412a9a5edcf1e8"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlcrad/fix_status_indicators_for_non_arr_apps_added_to/",
          "author": null,
          "description": "Is there any way to fix the \"status\" indicator for non -arr apps added to Homarr?\n I don't use -arr services right now, but I like Homarr as my dashboard. Unfortunately, the little \"online\" indicators all show as offline, except for Dash. (dashdot). I know the services are online, but not sure how to fix this.\n I can remove these indicators by toggling the option within the advanced options tab, but it'd be nice to have a quick visual status indicator.\n Any ideas?\n First picture shows NPM as offline, but pings show otherwise.\n    submitted by    /u/radakul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlcrad/fix_status_indicators_for_non_arr_apps_added_to/",
          "publishedOn": "2022-12-14T00:57:29.000Z",
          "wordCount": 16801,
          "title": "Fix status indicators for non -arr apps added to Homarr?",
          "imageUrl": "https://external-preview.redd.it/C5Ze1dn7H9hTdcc9w4Vc2213_-SUopVV94ATuZ94P-g.jpg?auto=webp&s=3555f1d2b9577d7056d8d942a1cd5e951824b610"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlbk74/nginx_proxy_manager_lan_requests_cant_reach_proxy/",
          "author": null,
          "description": "I have an Unraid server connected to a router that is using a DynDNS service to forward traffic from my subdomain (seafile.example.com). I am using NPM to catch network traffic arriving through this DNS. I also have a PiHole as a local DNS and DHCP server. \n I can reach the proxy host when I access the subdomain from outside my local network (i.e. using my phone's cellular data) but I am unable to reach the host locally. I am able to reach the proxy host through the IP address+port directly on LAN. \n Any help is greatly appreciated, thanks!\n    submitted by    /u/Gordogato81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlbk74/nginx_proxy_manager_lan_requests_cant_reach_proxy/",
          "publishedOn": "2022-12-14T00:06:21.000Z",
          "wordCount": 16839,
          "title": "Nginx Proxy Manager: LAN requests can't reach proxy host via domain requests, but WAN requests can",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlau5x/monica_alternative_with_photo_gallery/",
          "author": null,
          "description": "Been searching for this for a while and just couldn't find anything like it. Checked monica but couldn't find that feature on it anywhere. \n I'm looking for something basically like monica, but where you can create a photo gallery for each contact. Or something like a social network but without other accounts where I can save notes and photos. \n Does anyone have any kind of recommendation? Maybe even some software that isn't designed for it, but can work easily in that way? Also don't need the notifications part, if that helps\n    submitted by    /u/ctaeth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlau5x/monica_alternative_with_photo_gallery/",
          "publishedOn": "2022-12-13T23:36:18.000Z",
          "wordCount": 16779,
          "title": "Monica alternative with photo gallery?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zla0vh/how_do_you_give_an_ip_with_a_port_its_own_local/",
          "author": null,
          "description": "I am just getting into self hosting and I've started witha pihole and docker compose on my windows PC.\n I've installed Nginx, pihole and tailscale on my Pi zero W. (Nginx and tailscale dont work well but thats another issue).\n I've installed photoprism, komga, plex, tautulli and portainer on my desktop with docker compose.\n To access all my desktop docker applications its 192.168.X.X:port. Is there a way that I can give all these applications a local domain such that photoprism is photoprism.local?\n    submitted by    /u/_BluePineapple  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zla0vh/how_do_you_give_an_ip_with_a_port_its_own_local/",
          "publishedOn": "2022-12-13T23:04:19.000Z",
          "wordCount": 16813,
          "title": "How do you give an Ip with a port its own local domain?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl9y0o/soi_came_home_and_wanted_to_take_a_snapshot_of_my/",
          "author": null,
          "description": "After taking the snapshots, I try to SSH into them and nothing. So I go back, log in via the ESXI webpage and see that all my Linux VMs are now booting in emergency mode. No errors on ESXI and Linux says emergency mode. Has anyone experienced this?\n    submitted by    /u/limskey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl9y0o/soi_came_home_and_wanted_to_take_a_snapshot_of_my/",
          "publishedOn": "2022-12-13T23:01:12.000Z",
          "wordCount": 1879,
          "title": "So…I came home and wanted to take a snapshot of my ESXI VMs…but….",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl6nc2/problems_configuring_changedetectionio/",
          "author": null,
          "description": "Hi there,\n I have setup changedetection.io in a Docker and set up some test scenarios. \n I can't figure out how i can trigger from a class change. The Website I am trying to monitor has an <li class=\" signup inactive\">Signup</li> and changes it to something like <li class=\"signup active\"><a href=\"\">Signup</a></li>. how do I detect this change? I tried this with a test website but I can't get it to work since the Text dosn't change on the page. Can anyone help?\n    submitted by    /u/sasleu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl6nc2/problems_configuring_changedetectionio/",
          "publishedOn": "2022-12-13T20:54:32.000Z",
          "wordCount": 17141,
          "title": "Problems Configuring changedetection.io",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl5fub/struggling_to_get_monica_crm_working_with_ssl/",
          "author": null,
          "description": "The subject says it all, but I wanted to clarify that this is for my internal LAN with a URL of something like https://monica.int.foo.com:8080/. (This is a FQDN.) I have seen the docs and followed the various tips including adjusting APP_URL, APP_ENV and APP_FORCE_URL. Whenever I switch APP_URL to https, the site becomes inaccessible with an SSL error.\n Here are the configs: https://pastebin.com/Qccwu1LN\n As an aside, I poked around the Apache configs in the Docker container and was curious to see that there is no SSL conf in sites-enabled. There is a config in sites-available, but I think that the path to the SSL certs is wrong. Could this be causing the issue?\n It feels like, \"it just works\" for most people here, but for whatever reason, I have had nothing but problems configuring SSL. (HTTP works fine.)\n TIA\n    submitted by    /u/JL_678  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl5fub/struggling_to_get_monica_crm_working_with_ssl/",
          "publishedOn": "2022-12-13T20:07:00.000Z",
          "wordCount": 18058,
          "title": "Struggling to get Monica CRM working with SSL",
          "imageUrl": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&v=enabled&s=decc328886393c0699bb01cf9d08b602f60525c8"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl58kb/github_tailscalegolink_a_private_shortlink/",
          "author": null,
          "description": "submitted by    /u/redsashimi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl58kb/github_tailscalegolink_a_private_shortlink/",
          "publishedOn": "2022-12-13T19:59:26.000Z",
          "wordCount": 16104,
          "title": "GitHub - tailscale/golink: A private shortlink service for tailnets",
          "imageUrl": "https://external-preview.redd.it/hL3TOhfduw5xaU11iMDUla5EdWb4ZpJtP24Hp7RZsXE.jpg?auto=webp&v=enabled&s=f13aa73426ac9c44af1781041c04f0638f856c7d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl3weu/short_guide_on_custom_css_for_flame/",
          "author": null,
          "description": "Hi everyone\n I found recently the Flame dashboard and really liked the look. I had no experience in customizing such things, but found out how to do it myself and am happy to share. Hopefully it will be helpful for someone out there! :)\n I know it's not a big deal, however, I am still happy about this achievement.\n Dashboard repository: https://github.com/fdarveau/flame \n My Guide: https://github.com/DevGoran/Flame-Custom-CSS-Guide\n Any recommendation or feedback is welcome.\n    submitted by    /u/gripfly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl3weu/short_guide_on_custom_css_for_flame/",
          "publishedOn": "2022-12-13T19:05:32.000Z",
          "wordCount": 19482,
          "title": "Short guide on custom CSS for Flame",
          "imageUrl": "https://external-preview.redd.it/8EtLkLQ8No6VnMsA71YuLE7Z6kckgPVGF3FWS3p0y2s.jpg?auto=webp&s=1e8ef4d79bdd15914127d5ec901d2458eaa42a04"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl1svo/piwigo_and_syncthing/",
          "author": null,
          "description": "I want to use piwigo as my full time Google photos alternative and everytime I connect to my network I want my pictures to he backed up to my home server and I have syncthing setup for that, now I'm running both on docker and both point to a common directory ( /gallery in piwigo), how can I import those photos into my piwigo instance to view them?\n I tried going to the dashboard and doing Quick Sync, but it uses ./galleries/ which I can't find on my piwigo instance using the shell and when I try to add /gallery as a site it says the directory doesn't exist.\n If there's any other better way to sync my gallery with piwigo I would love to hear it, I'm using Android.\n I did try to use photoprism and lychee too but they didn't play well with syncthing and I didn't find any free ways to sync my gallery with either of them\n ​\n This is my docker compose for both syncthing and piwigo\n Edit: I checked with the entire file system and just had to route the shared folder of syncthing and piwigo to /gallery/galleries in the piwigo instance\n    submitted by    /u/XenoDan_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl1svo/piwigo_and_syncthing/",
          "publishedOn": "2022-12-13T17:44:50.000Z",
          "wordCount": 17039,
          "title": "Piwigo and syncthing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl0xjv/vpn_issue_with_yunohost_that_has_been_bugging_me/",
          "author": null,
          "description": "I wanted to use the VPN client with my self hosted Yunohost but keep running into issues. I tried 4 different VPN's and as of this morning purchased a new dedicated IP with a new services.\n ​\n https://yunohost.org/en/providers/vpn\n ​\n https://github.com/YunoHost-Apps/vpnclient_ynh\n ​\n Now the issue is this, after uploading the config file ( ovpn ) through webadmin, it gives this message:\n ​\n WARNING - Job for openvpn@client.service failed because a timeout was exceeded. \n WARNING - See \"systemctl status openvpn@client.service\" and \"journalctl -xe\" for details. WARNING - tail: cannot open '/var/log/openvpn-client.log' for reading: No such file or directory \n ​\n When I SSH in and run \"systemctl status openvpn@client.service\", I get this message\"\n ​\n  DEPRECATED OPTION: --cipher set to 'AES-128-CBC' but missing in --data-ciphers (AES-256-GCM:AES-128-GCM). Future OpenVPN version will ignore --cipher for cipher negotiations. Add 'AES-128-CBC' to --data-ciphers or change --cipher 'AES-128-CBC' to --data-ciphers-fallback 'AES-128-CBC' to silence this warning. \n How do I add to Data Cipher as mentioned?\n    submitted by    /u/xkingxkaosx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl0xjv/vpn_issue_with_yunohost_that_has_been_bugging_me/",
          "publishedOn": "2022-12-13T17:11:20.000Z",
          "wordCount": 1976,
          "title": "VPN issue with Yunohost that has been bugging me!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkyp9z/forms_builder_with_prefill_from_url_function/",
          "author": null,
          "description": "Hello, Reddit! (Sorry for my english)\n I'm looking for a simple self-hosted Forms Builder with a really important feature. It should have an option to prefill some fields using attributes from URL\n I have an example - https://github.com/ohmyform/ohmyform\n So if i'll use link http://myip:5200/form/gdR6dx?field1=text1 I'll get prefilled field \"field1\" with \"text1\"\n I guess you've got the idea. But this APP is buggy and is not really supported how I can see. So I'm looking for another one with same feature\n Also https://forms.yandex.com/ provide the same feature, but it's not a self-hosted app\n https://cloud.yandex.com/en-ru/docs/forms/pre-fill\n I checked a few posts with same topic but didn't find exactly what I'm looking for\n Apps which I already tried:\n https://github.com/ohmyform/ohmyform\n https://github.com/Budibase\n https://github.com/formio/formio\n Thanks for your help!\n    submitted by    /u/LittleShok  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkyp9z/forms_builder_with_prefill_from_url_function/",
          "publishedOn": "2022-12-13T15:40:56.000Z",
          "wordCount": 18177,
          "title": "Forms Builder with \"prefill from url\" function",
          "imageUrl": "https://external-preview.redd.it/DV1lEUgPol4XLquQ4y1_kt1Tzf1-jyLnghC9aPJwgzY.jpg?auto=webp&s=53044a6a37c4f675b656fdf4204268b31fe05765"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkxyl0/i_need_ideas_for_my_new_project/",
          "author": null,
          "description": "Hey there,\n I'm working on a open source self-hosted dashboard that has the following core functionalities: hardware monitoring and file storage/management. My goal is to make it as minimalistic and user friendly as possible. The current name I have in mind is X-Panel. I'm looking for suggestions for a good name and some more features for this web app. I want a name that is easy to remember and accurately reflects the functionality of the web app. Any suggestions or ideas for improving the current name or coming up with a new one would be greatly appreciated! I have also added some screenshots of the web interface.\n Thanks in advance for any help.\n ​\n https://preview.redd.it/8qjjknboko5a1.png?width=1920&format=png&auto=webp&s=bf1d67a50c411278f831357547784e748954dc2e\n https://preview.redd.it/4zouvqboko5a1.png?width=1920&format=png&auto=webp&s=6806e47c84e9db8b145a84ccef5eb33051c155d6\n https://preview.redd.it/b4ax8mboko5a1.png?width=1920&format=png&auto=webp&s=90fbbea103e46a897bc700a5f41e4d4f23ebdc11\n    submitted by    /u/Different_Carpet_479  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkxyl0/i_need_ideas_for_my_new_project/",
          "publishedOn": "2022-12-13T15:06:52.000Z",
          "wordCount": 17866,
          "title": "I need ideas for my new project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkxseh/anything_like_sendsafely_thats_free_and_can_be/",
          "author": null,
          "description": "submitted by    /u/ChrisOSSTMM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkxseh/anything_like_sendsafely_thats_free_and_can_be/",
          "publishedOn": "2022-12-13T14:59:29.000Z",
          "wordCount": 16421,
          "title": "Anything like sendsafely that’s free and can be self hosted? Thx",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkwgfe/most_secure_and_easy_way_to_store_photos/",
          "author": null,
          "description": "Hey everyone. I am trying to find a solution to store all the family photos on a VPS. I'd like to have end-to-end and server side encryption. Seafile seems ideal, but heard some critique regarding the way files are stored and issues that could happen if something happens to the database. \n We all use Apple devices, so syncthing is not so good either as their iOS app is really awful. \n Nextcloud feels very sluggish and OwnCloud Infinite Scale is very young with not lots of documentation (not even sure it has server side encryption).\n Any recommendations on that matter? Thanks!\n    submitted by    /u/WEZANGO  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkwgfe/most_secure_and_easy_way_to_store_photos/",
          "publishedOn": "2022-12-13T14:00:55.000Z",
          "wordCount": 17901,
          "title": "Most secure and easy way to store photos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkw21v/koreui_a_keycloak_login_theme/",
          "author": null,
          "description": "Hi all,\n I’m happy to present a new Keycloak login theme based od CoreUI.\n I started to develop this theme for myself, but I hope it will be useful to others too.\n You can find and download the theme on my github page.\n    submitted by    /u/nkelemen18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkw21v/koreui_a_keycloak_login_theme/",
          "publishedOn": "2022-12-13T13:42:53.000Z",
          "wordCount": 16436,
          "title": "Koreui a Keycloak login theme",
          "imageUrl": "https://external-preview.redd.it/wlbJlmWqA0iEvceUeSXLb3pWVUNXNQKQ7JYS47zJVb0.jpg?auto=webp&s=a43f1f478440ba781e6c5b91f857c5652097cbac"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkumqk/status_pages_with_manual_on_an_off_button/",
          "author": null,
          "description": "Hallo and greetings from Red Cross Germany.\n We are building an Intranet and I am looking for something like https://www.apple.com/support/systemstatus/ \n BUT something where I have the option to manually click or select what service is offline or online.\n uptime-kuma is cool but it lacks the manual Intervention. \n any help would be great :)\n    submitted by    /u/Exciting_Habit_129  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkumqk/status_pages_with_manual_on_an_off_button/",
          "publishedOn": "2022-12-13T12:33:39.000Z",
          "wordCount": 18203,
          "title": "status pages with manual on an off button?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zksbyf/learn_all_about_peertube_v5/",
          "author": null,
          "description": "submitted by    /u/Framasoft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zksbyf/learn_all_about_peertube_v5/",
          "publishedOn": "2022-12-13T10:17:52.000Z",
          "wordCount": 17140,
          "title": "Learn all about PeerTube v5!",
          "imageUrl": "https://external-preview.redd.it/EH2OKJVz-ec_6l8OGFc9jO9OcTwPnQvUrAxYp1ugvD0.jpg?auto=webp&s=5d2658d6c8cedba6a017047cef317cef91ee9606"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zks8xn/looking_for_seaweedfs_experiences/",
          "author": null,
          "description": "TLDR;\n I'm torn between wanting to use SeaweedFS and worrying about data availability/recoverability. Hence I am looking for some (long-term) experiences from people who have tried or are using SeaweedFS.\n Full story;\n I have been following SeaweedFS for quite some time and I loved it initially, however, as time progresses and I learned more about it I got a bit worried about its recoverability.\n I tested it locally and had some issues with it, but those were mainly due to my own lack of knowledge with regards to SeaweedFS and Linux. My failures are what made me initially doubt the recoverability potential of the software since I did have data-loss during my tests. Luckily it was only test-data.\n When you initially start reading about SeaweedFS it sounds really easy to set up and get started with, and it is, but there are so many things to be aware of when using it \"in production\" that are not always clear in the beginning. For example: The Filer *IS* a single point of failure if you don't back it up (even though the GitHub page states that there is no single point of failure). Or that it's best to use config files instead of cli parameters when running in production.\n On the other hand, if you know you need to keep these things in mind, then it doesn't really form an issue.\n I'm really torn between wanting to use SeaweedFS and worrying about data availability and recoverability, and I'm looking for some experiences from people that have tried it are using SeaweedFS, especially long-term use.\n    submitted by    /u/Stitch10925  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zks8xn/looking_for_seaweedfs_experiences/",
          "publishedOn": "2022-12-13T10:12:03.000Z",
          "wordCount": 17311,
          "title": "Looking for SeaweedFS experiences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zks324/simple_useful_apps_that_you_selfhost/",
          "author": null,
          "description": "Anything that you self-hosted recently that provoked a thought like \"hell, so simple, yet so useful. why haven't I found it before...\"? \n Lemme list a couple of things I \"discovered\" by myself:\n - miniflux - the best self-hosted rss ever. fast (due to spartan UI), yet extensible via customized CSS and tons of extensions. Integrates nicely with Mac's Reeder and Reeder app on iOS (which is an essence of brilliant UX/UI for me).\n - kanboard - extremely simple kanban board, still so powerful and elegant. An essence of extreme usefulness combined with almost no UI.\n - flame - a simple dashboard. Hell, I wish I found it before - it would save me a lot of time setting up my family's bookmarks. Being able to see different set of bookmarks depending on whether you're \"signed-in\" or not was the game changer for me.\n - metube - best tool to fetch YouTube music to feed your AzuraCast home radio\n    submitted by    /u/haksior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zks324/simple_useful_apps_that_you_selfhost/",
          "publishedOn": "2022-12-13T10:01:13.000Z",
          "wordCount": 20076,
          "title": "Simple, useful apps that you self-host?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkqtap/doomsday_drive/",
          "author": null,
          "description": "Long story short I have been trying to put together documentation together or more so a large list of items related to my self hosting setup, important personal information(not particular to self hosting) and resources for the items. This was originally brought up by my brother since my family more or less relies on alot of my self hosted items and would not know what to do if I \"got hit by a bus\". I'm calling this my doomsday drive, as I'm hoping to store this in a safe at my parents home and potentially safe within my home.\n ​\n I'm curious if anyone has any templates out there or has any ideas for this. My documentation has by no means been good and I'm trying to get better and by adding items into my notion.so account (not self hosted, may get smite'd for this).\n ​\n Edit:\n Taking all the feedback I received this is the plan I'm going with:\n  \nMoving from LastPass over to Bitwarden (this has been on my mind for awhile but this gave me the momentum to go through with it).\n Using https://github.com/potatoqualitee/eol-dr provided from u/felipefideli as a template for accounts and just general personal info that will be stored within Bitwarden.\n Continuing documentation and building a static website for the documentation with instructions of how to spin up the container as well as a copy of it so it can be ran on a rasp pi which will be stored in my parents safe. Will also be writing these in text(markdown) files as well, will be encrypted as well.\n Recovery codes are going to be stored within bitwarden as well as physical copies stored at my bank and at my parents safe, this is only in case something were to happen to my phone as my fiancé knows how to access it. \n Currently in the process of learning Ansible and setting up AWX so if something fails in the short term (like NVR) I will have templates to easily fix it.\n Continuing teaching my brother my environment.\n  \n   submitted by    /u/JANGxBANGER  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkqtap/doomsday_drive/",
          "publishedOn": "2022-12-13T08:36:28.000Z",
          "wordCount": 19335,
          "title": "Doomsday drive",
          "imageUrl": "https://external-preview.redd.it/gk5c58dd5_1T5gdwVU4V-F44A0FTpgI4H5Kbn_1Y3-I.jpg?auto=webp&v=enabled&s=6aef2c01d9930fb8983bb6e568da0e8250faf6be"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkpeok/les_pas_270/",
          "author": null,
          "description": "submitted by    /u/lespasapp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkpeok/les_pas_270/",
          "publishedOn": "2022-12-13T07:10:15.000Z",
          "wordCount": 16611,
          "title": "Les Pas 2.7.0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkl5ee/is_it_safe_to_leave_vaultwarden_login_page_public/",
          "author": null,
          "description": "I am self-hosting through Vaultwarden. I'm using Cloudlfare and nginx reverse proxy because, as you know, it requires an SSL certificate and an HTTPS connection. I've acquired a domain name to do it. However, is it safe to leave it like that? Is there a way to close the publicly accessible page and just use Wireguard so that only I can connect?\n    submitted by    /u/greenlightison  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkl5ee/is_it_safe_to_leave_vaultwarden_login_page_public/",
          "publishedOn": "2022-12-13T03:35:44.000Z",
          "wordCount": 19518,
          "title": "Is it safe to leave Vaultwarden login page public?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkevcs/for_those_with_colo_servers_how_do_you_access/",
          "author": null,
          "description": "I'm thinking of getting a 1U server and putting it in colo. Since it would be driving distance, I can set it up and bring it in but in case I need to reboot or update hypervisor I would need to access IPMI.\n I know there is a firewall feature on some Supermicro servers but tech support answer was it doesn't work because no one is using it.\n Having it exposed to net is a no go. But if I go with some VPN device I will need to pay for another U.\n    submitted by    /u/Otaehryn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkevcs/for_those_with_colo_servers_how_do_you_access/",
          "publishedOn": "2022-12-12T23:07:45.000Z",
          "wordCount": 17338,
          "title": "For those with colo servers, how do you access IPMI/ILO/IDRAC/IMM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zke683/is_seafile_any_good_compared_to_nextcloud_just/",
          "author": null,
          "description": "Thanks\n    submitted by    /u/Kraizelburg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zke683/is_seafile_any_good_compared_to_nextcloud_just/",
          "publishedOn": "2022-12-12T22:41:32.000Z",
          "wordCount": 15434,
          "title": "Is seafile any good compared to nextcloud just for file storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkdr80/running_containerized_x_server/",
          "author": null,
          "description": "Hi everyone. I have a home server where I run all of these lovely services we like to use in this community. This server happens to be pretty near my TV. And even though I do access some of these over the network I always thought that it would be nice to have some graphic interface on the server and access it just by plugin a HDMI to the TV. I'm with a shameless Ubuntu server 20.04 without X nor any windows server and all of the services with Podman.\n I'd like to keep my host clean, so the idea would be to run either a full os with vagrant or something similar or just run a container with the X server installed and some devices mounted. I don't necessarily want to run a whole wm nor anything similar, I guess I will mostly use it to run regular desktop apps or even just a browser.\n Does it makes sense ? Is any of you doing anything similar ?\n    submitted by    /u/contre95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkdr80/running_containerized_x_server/",
          "publishedOn": "2022-12-12T22:26:59.000Z",
          "wordCount": 16572,
          "title": "Running containerized X server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkcd46/minimalistic_watchlist_appsite_something_like/",
          "author": null,
          "description": "Hey, I'm currently writing an auto-stream downloader for my grandparents.\n I need to fast/easy select Movies, episode/s, season/s, and complete series with something like an API or email notification\n Thx\n (sorry for my English)\n Edit: Overseerr dont have single episode feature\n    submitted by    /u/Ok-Dingo-9988  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkcd46/minimalistic_watchlist_appsite_something_like/",
          "publishedOn": "2022-12-12T21:38:21.000Z",
          "wordCount": 16311,
          "title": "minimalistic Watchlist App/Site something like justwatch.com with API",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkc46g/website_status/",
          "author": null,
          "description": "Hello, im looking for a cms Who check if website is online. \n But i want to limit only for my client and they easy check without login or Signup.\n    submitted by    /u/Elemis89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkc46g/website_status/",
          "publishedOn": "2022-12-12T21:29:18.000Z",
          "wordCount": 18943,
          "title": "Website status",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zka1j8/should_i_create_multiple_vms_with_dockerengine_or/",
          "author": null,
          "description": "Basically if I have only 1 server with Proxmox VE, is there any advantage to spin up for example 3 VMs and install Docker-Engine on each, acting like a cluster? \n Or should I just keep 1 VM and run all my containers on the one VM?\n    submitted by    /u/Julwazza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zka1j8/should_i_create_multiple_vms_with_dockerengine_or/",
          "publishedOn": "2022-12-12T20:14:58.000Z",
          "wordCount": 15439,
          "title": "Should I create multiple VMs with Docker-Engine or a single one for all my containers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk9sun/using_google_compute_instance_with_tailscale_and/",
          "author": null,
          "description": "I work in a small company and there are about 8 of us that remote in to our respective workstations from time to time. Currently, we use RealVNC but I have been thinking about replacing that with Tailscale and Apache Guacamole. I like the idea of a clientless solution for remote access.\n In terms of the Guacamole server, I was wondering if it would work to use a small Google Compute instance, install tailscale and the guacamole server on that, and then install tailscale on the various workstations and connect them all up. The users would login to the Guacamole server running on the google compute platform and then from there access their machines. \n If this works, then since this instance of Guacamole would be public facing, I would enable the 2FA plugin. Any other security recommendations? Reverse proxy?\n Any thoughts, suggestions, concerns are welcome. Thanks in advance.\n    submitted by    /u/No_Excuse_889  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk9sun/using_google_compute_instance_with_tailscale_and/",
          "publishedOn": "2022-12-12T20:05:53.000Z",
          "wordCount": 15705,
          "title": "Using google compute instance with tailscale and apache guacamole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk8lfu/spare_pi4_uses/",
          "author": null,
          "description": "Hi all, since repurposing an old mini pc to proxmox and migrating VMs and services there my dear Pi4 is collecting dust… At first it was running PiHole and OMV but now…. I have no idea what do do with it :/ Suggestions?\n    submitted by    /u/VengefulMustard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk8lfu/spare_pi4_uses/",
          "publishedOn": "2022-12-12T19:22:31.000Z",
          "wordCount": 15957,
          "title": "Spare Pi4 uses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk7sre/question_is_there_selfhosted_email_server_with/",
          "author": null,
          "description": "submitted by    /u/sheerun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk7sre/question_is_there_selfhosted_email_server_with/",
          "publishedOn": "2022-12-12T18:54:05.000Z",
          "wordCount": 18519,
          "title": "Question: Is there selfhosted email server with spam filtering by offline AI model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk7cs0/domain_name_registrar/",
          "author": null,
          "description": "I need a domain name registrar that allows PTR records. My current one dynadot don't support it. Does anyone have any recommendations for one?\n    submitted by    /u/LeastZombie3436  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk7cs0/domain_name_registrar/",
          "publishedOn": "2022-12-12T18:39:17.000Z",
          "wordCount": 16959,
          "title": "Domain name registrar",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk6swi/help_port_forwarding_with_gluetun_and_selfhosted/",
          "author": null,
          "description": "Hi all.\n I'm setting up an Ubuntu homeserver w/ a lot of docker containers organized in stacks.\n One of my stacks is an entertainment stack w/ qbittorrent, jackett and amule as the downloading part of the stack.\n For security reasons this stack connect to the outside via a vpn.\n The vpn is a wireguard vpn created w/ pivpn in an oracle cloud instance (ubuntu server).\n This is a semplified schema: \n  torrent vpn schema \n This is my docker compose:\n version: '3.5' services: gluetun: image: qmcgaw/gluetun container_name: vpn cap_add: - NET_ADMIN volumes: - /srv/docker/wireguard/casalt.conf:/gluetun/config.conf:ro ports: - 9117:9117 # jackett - 8090:8090 # qbittorrent - 6881:6881 # qbittorrent - 6881:6881/udp # qbittorrent - 4711:4711 # amule - 4783:4783/tcp # amule - 4786:4786/udp # amule - 47…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk6swi/help_port_forwarding_with_gluetun_and_selfhosted/",
          "publishedOn": "2022-12-12T18:19:29.000Z",
          "wordCount": 17142,
          "title": "[HELP] port forwarding with gluetun and selfhosted VPN",
          "imageUrl": "https://external-preview.redd.it/H3exIxBA37Hc0kfKKAFNA6FQslO0lQ7I8MJc_ShILxw.jpg?auto=webp&s=90aa0aed7fa1e57df342af7ab57f0f97a67303a8"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk6k3w/gtd_methodology_tools/",
          "author": null,
          "description": "Someone else using gtd methodology of David Allen for personal and work related \"stuff\"?\n If yes: What (self-hosted) tools do you use?\n I'm currently only using my dsNotes app on my synology. Works for me but probably not the most beautiful solution compared to these dashboards you can set up in notion for example.\n    submitted by    /u/yannbros  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk6k3w/gtd_methodology_tools/",
          "publishedOn": "2022-12-12T18:10:04.000Z",
          "wordCount": 15885,
          "title": "GTD methodology tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk5fhj/ticketing_system/",
          "author": null,
          "description": "does anyone know of a self-hosted ticketing system to track customer service/helpdesk tasks for a company?\n    submitted by    /u/uncmnsense  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk5fhj/ticketing_system/",
          "publishedOn": "2022-12-12T17:30:15.000Z",
          "wordCount": 15417,
          "title": "ticketing system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk3n4t/storing_homelab_passwords_and_information/",
          "author": null,
          "description": "I was wondering where most people store all of those little bits of information, and VM passwords, IP addresses, service port numbers etc. for their Homelabs? \n I've been putting mine in my password manager, but it looks ugly in there.\n    submitted by    /u/80Ships  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk3n4t/storing_homelab_passwords_and_information/",
          "publishedOn": "2022-12-12T16:24:38.000Z",
          "wordCount": 18278,
          "title": "Storing Homelab Passwords and Information?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk303p/self_host_rss_reader_why/",
          "author": null,
          "description": "I'm currently using feedme on Android to follow and download a couple of feeds. It 'just' uses Feedly (free). \n As I have a server running, I was wondering what advantage freshrss or others could have, but it was surprisingly hard to find comparisons. Maybe completely overlooked? Is there some features that I'm not seeing yet?\n I could think of privacy and unlimited number of feeds / articles. What else?\n    submitted by    /u/wokkieman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk303p/self_host_rss_reader_why/",
          "publishedOn": "2022-12-12T16:01:24.000Z",
          "wordCount": 17223,
          "title": "self host rss reader. why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk197w/pihole_and_pivpn_you_have_to_try_them_together/",
          "author": null,
          "description": "I know I'm late to the game, but I just tried this couple of tools and I really love them. \n PiHole is super convenient to:\n - prevent _some_ advertisement on websites\n - it can also offer an interface in front of DNSMasq\n - and can also work as DHCP server.\n If you use the DHCP feature, you can associate each DNS request to an hostiname, in case you're curious to know which website you're wife is browsing ;) \n I wanted to use the raspberry as VPN server and I tried WireguardEasy, it's a nice project but could not make PiHole to answer to the DNS requests coming from Wireguard running as docker. \n Then I tried PiVpn, the installation took just few seconds and automatically recognize I had PiHole installed, configuring it to listed on the VPN interface. \n Overall took me a few hours to find the right tool, but if you read this post you can just install PiHole and PiVPN in just a minute.\n    submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk197w/pihole_and_pivpn_you_have_to_try_them_together/",
          "publishedOn": "2022-12-12T14:55:26.000Z",
          "wordCount": 16675,
          "title": "PiHole and PiVPN, you have to try them together!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjzf0r/media_processing_workflow_orchestration_framework/",
          "author": null,
          "description": "submitted by    /u/Bikiew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjzf0r/media_processing_workflow_orchestration_framework/",
          "publishedOn": "2022-12-12T13:40:50.000Z",
          "wordCount": 16489,
          "title": "media processing workflow orchestration framework",
          "imageUrl": "https://external-preview.redd.it/kr2XTWvOFvayEPHx5YAbXkeFPcxWOmjLyYUhEVnDtTM.jpg?auto=webp&s=ae485bb38e6aba2d8382d80ab8f96882966d1849"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjy129/free_selfhosted_file_and_project_management/",
          "author": null,
          "description": "​\n Cospace\n Hey. We are launching a FREE self-hosted collaboration tool. It's a simple alternative to slack, Monday, dropbox, and asana. You can plan your daily to-dos, assign tasks, manage projects, store large files, create your own documents, etc.\n We made sure installation is as easy as it can be with single-line installation - https://cospace.mytwigex.com/en/Installation\n You can find us here- https://www.reddit.com/r/cospace/\n ​\n    submitted by    /u/rutinja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjy129/free_selfhosted_file_and_project_management/",
          "publishedOn": "2022-12-12T12:44:04.000Z",
          "wordCount": 17799,
          "title": "Free self-hosted file and project management.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjw2mk/domain_problem_httpswww/",
          "author": null,
          "description": "Hey! I got a new domain name from \"porkbun\" and attached the Server IP with it. I also got an SSL Cert (https) set up. Now when i connect to the site in my browser using\n www.name.com, or https://name.com, or just name.com\n i get \"https://www.name.com\"\n How do i get rid of that additional \"www.\"?\n Edit: its just a simple apache2 server, no reverse proxy. Edit 2 : on the porkbun dns site, when you add a record, it asks you to put something in the \"host\" field. I typed www in there, because i have seen this working on other sites. Now i left the field empty and it worked.\n    submitted by    /u/5calV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjw2mk/domain_problem_httpswww/",
          "publishedOn": "2022-12-12T11:16:11.000Z",
          "wordCount": 18401,
          "title": "Domain Problem? https://www.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjvxld/witch_music_server_handles_mp3tags_the_best/",
          "author": null,
          "description": "Hello all. I spent my last weekend completely on tagging my music collection on my NAS. Scanning folder by folder with the Mp3tag software and giving it the correct album information one by one.\n Today I was adding the complete library in Plex... The outcome was not as expected... I have far more albums in Plex than folders on my NAS. In Plex, I see some albums multiple times, each with only two or three numbers of that album.\n I tried in Navidrome but that was even worse...\n What am I doing wrong? Is the tagging done wrong? Is there a better server solution?\n Thanks!\n    submitted by    /u/babsenfred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjvxld/witch_music_server_handles_mp3tags_the_best/",
          "publishedOn": "2022-12-12T11:09:42.000Z",
          "wordCount": 16683,
          "title": "Witch music server handles mp3tags the best?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjuomt/nginx_proxy_manager_use_same_cloud_host_or_use/",
          "author": null,
          "description": "I have a server (host) which I use primarily for my Nextcloud VMs, Adguard Home, and a few other services. I also use a Synology NAS and utilize Nginx Proxy Manager to reach them outside my home. My question is, does it matter which server (host) I put my NPM on? Or should I separate it from my main cloud services host? I have two other available servers (hosts) but didn’t know what would be the best set up. I don’t want to affect the cloud server’s (Host’s) Nic…if that is even a thing. \n Appreciate the help in advance!\n    submitted by    /u/flyjim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjuomt/nginx_proxy_manager_use_same_cloud_host_or_use/",
          "publishedOn": "2022-12-12T10:09:05.000Z",
          "wordCount": 20055,
          "title": "Nginx Proxy Manager - Use same cloud host or use separate host?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjph76/cloudflare_tunnel_does_cloudflare_analyse_the/",
          "author": null,
          "description": "Hi all,\n I would really love to use Cloudflare Tunnel for usecases where a VPN isn't possible. E.g. usage via company notebook.\n The great thing is the possibility to secure it directly via Cloudflare with Two-Factor Authentication, so any request must past Cloudflare Auth before getting to my private NGINX. For me much more secure when opening ports directly.\n However, as Cloudflare is generating the HTTPS certificate, they can as Man in the Middle read my traffic (passwords, data, etc) in plain text. Right?\n So is there any possibility to use Cloudflare Tunnel but to secure my data so it cannot be encrypted via Cloudflare?\n    submitted by    /u/Simplixt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjph76/cloudflare_tunnel_does_cloudflare_analyse_the/",
          "publishedOn": "2022-12-12T06:09:24.000Z",
          "wordCount": 1935,
          "title": "Cloudflare Tunnel - does Cloudflare analyse the traffic? Can I prevent it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjo0j0/looking_for_a_specific_gallery_app_with_precise/",
          "author": null,
          "description": "Hi everyone!\n TLDR : i'm looking for an image gallery capable of precise geotagging, and showing it on a map at very little scale (~500m²).\n Full version : I'm in the team of an outdoor event, and each year we take a lot of technical pictures (where a thing is plugged, did we installed a trash here or here, where the hell water distribution was routed, etc.). Those images are invaluable for planning and correcting errors the next year, because plans rarely adapt to the reality, and details evolve organically.\n Generally, we have 700-1000 pictures, from diverse sources. It's complicated when all you have is a big folder to search in.\n So, i'm looking for a selfhosted app where you can geotag a photo, and show it on a map very close, showing roughly 500m² of terrain or less. Ideally an orientation indicator would be useful. A good point would be filtering the points/pictures by tags on the map. For tagging, OpenStreetMap is exact where we are, because of micro-mapping and high precision points, and all that matters is relative positioning anyway.\n I'm already testing apps, but what i want is never a selling point. Map view are often limited to a low zoom, or the pictures shown in full instead of points. Basically i need to install every single one listed on the big list, and it's not an efficient process, when i can ask for help here too ! ;)\n Thanks !\n    submitted by    /u/Moff_Tigriss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjo0j0/looking_for_a_specific_gallery_app_with_precise/",
          "publishedOn": "2022-12-12T05:09:26.000Z",
          "wordCount": 16482,
          "title": "Looking for a specific gallery app with precise geotagging",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjhtt9/help_how_to_make_your_own_smtp_relay_server/",
          "author": null,
          "description": "Hello, I come to ask for some guidance for the creation of SMTP only for sending emails. I have installed poste.io on my synology working but I need to be able to send emails from my poste.io and that my server postfix in vps in hetzner (I am waiting for port unblocking) whoever sends all the emails, I know this is very risky but I have sendinblue and when I send emails this company saves all the info and that makes me have little confidence\n ​\n I have already installed postfix configured as it indicates in the digital ocean tutorial I use smtp as I only send\n ​\n But now, how do I add a user who is the one who posts in my iposte.io as smtp relay and how to send all the emails that I have in my poste.io through the postfix of my vps\n ​\n What I need is a server equal to sendgrid, mailgun, etc. in my own vps. How do I protect and connect to my server in the vps?\n ​\n I have installed\n ​\n -----postfix\n -----libsasl2-2 sasl2-bin\n ​\n My user already creates my user but I cannot connect to my server with these led credentials I leave as I have my sudo nano /etc/postfix/main.cf\n test\n    submitted by    /u/armando0000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjhtt9/help_how_to_make_your_own_smtp_relay_server/",
          "publishedOn": "2022-12-12T01:19:17.000Z",
          "wordCount": 17187,
          "title": "Help how to make your own smtp relay server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjhdhe/i_would_love_for_a_couple_of_people_to_give_me/",
          "author": null,
          "description": "I would love people that are interested in self-hosting and curating media collections could look at this and let me know\n 1) Is this interesting at all to you?\n 2) Why or why not? Is it missing features? (Cloud sources or backups, etc)\n Most media servers let you quickly find something to watch, then you watch it in full on a chosen device. I wanted something else that was for browsing around and adding more granular metadata.\n I made a thing for digging around in your content and adding tags to specific moments. It has animated thumbnails and you can transcribe media that have no subtitles.\n https://gridly.media/\n I have been trying to decide what direction to take this in, but I have been struggling to find people to ask.\n    submitted by    /u/GridlyMedia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjhdhe/i_would_love_for_a_couple_of_people_to_give_me/",
          "publishedOn": "2022-12-12T01:03:14.000Z",
          "wordCount": 16231,
          "title": "I would love for a couple of people to give me some feedback on my media collection project",
          "imageUrl": "https://external-preview.redd.it/1RuOL76MtRhXO0tPbvHBKBiIbDHrubQwF39m4UvV5CI.jpg?auto=webp&s=de29bc86e5dc896bf6e25944a62ca03836d0a521"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjh92q/i_cant_use_bookstack_with_cloudflare_tunnel/",
          "author": null,
          "description": "Hi everyone. Sorry i am newbie here. I have some trouble to setup Bookstack with Cloudflare Tunnel. This is my Bookstack stack file which i was deploy on portainer\n  \nversion: \"2\" services: bookstack: image: lscr.io/linuxserver/bookstack container_name: bookstack environment: - PUID=1000 - PGID=1000 - APP_URL=localhost:6875 - DB_HOST=bookstack_db - DB_USER=bookstack - DB_PASS=<yourdbpass> - DB_DATABASE=bookstackapp volumes: - /path/to/data:/config ports: - 6875:80 restart: unless-stopped depends_on: - bookstack_db bookstack_db: image: lscr.io/linuxserver/mariadb container_name: bookstack_db environment: - PUID=1000 - PGID=1000 - MYSQL_ROOT_PASSWORD=<yourdbpass> - TZ=Europe/London - MYSQL_DATABASE=bookstackapp - MYSQL_USER=bookstack - MYSQL_PASSWORD=<yourdbpass> volumes: - /path/to/data:/config restart: unless-stopped\n I can access bookstack in my local with address http://localhost:6875. But when I setup a cloudflared tunnel with a subdomain point to http://localhost:6875. It just show a white window on my browser. Anyone know what is wrong with my bookstack? How can I fix this? Thanks\n    submitted by    /u/tuong_dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjh92q/i_cant_use_bookstack_with_cloudflare_tunnel/",
          "publishedOn": "2022-12-12T00:59:10.000Z",
          "wordCount": 15521,
          "title": "I can’t use bookstack with Cloudflare Tunnel",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjftoz/looking_for_selfhosted_realty_search_zillow/",
          "author": null,
          "description": "Is anyone aware of a selfhosted app that scrapes Zillow, Redfin and the likes for property? Maybe let you search by specific parameters, and provide updates for changes?\n    submitted by    /u/tgp1994  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjftoz/looking_for_selfhosted_realty_search_zillow/",
          "publishedOn": "2022-12-12T00:11:26.000Z",
          "wordCount": 16569,
          "title": "[Looking for] Selfhosted Realty Search - Zillow, Redfin companion?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjcps6/uptime_kuma_tcp_ping_always_fails/",
          "author": null,
          "description": "Hi, so I'm trying to monitor Tautulli and Plex (among other things) using TCP port in Uptime Kuma, but it always gives an error.\n My plex is hosted at: 192.168.1.2:32400 but kuma always states: \n [Plex] [DOWN] Connect EHOSTUNREACH 192.168.1.2:32400\n Does anyone have any idea what I might be doing wrong? Plex is hosted on a windows server machine, and kuma is inside a docker container running inside an ubuntu server vm on the same device (vm's private ipv4 is 192.168.1.3) TIA.\n    submitted by    /u/80Ships  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjcps6/uptime_kuma_tcp_ping_always_fails/",
          "publishedOn": "2022-12-11T22:37:34.000Z",
          "wordCount": 16033,
          "title": "UpTime Kuma TCP Ping always fails",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjbihs/self_hosting_nextcloud_via_vpn/",
          "author": null,
          "description": "I’m struggling here.\n I’d like to run Nextcloud so that it syncs only when my iOS devices are either 1) locally connected to network or 2) VPN’d remotely.\n I don’t want to expose a public IP or use reverse proxy.\n VPN is setup and working properly on my router & router has ddns address.\n Nextcloud All-In-One docker is installed on Mint Linux box but during setup NC asks for domain and does not allow IP (why?)\n Now I’m stuck bc I dont have a public domain. I have a ddns IP from NoIP for the VPN but not sure this NoIP domain is what I want to use (along with router port forwarding) since its public facing.\n I think an option is to create a private domain via technitium’s zone and point the router to this DNS so that the iOS devices use the DNS but I’m not sure this will work when VPN’d.\n    submitted by    /u/Hubba_Bubba_Lova  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjbihs/self_hosting_nextcloud_via_vpn/",
          "publishedOn": "2022-12-11T22:09:46.000Z",
          "wordCount": 17764,
          "title": "Self hosting Nextcloud via VPN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj8get/selfhosted_backup_solution/",
          "author": null,
          "description": "heya selfhosters and homelabbers\n i‘m trying to get rid of acronis , since it‘s a little messy with my macbook ..\n does anyone have a backup solution in place which cover macOS as well windows?\n thanks!\n    submitted by    /u/Two-Nearby  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj8get/selfhosted_backup_solution/",
          "publishedOn": "2022-12-11T20:54:56.000Z",
          "wordCount": 16814,
          "title": "selfhosted backup solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj6sd9/vm_works_container_doesnt_proxmox_radarr_portainer/",
          "author": null,
          "description": "I am having a whole world of difficulty getting this stuff to work the way I would expect it to, but I am very new to Docker. I guess some people would say this should go in a proxmox/docker/servarr subreddit, but figured it was generic enough to put it here.\n I have a Synology NAS for all my storage. \n ​\n I have two hosts running proxmox in a cluster prox1 has vpn to lan, lisc lxcs and prox2 has PLEX. Plex is working.\n ​\n I have been mounting my network shares from my NAS via CFIS in fstab with the following:\n //192.168.1.2/Media /media/Media cifs username,password,iocharset=utf8,noperm 0 0\n This has been successful in many iterations of my PLEX server on Ubuntu server on bare metal, and now in an LXC with debian base for PLEX.\n ​\n I've been banging my head on the wall trying to get Overs…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj6sd9/vm_works_container_doesnt_proxmox_radarr_portainer/",
          "publishedOn": "2022-12-11T20:16:07.000Z",
          "wordCount": 20562,
          "title": "VM works, Container doesn't: Proxmox, Radarr, Portainer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj5one/best_approach_for_pihole_unbound_access_from/",
          "author": null,
          "description": "Hi, new on here and generally new to the whole self hosting thing apart from pihole.\n Currently I’m running just pihole and unbound on raspberry B+ (2014) model on dietpi. My goal is to be able to use it outside of my home network in the SAFEST way possible with least amount of lag possible.\n I would rather spend some extra time to achieve both (if possible) than to take a shortcut. I’ve heard about wireguard, Tailscale and zetotier but not looked deep enough to decide which one is the best approach of the three.\n What i was hoping to do was fresh install of everything on a new sd card for two reasons; in case things go south i still have copy of current setup on old card and secondly so that i can easily follow certain guide as its been a while since i setup the pihole. I have some extra questions i want to ask for future planning.\n  \nHow many things can i run on this raspberry pi? In near future i want to try few other things I’ve come across such as bookmark manager like shiori or password manager like Bitwarden/vaultwarden2.\n if I can run more than just the pihole setup mentioned in second paragraph, whats the best approach? And how?\n Does it make sense to use flash drive (if possible) to run this on for extra reliability.\n say someone is able to access my pihole, aside from my dns queries what other data can they access\n  \nMy ultimate goal for future would be to use pihole as primary dns and have everything else running on some server (post for another day)\n I would really appreciate any help you guys can provide. Thanks in advance\n    submitted by    /u/C0mpleteAnnihilation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj5one/best_approach_for_pihole_unbound_access_from/",
          "publishedOn": "2022-12-11T19:46:46.000Z",
          "wordCount": 17734,
          "title": "Best approach for pihole + unbound + access from anywhere",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj5g9w/manage_services_running_on_local_machines/",
          "author": null,
          "description": "Hello. A while ago I started building a solution for managing my projects. Even though I kind of have it working, I feel like there should be an existing solution for this that could be of more value for me. Here is my situation:\n I have a few machines running on my network, each of them runs some projects of mine. When I want to run a project, I log on to the machine, clone the repo and run a command to build and serve it.\n I develop and update projects from my main machine, and whenever I push an update I have to log on to the relevant machine and do the whole process manually over again.\n What I would like is to be able to upgrade, rebuild, and rerun the projects on each machine, from a central dashboard of some sort, eliminating the need to log on to each machine. Ideally I would like to hook this up with some git events so that the whole process is automated.\n I feel like there has to be some software that does this, that's not enterprise level. I was recently looking at portainer, which I think does what I want, but I don't have everything in containers so it doesn't work for me.\n ​\n Surely someone here has experience with this problem and can offer some advice!\n Thanks a lot in advance for any help.\n ​\n    submitted by    /u/modenv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj5g9w/manage_services_running_on_local_machines/",
          "publishedOn": "2022-12-11T19:38:57.000Z",
          "wordCount": 15621,
          "title": "Manage services running on local machines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj52dr/setup_to_automate_jellyseer_google_drive_jellyfin/",
          "author": null,
          "description": "Hey,\n any good solution out there to download a folder from google drive when requested via Jellyseer? And rename the episodes after that for Jellyfin? Only DIY possible or is there some sort of tool which \"bridges\" that gap?\n    submitted by    /u/st01x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj52dr/setup_to_automate_jellyseer_google_drive_jellyfin/",
          "publishedOn": "2022-12-11T19:27:30.000Z",
          "wordCount": 15664,
          "title": "Setup to automate Jellyseer + Google Drive + Jellyfin?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zizzk1/can_i_host_multiple_services_at_the_same_public/",
          "author": null,
          "description": "Hi all - I'm just getting started in self-hosting and I've set up a homebrew calendar application in Django that used to be rent-hosted. So now I have it run on a old laptop in my office, and I use ddns.org for dynamic DNS. I'd like to start up a second service on the same machine, and access the original calendar service at a URL like myfake.ddnsdomain.org/calendar/ and the new notes-like service at myfake.ddnsdomain.org/notes/\n I tried using nginx to redirect the /calendar/ URL suffix from my HTTP port to a different port on which the Django app was running, and that worked for the initial page, but that same suffix was not appended the follow-up HTTP requests from the client side. How can I achieve this behavior without modifying the code for the calendar app? (Of course, I can technically do it for the calendar app, but then I wouldn't have a solution for the other services...)\n Is this possible? Or do I have to do something different, like should I do a 301 request to a different port and open multiple on my home router?\n    submitted by    /u/MrMallIronmaker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zizzk1/can_i_host_multiple_services_at_the_same_public/",
          "publishedOn": "2022-12-11T17:10:01.000Z",
          "wordCount": 16599,
          "title": "Can I host multiple services at the same public IP using URL patterns?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zizqnj/unified_messaging_platform/",
          "author": null,
          "description": "Hi! \n I'm looking for a unified messaging app. What this means is a web browser based or programm that allows me to have all my messages in 1 place from different apps. \n An example of this is: Texts \n https://texts.com/ \n Not sure if something excists but i'm looking forward to your answers!\n    submitted by    /u/jorissels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zizqnj/unified_messaging_platform/",
          "publishedOn": "2022-12-11T17:03:19.000Z",
          "wordCount": 15713,
          "title": "Unified messaging platform.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ziyyb6/synlogy_ds214play_upgradealternatives_with_docker/",
          "author": null,
          "description": "Looking for some advise from more experienced friends.\n I currently have Synlogy DS214Play with two 4TB HDDs.\n I have a cctv software with one camera and plex installed, and they work great.\n Unfortunately Docker is not supported on DS214Play and I'm looking for some alternatives.\n My requirements are:\n - Network storage\n - Plex\n - Ability to install various packages, for example https://www.home-assistant.io/ or similar.\n - Ability to install a few CCTV cameras with CCTV management software. I would prefer something different than built-in synology software.\n Basically it would be nice if I could run everything on docker.\n What hardware do you recommend that is similar in physical size to synology boxes (can be synology). I don't have a space for a rack in my flat.\n    submitted by    /u/f899cwbchl35jnsj3ilh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ziyyb6/synlogy_ds214play_upgradealternatives_with_docker/",
          "publishedOn": "2022-12-11T16:41:15.000Z",
          "wordCount": 16169,
          "title": "Synlogy DS214Play upgrade/alternatives with docker",
          "imageUrl": "https://external-preview.redd.it/UJkqXw8jYcOSjjqxZvMXdvsyZBUeXSy1eKeKStW6xFQ.jpg?auto=webp&s=b2b48b101fa6f1058daa3ecfc92f13bc42212363"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ziw5tz/limiting_ssh_access_to_vpn/",
          "author": null,
          "description": "Hi\n I am running several Ubuntu VPS and I am thinking about limiting ssh access to only my VPN (ZeroTier). I have no reasons to want ssh to be exposed to the Internet.\n However, is that a good idea? What if a server restarts and can't load/connect to the ZeroTier VPN?\n    submitted by    /u/TedBob99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ziw5tz/limiting_ssh_access_to_vpn/",
          "publishedOn": "2022-12-11T15:21:31.000Z",
          "wordCount": 16453,
          "title": "Limiting ssh access to vpn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ziv8vo/grist_alternatives/",
          "author": null,
          "description": "Hello there, I’m looking for a self hosted spreadsheet software for multi user usage with customisable user roles (able to edit, delete, create rows)\n I’ve tried Grist, Baserow and Seatable but it is unable to customise user roles.\n Any recommendations?\n    submitted by    /u/Express_Steak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ziv8vo/grist_alternatives/",
          "publishedOn": "2022-12-11T14:58:15.000Z",
          "wordCount": 17129,
          "title": "Grist alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zitmds/proxmox_homeserver/",
          "author": null,
          "description": "Quick question: I recently set up Proxmox VE on an old desktop I had lying around (Specs: i5 6600, 16gb DDR4 Memory, 500gb ssd, Gigabit LAN) and I also have HomeAssistant up and running on a VM.\n Now I'd like to install quite a few services that usually run in a docker container like piHole/Adguard, Whoogle, TrueNas or similar for Storage, and maybe Yacht so that I am able to install more services easily.\n My question is, what is the best way to go to set these up? Should I use Proxmox LXC Containers, a designated linux vm in Proxmox or should I directly run the services as docker containers on the Proxmox Debian installation?\n Thanks in advance\n    submitted by    /u/StefanArts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zitmds/proxmox_homeserver/",
          "publishedOn": "2022-12-11T14:14:45.000Z",
          "wordCount": 17364,
          "title": "Proxmox Homeserver",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zirgvf/self_hosted_appointment_software_calandlylike/",
          "author": null,
          "description": "Hi guys, \n I'm in the process of launching my own digital agency and I'm looking for a software solution so the customer could book appointment with me. I'm thinking of something like calandly, but preferably self-hosted / FOSS, so I can integrate it in my website. \n Does any of yee have any experience with calandly, easy-appointement, cal.com, meetsy,...? Any feedback? I'd appreciate the following feature: \n - self-hosted Frontend and API\n - Calandar integration\n - Sending appointement reminder\n - Integration with jitsy or zoom?\n    submitted by    /u/trollfre3account  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zirgvf/self_hosted_appointment_software_calandlylike/",
          "publishedOn": "2022-12-11T13:14:13.000Z",
          "wordCount": 15867,
          "title": "Self hosted appointment software? (calandly-like)",
          "imageUrl": "https://external-preview.redd.it/mpwVK4VfbYoKCUAxw8JWVkQh3l9fxwBZ3Xe05u-oWoA.jpg?auto=webp&s=0446bcb6a9f7dfd024fa974e67ffe9b663e3b987"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zinppw/how_important_to_have_tlsa_records/",
          "author": null,
          "description": "I just got to setup my dns server(s) properly with DNSSEC. Now reading further I got to TLSA records and thinking about how important it is in current state? Before I used DNS server from provider where I didn't heart about TLSA and didn't it setup for years. Are there known issues/restrictions by not setting it up?\n    submitted by    /u/champonthis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zinppw/how_important_to_have_tlsa_records/",
          "publishedOn": "2022-12-11T10:46:26.000Z",
          "wordCount": 18384,
          "title": "How important to have TLSA records?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zinp3e/anyone_ever_successfully_self_host_simplelogin_on/",
          "author": null,
          "description": "I've been struggling to self host SimpleLogin on my home server where my internet provider provided a public ip which is usually changed from time to time because I do not subscribe for the much higher price fixed public ip.\n simple-login/app: The SimpleLogin back-end (github.com) \n I understand that the installation guide provided in the GITHUB link above is based on the self-host environment where the server has a permanent fixed public IP?\n I've installed it on the home server and added all the DNS records required on Cloudflare where I managed my registered domain. I can open up the SimpleLogin signup webui and the signup email verification was successfully sent to Yahoo by postfix (I know by looking at the /var/log/mail.log), but my yahoo inbox/spam box never got the mail. So I'm stuck. I suspect it has something to do with the system mail name, my domain, etc. that I setup for Postfix. \n My internet provider doesn't block port 25, so it is not a port problem.\n My home servers:\n - PfSense box running HAProxy as a reversed proxy\n - Self-hosted SimpleLogin was installed on Debian VM (which runs on my Unraid server)\n - mydomainname.com was registered at Namecheap but I transferred the DNS management to Cloudflare. All subdomains set on Cloudflare DNS are working fine hand in hand with my pfSense HAProxy. \n Any advice would be appreciated.\n    submitted by    /u/europacafe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zinp3e/anyone_ever_successfully_self_host_simplelogin_on/",
          "publishedOn": "2022-12-11T10:45:34.000Z",
          "wordCount": 16642,
          "title": "Anyone ever successfully self host SimpleLogin on your home server?",
          "imageUrl": "https://external-preview.redd.it/36T2m9krmTYHKICNIbRcIap1V56wdIjX5ZKeURovHoU.jpg?auto=webp&s=eae392cf7d4dda51f700c5c63d3a051dbae491b3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zile9g/creating_own_rss_feed_from_database/",
          "author": null,
          "description": "Hi everyone,\n A bit new to selfhosting - currently have a RPi4 running FreshRSS & NextcloudPi behind an nginx reverse proxy, all hosted in docker containers.\n I have a database of articles including a section and article link - there are a total of about ~10,000 articles in it. I would like to create an RSS feed that randomly picks up one article every day and sends it to FreshRSS, so I can read the articles on my phone/linux system. \n Any information on how to do this easily is very much appreciated. Thank you!\n    submitted by    /u/seriouslyfun95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zile9g/creating_own_rss_feed_from_database/",
          "publishedOn": "2022-12-11T08:58:12.000Z",
          "wordCount": 16460,
          "title": "Creating own RSS feed from database?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zikqoj/best_python_script_orchestrator/",
          "author": null,
          "description": "Hey all. \n I have a number of different small scripts to automate and integrate various tasks. I've used UnRaid's Custom User Scripts to host these over the past couple years. Things are starting to become unmanageable and I've starting looking into a more robust solution.\n At the end of the day, I'm looking for some application to run python scripts, manage environments, integrate with GitHub, and have some centralized scheduler. Things like logging, error notifications, or managing credentials would all be solid extras. \n Most of the applications I've found seem overly complex, resource intensive, or just completely miss the mark. Things like JupyterHub, Jenkins, Airflow, VS Code Server, and others. \n Airflow is probably the front runner, however it is still much, much more than what I'm really looking for. I feel like I'm searching the wrong keywords...\n Any recommendations?\n    submitted by    /u/Rebeleleven  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zikqoj/best_python_script_orchestrator/",
          "publishedOn": "2022-12-11T08:27:07.000Z",
          "wordCount": 16905,
          "title": "Best (Python) Script Orchestrator?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zif4d3/pros_and_cons_of_an_onion_homeserver/",
          "author": null,
          "description": "I've been thinking of the implications of a homeserver based on the tor network. Assuming that the users apply the best practices, would some anonymity be achieved by this kind of setup? Also, ⠀would an obfuscated bridge help?\n    submitted by    /u/AmandaPolx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zif4d3/pros_and_cons_of_an_onion_homeserver/",
          "publishedOn": "2022-12-11T04:39:53.000Z",
          "wordCount": 17082,
          "title": "Pros and cons of an .onion homeserver .",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zidehg/can_a_2012_emachine_computer_be_my_web_server/",
          "author": null,
          "description": "Found this old computer in my basement and I wanna use it as web server for my web app. With these specs do you think it hold high traffic (10k visitors a day)\n Should I just use a raspberry pi instead of this?\n Is it possible to use both as a server for the same web app?\n Keep in mind, I don’t want to spend money if I don’t have to!\n    submitted by    /u/QualityOrnery282  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zidehg/can_a_2012_emachine_computer_be_my_web_server/",
          "publishedOn": "2022-12-11T03:35:10.000Z",
          "wordCount": 18689,
          "title": "Can a 2012 Emachine computer be my web server",
          "imageUrl": "https://preview.redd.it/1q4ckjm7d85a1.jpg?auto=webp&s=a2f0ebbdcd0440a5404ec08b63396469cf6a1374"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi62v9/how_would_pomerium_authentik_compare_to_traefik/",
          "author": null,
          "description": "Hi all! I've been working on my homelab slowly for the past six months or so when I have time. I'd really like to host some services for my friends, though not all are web-based. I heard about Pomerium and am a little confused as to why people are using it in conjunction with Traefik. It seems to me that practically it is traefik for my k8-less uses but would allow for easier monitoring of who is using my services? I really like the idea of having to approve of each device on Pomerium before they can use any service of mine, and I'm not sure if that's possible with Authentik.\n If anyone has any knowledge they could enlighten me with here that would be cool! Does Traefik + Authentik work well for hosting a game server?\n    submitted by    /u/alexlyee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi62v9/how_would_pomerium_authentik_compare_to_traefik/",
          "publishedOn": "2022-12-10T22:45:14.000Z",
          "wordCount": 16182,
          "title": "How would Pomerium + Authentik compare to Traefik + Authentik?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi5yto/raspberry_pi_stream_filestorrents_to_tv/",
          "author": null,
          "description": "Hello,\n This sub inspired me to create something selfhosted with my Raspberry Pi, so thank you!\n I just bought a new TV(Android TV) for my family and I thought how could I stream/watch my downloaded movies/TV series easier. \n What I have done so far - Installed DietPi on my Raspberry Pi 3B, added external HDD storage, created remote access to it.\n Maybe someone can explain the next process? What setup should I use and how it actually works?\n    submitted by    /u/tasesmuemils  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi5yto/raspberry_pi_stream_filestorrents_to_tv/",
          "publishedOn": "2022-12-10T22:40:37.000Z",
          "wordCount": 15974,
          "title": "Raspberry Pi - stream files/torrents to TV",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi5goi/shoutout_for_linkding_bookmark_manager/",
          "author": null,
          "description": "i've had linkding on my list of things to install for ages, and finally got around to it this week. so far, it's great.\n imported all of my pinboard.io bookmarks, my firefox bookmarks, and when i find it i'll import an old bookmarks file i've had lying around somewhere for a decade.\n i also really like the linkding injector browser plugin. now, every time i search on google or duckduckgo it also searches my own bookmarks and reminds me of any relevant searches. \n https://preview.redd.it/gzed07thb55a1.png?width=2048&format=png&auto=webp&s=c64e09086a397cb8d803dfdab27a21b11feb204f\n    submitted by    /u/adamshand  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi5goi/shoutout_for_linkding_bookmark_manager/",
          "publishedOn": "2022-12-10T22:20:30.000Z",
          "wordCount": 16265,
          "title": "shoutout for linkding bookmark manager",
          "imageUrl": "https://external-preview.redd.it/rexUR795_LYewaXbxIYQLET1WDJAcIe_HHd8MbHQFEU.jpg?auto=webp&s=4201395de942f0f8db8af1588b1114f5fd27466d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi33gz/lets_say_im_gonna_get_a_domain_name_for_my_home/",
          "author": null,
          "description": "Thinking about getting a proper domain name rather than duckdns just for the sake of it;\n But I never experienced with normal domains names neither do I know how they work.. (Really wondering how a domain name costs more or less on some websites and how do they all know that I own it ?)\n So, if I should know anything before buying it, tell me !\n    submitted by    /u/Daitan_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi33gz/lets_say_im_gonna_get_a_domain_name_for_my_home/",
          "publishedOn": "2022-12-10T20:48:18.000Z",
          "wordCount": 16277,
          "title": "Let's say I'm gonna get a domain name for my home server, what should I know before ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi27ol/looking_for_a_cool_domain_name/",
          "author": null,
          "description": "Don't know where to ask this bot I'm really uncreative so do you guys have any inspiration for a cool domain?\n    submitted by    /u/Im1Random  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi27ol/looking_for_a_cool_domain_name/",
          "publishedOn": "2022-12-10T20:12:20.000Z",
          "wordCount": 15515,
          "title": "Looking for a cool domain name",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi1m7u/solution_to_track_progress_in_graphs/",
          "author": null,
          "description": "Hey guys! \n I am looking for something selfhosted ( preferable ARM compatible and mobile friendly ) where i can have different databases which i can input data in everyday to track my overal health and performance as a human beeing. \n For example; \n Everyday of the week i need to give myself a score starting from 1 -10: \n - mentally\n - how i slept good/bad\n - how many hours i slept\n - did i go to the gym that day yes/no\n etc\n Then i would like to have graphs of all of them so i can check for example how productive am i on a monday compared to next monday and what changed? \n If someone has sugestions I would love to hear it! Doesn't necesarraly have to be exactly this, I'm open to anthing! \n Thank you all in advance!\n    submitted by    /u/jorissels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi1m7u/solution_to_track_progress_in_graphs/",
          "publishedOn": "2022-12-10T19:49:28.000Z",
          "wordCount": 15522,
          "title": "Solution to track progress in graphs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhzhu3/how_to_set_up_cloudflare_zero_trust/",
          "author": null,
          "description": "I'm trying to set up cloudflare zero trust, so I can generate some traffic over it. I will be honest, I'm doing this just so I can get a code for yubikey, since I'm interested in a hardware 2FA key and how they work and this is a deal which I wouldn't want to miss. I know the deal is valid until the end of December, so I want to try to get the code. \n So far, I applied for the offer, but I got an email saying right now, I'm not eligible. What I did meantime is:\n  \nRun a vaultwarden docker container on a laptop which has an IP 192.168.1.x and I can access it from other local devices.\n On zero cloud website under Access > Applications, I added the app, with a type \"Private net\" and application url is the IP above, allow rule for policies\n Created a tunnel under access > tunnels and run a connector on the same laptop where the docker is. Once it was run, status was connected on the website\n Next thing I did is I created a user under my team > users. Login method is one-time PIN which gets sent on the email.\n When I login, I type team domain I got from settings > general, it asks for email, sends the code, I type it in and it shows the app I created in the step two.\n The problem is, when I click the app, it redirects me to the IP 192.168.1.x as it's an application url, but only if I'm on the local WiFi. If I try the procedure from my mobile data, obviously it fails as it redirects to the mentioned IP\n  \nIn both cases (WiFi and mobile data) it doesn't generate any traffic on cloudflare website at all as DNS requests, top logins by app are empty. So can someone tell me what I'm doing wrong or which step I'm missing?\n    submitted by    /u/OkKitchen1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhzhu3/how_to_set_up_cloudflare_zero_trust/",
          "publishedOn": "2022-12-10T18:22:44.000Z",
          "wordCount": 15986,
          "title": "How to set up Cloudflare zero trust?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhz3us/selfhosted_cctv_footage_browser/",
          "author": null,
          "description": "I have few IP cameras which saves footate directly to NAS when detect motion. Now I would like to be able to view it from some web app - do you know if is there any?\n    submitted by    /u/witek_smitek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhz3us/selfhosted_cctv_footage_browser/",
          "publishedOn": "2022-12-10T18:07:08.000Z",
          "wordCount": 15996,
          "title": "Selfhosted CCTV Footage browser",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhz00a/miniflux_remove_hostory/",
          "author": null,
          "description": "Hello everyone. Sorry if this has been asked before, but I couldn’t find it. I just installed Miniflux on my raspberry pi. Everything is running great. However, s there a way to disable the history option? I found the cleanup parameters, but that doesn’t seem to be what I’m looking for. If there is no way, I can keep the parameters set to 1 day. Thank you for your help\n    submitted by    /u/cyberFish79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhz00a/miniflux_remove_hostory/",
          "publishedOn": "2022-12-10T18:02:52.000Z",
          "wordCount": 16517,
          "title": "Miniflux remove hostory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhtr1x/self_hosted_podcasts/",
          "author": null,
          "description": "Exactly what the title says Any docker app for doing this ? Currently working with music on navidrome and jellyfin So if those have any plugins or stuff that's welcome too \n Thanks for any help :)\n    submitted by    /u/Least_Toe_8980  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhtr1x/self_hosted_podcasts/",
          "publishedOn": "2022-12-10T14:22:28.000Z",
          "wordCount": 16023,
          "title": "self hosted podcasts ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhtnqm/what_is_the_best_practice_and_and_best_way_deploy/",
          "author": null,
          "description": "Hello everybody. I'm having as slight problem. I usually deploy my selfhosted app locally, but after some down time in some work critical apps (my isp sucks), i decided to go VPS route for those that i need high availability. The problem i came across is that now i have to use firewall to restrict access to ports i dont want to be access from the outside. Here comes the problem, I tried iptables, ufw, firewalld always worked fine till a restart, after that i found that docker overwirtes the rules and pass its rules first... \n I found whalewall, and I get some success with it, but i ask myself, that is the best way to do it? Can some of you with more experience and knowledge about this give me a few directions for this simple situation.\n My objective is to pass most my docker apps through nginx proxy, with a exception of one or another.\n Thanks\n    submitted by    /u/DelScipio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhtnqm/what_is_the_best_practice_and_and_best_way_deploy/",
          "publishedOn": "2022-12-10T14:18:36.000Z",
          "wordCount": 16162,
          "title": "What is the best practice and and best way deploy docker containers and restrict some ports to local access?",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "homelabbity",
      "feedUrl": "https://www.reddit.com/r/homelab.rss",
      "siteUrl": "https://www.reddit.com/r/homelab",
      "articles": [
        {
          "id": "https://www.reddit.com/r/homelab/comments/1070ikh/question_pfsense_ap_pihole/",
          "author": null,
          "description": "For background, my current setup is as follows: Xfinity/comcast network being they are the only available option in my area. I have their router/modem combo along with 3 of the xfi pods. Due to this not helping disperse the network across 3 floors too well, we’ve ran lan cables all over the house and I’ve configured two old routers as Access Points. I also run a windows server for plex, wireguard, etc. Could I create an isolated network/AP with say pfsense in docker or a vm and apply pihole here? Ultimately I have not found a way to get around the xfinity devices preset DHCP/dns assigning. This is also my parents house so I don’t have the freedom to opt for a new router/modem combo and the xfi pods are labeled as only working with xfinity all in one.\n    submitted by    /u/Ben13060  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1070ikh/question_pfsense_ap_pihole/",
          "publishedOn": "2023-01-09T01:19:53.000Z",
          "wordCount": 14277,
          "title": "[Question] PfSense AP + PiHole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1070av9/help_needed_managed_switch_on_wan_side/",
          "author": null,
          "description": "Hello everyone, looking for some ideas here, TIA!\n My ISP, Google Fiber, allows 2 public IPs from upstream DHCP server. I'm using one for regular home use and one for home lab testing.\n Current setting is Fiber jack ---> PoE injector ---> unmanaged TP-Link switch ---> two pfSense boxes (each has its own public IP). Fiber jack gets power from PoE.\n I just got a Cisco SG300-10PP (managed PoE switch) and would like to replace the PoE injector and the TP-Link switch with this Cisco one. However, since it's a managed switch, when I connect it to the Fiber jack, itself will take one public IP from the upstream DHCP server and then only pass the remaining IP to one pfSense box. The other pfSense box is not able to receive a public IP.\n Is there anyway to keep both public IPs for my pfSense boxes?\n    submitted by    /u/ihank724  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1070av9/help_needed_managed_switch_on_wan_side/",
          "publishedOn": "2023-01-09T01:10:22.000Z",
          "wordCount": 14527,
          "title": "Help needed. Managed Switch on WAN side",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10705wp/recommend_a_win1011debian11_compatible_hba/",
          "author": null,
          "description": "I need to expand my system to have more SATA 6gbps ports and I need an HSB that's compatible with both Win10/11 and Debian 11. Please point me to tested products that would work for this. Thanks!\n    submitted by    /u/aws-ome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10705wp/recommend_a_win1011debian11_compatible_hba/",
          "publishedOn": "2023-01-09T01:04:18.000Z",
          "wordCount": 14603,
          "title": "Recommend a Win10/11/Debian11 compatible HBA?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106yadm/memtest86_equivalent_for_nics/",
          "author": null,
          "description": "I have a suspicion that my Proxmox host has issues with the onboard NIC. What kinds of tools can I run to test this?\n    submitted by    /u/Wiltify  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106yadm/memtest86_equivalent_for_nics/",
          "publishedOn": "2023-01-08T23:43:39.000Z",
          "wordCount": 15115,
          "title": "MEMTEST86 Equivalent for NICs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106y1hx/building_new_network_from_scratch_any_switch_and/",
          "author": null,
          "description": "I’m currently planning and building an entire network from scratch. I have experience with servers and virtualization, and generally have rough plans and everything I need to begin. The only issues is I have never worked with or had any enterprise routers or switches, and am a bit overwhelmed with choices. I’m also not sure which mediums to use (cat6a, DAC, or fiber). I have looked at and considered Ubiquity, however I’ve heard there are some limitations. I currently have 1 Gb fiber internet, but am planning on upgrading this to 5 Gb in the near future. I know there will be a need for PoE at the edge for various devices (phones, APs, cameras,etc.) I’m aiming to build a 10Gb capable network, at least in the core, but preferably end-to-end, and am planning this out with future proofing and redundancy in mind. However, for the core switches and in the server room, I’m considering 25Gb or higher, there will be many VM hosts, and I will be building a SAN and testing MaaS. Most of the servers have NVme drives.\n    submitted by    /u/gavinvi7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106y1hx/building_new_network_from_scratch_any_switch_and/",
          "publishedOn": "2023-01-08T23:33:28.000Z",
          "wordCount": 15095,
          "title": "Building new network from scratch, any switch and design recommendations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106xxgy/grafana_dashboards/",
          "author": null,
          "description": "What are some of the best grafana dashboards that you use, or heard of? One of the best ones that I use is the VMware vsphere one in my homelab.\n    submitted by    /u/CoolGaM3r215  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106xxgy/grafana_dashboards/",
          "publishedOn": "2023-01-08T23:29:04.000Z",
          "wordCount": 14004,
          "title": "Grafana dashboards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106wb32/i_found_a_way_to_retrofit_gen7_hp_caddies_to_work/",
          "author": null,
          "description": "I don't know if anybody else knew but I just found out that gen7 caddies will fit into a gen8 server. Sure they stick out a little and it won't be quite as happy that you're not using \"official\" caddies at POST but that's a whole lot better than having them haging IMO. Of course this only makes sense in a homelab environment given how inexplicably expensive hard drive caddies are but given I have a bunch of gen7 caddies this makes sense for me.\n    submitted by    /u/windows10_is_stoopid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106wb32/i_found_a_way_to_retrofit_gen7_hp_caddies_to_work/",
          "publishedOn": "2023-01-08T22:24:22.000Z",
          "wordCount": 14756,
          "title": "I found a way to retrofit Gen7 HP caddies to \"work\" with Gen8 servers.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106w7yp/my_little_50w_homelab_cannot_decide_which_rack_to/",
          "author": null,
          "description": "submitted by    /u/mjnck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106w7yp/my_little_50w_homelab_cannot_decide_which_rack_to/",
          "publishedOn": "2023-01-08T22:20:57.000Z",
          "wordCount": 14828,
          "title": "My little 50w homelab (cannot decide which rack to buy for it)",
          "imageUrl": "https://preview.redd.it/szshdbrn9waa1.jpg?auto=webp&s=730c19d4970fb200983ae30a645d87dffe728b6c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106vujv/how_to_make_a_direct_access_storage_accessible/",
          "author": null,
          "description": "Be it wired or wireless, how to make a DAS accessible from all home computers (running Mac OS, Windows, Linux, iOS)? Ideally files from the above mentioned OS be able to stored in the DAS.\n    submitted by    /u/largelcd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106vujv/how_to_make_a_direct_access_storage_accessible/",
          "publishedOn": "2023-01-08T22:06:24.000Z",
          "wordCount": 14525,
          "title": "How to make a Direct Access Storage accessible from all home computers and devices?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106vu02/security_options_for_a_raspberry_pi/",
          "author": null,
          "description": "Hello everybody,\n I've got a Raspberry Pi 4 4gb that I've decided to turn into a small homelab of sorts. Therefore, the plan is as follows:\n  \nStep 1: Secure the Pi/network\n Step 2: Gateway for the Pi\n Step 3: Work on Pi at work using gateway\n Step 4: Expand the homelab\n  \nSo far, I've installed Docker and Portainer to begin making containers for apps/services, but I'm not sure what I should use to secure the network and the Pi. I want to make the Pi as secure as I can before exposing it to the internet for self hosting and remote access. What would you guys recommend?\n    submitted by    /u/Shortstack_Sean98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106vu02/security_options_for_a_raspberry_pi/",
          "publishedOn": "2023-01-08T22:05:49.000Z",
          "wordCount": 14969,
          "title": "Security Options for a Raspberry Pi",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106vcpf/tailscale_wireguard_and_dns/",
          "author": null,
          "description": "I've been using Tailscale to make accessing private services easy while not opening up ports to the big scary internet, and it's been working great. But there are a few problems creeping up - namely, that the tailscale iOS app crushes battery, and that in an increasing number of cases the tailscale client will confuse the linux networking stack and actually block off regular internet traffic.\n So I'm thinking of rolling my own wireguard or openvpn. But how can I replicate the DNS features of Tailscale, which are really handy? On any of my devices I can refer to my devices by a single name and they will resolve.\n Here's my question - can you use a public domain and set the DNS servers for that domain to be the local ip of your internal DNS? So, if you're not on the VPN those names don't resolve, but if you happen to be then <hostname>.example.net will be resolved by your private/internal DNS. Then you could also set a search domain so a machine will assume <hostname> is actually <hostname>.example.net\n Anyone done this?\n    submitted by    /u/saksoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106vcpf/tailscale_wireguard_and_dns/",
          "publishedOn": "2023-01-08T21:47:29.000Z",
          "wordCount": 15063,
          "title": "Tailscale, Wireguard and DNS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106v4gb/what_rmm_software_do_you_use/",
          "author": null,
          "description": "Hi all,\n I am looking for a good well rounded and preferably open source rmm software that I can use for my home lab. I am running a pfsense box so it would need to support freebsd.\n If anyone has any suggestions that would be greatly appreciated.\n    submitted by    /u/eaglescoutb01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106v4gb/what_rmm_software_do_you_use/",
          "publishedOn": "2023-01-08T21:38:37.000Z",
          "wordCount": 15230,
          "title": "what RMM software do you use",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106v17k/having_2_adguard_or_pihole_servers_is_not/",
          "author": null,
          "description": "I found out today that my 2 adguard servers will not help if one goes down. One of mine is in proxmox and my proxmox server hung up on reboot after an update. All of the sudden a lot of devices on my network stopped working but not all of them. My proxmox is headless so it took me a little while to realize it was locked up. My PI4 running adguard was working fine but did not provide lookups. After some digging, I learned that having primary and alternate DNS servers helps with load balancing and is not there in case of failure of either one. Is this correct?\n    submitted by    /u/bclinton  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106v17k/having_2_adguard_or_pihole_servers_is_not/",
          "publishedOn": "2023-01-08T21:35:10.000Z",
          "wordCount": 15172,
          "title": "Having 2 Adguard or Pihole servers is not redundancy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106utj3/need_advice_on_motherboard_selection_for_my/",
          "author": null,
          "description": "I am trying to build a server/workstation for virtualization purpose and have some questions. Here is me hoping I get some good advice from the experts.\n I am not looking to get a rackmounted server (though not too opposed to it) as that is too much for my needs (I am fairly comfortable building desktop/workstation, but never dealt with rackmounted servers), so sticking to desktop/workstation type build. I want to run dual xeon setup and have already acquired a matching pair of E5-2699v4. My question is mainly about compatible motherboard and memory.\n I am leaning towards the supermicro X10DRH-IT board for this purpose. Do you think this is a good choice? Or do you recommend something else? I believe this motherboard only takes ECC memory which means I am going to have to acquire some sticks. I am thinking about going with 32GB x 8 = 256GB with option to expand to 512 GB later (by adding more sticks).\n I have looked at some faily inexpansive chinese motherboards (e.g. Machinist X99-D8-MAX) that have m.2 slots (which I prefer) and can take both ECC as well as non-ECC memory but I am not sure if they are reliable or supported for my CPU setup. Or for that matter a good choice.\n How much PSU will I need. Do you think something like a 750W would be sufficient (say with 4 x 3.5 in HDD)?\n Appreciate your help in advance.\n    submitted by    /u/dragoncoder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106utj3/need_advice_on_motherboard_selection_for_my/",
          "publishedOn": "2023-01-08T21:26:59.000Z",
          "wordCount": 15122,
          "title": "Need advice on motherboard selection for my virtualization workstation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106sc95/dell_optiplex_790_vs_3010_home_lab/",
          "author": null,
          "description": "Hey\n I want to get into a home lab but have a small budget. I found 2 different dell optiplexes near me for $75 CAD.\n The 790 is upgraded and has a 8tb hard drive and a 240gb ssd with 12gb of ram. The 3010 has a 120gb ssd but is the same price.\n What would be the right choice? should i get the 790 because of the storage and ram then upgrade the cpu?\n Edit: i want to use it as a jellyfin server or a minecraft server for friends\n    submitted by    /u/KingYonatan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106sc95/dell_optiplex_790_vs_3010_home_lab/",
          "publishedOn": "2023-01-08T19:49:04.000Z",
          "wordCount": 15648,
          "title": "Dell optiplex 790 vs 3010 home lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106r7js/rack_mounted_wyse/",
          "author": null,
          "description": "Curious if anyone has seen a rack mount setup for a Dell wyse 5070? Either commercially produced or DIY. Google not helping and I thought I'd check here before sorting out a solution myself.\n ​\n Thanks!\n    submitted by    /u/fliberdygibits  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106r7js/rack_mounted_wyse/",
          "publishedOn": "2023-01-08T19:04:00.000Z",
          "wordCount": 14335,
          "title": "Rack mounted wyse?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106qayx/pcie_slots_lanes_question_with_gigabyte_b660_ds3h/",
          "author": null,
          "description": "submitted by    /u/cougar694u  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106qayx/pcie_slots_lanes_question_with_gigabyte_b660_ds3h/",
          "publishedOn": "2023-01-08T18:27:58.000Z",
          "wordCount": 16547,
          "title": "PCIe slots & lanes question with Gigabyte B660 DS3H AX & i7-12700k",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106nv7g/homelab_admin_network_setup/",
          "author": null,
          "description": "I have an ever growing homelab setup picking up used servers locally for way less than market value. My wife of course shakes her head every time another rackmount box is brought home (I plan to sell off some others to make room I swear /s)\n Up until now I've mostly haven't needed the management interfaces like iDrac, IPMI, UPS network port/console, etc. First setup is with an attached keyboard/mouse then installed on the LAN. On the few occasions the box needs attention I go into the basement and address it, sometimes even dragging a monitor and keyboard over if needed. Each time cursing myself for not setting up a private admin LAN to do this remotely from the main floor.\n After reading the post about the publicly exposed iDrac port and shaking my head knowing that's a bad idea, it reminded me it's time for today me to connect my homelab server management ports so tomorrow me is happy. But I don't know where to start.\n Separate physical LAN or VLAN yes of course, no access from the Internet side, but then what? Air gapped until I need access so go into the basement to plug in a network cable? That's painful.\n What's a decent way to setup a homelab management network for iDrac, IPMI, and UPS network ports? I want security but ease of use, it's a homelab not top secret government work.\n How is your homelab Admin Network setup?\n    submitted by    /u/SD18491  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106nv7g/homelab_admin_network_setup/",
          "publishedOn": "2023-01-08T16:51:38.000Z",
          "wordCount": 16975,
          "title": "Homelab Admin Network Setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106kjwg/dell_r720xd_motherboard_reset/",
          "author": null,
          "description": "One of my R720XDs motherboards finally bailed after several pink screens of death and I’ve replaced it with an Amazon refurbished MB. It’s all cabled up properly (I compared it with another R720XD to make sure). The two PSUs are lit, the on board network interfaces are lit, and the status light on the back has come on at least once when the room got a bit cold. The replacement MB is “new” and since I can’t turn it on, I haven’t been able to configure the IDRAC so don’t know what it might be set to, IP address and credentials.\n However it won’t power on. Pressing the power on button does nothing. No lights on the front either. I’m probably wrong but the only thing I can think of other than a faulty MB is the IDRAC is configured to disable the power on button. As I’ve never encountered that before, I’m not sure how the system would look if it was in that state, as in would there still be lights on the front or would it be as it is now, dark.\n Anyway, I was searching the ‘net to see if there was a way to physically restore the IDRAC to the factory defaults such as a jumper on the MB but searches have failed. Either no way or my search terms are failing.\n Heck, at this point, it seems like just buying a “new” R720XD will be the optimum solution. The ebay costs are about what I paid for the refurbished MB. But I thought I’d check before pulling that trigger.\n    submitted by    /u/HayabusaJack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106kjwg/dell_r720xd_motherboard_reset/",
          "publishedOn": "2023-01-08T14:29:44.000Z",
          "wordCount": 17590,
          "title": "Dell R720XD Motherboard Reset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106hf5x/whats_the_go_to_aliexpress_pfsense_box_at_the/",
          "author": null,
          "description": "Plan to run Pfsense bare metal, need 4x2.5gb ports\n theres a quite a few different variants\n as i226 doesnt work with pfsense 2,60CE yet, are the i225 B3 stable for every day use? \n Patrick from STH seems to favour the N5105 as the sweet spot for performance and power.\n thanks\n    submitted by    /u/bigup7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106hf5x/whats_the_go_to_aliexpress_pfsense_box_at_the/",
          "publishedOn": "2023-01-08T11:51:10.000Z",
          "wordCount": 15463,
          "title": "Whats the go to Aliexpress PFsense box at the moment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/106gtzz/first_time_adding_a_ups_to_my_homelab/",
          "author": null,
          "description": "submitted by    /u/sysLee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/106gtzz/first_time_adding_a_ups_to_my_homelab/",
          "publishedOn": "2023-01-08T11:15:53.000Z",
          "wordCount": 15824,
          "title": "First time adding a UPS to my homelab",
          "imageUrl": "https://preview.redd.it/9ivg89j8zsaa1.jpg?auto=webp&s=8f28a6fa9bf1ef73569a131f46e7317cb63cd132"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1065zzy/cant_flash_ibm_m5110_card/",
          "author": null,
          "description": "I bought an M5110 card and not having much luck in flashing to IT mode with the instructions at https://lazymocha.com/blog/2020/06/05/cross-flash-ibm-servraid-m5110-and-h1110-to-it-hba-mode/\n sas2flsh -list tells me it failed to initialize pal. Alright Let's skip to the uefi shell and see what happens. I try running sas2flash -list and it tells me it can't find any adapters?\n So what am I doing wrong here? Some people say to try flashing on a different box but I tried on a Thinkstation S30 and then on a brand new Ryzen 5 box and get the exact same results? What am I doing wrong? Anyone had success with this card? I was able to get into the card setup and run the Megaraid utility in windows so it appears to be functional.\n    submitted by    /u/sopabe6197  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1065zzy/cant_flash_ibm_m5110_card/",
          "publishedOn": "2023-01-08T01:33:21.000Z",
          "wordCount": 14207,
          "title": "Can't flash IBM M5110 card",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1065le5/cisco_packet_tracer_test_lab/",
          "author": null,
          "description": "I am looking to create a \"test\" enviroment of our network of 20 sites in packet tracer. We have MPLS, DMVPN using BGP. I am trying to come up with the best way to link all of the sites. My first though would be having a layer 3 switch doing ip routing to act as the MPLS so link everything, but something keeps nagging at me saying it will not work correctly. Let me know if this would work or there is a better way of linking it all together.\n    submitted by    /u/Accomplished_Bed7023  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1065le5/cisco_packet_tracer_test_lab/",
          "publishedOn": "2023-01-08T01:14:59.000Z",
          "wordCount": 14139,
          "title": "Cisco Packet Tracer Test Lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1065iyi/why_dont_hp_g8_ilo_remote_consoles_stay_connected/",
          "author": null,
          "description": "submitted by    /u/transdimensionalmeme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1065iyi/why_dont_hp_g8_ilo_remote_consoles_stay_connected/",
          "publishedOn": "2023-01-08T01:11:45.000Z",
          "wordCount": 14391,
          "title": "Why don't HP G8 iLo remote consoles stay connected ? Is there a direct link to opening the console ?",
          "imageUrl": "https://external-preview.redd.it/9f_I7CbR9ahF27d5WdlzYxxClUH6CLk-9uBBuG8D6XI.png?auto=webp&s=8ff698517ea67e51dc38cac2cc89d85d947497dc"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1064zje/get_used_server_grade_ssd_or_new_consumer_grade/",
          "author": null,
          "description": "So I am looking to add to my home lab with a used Dell R720 for Proxmox and PfSense. I can get new Crucial MX500 drives for about the same price and size as used server grade SSD’s from the company I am looking at buying the server from. Given that I don’t know how much data has been written to the used drives, would it be better to have new consumer grade SSD’s, or does the server grade out weigh the question of the data written to the drive already?\n I am looking at loading the 8 bays with 250GB drives in either a ZFS raidz1 or raidz2 configuration.\n    submitted by    /u/mtnbronco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1064zje/get_used_server_grade_ssd_or_new_consumer_grade/",
          "publishedOn": "2023-01-08T00:48:08.000Z",
          "wordCount": 14469,
          "title": "Get used server grade SSD or new consumer grade SSD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1064zhv/ups_self_power_consumption/",
          "author": null,
          "description": "Hi everyone,\n ​\n As I don't have a UPS till now (shame on me), I'm planning to buy one. I'm looking to a 1000 or 1500VA model, rackable if possible. My usual load is about 100 W but sometimes, when gaming for example, load could go up to about 800 W. As you know, electricity price is raising in Europe. I read multiple time, some UPS, especially the rackable ones are drawing up to 50 W by themself, at idle (batteries charged), so in my case about half of my usual load... And if I take the efficiency percentage, with a let's say 1000VA, 980W, 97% efficiency, if I understood well, it means, max about 30W for the self consumption.\n ​\n Did you ever measure the self consumption of your UPS ? \n Which models (SmartUPS vs Back UPS pro or Ellipse Pro vs 5PX...) have the smallest self power consumption ?\n Is form factor affecting the self power consumption (tower vs rack like the APC SMT 1500) ?\n ​\n Thanks a lot\n    submitted by    /u/jcoutare  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1064zhv/ups_self_power_consumption/",
          "publishedOn": "2023-01-08T00:48:05.000Z",
          "wordCount": 14283,
          "title": "UPS self power consumption",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1064vbs/first_homelab_advice_needed_on_configuration/",
          "author": null,
          "description": "Hi everyone, so I bought a dell r720 about a year ago when I knew I wanted to get into Network Engineering, Systems Admin, Cybersecurity, etc. I'm tech savvy so getting a server for hosting services seemed like a great step to continue learning but on a more advanced and enterprise level. Needless to say, owning a server and getting it up and running has been a huge learning experience (some painless some painful but I still love it all of course). I've finally reached the final stage of hardware changes before the server is fully operation and I would love some advice on my final hardware change involving IT Mode vs stock RAID Card and whether or not I need both.\n ​\n Just some disclaimers, this is a homely server for learning and self hosting and I intended on running/hosting:\n Nextcloud …",
          "link": "https://www.reddit.com/r/homelab/comments/1064vbs/first_homelab_advice_needed_on_configuration/",
          "publishedOn": "2023-01-08T00:42:51.000Z",
          "wordCount": 14891,
          "title": "First Homelab [Advice Needed on Configuration]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1064ue1/tlsg108_wake_on_lan_not_working/",
          "author": null,
          "description": "When TL-SG108 Starts for the First Time, We cannot Turn On Devices Connected to this Switch.\n WOL is working Once the device goes Offline after being connected to the Switch.\n Once we turn off the Switch and bring it back Online. WOL will not work.\n Usually, I encounter this in the morning.\n I turn on the Switch using a Smart Power Plug.\n But I cannot remotely turn on NAS or PC connected to this Switch.\n Is there any way we can avoid this issue?\n    submitted by    /u/Bad-Evil-King  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1064ue1/tlsg108_wake_on_lan_not_working/",
          "publishedOn": "2023-01-08T00:41:38.000Z",
          "wordCount": 14915,
          "title": "TL-SG108 Wake On Lan NOT Working",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1064rs6/suggestion_for_a_newbie_should_i_buy_this_server/",
          "author": null,
          "description": "Hello fellow nerds!!!\n Been lurking here for a while, this is my first post here and wanted to get this community's opinion before making a purchase I think might be a good one. Recently I've been trying to recycle every spare pc part I have in the closet prior to a move so I get an idea of what's worth salvaging and what's garbage. Since I'm selling mostly via the facebook marketplace, I couldn't help but browse every so often. And then I found this... An X8DTL with 2 Xeon cpu and 32gb of ddr3 ram. It's listed for 50 bucks but considering I'm running a 2 core, 8 year old intel cpu that doesnt even support VT-d, I'm not sure if it's cheap because its not efficient or did I get somewhat lucky?\n Links to details in the pictures.\n Thanks in advance for any words of wisdom.\n ​\n P.S. I'm a newbie in the sense that I mainly want to run a media server and a \"guest gaming pc\" which is why I made reference to the VT-d.\n    submitted by    /u/aFlyingTaco420  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1064rs6/suggestion_for_a_newbie_should_i_buy_this_server/",
          "publishedOn": "2023-01-08T00:38:22.000Z",
          "wordCount": 15024,
          "title": "Suggestion for a newbie - Should I buy this server mobo?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10642jv/dsr2161_worth_for_anything_else_then_being_a/",
          "author": null,
          "description": "So, I just got an old Avocent DSR2161 from work, according to its description it is a \"KVM over IP switch\", but the \"over IP\" part seems to be disabled(?) or not working without additional software.\n According to some research I have already done, the software is \"DSView3\" but I can't find it anywhere and the new version \"DSView 4.5\" costs a hell of a lot of money. \n My question here would be, is it worth keeping it as a local KVM switch (even though I don't own a PS2 keyboard or mouse yet) or is it a case for someone elses Homelab?\n    submitted by    /u/5trubel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10642jv/dsr2161_worth_for_anything_else_then_being_a/",
          "publishedOn": "2023-01-08T00:08:17.000Z",
          "wordCount": 14185,
          "title": "DSR2161 worth for anything else then being a normal KVM Switch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10641qc/poweredge_r730_wakes_the_fan_for_2_seconds_every/",
          "author": null,
          "description": "​\n PowerEdge R730 \n iDRAC Version 2.61.60.60 (Build 08) \n ​\n I turned off my R730 and I am noticing every 5 min I can hear the fan for 2 seconds then goes silence again.\n ​\n I guess this has something to do with iDRAC.\n ​\n Where is this \"turn on fan every 5 min\" setting when the server is turned off ?\n    submitted by    /u/RevolutionaryHunt753  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10641qc/poweredge_r730_wakes_the_fan_for_2_seconds_every/",
          "publishedOn": "2023-01-08T00:07:19.000Z",
          "wordCount": 14101,
          "title": "PowerEdge R730 wakes the fan for 2 seconds every 5 min when turned off",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1063m31/small_but_powerful_enough_to_run_the_home_and/",
          "author": null,
          "description": "submitted by    /u/gavindi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1063m31/small_but_powerful_enough_to_run_the_home_and/",
          "publishedOn": "2023-01-07T23:49:23.000Z",
          "wordCount": 15053,
          "title": "Small but powerful (enough) to run the home and some small businesses we do",
          "imageUrl": "https://preview.redd.it/azjpt8bmkpaa1.jpg?auto=webp&s=86fcbd608a4fb4a71cf19808c2d6fd590eb7dff8"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1062ft3/found_something_the_poweredge_is_good_for/",
          "author": null,
          "description": "submitted by    /u/Karness_Muur  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1062ft3/found_something_the_poweredge_is_good_for/",
          "publishedOn": "2023-01-07T23:00:47.000Z",
          "wordCount": 14432,
          "title": "Found something the PowerEdge is good for.",
          "imageUrl": "https://preview.redd.it/jmwat05stqaa1.jpg?auto=webp&s=c617e11fdd1b69f6f0354c6d6347875d43d587f5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1060oh7/spot_the_server_rack_dormlab_project_v01a/",
          "author": null,
          "description": "submitted by    /u/greysourcecode  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1060oh7/spot_the_server_rack_dormlab_project_v01a/",
          "publishedOn": "2023-01-07T21:48:08.000Z",
          "wordCount": 16418,
          "title": "Spot the server rack (dormlab project v0.1a)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1060hkk/looking_for_a_big_tower_case_which_will_take_many/",
          "author": null,
          "description": "OK so I have loads of random 3.5 hdds which I want to use once and for all. The drives will mixed makes and capacities so I need to be able to add them to Truenas pools and remove them when they fail / degrade without the loss of data.... What raid type will that be in Truenas? \n So I need a tower case for:\n 1) Many 3.5 hdds (sata) preferable backplane but will cable if need be 2) Will take a dual nic card 3) Fit a micro atx mobo (already got the base system not sure of mobo model, to go in it, just need a better psu) 4) Doesn't need to fit in a rack, be free standing 5) Black in colour 6) Quiet preferably (I know, its the fans really)\n    submitted by    /u/discop3t3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1060hkk/looking_for_a_big_tower_case_which_will_take_many/",
          "publishedOn": "2023-01-07T21:39:57.000Z",
          "wordCount": 14760,
          "title": "Looking for a big tower case which will take many hard drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105zko9/nginx_mail_proxy/",
          "author": null,
          "description": "Hello home labers,\n Currently I have a cheap VPS acting as my main website/mail server however I would like to move the mail server to my homelab later this year. I'm looking at using the NGINX mail proxy directive to redirect from my current VPN to my home lab mail server.\n ​\n I would like to setup the proxy_cache directive on the mail server part in case my home lab goes offline for whatever reason but I'm not sure if it is needed or if it even supports the smtp protocol since most examples I can find only seem to apply to http/https traffic.\n ​\n Currently I haven't gotten around to testing it but I'm curious what happens to the mail if its accepted by the NGINX proxy but the upstream mail server (my homelab) is offline, will it be automatically cached until it can be passed to the server or will it just get lost or bounced back.\n ​\n Note: I'm still in the planning stage but hopefully will get even moved over in the next week or 2 once I get a UPS setup at home and a few other things done.\n    submitted by    /u/DarrenRainey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105zko9/nginx_mail_proxy/",
          "publishedOn": "2023-01-07T21:01:50.000Z",
          "wordCount": 16417,
          "title": "Nginx mail proxy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105yvhn/host_os_compromised_via_dell_idrac/",
          "author": null,
          "description": "TL;DR: If you're running Dell servers at home or otherwise, and have iDRAC publicly accessible, check your users for one called \"newuser\", there is a chance you have been compromised.\n ​\n I woke up this morning to an alert for one of my work servers going offline for 5 minutes. After an investigation, I found a Monero miner running that shouldn't have been there, and no clear way as to how it got there. What's weird is the server has secure users and an IP-based ACL, so it didn't make sense that it was compromised.\n ​\n I raised a ticket to my DC provider to let them know that we'd been breached, with some information and to let them know that I'd found a couple of other of their servers in a list of miners pointing at the wallet. They came back and said they'd had a load of new tickets rai…",
          "link": "https://www.reddit.com/r/homelab/comments/105yvhn/host_os_compromised_via_dell_idrac/",
          "publishedOn": "2023-01-07T20:32:40.000Z",
          "wordCount": 17928,
          "title": "Host OS compromised via Dell iDRAC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105ygyu/i_cant_afford_to_run_my_homelab_so_im_downsizing/",
          "author": null,
          "description": "My electricity is just too darn expensive. I've got lots of old computers and even a rackmount with 2x E5 2680 v2. I looked at my electricity rates and between feeding the servers and the air conditioning in the summer, a watt costs me about $3 a year. That 500 watt rackmount would be $1500 a year which is why I've never really run it. Well that and it's just too loud, but that's a different subject.\n I was running a variety of older desktops as servers. They are Sandy Bridge and Ivy Bridge mostly. They did what I needed and worked great, but depending on how many I had powered up were still a few hundred watts. Add in that they are ten years old and it's time for a change. They are mostly towers and use a lot of space.\n I'm going with thin clients that idle down between 4W and 10W. One HP…",
          "link": "https://www.reddit.com/r/homelab/comments/105ygyu/i_cant_afford_to_run_my_homelab_so_im_downsizing/",
          "publishedOn": "2023-01-07T20:15:24.000Z",
          "wordCount": 20175,
          "title": "I can't afford to run my homelab so I'm downsizing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105wtyd/keepass_vs_bitwarden_for_onprem_password/",
          "author": null,
          "description": "I need a manager for passwords used for my on-prem servers and service users. From reading a few posts here, the community is pretty split on KeePass and BitWarden.\n I don't really need access to the passwords from the internet (except if i use a VPN home), so no cloud.\n    submitted by    /u/MrMrRubic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105wtyd/keepass_vs_bitwarden_for_onprem_password/",
          "publishedOn": "2023-01-07T19:07:15.000Z",
          "wordCount": 15798,
          "title": "KeePass vs BitWarden for on-prem password management?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105w8sx/finally_got_everything_in_a_rack/",
          "author": null,
          "description": "submitted by    /u/TechShocked  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105w8sx/finally_got_everything_in_a_rack/",
          "publishedOn": "2023-01-07T18:42:27.000Z",
          "wordCount": 15021,
          "title": "Finally got everything in a rack!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105v25v/q_rhel_homelab_mirroring_rhsm_cdn_with_pulp/",
          "author": null,
          "description": "Hello everybody,\n I recently set up half a dozen RHEL VMs on a Intel NUC KVM host, using the RH developer subscription program to get free subs.\n Now, by default the RHEL machines fetch their updates from https://cdn.redhat.com/content/ and I was wondering if anybody here has ever tried to mirror that with Pulp or something similar?\n I know that I could achieve the same with a RH Satellite, server but it seems a bit overkill to purchase a license just for home-labbing.\n TLDR; will Pulp work with Red Hat's CDN repos?\n    submitted by    /u/0x412e4e  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105v25v/q_rhel_homelab_mirroring_rhsm_cdn_with_pulp/",
          "publishedOn": "2023-01-07T17:53:45.000Z",
          "wordCount": 16189,
          "title": "Q: RHEL homelab - mirroring rhsm cdn with Pulp",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105ovef/usb_iso_and_general_computer_toolkit_software/",
          "author": null,
          "description": "Hey everyone I'm looking for reccomendations for different useful software/bootable usb flash drives to have. I have experience with Kali Linux, Hirens, and use a ghost boot drive at work for imaging computer. I'm looking for things related to pentesting, hacking, and general \"toolkits\" items that help with everyday or advanced computer stuff. I have looked at pfsense for my network. I'm looking to have a few different usb drives that have different functions and then I'll probably have an external drive that holds vm's, OS iso's, random tools like putty, etc.\n Things I would like to experiment with:\n Some sort of File Recovery/System restore program\n Might be a little overkill but I like the idea of a security drive where my computer won't work without it (or retrofit something with my car if I install a push to start)\n Drive cloning\n    submitted by    /u/GhstZero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105ovef/usb_iso_and_general_computer_toolkit_software/",
          "publishedOn": "2023-01-07T13:19:48.000Z",
          "wordCount": 17488,
          "title": "USB ISO and general computer toolkit software recommendations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105k1en/my_home_lab/",
          "author": null,
          "description": "submitted by    /u/Ok_Cod_7238  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105k1en/my_home_lab/",
          "publishedOn": "2023-01-07T08:29:31.000Z",
          "wordCount": 15430,
          "title": "my home lab! :)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105dz8p/new_server_build/",
          "author": null,
          "description": "submitted by    /u/sinofool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105dz8p/new_server_build/",
          "publishedOn": "2023-01-07T03:02:19.000Z",
          "wordCount": 15029,
          "title": "New server build",
          "imageUrl": "https://preview.redd.it/gxnuypjyvkaa1.jpg?auto=webp&s=452439605b3084701a0550fba34d2e6e267052a7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105d28k/might_be_dumb_but_it_is_possible_to_get_an/",
          "author": null,
          "description": "submitted by    /u/BadConductor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105d28k/might_be_dumb_but_it_is_possible_to_get_an/",
          "publishedOn": "2023-01-07T02:18:30.000Z",
          "wordCount": 16087,
          "title": "Might be dumb... But it is possible to get an RTX3080 into the R720XD!",
          "imageUrl": "https://preview.redd.it/j8k8t5mf6jaa1.jpg?auto=webp&s=0de2b4596e8dbd6d6aec9e99c6e30ceefe7c8093"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105bnnc/idrac_after_power_loss/",
          "author": null,
          "description": "Hi folks, I'm after some help the other night we lost power for 5hrs due to a storm. I've powered on my Dell PowerEdge T420 afterwards and was going to run the script to reduce the noise of my fans, though my iDrac isn't getting an IP Address anymore, everything else on my network is. I've found that if I use the front panel and view IDRAC IP it does give a IP Address which is on the correct range that I'd be expecting, though I'm unable to ping it from any device.\n Should I just reset the iDrac to defaults and is there any risk in resetting to defaults, I've had bad experiences with iDrac before so don't want to risk bricking it.\n Thank you in advance.\n    submitted by    /u/NoGur082  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105bnnc/idrac_after_power_loss/",
          "publishedOn": "2023-01-07T01:15:32.000Z",
          "wordCount": 14264,
          "title": "iDrac after power loss",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105ax3i/aruba_central_any_options_for_homelab/",
          "author": null,
          "description": "Anyone aware of if there is a way to get licenses for Aruba Central for homelab use?\n Thinking of similar idea to VMUG where licenses are offered at a discount to encourage use for training, etc. Just can’t justify paying retail price for a couple switches and APs for lab use.\n    submitted by    /u/infinityends1318  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105ax3i/aruba_central_any_options_for_homelab/",
          "publishedOn": "2023-01-07T00:43:04.000Z",
          "wordCount": 14124,
          "title": "Aruba Central - Any Options for Homelab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105asb2/migrated_from_esxi_pfsense_to_proxmox_omada/",
          "author": null,
          "description": "Just sharing as a type of review for those that may be interested. I've been running a server at home for a long time now, I've had a pretty good setup which worked for a long time using ESXi and PfSense all in a single box. \n I have a 2700X, 128GB RAM, Intel I350-T4, Dell H710P and Quadro P620 and a bunch of disks/NVMe drives, its loaded out. I use this for work, home automation and services, and also for a startup running CI/CD. \n I also have a Unifi 16 Port PoE Switch and AC-Pro AP. Driving the network was pfsense, a VM on ESXi ( basically presented HW mode ) which I passed through some of the I350 interfaces like they were physical ( SR-IOV ) and performance was good, but Pfsense is my first reason for the move.\n ​\n Networking - I've used a lot of tech, and my preference is VyOS since …",
          "link": "https://www.reddit.com/r/homelab/comments/105asb2/migrated_from_esxi_pfsense_to_proxmox_omada/",
          "publishedOn": "2023-01-07T00:37:24.000Z",
          "wordCount": 17001,
          "title": "Migrated from ESXi + PFSense to Proxmox + Omada Gateway and happier for it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105ac8b/what_server_should_i_buildbuy/",
          "author": null,
          "description": "I’m looking to build or buy a server by next month. \n I want to run: OpenRouteService Pelias MySQL (shouldn’t be more than 5G db) NodeJS server to handle analytics/serve files\n I’m thinking of a 730, but could also just get a threadrupper and put it in a server case. Any ideas on what I should do? Don’t want to spend more than $1k.\n    submitted by    /u/programmrz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105ac8b/what_server_should_i_buildbuy/",
          "publishedOn": "2023-01-07T00:18:28.000Z",
          "wordCount": 14138,
          "title": "What server should I build/buy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/105aapg/total_run_time_1381_years_61_days_world_community/",
          "author": null,
          "description": "Total run time: 1,381 years 61 days -- World Community Grid Homelab team stats for Saturday, 1/6/2023\n  \nCurrent Members 240 (#34 in the world)\n Total Run Time (y:d:h:m:s) (Rank) 1381:061:14:51:06 (#142)\n Points Generated (Rank) 2,365,216,572 (#126)\n Results Returned (Rank) 3,857,879 (#131)\n  \nHomelabbers who have joined the Homelab team and are processing datasets for World Community Grid are working on the following projects:\n  \n Project Points Generated Results Returned Total Run Time (y:d:h:m:s) \n  \n OpenPandemics - COVID-19 438,290,326 655,942 205:235:08:57:07 \n  Africa Rainfall Project 29,180,969 6,734 15:259:17:55:19 \n  Help Stop TB 2,624,907 1,068 1:237:01:20:12 \n  Mapping Cancer Markers 1,345,098,260 1,882,032 853:170:13:51:43 \n  Beta Testing 588,775 966 0:125:19:17:04 \n  Microbiome Immunity Project 233,228,063 555,814 126:303:09:50:12 \n  OpenZika 56,754,339 148,682 27:023:07:53:07 \n  FightAIDS@Home - Phase 2 75,951,773 100,228 50:357:19:14:52 \n  Outsmart Ebola Together 61,922,110 115,152 29:077:20:37:22 \n  FightAIDS@Home 4,068,979 67,396 2:152:07:48:41 \n  Smash Childhood Cancer 117,508,071 323,865 67:308:08:05:27 \n \n Join the Homelab team here: \n (if you already participate in World Community Grid)\n https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n (if you are new to World Community Grid)\n https://join.worldcommunitygrid.org?teamId=124DTPZ682\n Link to team statistics: https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n    submitted by    /u/homelabber12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/105aapg/total_run_time_1381_years_61_days_world_community/",
          "publishedOn": "2023-01-07T00:16:43.000Z",
          "wordCount": 14264,
          "title": "Total run time: 1,381 years 61 days -- World Community Grid Homelab team stats for Saturday, 1/6/2023",
          "imageUrl": "https://external-preview.redd.it/wIj6ygk01ih8oIHxFRQ6FPPWByQkwZHSYkhAwFSPi5g.jpg?auto=webp&s=695923a3c1648c33a1135adf2092e5d80a1fa37d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1059sj2/is_unsupported_the_same_as_incompatible/",
          "author": null,
          "description": "I want to install an INTEL XEON E3-1245v6 into my HP ML-30 Gen9 to take advantage of Quicksync. \n It is not listed as a \"supported\" part but I have so far manage to install other unsupported parts (HBA, nvme, NIC). \n This begs the question: Will it be compatible?\n    submitted by    /u/I-make-ada-spaghetti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1059sj2/is_unsupported_the_same_as_incompatible/",
          "publishedOn": "2023-01-06T23:56:08.000Z",
          "wordCount": 14985,
          "title": "Is \"unsupported\" the same as incompatible?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1058ddw/synology_diskstation_vs_rackstation/",
          "author": null,
          "description": "Hello! n00b here wondering why Synology DS products are so much more popular than RS?\n Even for users with server racks, they put a DS on a shelf instead of installing an RS? Why? Cost?\n Thanks\n    submitted by    /u/Any_Coffee3661  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1058ddw/synology_diskstation_vs_rackstation/",
          "publishedOn": "2023-01-06T22:58:17.000Z",
          "wordCount": 14165,
          "title": "Synology DiskStation vs RackStation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10573s0/my_first_super_micro_motherboard_not_a_bad_find/",
          "author": null,
          "description": "submitted by    /u/Lgfromie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10573s0/my_first_super_micro_motherboard_not_a_bad_find/",
          "publishedOn": "2023-01-06T22:08:13.000Z",
          "wordCount": 15289,
          "title": "My first Super micro motherboard: not a bad find for $10",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1056tz6/thy_hole_is_prepared_for_a_new_server/",
          "author": null,
          "description": "So it's ready for microserver number 2.\n Also some minor updates:\n a) 2nd patch panel added and cabled b) Work shelf (dell optiplex & meraki) created c) Moved nucs down\n    submitted by    /u/discop3t3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1056tz6/thy_hole_is_prepared_for_a_new_server/",
          "publishedOn": "2023-01-06T21:58:05.000Z",
          "wordCount": 14701,
          "title": "Thy hole is prepared (for a new server)",
          "imageUrl": "https://preview.redd.it/73z4dqlndjaa1.png?auto=webp&s=6623fedaa965d343a8b88de1e04c6247bc50433e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1056tts/first_foray_into_a_1u_server/",
          "author": null,
          "description": "submitted by    /u/NonToxic628  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1056tts/first_foray_into_a_1u_server/",
          "publishedOn": "2023-01-06T21:57:55.000Z",
          "wordCount": 14570,
          "title": "First foray into a 1U server",
          "imageUrl": "https://external-preview.redd.it/u2B-0hRiKrcv6mZsIWpnFJd0Z-kSG61kaPXWyd4w9iY.png?format=pjpg&auto=webp&s=1a4e49c2dd1a1b25e31f45a3a76fa7c04e5985c3"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10563qd/apache_server_not_starting_with_error_ah00072/",
          "author": null,
          "description": "Hey y’all! So i started building my homelab and have the first part of it built but i’m having trouble on one part. I’m setting up a LAMP stack on a vm ubuntu server but unfortunately when installing apache2 and checking systemctl, I get the error “AH00072: make_sock: could not bind to address 0.0.0.0:80”. I’ve tried editing the config file but it doesn’t change anything. any help is GREATLY appreciated. Thank you so much!\n    submitted by    /u/Hshshshhf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10563qd/apache_server_not_starting_with_error_ah00072/",
          "publishedOn": "2023-01-06T21:29:08.000Z",
          "wordCount": 15594,
          "title": "Apache Server not starting with error AH00072?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1055dfd/ill_see_your_bookshelf_build_and_raise_you_a_6u/",
          "author": null,
          "description": "submitted by    /u/ZenAdm1n  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1055dfd/ill_see_your_bookshelf_build_and_raise_you_a_6u/",
          "publishedOn": "2023-01-06T21:00:23.000Z",
          "wordCount": 15117,
          "title": "I'll see your bookshelf build and raise you a 6u bookcase build. [details in comments]",
          "imageUrl": "https://external-preview.redd.it/OM_SzbOE-Z1LQzdQkdWKNOr9rAl1mDTsFDh87Jyo2t8.png?format=pjpg&auto=webp&s=04ce32494146a87d3578244e69b3aaee72cd2235"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10557f6/got_a_nice_cpu_upgrade_to_my_home_server_time_to/",
          "author": null,
          "description": "submitted by    /u/-Zimeon-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10557f6/got_a_nice_cpu_upgrade_to_my_home_server_time_to/",
          "publishedOn": "2023-01-06T20:54:03.000Z",
          "wordCount": 14421,
          "title": "Got a nice CPU upgrade to my home server ^.^ Time to give those VMs the vCPUs they deserve!",
          "imageUrl": "https://preview.redd.it/dz6mpt1fkhaa1.png?auto=webp&s=149d87201193094cb5e70c2beb9d0bc2d049a748"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1053p17/vlans_through_unmanaged_switch/",
          "author": null,
          "description": "Hi, all.\n I would like to utilize the power of wifi6 in my new network setup. I am therefore looking to buy 3 pieces of TP-Link EAP670.\n It has 2.5Gb port with PoE.\n I'd like to setup multiple SSIDs linked to specific VLANs.\n But, as much as I am looking around, I cannot find reasonably-priced 2.5GbE switch with management.\n I found a lot without management, though.\n Is it possible to pass through VLAN tags through unmanaged switch?\n The idea would be to plug the WiFi APs to some relatively cheap TrendNet or NetGear switch and from that switch I would grab the traffic to my Zyxel managed switches.\n But if the tagged packets do not get through, this makes little sense...\n Anyone can advise if this is possible?\n    submitted by    /u/sancho_sk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1053p17/vlans_through_unmanaged_switch/",
          "publishedOn": "2023-01-06T19:54:36.000Z",
          "wordCount": 16994,
          "title": "VLANs through unmanaged switch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104z9t3/proxmox_arm_running_on_the_orange_pi_5_with_nvme/",
          "author": null,
          "description": "submitted by    /u/TheWingsOfWar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104z9t3/proxmox_arm_running_on_the_orange_pi_5_with_nvme/",
          "publishedOn": "2023-01-06T17:00:38.000Z",
          "wordCount": 16061,
          "title": "Proxmox ARM running on the Orange Pi 5 with NVMe!",
          "imageUrl": "https://external-preview.redd.it/8bL0TF7GRmRrSyxYVjRMwWZk6nJ-BrIMbVUc15-4X7g.jpg?auto=webp&s=0619a7d8978889bd6af9d9b28b8ae604395dc65e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104xoiu/1u_but_its_the_bookshelf/",
          "author": null,
          "description": "submitted by    /u/arccookie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104xoiu/1u_but_its_the_bookshelf/",
          "publishedOn": "2023-01-06T15:57:51.000Z",
          "wordCount": 15379,
          "title": "1U, but it's the bookshelf",
          "imageUrl": "https://preview.redd.it/8h7trkhl3gaa1.jpg?auto=webp&s=b5fd91314b8bae85abc3f207f01c5f1d2e0bf95b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104wwga/adventures_in_unpopular_hypervisors/",
          "author": null,
          "description": "First, the background. I run a small in size, medium in scale home server environment on five Lenovo Tinys and an HP Microserver Gen10 Plus. I have two different requirements I try, but often fail, to keep segregated - one is self hosting the 35-40 containers it apparently takes to operate my home environment, and the other is a home lab. My job is technical strategy and thus my technical knowledge is more broad than deep, so I would rate myself as a below average sysadmin and I copy-and-edit rather than write the code. I'm also keen that this doesn't take over my life - I have a job already - so when I work on my home systems I want 90+% of the time to be fun and learning, not administration and troubleshooting just to keep the whole edifice running.\n About three years ago a series of glo…",
          "link": "https://www.reddit.com/r/homelab/comments/104wwga/adventures_in_unpopular_hypervisors/",
          "publishedOn": "2023-01-06T15:26:02.000Z",
          "wordCount": 23369,
          "title": "Adventures in \"unpopular\" hypervisors",
          "imageUrl": "https://external-preview.redd.it/pvr9JVEQlkHLPUZ6Jgt4X5luBUIileAu2xFVxvhiViI.jpg?auto=webp&s=abbb1beec54b217c83ea4b672e95e268f75df5a5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104qwkp/under_desk_homelab/",
          "author": null,
          "description": "submitted by    /u/Cry_Wolff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104qwkp/under_desk_homelab/",
          "publishedOn": "2023-01-06T10:30:22.000Z",
          "wordCount": 15004,
          "title": "Under desk homelab",
          "imageUrl": "https://external-preview.redd.it/rfuB10oqgEU5qKf0JAD0-zNAc5SYAOjqiG45wh8oObs.jpg?auto=webp&s=8f258b9534e1efe8e61b24ca3e22332599f48535"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104ois8/i_said_ill_be_getting_a_rack_this_year_and_i_did/",
          "author": null,
          "description": "submitted by    /u/sniff122  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104ois8/i_said_ill_be_getting_a_rack_this_year_and_i_did/",
          "publishedOn": "2023-01-06T08:01:40.000Z",
          "wordCount": 15951,
          "title": "I said I'll be getting a rack this year, and I did",
          "imageUrl": "https://preview.redd.it/tzx3ev0g8faa1.jpg?auto=webp&s=ceaa7e8ec7fc4cb9dc482919c21d6c300a046c5c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104n4pb/custom_active_hhhl_cooler_for_nvidia_p4/",
          "author": null,
          "description": "submitted by    /u/snake-robot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104n4pb/custom_active_hhhl_cooler_for_nvidia_p4/",
          "publishedOn": "2023-01-06T06:37:50.000Z",
          "wordCount": 15583,
          "title": "Custom Active HHHL Cooler For Nvidia P4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104jx7c/time_to_cluster/",
          "author": null,
          "description": "submitted by    /u/samiamdz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104jx7c/time_to_cluster/",
          "publishedOn": "2023-01-06T03:52:11.000Z",
          "wordCount": 14549,
          "title": "Time to Cluster",
          "imageUrl": "https://preview.redd.it/y5b72o0yzdaa1.jpg?auto=webp&s=c6594b9d9e48c1323726d927aa5304fb240645d7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104jsw5/budget_diy_ikea_build/",
          "author": null,
          "description": "submitted by    /u/So_Dodgy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104jsw5/budget_diy_ikea_build/",
          "publishedOn": "2023-01-06T03:46:24.000Z",
          "wordCount": 14904,
          "title": "Budget DIY Ikea build",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104idsw/update_to_the_whole_home_virtual_kvm_it_lives/",
          "author": null,
          "description": "submitted by    /u/Johnny1070  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104idsw/update_to_the_whole_home_virtual_kvm_it_lives/",
          "publishedOn": "2023-01-06T02:40:25.000Z",
          "wordCount": 16624,
          "title": "UPDATE to the whole home Virtual KVM. IT LIVES!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104i734/m2_nvenc_accelerator/",
          "author": null,
          "description": "submitted by    /u/PyrrhicArmistice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104i734/m2_nvenc_accelerator/",
          "publishedOn": "2023-01-06T02:31:57.000Z",
          "wordCount": 16016,
          "title": "M.2 NVENC Accelerator",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104frds/introducing_homelabapi_v01_a_selfhosted_api_that/",
          "author": null,
          "description": "Long story short, I have my own personal API I use for various things, and I realized one day that a whole bunch of my endpoints were homelab related. For organization sake, I thought it might be good to split the homelab endpoints out to their own API. I then thought, \"I wonder if any other homelabbers would be interested in this?\", and here we are.\n Some more information from the README...\n ---\n What is HomelabAPI?\n HomelabAPI is a self-hosted API that you can use to consolidate all of your homelab notifications and other outputs. This allows you to use HomelabAPI as your central input/output hub, and if you ever want to change where your homelab outputs go, it's just a matter of updating your HomelabAPI configuration.\n For example, let's say that you have all of your Home Assistant, Syn…",
          "link": "https://www.reddit.com/r/homelab/comments/104frds/introducing_homelabapi_v01_a_selfhosted_api_that/",
          "publishedOn": "2023-01-06T00:45:59.000Z",
          "wordCount": 15272,
          "title": "Introducing HomelabAPI v0.1 - A self-hosted API that you can use to consolidate all of your homelab notifications and other outputs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104fr8n/kids_room_is_hot_remote_workstation_displays_and/",
          "author": null,
          "description": "TL:DR - 2 gaming rigs in bedroom put out massive heat and I want to move them to my 'Server Room' with my rack and need suggestions to connect their IO devices over 75ft. I have seen the ICON USB Ravens (at $1200 each - Nope) and Optical Displayport cables. Was wondering if anyone has seen a device that runs over Fiber with Single in/Single out 'KVM' for remote workstations.\n Full Story:\n My 16 yo and 12 yo each have decent gaming rigs in their shared bedroom (R5 5600x's, RX6800's, Samsung G5 32in 1440P curved displays and secondary 24in 108P portrait displays for each). Been monitoring Home Assistant and even shut off the damper for HVAC going to their room and it gets HOT in there. Ecobee remote sensor shows 78-80 with the ceiling fan on and door open over Christmas break (again with no HVAC input). The rest of the rooms with sensors show 69-71 with the Ecobee set to 70. In NE Ohio so during the winter I guess its manageable but in the summer its near unbearable.\n What I would like to do is move their towers both down to my 'Server Room' (converted fruit cellar in the basement) with my rack and core infrastructure. House is wired with 6A in the walls but I did put conduit in with pull strings to the attic so pulling OM4 to their workstations isn't out of reach. Also since these are gaming rigs and not productivity workstations, would like to keep high refresh rate and low latency. (One can dream - right?)\n Thin clients may work with something light weight - but would rather local connection and not have to go out of the internal net (Looking at you Parsec).\n I'm guessing most of us manage gear over IMPI/SSH/Web interfaces but figured someone somewhere may have rack mounted their PC and is doing something similar to what I am trying to do.\n Thanks for any and all suggestions!\n    submitted by    /u/boom3198  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104fr8n/kids_room_is_hot_remote_workstation_displays_and/",
          "publishedOn": "2023-01-06T00:45:48.000Z",
          "wordCount": 14711,
          "title": "Kid's room is HOT! Remote Workstation Displays and USB Help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104fewr/r730xd_w_h730p_how_to_pass_thru_or_get_into_hba/",
          "author": null,
          "description": "Howdy HomeLabbers!\n I received a Dell R730XD with the H730P RAID controller today. I want to run ProxMox and then a bunch of stuff on top (TrueNAS, VMs, etc, etc)\n When I received it it was configured with 2 virtual disks (boot = 6TB, storage = 60TB)\n I have installed ProxMox on the boot \"array\", however I cannot see the \"storage\" array. In my research I have found that apparently ProxMox and other systems do not like hardware RAID controllers. \n Any suggestions on the path forward? It seems I can turn the controller \"off\" making it a \"dumb\" HBA--where would I find information on that topic? I havent been able to locate it.\n Can I delete the 60TB virtual disk and still boot via the 6TB array? IM ok with doing that if I have to \"pass through\" the individual disks...if that will even work.\n Any thoughts or suggestions would be greatly appreciated.\n    submitted by    /u/Adv4n6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104fewr/r730xd_w_h730p_how_to_pass_thru_or_get_into_hba/",
          "publishedOn": "2023-01-06T00:31:16.000Z",
          "wordCount": 14325,
          "title": "R730XD w/ H730P - How to pass thru or get into HBA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104f1w2/hp_elitedesk_800_g4_desktop_mini_65w_hp_fiber_nic/",
          "author": null,
          "description": "Hi,\n According to HP documentation, there is a HP Fiber NIC Port Flex IO expansion card (Part Number \"3TK73AA\")\n https://www8.hp.com/h20195/v2/GetDocument.aspx?docname=c06042607\n ​\n https://preview.redd.it/sn0jgfusfbaa1.png?width=587&format=png&auto=webp&s=83e76c23ee8b8430cc8a2c72ebccf3a84dffd297\n Questions :\n  \nWhich data rate can I expect with this module ?\n Which model of SFP do I have to choose to have a good compatibility ?\n The PCIe data rate is 40Gb/s, right ?\n  \nThanks\n    submitted by    /u/hafx_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104f1w2/hp_elitedesk_800_g4_desktop_mini_65w_hp_fiber_nic/",
          "publishedOn": "2023-01-06T00:15:56.000Z",
          "wordCount": 14851,
          "title": "HP EliteDesk 800 G4 Desktop Mini (65W) - HP Fiber NIC Port Flex IO Upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104eygk/i_need_the_communities_oppinion_on_my_new_setup/",
          "author": null,
          "description": "https://preview.redd.it/92kustqxebaa1.png?width=2121&format=png&auto=webp&s=52b379be702cdb0b5178c8845036aa6c95647098\n There are most likely things missing, or that will be added in future.\n ​\n Justification for the media servers running on windows server, that specific VM will have a gpu passed through for OBS and I would like to accelerate transcoding for media server stuff with a gpu.\n Any ideas or reccomendations would be great!\n    submitted by    /u/Peewee_Doggi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104eygk/i_need_the_communities_oppinion_on_my_new_setup/",
          "publishedOn": "2023-01-06T00:12:01.000Z",
          "wordCount": 14159,
          "title": "I need the communities oppinion on my new Setup, not built yet but any feedback would be great.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104euje/is_there_a_display_port_adapter_i_can_buy_that/",
          "author": null,
          "description": "I got 2 Samsung Odessy G9s stacked 1 on top of the other (they are 5k super ultrawide screens). I would like to use Nvidia Surround in order to combine the screens together into 1 super duper screen for when I play games. Problem is there is a giant bezel in the middle. I can physically flip 1 of the screens 180 degrees but nvidia surround does not allow me to flip only a single screen and combine them together (trust me, I've tried everything). \n ​\n Is there some kind of adapter/box I can get that lets me flip the output before it hits the screen? \n ​\n And before you comment \"why didn't u just get the Odessy Arc, its cus the pixel density on that thing sucks and this rig is primarily for video editing which benefits workflow-wise from having it set up as 2 physical separate screens.\n ​\n Thank you.\n    submitted by    /u/NepNep_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104euje/is_there_a_display_port_adapter_i_can_buy_that/",
          "publishedOn": "2023-01-06T00:07:30.000Z",
          "wordCount": 14700,
          "title": "Is there a display port adapter I can buy that intercepts the video connection and lets me flip it 180 degrees?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104d73g/what_processor_can_i_upgrade_this_to/",
          "author": null,
          "description": "submitted by    /u/htims05  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104d73g/what_processor_can_i_upgrade_this_to/",
          "publishedOn": "2023-01-05T23:01:41.000Z",
          "wordCount": 14723,
          "title": "What processor can I upgrade this to?",
          "imageUrl": "https://preview.redd.it/8hs1dzkj2baa1.png?auto=webp&s=d3a924827c472c9ca8b6b235103e4256a61a1142"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104d22t/hpe_dl560_g8_ssd_upgrade/",
          "author": null,
          "description": "I've got an HP DL560 G8 with 5 x 480GB SSDs in a hardware raid and I'm considering wiping the system and reinstalling everything to move toward a Proxmox server instead. Currently it has a single SABRENT 4TB NVME scratch (our numerical models like fast writes of temp files) on a Highpoint SSD7101A-1 NVMe 4-Port card. I'm thinking of putting two SABRENT 512GB NVMEs in it for the OS (can Proxmox boot from the Highpoint?) and upgrading the 480GB SSDs to something much larger as a storage drive for everything else. What SSDs can I put in the system? Can I just get off the shelf Western Digital 2.5\" 2TB SSDs and put them in the existing caddies?\n    submitted by    /u/NormalCriticism  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104d22t/hpe_dl560_g8_ssd_upgrade/",
          "publishedOn": "2023-01-05T22:56:29.000Z",
          "wordCount": 14239,
          "title": "HPE DL560 G8 SSD upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104cssx/look_at_what_im_taking_home/",
          "author": null,
          "description": "submitted by    /u/ZEROPOINTBRUH  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104cssx/look_at_what_im_taking_home/",
          "publishedOn": "2023-01-05T22:46:22.000Z",
          "wordCount": 14431,
          "title": "Look at what i'm taking home",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104axrz/has_anyone_used_a_dell_r810_server_as_a_game/",
          "author": null,
          "description": "This one has 256Gb of RAM and 4 x Xeon processors. I thought about putting my GeForce graphics card in it to use with XPlane. Has anyone done this or something si.ilar?\n    submitted by    /u/Empty-Ad5820  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104axrz/has_anyone_used_a_dell_r810_server_as_a_game/",
          "publishedOn": "2023-01-05T21:35:37.000Z",
          "wordCount": 14671,
          "title": "Has anyone used a Dell R810 server as a game machine?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1049jwt/proxmox_regular_hdd_access/",
          "author": null,
          "description": "I've been using dstat to check my drive usage to see if it would be feasible to have them spin down (if you want to comment on this then see my other recent post in here).\n I'm not using LVM for anything as Proxmox is installed onto a ZFS mirror and I've already added each drive to the global_filter in /etc/lvm/lvm.conf, which should prevent vgscan from accessing those drives.\n However I'm still getting regular activity on all my drives. One set of accesses happen at ~15 minute intervals, which appears to read ~247 bytes from each drive. The other set of accesses occur at ~30 minute intervals and read a mere 26 bytes per drive.\n For info, I've got 3 separate storage pools. rpool is a single mirror vdev and contains the proxmox install. Both drives are SSD's and I don't care about the activity here so they aren't included in the dstat output below.\n I've then got tank1 which is a single mirror vdev, made up of sdi and sdj. I've then got tank2 which is a single raidz2 vdev and contains sde, sdf, sdg, sdh, sdk, and sdl.\n Does anyone know what might be causing the regular access? and more importantly how to prevent it?\n  ----system---- --total-cpu-usage-- --dsk/sdi-- --dsk/sdj-- --dsk/sde-- --dsk/sdf-- --dsk/sdg-- --dsk/sdh-- --dsk/sdk-- --dsk/sdl-- -net/total- ---paging-- ---system-- time |usr sys idl wai stl| read writ: read writ: read writ: read writ: read writ: read writ: read writ: read writ| recv send| in out | int csw 05-01 19:10:16| 2 1 95 2 0| 749M 1029M: 617M 1029M: 111M 436M: 134M 436M: 121M 435M: 128M 436M: 144M 435M: 141M 437M| 0 0 | 0 0 | 80M 231M 05-01 19:11:16| 1 1 98 0 0| 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 | 29M 18M| 0 0 | 11k 30k 05-01 19:12:16| 1 1 98 0 0| 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 | 29M 18M| 0 0 | 10k 28k 05-01 19:13:16| 1 1 98 0 0| 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 | 29M 18M| 0 0 | 10k 28k 05-01 19:14:16| 1 1 98 0 0| 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 | 30M 18M| 0 0 | 10k 28k \n    submitted by    /u/0x30313233  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1049jwt/proxmox_regular_hdd_access/",
          "publishedOn": "2023-01-05T20:42:04.000Z",
          "wordCount": 16049,
          "title": "Proxmox Regular HDD access",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1049hhy/power_data_and_cable_management_arms/",
          "author": null,
          "description": "So standard wisdom is to run a CMA up one side of your rack and data and networking up and down the other side of the rack. It is known. This is the way. So uh, obviously if you're pulling your servers out twice a month for quick hardware swaps, upgrades, tweaks, and cleaning, like I do, you'll be using cable management arms to make sure your cables don't get splinched in the slide. Pretty basic stuff here. Now the real question. If you mount, say, all your power cables on the hinge side, and your data cables on the latch side, whichever side you mount your CMA on will have to have either power or data cables run across the rear of the rack to the CMA opening around back. What do you do about that awkward run of power or data across the rear of the rack over to the CMA ? Seems quite ugly to just have a bundle of cables all the way across. What's the correct or intended way to manage that awkward run from side to side?\n    submitted by    /u/AsYouAnswered  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1049hhy/power_data_and_cable_management_arms/",
          "publishedOn": "2023-01-05T20:39:21.000Z",
          "wordCount": 15866,
          "title": "Power, Data, and Cable Management Arms?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1049eg0/i_present_disc_mongerenstein/",
          "author": null,
          "description": "submitted by    /u/TheMatchlighter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1049eg0/i_present_disc_mongerenstein/",
          "publishedOn": "2023-01-05T20:35:58.000Z",
          "wordCount": 15487,
          "title": "I Present: Disc Monger-enstein",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10498u1/what_kind_of_container_stack_are_you_running/",
          "author": null,
          "description": "I finally setup my homelab and want to get into containers. Are you all running k8s, Rancher, Nomad..etc or just using docker cli? What other tools are you using (preferably free lol) to scan the containers for vulnerabilities? Any other tips and advice would be appreciated!\n    submitted by    /u/GetYourShitT0gether  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10498u1/what_kind_of_container_stack_are_you_running/",
          "publishedOn": "2023-01-05T20:30:07.000Z",
          "wordCount": 16740,
          "title": "What kind of container stack are you running?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10492dd/to_spin_down_or_not/",
          "author": null,
          "description": "In my quest to further reduce the power bill for my home lab I'm considering the merits of configuring my HDDs to spin down after a while.\n I've listed what I think are the pros and cons below, but I'm interested to hear others views on the subject.\n Pros\n  \nCost saving in electricity. Potentially several W per drive, which adds up when you've got 10+ of the things.\n Slightly reduced noise when drives aren't spinning (not an issue for me)\n  \nCons\n  \nPotential for reduced life span of drives = increased cost in replacing drives (need replacing more often)\n Increased latency when accessing files when drives have spun down (not an issue for me)\n  \nHave I missed anything and how much should I really be concerned with reducing the life span by spinning the drives down?\n    submitted by    /u/0x30313233  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10492dd/to_spin_down_or_not/",
          "publishedOn": "2023-01-05T20:23:07.000Z",
          "wordCount": 16573,
          "title": "To spin down or not",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/104886h/proxmox_use_case/",
          "author": null,
          "description": "Hi guys,\n I am fairly new to the homelabe community. \n Thanks to you guys and your effort I was able to implement a small homeserver on a Raspberry Pi 4 running a VPN server, Jellyfin and SMB/CIF shares. Also I am proud of my backup strategy which is a bash script with rsync mirroring all my data on my shares to a Windows drive on my desktop, which I shared on my network.\n So thank you all!\n ​\n But now I want to go further and tinker around with Proxmox. I might also have a use case for a friend of mine:\n He started a small engineering firm, so naturally he's a little tighter on cash.\n We are a small team (yes, I also work there part-time in addition to my main job and support him in setting up), but sometimes have quite computationally intensive workloads.\n Currently we have one workstation, which is well equipped in terms of compute power, but as soon as someone works on it, the others have to wait. The hardware would be sufficient to run our workloads in parallel. Also working from remote is not possible due to that.\n Do you guys think it would be a good idea to set up Proxmox on this PC and create several VMs for each Application we have?\n We are also using AutoCAD. Is it possible to work from remote on the VM without having it lag all the time?\n Do you guys have some nice resources to get started with Proxmox?\n I already ordered an old and cheap Thinclient to tinker around ;) \n Thank you!\n    submitted by    /u/Dense-Barracuda-96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/104886h/proxmox_use_case/",
          "publishedOn": "2023-01-05T19:49:57.000Z",
          "wordCount": 16346,
          "title": "Proxmox use case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1043xtj/new_to_proxmox_usage_stats_seem_higher_then_vm/",
          "author": null,
          "description": "submitted by    /u/Mutated_Zombie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1043xtj/new_to_proxmox_usage_stats_seem_higher_then_vm/",
          "publishedOn": "2023-01-05T16:59:40.000Z",
          "wordCount": 16278,
          "title": "New to proxmox, usage stats seem higher then vm reports?",
          "imageUrl": "https://preview.redd.it/m5d50bcy99aa1.png?auto=webp&s=2c27d556ad07a30d5fa814055417ef3bbce563f3"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1040jav/how_do_you_manage_ssl_certificates/",
          "author": null,
          "description": "I've got a few things on my network that require SSL certs for the same domain:\n  \nNGINX - I have letsencrypt set up on this VM and manually copy over certs from here to my other devices that are not behind the reverse proxy.\n Synology NAS - pain to copy to this one, but doable.\n PFSense - again a pain to copy, but doable\n Proxmox - I've set up a script on my NGINX VM to copy over the certs.\n  \nI feel like there is a better way to do this - any suggestions?\n    submitted by    /u/breakslow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1040jav/how_do_you_manage_ssl_certificates/",
          "publishedOn": "2023-01-05T14:40:48.000Z",
          "wordCount": 18467,
          "title": "How do you manage ssl certificates?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103zt1g/homelab_suggestions_lowpowered_new_1u2u_esxible/",
          "author": null,
          "description": "i would like to renovate my homelab (1265Lv2, 2680v2, 2680v4 etc) and i was wondering if there is something similar to my current laptop that can suits well the job.\n In my dreams i'd like a 2U 5700u/h with 2 pci express slots with adequate lanes, a boot device and maybe 4 ddr4 slots.\n I understand that i can go with a regular ryzen, but i'd prefer a low powered version.\n Has anyone already found something interesting or relatable?\n    submitted by    /u/pulzpulz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103zt1g/homelab_suggestions_lowpowered_new_1u2u_esxible/",
          "publishedOn": "2023-01-05T14:08:47.000Z",
          "wordCount": 15451,
          "title": "Homelab Suggestions: Lowpowered , new, 1U/2U , esxi-ble, ryzen 5700u/h. Do they exist?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103z7eo/homelab_experience_on_resume/",
          "author": null,
          "description": "Do you guys put homelab experience on your resume (especially if it isn’t part of your day to day work like a Linux cluster when at work you only work on windows) or do you just mention it in the interview in passing?\n    submitted by    /u/H3raclius476  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103z7eo/homelab_experience_on_resume/",
          "publishedOn": "2023-01-05T13:40:46.000Z",
          "wordCount": 20231,
          "title": "Homelab Experience On Resume",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103vhtz/time_for_an_update_to_the_hardware_guide_on_the/",
          "author": null,
          "description": "I noticed that on the hardware page, the recommendations for things like CPUs and HBAs are somewhat out of date. Perhaps it's time for an update so that power use is given more attention and that it represents the current status quo?\n    submitted by    /u/0nn0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103vhtz/time_for_an_update_to_the_hardware_guide_on_the/",
          "publishedOn": "2023-01-05T10:14:09.000Z",
          "wordCount": 16205,
          "title": "Time for an update to the hardware guide on the wiki?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103loh7/what_is_better_for_an_8_disk_raid_samsung_860_evo/",
          "author": null,
          "description": "I'm looking to fill my 8 bay server with 8x 1TB SSD's. This is for a homelab and most of the storage will be given to family for nextcloud storage. \n I plan to transition all pc's in my house to small workbooks and tell everyone to vpn into their assigned VM but that's down the road when I know what I'm doing now. As for now I'm just looking to buy the right SSD for this venture and not have to re-do it later on when I know what I'm doing.\n    submitted by    /u/GUI-Discharge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103loh7/what_is_better_for_an_8_disk_raid_samsung_860_evo/",
          "publishedOn": "2023-01-05T01:32:17.000Z",
          "wordCount": 14099,
          "title": "What is better for an 8 disk raid - Samsung 860 evo OR Crucial MX500 OR other?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103lg0o/unifi_docker_controller_changelog/",
          "author": null,
          "description": "Been running the UniFi controller docker container, but am looking for a changelog for the controller and firmware updates for UBNT devices. Right now I have it excluded from auto updating in Watchtower so I can get a handle on changes. \n I know you Ubiquiti fellas are a passionate group, so hoping someone knows the scoop.\n    submitted by    /u/kars85  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103lg0o/unifi_docker_controller_changelog/",
          "publishedOn": "2023-01-05T01:21:51.000Z",
          "wordCount": 13977,
          "title": "UniFi Docker Controller Changelog?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103l82x/software_engineering_is_my_job_network/",
          "author": null,
          "description": "submitted by    /u/spazonator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103l82x/software_engineering_is_my_job_network/",
          "publishedOn": "2023-01-05T01:12:30.000Z",
          "wordCount": 14283,
          "title": "Software Engineering is my job & Network Engineering is my hobby",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103kxzb/virtualizing_all_my_pcs_in_a_server/",
          "author": null,
          "description": "I'm looking to create a VM server to virtualize all the machines in my house. I'd want to be able to create separate VMs for gaming, coding, media, etc. and then access them through thin clients place around the house. I have the money to rewire shit if I need to run fiber throughout the home or something. Where should I start to understand how to do that and what kind of hardware I would need? Is this even a good idea?\n    submitted by    /u/NotReallyFromTheUK  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103kxzb/virtualizing_all_my_pcs_in_a_server/",
          "publishedOn": "2023-01-05T01:00:32.000Z",
          "wordCount": 15373,
          "title": "Virtualizing all my PCs in a server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103kvu1/seeking_isolation_transformer_and_info/",
          "author": null,
          "description": "Is anyone using an isolation transformer? I think I will need 1, or 2, or 3 maybe across the house :-)\n I let one go many years ago regretfully. I'm trying to source one, but not sure where to look. I see plenty on ebay but the shipping is going to be expensive. any idea what kind of businesses to check or where to look?\n I have to temporarily put my home lab gear in the laundry room, but also I'm trying to solve a dirty generator voltage problem that my UPS devices are sensitive to.\n    submitted by    /u/BreakingNewsDontCare  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103kvu1/seeking_isolation_transformer_and_info/",
          "publishedOn": "2023-01-05T00:58:15.000Z",
          "wordCount": 14059,
          "title": "Seeking Isolation Transformer and Info.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103kmou/and_so_it_begins/",
          "author": null,
          "description": "submitted by    /u/GRIND2LEVEL  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103kmou/and_so_it_begins/",
          "publishedOn": "2023-01-05T00:47:04.000Z",
          "wordCount": 14318,
          "title": "And so it begins....",
          "imageUrl": "https://preview.redd.it/lmu1g9kzx5aa1.jpg?auto=webp&s=06893884c79f2760bf13de03cb0bfef7002c48b5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103kkho/managing_ssl_certificates/",
          "author": null,
          "description": "I am attempting to manage my homelab’s SSL certificates but its slowly getting out-of-hand because some of the things I add SSL to have built-in functionality (such as iLO4, AdGuard, etc.) while some require a reverse proxy (Proxmox, Uptime-Kuma).\n Right now I am trying to set up SSL and manage the certificates on:\n  \niLO4\n OPNsense\n Proxmox\n AdGuard\n Grafana\n Uptime Kuma\n TL-SG108E\n TL-EAP225\n  \nI’d use Cloudflare Tunnel only if it didn’t expose/route the pages to the outside world (I’d rather the pages only load if the requests are from my VLANs, instead of having to setup email pin-code etc.). That way I could put SSL on anything easily with Cloudflare acting as a reverse proxy \n What do y’all use to achieve this in your own homelabs?\n    submitted by    /u/Arszilla  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103kkho/managing_ssl_certificates/",
          "publishedOn": "2023-01-05T00:44:29.000Z",
          "wordCount": 14758,
          "title": "Managing SSL Certificates",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103kiiu/using_windows_server_as_a_hypervisor/",
          "author": null,
          "description": "Hi there folks, I’ve been using ESXi as my hypervisor for a few years now but my current server is no longer supported on the newest version so I’m looking into alternatives. \n I currently have several Windows Server VMs for AD, Exchange, SharePoint and a few other services and I have a Windows Server 2022 Datacenter license so I was considering using that as my hypervisor since it allows me to automatically license all Windows VMs, but I was wondering if that’s a viable option or if I’m better off sticking with ESXi 6.5 or maybe moving to a different hypervisor. \n To be honest the only advantage of using WS as a hypervisor is the unlimited licensed VMs but if the resources overhead is too high then I guess getting additional licenses for my VMs would be the best option.\n Any thoughts on that?\n    submitted by    /u/lovemac18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103kiiu/using_windows_server_as_a_hypervisor/",
          "publishedOn": "2023-01-05T00:42:06.000Z",
          "wordCount": 14526,
          "title": "Using Windows Server as a Hypervisor",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103jouj/my_homelab_setup/",
          "author": null,
          "description": "Here’s my current homelab setup:\n 1 - 2014 MacBook Pro 16Gb (running Home Assistant, Portainer, and K3S Master node cluster) 2 - Raspberry Pi 4 4gb ram(running as 2 working nodes for K3S cluster) 1 - Raspberry Pi Zero 2 W (running Octopi for a 3D printer) 1 - lenovo thinkcentre m700 intel i5-6500t 24gb ram (running Proxmox 7.3: Windows 11 VM only) with 128gb SSD and 1tb NVME for VM storage\n Running Home Assistant and Portainer on the MacBook Pro has been great and a perfect server to run the few docker services. \n I’ve been struggling with Kubernetes and feel like I’m not using is to it’s potential so the VM on the MacBook and the two RPis running the working nodes is a waste of hardware. Any ideas heree? Maybe I’ll need to dedicate them to a bare metal service of some sort.\n RPi Zero 2 W is perfect for my 3d printer. \n And now I have a Proxmox server running only Windows 11 but has so much more potential. \n I feel like I have the necessary hardware to run all my services and more but is not much tho. How would you change it and how can I push my hardware to the limits?\n    submitted by    /u/rrlara21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103jouj/my_homelab_setup/",
          "publishedOn": "2023-01-05T00:06:56.000Z",
          "wordCount": 14370,
          "title": "My homelab Setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103hg16/advice_on_rolling_home_setup_to_k3s_from_docker/",
          "author": null,
          "description": "Hi everyone, looking for a little bit of input on revamping my lab to go full k3s instead of doing docker (compose) per individual node like I am. I understand I could use docker swarm, but I really want to learn the Kubernetes side of things and with my hardware below I think k3s is (probably?) the right fit. \n Please review what I'm proposing below and see if anyone has recommendations/guidance, sees any pitfalls, or if this is just a bad idea due to over complexity. \n Goals\n Multi node HA cluster. I want to be able to actually do things with my machines (move them, offline something, etc.) without everything going hard down.\n Kubernetes! Gotta learn at some point.. \n  \nHardware Available\n  \n Hardware Architecture RAM Thread & Cores CPU Proposed OS \n  \n Raspberry Pi 3B v1.2 ARM v8 64-bit…",
          "link": "https://www.reddit.com/r/homelab/comments/103hg16/advice_on_rolling_home_setup_to_k3s_from_docker/",
          "publishedOn": "2023-01-04T22:38:21.000Z",
          "wordCount": 16082,
          "title": "Advice on rolling home setup to k3s from docker",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103hed8/establishing_an_asn_for_fun/",
          "author": null,
          "description": "Me and a friend are heavily interested in establishing an ASN, and pretty much owning are own part of the internet. Purely for the use of us self hosting applications, such as mail, but also to get the experience, and work with these large enterprises and backbones. We first want to have a solid plan before we invest into anything, which we mostly have, however before we pay the $500 some dollars to establish our ASN, we obviously want to have a IPv4 block first. Would anyone know a broker or dealer that could get us a IPv4 block, doesn’t even have to be a big block, we are shooting for a /25, but could also settle with anything lower then that as well, being such that someone could subnet a small block from a bigger block they own to us. I’ve been trying to do this for 4 years now, but am finally now ready to invest my full time and energy into this. Recently came a cross this article, which is pretty similar to what we are wanting to accomplish https://blog.thelifeofkenneth.com/2017/11/creating-autonomous-system-for-fun-and.html\n    submitted by    /u/iota-rip  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103hed8/establishing_an_asn_for_fun/",
          "publishedOn": "2023-01-04T22:36:22.000Z",
          "wordCount": 15993,
          "title": "Establishing an ASN for fun",
          "imageUrl": "https://external-preview.redd.it/E5F6u90l3sB2CyB6QUa3iPtAdlmehkYrS6Ju-7VHMLQ.jpg?auto=webp&s=1f018abc28fcb3ff54daf324815eb25d09ae888a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103h6ay/friendly_reminder_to_always_buy_a_bigger_rack/",
          "author": null,
          "description": "submitted by    /u/mattalat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103h6ay/friendly_reminder_to_always_buy_a_bigger_rack/",
          "publishedOn": "2023-01-04T22:28:04.000Z",
          "wordCount": 15453,
          "title": "Friendly reminder to always buy a bigger rack than you think you need. Got a 12U instead of 6U last summer and here we are today",
          "imageUrl": "https://preview.redd.it/g9snnqh795aa1.jpg?auto=webp&s=a81ff39a2ec198e01d336518d78d28dbae4306b5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103gi1g/48vdc_to_raspberry_pi4_power_supply_with_a/",
          "author": null,
          "description": "submitted by    /u/intrepid3xplorer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103gi1g/48vdc_to_raspberry_pi4_power_supply_with_a/",
          "publishedOn": "2023-01-04T22:02:21.000Z",
          "wordCount": 14151,
          "title": "48VDC to Raspberry PI4 power supply, with a stylish enclosure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103g718/reverse_proxy_for_homelab/",
          "author": null,
          "description": "Hi,\n i would like to use a domain in my home network to access all my different services on different ports.\n I have running proxmox with different containers and vms.\n Is it possible to setup an reverse proxy to route everything over a domain instead of the ips/hostnames? Also i wanna remap every services webinterface to port 80 or 443 with the reverse proxy.\n For example:\n pihole.mydomain.com instead of http://192.168.178.67/admin\n or\n proxmox.mydomain.com instead of https://192.168.178.2:8006\n Also everything should automatically route over https.\n This plan is only for my local home network. Nothing should be exposed.\n I read about nginx but i dont know how to setup especially with pihole running. Do you guys know any good video on youtube or a good tutorial on any blog?\n THX\n    submitted by    /u/Past-Sky3552  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103g718/reverse_proxy_for_homelab/",
          "publishedOn": "2023-01-04T21:50:47.000Z",
          "wordCount": 15308,
          "title": "Reverse Proxy for HomeLab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103fyua/unifi_lack_rack_build/",
          "author": null,
          "description": "submitted by    /u/achosid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103fyua/unifi_lack_rack_build/",
          "publishedOn": "2023-01-04T21:41:43.000Z",
          "wordCount": 14221,
          "title": "Unifi Lack Rack Build",
          "imageUrl": "https://preview.redd.it/zlfo1jmdj3aa1.jpg?auto=webp&s=c2da3c80c8e2359903f5b5c5971bd72c71b9fe7f"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103fn31/my_homelab_see_picture_2/",
          "author": null,
          "description": "submitted by    /u/liamhildebrand  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103fn31/my_homelab_see_picture_2/",
          "publishedOn": "2023-01-04T21:29:27.000Z",
          "wordCount": 15025,
          "title": "My homelab (see picture 2)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103dlmu/whats_a_good_freecheap_monitoring_software/",
          "author": null,
          "description": "I currently use Pulseway and I love it, but I'm expanding my homelab from just the two systems on the free license and I want to be able to add all my VMs and such. To my knowledge, Pulseway isn't fairly cheap after the free license.\n I'd prefer something that has a good GUI on the web or an iOS app. I don't really require anything more than that. Remote access would be a plus, but it's not required since I can use TeamViewer to my PC and then RDP to the rest if needed.\n    submitted by    /u/Th3MadCreator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103dlmu/whats_a_good_freecheap_monitoring_software/",
          "publishedOn": "2023-01-04T20:10:42.000Z",
          "wordCount": 15005,
          "title": "What's a good free/cheap monitoring software?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103azzo/2022_homelab_progression/",
          "author": null,
          "description": "submitted by    /u/jackmcconnell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103azzo/2022_homelab_progression/",
          "publishedOn": "2023-01-04T18:30:38.000Z",
          "wordCount": 15106,
          "title": "2022 Homelab progression",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1038s75/what_is_the_best_wireless_security_equipment_free/",
          "author": null,
          "description": "Any good FOSS security equipment for both indoors and outdoors and that works on Debian/Linux? I want to setup my home with security but can't justify paying $150-350 and then a subscription for some of these cameras.\n    submitted by    /u/EuropiumNeptune  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1038s75/what_is_the_best_wireless_security_equipment_free/",
          "publishedOn": "2023-01-04T17:05:37.000Z",
          "wordCount": 15110,
          "title": "What is the best wireless security equipment? Free and Open source?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10381hv/online_backup_storage_within_the_eu/",
          "author": null,
          "description": "I have 2.5Tb of backup data that I want to store as cold data either cloudbased or at a hosting provider, what are the most affordable solutions to this within the EU?\n    submitted by    /u/celzo1776  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10381hv/online_backup_storage_within_the_eu/",
          "publishedOn": "2023-01-04T16:36:44.000Z",
          "wordCount": 15945,
          "title": "Online backup storage within the EU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103685g/moved_my_homelab_to_new_apartment/",
          "author": null,
          "description": "submitted by    /u/TiresomeLime  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103685g/moved_my_homelab_to_new_apartment/",
          "publishedOn": "2023-01-04T15:23:23.000Z",
          "wordCount": 16093,
          "title": "Moved my homelab to new apartment",
          "imageUrl": "https://preview.redd.it/9uk62gprn1aa1.jpg?auto=webp&s=47a34e314af61f2a234493f8af539e61d6af0c94"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/103543a/kubernetes_or_docker_to_make_two_pis_work_as_one/",
          "author": null,
          "description": "Hello everybody,\n I ended up getting two Raspberry Pi 4 4GB for Christmas and wanted to turn them into a homelab for things like WordPress, PiHole, etc. and was wondering whether I should start off with Kubernetes or Docker, because my goal is to make the two pis work together to handle the services I plan to run. I'm new to all of this so I just wanted to get a basic game plan going before I end up breaking these things.\n    submitted by    /u/Shortstack_Sean98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/103543a/kubernetes_or_docker_to_make_two_pis_work_as_one/",
          "publishedOn": "2023-01-04T14:35:06.000Z",
          "wordCount": 15838,
          "title": "Kubernetes or Docker to make two Pi's work as one",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1034mil/question_where_can_i_buy_a_4u_case_schematic/",
          "author": null,
          "description": "Hello everyone. I'm looking forward to build my rack but I want to put my everyday PC on it. I've been looking everywhere for a 4u rack case with good airflow but: \n - There are not many options for server cases on Brazil\n - Not everyone ships to Brazil. When they do, it's 5x the case's price\n ​\n So I'm inclined to fabricate one (not me, someone specialized). Where can I buy the schematics for an 4u case? Apparently Protocase have a design service, is there other options which I'm not aware of? Thanks in advance.\n    submitted by    /u/Facones  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1034mil/question_where_can_i_buy_a_4u_case_schematic/",
          "publishedOn": "2023-01-04T14:12:38.000Z",
          "wordCount": 15205,
          "title": "[Question] Where can I buy a 4u case schematic?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102vk0s/wired_network_build/",
          "author": null,
          "description": "submitted by    /u/sourdough_pizza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102vk0s/wired_network_build/",
          "publishedOn": "2023-01-04T05:54:28.000Z",
          "wordCount": 15419,
          "title": "wired network build",
          "imageUrl": "https://preview.redd.it/p259z8qxb0aa1.jpg?auto=webp&s=0beb4eebba57a79f528ee27115fd85b9ae21fc63"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102ptzl/i_dont_understand_zfs/",
          "author": null,
          "description": "I got a weird problem.\n Zfs on proxmox reports 1.32TB usage, when I do \"zfs list\" it says allocated 1TB (57% capacity)\n The problem I have is with my nextcloud instance, I don't know who is wrong.\n I have a ubuntu container with 900GB assigned from my zfs array. Proxmox says that CT Volume is 966GB, no big issue. Inside nextcloud, the max capacity somehow is 686GB? how did it manage to lose over 250GB? Who is wrong? zfs/proxmox showing a wrong assigned value? nextcloud displaying a wrong value limiting the entire instance? me?\n    submitted by    /u/JoaGamo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102ptzl/i_dont_understand_zfs/",
          "publishedOn": "2023-01-04T01:21:10.000Z",
          "wordCount": 14137,
          "title": "I don't understand zfs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102pi77/has_anyone_upgraded_their_ups_with_lifepo4/",
          "author": null,
          "description": "Edit: Did you have to beef up the inverter and charger, or is it a simple battery swap? \n Looking to increase the run time of a Triplite SMART1500LCD. I noticed it had a mode on the LCD that said “External Battery,” but I couldn't find what that meant.\n    submitted by    /u/EAW_astro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102pi77/has_anyone_upgraded_their_ups_with_lifepo4/",
          "publishedOn": "2023-01-04T01:06:53.000Z",
          "wordCount": 15527,
          "title": "Has anyone upgraded their UPS with LiFePO4 batteries?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102phwi/configure_ubuntu_remote_access_via_ssh/",
          "author": null,
          "description": "I have a microdesktop that I installed Ubuntu on with the intention to get better at Linux and tinker. While setting it up I configured it such that I can SSH into it and I thought that I set it up for remote access to the GUI. Now I'm remote and while I can SSH into it, I found that I can't pull up the GUI through Guacamole. Is it possible to configure VNC or RDP via SSH?\n    submitted by    /u/t_shaped_interests  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102phwi/configure_ubuntu_remote_access_via_ssh/",
          "publishedOn": "2023-01-04T01:06:31.000Z",
          "wordCount": 14110,
          "title": "Configure Ubuntu remote access via SSH.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102kqxu/my_home_labtemporarily/",
          "author": null,
          "description": "submitted by    /u/HardenedContainer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102kqxu/my_home_labtemporarily/",
          "publishedOn": "2023-01-03T21:56:26.000Z",
          "wordCount": 14310,
          "title": "My home lab(temporarily)",
          "imageUrl": "https://preview.redd.it/l6cpgpenyx9a1.jpg?auto=webp&s=e27970ed519bfb66e81e3fb8b134fedd27933c1e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102kqxm/what_desktop_oses_are_you_running/",
          "author": null,
          "description": "I just saw a thread about operating systems you run in homelabs, but I'm interested in what desktop OSes you are running on your development machines, that is desktops and laptops that you use to develop software, control and manage the rest of your infrastructure.\n And please elaborate your choices, what are the strong and weak points of OSes that you use.\n    submitted by    /u/voja-kostunica  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102kqxm/what_desktop_oses_are_you_running/",
          "publishedOn": "2023-01-03T21:56:26.000Z",
          "wordCount": 14896,
          "title": "What desktop OSes are you running?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102k9yv/1u_or_2u_home_server_options_low_power_storage/",
          "author": null,
          "description": "Long-time listener, first time caller :-)\n I'm in the midst of building out my 12U racked home network and upgrading to Ubiquiti network / protect and thinking about how to tweak my home server.\n The home server is a Plex box that is essentially 2 x 12TB drives coupled to a HP EliteDesk 800 G2 with a i5 6600T Quad Core 3.5 GHz and 16GB of RAM. It's solid and super low power but I've already lost one of these drives (warranty ftw!) which is really annoying to recover from. \n I'm in the market for a 1U or 2U option but hoping to find something with options for several drives, RAID and something that isn't crazy high power / loud or can be configured to run as such. I've been looking at the Dell R720 and equivalent HP but curious what other folks are using. I'd prefer not to use a NAS or Synology, etc as I like to get in there and tinker (for better or worse).\n Any thoughts/tips/ideas or posts folks can point me at?\n    submitted by    /u/kveton  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102k9yv/1u_or_2u_home_server_options_low_power_storage/",
          "publishedOn": "2023-01-03T21:38:34.000Z",
          "wordCount": 14768,
          "title": "1U or 2U home server options ... low power, storage, speed ... best option for all 3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102k87p/secure_connection_to_homelab/",
          "author": null,
          "description": "Hi everyone,\n let me explain my setup a bit, i currently have a linux vm running some services on my local nas in my house and i want to publish those services to the internet so anyone can use them.\n I thought it would be cool (and safe!) to just use a cheapo vps with a tailscale tunnel to my vm and use that vps as a reverse proxy so everybody can reach the public vps, and then only the vps uses tailscale to my local vm entering my local network.\n is this possible? i know for shure that i am missing some steps here but i want to learn.\n is this safer than some other possibilities? i dont want to host my services online cause i'll need to rent a pretty beefy vps for that and i already have the hardware which is capable of running those things in home.\n dont tell me to use a dmz cause i dont have control over router (not actually \"my\" house...) and neither have a public ip (isp doing natting shit).\n There's a way i can accomplish what i want? thanks!\n    submitted by    /u/Memesman12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102k87p/secure_connection_to_homelab/",
          "publishedOn": "2023-01-03T21:36:41.000Z",
          "wordCount": 15276,
          "title": "Secure connection to homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102iu4a/my_low_power_low_cost_starter_homelab/",
          "author": null,
          "description": "submitted by    /u/YourMomIsNotMale  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102iu4a/my_low_power_low_cost_starter_homelab/",
          "publishedOn": "2023-01-03T20:43:25.000Z",
          "wordCount": 14252,
          "title": "My low power low cost Starter homelab",
          "imageUrl": "https://preview.redd.it/cqqdrkimlx9a1.jpg?auto=webp&s=f3312d1bc76501abd97476c3a2246286b16d5548"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102invn/wanted_to_find_out_if_its_possible_it_is/",
          "author": null,
          "description": "submitted by    /u/Lavist3r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102invn/wanted_to_find_out_if_its_possible_it_is/",
          "publishedOn": "2023-01-03T20:36:21.000Z",
          "wordCount": 14963,
          "title": "Wanted to find out if its possible. It is.",
          "imageUrl": "https://preview.redd.it/rkeo6u9q2w9a1.png?auto=webp&s=aca9665493a13c5055d6c40ffc53222e6ce2f594"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102fgr8/need_help_with_first_homelab/",
          "author": null,
          "description": "Hey Everyone, I wanted to hear your opinions on my build and was wondering if I could get some help understanding some things.\n ​\n The components:\n CPU: Intel 10100\n MOBO: Asus H510M-E\n Storage: Western Digital 4TB WD Red Plus \n case: Fractal design node 304\n ram: Corsair Vengeance LPX 16GB (2x8GB) DDR4 DRAM 3200MHz\n ​\n My home server will mainly be used to host jellyfin, a VPN(to access my network remotely), a portfolio website, DNS, and to create a local file server.\n And Im wondering how to do it. \n ​\n Im thinking about just downloading Debian and running jellyfin on it and my file server and creating VMs for the rest which will run on top of the os. \n ​\n or \n ​\n using a hypervisor like proxmox to create VMs for each purpose. I heard Quicksync will not work this way and I hear having a media server on a VM is just asking for trouble. \n ​\n I hear docker could be an option but I don't have enough knowledge of docker and don't really understand it, maybe one of you could enlighten me. \n ​\n Im currently at a loss at the moment on how I should set this server up to be effective and easy to back up. \n ​\n I really want to be able to back up my saved media. \n ​\n    submitted by    /u/YouRSav1ouR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102fgr8/need_help_with_first_homelab/",
          "publishedOn": "2023-01-03T18:30:05.000Z",
          "wordCount": 17040,
          "title": "Need help with first Homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102ewji/what_the_fk_is_this_refsutil_just_doesnt_support/",
          "author": null,
          "description": "​\n https://preview.redd.it/dqqa8lzfav9a1.png?width=959&format=png&auto=webp&s=7053e0f3f128fba756ed3c28cd424d5be18f1ba9\n The filesystem on my storage server got corrupted from a sudden power loss during boot caused by a hardware failure. I've never had to recover a RAID array using ReFS before, but I heard the process was relatively painless thanks to the \"resilient\" nature of the filesystem itself and the accompanying diagnostic utility ReFSUtil.\n Then I saw this error message.\n Seriously, what the fuck is this? Did MS actually release an update to a filesystem designed for maintaining data integrity which actually makes the associated data recovery and diagnostic tool incompatible!? \n What the actual fuck?\n    submitted by    /u/Axiomatic36251  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102ewji/what_the_fk_is_this_refsutil_just_doesnt_support/",
          "publishedOn": "2023-01-03T18:08:42.000Z",
          "wordCount": 14897,
          "title": "What the fk is this!!?? | ReFSutil just doesn't support my filesystem version?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102e05j/ive_only_just_begun_gonna_fill_the_space_with_av/",
          "author": null,
          "description": "submitted by    /u/tjsase  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102e05j/ive_only_just_begun_gonna_fill_the_space_with_av/",
          "publishedOn": "2023-01-03T17:33:59.000Z",
          "wordCount": 15420,
          "title": "I've only just begun... gonna fill the space with AV equipment for digitizing laserdiscs and tapes, with some retro game consoles for good measure",
          "imageUrl": "https://external-preview.redd.it/_izJ6GJ0SLoEK5rRmQMAdTRgyG_uHoyTtFP5x3HmS2w.jpg?auto=webp&s=3305812b7e84a3526e1b01cca6797b203cf9fef1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102cuot/homelab_homepage_heimdall_alternatives/",
          "author": null,
          "description": "I’ve been using heimdall as my “Homepage” so to speak for a while. It’s fine but not especially gripping or extensible. I love that it’s easy to deploy as a container to run on my largely-rPi-powered homelab cluster. \n Is there anything folks recommend that is perhaps more flexible than Heimdall and keeps the ease-of-deployment?\n    submitted by    /u/kevlarcupid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102cuot/homelab_homepage_heimdall_alternatives/",
          "publishedOn": "2023-01-03T16:48:02.000Z",
          "wordCount": 16548,
          "title": "Homelab “Homepage” - Heimdall alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102btna/things_are_finally_starting_to_pick_up_pace_in_my/",
          "author": null,
          "description": "submitted by    /u/PLAN3T_KILL3R  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102btna/things_are_finally_starting_to_pick_up_pace_in_my/",
          "publishedOn": "2023-01-03T16:06:14.000Z",
          "wordCount": 14122,
          "title": "Things are finally starting to pick up pace in my homelab!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102bmye/what_oses_are_you_running/",
          "author": null,
          "description": "Greeting fellow homelabers,\n As starters, i'm a newbie when it comes to homelabs, so please take it easy on me :)\n I posted a while ago asking for help on how to set up my first homelab parts based on my needs and got an amazing help and guidance.\n Now that i'm starting to get the hardware i need, i was wondering what kind of operating systems and services are you (experienced) homelabers hosting?\n I want to know what's mostly used and see what might be interesting to me and learn more about it the more i go.\n    submitted by    /u/Da_Colinz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102bmye/what_oses_are_you_running/",
          "publishedOn": "2023-01-03T15:59:02.000Z",
          "wordCount": 20674,
          "title": "What OSes are you running?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102aty0/home_lab_backups/",
          "author": null,
          "description": "I have a 8TB Pi NAS and I'm thinking of using it to create a backup solution for multiple PIs running several self-hosted services. My thought is to create encrypted backups locally and automate uploads of the encrypted backups to the cloud. I have two questions:\n  \nDoes this make sense? I'm a bit uneasy about only storing backups locally. \n \nRecommended solutions to accomplish this plan? \n \n Thanks in advance!\n    submitted by    /u/djshaw0350  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102aty0/home_lab_backups/",
          "publishedOn": "2023-01-03T15:24:32.000Z",
          "wordCount": 15558,
          "title": "Home lab backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102aqjo/finally_installed_proper_rails/",
          "author": null,
          "description": "submitted by    /u/zevrant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102aqjo/finally_installed_proper_rails/",
          "publishedOn": "2023-01-03T15:20:30.000Z",
          "wordCount": 15400,
          "title": "finally installed proper rails",
          "imageUrl": "https://preview.redd.it/z430obe00w9a1.jpg?auto=webp&s=d8befe776268ac2898bdc62271b81ec0af748cf8"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1028nid/my_completely_automated_homelab_featuring/",
          "author": null,
          "description": "My Kubernetes cluster, deployments, infrastructure provisioning is all available over here on Github.\n Below are the devices I run for my Homelab, there is no virtualization. Bare metal k8s all day!\n LabPorn\n  \n Device Count OS Disk Size Data Disk Size Ram Operating System Purpose \n  \n Protectli FW6D 1 500GB mSATA - 16GB Opnsense Router \n  Intel NUC8i3BEK 3 256GB NVMe - 32GB Fedora Kubernetes Masters \n  Intel NUC8i5BEH 3 240GB SSD 1TB NVMe (rook-ceph) 64GB Fedora Kubernetes Workers \n  PowerEdge T340 1 2TB SSD 8x12TB ZFS (mirrored vdevs) 64GB Ubuntu NFS + Backup Server \n  Lenovo SA120 1 - 6x12TB (+2 hot spares) - - DAS \n  Raspberry Pi 1 32GB (SD) - 4GB PiKVM Network KVM \n  TESmart 8 Port KVM Switch 1 - - - - Network KVM (PiKVM) \n  APC SMT1500RM2U w/ NIC 1 - - - - UPS \n  Unifi USP PDU Pro 1 - - - - PDU \n \n Applications deployed with Helm\n Hajimari Dashboard of applications\n Automation Checklist:\n  \nDeployments: (GitOps with Flux)\n SSL: (cert-manager)\n Private DNS records: (k8s_gateway)\n Public DNS records: (external-dns)\n Container and Helm chart updates: (Github PRs created by Renovate)\n Volume Backups and Recovery: (VolSync backing up to S3)\n and more...\n  \nUsing Kubernetes and GitOps has been pretty niche but growing in popularity. If you have the hunger for learning k8s or bored with docker-compose/portainer/rancher, or just want to try I built a template on Github that has a walkthrough on deploying Kubernetes to Ubuntu/Fedora and deploying/managing applications with Flux.\n If any of this interests you be sure to check out our little community Discord, Happy New Year!\n    submitted by    /u/onedr0p  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1028nid/my_completely_automated_homelab_featuring/",
          "publishedOn": "2023-01-03T13:46:24.000Z",
          "wordCount": 16738,
          "title": "My completely automated Homelab featuring Kubernetes",
          "imageUrl": "https://external-preview.redd.it/n1zhndzTM3A0LEcBbiEl89PQ5FjTMpF9hFFbXeDBkgo.png?auto=webp&s=c5ef12786f99a0dbb6042143bd02a5677d733eb2"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1028lbf/old_ipad_as_a_grafana_dashboard/",
          "author": null,
          "description": "​\n https://preview.redd.it/pv70zg240u9a1.jpg?width=1632&format=pjpg&auto=webp&s=5cfd12008902eead3cc1c8dba4492a5823502626\n As we know, older Apple devices after the end of support quickly lose functionality. I have one of these devices - \"iPad Mini 1\", which despite of it's advanced age was still ok. I thought it would make a great dashboard for my mini server rack. This is where the adventure begins.\n Problems\n  \nSafari completely refuses to navigate to pages with a port specified, which means that the dashboard must be available on standard ports 80/443. We will use nginx in front.\n iOS 9 contains legacy root certificates, which, fortunately, can be easily installed. Because my home services are running on LE-certificates, this option came in handy.\n Most modern dashboards use JS features…",
          "link": "https://www.reddit.com/r/homelab/comments/1028lbf/old_ipad_as_a_grafana_dashboard/",
          "publishedOn": "2023-01-03T13:43:38.000Z",
          "wordCount": 16567,
          "title": "Old iPad as a Grafana Dashboard",
          "imageUrl": "https://external-preview.redd.it/JDwSonRzPsHG0doTqDAIL_FgHXlCaJwxh43Q3W84wbA.jpg?auto=webp&s=da83f7315124b928917ed896add2ea05f14440e0"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1027qal/new_to_the_homelab_scene_took_a_crack_at_a_lack/",
          "author": null,
          "description": "submitted by    /u/xRoguestatus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1027qal/new_to_the_homelab_scene_took_a_crack_at_a_lack/",
          "publishedOn": "2023-01-03T13:05:28.000Z",
          "wordCount": 15326,
          "title": "New to the Homelab scene. Took a crack at a Lack Rack!",
          "imageUrl": "https://preview.redd.it/ycpfybr0ut9a1.jpg?auto=webp&s=3b095bbe3a8867a020a54f1c3604d8b10030c74c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1024bnm/my_unnecessary_homelab_any_advice_welcome/",
          "author": null,
          "description": "submitted by    /u/NotAnITGuy_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1024bnm/my_unnecessary_homelab_any_advice_welcome/",
          "publishedOn": "2023-01-03T10:12:30.000Z",
          "wordCount": 18918,
          "title": "My unnecessary homelab, any advice welcome!",
          "imageUrl": "https://preview.redd.it/j6jjon52hu9a1.jpg?auto=webp&s=ff2ede29d1a9905811307ac202c4a0c0ff89e4a1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/102345f/my_homelab_complete/",
          "author": null,
          "description": "submitted by    /u/ZerueLX11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/102345f/my_homelab_complete/",
          "publishedOn": "2023-01-03T09:02:08.000Z",
          "wordCount": 15519,
          "title": "My Homelab complete!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101vfn8/just_some_storage_things/",
          "author": null,
          "description": "submitted by    /u/yodisbebrinkman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101vfn8/just_some_storage_things/",
          "publishedOn": "2023-01-03T02:23:58.000Z",
          "wordCount": 16711,
          "title": "Just some storage things",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101u7br/how_can_i_adjust_the_fan_speed_beyond_low_offset/",
          "author": null,
          "description": "Even at the \"low\" setting, the fans are running around 6-8k rpm and are loud as hell. I really want to reduce the noise this thing makes, but I don't want to resort to a full manual fan speed override in IPMI, since I still need it to stay cool under load in the summer. I'm running ESXi 6.5 on the server. Is there a utility I can use to quiet it down?\n    submitted by    /u/SimplifyAndAddCoffee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101u7br/how_can_i_adjust_the_fan_speed_beyond_low_offset/",
          "publishedOn": "2023-01-03T01:29:52.000Z",
          "wordCount": 14868,
          "title": "How can I adjust the fan speed beyond \"low offset\" and \"high offset\" on a Dell R520 server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101toty/good_alternatives_for_proxmox_for_raspberry_pi/",
          "author": null,
          "description": "I have a raspberry pi 3 that doesn’t support proxmox, wondering what a good alternative might be\n    submitted by    /u/sunnyo80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101toty/good_alternatives_for_proxmox_for_raspberry_pi/",
          "publishedOn": "2023-01-03T01:07:32.000Z",
          "wordCount": 14922,
          "title": "Good alternatives for proxmox for raspberry pi?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101t7xm/help_understanding_bulk_storage_options/",
          "author": null,
          "description": "Howdy homelabbers! \n I’m currently running a 3 node Proxmox cluster with a tiered Ceph storage pool backing my media library, which is advertised to the network via an SMB share running on a Windows Server VM. I run Plex separately on an M1 Mac Mini and don’t plan to change that. \n My current issue is that due to the limitations of how Ceph is implemented, I have 33% space efficiency. I’d like to migrate to something like ZFS/ReFS and drastically increase that efficiency, but I’m a little overwhelmed with all of the options.\n As I see it, there are 3 routes I can go from here to get more space out of my current storage, and make it much easier to add capacity in the future:\n  \n Build my own dedicated NAS server running either my Windows Server install or migrating to TrueNAS (don’t really care which one, comfortable with both *Nix and Windows)\n  Buy an off the shelf NAS\n  Buy/Build a JBOD enclosure and pass it through to my Windows install.\n  \nI’ve been leaning towards number 3 because I don’t really want another entire bare metal system taking up space and power, and I don’t really want to pay the prices Synology/QNAP are asking for off the shelf NAS offerings with enough bays to hold my current drive collection and my planned increase in drives. I am aware that by migrating to a JBOD, I will lose the capability to migrate my NAS management VM between Proxmox nodes like I can right now, but given that media isn’t a critical service, I can live with that.\n Can someone help me understand if I’m leaning the right way, and if so, how all of the JBOD stuff works? I keep seeing conflicting information about if a JBOD passes through individual drives to the managing system, or if they are exposed as one single “drive” that the JBOD itself manages/pools together. I’m not super picky about which OS I need to use or which file system is “best”, I just want to get more out of my drives than I get right now.\n    submitted by    /u/Hospital_Inevitable  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101t7xm/help_understanding_bulk_storage_options/",
          "publishedOn": "2023-01-03T00:47:16.000Z",
          "wordCount": 15356,
          "title": "Help understanding bulk storage options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101sgci/slow_performance_for_sshfscurlftpfs_mounted/",
          "author": null,
          "description": "I'm using Ubuntu server 22.04 as my server system, and I'm having trouble realizing full possible performance to my remote filesystem living on a VPS.\n I tried both sshfs and curlftps, and I'm only getting around 60-70 Mbit/s when transferring a file from the remote filesystem to my server. About 500 Mbit/s should be possible.\n These are my /etc/fstab mounts:\n sshfs#user@my.vps.com /mnt/vps fuse _netdev,Ciphers=aes256-ctr,cache=yes,kernel_cache,compression=yes,reconnect,ServerAliveCountMax=3,ServerAliveInterval=5,identityFile=/path/to/ssh_key,allow_other 0 0 curlftpfs#user:password@my.vps.com /mnt/vps_ftp fuse auto,user,uid=1000,allow_other,_netdev 0 0 \n as I said, both mounts only allow about 12.5% of performance. I did a copy with\n cp /mnt/vps/test.file ~/test.file and cp /mnt/vps_ftp/test.file ~/test.file \n the results are identical. I also did a download of the same file with curl\n curl -u user:password -o ~/test.file https://my.vps.com/test.file \n here I get the full performance of 500 Mbit/s\n Also, I \"double\" my performance when I copy 2 files in parallel by doing this in multiple terminals:\n  cp /mnt/vps/test.file ~/test.file cp /mnt/vps/test2.file ~/test2.file \n I tried several guides for boosting the performance of sshfs (switching cyphers tuning network parameters) to no avail. Also ftp performance equally bad which is not using any encryption\n Is there a setting that I'm missing why my remote shares are performing so badly?\n    submitted by    /u/Thagor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101sgci/slow_performance_for_sshfscurlftpfs_mounted/",
          "publishedOn": "2023-01-03T00:14:56.000Z",
          "wordCount": 15043,
          "title": "Slow Performance for sshfs/curlftpfs mounted remote filesystem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101rxtf/skylake_homelab_54_cores_256gb_ram_3_gpus/",
          "author": null,
          "description": "submitted by    /u/DeathByChainsaw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101rxtf/skylake_homelab_54_cores_256gb_ram_3_gpus/",
          "publishedOn": "2023-01-02T23:53:41.000Z",
          "wordCount": 14958,
          "title": "Skylake homelab - 54 cores 256gb ram, 3 gpus",
          "imageUrl": "https://external-preview.redd.it/_qI6AnjPTCVVuSjf5Gl3ZT0l2OZiJjMD74PZGiTKQrY.jpg?auto=webp&s=b38c4910f2ac6ffc92b545b648eece02b965f956"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101rss3/first_lab_setup_question_remote_access/",
          "author": null,
          "description": "I recently got some servers and a router for my first home lab. I am a student home on winter break so I am going to need to configure my lab for remote access if I wish to use it while I am away for the spring semester. What is the best way to go about doing this securely? Should I use a VPN to do this or is SSH with passwords disabled sufficient? Or a VPN and SSH?\n If anyone has some resources or some general steps that I should take for setting up remote access it would be really helpful! Apologies if these are really basic questions, I am very new to this.\n    submitted by    /u/terminalPIG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101rss3/first_lab_setup_question_remote_access/",
          "publishedOn": "2023-01-02T23:47:59.000Z",
          "wordCount": 15594,
          "title": "First Lab Setup Question: Remote Access",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101rsrm/help_with_lsi_940016i/",
          "author": null,
          "description": "Hi, I recently purchased an LSI 9400-16i for my home server/htpc. My SATA hard drives (about 10 WD golds of 18/20tb) show up ok but I’m not receiving any temperature or SMART data from the drives in Win 11 Pro.\n Is anyone familiar with this HBA and can you help be fix this issue?\n FYI I’m running latest firmware and drivers and the disks are connected directly to the card with SAS->SATA cables\n    submitted by    /u/SpiralCuts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101rsrm/help_with_lsi_940016i/",
          "publishedOn": "2023-01-02T23:47:58.000Z",
          "wordCount": 15370,
          "title": "Help with LSI 9400-16i",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101rgql/my_bedroom_friendly_homelab/",
          "author": null,
          "description": "submitted by    /u/mcfuzzum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101rgql/my_bedroom_friendly_homelab/",
          "publishedOn": "2023-01-02T23:34:11.000Z",
          "wordCount": 16343,
          "title": "My bedroom friendly homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101qzfd/domain_resolving_homelab_addresses/",
          "author": null,
          "description": "I've searched online and this subreddit for guides, but either the discussion goes beyond my understanding, or out of the scope of what i'm trying to accomplish.\n Essentially, I have a couple of machines, one running TrueNAS, and one running Proxmox with a couple of VMs for ubuntu with docker/minecraft servers, etc.\n Each one has a local ip address, and in the case of the ubuntu vm running docker containers, ip address with ports.\n Basically, instead of typing 192.168.x.xxx or 192.168.x.xxx:xxxx to access my servers, I want to be able to type something like truenas.com to access my NAS, or homelab.com to access my ubuntu server, with the docker containers being accessed like filebrowser.homelab.com, or portainer.homelab.com, instead of using ports.\n I've seen reccomendations for Traefik or DNS servers like using pihole, but I'm not interested in using another adblocking service, since i already use adguard.\n I'm a bit of a novice to this stuff, so any help is appreciated!\n    submitted by    /u/GloriousMilk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101qzfd/domain_resolving_homelab_addresses/",
          "publishedOn": "2023-01-02T23:14:52.000Z",
          "wordCount": 16962,
          "title": "Domain resolving homelab addresses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101qcet/my_lab_currently/",
          "author": null,
          "description": "submitted by    /u/crazycomputer84  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101qcet/my_lab_currently/",
          "publishedOn": "2023-01-02T22:49:18.000Z",
          "wordCount": 14923,
          "title": "my lab currently",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101pw54/homelab_build_sheet/",
          "author": null,
          "description": "Hi all, \n I am looking to build my first homelab setup to run a NAS, NVR, Proxmox (3 or 4 Linux-based VMs), and a JellyFin Server. I do not have the room for a rack-mountable solution, and was wondering if a machine with the specs below would be sufficient for my needs. \n Fractal Design Node 804\n Intel Core i5-11600K\n MSI PRO B660M-A\n CORSAIR Vengeance LPX 32GB\n LIAN LI SP 750W PSU\n Cooler Master Hyper 212 EVO\n 2 x 10TB WD Red Plus Drives to start!\n Thanks in advance, open to all criticisms and suggestions!\n    submitted by    /u/coolham123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101pw54/homelab_build_sheet/",
          "publishedOn": "2023-01-02T22:31:22.000Z",
          "wordCount": 15706,
          "title": "Homelab Build Sheet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101oh2s/update_on_home_server_room/",
          "author": null,
          "description": "submitted by    /u/f8computer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101oh2s/update_on_home_server_room/",
          "publishedOn": "2023-01-02T21:35:59.000Z",
          "wordCount": 16228,
          "title": "update on home server room",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101ls0y/city_of_heroes_server_is_alive/",
          "author": null,
          "description": "submitted by    /u/redfoxkiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101ls0y/city_of_heroes_server_is_alive/",
          "publishedOn": "2023-01-02T19:51:20.000Z",
          "wordCount": 15612,
          "title": "City Of Heroes server is ALIVE!",
          "imageUrl": "https://preview.redd.it/ubecb34f7q9a1.jpg?auto=webp&s=085b578905f1dede0c0c654451316f162aba5e12"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101lkt3/mystery_pdu/",
          "author": null,
          "description": "I have a Scientific Atlanta PC115-60. It’s a 2U rack mount power distribution unit with 8 switched and 4 unstitched outlets - all front facing; there’s nothing on the back side. It’s quite old but works well. Makes an initial hum when I flip its power switch, then the hum dies down. (Still audible but much more quiet.)\n Google has apparently never heard of it - No results.\n Anyone ever seen one of these and know anything about it? I’m not sure if it’s just a PDU or a PDU + surge protector or a PDU + power conditioner or…?\n I’d post pics but I can’t figure out how.\n    submitted by    /u/OctavioMasomenos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101lkt3/mystery_pdu/",
          "publishedOn": "2023-01-02T19:43:18.000Z",
          "wordCount": 14946,
          "title": "Mystery PDU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101ktwv/i_bought_a_27u_server_rack_i_dont_think_my_power/",
          "author": null,
          "description": "submitted by    /u/Wasted_Scripts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101ktwv/i_bought_a_27u_server_rack_i_dont_think_my_power/",
          "publishedOn": "2023-01-02T19:14:21.000Z",
          "wordCount": 15157,
          "title": "I bought a 27u server rack. I don’t think my power edge r330 doesn’t fit. Do I have to buy a new rack?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101jqac/is_this_a_good_setup/",
          "author": null,
          "description": "I recently enrolled into a cybersecurity degree plan and heard people talk about a HomeLab. So I asked around and found the following setup for $300. Wondering if I was had or if it’s a good start?\n    submitted by    /u/AlexDeets  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101jqac/is_this_a_good_setup/",
          "publishedOn": "2023-01-02T18:29:49.000Z",
          "wordCount": 15309,
          "title": "Is this a good setup?",
          "imageUrl": "https://preview.redd.it/7jvpb7gvsp9a1.jpg?auto=webp&s=7db46220888cc926dc613c9ca63537f3b71b5253"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101io55/anyone_have_wood_side_paneling_design_for/",
          "author": null,
          "description": "submitted by    /u/Wishiwascro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101io55/anyone_have_wood_side_paneling_design_for/",
          "publishedOn": "2023-01-02T17:48:02.000Z",
          "wordCount": 16195,
          "title": "Anyone have wood side paneling design for Startech 15u open frame?",
          "imageUrl": "https://preview.redd.it/u6zvg35flp9a1.png?auto=webp&s=99411a207bf9ee98a4308ad75a9246c1cd967a56"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101i8ot/for_those_that_want_to_live_in_the_80s/",
          "author": null,
          "description": "submitted by    /u/ngarret  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101i8ot/for_those_that_want_to_live_in_the_80s/",
          "publishedOn": "2023-01-02T17:30:49.000Z",
          "wordCount": 16230,
          "title": "For those that want to live in the 80s",
          "imageUrl": "https://preview.redd.it/xusb13tcip9a1.jpg?auto=webp&s=955230fa7c1706632e97bdc936215f8eac109fb3"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101e7vv/thinking_about_turning_my_desktop_gaming_rig_into/",
          "author": null,
          "description": "I realise this is a bit of a nebulous question on my part (how do I define mostly idle, what other components (e.g. the PSU) does the machine have, what is a non-worry amount of power consumption cost).\n But what I'm really getting at is to get someone's sort of common sense perspective on whether a machine designed to be a gaming rig (circa 2014) could:\n  \nMake for a sensible home server (e.g. if it's the case that Linux PCs can sip power surprisingly well if not constantly doing active work)\n Or if it's the case that as a rule of thumb machines built to be gaming rigs will still consume an unreasonable amount of power even under idle with a light Linux installation, and it's better to just get something like a NUC.\n  \nI do have a Pi, and an old laptop, which I use for homelab sort of purposes, but neither can do transcoding well on things like Jellyfin/Plex.\n    submitted by    /u/AlwynEvokedHippest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101e7vv/thinking_about_turning_my_desktop_gaming_rig_into/",
          "publishedOn": "2023-01-02T14:42:52.000Z",
          "wordCount": 19593,
          "title": "Thinking about turning my desktop gaming rig into a home server, but worried about power consumption (4790K/970). If the soon-to-be home server (running Linux) is most often idle, is the power consumption going to be a non-worry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/101a4na/how_to_remove_bios_password_from_fujitsu_server/",
          "author": null,
          "description": "Hi everyone, I hope someone can help me here. So, I bought a second-hand Fujitsu Primergy RX100 S7 for €100. (It said it was from 2014, but looked brand new.) Now, I got home and tried to fire it up. It loaded into ESXi, but I didn’t have the root password, so I couldn’t log in, or shut down “safely”. I then powered it off by holding the power button, and now I need a password to even startup the server. I can’t enter the BIOS or boot menu. I asked the seller but she said that she didn’t use the server, so she didn’t have any passwords. Now, I can’t do anything with it. I tried default BIOS-passwords; didn’t work. Removing the CMOS-battery for the night; didn’t work. Can someone help me remove this password? Thanks in advance!\n    submitted by    /u/jonathanmaes27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/101a4na/how_to_remove_bios_password_from_fujitsu_server/",
          "publishedOn": "2023-01-02T11:10:50.000Z",
          "wordCount": 15589,
          "title": "How to remove BIOS password from Fujitsu server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1015tdw/while_self_hosting_do_you_prioritize_mini_pcs/",
          "author": null,
          "description": "submitted by    /u/KingKongBingBong1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1015tdw/while_self_hosting_do_you_prioritize_mini_pcs/",
          "publishedOn": "2023-01-02T06:47:29.000Z",
          "wordCount": 19869,
          "title": "while self hosting, do you prioritize mini PCs with low power consumption or rack based servers with more raw power?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10157sd/looking_for_a_device_that_can_perform_this_anyone/",
          "author": null,
          "description": "submitted by    /u/FinkyFamboni  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10157sd/looking_for_a_device_that_can_perform_this_anyone/",
          "publishedOn": "2023-01-02T06:13:46.000Z",
          "wordCount": 21826,
          "title": "Looking for a device that can perform this, anyone know of such a thing?",
          "imageUrl": "https://preview.redd.it/ihvyiy2wnk9a1.png?auto=webp&s=99fcfc0903ae05211b079ec4216887be0aabfbd6"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1011d4k/cable_raceway_hack_for_homelabs/",
          "author": null,
          "description": "I just thought of this today and figured some folks here might get some use out of it. I needed a way to easily bunch and manage Ethernet cables, and I remembered these Multi-cable staples for in wall Romex.\n They’re cheap and widely available from home improvement stores. I cut the small guide tab off the bottom with some sheers and replaced the nails with screws, now they’re Ethernet cable raceways for my basement. They clip shut and can be unclipped to add more cables later, each one comfortably houses up to 12 Ethernet cables.\n    submitted by    /u/dlongwing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1011d4k/cable_raceway_hack_for_homelabs/",
          "publishedOn": "2023-01-02T02:55:13.000Z",
          "wordCount": 15881,
          "title": "Cable raceway hack for homelabs",
          "imageUrl": "https://external-preview.redd.it/iSYT9gElyvqLonsj8Rviqgu0Qt0XAm--k8qFbzPmPAM.jpg?auto=webp&s=5eeb01a9b929ac1e9b0865d578d081299c7e88a6"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100z7yo/shared_cpugpu_for_multiple_rooms_vm_over_lan/",
          "author": null,
          "description": "Hi,\n I have the following idea for setting up my home network/PCs.\n One last-gen PC with A+ CPU/GPU to be shared among: \n  \nRoom 1 (2nd floor): Low-latecy audio (DAW) and casual gaming.\n Room 2 (1st floor) : home-teather (main) and casual gaming.\n Potentially other rooms (max 1+).\n  \nA possibility is to run multiple virtual machines on the main PC (one per room), which is connected over wired LAN. Then, lowest-possible-cost PCs with small form factor (e.g. mini-PCs) located in the different rooms are used to connect to the VMs.\n Ethernet cables are already on place in the house (2 floors). All PCs need to be bought.\n Advantages: \n  \nno additional wiring (!) to buy and deploy (such as A/V, USB) like I have seen in similar projects.\n low-latency applications (audio) will be run from Main PC directly (or via VM, but still physically at the main PC).\n  \nDisadvantages:\n  \nRound-trip latency to game from Room2 over LAN (reasonable to keep it below 10-15 ms?)\n Keeping costs of mini-PC very low (?) to make the idea meaningful.\n Noise from Main PC (Room1 used for audio recording)\n  \nAny feedback here would be helpful! Especially on which VM framework to use, and if the whole idea is realistic, of course.\n ​\n https://preview.redd.it/qdq128ef5j9a1.png?width=1018&format=png&auto=webp&s=6a55538806b1dd30296e96c5954ff579da6f292d\n    submitted by    /u/jagardoden_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100z7yo/shared_cpugpu_for_multiple_rooms_vm_over_lan/",
          "publishedOn": "2023-01-02T01:14:15.000Z",
          "wordCount": 15046,
          "title": "Shared CPU/GPU for multiple rooms (VM over LAN)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100wvil/switch_for_core_virtualization/",
          "author": null,
          "description": "Hey all, I'm ready to move beyond exposure and understanding of what I'm working with infrastructure-wise to actually being responsible for buildout and maintenance, and before I start messing with edge technologies for multitenant environments (VRFs, etc.), I'd like to make sure I'm solid with my core virtualization infrastructure from a network perspective.\n I'm doing a hyper-v build soon since I'm more unfamiliar with it vs. vmware, but I'd like to have a pair of switches (stacked would be nice but is not necessary) that helps me understand the concepts that I'd be dealing with on a daily basis in a datacenter environment. I've considered sharing what I've designed so far, but since I'm open to hearing about what I don't know, I'll leave this open to everyone's interpretation and not prejudice your responses. Is anyone able to make a recommendation about where I should be focused, and what networking features (vxlan/varp/vrrp) and architectures (e.g. spine and leaf vs. a more traditional core/distribution/access model) should be interested in familiarizing myself with?\n I'm a quick study generally speaking so if you have thoughts or experience outside of what I've been exposed to, I might have follow-up questions. Either way, I appreciate the input, and believe me, I don't have any preconceptions that this is can be boiled down to a single post. Any and all feedback is appreciated.\n    submitted by    /u/thebackwash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100wvil/switch_for_core_virtualization/",
          "publishedOn": "2023-01-01T23:29:59.000Z",
          "wordCount": 15990,
          "title": "Switch for core virtualization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100wu65/can_someone_explain_to_me_the_difference_between/",
          "author": null,
          "description": "I'm having trouble understanding the purposes of each of these services? Are some of them operating systems? What does Proxmox do? Is it different from Docker? Or the same?\n    submitted by    /u/kvpop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100wu65/can_someone_explain_to_me_the_difference_between/",
          "publishedOn": "2023-01-01T23:28:11.000Z",
          "wordCount": 16124,
          "title": "Can someone explain to me the difference between unRAID/TrueNAS/ OpenMediaVault/Proxmox? And what to pick for a first-time NAS build?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100w0hx/what_os_would_you_run_in_this_scenario/",
          "author": null,
          "description": "I'm looking to build a speedy, all-in-one NAS for both storage and docker. So I have 12 SSDs and 6 NVMe drives in a machine with a 10G NIC and a 20 core CPU. note that this is all leftover hardware and pretty overkill for the purpose, but I plan to rebuild a more power-efficient version soon.\n I'm using TrueNAS on bare metal at the moment, and the storage pools are fast, but no docker capability means I have to setup a Linux VM for docker (currently using dietpi). I could also run Proxmox and run both TrueNas and linux in VMs. Or since I don't really need all the features of TrueNAS, I could just run Ubuntu Server and roll my own ZFS.\n What feels cleaner to y'all?\n    submitted by    /u/saksoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100w0hx/what_os_would_you_run_in_this_scenario/",
          "publishedOn": "2023-01-01T22:53:54.000Z",
          "wordCount": 15822,
          "title": "What OS would you run in this scenario?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100uygi/how_would_a_hp_proliant_dl360_g7_server_hold_up/",
          "author": null,
          "description": "Looking to get into setting up my own home server, and found this for ~$100. Not sure which xeon is in there or home much ram, still need to go look at it. Mainly curious about the platform and if it's still viable assuming it all works.\n Also saw on the data sheet that max internal storage is 4tb for hot plug sata, 8x500gb. If someone has an explanation of why there is a max capacity like that it would be appreciated.\n As for use, mainly Plex and a nas, but also want something to learn/mess around with\n    submitted by    /u/Chcken_Noodle_Soup  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100uygi/how_would_a_hp_proliant_dl360_g7_server_hold_up/",
          "publishedOn": "2023-01-01T22:08:28.000Z",
          "wordCount": 17077,
          "title": "How would a HP ProLiant DL360 G7 Server hold up?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100up4q/i_am_looking_for_advice_to_replace_my_old_server/",
          "author": null,
          "description": "Happy New year to every body !\n My current server is an old desktop PC with an i7 4770k and 16GB of RAM, all in a Fractal Design R5 case and no graphics card. It was at first a gaming PC with the CPU overclocked, then it has been has been running 24/7 for almost 7 years as server and I have never had a single problem, I really appreciate this machine for its reliability. However, with time the electricity bill increases because of the important consumption of the CPU.\n My server uses Proxmox as a hypervisor and runs mainly:\n  \nx2 LXC Container (Pi-Hole & Minecraft Server)\n x4 VM: \n Home Assistant\n Jellyfin\n Reverse Proxy\n Alpine Linux with docker to manage the rest of my services like nextcloud, bitwarden, miniflux, etc...\n \n  \nI'm looking to replace it all with a server that takes up less space and consumes less power.\n I also think to replace Proxmox by Fedora Server or Fedora CoreOS to use only containers with podman.\n I have two machines that hold my attention,\n The first one is the Lenovo ThinCenter M70q gen3 with an i5 and 16gb of ram, this product interests me a lot, but what I don't know is the noise pollution, my current server has a noctua ventirad and the Define R5 is totally silent, and I would like this little box to be as much.\n Second would be an Intel NUC 12 with i5 and 16GB of RAM. I'm less convinced because I'm not sure that this hardware is as reliable over time and may lack performance for some tasks, but it is probably the best for power consumption and noise.\n I'm also hesitating with the i3 model, I intend to get one or two more in the near future to make a cluster.\n Would you have an opinion on these two machines or others to recommend? \n I thought about the Dell Optiplex but in France they are sold with a Windows license, which means an extra cost.\n Thanks,\n    submitted by    /u/Rikles-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100up4q/i_am_looking_for_advice_to_replace_my_old_server/",
          "publishedOn": "2023-01-01T21:58:16.000Z",
          "wordCount": 15809,
          "title": "I am looking for advice to replace my old server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100t2v5/low_energy_proxmox_setup/",
          "author": null,
          "description": "I want to make a proxmox setup with as many cores as possible but with low power consumption. I saw the ryzen 5600 cpu has 6 cores and a TDP of 65. Would this be the best setup or do you guys have a better suggestion?\n    submitted by    /u/RonaldvanderMeer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100t2v5/low_energy_proxmox_setup/",
          "publishedOn": "2023-01-01T20:51:05.000Z",
          "wordCount": 15670,
          "title": "Low energy proxmox setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100sxyf/automating_proxmox_with_terraform_cloudinit_pxe/",
          "author": null,
          "description": "The situation is simple: I have a Proxmox node, and I want to spin up a few Debian or Alpine Linux VMs automatically using declarative configuration, and get to the point where I can run Ansible playbooks on them. I think Terraform would be good for creating VMs.\n I was originally going to build some images using debootstrap or Alpine's equivalent, customize the images a bit and upload them, but it seems like the Proxmox Terraform provider doesn't support that method. That means I have to use either PXE, cloud-init, or preprovision. Preprovision only supports Ubuntu and CentOS, so that's an instant dealbreaker.\n I looked around for some posts about cloud-init, and they seem kind of split on whether it's useful or not. Some people mentioned:\n  \nAnsible can do everything it can\n Hypervisors usually have templating features already\n cloud-init is for datacenters and you should use Packer and PXE boot\n  \nPXE boot sounds complicated to set up. Do you think cloud-init is good for this usecase?\n    submitted by    /u/dthusian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100sxyf/automating_proxmox_with_terraform_cloudinit_pxe/",
          "publishedOn": "2023-01-01T20:44:54.000Z",
          "wordCount": 20735,
          "title": "Automating Proxmox with Terraform: cloud-init, PXE, or something else?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100r2yi/alix_2d3_install_os_on_cf_on_different_machine/",
          "author": null,
          "description": "Hi,\n would it be possible to install pfsense or OPNsense directly on a compact flash on a different device with a CF -> USB adapter and then just put the CF card back into the Alix 2d3 to boot from it? (As a workaround from not using serial console?)\n    submitted by    /u/sheeesh83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100r2yi/alix_2d3_install_os_on_cf_on_different_machine/",
          "publishedOn": "2023-01-01T19:24:55.000Z",
          "wordCount": 20204,
          "title": "Alix 2d3 install OS on CF on different machine and then use it on the 2d3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100qf7r/everyone_here_has_physical_hardware_take_a_look/",
          "author": null,
          "description": "submitted by    /u/zdimension  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100qf7r/everyone_here_has_physical_hardware_take_a_look/",
          "publishedOn": "2023-01-01T18:56:17.000Z",
          "wordCount": 15762,
          "title": "Everyone here has physical hardware; take a look at my \"webserver.\"",
          "imageUrl": "https://preview.redd.it/zj39du52bh9a1.jpg?auto=webp&s=840ddd00780102c94b45f8b2e81ea1c8dad50b7f"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100q05o/if_you_moved_from_big_servers_to_nucs_or_micros/",
          "author": null,
          "description": "I’m considering moving from a big server to NUCs or micro PCs to ultimately save power and just down size a bit. So anyone that has done this, how satisfied are you? Any regrets or gotchas?\n For reference my main rig is a white box dual Xeon E5-2698 V4 / 256 GB Ram / dual 10g NICs/ 1660 Ti for transcoding - on proxmox. Running about 7 VMs and 25 containers.\n Mass storage is external on a synology DS1821+\n Power here isn’t terribly expensive @ 0.10 / kWh. But lab a low use / idle draws about 415 watts\n    submitted by    /u/electricpollution  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100q05o/if_you_moved_from_big_servers_to_nucs_or_micros/",
          "publishedOn": "2023-01-01T18:37:56.000Z",
          "wordCount": 18181,
          "title": "If you moved from big servers to NUCs or micros - how satisfied are you?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100ob8r/networking_setup_for_a_linux_server_running/",
          "author": null,
          "description": "My networking scheme (currently) is as follows: https://imgur.com/a/GcN4fc7 \n Everything under eth1 is what I'd want to achieve rather than the setup I have right now.\n My goal is to have multiple separate subnets which would contain virtual machines that are capable of reaching other machines within the subnet, but not the machines in other subnets, or machines within my LAN (192.168.0.0/24). Simultaneously, I want machines inside the subnets to be resolvable and reachable by external (outside of LAN) clients.\n My experience with networking is limited to esxi, and networking stack of linux is somewhat alien to me, so I would appreciate if not a fully detailed guide on how to achieve my goal, then at least a few helpful pointers on how I can do that with the tools that proxmox provides (that being, the entirety of Linux's networking stack). Thanks!\n    submitted by    /u/Honest-Cantaloupe114  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100ob8r/networking_setup_for_a_linux_server_running/",
          "publishedOn": "2023-01-01T17:23:13.000Z",
          "wordCount": 16298,
          "title": "Networking setup for a Linux server running proxmox",
          "imageUrl": "https://external-preview.redd.it/qV2L7sbHujPyI3K1xs7hV8c6RfzBO48DkFhKaLoCruw.jpg?auto=webp&s=9ae00c652dbbc0018bccf7f14952c6de07e44043"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100nt4p/securely_ingressing_into_bare_metal_kubernetes/",
          "author": null,
          "description": "submitted by    /u/mmontes11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100nt4p/securely_ingressing_into_bare_metal_kubernetes/",
          "publishedOn": "2023-01-01T17:00:21.000Z",
          "wordCount": 14995,
          "title": "Securely Ingressing into Bare Metal Kubernetes Clusters with Traefik and Gateway API ☸️🔌🔒",
          "imageUrl": "https://external-preview.redd.it/Sqjb1sZhAaVfkNF3sod6EAOEt43HOcXtzALm7NXR4YM.jpg?auto=webp&s=678854098b3b58f00b98da373c97f50e73201517"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100mwco/another_6_months_into_this_hobby/",
          "author": null,
          "description": "submitted by    /u/racomaizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100mwco/another_6_months_into_this_hobby/",
          "publishedOn": "2023-01-01T16:16:54.000Z",
          "wordCount": 18575,
          "title": "Another 6 months into this ... hobby",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100mjw0/my_first_shots_at_homelabbing/",
          "author": null,
          "description": "submitted by    /u/mcgoldcard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100mjw0/my_first_shots_at_homelabbing/",
          "publishedOn": "2023-01-01T16:00:20.000Z",
          "wordCount": 16054,
          "title": "My first shots at homelabbing.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100medj/moving_to_bitwarden_selfhosted/",
          "author": null,
          "description": "Hi there,\n Currently I use Dashlane as my password manager and I’m thinking of moving to a self hosted solution since I’ve just got my homelab setup. I know a lot of people have been recommending bitwarden and have a few questions before I move over:\n  \nDoes it require much maintenance? I.e management of database, fixing errors and updates?\n \nDoes Bitwarden support MFA? In addition to being a password manager I’d like my self hosted solution to support MFA codes built into the app.\n \nDoes Bitwarden have an addon for Brave which autofills login forms automatically? Say I’m on twitter.com will it recognise the website and fill in the password automatically?\n \nCan Bitwarden run in docker?\n \nIn general what issues have people faced with Bitwarden and is there anything I need to be aware of when setting it up/using it?\n \n Thanks in advance!!🙂\n    submitted by    /u/signups2959291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100medj/moving_to_bitwarden_selfhosted/",
          "publishedOn": "2023-01-01T15:53:11.000Z",
          "wordCount": 16762,
          "title": "Moving to Bitwarden Selfhosted",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100lxbg/ryzen_am4_serveroriented_board/",
          "author": null,
          "description": "Being ryzen a platform with pretty high power efficiency, it seems ideal for a homeserver.\n Now that AM5 boards have been released, all the previous gen hardware is getting cheaper, which makes it even more appealing.\n I don’t know if there are any server-oriented AM4 boards. I know I’m not getting things like IPMI or RDIMMs, but I wanted to know if there are any important features I need to take into account when looking for a board to use as a homeserver.\n    submitted by    /u/Lcs_26  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100lxbg/ryzen_am4_serveroriented_board/",
          "publishedOn": "2023-01-01T15:29:44.000Z",
          "wordCount": 17771,
          "title": "Ryzen AM4 server-oriented board",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100jtta/ipmi_over_lan_not_working_on_dell_poweredge_r720/",
          "author": null,
          "description": "Hello there,\n I'm trying to use ipmitool over my home LAN (no specific network configuration, no firewall, no VLAN) on my Dell PowerEdge R720 (running VMware ESXi 7.0) but I can't get it to work. What's really weird is that its configuration is identical to my other Dell PowerEdge server (which is an R720XD), for which it works... Here is my iDRAC network configuration :\n https://preview.redd.it/y3zginenpf9a1.png?width=3840&format=png&auto=webp&s=d0dfaab9e50e15d5b38696f9cfec3474c52f8d2f\n Here is the command I try to run as a test :\n  ipmitool -I lanplus -H 192.168.1.190 -U root -P PASSWORD sdr elist all \n And the error message I get :\n  \nError: Unable to establish IPMI v2 / RMCP+ session\n  \nAny idea ? 🤔\n    submitted by    /u/tigerblue77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100jtta/ipmi_over_lan_not_working_on_dell_poweredge_r720/",
          "publishedOn": "2023-01-01T13:35:22.000Z",
          "wordCount": 17774,
          "title": "IPMI over LAN not working on Dell PowerEdge R720",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100h6qx/everyone_here_has_highvalue_hardware_take_a_look/",
          "author": null,
          "description": "submitted by    /u/_lay4play  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100h6qx/everyone_here_has_highvalue_hardware_take_a_look/",
          "publishedOn": "2023-01-01T10:46:14.000Z",
          "wordCount": 16335,
          "title": "Everyone here has high-value hardware; take a look at my \"webserver.\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100gois/can_anyone_identify_this_type_of_connector/",
          "author": null,
          "description": "submitted by    /u/I-make-ada-spaghetti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100gois/can_anyone_identify_this_type_of_connector/",
          "publishedOn": "2023-01-01T10:08:45.000Z",
          "wordCount": 15713,
          "title": "Can anyone identify this type of connector?",
          "imageUrl": "https://preview.redd.it/lc8xcogjoe9a1.png?auto=webp&s=b92ead9b6e0523f6d5797fe083560e3b7c785e00"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100g3qi/finally_got_a_rack_for_my_gear_wiring_could/",
          "author": null,
          "description": "submitted by    /u/Chaos249  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100g3qi/finally_got_a_rack_for_my_gear_wiring_could/",
          "publishedOn": "2023-01-01T09:25:11.000Z",
          "wordCount": 15175,
          "title": "Finally got a rack for my gear, wiring could probably be much improved",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100esld/how_many_ports_is_too_many_ports/",
          "author": null,
          "description": "submitted by    /u/kiwimtf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100esld/how_many_ports_is_too_many_ports/",
          "publishedOn": "2023-01-01T07:51:11.000Z",
          "wordCount": 16547,
          "title": "How many ports is too many ports?",
          "imageUrl": "https://preview.redd.it/gheqn320if9a1.jpg?auto=webp&s=eb5781b7249c337294f39c02f53b5c97dac898e3"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100eirx/happhi_new_year/",
          "author": null,
          "description": "submitted by    /u/Vycid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100eirx/happhi_new_year/",
          "publishedOn": "2023-01-01T07:31:35.000Z",
          "wordCount": 17540,
          "title": "Happhi New Year!",
          "imageUrl": "https://external-preview.redd.it/6kBLlJ1F3r0Zv7ikqWPX8FU2e1vp1E5pHga9FfwskXA.png?format=pjpg&auto=webp&s=f55c0e67a976817898a7c007d221122bdf5f27f7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1007yyl/cisco_monstrosity/",
          "author": null,
          "description": "submitted by    /u/jonnypockets1121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1007yyl/cisco_monstrosity/",
          "publishedOn": "2023-01-01T00:45:30.000Z",
          "wordCount": 16151,
          "title": "Cisco monstrosity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1007csq/sunon_pf38281bxq121sa9_replacement/",
          "author": null,
          "description": "submitted by    /u/guruscanada  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1007csq/sunon_pf38281bxq121sa9_replacement/",
          "publishedOn": "2023-01-01T00:12:20.000Z",
          "wordCount": 15138,
          "title": "Sunon pf38281bx-q121-sa9 replacement",
          "imageUrl": "https://preview.redd.it/jfpjx4v58d9a1.jpg?auto=webp&s=f5359776d73fafae1bcfed12bd8ac4a3085ae052"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1007bg4/what_does_it_mean_when_a_nas_case_has_a_backplane/",
          "author": null,
          "description": "Dumb question, but does that mean you don’t need a separate SATA controller that can handle all the drives? Does it plug into the motherboard via PCIE?\n For instance, I was looking at making a power efficient rack mount Nas with this case and I’m not sure what I need to include in the build\n https://silverstonetek.com/en/product/info/computer-chassis/RM43-320-RS/\n    submitted by    /u/saksoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1007bg4/what_does_it_mean_when_a_nas_case_has_a_backplane/",
          "publishedOn": "2023-01-01T00:10:24.000Z",
          "wordCount": 15633,
          "title": "What does it mean when a NAS case has a “backplane”",
          "imageUrl": "https://external-preview.redd.it/ce0j0WCzF-9Kubp6_6IHJCugjOTCbYbxPQFBs-nz-C8.jpg?auto=webp&s=9d43a587fff35ef397bfef35b27e743cfc705201"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1007405/the_post_formerly_known_as_anything_friday/",
          "author": null,
          "description": "Post anything.\n  \nWant to discuss something?\n Want to have a moan?\n Want to show something off?\n  \nDo it here.\n View all previous megaposts here!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1007405/the_post_formerly_known_as_anything_friday/",
          "publishedOn": "2023-01-01T00:00:09.000Z",
          "wordCount": 14775,
          "title": "The Post Formerly Known as Anything Friday - January 2023 Edition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100726v/happy_homelabbing_2023/",
          "author": null,
          "description": "It's already 2023 here in the Netherlands, so I want to wish everybody here a happy homelabbing newyear!\n What do some of you have planned this year in upgrades?\n For me it's a new HPE 24p gigabit w/ 8x10Gbit SFP+ switch. This way I can connect almost all my servers with 10Gbit.\n    submitted by    /u/SilentDecode  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100726v/happy_homelabbing_2023/",
          "publishedOn": "2022-12-31T23:57:29.000Z",
          "wordCount": 15213,
          "title": "Happy homelabbing 2023!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1006w09/is_it_a_good_idea_to_build_a_dedicated_server/",
          "author": null,
          "description": "submitted by    /u/Jamesthedumbass  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1006w09/is_it_a_good_idea_to_build_a_dedicated_server/",
          "publishedOn": "2022-12-31T23:48:09.000Z",
          "wordCount": 14948,
          "title": "Is it a good idea to build a dedicated server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1006kze/questions_about_multi_monitoring_for_homelab/",
          "author": null,
          "description": "hello.\n i have not previously owned a multi monitor setup, but i really need one. and im going to do that but several challenges and questions lay ahead.\n firstly i own an AMD card, i wanted to know how it actualy is if you try to connect a few monitors to 1 GPU and a couple more to another GPU (of same gpu model) i have heard and seen very conflicting info from different sources, some say it works very good, some say it doesn't, some says it works but can be challenging to work with. what is the truth?\n also my budget is limited, the more monitors the better for my usecase. but i also want to have a stable setup, i want to use my budget as wisely as possible so i can have more left over for other things for my computer setup. so my question is, if i buy a very good monitor for the main one, and then buy multiple of a worse less resolution or size (or even a different brand) monitors, will that create chalanges and mess up the UX in any ways? will it create confusion for the PC when moving the mouse between different res screens because of different positioning? also how will it work both in linux and windows because i use both?\n and lastly if i try to connect my display port monitors to DP, and at same time connect more HDMI monitors using a hdmi>DP adapter to the display ports on the GPU will it create complications or DeSync of latency between displays?\n my overall goal and view is that i want my set up to be just as plug and play as if i had all the same monitors all with DP, and also get as many monitors as possible while trying to save money.\n thank you.\n    submitted by    /u/abused_by_girlfriend  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1006kze/questions_about_multi_monitoring_for_homelab/",
          "publishedOn": "2022-12-31T23:31:53.000Z",
          "wordCount": 15799,
          "title": "questions about multi monitoring for homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1004zp4/early_beginnings/",
          "author": null,
          "description": "submitted by    /u/Fartpenisnugget  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1004zp4/early_beginnings/",
          "publishedOn": "2022-12-31T22:10:36.000Z",
          "wordCount": 15098,
          "title": "Early beginnings",
          "imageUrl": "https://preview.redd.it/kf3q15qfmc9a1.jpg?auto=webp&s=47c3e1264ea26ebdab7d5a1999f4f7177bed7a99"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1004t02/network_ups_tool_setup_advice/",
          "author": null,
          "description": "Hi,\n I am trying to get NUT working correctly on a setup I am attempting to...setup.\n  \n The issue I am having is that none of the devices connected to the NUT server are doing what they are told.\n For example, I have set (on a test system), that particular system to shutdown when the battery gets to 99%, and a second test system set to shutdown at 90%.\n  \n If I remove the power (other than this brand new UPS immediately dropping to 80%!!!) neither system shuts down, but does immediately receive a syslog message about the UPS being on battery.\n Now, I am not confident i have my configs setup correctly.\n  \n Config wise - \n Server Config (this is on a RaspberryPi/Home Assistant OS/NUT Addon, so its all YAML) - \n devices: - name: CyberPower-750VA-SL750U driver: usbhid-ups port: auto config: -…",
          "link": "https://www.reddit.com/r/homelab/comments/1004t02/network_ups_tool_setup_advice/",
          "publishedOn": "2022-12-31T22:01:11.000Z",
          "wordCount": 15407,
          "title": "Network UPS Tool Setup Advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/10042jp/homelab_verylate_2022_p/",
          "author": null,
          "description": "submitted by    /u/rynal95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/10042jp/homelab_verylate_2022_p/",
          "publishedOn": "2022-12-31T21:25:14.000Z",
          "wordCount": 15045,
          "title": "HomeLab VeryLate 2022 :P",
          "imageUrl": "https://preview.redd.it/ydlyv3rnwa9a1.png?auto=webp&s=1878233276cb1072ed72e64825aa11673bf8ae86"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1002blq/threw_together_this_low_power_plex_server_with_a/",
          "author": null,
          "description": "submitted by    /u/I-am-shrek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1002blq/threw_together_this_low_power_plex_server_with_a/",
          "publishedOn": "2022-12-31T20:00:47.000Z",
          "wordCount": 16493,
          "title": "Threw together this low power Plex server with a GTX 1050 and 6TB storage for less than $80!",
          "imageUrl": "https://preview.redd.it/lm9xye8azb9a1.jpg?auto=webp&s=e9ee1d13ebb6508c346e216c92c3d54772a73d6c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/100207n/opnsense_truenas_on_bare_metal_or_in_proxmox_vms/",
          "author": null,
          "description": "So currently i’ve got:\n  \nA qotom box with an i7 and 8gb ram running OPNsense for my 1gbit fiber and adguard as a plugin. \n HP Proliant Micro Gen 10+ with a xeon E2224, 32Gb ram, 4 eth ports (Intel I350-AM4) with dual zfs mirrors of 6TB disks. \n  \nAnd I’m thinking, since both those boxes barely use cpu, should I just throw them both in Proxmox VMs on the proliant? What kind of overhead should I expect?\n    submitted by    /u/kjarkr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/100207n/opnsense_truenas_on_bare_metal_or_in_proxmox_vms/",
          "publishedOn": "2022-12-31T19:45:41.000Z",
          "wordCount": 18313,
          "title": "Opnsense + Truenas on bare metal, or in Proxmox VMs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1001yx4/had_to_reduce_my_lab_down_a_bit_but_it_turned_out/",
          "author": null,
          "description": "submitted by    /u/ejpman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1001yx4/had_to_reduce_my_lab_down_a_bit_but_it_turned_out/",
          "publishedOn": "2022-12-31T19:43:56.000Z",
          "wordCount": 20030,
          "title": "Had to reduce my lab down a bit but it turned out nice (Proxmox server + Wifi 6 AP + 2.5G switch + 950VA UPS)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1001l9l/home_lab_home_office/",
          "author": null,
          "description": "Completed this earlier in the year but only just decided to share. From top left to bottom right: 6x Pi4B 8GB (custom designed and 3d printed chassis with 2x120mm cooling), Fortigate 60E, Netgear ReadyNAS 2x2TB(mirror), WD My book World, Virgin 500/38 WAN2, BT 900/110 WAN1, UDM-PRO, USW-PRO 24, HP T730, Hikvision NVR, Jetson Nano (custom 3d printed case), PC (i5 8500, 64GB, 4x6TB ZFS + 2x 500GB ZFS (Download Drive), 3x HP EliteDesk 800 G5 i5 9500T (16GB, 1TB NVME, 1TB SSD, plus 256GB NVME boot in each). Running a K3S Cluster with 3 masters (EliteDesks) and 9 workers. Mix of Longhorn and NFS CSI for cluster storage. 230 Pods and growing. Office lighting done myself with 4x ZigBee RGBCCT controllers so each row is colour selectable.\n    submitted by    /u/Sirgrabalot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1001l9l/home_lab_home_office/",
          "publishedOn": "2022-12-31T19:25:37.000Z",
          "wordCount": 15303,
          "title": "Home Lab / Home Office",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1001kgi/people_who_use_homeland_for_cybersecurity_and/",
          "author": null,
          "description": "Title! I’m looking into setting up a homelab in around january and wondering what sort of software i should install. of course i’ll use the basics ones like pfsenses, webgoat, kali, etc etc, but i would love to know what stuff you use! maybe even your setups? thanks!\n    submitted by    /u/Hshshshhf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1001kgi/people_who_use_homeland_for_cybersecurity_and/",
          "publishedOn": "2022-12-31T19:24:32.000Z",
          "wordCount": 16780,
          "title": "People who use homeland for cybersecurity and pentesting, what software do you use and why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1000l7w/roommate_moved_out_and_took_the_tv_so_the/",
          "author": null,
          "description": "submitted by    /u/fossilsforall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1000l7w/roommate_moved_out_and_took_the_tv_so_the/",
          "publishedOn": "2022-12-31T18:37:24.000Z",
          "wordCount": 16756,
          "title": "Roommate moved out and took the Tv, so the entertainment center is now my homelab",
          "imageUrl": "https://preview.redd.it/fm76uupekb9a1.jpg?auto=webp&s=62f7770f4e8b1f5c6593d16e313eade2ccb530a7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/1000dx3/finally_got_my_new_to_me_rack_installed_in_the/",
          "author": null,
          "description": "Yes I know, the Ethernet cables look like they are in weird spots, I am terminating them to the top where the 1Gb and 40gb switches will be. Then they come down to the different “levels” where the servers will be.\n The networking is on the left side of the rack running through the internal rails and same with power but on the right side.\n And yes the big chonker power cable will be zip tied to the top when I go get more zip ties.\n    submitted by    /u/Kawaiisampler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/1000dx3/finally_got_my_new_to_me_rack_installed_in_the/",
          "publishedOn": "2022-12-31T18:27:59.000Z",
          "wordCount": 16516,
          "title": "Finally got my new to me rack installed in the house, now just gotta fill it up!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzyi3p/new_custom_build_for_proxmox_im_hyped/",
          "author": null,
          "description": "My 8-year old laptop's motherboard died 😢 so it's time to replace it! I already have an Odroid XU4 running some low-intensity services like Home Assistant, but it's not powerful enough to do what that laptop was doing.\n Goals\n  \nRun a web scraping bot I wrote\n Run another web-oriented bot\n Be a development environment for Haskell, whose compiler loves RAM and CPU power\n Eventually be a NAS\n Have some room to do more stuff as I think of it!\n  \nParts\n  \n Part Model Link \n  \n CPU Ryzen 7 3700X (8 core, 16 threads) Link \n  CPU Cooler Wraith Prism (stock with CPU)  \n  Motherboard ASUS PRIME B550M-A/CSM Link \n  RAM Corsair 32 GB module Link \n  Gfx Card ATI Radeon HD 3470 (lol) Link \n  Case Thermaltake Core V21 Link \n  PSU Thermaltake Smart 500W Link \n  SSD TeamGroup 1TB PCIe 3.0 Link \n \n Comments\n  \nI'm so excited about this! I haven't built a PC since I was a kid and it's so much fun\n The plan is to run Proxmox and have VMs for the different bots / environments\n I love the idea of having 16 threads to work with for different VMs\n I started with a single 32 GB RAM module so I can add more if I need/want\n It's a \"gaming\" motherboard, but it's a nice price and I think it'll work. I didn't see many better options.\n The cube case is the only thing fits in my home lab cabinet. Unfortunately I don't have space for a server rack\n No built-in graphics with the Ryzen CPU, but you can get a really old card for $9 on ebay!\n Cost pre-tax and pre-shipping is ~ $500\n  \nQuestions\n  \n How is this build for power usage? Anything I can or should do to reduce it?\n  I eventually want to get a couple 2TB HDDs and use this as a NAS. I was thinking ZFS mirroring for them. I also have a brand new 2.5in 500GB SSD lying around, could that be involved? What's the best setup in Proxmox?\n  I assume that I'll have to get out a USB drive to update the motherboard BIOS from time to time, is that right?\n Anything else about this setup you think I should know or look into?\n  \nThanks! 😁\n    submitted by    /u/lbseale  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzyi3p/new_custom_build_for_proxmox_im_hyped/",
          "publishedOn": "2022-12-31T17:01:48.000Z",
          "wordCount": 16554,
          "title": "New Custom Build for Proxmox - I'm HYPED",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzy8wm/openmediavault_and_proxmox_on_ct_or_on_vm/",
          "author": null,
          "description": "I want to install Openmediavault on my proxmox machine with 2 4TB HDD on a dual bay USB 3.0 (RAID 1). My idea is to use a CT to minimize the use of RAM (It's an old laptop), but I didn't found any recent guide to do it. It's a so ugly solution or is it possible to use a CT instead of a VM?\n    submitted by    /u/ziriuz84  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzy8wm/openmediavault_and_proxmox_on_ct_or_on_vm/",
          "publishedOn": "2022-12-31T16:50:15.000Z",
          "wordCount": 17122,
          "title": "Openmediavault and proxmox: on CT or on VM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzwni7/end_of_2022_home_la/",
          "author": null,
          "description": "Well 2022 was a big year for me, got 2 of those Cisco switches and that proliant DL380P G8. The SFF desktop and server is running proxmox. Running pfsense in a VM with a dual port NIC passed though on the desktop machine. Planning to get a little mini rack next year so I'll probably be posting when that happens\n    submitted by    /u/sniff122  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzwni7/end_of_2022_home_la/",
          "publishedOn": "2022-12-31T15:36:06.000Z",
          "wordCount": 16090,
          "title": "End of 2022 home la",
          "imageUrl": "https://preview.redd.it/g3cpqn92oa9a1.jpg?auto=webp&s=d3b64b6548c44187f27e09ed2d75af3d87f901b7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzwh1c/my_first_homelab/",
          "author": null,
          "description": "submitted by    /u/bharadia2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzwh1c/my_first_homelab/",
          "publishedOn": "2022-12-31T15:27:53.000Z",
          "wordCount": 15017,
          "title": "my first homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzrbyf/my_homelab_as_of_end_of_2022/",
          "author": null,
          "description": "submitted by    /u/stfn1337  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzrbyf/my_homelab_as_of_end_of_2022/",
          "publishedOn": "2022-12-31T10:40:58.000Z",
          "wordCount": 16816,
          "title": "My homelab as of end of 2022",
          "imageUrl": "https://preview.redd.it/g3ith1ge799a1.jpg?auto=webp&s=e8e8fdb8064db22d1f8dc1f01a16158692e6117c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzkd80/my_homelab_in_a_cube_details_in_the_comments/",
          "author": null,
          "description": "submitted by    /u/echouserpipemd5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzkd80/my_homelab_in_a_cube_details_in_the_comments/",
          "publishedOn": "2022-12-31T03:38:28.000Z",
          "wordCount": 16483,
          "title": "My homelab in a cube! (details in the comments)",
          "imageUrl": "https://external-preview.redd.it/qfZ2kNDvsP3L94WbT5dy8hQOL7eRmloYfsQku2DOQJI.png?format=pjpg&auto=webp&s=2020ab54cf75c493935775fb488d9efb1bc4782d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzgs6u/plinkusa_still_around/",
          "author": null,
          "description": "I tried to order one of thier 9in 1u server chassis for a pfsense box, but they returned my money and haven't responded to any emails. Anyone know if they are still around and taking orders?\n    submitted by    /u/BadNewsBalls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzgs6u/plinkusa_still_around/",
          "publishedOn": "2022-12-31T00:48:45.000Z",
          "wordCount": 14779,
          "title": "PlinkUSA still around?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzgmo3/ethernet_cables/",
          "author": null,
          "description": "I am having a hard time finding good ethernet cables (0.5 ft, 1ft, 3ft, 5ft). I bought some from amazon and they are really hard and so difficult to bend. Is there some place you can suggest?\n    submitted by    /u/CaptainMoney21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzgmo3/ethernet_cables/",
          "publishedOn": "2022-12-31T00:41:37.000Z",
          "wordCount": 14808,
          "title": "Ethernet cables",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzg78g/simple/",
          "author": null,
          "description": "submitted by    /u/trash666kill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzg78g/simple/",
          "publishedOn": "2022-12-31T00:22:21.000Z",
          "wordCount": 15259,
          "title": "Simple",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzfth9/x13saef_not_posting/",
          "author": null,
          "description": "Hello,\n I’ve recently gotten my hands on an X13SAE-F and some other hardware to build a homelab system. I installed a i3-12100 (using to update BIOS to support 13th gen) and Micron 32 GB ECC Udimm (MTC20C2085S1EC48BA1R). However, the board will not post and has error beeps (I believe its two short beeps and one long beep). I don’t see this error beep code in the appendix I am thinking that maybe the Micron ram is not supported and I need to order the Supermicro UDIMMs when they come in stock, but maybe the issue is something else\n Here is a video of the beep and memory (I currently have one out of two sticks installed since I was swapping them around to see if it would fix it) https://imgur.com/a/rkUtgMT\n And by no posting I mean theres no HDMI output. by the beeps im assuming its not posting but Im a total supermicro noob so…\n    submitted by    /u/BoltBoy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzfth9/x13saef_not_posting/",
          "publishedOn": "2022-12-31T00:05:57.000Z",
          "wordCount": 15061,
          "title": "X13SAE-F not posting",
          "imageUrl": "https://external-preview.redd.it/QOhiqufhkwICyXLp6WB3p2mokeyAAQVnaTsTLAESXZo.jpg?auto=webp&s=c66efd133bcbad3ddbe3696f4b05eaa40d944a7b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzezuz/building_a_combo_nas_server/",
          "author": null,
          "description": "Hi there! ... \n I'm in the process of upgrading my home network and I need to build a NAS. \n From the research I've been doing on different NAS drives, it seems the common sentiment is that they're noisy for a Home Lab. \n My 24U rack sits next to my desk where I do most of my work, it's within arms reach, do you think NAS drives will be too noisy for that situation, and if so, would any of you know any alternatives I could use? \n I really only need 10 or so Terabytes, so just a few 4TB drives or even 2TB drives would be fine. \n I thought about going with SSD's, but would be pretty expensive for large storage amounts, and I've heard that regular HDD's probably wouldn't last very long. This won't be a very heavily used NAS, just used for storage and only really accessed a few times a day. \n Also, as a sidenote, I'm also upgrading the internal network to 10g so the faster the NAS the better, I'm mostly using it for storing video and music recordings. \n Anybody have any drive suggestions I could look at?\n    submitted by    /u/IBreedBagels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzezuz/building_a_combo_nas_server/",
          "publishedOn": "2022-12-30T23:30:51.000Z",
          "wordCount": 15288,
          "title": "Building a Combo NAS / Server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zze4la/mini_file_server_hardware_recommendations/",
          "author": null,
          "description": "I want to build a small file server for home use and can't find exactly the type of hardware I'd like. The old N40L microservers from HP were exactly what I want, but they're too old now.\n Requirements are simply:\n  \nECC RAM\n At least 3 SATA ports\n  \nNot looking for rack-mountable. I'm aiming for as close to $500 as possible (before the cost of drives). Is there anything modern like those N40L servers?\n All the current-gen microservers are at least $900 and more like $2500. I considered the Dell T40 but it only includes one hard drive bay despite having more than one SATA port...\n    submitted by    /u/rdcldrmr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zze4la/mini_file_server_hardware_recommendations/",
          "publishedOn": "2022-12-30T22:54:21.000Z",
          "wordCount": 15182,
          "title": "mini file server (hardware recommendations)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzdvo1/hp_z840_help/",
          "author": null,
          "description": "I'm kind of a newbie to pc builds and stuff so bear with me please\n My hp z840 was found in an old work place which a family member took home for me, it has a gtx 1060 6gb gpu, intel xeon e5-2680 v4 cpu, 32gb ddr4 ram 2400mhz\n I'm thinking of upgrading some parts for gaming on 1080p both cpu and gpu bound games (mostly gpu bound) and was wondering if anyone could help me in reccomending parts for the upgrade, its hard for me to do with on my own as I'm worried for bottlenecks\n    submitted by    /u/Ace_aura112  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzdvo1/hp_z840_help/",
          "publishedOn": "2022-12-30T22:43:42.000Z",
          "wordCount": 15512,
          "title": "HP Z840 help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzdr70/probably_one_of_the_best_xeon_v4_processors_for/",
          "author": null,
          "description": "e5-2697 v4 has been sprouting up in ebay now for a while quite cheap. I got a matching pair for $180 a few weeks ago.\n ​\n Tis the season for upgrades!\n    submitted by    /u/uberbewb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzdr70/probably_one_of_the_best_xeon_v4_processors_for/",
          "publishedOn": "2022-12-30T22:38:32.000Z",
          "wordCount": 15039,
          "title": "Probably one of the best xeon v4 processors for budget",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzdjh3/choosing_a_managed_smart_switch_to_work_with/",
          "author": null,
          "description": "Hi ! \n I'm looking to add a managed switch behind my pfSense router in order to separate LANs. \n My pfSense runs on a m720q from Lenovo within Proxmox. My m720q has 3 NICs. One for Proxmox (might change since i'm currently in a double NAT configuration), one for pfSense WAN, one for pfSense LAN. No SR-IOV on my NICs but i'm not sure that would benefit me anyway. \n I think the best solution would be to add a managed switch behind my pfSense LAN NIC. This managed switch would provide at least three VLANs, one for my NAS / homelab gear, one for private network (NICs in walls in every room, wifi AP), and one for smart home devices. \n I've read that this sub doesn't like consumer grade gear and prefer used entreprise gear. I agree with that but couldn't fit a whole 19\" switch, since I'm building my homelab within a small furniture, which max width is about 12\" (30cm).\n From here do you know about an afordable new / refurbished / used model that would fit my need ? I tend to like Tp Link and Mikrotik as they seem to have good overall value. \n MIKROTIK RB260GS looks like a good solution, what do you think ? \n Thanks a lot !\n    submitted by    /u/ShiningPak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzdjh3/choosing_a_managed_smart_switch_to_work_with/",
          "publishedOn": "2022-12-30T22:29:41.000Z",
          "wordCount": 15143,
          "title": "Choosing a managed \"smart\" switch to work with pfSense",
          "imageUrl": "https://external-preview.redd.it/UkExvlKsgr8PoeCV1fc7M8kO7zYgFV7YXIiQxOY_Xow.jpg?auto=webp&s=93ce92291ea7361db20d6bc96c3033b761f63b3c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzdivk/where_do_i_find_out_which_sata_hba_to_buy/",
          "author": null,
          "description": "And how reliable are they generally? I have a little PCIe to SATA card that doesn't seem to work properly.\n How much does a decent SATA HBA cost? And are there certain features I should look out for?\n Do I need to ensure it receives server-like airflow over it?\n    submitted by    /u/Pyroven  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzdivk/where_do_i_find_out_which_sata_hba_to_buy/",
          "publishedOn": "2022-12-30T22:28:59.000Z",
          "wordCount": 15539,
          "title": "Where do I find out which SATA HBA to buy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzdgao/can_an_ssd_fit_in_a_pcie_adapter_for_proxmox/",
          "author": null,
          "description": "I want to redo my setup but keep all 8 drives on the front of my r830 server for storage. The answer is very unclear if I can use an ssd adapter to put an ssd in a pci slot in my Dell poweredge r830 as a boot drive for proxmox.\n I've seen some answers that some M.2 drives work but not others but no answer on a ssd. I also see some saying the drive will show up but not work as a boot drive. I guess that's not a big deal if it won't work as a boot as I still get to keep the same amount of drives but just not sure if this adventure is worth the time and money to figure out if it will work.\n    submitted by    /u/GUI-Discharge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzdgao/can_an_ssd_fit_in_a_pcie_adapter_for_proxmox/",
          "publishedOn": "2022-12-30T22:25:50.000Z",
          "wordCount": 15007,
          "title": "can an ssd fit in a pcie adapter for proxmox install on r830?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzdas7/gigabit_router_suggestions/",
          "author": null,
          "description": "Currently I am using a FW2B for my router, and I'm looking to upgrade. I want to upgrade because I'm now on a 1000/20 connection, and it seems like my current router can't handle it. Currently I've got my eyes set on the RB4011 from MicroTik, but I'm not sure if that will be the best choice. \n I don't have any spare PCs lying around, and the RB4011 seemed to be cheaper than rolling my own solution. However, I wanted to get some second opinions as well as look around and research before I make my purchase. \n Things I want my router to do:\n - WireGuard\n -DHCP Leasing\n -Basic Firewall rules and NAT\n -As mentioned earlier, Gigabit throughput \n -Not necessarily dead quiet, but not loud enough to be annoying\n Thanks for any useful information or advice.\n    submitted by    /u/real_anthonii  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzdas7/gigabit_router_suggestions/",
          "publishedOn": "2022-12-30T22:19:16.000Z",
          "wordCount": 14966,
          "title": "Gigabit Router Suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzcp5i/followup_on_cumulus_switch/",
          "author": null,
          "description": "submitted by    /u/tdavis25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzcp5i/followup_on_cumulus_switch/",
          "publishedOn": "2022-12-30T21:54:50.000Z",
          "wordCount": 14910,
          "title": "Followup on Cumulus Switch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzc0r5/my_lab_table/",
          "author": null,
          "description": "The server is a HP DL380p Gen 8 with 2 Xeon E5-2660 8 Core 16 thread cpus @2.2GHz and 128GB DDr3 ECC 1333MHz ram with 14TBs of total storage.\n    submitted by    /u/Kittens_YT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzc0r5/my_lab_table/",
          "publishedOn": "2022-12-30T21:26:39.000Z",
          "wordCount": 15682,
          "title": "My lab table",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zzbzwp/need_advice_from_the_experts_on_a_potential/",
          "author": null,
          "description": "In my current setup, I have a small server (HP Z600) that runs proxmox, and has several VMs running on it including Home Assistant, PiVPN, and Pihole, along with Ubuntu Desktop. I have another PC running my plex server, and yet another pc running truenas with only a couple of disks in it. I also have a 4 disk standalone Buffalo NAS that I've had for a long time. I would like to get a new, more powerful server to be able to consolidate some of these things and expanding my storage capabilities (and/or free up current hardware for tinkering on other projects). Here's what I'd like to use the new server for:\n 1) primary NAS for my Plex media with 8-12 drives for storage.\n 2) Hypervisor for not only the VMs that I mentioned above, but also for a couple of windows VMs for various things, and maybe even a hackintosh vm.\n 3) Run a web server. This can be done on one of the VMs mentioned above though...\n I've had my eye on a Dell r720 with 8 LFF drive bays, 20 cores, 192 GB ram... Would this be a good choice for the things I want to do? If so, what operating system should i consider running? I like proxmox, but how will I use the drives as a NAS (preferably with some redundancy)? I have heard that i'll have to do some advanced stuff to the hardware RAID card if I want to install truenas - plus, I'm not sure that TruNAS as the os would let me do all the VM stuff I want to do. I'd love some advice on how to make this work. Thanks in advance!\n    submitted by    /u/Evelle_Snoats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zzbzwp/need_advice_from_the_experts_on_a_potential/",
          "publishedOn": "2022-12-30T21:25:39.000Z",
          "wordCount": 15784,
          "title": "Need advice from the experts on a potential server purchase",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zz8ti0/how_do_you_keep_rdma_on/",
          "author": null,
          "description": "I installed Server 2022 on the server, switched to pro workstation on the... workstation and RDMA runs well when it does.\n But whenever I first power on the workstation or if the workstation goes to sleep RDMA is lost. It resumes when I reset but it's not ideal.\n How do I keep RDMA from tripping (balls)?\n ​\n https://preview.redd.it/i9s1bd7o439a1.png?width=353&format=png&auto=webp&s=c39484bfdf7c0bab2e6cdbc420dd6e10776570c3\n    submitted by    /u/mcdroid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zz8ti0/how_do_you_keep_rdma_on/",
          "publishedOn": "2022-12-30T19:15:38.000Z",
          "wordCount": 14827,
          "title": "How do you keep RDMA on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zz8mjj/homelab_via_midjourney/",
          "author": null,
          "description": "submitted by    /u/BlessedChalupa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zz8mjj/homelab_via_midjourney/",
          "publishedOn": "2022-12-30T19:07:37.000Z",
          "wordCount": 16925,
          "title": "“Homelab” via Midjourney",
          "imageUrl": "https://external-preview.redd.it/AerOxyEOeNc5gM1Q7FC4HobsMKm855xW8XK-501CSuo.jpg?auto=webp&s=cac009ee33898d8036f8bc16b63ad37e3ae7db7b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zz5yr5/fixing_up_an_lto_5_tape_drive_to_incorporate_into/",
          "author": null,
          "description": "submitted by    /u/TechShocked  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zz5yr5/fixing_up_an_lto_5_tape_drive_to_incorporate_into/",
          "publishedOn": "2022-12-30T17:20:03.000Z",
          "wordCount": 15907,
          "title": "Fixing up an LTO 5 Tape Drive to incorporate into my backup system!",
          "imageUrl": "https://external-preview.redd.it/xaCMdQBysl0Le2BktM9S4ZtoA4xoG_tAjgolo4kPfDg.jpg?auto=webp&s=f489af726fe8138eecc2e17ea8d409f9632b88ca"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zz5tc8/best_os_for_homelab_cluster/",
          "author": null,
          "description": "I have had a couple second hand servers and have been tinkering with them for quite a few months, but now I want to set them up in a more “professional” way (basically not having a messy chaos as I have right now). What would be ideal for me:\n  \nProduction node: this node will be hosting the VMs and containers I want to be HA, and that can’t afford to be down/broken if I screw up (Nextcloud, Home Assistant, Nginx, AdGuard, etc.).\n Tinkering node: a node fully used for testing and trying stuff (VMs, Docker, OSs, etc.)\n Storage node: a node used only for storage for the other two nodes (probably iSCSI). The other nodes will have just two mirrored SSDs for booting, and maybe another two for latency-sensible VMs in the production node.\n  \nMy goals: - Scalability: having storage-oriented and performance-oriented nodes makes the setup more flexible when trying to upgrade the cluster. - Flexibility: being able to move VMs between nodes without much hassle is KEY for me. Having the ability to move VMs from the servers to a PC Hypervisor and viceversa would also be ideal, but I understand that this is more complicated to achieve. - Ease of use: managing everything through a single interface would be much appreciated. Also being able to run Docker directly on the Hypervisor would be great. An easy to use offsite backup solution is also important.\n For the moment I have just used Proxmox (independent nodes, not clustering), and while the experience has been mostly great, it lacks some features, being Docker the most important one. I wanted to know what you guys are using and what is your experience. Thanks in advance!\n    submitted by    /u/Lcs_26  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zz5tc8/best_os_for_homelab_cluster/",
          "publishedOn": "2022-12-30T17:14:06.000Z",
          "wordCount": 17326,
          "title": "Best OS for Homelab cluster",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zz32wz/lenovo_tiny_p320_proxmox_10g_pfsense_box/",
          "author": null,
          "description": "Around this time of year, I start to get itchy fingers and need a project to kill a day or so, off i went researching and have now pfsense running 10Gb, totally overkill yes but hey ho\n Spec: i5-7500T 16Gb 512GB nvme 10Gb Mellanox ConnectX-3 MCX312A-XCBT 1x 10Gb DAC 1x 10GBASE-T SFP+ RJ45 Transceiver Module (FS.com SFP-10G-T) 3x Zyxel XGS1210-12 around the house\n ISP - 1Gb Virgin Media UK - SH5 in Modem mode using 2.5GBe port.\n Running proxmox just for the hell of it, the machine runs at 15W-17W idle which is pretty good for 10Gb card and 10GBASE-T module as they run quite power heavy. \n I may setup another pihole for HA but will have to see, got to make most of proxmox!\n Currently running Cat5e and Cat6 around the house so using the 2.5Gb switch ports for some runs, this works quite well, my Unraid server has a 2.5Gbe onboard and iperf from pfsense to it maxes out the 2.5gbe, im also taking advantage of the over-provisioning Virgin do with the speeds.\n Next is to grab a 10Gbe card for Unraid and see if I can get away with running anything up to 10Gb over Cat6\n This all replaced a HP T730 with 4x Intel Nic card\n All good fun!\n    submitted by    /u/bigup7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zz32wz/lenovo_tiny_p320_proxmox_10g_pfsense_box/",
          "publishedOn": "2022-12-30T15:22:55.000Z",
          "wordCount": 17324,
          "title": "Lenovo Tiny P320 - Proxmox - 10G PFsense Box",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zz2lx7/3d_printed_prototype_homelab_enclosure/",
          "author": null,
          "description": "submitted by    /u/reemster0180  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zz2lx7/3d_printed_prototype_homelab_enclosure/",
          "publishedOn": "2022-12-30T15:02:34.000Z",
          "wordCount": 17098,
          "title": "3d printed (prototype) homelab enclosure",
          "imageUrl": "https://preview.redd.it/oya0dyw5d39a1.jpg?auto=webp&s=2fcc69c21082388fc1e81ba0e16152032c7aa2f4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zz2h5m/how_many_devices_do_you_have_running_linux/",
          "author": null,
          "description": "Ever since I started this HomeLab journey, I have just been adding more and more Linux devices to my list \n Right now I have about 5 devices running linux and I think I will add another today \n Just unsure of what to do with my new one (number 6)\n    submitted by    /u/theguy_win  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zz2h5m/how_many_devices_do_you_have_running_linux/",
          "publishedOn": "2022-12-30T14:57:07.000Z",
          "wordCount": 18417,
          "title": "How many devices do you have running Linux?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zz01cl/small_homelab_setup_community_support/",
          "author": null,
          "description": "Hi Homelab Community!\n I've been enjoying this subreddit for some time now, while trying to figure out how to set up my own home network/lab. Based on what I've learnt here (and elsewhere), I have a plan. But I would love to get some feedback from the community.\n Motivation: Update my home network from my 10 year old router running OpenWRT to something more performent, secure, and future proof. Also to learn about networking and have some fun.\n Background: I don't work in tech, but I do programming for work (data science) and I have some basic knowledge when it comes to hardware. However, networking is pretty new to me; the most advanced thing I've done is to flash OpenWRT on my router and set up some VLANs (I also had some home automation stuff on a RasperryPi many years back).\n Prioritie…",
          "link": "https://www.reddit.com/r/homelab/comments/zz01cl/small_homelab_setup_community_support/",
          "publishedOn": "2022-12-30T13:03:33.000Z",
          "wordCount": 18403,
          "title": "Small Homelab Setup - Community Support",
          "imageUrl": "https://external-preview.redd.it/eZEP-a5UOxE4hnaN5JzBMTL4ANpnNCAJyBOgS22LlkM.jpg?auto=webp&s=b8cfd3755f2bdf16d0f923feeb2a1a83df3badb2"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zymhc5/recently_moved_out_on_my_own_for_the_first_time/",
          "author": null,
          "description": "submitted by    /u/TheTechDudeYT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zymhc5/recently_moved_out_on_my_own_for_the_first_time/",
          "publishedOn": "2022-12-30T01:05:56.000Z",
          "wordCount": 16297,
          "title": "Recently moved out on my own for the first time. Apartment Homelab V1!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zyl9nq/has_anyone_used_these_silverstone_cases_for_their/",
          "author": null,
          "description": "submitted by    /u/MJCS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zyl9nq/has_anyone_used_these_silverstone_cases_for_their/",
          "publishedOn": "2022-12-30T00:14:43.000Z",
          "wordCount": 15962,
          "title": "Has anyone used these SilverStone cases for their Home Lab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zykhf2/are_there_any_nas_solutions_that_offer_storage/",
          "author": null,
          "description": "It seems that all I could find was windows storage spaces, along with add on software to add it to ZFS. \n ZFS does offer ARC, but that's an adaptive replacement cache so it constantly writes to drives.\n    submitted by    /u/ThreeLeggedChimp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zykhf2/are_there_any_nas_solutions_that_offer_storage/",
          "publishedOn": "2022-12-29T23:43:39.000Z",
          "wordCount": 15522,
          "title": "Are there any NAS solutions that offer storage tiering?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zyk4j9/cant_find_r310_readyrails_for_36_rack/",
          "author": null,
          "description": "Hi all! \n I recently got myself an R310 and I need to find some rails that work with a 36\" rack. I bought some rails for the R310, but they fall a bit short of the end of my rack, so I can't use those. I'm struggling to find any ReadyRails that will fit the R310 and a 36\" rack, and I don't want to resort to using universal rails unless I have to. Does anyone know of the part number for rails that would suit my needs? \n Thanks!\n    submitted by    /u/milanmdevreal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zyk4j9/cant_find_r310_readyrails_for_36_rack/",
          "publishedOn": "2022-12-29T23:29:33.000Z",
          "wordCount": 14950,
          "title": "Can't find R310 ReadyRails for 36\" Rack",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zyjxar/wiki_or_a_static_website_for_homelab_description/",
          "author": null,
          "description": "Hi,\n I'm looking for a basic wiki or a website where I would write some info about homelab and other tech related stuff used at home so all the people living with me have some info about what is going on. Something with the aspect of readthedocs for example. I found wikijs but it looks like too big for what I want.\n Do you recommed anything?\n    submitted by    /u/josescxavier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zyjxar/wiki_or_a_static_website_for_homelab_description/",
          "publishedOn": "2022-12-29T23:21:32.000Z",
          "wordCount": 16151,
          "title": "Wiki or a static website for homelab description",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zyjptu/really_liked_the_concept_of_the_jonsbo_n1_so_i/",
          "author": null,
          "description": "I just completed this design. Once I actually build this and work out the kinks I'll share the files. I'll share the model files so they can be modified.\n Design\n BOM (WIP)\n From my last build, I have plenty of Aluminum Extrusion. I saw the Jonsbo N1 and challenged myself to make a 3D Printed replica. I have no need to upgrade my NAS right now, but I really want to after designing this. \n Comparison\n  \n  Jonsbo N1 3D Printed N1 Notes \n  \n Product Size (mm) 170 x 354 x 217 (13.05L) 204 x 367 x 204 (11.11L) 200 without panels \n  Hardware Material 2.5mm AL & 1mm Steel 3DP Filament & 2020 AL Extrusion  \n  Hard Disk Bay 1x 2.5\" & 5x 3.5\" 1+ 2.5\" & 5x 3.5\" Theoretically I see 3 locations for 2.5\" drives, just print more brackets. \n  Compatible Motherboard ITX ITX  \n  PCI Expansion Slot 1x Low Pr…",
          "link": "https://www.reddit.com/r/homelab/comments/zyjptu/really_liked_the_concept_of_the_jonsbo_n1_so_i/",
          "publishedOn": "2022-12-29T23:13:23.000Z",
          "wordCount": 19084,
          "title": "Really liked the concept of the Jonsbo N1 so I made, as close as possible, a 3D Printed replica with Aluminum Extrusion.",
          "imageUrl": "https://external-preview.redd.it/yZ871drjq08CMqXCQ7vvO50XORhLLXtCwqEX3aRc_eU.jpg?auto=webp&s=9e51e825777e2f215719c3717b0e70b5547bef6a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zyjk3p/question_need_u_guys_opinion_about_some_nics/",
          "author": null,
          "description": "Currently building a router from a thinclient.\n But don't really know what NIC to get, I got an NAS which is being used at least a couple of hours a day for large files. So 2,5 or 10 would be better in my eyes. Also in the market for a new switch so 2.5 and 10 are an option.\n Currently looking at the following 3 NICS, but open for suggestions;\n HP Ethernet 10Gb 2-port 561FLR-T\n HP FlexFabric 10Gb 2-port 533FLR-T\n Intel PRO/1000 PT Dual or Quad \n The reason for those NICS, is that I can buy them second hand here in Europe for under 50 euros.\n    submitted by    /u/itz_game_pro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zyjk3p/question_need_u_guys_opinion_about_some_nics/",
          "publishedOn": "2022-12-29T23:07:10.000Z",
          "wordCount": 15134,
          "title": "Question: Need u guys opinion about some NICS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zyj3ge/upgrade_existing_server_or_get_a_new_one/",
          "author": null,
          "description": "Hi, \n I recently got a cheap (280€) Dual Xeon Silver 4110 based Supermicro Server with 128GB RAM on eBay.\n The system itself works just fine however the CPUs are too slow for the intended purpose as a virtualization server. \n I'm now unsure whether it's worth upgrading the CPUs to some Xeon Gold Chips as most of them are priced at 250-300€ per CPU on eBay. \n At around 600€ I can already buy a similar performing second-hand AMD EPYC-based CPU including a new motherboard. \n As electricity is getting super expensive (59ct per kWh in Germany) I have to consider the power consumption as well. \n I'd love to hear your advice as I'm not sure if it's worth spending more money on the Intel Scalable platform or just leaving the system as it is and maybe using it for something else. \n I'd also have to upgrade the RAM, It currently has 8*16 2666MHz sticks, can I mix it with a few 32GB or even 64GB sticks with the same speed? \n Thanks!\n    submitted by    /u/v3ng00  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zyj3ge/upgrade_existing_server_or_get_a_new_one/",
          "publishedOn": "2022-12-29T22:48:44.000Z",
          "wordCount": 16294,
          "title": "Upgrade existing server or get a new one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zyit1p/anyone_here_with_an_iris_plus_655/",
          "author": null,
          "description": "Would anyone here have a system that has an iris plus 655 running windows? I'm desperately trying to find out which version of WDDM this chip will support as I need 2.7+ for gpu-pv\n If you happen to have one could you please be so kind to reply with the version fo WDDM as per dxdiag.exe?\n    submitted by    /u/bananna_roboto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zyit1p/anyone_here_with_an_iris_plus_655/",
          "publishedOn": "2022-12-29T22:36:52.000Z",
          "wordCount": 14886,
          "title": "anyone here with an iris plus 655?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zyishx/help_building_my_first_homelab_nas_server/",
          "author": null,
          "description": "Hi all,\n So I'm very new to homeservers. I'm currently running Nextcloud and some projects on a Raspberry Pi 4B with an external ssd. I've been looking into a NAS for a while now and wish to learn and experiment a bit more with a homelab / NAS server.\n What I want to do:\n  \nRun proxmox as a host OS, deploy different VM's/containers for services like Nextcloud, HA, Jellyfin, TrueNAS. At the moment I don't need too much storage, I would like to be able to expand in the future. \n  \n​\n What I've been looking to get:\n ​\n  \n CPU AMD Ryzen 5 3600 (AWOF Boxed) Hexa Core, ECC support € 89,90 \n  \n MB ASRock fatal1ty B450 Gaming-ITX/ac € 114,90 \n  M.2 NVE SSD WD PC SN730 (SED) 256GB (for OS) € 39,99 \n  RAM 2x 16GB KINGSTON KSM26ED8/16HD (ECC support) € 60,03 each, € 120,06 total \n  CASE Fractal Design Node 304 € 91,00 \n  HDD 2x Seagate IronWolf NAS HDD, 4TB € 83,95 each, €167,90 total \n  PSU Cooler Master V550 SFX Gold € 63,61 \n   Total € 687,21 \n \n Is this a solid start or do you have any other recommendations? Also energy out here is not cheap at all. I'm currently paying around € 0,70/kWh here, so it would be nice to keep this low..\n    submitted by    /u/PyVid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zyishx/help_building_my_first_homelab_nas_server/",
          "publishedOn": "2022-12-29T22:36:13.000Z",
          "wordCount": 16072,
          "title": "Help building my first homelab / NAS server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zyirqx/truenas_scale_vs_proxmox/",
          "author": null,
          "description": "Hello people, been running Proxmox with virtualized TrueNas Scale. Since i no longer use my HBA because of power being too expensive in Germany, i added passthrough of the disks directly. However performance is not 100% perfect like before. Now i am thinking if i could just switch to TrueNas Scale directly on the Host.\n The real Question/Problem is VMs in TrueNas. Does anybody know what’s best practice for doing VM Backups in TrueNas Scale?\n Thanks!\n    submitted by    /u/Floroform  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zyirqx/truenas_scale_vs_proxmox/",
          "publishedOn": "2022-12-29T22:35:21.000Z",
          "wordCount": 14912,
          "title": "Truenas Scale vs Proxmox",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zye0el/do_you_own_a_raspberry_pi_or_similar_sbc_if_yes/",
          "author": null,
          "description": "submitted by    /u/CallMeMichele0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zye0el/do_you_own_a_raspberry_pi_or_similar_sbc_if_yes/",
          "publishedOn": "2022-12-29T19:29:52.000Z",
          "wordCount": 16859,
          "title": "Do you own a Raspberry Pi or similar sbc? If yes, what do you use it for?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zydihh/3d_printed_an_adapter_to_put_my_desktop_switch_on/",
          "author": null,
          "description": "submitted by    /u/marxist_redneck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zydihh/3d_printed_an_adapter_to_put_my_desktop_switch_on/",
          "publishedOn": "2022-12-29T19:10:49.000Z",
          "wordCount": 15505,
          "title": "3D printed an adapter to put my desktop switch on the rack",
          "imageUrl": "https://preview.redd.it/3cj56xw0zv8a1.jpg?auto=webp&s=3cb8ebe5ecd499b478f1965d02a3469272a13481"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zybnzt/finally_completed_the_great_data_migration_see_ya/",
          "author": null,
          "description": "submitted by    /u/Theduke322  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zybnzt/finally_completed_the_great_data_migration_see_ya/",
          "publishedOn": "2022-12-29T17:58:37.000Z",
          "wordCount": 17518,
          "title": "Finally completed the \"Great Data Migration\", see ya Unraid!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zy9n49/homelab_v2/",
          "author": null,
          "description": "submitted by    /u/onept351  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zy9n49/homelab_v2/",
          "publishedOn": "2022-12-29T16:36:05.000Z",
          "wordCount": 15988,
          "title": "Homelab V2",
          "imageUrl": "https://preview.redd.it/7jh5djaa6v8a1.jpg?auto=webp&s=719ae0689a2d929c121af10c6664f8a0d1a9970c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zy9gu0/possible_to_run_optiplex_3050_usff_on_battery/",
          "author": null,
          "description": "I picked up a Dell OptiPlex 3050 USFF for $20, and I would love to turn it into a mobile/portable lab. I have 32GB of RAM coming for it, and it has the i5-7500. I'm going to put a hypervisor on it to run some VM's for a lab.\n It's powered by a Dell 65W laptop brick, and I was wondering if anyone knew of a good way to power this from a battery pack so I could use it as a mobile/portable lab?\n    submitted by    /u/Taylor_Script  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zy9gu0/possible_to_run_optiplex_3050_usff_on_battery/",
          "publishedOn": "2022-12-29T16:28:59.000Z",
          "wordCount": 16594,
          "title": "Possible to run OptiPlex 3050 USFF on battery?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zy6tvp/first_start_on_my_home_lab_setup_any_tips_on/",
          "author": null,
          "description": "submitted by    /u/SpicyLettive  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zy6tvp/first_start_on_my_home_lab_setup_any_tips_on/",
          "publishedOn": "2022-12-29T14:34:35.000Z",
          "wordCount": 15250,
          "title": "First start on my home lab setup. Any tips on further improvement or suggestions.",
          "imageUrl": "https://preview.redd.it/dlux7uk83w8a1.jpg?auto=webp&s=db3fcd6a8454aa551df2f43816207ae917728ab4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zy63n2/how_the_italians_hold_the_servers/",
          "author": null,
          "description": "submitted by    /u/RetrOS13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zy63n2/how_the_italians_hold_the_servers/",
          "publishedOn": "2022-12-29T14:00:40.000Z",
          "wordCount": 15996,
          "title": "how the italians hold the servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zy5io8/what_are_your_must_docker_containers_for_home_lab/",
          "author": null,
          "description": "submitted by    /u/Accomplished-Eye1673  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zy5io8/what_are_your_must_docker_containers_for_home_lab/",
          "publishedOn": "2022-12-29T13:33:00.000Z",
          "wordCount": 16924,
          "title": "what are your must docker containers for home lab?",
          "imageUrl": "https://preview.redd.it/hqs85bx9sv8a1.jpg?auto=webp&s=f589d8edba2c0968de5cfdbc1db8c2090d2b2fbb"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zy464k/would_like_to_replace_the_fans_on_an_fs/",
          "author": null,
          "description": "submitted by    /u/ajgnet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zy464k/would_like_to_replace_the_fans_on_an_fs/",
          "publishedOn": "2022-12-29T12:24:11.000Z",
          "wordCount": 16014,
          "title": "Would like to replace the fans on an FS S5860-24XB-U w/ Noctua NF-A4x20s but not sure where to start - are these PWM fans? How do I figure out the wiring?",
          "imageUrl": "https://preview.redd.it/b2zldepbyt8a1.jpg?auto=webp&s=1c4b076649ee8ba43fcbc83c26ebb937e745a459"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxzdnr/looking_for_advices_on_how_to_setup_19_rack/",
          "author": null,
          "description": "submitted by    /u/Alara_Kitan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxzdnr/looking_for_advices_on_how_to_setup_19_rack/",
          "publishedOn": "2022-12-29T07:41:01.000Z",
          "wordCount": 18587,
          "title": "Looking for advices on how to setup 19\" rack spaces in there for cheap",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxviqq/apparently_primocache_works_pretty_well/",
          "author": null,
          "description": "submitted by    /u/Wilkinz027  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxviqq/apparently_primocache_works_pretty_well/",
          "publishedOn": "2022-12-29T04:21:48.000Z",
          "wordCount": 16323,
          "title": "Apparently Primocache works pretty well.",
          "imageUrl": "https://preview.redd.it/4dfnl0px1t8a1.jpg?auto=webp&s=75cdbbda7f6a691f799ff30ff9a12c7aad1363d9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxrpuz/build_my_own_server/",
          "author": null,
          "description": "Hello everyone,\n I’m thinking of building my own home server that is capable of streaming music and movies to my iPhone and TV. On top of that, I would like to back-up files from my PC. More importantly, I would like to build my own VPN too. \n Currently, I’m a student who is learning computer programming. Recently, I just build my own PC and I would like to take on a new project.\n What type of advice would you provide in relation to hardware and software requirements? Are there any particular guide sites that you would recommend that would help me along the way? This can include YouTube channels too.\n Any advice would be greatly appreciated.\n Thank you.\n    submitted by    /u/techwithstef  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxrpuz/build_my_own_server/",
          "publishedOn": "2022-12-29T01:32:28.000Z",
          "wordCount": 14941,
          "title": "Build My Own Server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxqnv1/windows_or_linux_as_your_base_server_os/",
          "author": null,
          "description": "I plan on running both in a VM but which would suit better for the serve os? I plan on using a windows machine to remote desktop in to the parent os so i'm leaning windows but wanted to know if there was anything i may be overlooking or if there were a strong argument for Linux.\n    submitted by    /u/29Top  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxqnv1/windows_or_linux_as_your_base_server_os/",
          "publishedOn": "2022-12-29T00:48:41.000Z",
          "wordCount": 15396,
          "title": "Windows or Linux as your base server os?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxq99h/need_answer_quick/",
          "author": null,
          "description": "Not sure if this is related or not but if you have comcast do you have gigabit (1000) or gigabit extra (1200) which one should I get it's 10 dollar difference but not sure if there is any extra performance from it\n    submitted by    /u/joeyp0716  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxq99h/need_answer_quick/",
          "publishedOn": "2022-12-29T00:31:45.000Z",
          "wordCount": 15483,
          "title": "need answer quick",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxpskq/esxi_cluster_with_dell_7040_mffs/",
          "author": null,
          "description": "Hey all,\n Looking at picking up 4 Dell 7040 MFFs with i7-6700t and loading them each up with 32gb ddr4 and utilizing esxi 7.x cluster with ha/fo with a nfs data store with 60tb raw. Have a VMUG license already\n Just trying to hear your thoughts on the matter. I'm a long time esxi/vcenter fan boy/user. Currently have a single host esxi server i7-11700t rig but recently had a pink screen of death that took everything down till a reboot and wanting to have some redundancy now.\n    submitted by    /u/Orm1server  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxpskq/esxi_cluster_with_dell_7040_mffs/",
          "publishedOn": "2022-12-29T00:12:56.000Z",
          "wordCount": 15530,
          "title": "ESXI CLUSTER WITH DELL 7040 MFFs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxpp2t/hey_were_upgrading_our_core_network_you_want_one/",
          "author": null,
          "description": "Work is upgrading their core network and ditching all their Cumulus switches in the process. Been wanting more 10gb ports so one of the infra engineers reached out and asked if I wanted a cx-4048. I said heck yeah! 48x10gb and 6x40gb(!!!).\n Now to figure out power requirements for this beast.\n    submitted by    /u/tdavis25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxpp2t/hey_were_upgrading_our_core_network_you_want_one/",
          "publishedOn": "2022-12-29T00:09:04.000Z",
          "wordCount": 15225,
          "title": "\"Hey, we're upgrading our core network. You want one of the switches we're tossing?\"",
          "imageUrl": "https://external-preview.redd.it/2Gu6fOfgxEzoiEU5Km7-nVsfhcuzgyYWSFKowC6IIqc.jpg?auto=webp&s=41c5f7b627170846a0fff42b4d61bc3d3d31151c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxoyrs/lenovo_p520_as_a_server/",
          "author": null,
          "description": "I was wondering if I should move from my dell R440 to a lenovo p520 with a xeon w-2175, core count would be higher but is it an upgrade or not as both have 128gb ecc ram and using an hba for my book stack.\n The p520 have more pci 16x slots for adding 10gb nic card and a 1080gt.\n    submitted by    /u/resident-not-evil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxoyrs/lenovo_p520_as_a_server/",
          "publishedOn": "2022-12-28T23:40:13.000Z",
          "wordCount": 14868,
          "title": "lenovo p520 as a server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxnbj7/its_a_start/",
          "author": null,
          "description": "submitted by    /u/ziriuz84  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxnbj7/its_a_start/",
          "publishedOn": "2022-12-28T22:36:16.000Z",
          "wordCount": 15114,
          "title": "It's a start",
          "imageUrl": "https://preview.redd.it/w1fglfbacr8a1.png?auto=webp&s=8cbcb8884f7f1b1419c0260d634cb7ea8de6f6ca"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxn4xt/advice_pls_short_ethernet_cables/",
          "author": null,
          "description": "We recently ran cat6a throughout the house. The builder ran the cables and left odd lengths of cable. Some cables are as short as 30cm others are over a metre. \n I have a full depth rack (1m) but I can adjust the mounting depth. For now I put the router mid rack, but even so, a lot of cables don't come close so I can't mount a patch panel at the same depth.\n I could mount the panel at the back of the rack and use long patch cables. Alternatively, I could cut the wires (I already terminated them) and extend them with a shielded cat6a junction box. \n What do you suggest as the best approach? \n Attached is a picture of the current mess I'm trying to tidy up.\n    submitted by    /u/djchillerz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxn4xt/advice_pls_short_ethernet_cables/",
          "publishedOn": "2022-12-28T22:29:14.000Z",
          "wordCount": 15519,
          "title": "Advice pls: Short ethernet cables",
          "imageUrl": "https://preview.redd.it/g0r3xiv0br8a1.png?auto=webp&s=97c4f0425c5da841a7d61d8590cd0f8ecd220300"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxmvnh/cable_management_is_overrated_when_you_have_27/",
          "author": null,
          "description": "submitted by    /u/iamcts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxmvnh/cable_management_is_overrated_when_you_have_27/",
          "publishedOn": "2022-12-28T22:19:10.000Z",
          "wordCount": 14955,
          "title": "Cable management is overrated when you have 27 drives in a case to cable up",
          "imageUrl": "https://preview.redd.it/tll16p189r8a1.jpg?auto=webp&s=4955f34473be257ad52740705bf174c7dd3ea796"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxlpll/first_time_parting_out_a_homelab_from_scratch/",
          "author": null,
          "description": "Hi all, I'm currently trying to part out a homelab from scratch (current set up is no more than a 2012 dell with some more ram and a few extra drives in it) and I was hoping for some tips and pointers from those who have treaded this path before. I will add that I’m no stranger to parting out and building gaming computers, but I’ve never touched anything like this outside of finding a new use for my old Dell XPS 8700.\n I've recently finished my undergrad and I’m currently residing in London, so cost and space are a premium. I’m thinking a sub-ATX motherboard that I can readily source from the used market. \n The most demanding thing it will be doing is hosting VM’s and serving as a rendering box and so I’m more than happy to use a platform that’s a few generations old.\n Right off the bat I’m not sure if I should go with a consumer/pro-summer/server motherboard. I know you can get retired server and workstation gear for cheap on the used market but I worry that must be folly for my application.\n Professional features like remote management would be a ‘nice to have’ but not at all necessary for my application. \n In regards to RAM, I have heard ECC memory is either 'a nice to have' or ‘damn right crucial’ for ZFS depending where I ask, and so some advice on memory type would be greatly appreciated.\n Besides that, if people could post what CPUs and cases they run for a budget and space friendly set up that would be greatly appreciated. I’ll post a couple that I have bookmarked incase anyone has any experience with them.\n    submitted by    /u/Working_Inspection22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxlpll/first_time_parting_out_a_homelab_from_scratch/",
          "publishedOn": "2022-12-28T21:33:51.000Z",
          "wordCount": 16135,
          "title": "First time parting out a homelab from scratch, looking for advice as a recent graduate in a small London flat",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxkmhg/my_home_lab/",
          "author": null,
          "description": "yeah its messy, but with all the computers in my work area... I have tons of processing power. Pick your OS, I'm sure you will see at least one device running it! lol\n https://preview.redd.it/ul732t6ccp8a1.jpg?width=4032&format=pjpg&auto=webp&s=9dabb55edffa9d3855d2de1081556df3a25c5d46\n https://preview.redd.it/d9zj3y6ccp8a1.jpg?width=3024&format=pjpg&auto=webp&s=bde4bb1f515a828920ea3569c99315708de00133\n    submitted by    /u/ThreadRipperPro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxkmhg/my_home_lab/",
          "publishedOn": "2022-12-28T20:51:57.000Z",
          "wordCount": 14883,
          "title": "My Home Lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxkdu8/server_rack_with_mounting_on_exterior_of_posts/",
          "author": null,
          "description": "I was browsing my local used marketplace when I found this server rack cabinet with its mounting holes on the outside on the posts.\n https://imgur.com/a/3xctqLJ\n Am I being an idiot or did the seller just assemble the rack wrong? I can't quite see how it gets assembled from the pictures and the seller doesn't know.\n If anybody knows what's going on here, I'd appreciate any help. Thanks.\n    submitted by    /u/ForgetsTheSlashS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxkdu8/server_rack_with_mounting_on_exterior_of_posts/",
          "publishedOn": "2022-12-28T20:42:20.000Z",
          "wordCount": 16738,
          "title": "Server rack with mounting on exterior of posts?",
          "imageUrl": "https://external-preview.redd.it/98Elx2gBWIXSxi8GpBkrg__EqNh8Yq6SdQp-qp0HS4Q.jpg?auto=webp&s=5cd9abf8b5d1f30f6409edce21328e82bef36dc5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxk0x2/weird_vps_disc_partitioning/",
          "author": null,
          "description": "What exactly is happening here? I have a VPS with 80 gigs of storage, but the OS (Ubuntu 22.04) can only access 40 gigabytes of it. When I look at the discs I see this, and I'm just confused. Can anyone help?\n https://preview.redd.it/cmcin2it7p8a1.png?width=504&format=png&auto=webp&s=aa75f4046c458123de98feb2e0fd9eac66dcef5d\n    submitted by    /u/Cats3214  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxk0x2/weird_vps_disc_partitioning/",
          "publishedOn": "2022-12-28T20:28:27.000Z",
          "wordCount": 17644,
          "title": "Weird VPS Disc Partitioning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxhl96/this_homelab_goes_hard_af_specs_in_comments/",
          "author": null,
          "description": "submitted by    /u/JakeGinesin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxhl96/this_homelab_goes_hard_af_specs_in_comments/",
          "publishedOn": "2022-12-28T18:53:16.000Z",
          "wordCount": 15990,
          "title": "This homelab goes hard af (specs in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxdc39/fastkubeflow_kubeflow_tutorial_sample_usage/",
          "author": null,
          "description": "I want to share the Kubeflow tutorial (Machine Learning Operations on Kubernetes), and usage scenarios that I created as projects for myself. I know that Kubeflow is a detailed topic to learn in a short term, so I gathered useful information and create sample general usage scenarios of Kubeflow.\n This repo covers Kubeflow Environment with LABs: Kubeflow GUI, Jupyter Notebooks running on Kubernetes Pod, Kubeflow Pipeline, KALE (Kubeflow Automated PipeLines Engine), KATIB (AutoML: Finding Best Hyperparameter Values), KFServe (Model Serving), Training Operators (Distributed Training), Projects, etc. Possible usage scenarios are aimed to update over time.\n Kubeflow is powerful tool that runs on Kubernetes (K8s) with containers (process isolation, scaling, distributed and parallel training).\n T…",
          "link": "https://www.reddit.com/r/homelab/comments/zxdc39/fastkubeflow_kubeflow_tutorial_sample_usage/",
          "publishedOn": "2022-12-28T16:06:21.000Z",
          "wordCount": 17178,
          "title": "Fast-Kubeflow: Kubeflow Tutorial, Sample Usage Scenarios (Howto: Hands-on LAB)",
          "imageUrl": "https://external-preview.redd.it/DAxAiZAHdHJf7VD1zB9f6ReZfh6bxLbemdOHzT6dKWE.jpg?auto=webp&s=ea3857469827d45b65eb0b24bd7cb6500c26fb59"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxc1vf/ups_for_small_installation/",
          "author": null,
          "description": "Hello everyone, \n I recently purchased a Qnap TS-464 and would like to add a UPS to my installation. I just need a few minutes of autonomy to shut down the NAS properly. Today I only have one NAS, three Raspi's and one switch, however I'm thinking of adding a small server in a while.\n Also, I've been looking at what UPS's are out there, however I'd like to know what your recommendations would be for this kind of small installation?\n Thanks and have a nice day!\n    submitted by    /u/kriscorp_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxc1vf/ups_for_small_installation/",
          "publishedOn": "2022-12-28T15:15:16.000Z",
          "wordCount": 16602,
          "title": "UPS for small installation.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxbg41/what_can_i_do_with_a_dell_wyse_3040/",
          "author": null,
          "description": "I have a spare Wyse box that I don't currently know what to do with. It's got an Intel Atom x5 and 8GB storage with dual DisplayPort, so I'm considering using it as a lite system for my Fiancee to play D&D on, but I don't really know what OS to use. \n Is there a lite OS I could install that would allow me to use RDP to a VM hosted on my home server? Or maybe someway to make the system boot to the VM?\n    submitted by    /u/Th3MadCreator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxbg41/what_can_i_do_with_a_dell_wyse_3040/",
          "publishedOn": "2022-12-28T14:51:00.000Z",
          "wordCount": 16668,
          "title": "What can I do with a Dell Wyse 3040?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zxadd1/what_hardware_mods_have_people_tryed_on_the_dell/",
          "author": null,
          "description": "[link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zxadd1/what_hardware_mods_have_people_tryed_on_the_dell/",
          "publishedOn": "2022-12-28T14:04:35.000Z",
          "wordCount": 16761,
          "title": "What hardware mods have people tryed on the Dell poweredge r710 ?",
          "imageUrl": "https://preview.redd.it/qksh43xzso8a1.jpg?auto=webp&s=17e2c44d2f5d8c880b236308083a05e12acb840f"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zx9jfe/new_nas_build_recommendations_road_to_efficiency/",
          "author": null,
          "description": "Hello everyone! I've been looking at buying a NAS for a while now, but now I'm thinking it would be more fun to build one.\n Usage would be mainly storage and cloud (eg. next-cloud) and some services (home assistant, docker containers, some VMs). Still don't know if Proxmox or TrueNAS scale as OS.\n I don't know what to choose for CPU and MB. What I was aiming for was to do everything at adequate performance but with an eye to energy consumption (Italy where energy is not free at all). Not a clear idea on the budget, mainly around 600/700 euros, lower the better.\n The only starting point was the case (Silverstone CS351), since is the only one with \"small\" size and hot-swap bays (which I'd like to have) that i found easily available, but anything better is welcomed.\n Thanks for the help!\n    submitted by    /u/Chachux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zx9jfe/new_nas_build_recommendations_road_to_efficiency/",
          "publishedOn": "2022-12-28T13:26:11.000Z",
          "wordCount": 17664,
          "title": "New NAS build recommendations - road to efficiency",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zx5dol/can_i_use_this_to_connect_my_server_to_the_ups/",
          "author": null,
          "description": "submitted by    /u/sohailoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zx5dol/can_i_use_this_to_connect_my_server_to_the_ups/",
          "publishedOn": "2022-12-28T09:29:26.000Z",
          "wordCount": 16336,
          "title": "can i use this to connect my server to the UPS directly or is there something special about PSU cable",
          "imageUrl": "https://preview.redd.it/a6vtgitwfn8a1.jpg?auto=webp&s=1bf9e102ba76a4ccfd9812aff23085247c6c6bf5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zx3u4p/so_i_bought_used_sas_drives_on_ebay/",
          "author": null,
          "description": "Was not disappointed 🙂\n    submitted by    /u/gougou_gaga  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zx3u4p/so_i_bought_used_sas_drives_on_ebay/",
          "publishedOn": "2022-12-28T07:50:15.000Z",
          "wordCount": 16833,
          "title": "So I bought used sas drives on ebay",
          "imageUrl": "https://preview.redd.it/f21335v7ym8a1.jpg?auto=webp&s=db17c1d653fed1d0a25b03f17fb89b68406002ad"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwyl2m/i_have_a_problem/",
          "author": null,
          "description": "submitted by    /u/Inevitable-Cow-7057  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwyl2m/i_have_a_problem/",
          "publishedOn": "2022-12-28T03:07:25.000Z",
          "wordCount": 16018,
          "title": "I have a problem",
          "imageUrl": "https://preview.redd.it/12zdvexqjl8a1.jpg?auto=webp&s=83d25be7b46b339833c04a36733e34edaf247ebd"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwyi1z/portable_and_space_for_upgrades_home_lab_and/",
          "author": null,
          "description": "submitted by    /u/Opposite_Estate2897  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwyi1z/portable_and_space_for_upgrades_home_lab_and/",
          "publishedOn": "2022-12-28T03:03:21.000Z",
          "wordCount": 16900,
          "title": "Portable and space for upgrades, home lab and on-the-go lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zww6cm/scanning_question/",
          "author": null,
          "description": "Hello,\n I’m trying to harden my home network and I heard one should scan there network from outside of your network, correct? How do you guys accomplish this? VPN? Virtual machine? I know something like Linode would work but just want to hear what you guys personally do. \n Thank you\n    submitted by    /u/Dramatic-Ocelot-8024  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zww6cm/scanning_question/",
          "publishedOn": "2022-12-28T01:14:10.000Z",
          "wordCount": 13698,
          "title": "Scanning question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwvsae/choosing_a_kilowatt/",
          "author": null,
          "description": "Hey all, \n I need to check my power usage and wondering if there is a particular kilowatt that will work or does it matter?\n    submitted by    /u/crazydrve  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwvsae/choosing_a_kilowatt/",
          "publishedOn": "2022-12-28T00:56:42.000Z",
          "wordCount": 13885,
          "title": "Choosing a kilowatt?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwvga4/a_minecraft_server_for_the_kids_to_play_while_in/",
          "author": null,
          "description": "I'm actually thinking about making one of my servers a dedicated MineCraft server. I have 384 GB of DDR4 2133p and 38 TB in a raid 10 configuration (2 RAID Array). It also has 56 threads at 3.6 GHZ. What's your guys's opinion on it? Oh BTW, I'm making it for my kids... they go to colleges across the country from each other and I figured them being able to still play with each other might make them not so home sick. So I'm thinking of making this an awesome, huge world with over 150 plugins/mods.... Does this sound cool to anyone else, or am I going for overkill?\n    submitted by    /u/ThreadRipperPro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwvga4/a_minecraft_server_for_the_kids_to_play_while_in/",
          "publishedOn": "2022-12-28T00:41:29.000Z",
          "wordCount": 14925,
          "title": "A MineCraft Server for the kids to play while in college",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwuxs7/nvidia_tesla_p100_pcie_bracket_help/",
          "author": null,
          "description": "I appear to have bought the wrong model of the p100. the one I bought doesn't have the standard PCIE bracket but a taller bracket with a spring screw. Is it possible to swap the correct bracket onto the the card, or will I have to return and buy the correct one? trying to avoid that because the ebay seller says there is a 35% restocking fee for returns. If it is possible anyone have any idea where to get the proper bracket?\n    submitted by    /u/Bollo9799  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwuxs7/nvidia_tesla_p100_pcie_bracket_help/",
          "publishedOn": "2022-12-28T00:19:06.000Z",
          "wordCount": 13784,
          "title": "Nvidia Tesla p100 PCIE bracket help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwu8w9/am_i_doing_this_right/",
          "author": null,
          "description": "submitted by    /u/Normal_Compote7774  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwu8w9/am_i_doing_this_right/",
          "publishedOn": "2022-12-27T23:49:32.000Z",
          "wordCount": 13749,
          "title": "am i doing this right",
          "imageUrl": "https://preview.redd.it/ufgo3rzfkk8a1.jpg?auto=webp&s=c80021328bab1bd6d87b531586b9ff683764cc83"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwtm2m/lsi_hba_that_for_hp_dl380_g9_that_can_boot/",
          "author": null,
          "description": "I'm in the process of getting a DL380 Gen 9 that I acquired set up to serve as my primary NAS (at least at my home).\n I spent some hours (re: many of them) messing around with it over the holiday weekend. I had pulled a Dell H710 that was flashed to IT mode to replace the janky HP Smart Array adapter but while it would see it as a device in the bios, I could never get it to actually boot from any drives connected to it. TrueNAS could see it and address the drives just fine, but would not boot after installation. Legacy or UEFI made no difference. I finally gave up, put the HP adapter back in, set it to 'HBA' mode (which is kind of a misnomer with that card), reinstalled TrueNAS Scale for the 4th time and proceeded to configure the machine.\n It works but the HP adapter doesn't pass SMART info to TruNAS, so I'd be reliant on notifications from the iLO in case one of the boot pool SSDs fail or whatnot. \n Ye, I attempted to search for solutions for both the Dell LSI card and the HP 'HBA' but found nothing that seemed useful. Saw some posts about taping a couple of pins on the H710, but the symptom didn't match what I was experiencing. \n Thinking I might want to find an actual LSI card that the HP bios will boot from then rebuild the OS before I start moving data to it. Just for peace of mind, familiarity, and centralized SMART notifications. I'd end up having 2 LSI cards, as in order to run the external JBOD I have a LSI SAS9200-8e to facilitate my capacity drives, which appears to be working fine, but I don't intend to boot from it (If I even could on this machine). \n In the future I may slap some cheap SSDs into the 6 free SFF slots for a fast pool for VMs or whatever at some point, so having them all in a similar ecosystem might be easier down the road.\n    submitted by    /u/Kilzon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwtm2m/lsi_hba_that_for_hp_dl380_g9_that_can_boot/",
          "publishedOn": "2022-12-27T23:22:48.000Z",
          "wordCount": 14371,
          "title": "LSI HBA that for HP DL380 G9 that can boot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwtegm/i_updated_my_home_setup_to_rack_mount_home/",
          "author": null,
          "description": "submitted by    /u/johnzanussi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwtegm/i_updated_my_home_setup_to_rack_mount_home/",
          "publishedOn": "2022-12-27T23:14:07.000Z",
          "wordCount": 13814,
          "title": "I updated my home setup to rack mount Home Assistant Yellow and a RPi4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwt4jj/what_are_these_cables_for/",
          "author": null,
          "description": "Recently moved to our new house (23-yo old, but new for us). Found these wires (black red yellow green, blue white and orange brown) in the DSC PC5010 control panel box. There were cut off from the actual circuit board. What were they used for? Thanks in advance!\n    submitted by    /u/ihank724  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwt4jj/what_are_these_cables_for/",
          "publishedOn": "2022-12-27T23:02:58.000Z",
          "wordCount": 15308,
          "title": "What are these cables for?",
          "imageUrl": "https://preview.redd.it/nm5d4055ck8a1.jpg?auto=webp&s=7e079111d08c5a7c2535e0e68beba21ed57279ff"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwsybu/pytorch_benchmarking_homelab_budget_gpu_drag_race/",
          "author": null,
          "description": "Greetings!\n Recently I was asked about a budget AI / ML workload, and decided to test it against some of my own lab GPUs. \n I'll be adding more tests, and benchmarks over time, but below is a link to my website where I covered it. As well as the code I wrote to benchmark them. \n Hopefully this helps someone out there. :-) \n https://www.zb-c.tech/2022/12/26/pytorch-drag-race-tesla-k80-performance/\n    submitted by    /u/zveroboy152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwsybu/pytorch_benchmarking_homelab_budget_gpu_drag_race/",
          "publishedOn": "2022-12-27T22:56:27.000Z",
          "wordCount": 13744,
          "title": "PyTorch Benchmarking | Homelab Budget GPU Drag Race",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwsfdq/am_i_evil_for_putting_my_ups_at_the_top_of_my_rack/",
          "author": null,
          "description": "i swear there’s a good reason, i only have a 16u rack so it’s not gonna topple over, and i have 3 liquid cooled servers. my thought is if the cooking leaks (god forbid) shouldn’t i keep the ups out of harms way? so if it leaks it just leaks out the bottom of the rack? (assuming the servers are at the bottom of the rack)\n    submitted by    /u/Lukas245  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwsfdq/am_i_evil_for_putting_my_ups_at_the_top_of_my_rack/",
          "publishedOn": "2022-12-27T22:35:33.000Z",
          "wordCount": 14141,
          "title": "am i evil for putting my ups at the top of my rack?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwrf1u/take_time_out_for_those_you_love/",
          "author": null,
          "description": "I am posting to say this. Please do not let your home lab, your home projects, even work always come before those you love. Saying to yourself \"it can wait until tomorrow\" for something trivial, sometimes tomorrow doesn't come. Sometimes setting up a new piece of equipment, a new operating system, a new container, working on a new project, whatever isn't the most important. Time is limited, and we all are guilty of this. You don't want to end up like me.\n My mother was hospitalized Friday. She didn't want to go, thought she would be fine and said she didn't want to be in the hospital over the holidays nor on her birthday, since her birthday is a few days after Christmas (12/30). But I overrode that decision and had them take her to the hospital.\n Next thing I know, I'm consenting to allowi…",
          "link": "https://www.reddit.com/r/homelab/comments/zwrf1u/take_time_out_for_those_you_love/",
          "publishedOn": "2022-12-27T21:55:45.000Z",
          "wordCount": 17293,
          "title": "Take time out for those you love.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwpp3m/how_do_i_configure_a_secondary_wifi_router_whos/",
          "author": null,
          "description": "I'm having trouble getting this to work. Diagram here: https://imgur.com/xLMVzeE\n The goal is to use an old wifi router and use it so that all of my wifi cameras connect to it so that the cameras 1) Are isolated from my home network and 2) Have no internet connection.\n Some information about the set up:\n  \nServer is a laptop with two NICs\n Server runs Linux Mint\n I do not want to use VLANs\n  \nI did some digging and know that I should connect the secondary router's WAN to the server's NIC. However, I can't figure out how to access the router's login page (from the server) which probably means the server won't be able to access the RTSP streams either.\n There are a lot of network settings (DHCP etc.) on the server (Linux Mint) that I'm sure I have to set up but have no idea on how to do it. All of my Google searches aren't turning up with setups similar to mine.\n Can you help me?\n    submitted by    /u/Melodic_Walk_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwpp3m/how_do_i_configure_a_secondary_wifi_router_whos/",
          "publishedOn": "2022-12-27T20:47:13.000Z",
          "wordCount": 16610,
          "title": "How do I configure a secondary wifi router who's sole purpose is for my wifi cameras to connect to but with no internet access? Cameras will share their RTSP streams to a server connected to the wifi router by ethernet.",
          "imageUrl": "https://external-preview.redd.it/Lu0ECJGdM1v0xy26SFV0jSpEKR-53rGxoMTnlL2kKBA.jpg?auto=webp&s=fd7bfce1cb4e456ad3e0adc9239384556bbaeee5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwov62/mac_pro_2013_trashcan_as_an_esx_host/",
          "author": null,
          "description": "I have the need to run some macOS vm's. I don't want to go the hackintosh route even though Apple/vmWare doesn't formally support ESX anymore.\n I'm curious of the following:\n  \nIs the Mac Pro 2013 a good choice for ESX? (I'm looking for something low-cost where I can upgrade the CPU and RAM)\n I want to run ESX 8. Anyone doing that successfully?\n How does OS support work? The Mac Pro 2013 doesn't support Ventura but if I virtualized it on it with ESX will the VM install\\run?\n How loud is this trashcan going to sound?\n  \nThanks\n    submitted by    /u/SimplyThatGuyS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwov62/mac_pro_2013_trashcan_as_an_esx_host/",
          "publishedOn": "2022-12-27T20:13:20.000Z",
          "wordCount": 15722,
          "title": "Mac Pro 2013 (trashcan) as an ESX host",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwml8r/my_first_experience/",
          "author": null,
          "description": "submitted by    /u/Stephxn__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwml8r/my_first_experience/",
          "publishedOn": "2022-12-27T18:38:08.000Z",
          "wordCount": 14175,
          "title": "My first experience.",
          "imageUrl": "https://preview.redd.it/76h1z7wv0j8a1.jpg?auto=webp&s=17cff7b83d4ab094356efe2c1fa3d3ce5998ffe1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwm5mg/rhel_for_homelab_anyone_using_this_one_year_after/",
          "author": null,
          "description": "It's been a year since RH launched (relaunched) the Developer Susbscription. You get 16 prod servers for free + unlimited servers on RHEL Beta.\n Has anyone used this for Homelab? I'm in the midst of doing a rebuild, and am exploring distros to play with (nothing mission critical on my lab, can tear down and rebuild in a few hours if needed). \n I like the Insights Portal and the auto patching and the general visibility into the servers thanks to RHEL's web portal. But it is a fair amount of mental overhead to learn the \"RHEL way\". \n Is it worth investing the time to learn it for homelabbing? I don't need to learn this for my job or anything, so that's no motivation. \n I'd like to hear from the community here.\n    submitted by    /u/gigbithomelab  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwm5mg/rhel_for_homelab_anyone_using_this_one_year_after/",
          "publishedOn": "2022-12-27T18:19:32.000Z",
          "wordCount": 16571,
          "title": "RHEL for Homelab - anyone using this one year after they launched the Developer License?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwlurj/so_this_is_how_it_feels_like_retiring_at_age_75/",
          "author": null,
          "description": "submitted by    /u/Tafinho  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwlurj/so_this_is_how_it_feels_like_retiring_at_age_75/",
          "publishedOn": "2022-12-27T18:06:50.000Z",
          "wordCount": 13496,
          "title": "So this is how it feels like retiring at age 75….?",
          "imageUrl": "https://preview.redd.it/roe12e6bvi8a1.jpg?blur=40&format=pjpg&auto=webp&s=8273b24563aaa6570fd26d51bb8f8ccb65559d60"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwlt1r/another_what_do_i_do_with_this_old_hw_post/",
          "author": null,
          "description": "Wife finally retired her OLD xps13 after barely using it for the past several years... Model number L322x, i7-3537u, 8gb ram, 128gb ssd.\n What could be a good use? Don't have capacity for Ethernet so I'm thinking some kind of logging/monitoring use, also Im thinking about putting proxmox on it to learn multi node stuff like container migration/high avail (have another machine with proxmox), would that be a bad idea?\n    submitted by    /u/soloist_huaxin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwlt1r/another_what_do_i_do_with_this_old_hw_post/",
          "publishedOn": "2022-12-27T18:04:57.000Z",
          "wordCount": 14480,
          "title": "Another \"what do I do with this old HW\" post",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwlld2/messy_homelab/",
          "author": null,
          "description": "submitted by    /u/AmbitiousFlowers  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwlld2/messy_homelab/",
          "publishedOn": "2022-12-27T17:56:12.000Z",
          "wordCount": 14751,
          "title": "Messy homelab",
          "imageUrl": "https://preview.redd.it/0qzjjqasbh8a1.jpg?auto=webp&s=fc3580f20933fcbad4b6cefcf94d3d682543ec0b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwlaiz/thinkcentre_m75q2_additional_nic/",
          "author": null,
          "description": "Added NIC for thinkcentre M75Q gen 2 additional NIC to make pci passthrough.\n ​\n https://preview.redd.it/yhd9yhbx8h8a1.png?width=2425&format=png&auto=webp&s=d7da3aea3944ddadc1f0b7e5fa6bb9d505a3f113\n https://preview.redd.it/xrvk8voy8h8a1.png?width=4000&format=png&auto=webp&s=e8387bba16fd99e308d32c12a9de0dfd66198252\n https://preview.redd.it/twh6ybciah8a1.png?width=930&format=png&auto=webp&s=8b43b37942b1bdb586c500392c7bb07a2c5dc179\n    submitted by    /u/erzhan89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwlaiz/thinkcentre_m75q2_additional_nic/",
          "publishedOn": "2022-12-27T17:43:29.000Z",
          "wordCount": 14610,
          "title": "Thinkcentre M75Q-2 additional NIC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwj85b/why_is_it_we_dont_need_to_manually_have_to_worry/",
          "author": null,
          "description": "I remember, we always had problems if IRQ were not balanced/shared across devices correctly and we would have to manually change IRQs and figure out the correct order, and or find out we had too many devices.\n Are there more interrupts available now?\n    submitted by    /u/cooly0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwj85b/why_is_it_we_dont_need_to_manually_have_to_worry/",
          "publishedOn": "2022-12-27T16:14:39.000Z",
          "wordCount": 18321,
          "title": "Why is it we don't need to manually have to worry about balancing Interrupts (IRQs) anymore.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwchqe/my_little_k8s_cluster/",
          "author": null,
          "description": "submitted by    /u/dalite_f  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwchqe/my_little_k8s_cluster/",
          "publishedOn": "2022-12-27T10:20:48.000Z",
          "wordCount": 17171,
          "title": "my little k8s cluster",
          "imageUrl": "https://preview.redd.it/o5zawwd5kg8a1.jpg?auto=webp&s=9ad0f196b9ed19f1e0ca8ae3f1746545866ac505"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zwbn55/my_single_machine_home_lab_proxmox_with_4_server/",
          "author": null,
          "description": "submitted by    /u/vinaypundith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zwbn55/my_single_machine_home_lab_proxmox_with_4_server/",
          "publishedOn": "2022-12-27T09:24:50.000Z",
          "wordCount": 19678,
          "title": "My Single Machine Home \"Lab\" - Proxmox with 4 Server VMs (details in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zw9kre/fun_fact_you_can_use_old_electrical_tape/",
          "author": null,
          "description": "submitted by    /u/HiSmartAlarms  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zw9kre/fun_fact_you_can_use_old_electrical_tape/",
          "publishedOn": "2022-12-27T07:11:37.000Z",
          "wordCount": 15088,
          "title": "Fun fact, you can use old electrical tape containers to store networking and console cables!",
          "imageUrl": "https://preview.redd.it/f57pjtrbmf8a1.jpg?auto=webp&s=97fc9118373156ea7a2318e7512e408c16764264"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zw2za9/building_my_first_homelab/",
          "author": null,
          "description": "Hello /r/homelab,\n Currently working entry level IT, but looking to practice with a homelab at home. I would like to create a lab to setup/have/learn pihole, plex, virtualization, azure, active directory, game server hosting, study for certifications etc. Here is a list of items I own/ ordered over boxing day:\n _\n  \nRouter: ASUS Wireless AX5700 Dual-Band Wi-Fi 6 Router (RT-AX86S)\n TP-Link 8 Port Gigabit Easy Smart Switch (TL-SG108E)\n Dell OptiPlex 3050, Micro, 1x Intel Core i5 Quad (i5-7500T) 2.70 GHz, 16 GB, 500 GB, No Optical, Intel Integrated Graphics, 64-bit Windows 10 Home\n Raspberry Pi 4 - 4 or 8 gb ram (don't recall)\n  \n_ \nItems I got for free but unsure if it would work for my plans.\n  \nOrico 4 bay external hdd - https://www.amazon.ca/External-Enclosure-Support-Aluminum-Storage/dp/B07XL2BS53?th=1 Not quite the same, but close. No RAID button at the back. \n \nLaCie 2big Thunderbolt 2 - https://www.lacie.com/ca/en/support/raid/2big-thunderbolt-2/\n \n Main plan for now would be setting up the dell to run pihole and plex. Many posts about people running this in docker containers. Just trying to figure out how to set myself up. Reading many threads of people buying a newer NAS to run plex on directly. or using an older one to host to plex files and run it through the dell to transcode. \n (Bought a cheap plex lifetime subscription a long time ago, finally had funds + time to start this endeavor.)\n Sorry for the rambling, just looking for some advice guidance.\n    submitted by    /u/iMorph  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zw2za9/building_my_first_homelab/",
          "publishedOn": "2022-12-27T01:32:54.000Z",
          "wordCount": 14067,
          "title": "Building my first homelab.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zw2uhi/can_docker_swarm_ingressoverlay_network_specify/",
          "author": null,
          "description": "Long story is I have 3 docker swarm nodes with x.x.x.10 virtual ip across all notes using keepalived and x.x.x.11 x.x.x.12 x.x.x.13 static ip at each node. For services exposing web I am using traefik with port forwarding to x.x.x.10 All nodes also have glusterfs replicated storage, so I can take two nodes down and still have all services.\n Right now, all services or containers on overlay network expose ports on 0.0.0.0 which I want to limit for some applications to maybe another virtual ip using keepalived (e.g., x.x.x.18) or a specific node's ip like x.x.x.12\n The goal in mind is to leverage docker's overlay network but limit it to specific ip. Now that I am tying this out, I am having doubts whether this would even be supported or work properly. If a single virtual IP and a single container are running on different hosts, would docker even route traffic properly in that case?\n One use case that I would apply this is having two pihole replicas on different nodes, but come think of it, maybe running three replicates with each host LAN ip (.11 .12 .13) could work just as well\n    submitted by    /u/jM2me  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zw2uhi/can_docker_swarm_ingressoverlay_network_specify/",
          "publishedOn": "2022-12-27T01:26:28.000Z",
          "wordCount": 14023,
          "title": "Can docker swarm ingress-overlay network specify hosts ip address?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zw1w4o/help_with_3com_4200g_web_management_interface/",
          "author": null,
          "description": "Got a hold of a 3COM 4200G switch. I was attempting to setup the web management interface with the following guide:\n 3com Switch 4200G Configuration Guide | PDF | Command Line Interface | Radius (scribd.com)\n PAGE: 42-45\n Before following the guide instructions, I set up management VLAN 10 with the instructions on page 60\n While following the instruction on page 42-45 on instruction part 2: \n \"Configure a static route from the switch to the gateway.\n [4200G] ip route-static ip-address 0.0.0.0 255.255.255.255\"\n I got the following:\n [4200G]ip route-static ip-address 0.0.0.0 255.255.255.255 ^ % Wrong parameter found at '^' position. \n Any help with getting in the web interface would be appreciated.\n    submitted by    /u/AdministrativeTwo607  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zw1w4o/help_with_3com_4200g_web_management_interface/",
          "publishedOn": "2022-12-27T00:42:32.000Z",
          "wordCount": 15363,
          "title": "Help with 3COM 4200G web management interface setup",
          "imageUrl": "https://external-preview.redd.it/9xBZGTzuo5pagYcsrFmf06PLAEQSdefFPVO97AUwg2I.jpg?auto=webp&s=d515037c2e4d97733963b365936ad96d17960292"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zw1lce/my_first_homelab_i_need_some_help_please_dell_r620/",
          "author": null,
          "description": "Hello HomeLabbers!\n I am a Network Engineer by trade however I have not had the luxury of playing around with physical routers or servers in person. I have also been a lurker and hoping to build my own lab. So I've bought my first component!\n I have just received my R620 (barebones, included fans and psu) however I'm looking at the specs and I can see that I can run an E5-2600 V1 or V2. My question is, How can I tell if I have the BIOS from V1 or V2? can I just buy a couple of V2 CPU's (If people have suggestions on a CPU aswell that would be greatly appreciated (Hoping to use it as a storage and virtualisation server)) and check the BIOS before I load it with an OS (probably UNRAID)?\n    submitted by    /u/henry2911  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zw1lce/my_first_homelab_i_need_some_help_please_dell_r620/",
          "publishedOn": "2022-12-27T00:28:59.000Z",
          "wordCount": 13935,
          "title": "My first HomeLab, I need some help please (Dell R620)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zw1abc/budget_nas_build/",
          "author": null,
          "description": "I want to build a budget NAS and I am kinda overwhelmed by the amount of hardware (old / new) and different variables influencing the price of the project (the choice of CPU being a major influence in the price of the mainboard and vice versa)\n A lot of budget builds and suggestion for hardware I found were really focusing on power efficiency. However I don’t have to pay for the energy bills in my Appartement, so energy efficiency is no real factor for me. Does this open doors for new hardware? If yes, what would you suggest.\n Currently I have a RaspberryPi as a NAS but I had some troubles with dust coming into my USB ports and I want 10 Gbit connectivity in my next NAS. Also upgradability is not really given in my opinion.\n    submitted by    /u/GER13117  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zw1abc/budget_nas_build/",
          "publishedOn": "2022-12-27T00:15:26.000Z",
          "wordCount": 14200,
          "title": "Budget NAS build",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zw14w7/finally_posting_my_homelab/",
          "author": null,
          "description": "submitted by    /u/michelfrancisb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zw14w7/finally_posting_my_homelab/",
          "publishedOn": "2022-12-27T00:09:02.000Z",
          "wordCount": 13760,
          "title": "Finally Posting My Homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zw0mw1/dell_r730xd_raid_controller_card_options_for/",
          "author": null,
          "description": "Hi,\n I picked up some SanDisk non-Dell branded SSD's over on homelabsales with 97 - 100% life left on them for a good deal. I have a R730xd with a PERC H730P Mini RAID controller. I can make the drives non-RAID drives via Dell's management software and the SanDisk software is able to see the drives, read SMART data, and update firmware. However, the Dell management software or the OS still doesn't appear to get the SMART data. Plus, I would like to put some of these drives in a RAID array.\n What are my options to try and accomplish this? I've read the H330 controllers can be flashed into IT mode, but I don't believe that will allow me to create a RAID array.\n Any thoughts or suggestions is appreciated.\n Thanks!\n    submitted by    /u/colombo01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zw0mw1/dell_r730xd_raid_controller_card_options_for/",
          "publishedOn": "2022-12-26T23:47:16.000Z",
          "wordCount": 14166,
          "title": "Dell R730xd RAID Controller Card Options for Non-Dell Branded Drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvzzxh/revision_one_million_constant_tweaking/",
          "author": null,
          "description": "With many past revisions comes a cleaner setup. I had a few switches before that just made for a big mess and I decided to simplify things while adding some switching speed. \n From top to bottom: BGW320 in pass through with 2gbps service Dell 7040 micro PC with WIN10 for web browsing on the tv Surface pro with Ubuntu and pi hole Hue hub Dumb 2.5 gbps switch to be removed OC200 SG2428P POE switch Patch panel Old dumb gigabit switch to be removed ER8411 S3008F 10gb fiber switch Home theater receiver Reolink NVR Cyberpower 700VA rack mount UPS\n I’ve been looking for a used server that I can start playing around with. Any recommendations for something rack mountable on the quieter side? Or the ability to keep the volume down? \n How do you guys like to stack your rack?\n    submitted by    /u/TheRigSauce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvzzxh/revision_one_million_constant_tweaking/",
          "publishedOn": "2022-12-26T23:18:45.000Z",
          "wordCount": 14509,
          "title": "Revision one million. Constant tweaking!",
          "imageUrl": "https://preview.redd.it/30bl9as1ad8a1.jpg?auto=webp&s=881a2e34883f50832c21201d70039fc218076851"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvznvo/10_gbits_copper_vs_fiber/",
          "author": null,
          "description": "Hi all,\n I'm planning to add 10G to my lab. For now, it's going to be a point-to-point connection specifically for MPI. It's what I call a JoJa-class cluster - it's bizarre, and it's an adventure to get it working. I'm thinking about two options: good ol' copper (like cat6) and fiber in the form of SFP+ - SFP+ cable (i.e. with already attached transceivers). The first option seems somewhat easier, but I'm worried about possible EMI and, therefore, higher latency. The second one seems more solid, but I've never worked with fiber before.\n Are my worries unfounded? Should I go with the fiber option?\n P.S. The \"cluster\" consists of two nodes: Intel i7-12700K with 128 GB DDR4-3600, and AMD Ryzen 7950x with 128 GB DDR5-4000, both running NixOS. Curiously, their performance per hyperthread is pretty close.\n    submitted by    /u/HealingPotatoJuice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvznvo/10_gbits_copper_vs_fiber/",
          "publishedOn": "2022-12-26T23:04:24.000Z",
          "wordCount": 14210,
          "title": "10 Gbit/s - copper vs fiber",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvz0qe/md1200_alternative/",
          "author": null,
          "description": "I've currently got a Dell MD1200 (12 LFF drivebays). I'm using it with shucked WD drives.\n To reduce power consumption I've removed one of the EM modules as there no benefit to having it powered as all the drives are SATA and I don't need to split the enclosure. However the enclosure is still power hungry (even with all the drives removed).\n On top of this it appears to have an intermittent fault, or at least it thinks it does. Every few minutes it'll turn the status LED orange and ramp the fans up to 100% before slowing the fans down and going back to blue. However I can't see any errors in any logs and the drives are all fully accessible.\n I'm therefore thinking it might be time to replace it with something else, but I'm not sure what.\n Does anyone have any suggestions for an external enclosure that will take at least 12 x 3.5\" SATA drives and is available in the UK.\n    submitted by    /u/0x30313233  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvz0qe/md1200_alternative/",
          "publishedOn": "2022-12-26T22:36:52.000Z",
          "wordCount": 13929,
          "title": "MD1200 alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvxhhk/how_to_use_m2_pcie_risers/",
          "author": null,
          "description": "Looking for help / suggestions on how to actually mount pcie cards which are plugged into m2 risers such as the attached image...\n The issue is, \n A) when I put it in the closest m2 slot on the MB the card does not fit (the pcie is not as recessed as the real slots and so the bracket can't be screwed in.\n B) when I use a more out of the way M2 slot the riser cable is so rigid... It may be possible to do some really slick tri-folds... But it doesn't seem right off the bat.\n C) when I think of using the closest m2 with a vertical riser then I have to move two other cards to vertical risers also which they get all fumbly and interfere with each other..\n Perhaps there exists some sort of 3D printable bracket that pulls the card back off the motherboard a bit to accomodate a fold or bulk of a riser or the amount of lift from the M2 card... But what are you all doing to get these to fit??\n PS. My case is Thermaltake P3 and my MB is MSI z690 Tomahawk DDR4. There are 3 x16 on the board but last one operates only at x1. I've got a gpu, TB4, card and a 10g SFP. Which is why I need to use one of the M2 which is pcie4x4.\n    submitted by    /u/anixon604  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvxhhk/how_to_use_m2_pcie_risers/",
          "publishedOn": "2022-12-26T21:31:09.000Z",
          "wordCount": 14110,
          "title": "How to use m2 pcie risers?",
          "imageUrl": "https://preview.redd.it/jwqbkvjuqc8a1.jpg?auto=webp&s=faee653ae949b46912710c6badb80197e4ec40d2"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvwu4j/help_with_openmptcprouter_and_opnsense_on_same/",
          "author": null,
          "description": "submitted by    /u/Intergalacticbears  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvwu4j/help_with_openmptcprouter_and_opnsense_on_same/",
          "publishedOn": "2022-12-26T21:03:11.000Z",
          "wordCount": 15198,
          "title": "Help with OpenMPTCProuter and opnsense on same server",
          "imageUrl": "https://preview.redd.it/8nqh4g2vlc8a1.jpg?auto=webp&s=ccb4ec63982a3d91dd3cbc8028bba556af6ca4cd"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvvtkw/lets_share_my_homelab/",
          "author": null,
          "description": "submitted by    /u/phoonaree  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvvtkw/lets_share_my_homelab/",
          "publishedOn": "2022-12-26T20:18:17.000Z",
          "wordCount": 14908,
          "title": "let's share my \"Homelab\"",
          "imageUrl": "https://preview.redd.it/qgdq00mrdc8a1.jpg?auto=webp&s=eb15559e5169d5e62551484aac0a0813704fd279"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvv434/hp_procurve_1810_24g_j9450a_sfp_module/",
          "author": null,
          "description": "submitted by    /u/sandysound  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvv434/hp_procurve_1810_24g_j9450a_sfp_module/",
          "publishedOn": "2022-12-26T19:46:30.000Z",
          "wordCount": 15340,
          "title": "HP Procurve 1810 24G (J9450A) SFP module recommendations please",
          "imageUrl": "https://preview.redd.it/caxr0xc68c8a1.png?auto=webp&s=4d04688a0f209ac1b15af70df88b02b42daf8bb6"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvuems/how_do_i_isolate_the_guest_house_network_from_my/",
          "author": null,
          "description": "See my home network diagram attached. I have a separate structure from my main house that I'd like to isolate from my main network and devices. Is this typically done from the router or switch? My router is a Microtik with RouterOS. My main switch is a Unifi 24. All WAPs are Unifi. diagram\n    submitted by    /u/greatluck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvuems/how_do_i_isolate_the_guest_house_network_from_my/",
          "publishedOn": "2022-12-26T19:14:48.000Z",
          "wordCount": 15466,
          "title": "How do I isolate the guest house network from my main?",
          "imageUrl": "https://external-preview.redd.it/hKr6rDN9YkL7bEQppBkZCt0-J8UkXQP95q_PiRk3N0s.jpg?auto=webp&s=b175350c33a040fa806adfcb9b0fd00d7c0fcf12"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvu8p7/since_its_the_end_of_the_year_lets_see_how_your/",
          "author": null,
          "description": "submitted by    /u/D3imOs8910  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvu8p7/since_its_the_end_of_the_year_lets_see_how_your/",
          "publishedOn": "2022-12-26T19:07:23.000Z",
          "wordCount": 14319,
          "title": "Since it’s the end of the year, let’s see how your lab started and how it ended the year.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvtt92/vertical_hanging_bracket_for_35_drive/",
          "author": null,
          "description": "Case is a Fractal Design 5. All HD slots full and 5.25” drives full. \n I’m after a bracket as per pic to hang a drive on the cage. Any idea what I can use ? Drive is 3.5”. \n Thanks\n    submitted by    /u/bigup7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvtt92/vertical_hanging_bracket_for_35_drive/",
          "publishedOn": "2022-12-26T18:48:46.000Z",
          "wordCount": 15898,
          "title": "Vertical hanging bracket for 3.5” drive?",
          "imageUrl": "https://preview.redd.it/rve4gbpvxb8a1.jpg?auto=webp&s=809a5c23173851b012eec55a76163216746e1c70"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvskuu/reverse_proxy_with_google_auth/",
          "author": null,
          "description": "tl;dr is I'm wondering if anyone has setup a reverse proxy for remote access to homelab services that uses google auth\n After reading all the horror story posts on here of people having services exposed to the internet and waking up to a ransomware encrypted NAS I closed off my entire lab to the internet and now use Tailscale more or less exclusively to access servers. It works great, but it's not perfect - particularly, the iOS app uses a ton of battery.\n My ideal setup would be to expose a single SSL reverse proxy that requires Google auth. That would not only allow secure remote access without Tailscale\n Feels possible - has anyone made this work?\n    submitted by    /u/saksoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvskuu/reverse_proxy_with_google_auth/",
          "publishedOn": "2022-12-26T17:54:32.000Z",
          "wordCount": 16262,
          "title": "Reverse proxy with Google auth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvrwpg/homelab_ikea_hack_edition/",
          "author": null,
          "description": "submitted by    /u/ShiningPak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvrwpg/homelab_ikea_hack_edition/",
          "publishedOn": "2022-12-26T17:24:10.000Z",
          "wordCount": 16125,
          "title": "Homelab - Ikea Hack Edition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvnii6/mounted_my_oled_tv_which_led_to_a_very_diy/",
          "author": null,
          "description": "submitted by    /u/hunterm21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvnii6/mounted_my_oled_tv_which_led_to_a_very_diy/",
          "publishedOn": "2022-12-26T13:49:50.000Z",
          "wordCount": 14480,
          "title": "Mounted my OLED TV, which led to a very DIY homelab rack change too",
          "imageUrl": "https://external-preview.redd.it/fIr4JAVxN6WHfZR39KFmw79hjMO8AsdfTsN10kw9VD4.jpg?auto=webp&s=908d4a0d4808dcc1d79ebee9ff88e1b15250b53a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvmmjv/home_network_plan_for_wanlan_devices/",
          "author": null,
          "description": "submitted by    /u/Saajaadeen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvmmjv/home_network_plan_for_wanlan_devices/",
          "publishedOn": "2022-12-26T12:58:03.000Z",
          "wordCount": 15935,
          "title": "Home network plan for WAN/LAN devices",
          "imageUrl": "https://preview.redd.it/nh3hozrpp88a1.png?auto=webp&s=0d93a661d44f6a7255b3b4ef3c450612ec3e3374"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvko1v/segmenting_your_home_network/",
          "author": null,
          "description": "curious to how you are segmenting your networks, what's your VLAN setup? are you running IoT devices just on a separate VLAN or have setup a completely segregated network for these devices? I'm scratching my head a bit on how to manage devices/servers via my iphone both inhouse and remotely..\n    submitted by    /u/celzo1776  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvko1v/segmenting_your_home_network/",
          "publishedOn": "2022-12-26T10:44:20.000Z",
          "wordCount": 16060,
          "title": "Segmenting your home network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zve27r/results_of_my_battle_with_bipolar_disorder/",
          "author": null,
          "description": "submitted by    /u/Crypt0N3wb13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zve27r/results_of_my_battle_with_bipolar_disorder/",
          "publishedOn": "2022-12-26T03:34:04.000Z",
          "wordCount": 20296,
          "title": "Results of My Battle with Bipolar Disorder",
          "imageUrl": "https://preview.redd.it/8hgc0ppoe78a1.jpg?auto=webp&s=a665afc60b9441068963426f2bcdf69ee07bca7b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvbo5n/can_proxmox_or_xcpng_do_gpu_partitioning_between/",
          "author": null,
          "description": "Anyone know if this is possible?\n    submitted by    /u/pzach3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvbo5n/can_proxmox_or_xcpng_do_gpu_partitioning_between/",
          "publishedOn": "2022-12-26T01:21:19.000Z",
          "wordCount": 14033,
          "title": "Can Proxmox or XCP-NG do gpu partitioning between VM’s?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvbk6b/dell_7040_sff_supports_2tb_sata_hdd/",
          "author": null,
          "description": "I just got a Dell 7040 SFF and am about to get a 6-8TB (or larger if I've weak) HDD when I was doing some research the manual states that it only supports up to 2TB. I've found a posting saying they did it, but I want to be 100% sure.\n Has somebody successfully used a >2TB drive?\n    submitted by    /u/Malvane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvbk6b/dell_7040_sff_supports_2tb_sata_hdd/",
          "publishedOn": "2022-12-26T01:15:26.000Z",
          "wordCount": 13820,
          "title": "Dell 7040 SFF supports >2TB SATA HDD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvav1d/best_home_email_server/",
          "author": null,
          "description": "I want to create email server for just internal LAN use so apps (like nessus scans, proxmox backup confirmations) can use SMTP and I can read this mails via web gui, what do you recommend? Probably will be hosted on Ubuntu server, and the best would be if it's something popular in enterprise world to learn something that may be valuable.\n    submitted by    /u/bitstrim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvav1d/best_home_email_server/",
          "publishedOn": "2022-12-26T00:38:38.000Z",
          "wordCount": 14401,
          "title": "Best home email server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zva8gl/looking_for_suggestions_for_virtual_homelab_host/",
          "author": null,
          "description": "Basically want 1 machine with virtualization to run about 5 or so VMs. My old virtual lab Windows Pro w Hyper V tower is pretty old and noisy, and probably too outdated at about 10 years old. My daily machine is now a MacBook pro m1 with 8GB RAM, so not a lot of room for VMs there.\n Want one machine, don't want to get into a lot of equipment. Don't want it to be \"always on\", and don't care about HA. Prefer quiet hardware as I would probably put it in my home office. I could put something in my basement but I imagine it would be a hassle turning it on remotely, since I don't want always on. Most familiar with Windows Hyper V or VMware, but am open to other options.\n Reason for lab is to test ansible/Jenkins/terraform (among others) development to Windows and Linux guests (VMs), and also some Active Directory too. \n Does someone have a similar setup, or any general suggestions of how to spec out something like this, what the options are?\n    submitted by    /u/VerySpecialStory  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zva8gl/looking_for_suggestions_for_virtual_homelab_host/",
          "publishedOn": "2022-12-26T00:05:08.000Z",
          "wordCount": 15539,
          "title": "Looking for suggestions for virtual homelab host server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv9x2c/recommendations_for_a_quiet_poe_125510g_mgig/",
          "author": null,
          "description": "Hi guys - Looking to upgrade the core switch in my network. Needs to be one single switch that has decent fan curves so my wife doesn't go crazy (1U is the only space we have in our closet).\n  \nNeed at least 8x mgig 2.5/5/10 Gbps ports that support POE (POE for Wifi6E APs)\n Need at least 8x 1GbaseT ports that support POE\n 4x SFP+ ports (uplink to 10G router and servers)\n 2x QSFP+ ports (not required but would be nice for upgradability)\n  \nRight now the only one I've found is the Meraki MS355 but the licensing fees really turn me off. The product stops switching if the license expires and I'm unsure of the fan noise.\n I believe Cisco has variants in the 9300 series but I'm very nervous about the fan noise.\n Any other recommendations?\n Thank you\n    submitted by    /u/ajgnet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv9x2c/recommendations_for_a_quiet_poe_125510g_mgig/",
          "publishedOn": "2022-12-25T23:48:50.000Z",
          "wordCount": 14167,
          "title": "Recommendations for a quiet POE 1/2.5/5/10G mgig switch (24 ports) with SFP+ and QSFP+ uplinks.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv9wq4/dell_r220_is_randomly_powercycling/",
          "author": null,
          "description": "I am sorry if this is the wrong place to ask this, but I'm at my wits' end. I am new to actual servers because I usually just use old PCS, but I recently got an R220 server off eBay. This server will sometimes randomly restart and will sometimes randomly power off. The memory scans good with memtest and all other hardware appears to be okay. The weird thing is that I don't think it is actually shutting windows itself down. I left a notepad file up on the server as a test to see when it shuts down, but when I power the server back up the notepad file was still open. I also don't see anything in event viewer. It looks like it is maintaining the last OS state somehow. Through Googling I found out that it might be related to iDrac, but I don't know enough about what that is to know for sure. I did go ahead and update iDrac and the BIOS though and that didn't fix it. Any advice would be helpful. Thanks!\n    submitted by    /u/ORION93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv9wq4/dell_r220_is_randomly_powercycling/",
          "publishedOn": "2022-12-25T23:48:19.000Z",
          "wordCount": 14430,
          "title": "Dell R220 is randomly power-cycling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv9t2f/help_with_case_for_home_nas/",
          "author": null,
          "description": "i would like to get a different case for my home nas i am using some random office PC but i would like more room and more drive bays theses are the cases that i have been looking at i am on some what of a budget. \n Fractal Design FD-CA if i got this i would try to mod it to have more bays.\n fractal r5 this would be the best case i just don't like the price new and the used ones but this would be the best one.\n i haven't seen really anything other then those two recommended in other subs or youtube.\n    submitted by    /u/Rasr123105  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv9t2f/help_with_case_for_home_nas/",
          "publishedOn": "2022-12-25T23:42:52.000Z",
          "wordCount": 13819,
          "title": "help with case for home nas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv9qjd/dell_r720_still_a_good_choice/",
          "author": null,
          "description": "I'm about to buy an used dell r720 for almost 900€. Is it old or still a good option for a homelab? It would be my first server.\n 2x intel xeon e5-2670 128gb RAM 2tb sas disk\n    submitted by    /u/Bullinh0s  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv9qjd/dell_r720_still_a_good_choice/",
          "publishedOn": "2022-12-25T23:39:09.000Z",
          "wordCount": 14682,
          "title": "Dell R720 still a good choice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv8kcw/reusing_an_sff_pc_as_a_nas/",
          "author": null,
          "description": "So I have a small PC from zotac that I can't update my plan was to add to that computer a good HDD thunderbolt drive bay and turn it into a NAS (or just a hyper converged docker server) my only need is drive redundancy actually so if one fail I have a spare.\n Now how can I achieve that ? Can I simply do some sort of software raid and let an Ubuntu server handle the whole thing ? \n Thanks for any feedback !\n    submitted by    /u/SirSirae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv8kcw/reusing_an_sff_pc_as_a_nas/",
          "publishedOn": "2022-12-25T22:39:27.000Z",
          "wordCount": 13939,
          "title": "Reusing an SFF PC as a NAS ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv7v4g/ideas_to_go_about_improving_this_mess/",
          "author": null,
          "description": "submitted by    /u/mrabstract29  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv7v4g/ideas_to_go_about_improving_this_mess/",
          "publishedOn": "2022-12-25T22:04:49.000Z",
          "wordCount": 14888,
          "title": "Ideas to go about improving this mess?",
          "imageUrl": "https://preview.redd.it/yanvidxxr58a1.jpg?auto=webp&s=a97a0801334baf6848156e11862e54e1f60cbd5b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv7mom/super_confused_about_good_storage_setup_and_file/",
          "author": null,
          "description": "I got a HP elitedesk 800 G2 SFF system from work with a i5 6500 and 32gb of 2133 MHz ram (4x8) which I wanted to turn into a server for me. \n Server would consist of probably a few VMs, including a game server, home automation stuff, seafile, perhaps a simple NAS, and as many of them as possible in Docker containers I think. So I think Proxmox would be a good fit for this.\n The system has a random 500GB HDD in it and a 500GB Samsung nvme drive. I installed Proxmox already to it with ZFS and both drives in raid 0 because I read that I should use ZFS because that gives snapshotting and it seems like a good thing to have. Also ZFS seemed like a good option (albeit a bit complicated) in general. Well I noticed that my NVME drive fails SMART check as it apparently has 255% of its lifetime used …",
          "link": "https://www.reddit.com/r/homelab/comments/zv7mom/super_confused_about_good_storage_setup_and_file/",
          "publishedOn": "2022-12-25T21:53:09.000Z",
          "wordCount": 15379,
          "title": "Super confused about good storage setup and file system for Proxmox (beginner).",
          "imageUrl": "https://external-preview.redd.it/tKnhjAyvwSTtr2LNKY-hES1R6Y2PdKZI7kISjxn6kwQ.jpg?auto=webp&s=54bd72d804703c3915ad7aef8b2b8cf04206c161"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv7m0f/250_home_lab/",
          "author": null,
          "description": "Hi. I'm thinking making a 250$ home lab after I played around with nextcloud and plex on my old laptop.\n I would use the server for running Nextcloud so i can stop using google drive , plex or jellyfin for movies and tv series and maybe some other self hosted applications.\n I have a 250$ budget including drives ( I don't think i need more than 1 or maybe 2tb). I would be nice if it was small and energy efficient.\n Do you guys have any recommendations of what to buy?\n    submitted by    /u/PawysV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv7m0f/250_home_lab/",
          "publishedOn": "2022-12-25T21:52:12.000Z",
          "wordCount": 14826,
          "title": "250$ Home Lab.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv63yy/rework_of_my_mobile_labdemo_setup/",
          "author": null,
          "description": "submitted by    /u/lupuscon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv63yy/rework_of_my_mobile_labdemo_setup/",
          "publishedOn": "2022-12-25T20:37:04.000Z",
          "wordCount": 15355,
          "title": "Rework of my mobile Lab/Demo setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv5m9v/pcie_cards_being_renamed_after_an_addition/",
          "author": null,
          "description": "How can I best fix this issue I am having - I installed a GPU and now my ethernet port is not working. I believe it is due to linux doing renaming, sorry I am a newb and don't know all the terms. I plan to add an additional card so I would hate losing my internet again as I try to run this headless on proxmox.\n I am referencing this recommendation .\n I ran the following:\n journalctl -b 0 | grep renamed \n And it states that \"....enp3s0: renamed from eth0\"\n What do I need to type in order to get the correct namesso that my ethernet will work again?\n    submitted by    /u/h0va4life  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv5m9v/pcie_cards_being_renamed_after_an_addition/",
          "publishedOn": "2022-12-25T20:12:05.000Z",
          "wordCount": 15119,
          "title": "PCIE cards being renamed after an addition (ethernet doesn't work after adding gpu)",
          "imageUrl": "https://external-preview.redd.it/tKnhjAyvwSTtr2LNKY-hES1R6Y2PdKZI7kISjxn6kwQ.jpg?auto=webp&s=54bd72d804703c3915ad7aef8b2b8cf04206c161"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv5ef8/help_with_hdd_partition_in_esxi/",
          "author": null,
          "description": "First time using any sort of VM software. I've downloaded and installed ESXI 8 on my mini pc as I plant to run Home Assistant on a VM. After logging in to EXSI and trying to create a VM it doesn't show any storage options. \n I've got a 128gb SSD but after install it's showing nothing available. I can only assume I need to resize my HDD and create a partition?\n Any help appreciated.\n    submitted by    /u/Reep881  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv5ef8/help_with_hdd_partition_in_esxi/",
          "publishedOn": "2022-12-25T20:00:54.000Z",
          "wordCount": 16737,
          "title": "Help with HDD partition in ESXI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv440k/what_do_most_of_you_server_owners_use_the_servers/",
          "author": null,
          "description": "submitted by    /u/Pepek23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv440k/what_do_most_of_you_server_owners_use_the_servers/",
          "publishedOn": "2022-12-25T18:56:31.000Z",
          "wordCount": 17925,
          "title": "What do most of you server owners use the servers for",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv1hnj/quiet_and_dustless_apartment_homelab/",
          "author": null,
          "description": "submitted by    /u/cbapel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv1hnj/quiet_and_dustless_apartment_homelab/",
          "publishedOn": "2022-12-25T16:41:51.000Z",
          "wordCount": 16393,
          "title": "Quiet and dustless apartment homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuyvuu/does_it_exist_dual_motherboard_hard_drives_dual/",
          "author": null,
          "description": "Hi there, and happy holidays! I’m trying to find a single case that can house my two Optiplex 390s DT (I think they’re mini-ATX motherboards) their power supplies, and a bunch of 3.5 inch hard drives. \n Does this exist? Any suggestions? Thanks!!\n    submitted by    /u/TwoDogDad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuyvuu/does_it_exist_dual_motherboard_hard_drives_dual/",
          "publishedOn": "2022-12-25T14:15:48.000Z",
          "wordCount": 16221,
          "title": "Does it exist? Dual motherboard, hard drives, dual power supply, rack mounted case.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuylpz/best_wlan_aps/",
          "author": null,
          "description": "Hello, please give your recommendations for WLAN access points, VLAN capability and multiple SSIDS would be nice. Gladly include your personal experience!\n Thanks in advance\n    submitted by    /u/Bubbleqq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuylpz/best_wlan_aps/",
          "publishedOn": "2022-12-25T13:59:03.000Z",
          "wordCount": 17648,
          "title": "Best WLAN APs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zusek9/what_is_the_difference_between_these_drives/",
          "author": null,
          "description": "submitted by    /u/santosaunders  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zusek9/what_is_the_difference_between_these_drives/",
          "publishedOn": "2022-12-25T06:31:21.000Z",
          "wordCount": 15078,
          "title": "What is the difference between these drives?",
          "imageUrl": "https://preview.redd.it/cmsd4rhe518a1.jpg?auto=webp&s=a6fe88522dfef032d51488c0e4fa52c000e63d97"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zupbpe/i_got_the_r630_specific_rail_kit_supposedly_is_it/",
          "author": null,
          "description": "Been having a pretty rough time with rack assembly the past couple days but come now, shouldn't the fronts of the units be flush at least? I'd like to be able to close the front door of the cabinet :,)\n    submitted by    /u/UnknownSP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zupbpe/i_got_the_r630_specific_rail_kit_supposedly_is_it/",
          "publishedOn": "2022-12-25T03:11:09.000Z",
          "wordCount": 15619,
          "title": "I got the R630 specific rail kit supposedly, is it really supposed to stick out like that?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuom8v/a_complete_redesign_of_my_network_before_this_it/",
          "author": null,
          "description": "submitted by    /u/iKill101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuom8v/a_complete_redesign_of_my_network_before_this_it/",
          "publishedOn": "2022-12-25T02:27:10.000Z",
          "wordCount": 16586,
          "title": "A complete redesign of my network. Before this, it was all on 10.0.0.0/8 and the documentation was only in DokuWiki. Still early days for the diagram.",
          "imageUrl": "https://external-preview.redd.it/Y_KooBeFcp7ejMD2uutAXcaCVezqw-aEtkIJoq9IEdA.png?auto=webp&s=fd5669a54f4c526ca35c7c0dd450fcd301393dee"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zunl27/what_will_you_build/",
          "author": null,
          "description": "If you had a 2018 Dell Precision 5820 with 128GB of RAM and 2TB of storage, what will you build?\n    submitted by    /u/mossiboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zunl27/what_will_you_build/",
          "publishedOn": "2022-12-25T01:23:40.000Z",
          "wordCount": 13758,
          "title": "What will you build?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zunb54/best_way_to_setup_iaas_for_my_friends/",
          "author": null,
          "description": "I have rather a lot of compute power, and I'd like to find a way to rent it to my friends. Any solutions for this?\n    submitted by    /u/decduck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zunb54/best_way_to_setup_iaas_for_my_friends/",
          "publishedOn": "2022-12-25T01:07:17.000Z",
          "wordCount": 13784,
          "title": "Best way to setup IaaS for my friends",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zumrp8/new_home_lab/",
          "author": null,
          "description": "Hello,\n I'm going through my spare parts bins and junk that I have access to, and have come up with this so far:\n x56 ASUS P6T mobo\n i7 920 CPU -or- Xeon x5690 (probably go with the X5690)\n 24Gb matching GSkill Ripjaw DDR3 1600 RAM (not ecc obvs)\n big ATX case\n I took an ancient Geforce GTX 480 off the mobo, and have several smaller GPUs to use, MUCH less power consumption than this GTX480. Surprisingly the GTX480 works great, but its a power hog for sure! I suppose I could easily go headless, once the server is up and running anyway.\n I'm hoping to do something you all probably think is simple enough, but I'm new to this stuff.\n I'd like to run Proxmox - virtualization is cool. I've loaded it once or twice on a few SSDs I've got, and just getting used to it a bit. I'm not sure how but Pro…",
          "link": "https://www.reddit.com/r/homelab/comments/zumrp8/new_home_lab/",
          "publishedOn": "2022-12-25T00:36:05.000Z",
          "wordCount": 14778,
          "title": "New home lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zumq5s/technotims_homelab_tour/",
          "author": null,
          "description": "submitted by    /u/geerlingguy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zumq5s/technotims_homelab_tour/",
          "publishedOn": "2022-12-25T00:33:34.000Z",
          "wordCount": 13814,
          "title": "TechnoTim's Homelab tour",
          "imageUrl": "https://external-preview.redd.it/BhbBYG5E8OLdYnQSap30ovKwRKBSio-n9ac65xA7txw.jpg?auto=webp&s=867759d14a710084cd800cf935f2a6c4242c927a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zumlxz/nvidia_k80_in_dell_r720/",
          "author": null,
          "description": "submitted by    /u/International-Fee473  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zumlxz/nvidia_k80_in_dell_r720/",
          "publishedOn": "2022-12-25T00:26:48.000Z",
          "wordCount": 14251,
          "title": "Nvidia k80 in Dell r720?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zukpzg/i_just_got_ups_apc_bx950mi_not_user_replacable/",
          "author": null,
          "description": "I am pretty sure the last model was listed as user replaceable, but I now realize this one says its not user replacable but still lists replacement battery for it.\n I just want to know, so I know when the time that will eventually come, comes:\n Is it actually hard to replace, or is it simple and I can do it, but they say its not to cover their asses?\n    submitted by    /u/TheMihle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zukpzg/i_just_got_ups_apc_bx950mi_not_user_replacable/",
          "publishedOn": "2022-12-24T22:44:53.000Z",
          "wordCount": 15100,
          "title": "I just got UPS APC BX950MI, not user replacable batteries?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zukfzo/i_want_to_start_a_home_server/",
          "author": null,
          "description": "I am trying to figure what to get for my first home server. I have an extra itx motherboard and a 6th generation Intel i7 processor. I am wanting to make a good server. The main thing is cloud and NAS for projects. I want to learn to be a system admin.\n    submitted by    /u/VirusNegativeorisit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zukfzo/i_want_to_start_a_home_server/",
          "publishedOn": "2022-12-24T22:30:17.000Z",
          "wordCount": 14952,
          "title": "I want to start a home server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuic6c/dell_t5600_sata_and_sas_drives_in_esxi/",
          "author": null,
          "description": "So I've got ESXI 6.7 running on a dell precision T5600 (Dual Intel(R) Xeon(R) CPU E5-2690) that has the onboard SAS port / controller. I have a 1 TB 2.5 inch SSD as the boot drive for ESXI 6.7 and a 2 TB HDD for VMs. I've recently installed an ICY DOCK Tray-Less 4 x 2.5 SATA HDD Hot-Swap Docking Enclosure in the 5.25\" Bay directly beside the disk drive and used a Cable Matters Internal Mini SAS to SATA Cable to plug into the SAS port of the system and fan out to the 4 ports on the hot swap bay. \n ​\n However, I'm not getting ESXI to see any drives connected in the hotswap bay. while in the bios I'm able to see the one test drive I have connected and I verified the drive is functional in my main computer. Current configuration I have for the bios is that I have SATA/RAID enabled and AHCI set, I have also installed the megarid sas drivers into esxi but still no luck. Has anyone tried this before, is the bios on the T5600 a SAS or SATA type deal where only one port type works?\n    submitted by    /u/CortexAnthrax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuic6c/dell_t5600_sata_and_sas_drives_in_esxi/",
          "publishedOn": "2022-12-24T20:43:18.000Z",
          "wordCount": 15261,
          "title": "Dell T5600 Sata and SAS drives in ESXI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuhzwn/x99_c612_dual_xeon_2696v4_help/",
          "author": null,
          "description": "Went ahead and tried a Chinese board, decided to get one on Amazon instead of Aliexpress and wait until Feburary.\n Running two 2696V4's on a Shangzhaoyuan C612 chipset mobo...\n https://www.amazon.com/dp/B0B9FY9YK5?psc=1&ref=ppx_yo2ov_dt_b_product_details\n Everything works great, however, OCCT and HWINFO show both CPU Package powers capped at 23Watts. PSU we're using is a, 1300W EVGA G2.\n https://www.amazon.com/gp/product/B00COIZTZM/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&psc=1\n I've messed around with BIOS settings and edited C-States and what not, I got a net gain on benchmarks/Prime95/OCCT/Furmark from 20W capped to now a 30W capped. Throwing WHEA errors on HWINFO/OCCT.\n I have two separate EPS rails per socket power. CPU1, CPU2. EVGA's rails rate \"108AMPS/120Watts\" per 12V rail, not sure if I'm reading that right... or am I missing something here in BIOS, or on the board itself?\n I've used this power supply to push 300 watt CPU package spikes on a 5950X with PBO curves, I don't think it is the PSU?\n Maybe the board just isn't able to report actual power draw, I'm not sure.\n Fixed WHEA error 19, but no change in actual draw. Running Stress/OCCT/Cinebench/Prime95 over the course of two days everything looks fine otherwise.\n    submitted by    /u/Cythisia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuhzwn/x99_c612_dual_xeon_2696v4_help/",
          "publishedOn": "2022-12-24T20:25:52.000Z",
          "wordCount": 15384,
          "title": "X99 C612, dual Xeon 2696V4 help.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zug16z/what_else_could_i_add_to_my_homelab_my_comment/",
          "author": null,
          "description": "submitted by    /u/BouncyPancake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zug16z/what_else_could_i_add_to_my_homelab_my_comment/",
          "publishedOn": "2022-12-24T18:48:38.000Z",
          "wordCount": 14469,
          "title": "What Else Could I Add to My Homelab ? (My comment will explain what the VMs are)",
          "imageUrl": "https://preview.redd.it/u3wq6mg86w7a1.png?auto=webp&s=a820530de3d0ab3e5089c30dec95dd11f12de783"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zug11y/total_run_time_1374_years_61_days_world_community/",
          "author": null,
          "description": "Total run time: 1,374 years 61 days -- World Community Grid Homelab team stats for Saturday, 12/24/2022\n  \nCurrent Members 245 (#33 in the world)\n Total Run Time (y:d:h:m:s) (Rank) 1374:061:09:39:49 (#145)\n Points Generated (Rank) 2,351,407,143 (#126)\n Results Returned (Rank) 3,835,954 (#131)\n  \nHomelabbers who have joined the Homelab team and are processing datasets for World Community Grid are working on the following projects:\n  \n Project Points Generated Results Returned Total Run Time (y:d:h:m:s) \n  \n OpenPandemics - COVID-19 438,170,950 655,764 205:213:22:15:20 \n  Africa Rainfall Project 29,124,496 6,722 15:246:20:47:57 \n  Help Stop TB 2,624,907 1,068 1:237:01:20:12 \n  Mapping Cancer Markers 1,331,464,680 1,860,297 846:204:16:29:35 \n  Beta Testing 588,775 966 0:125:19:17:04 \n  Microbiome Immunity Project 233,228,063 555,814 126:303:09:50:12 \n  OpenZika 56,754,339 148,682 27:023:07:53:07 \n  FightAIDS@Home - Phase 2 75,951,773 100,228 50:357:19:14:52 \n  Outsmart Ebola Together 61,922,110 115,152 29:077:20:37:22 \n  FightAIDS@Home 4,068,979 67,396 2:152:07:48:41 \n  Smash Childhood Cancer 117,508,071 323,865 67:308:08:05:27 \n \n Join the Homelab team here: \n (if you already participate in World Community Grid)\n https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n (if you are new to World Community Grid)\n https://join.worldcommunitygrid.org?teamId=124DTPZ682\n Link to team statistics: https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n    submitted by    /u/homelabber12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zug11y/total_run_time_1374_years_61_days_world_community/",
          "publishedOn": "2022-12-24T18:48:26.000Z",
          "wordCount": 14342,
          "title": "Total run time: 1,374 years 61 days -- World Community Grid Homelab team stats for Saturday, 12/24/2022",
          "imageUrl": "https://external-preview.redd.it/wIj6ygk01ih8oIHxFRQ6FPPWByQkwZHSYkhAwFSPi5g.jpg?auto=webp&s=695923a3c1648c33a1135adf2092e5d80a1fa37d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuflas/new_rescue_lulo_loves_the_latest_addition_to_the/",
          "author": null,
          "description": "submitted by    /u/jotafett  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuflas/new_rescue_lulo_loves_the_latest_addition_to_the/",
          "publishedOn": "2022-12-24T18:26:53.000Z",
          "wordCount": 14096,
          "title": "New rescue (Lulo) loves the latest addition to the catlab. I mean homelab.",
          "imageUrl": "https://preview.redd.it/napfuebb2w7a1.jpg?auto=webp&s=04c8b6bcd840f21c660f323706dba11346d8b0b4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zudpsi/my_homelab_has_changed_again/",
          "author": null,
          "description": "submitted by    /u/Techno-Tim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zudpsi/my_homelab_has_changed_again/",
          "publishedOn": "2022-12-24T16:54:56.000Z",
          "wordCount": 17075,
          "title": "My HomeLab has changed again...",
          "imageUrl": "https://preview.redd.it/u2vrdfj6mv7a1.jpg?auto=webp&s=7bd3a95a9182029ec44ec0b2698cd2de44a9f752"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zucfs0/proxmox_ve_72_on_intel_compute_stick_stk2m3w64cc/",
          "author": null,
          "description": "Hi everyone!\n First: Why?\n Well, a low power node to run the network's essentials is never a bad thing, and I didn't wanted to go for a RaspberryPI, because it's both expensive for what it is at the moment due to shortages, and also because I prefer to reduce the number of different environments I'm running, just for cohesion.\n Though, as a piece of tech from 2017, it sure needed fresh thermal paste. Thankfully, they are quite easy to open and clean. 1 screw under the back sticker, clips all around, 4 screws on the cooler (1 on the back of the board into the cooler, 3 from the front into the chassis), and the fan is just clipped in the removed panel.\n ​\n Second: How?\n Well sure, the compute stick only have wifi and bluetooth, and rely on proprietary blobs I can't (or am too lazy to) find, …",
          "link": "https://www.reddit.com/r/homelab/comments/zucfs0/proxmox_ve_72_on_intel_compute_stick_stk2m3w64cc/",
          "publishedOn": "2022-12-24T15:49:46.000Z",
          "wordCount": 16556,
          "title": "Proxmox VE 7.2 on Intel Compute Stick STK2M3W64CC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zubrhl/grafana_dashboard_for_my_current_instance_of_home/",
          "author": null,
          "description": "submitted by    /u/chkpwd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zubrhl/grafana_dashboard_for_my_current_instance_of_home/",
          "publishedOn": "2022-12-24T15:14:29.000Z",
          "wordCount": 14968,
          "title": "Grafana Dashboard for my current instance of Home Prod",
          "imageUrl": "https://preview.redd.it/01jts7n74v7a1.png?auto=webp&s=7dadb1583d7767c3ba5abf1c5d8090832ad34e06"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuboet/are_usb_enclosure_more_prone_to_errors/",
          "author": null,
          "description": "Hi everyone,\n I was thinking to upgrade my NAS from an intel G4400 to a Intel NUC+some HDD \"rack\" like Yottamaster, Terramaster or Fantec like this ones:\n https://www.amazon.it/Yottamaster-Esterno-USB3-0-modalit%C3%A0-Silenzioso/dp/B084Z2Y97C\n https://www.amazon.it/Yottamaster-Alluminio-Esterno-Ventilatore-Silenzioso/dp/B083Q8Z2KM\n https://www.amazon.it/QB-35US3-6G-Esterno-pollici-Ventola-Sensore/dp/B07DD1QZY7\n https://www.amazon.it/TerraMaster-Storage-esterno-Enclosure-Diskless/dp/B08CN4Z4PC\n I read that this kind of USB cases are more prone to errors compared to SATA disk connected diractly to the motherboard. Is it true? If yes, there is some way to avoid it without using ECC RAM?\n    submitted by    /u/TopdeckIsSkill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuboet/are_usb_enclosure_more_prone_to_errors/",
          "publishedOn": "2022-12-24T15:10:00.000Z",
          "wordCount": 14902,
          "title": "Are USB enclosure more prone to errors?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zubmdm/first_actual_server_market_place_for_130_let_the/",
          "author": null,
          "description": "submitted by    /u/Spiritual_Panda_8392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zubmdm/first_actual_server_market_place_for_130_let_the/",
          "publishedOn": "2022-12-24T15:07:05.000Z",
          "wordCount": 16232,
          "title": "First actual server, market place for 130. Let the fun begin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zubf3x/psa_tva_electric_customers/",
          "author": null,
          "description": "submitted by    /u/mspencerl87  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zubf3x/psa_tva_electric_customers/",
          "publishedOn": "2022-12-24T14:56:52.000Z",
          "wordCount": 16955,
          "title": "PSA: TVA electric customers",
          "imageUrl": "https://preview.redd.it/bobd6wkoiw7a1.jpg?auto=webp&s=60e57c997972b00cbf8a396d14283a9717b68a48"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zub19t/squeaky_wheel_gets_the_oil/",
          "author": null,
          "description": "submitted by    /u/RoyRock413  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zub19t/squeaky_wheel_gets_the_oil/",
          "publishedOn": "2022-12-24T14:35:42.000Z",
          "wordCount": 20751,
          "title": "squeaky wheel gets the oil! 😳",
          "imageUrl": "https://external-preview.redd.it/1hxJs-JteUq8ibpLueXxZO-dgF9X8mbn9mR74vNKosA.png?format=pjpg&auto=webp&s=3beff9f6b4b8dba29d2a0a39af11f0755212bcb9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zu9hdq/how_do_i_keep_a_10gb_nic_cool_in_a_nonserver_case/",
          "author": null,
          "description": "I got myself an early Christmas present and put together a NAS inside a Define R6 case. I threw in a 10Gb NIC (Intel X520) to speed up transfers from my main PC. Airflow isn't bad, but it's not as good as you'd find in a server chassis - especially over the PCIe area.\n https://preview.redd.it/2ra57acm6u7a1.jpg?width=1024&format=pjpg&auto=webp&s=feab3bcbd1f9e114c8751e146ed1ea717587a8ab\n After being powered on for only a few minutes I noticed the NIC was getting extremely warm with the heatsink being too hot to touch. I took a look with a thermal camera and it was by far the warmest part in the system. The heatsink was too reflective to get an accurate temperature but the back of the board was around 70°C.\n https://preview.redd.it/30h3qgq3eu7a1.jpg?width=512&format=pjpg&auto=webp&s=255f5483a9e963f844a931bae48c8316dbe6948b\n https://preview.redd.it/fc512lz4eu7a1.jpg?width=512&format=pjpg&auto=webp&s=a78e04df7ced4a4bd504617f44a92728f55a7ce8\n I took a look at the X520's datasheet and it requires a minimum air flow of 100LFM. I don't have anything to measure this, but I don't expect I'm even close. I can't see anywhere good to mount a fan nearby, but I might be able to go wild with some zip ties and make something work. I'd be interested to know what people have done to keep their NICs cool in cases they're not designed for. Thanks!\n    submitted by    /u/_jackTech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zu9hdq/how_do_i_keep_a_10gb_nic_cool_in_a_nonserver_case/",
          "publishedOn": "2022-12-24T13:07:06.000Z",
          "wordCount": 17261,
          "title": "How do I keep a 10GB NIC cool in a non-server case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zu8sac/though_i_occasionally_have_negative_paid_to_use/",
          "author": null,
          "description": "Prices trended in the high $2-3 until morning. Are server naps a regular thing for any of you these days?\n    submitted by    /u/Tri_Ban_Had  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zu8sac/though_i_occasionally_have_negative_paid_to_use/",
          "publishedOn": "2022-12-24T12:21:52.000Z",
          "wordCount": 15278,
          "title": "Though I occasionally have negative (paid to use) electricity rates, which caused a bit of a stir here previously. I also wanted to share the part of that program where I decide to shut the rack down for 12 hours. Are server naps a regular thing for any of you these days?",
          "imageUrl": "https://preview.redd.it/q4iuj7q0rv7a1.jpg?auto=webp&s=bd8abca90c21c92ddf5d9f70955a36ac94eda88b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztxurv/help_identifying_a_nic/",
          "author": null,
          "description": "I have 2 X520-SR2 NICs that I bought off eBay. 1 had a yottamark and verified fine, the other did not. I’m having issues with speed with the second one, not hitting 10gb using iperf. I tested with the X520 and the old Mellanox connectX3 I had, to verify it was the NICs issue. I’m trying to see if I got a counterfeit card so I can file a dispute for one of them. I was looking at the product ID and I can’t find it anywhere. \n E70856-013 (I thought E70856 was sun/Oracle but I can’t find anything with -013). I’m trying to ID this card so I can further troubleshoot. \n https://imgur.com/a/9nGCwOu/\n Thank you all!\n    submitted by    /u/FinancesAr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztxurv/help_identifying_a_nic/",
          "publishedOn": "2022-12-24T01:06:45.000Z",
          "wordCount": 13903,
          "title": "Help identifying a nic",
          "imageUrl": "https://external-preview.redd.it/8RmRGh4f5UV6k5-4bu3RLbjPz7VHtZ4VH27mRtww44Y.jpg?auto=webp&s=3ef0afadc26a2810502e4488c2d13b698e7453a0"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztxty2/so_my_house_is_setup_for_cat_6_and_cant_find_any/",
          "author": null,
          "description": "submitted by    /u/4runner99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztxty2/so_my_house_is_setup_for_cat_6_and_cant_find_any/",
          "publishedOn": "2022-12-24T01:05:38.000Z",
          "wordCount": 14205,
          "title": "so my house is setup for cat 6 and can't find any Jack's..has coax in said rooms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztxgu5/dell_perc_h700_marking_4tb_drives_as_failed/",
          "author": null,
          "description": "The Dell PERC H700 inside of my Powervault NX300 is detecting these OEM Seagate ST4000NM0023's (SAS), but displays them as \"Failed\". As you can see by the image at the imgur link, they're showing \"No Fault\" on SMART status. I've seen plenty of weird compatiblity issues, but this one is entirely new to me. Controller is running latest firmware, BIOS has also been upgraded to latest. The drives are firmware 7FA6, and the previous drives I had installed were of the OEM Hitachi Enterprise 2TB SAS variety.\n PERC H700 Config Screen\n ​\n To add to the weirdness, when I first boot into the controller, they display as \"Ready\". Only after I try to add them to a VD do they go to \"Failed\" status.\n ​\n Any help is appreciated :)\n    submitted by    /u/tipripper65  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztxgu5/dell_perc_h700_marking_4tb_drives_as_failed/",
          "publishedOn": "2022-12-24T00:47:27.000Z",
          "wordCount": 14865,
          "title": "Dell PERC H700 Marking 4TB Drives as Failed",
          "imageUrl": "https://external-preview.redd.it/IY7RqOFd7ZeUaElaC3Wg4yavfe3wJy16RxWtdrjJlBA.png?auto=webp&s=3e555422fcb98505e156b72597605915fa7ccd24"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztw19n/setting_up_windows_storage_space_for_colorist/",
          "author": null,
          "description": "Hi, \n I feel like every time I think I figured something out with Storage Spaces, I read something else and I'm even more confused. \n Here's my situation: \n I'm a colorist, doing color grading on 4K+ projects for Web and TV, as well as occasionnal video editing. I work from home, so I'm setting up a network that would be used by 1, occasionnally 2 workstations.\n I usually have a few hundreds of gigs to a TB of media of projects I'm working on but I like to keep everything accessible, so I currently have about 50TB of storage in my machine, that I'm moving to a server to free up airflow, and allow for expandability and have a permanent FTP server for clients. Most of the files I work with are multiple gigs or tens of gigs, excluding project cache files, but those are stored on an NVME SSD o…",
          "link": "https://www.reddit.com/r/homelab/comments/ztw19n/setting_up_windows_storage_space_for_colorist/",
          "publishedOn": "2022-12-23T23:38:07.000Z",
          "wordCount": 16449,
          "title": "Setting up Windows Storage Space for colorist home studio",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztvsn6/25_hdd_recommendations/",
          "author": null,
          "description": "Does anyone have any recommendations for reliable 2?5\" HDDs? SSDs are also of interest to me, but not as much.\n I've poked around some used markets but I'm unsure of which ones are reputable.\n    submitted by    /u/Senkyou  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztvsn6/25_hdd_recommendations/",
          "publishedOn": "2022-12-23T23:26:52.000Z",
          "wordCount": 14110,
          "title": "2.5\" HDD recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztvbo9/45drives_av15_zpool_configuration/",
          "author": null,
          "description": "I just acquired a 45Drives AV15 server. Currently, I have a Synology ds1813+ with 8x3TB WD Reds. I want the AV15 to replace the ds1813, but I need to get a 16TB to back up the Synology data first. Once I do that, I want to develop the best ZFS design for the av15 based on my current needs. So I’ll have 12x3TB WD Reds and 3x1TB SSD drives that I can use. My current setup is as follows. \n Synology ds1813 Shares folders Media streaming (jellyfin) Music, airsonic Photos, dsphoto app ISO files and other data stored in the ds1813 VMBackups VMdata (stores some light lxd and vms disk)\n Lenovo m920q. (Proxmox host) VMs and Docker containers are running on it. Backup all proxmox VMs to VMBackups NFS shared\n The plan is to do a hyper-converged on the av15 with proxmox and the Huston gui. I’m new to ZFS and looking for advice on the design of the zpool or pools. \n Possible considerations Scenario 1 1. zpool with 12 HDD and 3 SSD 1. Two or three VDEV (raidz1,2,3)? 1. Store everything on the zpool\n Scenario 2 1. zpool for the SSD only (raidz1 or mirror) 1. Store VMs on ssd pool 2. Zpool for the HDD (add third SSD for cache)? 1. 2 VDEV raidz1,2? 2. Store media on HDD pool\n Everything will be back up to the 16TB I’ll use to copy the data from the Synology temporarily. \n Thoughts and suggestions are much appreciated. \n Thanks Dan\n    submitted by    /u/nodejson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztvbo9/45drives_av15_zpool_configuration/",
          "publishedOn": "2022-12-23T23:05:33.000Z",
          "wordCount": 14137,
          "title": "45Drives AV15 zpool configuration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztv6q6/replaced_cyberpower_1500_sla_with_lifep04_2_for/",
          "author": null,
          "description": "I am in the old part of town with frequent power outages. Unmonitored situation with 8 computers. Get about 2 years out of the original batteries but the SLA quickly lose capacity since they are totally discharged every time the power goes out. Then when we are at work the UPS are only useful for power blips and brownouts. The the power goes out we only get 5-10 min actual run time. I expect this situation will improve with the LiFeP04 and the overall cost will be much lower. Even deep cycle SLA do not tolerate frequent full discharges so that technology is not useful to me.\n    submitted by    /u/Turbulent-Apricot680  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztv6q6/replaced_cyberpower_1500_sla_with_lifep04_2_for/",
          "publishedOn": "2022-12-23T22:59:42.000Z",
          "wordCount": 13925,
          "title": "replaced Cyberpower 1500 SLA with LiFeP04 2 for $75 8Ah works well",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztv515/dl380_g5_g4_servers/",
          "author": null,
          "description": "I happen to have a bunch of old g4 & g5 servers and some fiber channel stuff. I am at a loss as to what to do with it all as most of it is useless (to me).\n Do I recycle it all? Try to do some ATX case conversions? Give them away? Part them out on eBay (seems like a waste of time and money to me but hey).\n    submitted by    /u/No_Stretch_9237  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztv515/dl380_g5_g4_servers/",
          "publishedOn": "2022-12-23T22:57:25.000Z",
          "wordCount": 14099,
          "title": "DL380 g5 &g4 Servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztuk18/pondering_pastebin_alternatives_after_reading/",
          "author": null,
          "description": "Hi all,\n There have been many posts here on this topic, but after reviewing most of them I emerge perplexed. What I like about Pastebin is the ability to login and see your past pastes. I also like the ability to modify or even delete posts. Obviously, it is multi-user, but that is not needed in the homelab.\n The options that I have considered are LenPaste and Privatebin, but both seem to have a concept of creating a paste that has no editability or even in some cases visibility after creation. (For example, neither seem to allow edit or deletion of pastes after creation.) I think that the they do this to ensure privacy and security, but I prefer something more Pastebin like even if it requires a security trade off.\n I am confused about why these seemingly basic features are nowhere to be found in OSS pastebin alternatives. Am I missing something? Are there other options that I should be considering that have these features?\n TIA!\n    submitted by    /u/JL_678  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztuk18/pondering_pastebin_alternatives_after_reading/",
          "publishedOn": "2022-12-23T22:30:33.000Z",
          "wordCount": 13999,
          "title": "Pondering Pastebin alternatives after reading many posts here",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztuefj/evga_supernova_450_gm_6pin_sataperif/",
          "author": null,
          "description": "Hi. I need to connect 8 SATA HDDs (mix of Seagate and HGST, <10W) to my EVGA SuperNOVA 450 GM. Since I want to avoid Molex-to-SATA adapters, is it possible to connect a 6-pin to 4x SATA (EVGA) to the 6-pin PERIF connector (PSU side)? Looking around, I found that the only difference is the absence of the 3.3v pin. Am I right?\n ​\n https://preview.redd.it/ofhsebbg3q7a1.jpg?width=2048&format=pjpg&auto=webp&s=1a8806e4f845e0e47faf61ac4fad3da00628edb9\n    submitted by    /u/icantfindac00lname  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztuefj/evga_supernova_450_gm_6pin_sataperif/",
          "publishedOn": "2022-12-23T22:23:17.000Z",
          "wordCount": 15020,
          "title": "EVGA SuperNOVA 450 GM 6-pin SATA/PERIF interchangeable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztucqw/newbie_here_recommendation_for_4u_rack_case/",
          "author": null,
          "description": "I currently have somewhat of a setup(s) in my living room and want to potentially movie both the systems to a rack in the garage\n System1:\n  \nAsrock Steel Legend X570 \n Ryzen 3900X\n 32GB RAM (thinking might add another 64GB here and increase the number of VM's to include some other things like pfSense, VPN, etc..)\n HDD: 512 GB SSD for OS + 4TB + 8TB + 12TB + 14TB\n This is currently running proxmox and 2 VM's \n Ubuntu - running multiple services in a docker\n Home Assistant OS\n \n  \nSystem2:\n  \nHP Z800 w/Intel Xeon X5650 (Dual Configuration)\n 64GB RAM (ECC)\n HDD: 512GB SSD (OS) + 3x14TB\n This system is currently running proxmox and 1 single VM \n Truenas\n \n  \n​\n So far it seems like the only 4u case that does not break the bank a lot is the RSV-L4000U from Rosewill . Is it a good choice? Are there any other recommendations? \n Also seems like the prices are currently elevated (supply chain issues still?) Any guidance on if waiting a bit longer would bring sanity to the prices? I've read that the Rosewill RSV-L4000U used to be around $130 not too long ago.\n ​\n Thanks in advance!\n    submitted by    /u/presler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztucqw/newbie_here_recommendation_for_4u_rack_case/",
          "publishedOn": "2022-12-23T22:20:58.000Z",
          "wordCount": 14872,
          "title": "newbie here, recommendation for 4U rack case ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztt6a1/hpe_spp_for_dl360g9_and_ml350g8/",
          "author": null,
          "description": "Hi. \n Could someone please confirm for me which are the latest SPP's available to download for the 2 models of servers below: \n 755258-B21\n 646676-001\n ​\n Thank you!\n    submitted by    /u/networkn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztt6a1/hpe_spp_for_dl360g9_and_ml350g8/",
          "publishedOn": "2022-12-23T21:30:20.000Z",
          "wordCount": 13731,
          "title": "HPE SPP For DL360G9 and ML350G8",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztsz7w/refurbished_supermicro_x9dblif_wont_boot/",
          "author": null,
          "description": "Hey guys,\n I just bought a 1u server off eBay with the motherboard in title.\n It came with with everything it should need to run. The seller listed it saying it posted and that’s as far as they tested.\n When I power it on, the fans spin up for a few seconds, then it shuts off.\n I have connected the ipmi lan Port and was able to get on the ipmi web page, but the default credentials don’t work.\n When I connect my monitor, it switches on to react to the new connection, but doesn’t display anything when the server powers on.\n I have tried my gaming pc power supply connected to the main board but it does the same thing. My pc psu only has 1 8pin cpu connector and this motherboard needs 2 8 pins. \n I tried taking the memory out to try get a beep code, but it acted exactly the same.\n There is definitely a cpu in the socket.\n Visually the motherboard looks ok. No burst caps or anything.\n Am I looking at a dead server or am I missing something?\n    submitted by    /u/fusrohdann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztsz7w/refurbished_supermicro_x9dblif_wont_boot/",
          "publishedOn": "2022-12-23T21:21:37.000Z",
          "wordCount": 14940,
          "title": "Refurbished supermicro x9DBL-IF won’t boot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zts7ym/registered_vs_unregistered_vs_buffered_vs/",
          "author": null,
          "description": "I am in search for a ram for Supermicro X11SSH-F. It takes unbuffered ECC ram. I see so many ebay listings and some of them mention being ECC but sometimes without other words like unregistered or unbuffered\n Is registered and buffered used interchangeably and same for unregistered and unbuffered? Or its different terms?\n Little education may help me to find something in reasonable price. I am looking for 8gb or 16gb RAM for pfsense. I know pfsense doesn’t use much but if it is cheaper, I don’t mind it goes to waste.\n    submitted by    /u/PirateParley  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zts7ym/registered_vs_unregistered_vs_buffered_vs/",
          "publishedOn": "2022-12-23T20:47:25.000Z",
          "wordCount": 15939,
          "title": "Registered vs unregistered vs buffered vs unbuffered",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztrxl0/my_lack_rack_home_lab/",
          "author": null,
          "description": "submitted by    /u/iamtehstig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztrxl0/my_lack_rack_home_lab/",
          "publishedOn": "2022-12-23T20:34:31.000Z",
          "wordCount": 14126,
          "title": "My lack rack home lab",
          "imageUrl": "https://external-preview.redd.it/UttTcRV0eZw2wjwEwuM4VKanPmXSILTfcei3OnpZOk0.jpg?auto=webp&s=e080e89775373f2ea17653e89bb8bc2d22c4f0be"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztqna8/firewall_recommendations/",
          "author": null,
          "description": "I am looking for firewall recommendations other than pfsense. I love pfsense, but how it handles NAT is a pain. I have done plenty of researching and trouble shooting but I can have two pcs trying to play games on the same network. Does anyone have a recommendations on a firewall?\n    submitted by    /u/4MAZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztqna8/firewall_recommendations/",
          "publishedOn": "2022-12-23T19:37:47.000Z",
          "wordCount": 15403,
          "title": "Firewall recommendations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztpthb/lastpass_users_your_info_and_password_vault_data/",
          "author": null,
          "description": "submitted by    /u/ThatGuy_ZA  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztpthb/lastpass_users_your_info_and_password_vault_data/",
          "publishedOn": "2022-12-23T19:01:25.000Z",
          "wordCount": 16752,
          "title": "LastPass users: Your info and password vault data are now in hackers’ hands. Password manager says breach it disclosed in August was much worse than thought.",
          "imageUrl": "https://external-preview.redd.it/1A3tQAM8v9bkoFfDEZWJ85ON6AQPTCOZXiAt_LkGFnk.jpg?auto=webp&s=9aa3fc7c54688d3ae48ada453fdf05659e58dc36"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztklzh/accidentally_corrupted_my_proxmox_cluster_on/",
          "author": null,
          "description": "submitted by    /u/Theduke322  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztklzh/accidentally_corrupted_my_proxmox_cluster_on/",
          "publishedOn": "2022-12-23T16:05:18.000Z",
          "wordCount": 15504,
          "title": "Accidentally corrupted my Proxmox cluster on Christmas Eve Eve... welcome XCP-NG!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztihct/hi_i_am_slowly_making_my_own_home_lab_and_i_have/",
          "author": null,
          "description": "submitted by    /u/HieroglyphicEmojis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztihct/hi_i_am_slowly_making_my_own_home_lab_and_i_have/",
          "publishedOn": "2022-12-23T15:04:31.000Z",
          "wordCount": 15475,
          "title": "Hi! I am slowly making my own home lab and I have questions. (I’m new! But I’ve been reading a lot!) So, I have a few photos and then I need advice, please.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztclqr/how_to_you_reduce_your_energy_usage/",
          "author": null,
          "description": "Our energy bills skyrocket (even more if you're unfortunate to live in a middle of Europe), and most of us start thinking twice before adding shiny new refurbished server into our racks. I wonder how do you folks optimise energy usage for your homelab? \n The path I went through recently began from re-thinking the purpose of all my boxes:\n  \nwhich ones need to run constantly 24h/day?\n which ones should run during a day, when most of my (and my family's) activity happens?\n which ones should run occasionally, when one needs to access concrete services?\n  \nSurprisingly, the answer for 1. was \"none\" - I don't need to keep anything running during a night and this way I also discovered I may \"sleep\" and \"wake-up\" on predefined schedule all of my servers, including Synology NAS. Proxmox behaves a bit weird (for example I can't log-in to certain nodes after wake up for some reason), but I can live with it.\n The answer for 2nd question was more tricky. Definitely NAS with couple of crucial docker containers (like paperless, dashboard) and AzuraCast are something that everyone at home uses a lot and it should run at least till 22:00. This is where I discovered that all these services are lightweight enough to locate them on single raspberry pi. \n The answer for 3rd question was the easiest - everything else should run \"on-demand\". In particular things related to software dev (Gitea, Drone CI, Coolify, etc.) should start when needed. I managed to reduce required hardware to 2 boxes only - Intel NUC for Kubernetes cluster and Lenovo m720q for the rest, and move them straight onto my desk. They are extremely quiet so no feeling of sitting next to the jumbo-jet.\n I'm still curious how much does it save (maybe not worth the effort), still measuring energy usage. Along the way, I also had to re-evaluate my plans to buy Dell r720. Would be great to have those 48 threads for my hungry clojure containers, but I guess I would have to find another job to pay crazy bills :)\n    submitted by    /u/haksior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztclqr/how_to_you_reduce_your_energy_usage/",
          "publishedOn": "2022-12-23T11:00:01.000Z",
          "wordCount": 17011,
          "title": "How to you reduce your energy usage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztacy0/jonsbo_n1_11_drive_itx_nas_5_hdd_6_25_ssd/",
          "author": null,
          "description": "Meant to post a while ago but life has been busy, felt like sharing probably the densest NAS build I've made.\n I was looking for something that could hold some hard drives but I wanted to explore doing a all flash based vdev, managed to shove all of it inside this ITX case with barely any room to spare. SSDs are in raidz1, 8TBs are mirrored archival, 16TBs are in raidz1 for a redundant copy of data and things I don't care too much about. 3-2-1.\n This thing gets toasty though, the case is nice but isn't built well for airflow. I get way better performance leaving the outer shell off. It draws more power than I intended, might explore the Atom based platforms next.\n Max capacity of this this thing could be insane with ~100TB of HDD capacity, 48TB of 2.5\" SSD capacity, and another 40TB of NVM…",
          "link": "https://www.reddit.com/r/homelab/comments/ztacy0/jonsbo_n1_11_drive_itx_nas_5_hdd_6_25_ssd/",
          "publishedOn": "2022-12-23T08:35:01.000Z",
          "wordCount": 16009,
          "title": "Jonsbo N1 - 11 Drive ITX NAS (5 HDD, 6 2.5\" SSD)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zta2ub/the_4_dashboards_of_my_homelab_network_home/",
          "author": null,
          "description": "submitted by    /u/giuliomagnifico  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zta2ub/the_4_dashboards_of_my_homelab_network_home/",
          "publishedOn": "2022-12-23T08:16:46.000Z",
          "wordCount": 17205,
          "title": "The 4 dashboards of my homelab (network, home appliances, weather, pihole) + my homelab hardware",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zt2n5l/work_was_going_to_throw_this_away_they_didnt/",
          "author": null,
          "description": "submitted by    /u/JanitorPants  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zt2n5l/work_was_going_to_throw_this_away_they_didnt/",
          "publishedOn": "2022-12-23T01:14:09.000Z",
          "wordCount": 15122,
          "title": "Work was going to throw this away, they didn't understand why I would want it but were happy to have me take it from them.",
          "imageUrl": "https://external-preview.redd.it/Zh_zV_LkbzXBIc_Z63DpdoiEBLfqdk9EOPvBbmFGbF0.jpg?auto=webp&s=1c09ff1d8d4e4d5f15aca284b5acd529c6b9e841"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zt2mg4/looking_to_start_a_home_lab_will_this_be_enough/",
          "author": null,
          "description": "I am looking to make a home server to use as a homelab for mostly coding VMs and hosting a MC server. Will the following specs suffice? For 120 dollars: Intel xeon w3670 (6 core 12 thread) 24gb ram (only 1066 mhz I think D:) 500gb hdd (I'm not worried about boot times, and I plan to upgrade in the future) Quadro 600\n    submitted by    /u/UpbeatAardvark2307  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zt2mg4/looking_to_start_a_home_lab_will_this_be_enough/",
          "publishedOn": "2022-12-23T01:13:10.000Z",
          "wordCount": 14252,
          "title": "Looking to start a home lab. Will this be enough?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zt2c0z/pendulum_temperature_monitor/",
          "author": null,
          "description": "Seems reliable for detecting over temperature.\n    submitted by    /u/StraightOuttaCanton  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zt2c0z/pendulum_temperature_monitor/",
          "publishedOn": "2022-12-23T00:59:00.000Z",
          "wordCount": 14182,
          "title": "Pendulum temperature monitor",
          "imageUrl": "https://external-preview.redd.it/YLAF7P_HG6H367la65eyQVFpDqdr8pdwWMSMYymeMRM.png?format=pjpg&auto=webp&s=08419d22d0d42a38438f71527859820d51feccfe"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zt0ixo/how_do_you_guys_incorporate_homelab_experience_on/",
          "author": null,
          "description": "I've seen a number of articles on how to add Homelab experience to your resume, but can't seem to find any good ones on how to add it to your LinkedIn.\n    submitted by    /u/Aehri  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zt0ixo/how_do_you_guys_incorporate_homelab_experience_on/",
          "publishedOn": "2022-12-22T23:35:00.000Z",
          "wordCount": 14615,
          "title": "How do you guys incorporate Homelab experience on your LinkedIn profiles?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zszzzz/esxi_and_nas_on_same_hardwaredrives/",
          "author": null,
          "description": "New home labber, bought a Dell Optiplex 7040 for cheap to be me home server. Currently have ESXI up and running. I mainly want a NAS, Plex, Linux fuck around box. \n The machine currently has a 256Gb SSD and I have 2x 3Tb drives on the way. I’d like to use the Tb drives to be all of the storage for the VMs with some redundancy. \n Can I virtualize a TrueNAS or Unraid setup on part of the drives and leave part for storage on any other machines? Part of the use case would be virtualized Plex, pointing to files on the NAS. Is this a bad idea? What are my other options without spending money on additional hardware?\n    submitted by    /u/citrus_based_arson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zszzzz/esxi_and_nas_on_same_hardwaredrives/",
          "publishedOn": "2022-12-22T23:18:24.000Z",
          "wordCount": 15185,
          "title": "ESXi and NAS on same hardware/drives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zszyr6/ryzen_4300u_apu_passthrough_for_windows_10_vm/",
          "author": null,
          "description": "Hi, \n I am currently trying to pass through the 4300U APU on my Gigabyte Brix 4300U running Proxmox to a windows 10 VM. \n Unfortunately, I could not achieve any result despite following a guide on passing the graphic on 5700G. So the only hope I have right now would be to post something here.\n Really appreciate if anyone who have done this before could share what they did to make it work.\n Again, much thanks\n    submitted by    /u/Specialist_Track_430  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zszyr6/ryzen_4300u_apu_passthrough_for_windows_10_vm/",
          "publishedOn": "2022-12-22T23:17:14.000Z",
          "wordCount": 15013,
          "title": "Ryzen 4300U APU passthrough for windows 10 vm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zszuvx/holiday_homelab_checklist/",
          "author": null,
          "description": "Holidays Homelab Checklist 2022\n Are you ready for the holidays? Are you ready for the next year? Make sure you go through this basic checklist. Comment with suggestions.\n  \nDo you have backups? Have you tested restoration? (this should be a 24/7-365.25 day goal, but eggnog and family may spell disaster)\n If you’re hosting, is your guest network ready? Have you tested it DHCP and DNS? Is the password posted for all to see?\n If you’re hosting, have you made sure your computer and lab are locked up and protected? Some of us have LEDs and toddlers like things to grab and bright lights. So do drunk adults. And people in general. Assume it's not safe unless locked. Locked well.\n If you’re hosting, do you have decoys ready? \n If your family/guests ask you to work on their computers, are you read…",
          "link": "https://www.reddit.com/r/homelab/comments/zszuvx/holiday_homelab_checklist/",
          "publishedOn": "2022-12-22T23:12:52.000Z",
          "wordCount": 14863,
          "title": "Holiday Homelab Checklist",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsyqt6/controlling_desktop_pc_located_in_server_room/",
          "author": null,
          "description": "I just started a Truenas storage server, backup server, and moved all my networking gear to my \"server homelab room.\" I have a pretty specked out desktop PC I use for 4k video editing with Davinci Resolve studio on windows. Due to the size of the RTX 4090 and 360 degree rad, and with all my peripherals plugged in, it takes up a ton of space in my office. Moving my primary desktop to my server room so that everything is in one place and out of the way seems like an attractive idea. I was thinking of having my main desktop in my sever room running a VM software such as proxmox, vmware, or virtualbox with a windows VM connected to a 10G switch via ethernet, then adding a mini ITX build in my office connected to the 10G LAN network, and having the VM stream(not sure this is the right terminolo…",
          "link": "https://www.reddit.com/r/homelab/comments/zsyqt6/controlling_desktop_pc_located_in_server_room/",
          "publishedOn": "2022-12-22T22:25:48.000Z",
          "wordCount": 15392,
          "title": "Controlling desktop PC located in server room, with another computer located in office, via ethernet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsyesl/a_storm_is_coming/",
          "author": null,
          "description": "So I'm resilvering my 4th of 4 drives that I'm upgrading in my truenas scale nas. I'm at 60% completed with about 3.3 (of 9) days left to go. I don't have a ups and there's a good chance we'll have a power outage because of the storm headed to my part of the US tonight into tomorrow evening. Can/should I power down the nas now? Will it pickup where it left off when I boot it up again?\n Any insights are appreciated. TIA\n    submitted by    /u/SurenAbraham  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsyesl/a_storm_is_coming/",
          "publishedOn": "2022-12-22T22:11:35.000Z",
          "wordCount": 14594,
          "title": "A storm is coming",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsy144/what_is_the_optimal_number_of_ram_modules_for_a/",
          "author": null,
          "description": "​\n I am working on the RAM spec of a Dell PowerEdge R730 with dual Xeon E5-2620 v4\n ​\n The Xeon E5-2620 v4 CPU details listed here:\n https://www.intel.ca/content/www/ca/en/products/sku/92986/intel-xeon-processor-e52620-v4-20m-cache-2-10-ghz/specifications.html\n ​\n Here is the CPUs memory specification:\n https://preview.redd.it/g3uf4b5jti7a1.png?width=811&format=png&auto=webp&s=ebd3e791801cdc6833dda7aa789048690a80d99b\n According to the specification, Max number of Memory Channels is 4\n Considering that I have two of the CPU, is it safe to assume that the server perform better with 2x4 = 8 modules?\n If the answer is no, how do I find the optimal number of DDR DIMMs for the server?\n    submitted by    /u/RevolutionaryHunt753  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsy144/what_is_the_optimal_number_of_ram_modules_for_a/",
          "publishedOn": "2022-12-22T21:56:35.000Z",
          "wordCount": 15736,
          "title": "What is the optimal number of RAM modules for a server with dual Xeon E5-2620 v4",
          "imageUrl": "https://external-preview.redd.it/Hlbf52-zMgk3lZiQPiNlVwXxuQqfSuHNMRFDsvyExVQ.jpg?auto=webp&s=0402e358a1b5b71d7e7e3840908c20761a156712"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsx8sv/much_needed_and_cheap_upgrade/",
          "author": null,
          "description": "submitted by    /u/ilvyker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsx8sv/much_needed_and_cheap_upgrade/",
          "publishedOn": "2022-12-22T21:22:52.000Z",
          "wordCount": 14857,
          "title": "much needed and cheap upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zswv0u/finally_getting_2gbps_internet_and_have_some/",
          "author": null,
          "description": "I’ve been struggling for the longest time with 50mbps ISP service where I’m located. I just received a door hanger yesterday from Frontier that they’re expanding fiber to my address and it looks like I’ll be signing up for their 2gig service.\n With that in mind, all of my existing networking is setup at a pretty basic level since I’ve only been working with a 50mbps service. My setup comes from my ISP source and goes into a Linksys Velop WHW03 and then into a basic 1g switch that then goes to the rest of my network. Everything is utilizing Cat5 or Cat5e. I also have an UnRaid server running on a Dell R720 that I’d like to optimize for my network traffic since I run a Plex server, Nextcloud and other services on it.\n Frontier is running a promo where they provide a free Eero 6 mesh system during setup, so I should be ok from a router/AP standpoint.\n I’m mostly wanting to know what the most optimal, budget friendly setup would be from a cabling standpoint, and what network switch I should go with. I’m wanting to do it as cheaply as possible while still making use of the upgraded ISP speeds.\n Thanks!\n    submitted by    /u/lifeisruf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zswv0u/finally_getting_2gbps_internet_and_have_some/",
          "publishedOn": "2022-12-22T21:06:38.000Z",
          "wordCount": 15145,
          "title": "Finally getting 2gbps internet and have some questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsw4qc/h8sglf/",
          "author": null,
          "description": "Hey guys I’m trying to understand the purpose of this board and what it can do. I’ve done some research but I’m not really sure on what I’m looking at and it’s purpose, it has been sitting around my house for a while but I’d like to understand it and be able to utelize it. If anyone could educate me on this matter I’d be grateful.\n :D thanks\n    submitted by    /u/Tall_Author_8945  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsw4qc/h8sglf/",
          "publishedOn": "2022-12-22T20:35:19.000Z",
          "wordCount": 14610,
          "title": "H8SGL-F",
          "imageUrl": "https://preview.redd.it/ttme74y4xj7a1.jpg?auto=webp&s=2e650e261c40923d79cb61348094a7b70a09ee4c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsv2zo/best_use_of_150month_azure_credit/",
          "author": null,
          "description": "Through my employer I get a $150 azure credit/month. I’m planning on just using it for cloud storage for back ups (1TB) but from what ive seen that would eat up like $120-130. Better ideas? \n  \noff load game servers from my main server to the cloud\n off load some constantly running python scripts maybe?\n  \n   submitted by    /u/le_velocirapetor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsv2zo/best_use_of_150month_azure_credit/",
          "publishedOn": "2022-12-22T19:50:21.000Z",
          "wordCount": 15995,
          "title": "Best use of $150/month azure credit?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsudvu/got_old_ups_for_free_looking_for_purchasing/",
          "author": null,
          "description": "submitted by    /u/SonicDart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsudvu/got_old_ups_for_free_looking_for_purchasing/",
          "publishedOn": "2022-12-22T19:20:39.000Z",
          "wordCount": 15700,
          "title": "Got old ups for free, looking for purchasing advice for batteries.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsrl9y/dell_t620_issues_with_installing_server_2019/",
          "author": null,
          "description": "I am about to loose my ever-loving sh**. I have a T620 that I've put together with a mix-match of used parts I find on ebay in bulk. I paid 35 bucks for the server fully intact and have just upgraded since.\n When I was first getting started in automation and VMs I put a few things together in different raid configurations to try and test performance.. I never intended for anything to stay permanent because I was using used retired SAS drives in the raid. Well, you know how that goes, skip forward 4 years and things were left to collect dust and just run. A month or so ago my hass.io instance stopped responding and I kept putting it off until two weeks ago when we had a snow storm that kept me home for a week. I finally started digging in to it and found that one of the drives in my raid-0 …",
          "link": "https://www.reddit.com/r/homelab/comments/zsrl9y/dell_t620_issues_with_installing_server_2019/",
          "publishedOn": "2022-12-22T17:25:29.000Z",
          "wordCount": 16562,
          "title": "Dell T620 issues with installing Server 2019",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsokj9/connecting_proxmox_truenas_servers_via_peer_to/",
          "author": null,
          "description": "So I have a Proxmox server and TrueNAS server that I want to connect directly to each other to get 10GbE speeds between the two. Looking for the cheapest route. So I’m thinking of getting a 10g RJ-45 PCIE NIC for each server and connecting the two via CAT6. Then configuring each NIC with an IP on a different subnet than my current LAN. If my understanding is correct, this should work right? Wanted to upgrade my entire LAN to 10g but prices of switches and other needed hardware are kinda high right now. Also only really need 10g between the two servers. I can make it happen for around $30-$50 buying used NICs on eBay. Already have the CAT6 cabling.\n    submitted by    /u/Techie_19  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsokj9/connecting_proxmox_truenas_servers_via_peer_to/",
          "publishedOn": "2022-12-22T15:23:23.000Z",
          "wordCount": 15895,
          "title": "Connecting Proxmox & TrueNAS Servers via Peer to Peer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zso19e/recommendations_for_10gbps_switches/",
          "author": null,
          "description": "Hello, r/homelab,\n My ISP now offers 1.5+ gbps (3 gbps is already available, with 8 gbps coming early 2023). So that means upgrade time for my network.\n I have been looking for a 10 gbps switch/router, with a preference for a managed, L3 switch. 8+ ports (either copper of fiber as converters exists anyway). Interconnect is 2 X NAS systems, main desktop, 2-3 servers running Kubernetes (might be on a separate l2 switch as a bit far. None currently have 10 gbps adapters so will need to be purchased. All on copper at this time. Also I have APs and a few other devices that will remain on 1gbps. I already have a m,icrotik router that I can reuse (1gbps, 10 ports).\n I am in a fairly small space so noise is an important factor. Here is what im looking at for now:\n L3:\n New - Microtik CRS309-1G-8S+IN:\n Looks decent, 8 x sfp+ ports. I have experience with Microtik and am used top their OS, however specs are low, especially on L3. It is cheap and should be silent. about 280$USD\n Used - Arista DCS 7X series, 1U. 24X+ SFP+, good manageability, no experience with Arista but thats fine (I have dealt with Juniper and Cisco in the past). Worried about noise... About 400$USD on ebay.\n New - NETGEAR 10-Port Multi-Gigabit/10G Ethernet Smart Managed Pro Switch (MS510TXM) :\n Looks ok but I have heard of issues with Netgear stuff. Mostly copper so less work as installing fiber is more complex, however 2.5 gbps/10gbps copper is more expensive. Also 2x more expensive the others at about 600$USD. Might be worth the cost if silent and ok l3 features.\n I have also looked at Cisco and Jiuniper, but noise levels and cost are really high on those, so im really not sure it makes sense.\n L2:\n Ubiquiti Networks UniFi 8-Port 10G SFP+, looks ok, cost-effective, but out of stock everywhere.\n Anyone has go to models for this? Its a lot more complex then I taught it would be, so many options.\n    submitted by    /u/neurotix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zso19e/recommendations_for_10gbps_switches/",
          "publishedOn": "2022-12-22T15:00:04.000Z",
          "wordCount": 17509,
          "title": "Recommendations for 10Gbps+ Switches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsnnfo/two_nas_or_just_one/",
          "author": null,
          "description": "I'm planning on doing a major rebuild of my homelab, hopefully starting it this weekend, and completing by next. I've been going back and forth on whether I should keep a second NAS running for an additional backup location or not.\n The main NAS will be a TrueNAS and main pool will be a 5 disc raid z2 configuration. Raid is not a backup, I know this. I typically keep very important data also saved, less frequently, to an external HDD that spends most of its life unplugged.\n Finally I'm planning to hopefully get an offsite TrueNAS setup in either my office (different state) or mother's home (also different state) that I can remotely backup to.\n I have everything to setup a second unRaid at home. My thought is it's a second backup location, and using unRaid means I can just dump drives as needed into it to grow the pool with little thought to the structure compared to TrueNAS?\n Thoughts from you other homelabbers?\n View Poll\n    submitted by    /u/IroesStrongarm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsnnfo/two_nas_or_just_one/",
          "publishedOn": "2022-12-22T14:42:27.000Z",
          "wordCount": 15905,
          "title": "Two NAS or just one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsmfgl/nginx_reverse_proxy_docker_network_and_homenetwork/",
          "author": null,
          "description": "I want to use nginx reverse proxy to reverse proxy my home network and my docker network.\n If i visit docker1.mydomain.ns i want to access a container in my docker network.\n If i visit server1.mydomain.ns i want to access a server in my home network.\n All of them have the same public ip.\n What is the best way to archive this?\n    submitted by    /u/Transistor4aCPU  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsmfgl/nginx_reverse_proxy_docker_network_and_homenetwork/",
          "publishedOn": "2022-12-22T13:46:05.000Z",
          "wordCount": 19431,
          "title": "NGINX reverse proxy docker network and homenetwork",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsjl3o/how_to_isolate_a_vm/",
          "author": null,
          "description": "Hi all. I want to better secure my homelab by isolating the VM with internet facing services. Ideally the rest of the network should be able to talk to this VM, as one of the internet facing services is overseerr, and I'll need to be able to make changes with it anyway. But in the interest of security, I don't want someone accessing this VM then getting into the rest of the network from it. Does anyone have any advice on the best way to go about this?\n The VM is running in esxi and I'm using unifi networking gear\n    submitted by    /u/Malromen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsjl3o/how_to_isolate_a_vm/",
          "publishedOn": "2022-12-22T11:08:33.000Z",
          "wordCount": 15763,
          "title": "How to isolate a VM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsi3y0/got_a_new_domain_for_cloudflare_tunnels_2_days/",
          "author": null,
          "description": "I recently learned how to use Cloudflare Tunnels to expose services hosted at my home lab (the recent NetworkChuck Video). I got a new domain, linked a couple of my homelab services (jellyfin, tinytiny rss feed aggregator) to it and it worked great (having 500/500mbps fiber connection).\n 2 days later google flagged the main domain and all subdomains as dangerous (Phishing and malware).\n I connected my domain with Google Search Console/Webmaster tools, and it shows that the tinytiny-rss feed aggregator subdomain as the main culprit for the dangerous site.\n I removed the suspected hostname/subdomain from the tunnel 24 hours ago, and still my main site url is still flagged, and even many AV software and firewalls are continuously flagging my domain as malware. I was able yesterday to open my service in Chrome by click continue to the site, but now my AV and firewall refuses the connection.\n I requested google to re-check the domain, but it seems this is not going to work.\n Any tips? Why did even Google flag it? I never published the domain to anybody, it is just for personal use and personal services.\n    submitted by    /u/tech_engineer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsi3y0/got_a_new_domain_for_cloudflare_tunnels_2_days/",
          "publishedOn": "2022-12-22T09:42:17.000Z",
          "wordCount": 17285,
          "title": "Got a new domain for CloudFlare tunnels, 2 days later domain got flagged as dangerous.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsgs94/my_server_seems_like_hacked_and_encrypted_by/",
          "author": null,
          "description": "​\n https://preview.redd.it/sg58xd4zse7a1.png?width=2008&format=png&auto=webp&s=84d475637267ad4cffabfa109832448bf0abf30d\n    submitted by    /u/SatisfactionHead9119  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsgs94/my_server_seems_like_hacked_and_encrypted_by/",
          "publishedOn": "2022-12-22T08:23:02.000Z",
          "wordCount": 20035,
          "title": "My server seems like hacked and encrypted by hackers what can I do ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsfdk9/any_12_bay_small_to_medium_size_case/",
          "author": null,
          "description": "My use case here is a 12 3.5in bay offsite backup. Grunt isn't really required outside of just being able to manage the disks, it's largely about the bays and if i can get unraid running on it. Hotswap is also something i would prefer due to how i store drives during transport. Not looking for anything rack mounted as that's just too much for this purpose.\n So i have two possibilities: \n  \nI can try to find a 12 bay case of the small to medium size variety and work around that(maybe with 5.25\" hot swap expanders?)\n I can find a consumer NAS that can have it's OS changed(i.e a terramaster, QNAP, etc) and use one of those if i can find one that isn't egregiously expensive, as they tend to have smaller form factors than most DIY cases.\n  \nAnybody have any ideas on suggestions for either the former or the latter? 12 seems to be a pretty odd non-rack form factor so there's not a whole lot out there i could find. Stuff like the QNAP TS-1655 might work but i couldn't find any to even get a price. The Terramaster T12-423 looked promising but i was wondering if i could find anything cheaper. Old consumer NAS units might be the way to go but i'm not familiar enough with the model numbers of said units to know what to search for. Most case searches yielded not a whole lot.\n    submitted by    /u/zeronic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsfdk9/any_12_bay_small_to_medium_size_case/",
          "publishedOn": "2022-12-22T07:07:20.000Z",
          "wordCount": 16765,
          "title": "Any 12 bay small to medium size case possibilities? Or possibly retrofitting a consumer NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs83yg/thoughts_on_new_network_setup_omada_over/",
          "author": null,
          "description": "Situation\n I want to upgrade my network due to inconsistent performance (poor reception / unexpected drop outs of non-moving devices), and a desire to roam around my house without the network dropping while working from home. I'd appreciate any thoughts you all have on my plan.\n Constraints\n My brick house is a 2800 sq. ft. split-level with five half-levels that need coverage and a 1/4 acre backyard that needs coverage. Walls are a combination of plaster and drywall.\n Current Setup\n I'm current running a TP-Link Archer C9 router/AP (flashed with DD-WRT) from the top floor on one side of the house and a TP-Link powerline Wi-Fi AP to the third floor on the other side of the house. In general, it works pretty well when near the APs -- within 20 ft sphere of it.\n Proposed Setup\n I examined Ubi…",
          "link": "https://www.reddit.com/r/homelab/comments/zs83yg/thoughts_on_new_network_setup_omada_over/",
          "publishedOn": "2022-12-22T01:28:50.000Z",
          "wordCount": 14628,
          "title": "Thoughts on New Network Setup - Omada over InstantOn or UniFi",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs83hl/thoughts_on_swapping_an_hpe_jg927a_for_a_netgear/",
          "author": null,
          "description": "Hi everyone! Currently I'm using an HPE V1920-48G (JG927A) for my homelab and recently I was given a Netgear GS752TPP for free from work. I dug into the spec sheets for both and from what I can find they seem pretty comparable to each other (except for the Netgear having POE). \n I was wondering if anyone has had experience with one versus the other or knew of any features that one might have over the other. In general though, I'm just curious about people's opinions for whether I should \"switch\" (no pun intended) out what I have for what I received. As of right now, the only positive I can find for doing so is having POE. \n Thanks!\n    submitted by    /u/thebootsie123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs83hl/thoughts_on_swapping_an_hpe_jg927a_for_a_netgear/",
          "publishedOn": "2022-12-22T01:28:14.000Z",
          "wordCount": 14176,
          "title": "Thoughts on swapping an HPE JG927A for a Netgear GS752TPP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs81xl/can_i_use_this_wireless_card_to_broadcast_my/",
          "author": null,
          "description": "submitted by    /u/Saajaadeen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs81xl/can_i_use_this_wireless_card_to_broadcast_my/",
          "publishedOn": "2022-12-22T01:26:21.000Z",
          "wordCount": 14047,
          "title": "Can I use this wireless card to broadcast my homelab wifi network and allow clients to connect?",
          "imageUrl": "https://preview.redd.it/gd97zn1fqc7a1.png?auto=webp&s=1076b94835bcf521b2599355165a0ad2a0899d4e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs81nm/why_do_rj45_sfps_exist/",
          "author": null,
          "description": "Why wouldn't you just use an RJ45 port on the switch? I thought the purpose of SFPs was to easily connect different fiber connectors.\n    submitted by    /u/mopman34  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs81nm/why_do_rj45_sfps_exist/",
          "publishedOn": "2022-12-22T01:26:02.000Z",
          "wordCount": 14268,
          "title": "Why do RJ45 SFPs exist?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs6ru9/i_have_got_a_router_what_should_i_do_with_it/",
          "author": null,
          "description": "Hey guys i have got a technicolor TC7200.1dl router need suggestions what to do with it. Thinking about flashing it with ddwrt or openwrt but the device isnt listed in both sites also there isnt much info about hardware specifications. It has a single lan port and a coax connector.\n    submitted by    /u/jisaaddafifig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs6ru9/i_have_got_a_router_what_should_i_do_with_it/",
          "publishedOn": "2022-12-22T00:33:09.000Z",
          "wordCount": 15571,
          "title": "I have got a router what should i do with it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs6kfs/noise_levels_of_nas_hdds/",
          "author": null,
          "description": "I currently am planning to build a homelab, but I live in a very small studio apartment, so the PC must be in the room with me when I sleep. Currently I am planning on getting 3-5 WD Red Plus HDDs that I will RAID-Z together. How loud will these drives be? Is there any way I can cheaply quiet them down? For reference, I have an i7-8700k that I plan to cool with either 1 or 2 Noctua NF-A15 fans, which will hopefully be fairly quiet.\n    submitted by    /u/Corroddity  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs6kfs/noise_levels_of_nas_hdds/",
          "publishedOn": "2022-12-22T00:24:40.000Z",
          "wordCount": 14285,
          "title": "Noise levels of NAS HDDs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs4jhg/iscsi_san_w_3rd_party_drives/",
          "author": null,
          "description": "I have a Dell MD1200 I use with a H800 controller in my homelab. I would like to \"upgrade\" to a iSCSI SAN device so I can share volumes between multiple computers. I looked at the Dell MD3600f/i series but it appears they only work w/ Dell-certified drives (compared to my MD1200 which is running non-Dell 14TB drives at the moment)\n Can anyone recommend an iSCSI SAN appliance which will work w/ 3rd party 3.5\" SATA drives?\n    submitted by    /u/DisposableAccount712  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs4jhg/iscsi_san_w_3rd_party_drives/",
          "publishedOn": "2022-12-21T23:05:53.000Z",
          "wordCount": 15041,
          "title": "iscsi SAN w/ 3rd party drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs3t35/windows_server_install/",
          "author": null,
          "description": "Since I started my homelab around a year ago, I have been running windows 10 as my server with hyper-v. I have wanted to move away from JumpCloud and properly set up Active Directory on Windows Server 2022. I already moved all my VM's to a second hard drive (and physically unplugged it), so nothing important is on my C drive. I also made a windows server USB flash drive with Rufus, but I am not sure what the best way to install it is. My server is in my basement and does not have a monitor, keyboard, or mouse plugged into it. I have always used MeshCentral/Team Viewer to access it. \n Is there a way to remotely install Windows Server, such as through TeamViewer? Obviously, TeamViewer wouldn't work because the os is being installed, but there has to be an easier way than to sit there with a monitor and keyboard. Does anyone know of any software that would allow me to remotely install an OS, or even a way to install TeamViewer/MeshCentral after install automatically? I use NTLite to install Windows 10 with PowerShell scripts to install everything, but would that work for Windows Server?\n Edit: To clarify, NTLite does work for Windows Server, but even that still requires me to click on the screen to start the install. It’s a lot less clicks, but still requires interaction with a monitor/keyboard.\n    submitted by    /u/BothConsequence5513  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs3t35/windows_server_install/",
          "publishedOn": "2022-12-21T22:38:44.000Z",
          "wordCount": 14484,
          "title": "Windows Server Install",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs3rbk/hp_z620_max_specs/",
          "author": null,
          "description": "Hi guys. I just got my hands on a HP Z620 for relatively cheap and I plan to use it to learn more about Ubuntu server, containerization and multi-threading. What I have is the 2013 boot block version, with the CPU raiser card (2x Xeon E5-2603), 64 Gb Ram.\n I want to know what CPU would you recommend. I read the max core count for dual cpu is 16 core but I have seen that some second hand shops sell this with a configuration of 2x E5-2680v2 (10 core per CPU). Did i misread or the 2013 boot block motherboard supports more than 16 core total?\n Also I was thinking of upgrading to 2x E5-2667v2. What are your thoughts? Thanks\n    submitted by    /u/Bakersor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs3rbk/hp_z620_max_specs/",
          "publishedOn": "2022-12-21T22:37:19.000Z",
          "wordCount": 15033,
          "title": "HP Z620 max specs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs3qn2/how_do_you_set_up_idrac7_and_8_so_you_can_access/",
          "author": null,
          "description": "I've been smashing my head against this for a week, I want to be able to access the idrac web gui for my r720 and my r730 from a browser using a fully qualified domain name (ex: idracdnsname.dnsdomain.name ) instead of an ip address within my internal network.\n I tried setting idrac dns name and static dns name in idrac network settings but that didn't work.\n I don't know if I have to set up something outside of the idrac or what I have done incorrectly. \n Help would be very appreciated please.\n    submitted by    /u/Computer-bomb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs3qn2/how_do_you_set_up_idrac7_and_8_so_you_can_access/",
          "publishedOn": "2022-12-21T22:36:48.000Z",
          "wordCount": 14365,
          "title": "How do you set up idrac7 and 8 so you can access it with an fqdn?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs354g/requirements_for_grounding_a_patch_panel_in_wall/",
          "author": null,
          "description": "Residential. Texas, US. House built in 2015. The patch panel I purchased has come with a grounding wire. House is wired for UTP CAT5, and patch cables where used are UTP CAT6. CAT6 is used for two POE Unifi AP’s. The rack is wall mounted and the rack mount power strip is plugged into a UPS that sits on the floor, but will soon be wall mounted with a R720 server - very close to rack in question. There is a Unfii Dream Machine SE and QNAP NAS in the rack, both have three prong plugs. The POE ports on the DMSE will plug into patch panel and then continue on there way. \n Do I need to ground the rack? Should I ground the rack? If I do, can I attach ground cable to the rack and bolts where DMSE connects to the rack where there is bare metal? I don’t see a grounding point on the rack - although might have missed it. If my situation doesn’t require grounding, is there a possible home lab/networking upgrade path where I would need to ground? Thanks in advance for any advice. \n Links Patch Panel: Patch Panel 24 Port Cat6A with Inline Keystone 10G Support, Rapink Coupler Patch Panel STP Shielded 19-Inch with Removable Back Bar, 1U Network Patch Panel for Cat7, Cat6, Cat6A, Cat5e, Cat5 Cabling https://a.co/d/5G9LnNl Wall mounted rack: RackPath 12U Performance Wall... https://www.amazon.com/dp/B0995K2KRQ?ref=ppx_pop_mob_ap_share Rack power supply: StarTech.com 8 Outlet Horizontal 1U Rack Mount PDU Power Strip for Network Server Racks - Surge Protection - 120V/15A - w/ 6ft Power Cord (RKPW081915) https://a.co/d/8BzwjOO\n    submitted by    /u/hive5mind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs354g/requirements_for_grounding_a_patch_panel_in_wall/",
          "publishedOn": "2022-12-21T22:20:29.000Z",
          "wordCount": 15271,
          "title": "Requirements for grounding a patch panel in wall mounted rack. UTP cabling.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs2zha/double_plex_library_project_questions/",
          "author": null,
          "description": "Hey Homelab crew,\n I would like to setup a second plex instance from my current homelab, I would like to have the exact same library for now and I wanted to know what would be the best way to have it automatically do that. Is there a way one Ombi request can populate or communicate with 2-3 sonar and radarr instances ? Thanks for any info\n    submitted by    /u/Iceman-1317  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs2zha/double_plex_library_project_questions/",
          "publishedOn": "2022-12-21T22:15:31.000Z",
          "wordCount": 15164,
          "title": "Double plex library project questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs2t4r/homelab_setup/",
          "author": null,
          "description": "Ok, so I know I have a lot of options here but Im throwing this out there for some recommendations. I started building a lower end Home Lab without going full server or even full NAS. I have two different Macbook Pros that I work on. Here is what I have:\n  \nLenovo ThinkCentre M910Q Tiny Desktop Computer, Intel Core i7-6700T , 32GB RAM, 1TB NVMe SSD\n 4 Raspberry Pis 8GB RAM with SSD drives and cables\n 1 Raspberry PI 4 GB RAM with SSD\n Couple of TP Link desktop switches\n Protectli 2 port running OpenSense\n Older Apple Time Capsule 1TB\n  \nCurrently running a pi server with a variety of Docker containers (Ad Guard, Homepage, Grafana, Prometheus, portainer, Bitwarden, Homebridge\n OMV NAS with 3TB also running Plex, Nextcloud, FileBrowser, Portainer and Yacht\n Home Assistant on a Rasp Pi\n Will have two clean Rasp Pis and the ThinkCenter...Im thinking Proxmox on the ThinkCenter, not sure about the rest. What are some options and should I go Proxmox on the Lenovo?\n Interested in home automation, learning and just general tinkering.\n ​\n ​\n    submitted by    /u/djshaw0350  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs2t4r/homelab_setup/",
          "publishedOn": "2022-12-21T22:10:54.000Z",
          "wordCount": 14166,
          "title": "Homelab setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs1vzm/question_about_the_future_of_10g_baset/",
          "author": null,
          "description": "I have been wiring rooms in my house with some Cat 6 ethernet cables (20-30m) as I wanted some future proofing for 2.5Gbe, 5Gbe and potentially 10Gbe. Currently 10Gbase-T seems very demanding on amount of power draw and the cooling required for anything more than just a single port. I know there are fiber options but bending OM3 cables around corners fills me with dread.\n Just wanted to know is the power draw due to the amount of processing required to send and read data? Will power/heat come down in the future as we get more efficient/faster chips to the point where we can get affordable consumer grade switches/routers. Was transitioning from 100 mbe to 1 Gbe similar in that the power/heat was significant but came down over time?\n    submitted by    /u/binary101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs1vzm/question_about_the_future_of_10g_baset/",
          "publishedOn": "2022-12-21T21:44:02.000Z",
          "wordCount": 15552,
          "title": "Question about the future of 10G Base-T",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrveci/computer_infrastructure_in_your_garage_workshop/",
          "author": null,
          "description": "Hey all, as I have a bit of free time during the holidays, I'm beginning to think about building out some network infrastructure in my garage which mostly serves as a wood working workshop, but which also includes a workbench that I use for some minor experimentation with ham radio and electronics. I currently have two POE cables running into the room to power a pair of POE cameras that I use to monitor a feral cat that I feed inside, but I don't have any other cabling currently: it's a blank slate.\n Basic needs are perhaps six or so ports that are routed to my electronics bench, another four or so which are POE ports that I can use to power my existing cameras, plus an extension, and maybe an inexpensive 2.4G access point to provide more reliable access to some Tasmota sensors. I currently am using a https://www.amazon.com/gp/product/B08GS211V9 hooked to my pfsense router, which may get repurposed out to the garage. 1GB networking is probably fine here, I'll probably create a subnet using one of the spare ports on my KingNovy pfsense box, which technically opens up the possibility of 2.5GB networking, but no device I'm likely to have in the garage \n Has anyone else done something like this? I am interested in seeing other similar small network setups. The environment is likely to be fairly dusty (working on better dust collection in the shop, but again, that's another project). I'm probably going to build a small case to house the major bits, with just a small switch mounted to the workbench, with some little silicone dust caps to keep the worst of the dust out when not in use? \n I recognize this isn't a very fancy project, but I'm interested in doing a better job than just laying cables around everywhere willy nilly.\n Thank you all for your advice!\n    submitted by    /u/CommitteeTop5321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrveci/computer_infrastructure_in_your_garage_workshop/",
          "publishedOn": "2022-12-21T17:42:20.000Z",
          "wordCount": 15733,
          "title": "Computer infrastructure in your garage workshop?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrtw5t/dont_expect_a_raspberry_pi_5_next_year/",
          "author": null,
          "description": "submitted by    /u/jesse_james  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrtw5t/dont_expect_a_raspberry_pi_5_next_year/",
          "publishedOn": "2022-12-21T16:49:54.000Z",
          "wordCount": 15692,
          "title": "Don’t Expect a Raspberry Pi 5 Next Year",
          "imageUrl": "https://external-preview.redd.it/f7XBrrI-7LP8t6T_uNwtDo0a9dIsrCHItSdmOTGc_DQ.jpg?auto=webp&s=f3ccef45180a3b46f984eb08e952ffc49084d324"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrt3t0/help_me_to_identify_the_ram_module/",
          "author": null,
          "description": "​\n https://preview.redd.it/jf642css1a7a1.jpg?width=2016&format=pjpg&auto=webp&s=d36ac9ed6c2a59c205423a3db9943a48587a0606\n Here I'm sharing two RAM module, on first.jpg (above) I can easily identify its DDR3 12800 (Mhz) to replace the ram i have to take care of these number\n But look at the below image second.jpg RAM module has weird marking that i do not understand, can someone help me to understand what is this marking and what could be the replacement\n second.jpg\n Second.jpg is installed in leptop if i replace it with first it does not work, but i checked first.jpg in some other laptop its working fine as well. \n ​\n ​\n    submitted by    /u/sairfan1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrt3t0/help_me_to_identify_the_ram_module/",
          "publishedOn": "2022-12-21T16:26:49.000Z",
          "wordCount": 15259,
          "title": "Help me to identify the RAM module",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrrbfy/do_i_need_unraid/",
          "author": null,
          "description": "Specs: i5 Gen 11, 32 gb ram, 3 HDD (4tb + 1tb + 500gb) , 500gb NVME SSD, 3 16TB HDD (to be installed after rebuild)\n Currently, I am running Proxmox and have 4 VM + 4 LXC running on it. I have the following services: https://imgur.com/a/POaQFhG\n I want to have redundancy on my drives. I initially planned on installing OMV and using RAID5 config. for the drives. The machine will be used for media storage only. I have another machine for NAS stuff. I plan to backup all the media to Backblaze B2.\n I recently was in talks with a developer for Bazarr app, he suggested that I go with unRAID. So, I got a trail for unRAID. It's nice and simple. Few click here, few click there and you are done.\n I managed to mock migrate all my current services to unRAID docker containers just fine. Played around with caching too.\n After using it for about a week, I am still questioning whether it is a necessary purchase for me.\n My main questions are:\n  \nHow different is unRAID's parity disk approach from RAID5?\n How reliable is OMV?\n Most importantly, do I need unRAID?\n  \n   submitted by    /u/trainwreck_summer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrrbfy/do_i_need_unraid/",
          "publishedOn": "2022-12-21T15:44:11.000Z",
          "wordCount": 17066,
          "title": "Do I need unRAID?",
          "imageUrl": "https://external-preview.redd.it/b6crZmHgAC7CxXBFEb6MBuot2mehNBC2ATmoWhg-Eog.jpg?auto=webp&s=52b641a46b6dc1e70e52a78be1dc50116f4ca261"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrkpkm/what_is_your_disaster_recovery_plan/",
          "author": null,
          "description": "I came across a good article in a magazine about how one should have a good disaster recovery, whether is from a data breach or data disaster. Also the importance of offsite backups and data encryption. I wanted to know how many of us have an actual plan to go from 0 to 100% recovered.\n    submitted by    /u/D3imOs8910  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrkpkm/what_is_your_disaster_recovery_plan/",
          "publishedOn": "2022-12-21T12:54:20.000Z",
          "wordCount": 18524,
          "title": "What is your disaster recovery plan?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrklre/thoughts_on_my_setup/",
          "author": null,
          "description": "​\n https://preview.redd.it/bk9ycj4hz87a1.jpg?width=4000&format=pjpg&auto=webp&s=22be43abeed338b64783992d54d5b8296a9d9fbd\n My Home lab Setup.\n  \nDesktop Server \n \nAsus Chromebox 3 with custom BIOS and Proxmox \n \nTP-Link AXE95\n \nTP-Link AX50\n \n350/350 Mbps ISP Fiber Connection\n \n ​\n A. Desktop Server \n  \nIntel i5 3570K \n \n16GB DDR3 RAM \n \nGTX 1650 (Plex Transcoding)\n \n16TB SATA Storage (4*4)\n \n2 Gigabit NICS\n \nUnraid \n \n B. Asus Chromebox\n  \nIntel i7 8550U \n \n16GB DDR4 \n \nWifi 6\n \nGigabit NIC \n \n2 Ubuntu Servers, 1 Win 11 & OpenWRT VMs\n \n Using AXE95 as my main access point as it gives near gigabit throughput on wifi 6. \n Using AX50 with Proxmox Openwrt & Nordvpn as a VPN router. \n ​\n What you guys think ?\n    submitted by    /u/adasmalakar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrklre/thoughts_on_my_setup/",
          "publishedOn": "2022-12-21T12:51:32.000Z",
          "wordCount": 16196,
          "title": "Thoughts on My Setup ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrgmwr/iperf3_between_openmediavault_servers_only/",
          "author": null,
          "description": "I'm pulling my hair out over this, but I have 2 openmediavault servers that I'm running (one is going to be the new daily driver and the other will become my backup machine). I want to get evertyhing copied over from the existing one and I have dual 10gig NICs in each of them so I'd like to use that lane for the initial copy and subsequent scheduled backup.\n I have the 10gig interfaces configured like so for each server (only posting the image of one)\n ​\n https://preview.redd.it/hfpn8913b87a1.png?width=2358&format=png&auto=webp&s=a148539f3913b3b9c8480d1c5971d30690d9fece\n When I run iperf3 from one of them as the 'server' and the other as the 'client' I can't get more than 980 mbps for transfers. One thing to note: when I run the client command I use the IP of the other server, but it's not the IP of either of the above interfaces. If I try to call it with one of the 10gig IPs from the image above it just hangs there.\n So i feel like the issue with my test is that iperf3 isn't actually using the NICs for the transfer. Am I doing something wrong in iperf or in the setup, or both?\n    submitted by    /u/FourTimesRadical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrgmwr/iperf3_between_openmediavault_servers_only/",
          "publishedOn": "2022-12-21T10:34:46.000Z",
          "wordCount": 17630,
          "title": "iperf3 between openmediavault servers only showing up to 980mbps with 10gig cards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrgh4o/bought_2_raspberry_pi_4_accidentally/",
          "author": null,
          "description": "So wanted to buy one rpi but bought 2 with bunch of sensors etc. Now no option to cancel. Bit pissed with myself but also excited... Give me some cool project ideas, please 😂\n    submitted by    /u/adasmalakar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrgh4o/bought_2_raspberry_pi_4_accidentally/",
          "publishedOn": "2022-12-21T10:25:04.000Z",
          "wordCount": 15042,
          "title": "Bought 2 Raspberry Pi 4 accidentally!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrdg4w/taking_care_of_a_friends_sugar_glider_for_a_few/",
          "author": null,
          "description": "submitted by    /u/feelingsupersonic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrdg4w/taking_care_of_a_friends_sugar_glider_for_a_few/",
          "publishedOn": "2022-12-21T07:20:35.000Z",
          "wordCount": 16698,
          "title": "Taking care of a friend's sugar glider for a few days. They like warm temperatures, so Penny is now A+ certified.",
          "imageUrl": "https://preview.redd.it/xsrfhdppc77a1.jpg?auto=webp&s=13ec89cebcf20e4039eaa1ef71dcc510e77eec59"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr5gzm/homelab_firewall/",
          "author": null,
          "description": "Hello, I am thinking of buying a used firewall for my homelab from ebay. I just bought a 42u server rack, and I just upgraded one of my Dell Powervault DR4100 server with 192GB of memory. I also have a cisco catalyst 4948 switch as well. I was thinking of buying a Forigate Fortinet firewall, I have seen other people recommend untangle firewall as well. I have heard mixed reviews on both. I was wondering, If I am correct in saying, that if the license is expired, I cannot use most of the features. Including the web filtering feature. Is there any firewall I can buy off of ebay to either test or possibly implement down the road with that doesn't require a license to use these features?\n Thank you.\n    submitted by    /u/IceCreamMan1776  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr5gzm/homelab_firewall/",
          "publishedOn": "2022-12-21T00:49:43.000Z",
          "wordCount": 14209,
          "title": "Homelab firewall.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr52zt/looking_for_long_endurance_ssds_12tb_1pbw/",
          "author": null,
          "description": "I am looking for some advice regarding ssd choice for a new system\n (planing to run 3 in raidz1 for vms + logging and another 2 for caching)\n Since it should last as long as possible and the server is going to be used for extensive writing (logging as well as cache for some jbods/hdd pools) i am looking for at least 1pbw better 4+pbw lifespan.\n I already looked through used enterprise ssds on ebay for a couple hours but didnt decide yet.\n One that caught my attention is the Toshiba THNSN81Q92CSE (1.92tb for 120$) but i couldnt find any documentation regarding lifespan.\n Would it be a good choice?\n I also looked through many intel ones but got a bit confused regarding their naming (and vastly different endurance ratings according to the wikipedia article)\n What can you recommend?\n    submitted by    /u/Pommes254  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr52zt/looking_for_long_endurance_ssds_12tb_1pbw/",
          "publishedOn": "2022-12-21T00:37:34.000Z",
          "wordCount": 14245,
          "title": "Looking for long endurance SSDs | 1-2tb | 1+pbw",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr52np/looking_for_help_flushing_out_my_new_setup/",
          "author": null,
          "description": "I have a new machine I have built that I am looking to help work the way I envision, and need some help ensuring I know what I need next to make this happen. I apologize as I am a bit of a noob both proxmox and zfs.\n Machine Ryzen 5700x, msi b550m pro-vdh wifi, 16gb ram.\n pci sata card: https://www.startech.com/en-ca/cards-adapters/pexesat322i\n Drive 1x 500gb SSD, 3x3TB HDD, 1x1TB HDD\n Looking to run Proxmox, and virtualize unRaid purely as a NAS, and using proxmox as I need to virtualize a couple other environments.\n I did one pass and got everything up and running with proxmox install in xfs, however I want to encrypt all of the drives.\n Following the guide here I can encrypt the Proxmox install:\n https://herold.space/proxmox-zfs-full-disk-encryption-with-ssh-remote-unlock/\n ​\n However, I need a sanity check on what I need to do to make this work effectively:\n  \nGet another SSD, and install it zfs in raid1 on JUST the SSDs and encrypt the zfs\n Get a larger pci raid card and pass through the pci card with all drives to unRaid have unraid encrypt xfs / zfs and manage\n Get a 3rd SSD for a cache drive connected to the raid card, or can I virtualize this from extra space on the zfs drives\n Backup all my files from my VM's on unRaid\n  \nOption 2: Set all drives to ZFS (pool 0 - SSD) (pool1 - HDD) by proxmox and nas some other way.\n Option 3: Option 2 + Pass virtualized drives to unRaid? I think I lose access to smart data etc if I do it this way.\n My goal is just encrypted fault resistant storage of my VM's and Data.\n    submitted by    /u/c_o_f_f_e_e  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr52np/looking_for_help_flushing_out_my_new_setup/",
          "publishedOn": "2022-12-21T00:37:13.000Z",
          "wordCount": 14503,
          "title": "Looking for help flushing out my new setup",
          "imageUrl": "https://external-preview.redd.it/s6zz1vUgVar8Sy-ud-LjA71yJTC-3ExGVoRv89-qCq0.jpg?auto=webp&s=cd3944b7221dfd2739453fd3533007aeebb63c64"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr45uw/my_attempt_at_a_homelab_from_old_work_pc_and/",
          "author": null,
          "description": "submitted by    /u/Important-Duty-5608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr45uw/my_attempt_at_a_homelab_from_old_work_pc_and/",
          "publishedOn": "2022-12-21T00:06:37.000Z",
          "wordCount": 14332,
          "title": "My attempt at a homelab from old work pc and server.",
          "imageUrl": "https://preview.redd.it/zhym6q24p67a1.png?auto=webp&s=e43f3949760b02cfbc790d0b4039ba6e673c000d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr3pxr/building_a_home_lab_for_nas_and_machine_learning/",
          "author": null,
          "description": "Hey everyone, my name is Jay\n I am currently in the possession of three Dell T5810s with varying specifications that I want to turn them into a NAS storage, regular PC, and a machine learning workstation, but to make the purpose of all of these machines easier, I'm just going to call them - Alpha, Bravo, and Charlie. Here's the current specification for each of these machine once I upgrade the CPU: \n Alpha Machine\n  \nIntel Xeon E5-2650v4\n 16GB (2x4) DDR4 RAM\n Nvidia GTX 1060\n Samsung 500GB EVO Drive\n used Western Digital 1TB 7200RPM Drive\n \n425W Dell Power Supply\n Bravo Machine\n \nIntel Xeon E5-2650v4\n \n16GB (4x4) DDR4 RAM\n \nNvidia Quadro 600\n \nNvidia Quadro K2200\n \nSamsung 500GB EVO Drive\n \nused Western Digital 1TB 7200RPM Drive\n \n425W Dell Power Supply\n \n Charlie Machine\n  \nIntel Xeon E5-…",
          "link": "https://www.reddit.com/r/homelab/comments/zr3pxr/building_a_home_lab_for_nas_and_machine_learning/",
          "publishedOn": "2022-12-20T23:48:03.000Z",
          "wordCount": 14728,
          "title": "Building a home lab for NAS and Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr2dki/i_recently_passed_my_a_and_im_excited_to_get/",
          "author": null,
          "description": "I’ve tried using Virtual box to install Server 2016, Parallels and tried using Azure but keep getting repeated errors. \n I’ve googled a ton and watched a ton of YouTube videos on how to set up windows sever as a VM. I’ve also read a few things which suggest that it is not possible to set Windows sever on a MacBook with an M1 processor. \n Does anyone have any other suggestions of how I could set up windows sever and AD? Thanks in advance.\n    submitted by    /u/GlassMountain9473  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr2dki/i_recently_passed_my_a_and_im_excited_to_get/",
          "publishedOn": "2022-12-20T22:53:28.000Z",
          "wordCount": 15227,
          "title": "I recently passed my A+ and I’m excited to get started in IT. For the past 2 days I’ve been trying to set up Windows sever on a VM on a MacBook Pro M1 and have encountered a few issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr250h/acquired_a_poweredge_t130_with_7tbs_of_hdd_space/",
          "author": null,
          "description": "Hey y’all. It came with 3x 2tb 3.5 and 1x 1tb 3.5\n Questions are.\n Can I put more HDD’s in? Maybe some 2.5?\n If I set it up as a NAS now then decide later I want bugger HDDs can I just add them to the system or do I need to start a new instance of the NAS some how? \n Lastly, TrueNAS scale or core ?\n    submitted by    /u/Dev-N-Danger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr250h/acquired_a_poweredge_t130_with_7tbs_of_hdd_space/",
          "publishedOn": "2022-12-20T22:43:43.000Z",
          "wordCount": 14149,
          "title": "Acquired a poweredge T130 with 7Tbs of Hdd Space. Planning on using this for NAS but have a couple questions…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr0yok/which_type_of_switch_should_i_get/",
          "author": null,
          "description": "I am new to the home lab environment and I am wondering whether I should get a managed or unmanaged switch. I have done some research before posting here but i am still unsure.\n I have read many articles saying that managed switched are useful for homes that have a lot of IoT devices, which I have a ton of (smart lighting, smart sockets and digital assistants in almost every room of my house). I don't know if the ability to create VLANs will be necessary for me as it will only be used for my main machine and 2 servers, one that will be running a webserver and a game server, each in its own docker container and then the other as a NAS.\n Based on this would it be worth getting a managed switch anyway, and spending the time learning the necessary network management skills, or just getting an unmanaged switch for the simplicity.\n    submitted by    /u/nuratic0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr0yok/which_type_of_switch_should_i_get/",
          "publishedOn": "2022-12-20T21:56:52.000Z",
          "wordCount": 15149,
          "title": "Which type of switch should I get?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr029g/looking_for_a_hardware_vpn_gateway/",
          "author": null,
          "description": "Hey!\n My homelab grows little by little, and I want to have access to it outside of my LAN, via VPN. Now, I could install Wireguard on my server, but I mess a lot with it, and it has big chance of being broken. More over, since it's a simple ThinkCentre that does not support wake-on-wan, theoretically I could lose connection in case of power outage while I'm away.\n So I'm looking for a dedicated device that will run only VPN, and maybe DNS (AdGuard Home). I could get a Pi for that, but I kind of don't understand their point. They are not cheap, and they run on SD cards which a prone to corruption (eventually).\n Another option is to run the VPN on my router, but Omada currently supports only OpenVPN and not Wireguard, and I have no idea when, or if, they will support it.\n I found this one GL.iNet - GL-MT2500 / Brume 2 which is in pre order and pretty affordable. It runs Wireguard and AdGuard home, and acts as both VPN server and client. I've heard about GL.iNet before, but I still worry about their reputation (although it seems they run mainly on open source software).\n Appreciate if someone can shed some light on that particular device or suggest something else.\n Thanks!\n    submitted by    /u/skwee357  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr029g/looking_for_a_hardware_vpn_gateway/",
          "publishedOn": "2022-12-20T21:21:11.000Z",
          "wordCount": 15136,
          "title": "Looking for a hardware VPN Gateway",
          "imageUrl": "https://external-preview.redd.it/d9CE0i8tWzmBbSItKfejFKjaJN8gNMJM4GbTv3PFAYY.jpg?auto=webp&s=a5c224bfa9cacc525a37c7cdfbebabdc07681b88"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqzp5h/help_evaluating_lsi_92118i_authenticity/",
          "author": null,
          "description": "Hey gang, I've spent a solid day of interspersed researching on these cards and found a lot of guidance that says these things usually have an LSI logo, but not neccesarily that its fake if it doesn't. I bought https://www.ebay.com/itm/155042469639 this card recently and it hasn't arrived yet, but I'd love to understand if there are any signs this is either legitimate or fake from the stock images.\n Particulary, it looks like it has the words \"FastPCB\" where I'd expect a logo to go. However, the seller has extensive and positive feedback (5 digits of positive). \n The card itself looks to be an Inspur with a model #YZCA-00019-101 found on the back of the image. \n I tried googling for this metadata and found nothing really to say yes or no for counterfeit signs or if the logo should be missing.\n Basically I'm struggling to reach a good stopping point here and would love this squad's advice on any and all analysis of this offering's legitimacy. \n Thanks so much in advance.\n    submitted by    /u/cadorett  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqzp5h/help_evaluating_lsi_92118i_authenticity/",
          "publishedOn": "2022-12-20T21:06:57.000Z",
          "wordCount": 14579,
          "title": "Help evaluating LSI 9211-8i authenticity",
          "imageUrl": "https://external-preview.redd.it/l25Q1ECbqNx-4aWFMaA3F-xarkYoOMZKPgqdKMUFsB0.jpg?auto=webp&s=a71454b5641a2ce550e090e77f9140e52460505a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqydo9/help_with_permissions_of_an_smb_share_from/",
          "author": null,
          "description": "Edit: I forgot to add the UID and GID of the users needing access to the share when mounting in CIFs.\n ​\n Hi All, not sure if this is the best place to post, but thought I'd try.\n ​\n I'm rebuilding some of my VMs and am running into some permissions problems. I am able to write to the share with one VM, but not the other, with the built in user 'radarr'.\n ​\n Both the old (left) and the new (right) VMs have the same SMB share mounted to /mnt/media using cifs. The cifs credentials are the same in each VM and allows me to have full control of the data from TrueNAS under my admin user 'andrew'.\n ​\n You can clearly see in the picture that the permissions of the old VM are set as rwxrwxrwx, while the new is missing write for groups and other. I believe I may have used chmod -R 777 /mnt/media on the old VM, but I honestly can't remember and I'm not sure how to see this (I've since started documenting all changes I make and what they do so this won't happen in the future). I'd also prefer to not 777 an entire dataset, even if it is not sensitive data.\n ​\n I know I can fix this by changing the user running the service, but I want to keep the radarr service running as the user radarr as that is best practice for linux.\n ​\n Any help or pointing to an article I can read would be much appreciated.\n ​\n https://preview.redd.it/yhhsy9tew37a1.png?width=1766&format=png&auto=webp&s=fa73c6aa0cdebb300cd8f1bbe9b1fc186a4ecbaf\n    submitted by    /u/WhatsAQazza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqydo9/help_with_permissions_of_an_smb_share_from/",
          "publishedOn": "2022-12-20T20:14:08.000Z",
          "wordCount": 16095,
          "title": "Help with permissions of an SMB share from TrueNAS on a Linux VM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqy6sb/where_do_you_store_encryption_keys/",
          "author": null,
          "description": "I'm starting to setup backups of my VMs/containers, and want to make sure everything is encrypted when it goes to backblaze...but what if I lose the key/salt? Currently I have\n  \nVM backups important data in .tar.gz files daily\n VMs add the .tar.gz files to an NFS share running on truenas\n Truenas runs multiple snapshots and uploads dataset to B2 with an encryption key/salt\n  \nEverything seems fine and I have reminders to test it...but where do you safely story those keys? Currently I wrote it down on a sticky note in my wallet and in bitwarden. Safe enough lol?\n    submitted by    /u/MeerkatMoe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqy6sb/where_do_you_store_encryption_keys/",
          "publishedOn": "2022-12-20T20:06:17.000Z",
          "wordCount": 15529,
          "title": "Where do you store encryption keys?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqx96g/rebuilding_the_home_network_is_a_unified/",
          "author": null,
          "description": "Hi /r/homelab,\n I've been deep in research for weeks now looking into all the possible ways to go for a home network rebuild. For a long time I was putting a high value on unified management / SDN solutions like Unifi or TP-Link Omada, but I am beginning to rethink that. It seems like both platforms have the kinds of drawbacks (support, hardware quality and availability, feature roadmaps that never materialize) that I would find endlessly frustrating as someone with a day job in IT.\n I know the sub is geared more toward learning and experimentation, and I value that too, but I have to balance that with reliability and availability of the network, particularly as I work remotely. Central management seemed very appealing for a no-nonsense setup, but now I am less sure that I will see long-term value from buying into such a stack.\n So I'm looking for input on this -- is the single pane management of something like Unifi or Omada worth the other headaches from these companies? Or would I be better served going with older \"best of breed\" enterprise equipment for switching and wireless, paired with something like pfSense for routing? I lose the central management, but it seems clear that I would have better hardware for similar expense.\n If you lean enterprise in your response, please mention what hardware you prefer for APs, switching, and routing. I would especially like to hear your opinions on mixed environments. ATM I am considering Ruckus AP / Aruba ION switching (local control) / pfSense as a potential build if dissuaded from Unifi or Omada, for example.\n    submitted by    /u/DullFuplex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqx96g/rebuilding_the_home_network_is_a_unified/",
          "publishedOn": "2022-12-20T19:29:00.000Z",
          "wordCount": 17218,
          "title": "Rebuilding the home network. Is a unified management stack (e.g. Unifi) really worth the drawbacks of such a platform?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqwo4m/expanded_storage_for_a_bitfenix_ghost_case/",
          "author": null,
          "description": "Hello r/Homelab,\n I've recently come into 8x6TB WD Red drives and I plan to configure these all in RAID6. I've already got an LSI-9211 RAID card for the setup.\n My problem is that my case, which I otherwise love, doesn't have enough storage for 8 3.5\" drives. Here's a link to the specs of the case that I have and it only has 4 internal 3.5\" bays. I'm okay with removing any or all of the 2.5\" bays or the 5.25\" bays if needed, but I haven't found a suitable storage method for what I would put in place for those drives.\n Has anyone had experience or luck expanding storage in their homelab? Are there any other concerns I should be aware of? I know heat may be an issue, but there are two 80mm fans directly in front of the drive bays, and the processor is watercooled by a Swiftech H220 so the internals of the computer don't get too hot as it's configured now.\n    submitted by    /u/Ponderputty  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqwo4m/expanded_storage_for_a_bitfenix_ghost_case/",
          "publishedOn": "2022-12-20T19:05:46.000Z",
          "wordCount": 15257,
          "title": "Expanded storage for a BitFenix Ghost case?",
          "imageUrl": "https://external-preview.redd.it/A5d58aFKsRHnVxTf5Ohr80852B4FclBcJltwzKF_wF0.jpg?auto=webp&s=3b05ec3e127740af13862c31dfa651d7c908dc43"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqvxjh/dell_r210_ii_still_a_good_option_for_pfsense/",
          "author": null,
          "description": "I'm currently running my pfsense virtualized under proxmox on a small white-box i prepared myself. The thing is that I've become tired of the problems of not having it bare metal and I'm seeking for a new box.\n I've come into an offer for a r210 II and I've read good things about it, but i was wondering if it is old info and if there are currently better options.\n I have several vlans and unfortunately my switch showed as a fake L3 one, so i need inter-vlan routing at router level. But i also seek for low power consumption, as my homelab runs on sun power. 😎\n I bought two NUCs, but they simply didn't seem good to use them for pfsense. I repurposed them as Iot machines.\n Thanks guys for your suggestions 🙂\n Edit: Ah, and I'm running it on a stick, i would put a 10gbe card on it.\n    submitted by    /u/Qbic_dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqvxjh/dell_r210_ii_still_a_good_option_for_pfsense/",
          "publishedOn": "2022-12-20T18:36:41.000Z",
          "wordCount": 16746,
          "title": "Dell r210 II still a good option for pfsense?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqs9kj/looking_for_opinions_on_thinclient_rtsp_streaming/",
          "author": null,
          "description": "Some backstory before the question:\n I've had some suspicious activity in my neighborhood lately. I have some outdoor facing PoE cameras on my network that are currently accessible to the internet so we can view them when not home (using BlueIris). I've been doing some more networking at work and want to really isolate everything correctly on my home network. Separating the cameras and BlueIris VM onto their own vlan, setting up routes to only allow certain IPs to connect, things like that. I think it would be good exercise to learn more on networking along with properly securing my network.\n The end goal is to view the RTSP streams of the cameras on a single monitor without having to RDP into my blue iris VM. Being able to do that without having to do anything except start the device would be great too, but thats more of a wish because I don't know if it is possible yet.\n I've been looking at Thin-Clients like a Dell Wyse 3040 or an HP T620 to view camera streams either through VLC or to just load a webpage that is hosting the RTSP streams on. I see a lot of raspberry pi suggestions online for my use-case, but the shortage and prices make it completely out of the question. I want to have this device on the same vlan as the cameras/BlueIris VM/Webserver hosting the streams, only connected to a monitor so my non-tech-savy other half doesn't have to do anything but turn the monitor on. \n The question:\n Has anyone used thin-clients to achieve something similar? I don't think viewing the streams is that resource intensive, but I don't have any experience with thin-clients. Are they are powerful enough to view all the streams at the same time, whether on VLC locally, or viewing them on a webpage? I figured I would take a shot in the dark and ask before spending anything on this idea.\n Thank you for reading and considering my rambling\n    submitted by    /u/damiwork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqs9kj/looking_for_opinions_on_thinclient_rtsp_streaming/",
          "publishedOn": "2022-12-20T16:08:25.000Z",
          "wordCount": 16374,
          "title": "Looking for opinions on Thin-client / RTSP Streaming idea",
          "imageUrl": "https://external-preview.redd.it/ZQg-d3Rxfb5B3H_4d8OJMdgJJdRgzCwGkrySCJT0Bg8.jpg?auto=webp&s=97f5f0edbce2461088c47ccbbcd15496d191015d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqs2ub/power_usage_of_e52630l_v3_vs_e52620_v4_compared/",
          "author": null,
          "description": "I have seen people ask in the past about the power difference going from v3 to v4 processors, so I wanted to share my experience, your results may vary this is just what happened with my particular TrueNAS Scale server.\n For starters, it's a Dell T-7910 with 128GB of DDR4 ECC memory, 4x6TB WD Red's and 4x800GB Intel DC S3610 SSD's, a Quadro K2200 for the o/s and Quadro P600 video card passed thru to a vm and an Asus quad nvme card with 2 Samsung 1TB 970 evo's. Currently running TrueNAS Scale 22.02.4 with a few apps and a few vm's running game servers and plex, this is not idle power as my system is never truly idle.\n When it had dual E5-2630l v3 processors it averaged 23% cpu utilization as reported by TrueNAS and was pulling on average 165 watts as reported by a kill-a-watt\n With the dual E5-2620 v4 processors installed with the same apps and vm's running, TrueNAS reports 12% utilization and kill-a-watt is reporting 148 watts on average. \n I thought this would be a decent comparison since both of these models are 8 core 16 thread cpu's, however there is a small difference in clock speeds. 1.8 on the L version v3 and 2.1 on the v4. the L version also has a tdp of 55 watts where the v4 has a TDP of 85 watts. The v3 is a Haswell and the v4 is a Broadwell. \n These were averages over a 24 hour period of normal use, so all in all it saved only 17w doing the upgrade to the newer processors under my particular use case. These are approximations and not scientific by any means but just wanted to share my results.\n    submitted by    /u/Lab_IT_Guy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqs2ub/power_usage_of_e52630l_v3_vs_e52620_v4_compared/",
          "publishedOn": "2022-12-20T16:00:45.000Z",
          "wordCount": 15567,
          "title": "Power usage of E5-2630l v3 vs E5-2620 v4 compared in a Dell T-7910",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqr47i/my_first_homelab_setup/",
          "author": null,
          "description": "​\n https://preview.redd.it/09qgf0zmm27a1.jpg?width=2268&format=pjpg&auto=webp&s=1c5d7e0337ff98a56a8717e6ad5f4dc14d011a05\n    submitted by    /u/DaggerBomb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqr47i/my_first_homelab_setup/",
          "publishedOn": "2022-12-20T15:20:29.000Z",
          "wordCount": 14340,
          "title": "My first Homelab setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqk5pb/a_rack_accessory_for_all_the_smokers_out_there/",
          "author": null,
          "description": "submitted by    /u/B09DBWW92D  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqk5pb/a_rack_accessory_for_all_the_smokers_out_there/",
          "publishedOn": "2022-12-20T09:36:29.000Z",
          "wordCount": 16855,
          "title": "A rack accessory for all the smokers out there",
          "imageUrl": "https://preview.redd.it/uiwe5qlvd27a1.jpg?auto=webp&s=e92693859f22723d8f478faeb8fc0f3194c010d9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqezxu/my_very_old_school_setup_circa_2001_see_comments/",
          "author": null,
          "description": "submitted by    /u/skunkwoks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqezxu/my_very_old_school_setup_circa_2001_see_comments/",
          "publishedOn": "2022-12-20T05:00:29.000Z",
          "wordCount": 19775,
          "title": "My very old school setup (circa 2001), see comments for details",
          "imageUrl": "https://preview.redd.it/o0v3nh61jz6a1.jpg?auto=webp&s=81a852146d32fdda15c5db557e5ef302a12937ea"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqdlnu/3_dell_r710_short_rack_aquarium_filters_for_air/",
          "author": null,
          "description": "I wasn’t sure this would work but it is keeping the dust out pretty well. I cut some cheap aquarium filter material to size to fit under the faceplates. It gets pretty dusty without it. Thoughts?\n I was running ESXi 6 with vSphere 6 but switched to Azure Stack HCI when VMUG announced they were discontinuing everything before vSphere 7, which would have meant replacing 3 raid controllers and even then expecting no support.\n    submitted by    /u/Syroxieon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqdlnu/3_dell_r710_short_rack_aquarium_filters_for_air/",
          "publishedOn": "2022-12-20T03:55:39.000Z",
          "wordCount": 15053,
          "title": "3 Dell R710 short rack, aquarium filters for air intake in cool basement.",
          "imageUrl": "https://preview.redd.it/jf5e55d2p07a1.jpg?auto=webp&s=f56989fcdfa576a242ef92f15d27a46e73f498d8"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq8x6a/is_my_outlet_already_appropriate_for_240v/",
          "author": null,
          "description": "I have a server that I want to plug into my wall outlet in my loft. It says load with all drives occupied uses about 900W, there are two power supplies (one for failover). The input voltage needs to be 208 or 240 V AC. The plug that comes with the server is 3 prong type B.\n Do I need to get an electrician to change anything? The breaker for that outlet on my breaker box says 120/240v. Will it already provide 240v power to this outlet?\n Breaker\n https://imgur.com/KgZGuxs\n Plug\n https://imgur.com/FxxIcNm\n    submitted by    /u/Hot-Guest1275  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq8x6a/is_my_outlet_already_appropriate_for_240v/",
          "publishedOn": "2022-12-20T00:36:39.000Z",
          "wordCount": 14802,
          "title": "Is my outlet already appropriate for 240V?",
          "imageUrl": "https://external-preview.redd.it/zDpG6SyvT4nxKRsFgYLYM0cv6PAkGyEwenffeDZATlg.jpg?auto=webp&s=7a008dac5857231571e0080411a6ad1f9aa283e4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq81t5/got_this_switch_for_free_from_my_workplace_can_i/",
          "author": null,
          "description": "submitted by    /u/AsifBhai001  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq81t5/got_this_switch_for_free_from_my_workplace_can_i/",
          "publishedOn": "2022-12-20T00:01:47.000Z",
          "wordCount": 14316,
          "title": "Got this Switch for free from my Workplace. Can I use it on my home lab for practice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq7hhw/dual_4090_or_a6000_in_antec_p101/",
          "author": null,
          "description": "Any one manage to fit a 4090 or a600 in this case? According to the math I need to remove the middle 4 hdd trays.\n If you have a build a photo would be nice or even another suggestion. What I need is something that can accomdate dual 4090s and still have room for 8 HDDs\n    submitted by    /u/eagle6705  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq7hhw/dual_4090_or_a6000_in_antec_p101/",
          "publishedOn": "2022-12-19T23:39:08.000Z",
          "wordCount": 14234,
          "title": "Dual 4090 or A6000 in antec p101",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq69hq/how_do_i_get_these_drives_to_work_in_a_non_dell/",
          "author": null,
          "description": "submitted by    /u/Deepspacecow12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq69hq/how_do_i_get_these_drives_to_work_in_a_non_dell/",
          "publishedOn": "2022-12-19T22:51:34.000Z",
          "wordCount": 14494,
          "title": "How do I get these drives to work in a non dell server(x3650 m5)? I was told on r/computers that they use custom firmware. My m1215 raid controller says that they are unsupported and states them as \"unconfigured good\". Only thing I can di is \"prepare for removal\" in the imm",
          "imageUrl": "https://preview.redd.it/usftwqf0px6a1.jpg?auto=webp&s=f98be4d5120382e3fcb435b80164aba0cd8e5e5d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq55pk/so_my_mother_has_a_server_rack_now/",
          "author": null,
          "description": "submitted by    /u/wannabe_nerd2811  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq55pk/so_my_mother_has_a_server_rack_now/",
          "publishedOn": "2022-12-19T22:08:04.000Z",
          "wordCount": 15976,
          "title": "So... my mother has a server rack now!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq4r2x/cheap_affordable_server_rack_cases/",
          "author": null,
          "description": "Hi,\n I hope this type of post is not considered off-topic here. I have read the rules and I think my question is appropriate for this sub-reddit.\n First of all, this is my very first post in this subreddit 😄\n I have a question relating to server racks i.e. server rack cases specifically.\n I'm not in the position to afford expensive server computers that are rack mountable, and even if I could, it would be unreasonable for my use case.\n What I wanna do is \"migrate\" (I have some servers in a normal desktop tower case) my existing hardware into a setup that is rack-mountable.\n So, I wanna buy a rack cabinet (10\" or 19\" doesn't really matter to me) and put my \"cheap\" desktop gear into it.\n I have searched the internet for \"server rack cases\" and I've found some matches, but they're generally quite tall and bulky.\n There also seem to be cases that are rack-mountable, but they don't have any mount points for, like let's say, a motherboard.\n My existing servers all have an ATX sized motherboard, if possible I'd like to keep them.\n Are there cheap \"desktop\" (preferably slim) cases that are made to be mounted in a rack cabinet?\n (I know that \"desktop\" PC and \"rack mountable case\" are a bit mutually exclusive, why would a normal user want to have their PC in a rack :D)\n    submitted by    /u/moronwithinternet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq4r2x/cheap_affordable_server_rack_cases/",
          "publishedOn": "2022-12-19T21:52:54.000Z",
          "wordCount": 14626,
          "title": "Cheap / Affordable Server Rack Cases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq47kc/how_do_you_monitor_power_usage/",
          "author": null,
          "description": "I am looking to start doing power monitoring of my lab and I was wondering how you guys go about doing your lab power monitoring?\n    submitted by    /u/RockisLife  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq47kc/how_do_you_monitor_power_usage/",
          "publishedOn": "2022-12-19T21:32:02.000Z",
          "wordCount": 14400,
          "title": "How do you monitor power usage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq3o3j/new_virtual_install_cant_connect_to_the_network/",
          "author": null,
          "description": "submitted by    /u/cberm725  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq3o3j/new_virtual_install_cant_connect_to_the_network/",
          "publishedOn": "2022-12-19T21:10:50.000Z",
          "wordCount": 15263,
          "title": "New virtual install can't connect to the network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq0sn6/what_could_go_wrong/",
          "author": null,
          "description": "submitted by    /u/rynot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq0sn6/what_could_go_wrong/",
          "publishedOn": "2022-12-19T19:20:03.000Z",
          "wordCount": 14836,
          "title": "What could go wrong?",
          "imageUrl": "https://preview.redd.it/fus9hxt25y6a1.jpg?auto=webp&s=39635fe7407bfb33d69fdcb7a12793ddd6c243ad"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq0lmw/cabling_wall_to_rack/",
          "author": null,
          "description": "OK homelabbers, I'm looking for some advice. I have a wall-mounted cabinet terminating the Cat5 cable runs in the house. I now need to run fibre from the wall cabinet to a free-standing 19\" 27U rack. \n The rack is on wheels and needs to be moved about a bit in a tight space to replace equipment now and then, so some \"slack\" in the fibre is needed? \n Do I run the fibre along the floor and up into the rack? That seems to be asking for trouble. \n Do I try and dangle it from the ceiling into the rack on some hooks?\n Why don't they make fibre in old-school-curly-phone-handset style ;)\n    submitted by    /u/beerygaz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq0lmw/cabling_wall_to_rack/",
          "publishedOn": "2022-12-19T19:12:40.000Z",
          "wordCount": 14252,
          "title": "Cabling wall to rack",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq0a70/need_ideas_for_pc_upgrade_shelving_and_server/",
          "author": null,
          "description": "I am a beginner in Linux and homelab. Very beginner in web hosting. I have inherited a Windows 7 Gateway desktop PC: https://uk.pcmag.com/desktops/20161/gateway-dx4860-ub33p?specs\n I have loaded with Ubuntu 22.04 server and have been running Plex server and Foundry VTT via docker. Using SFTP / FileZilla for simple file storage. Also working to self host static site with Caddy and Porkbun. Having some learning trials getting things from local to public. \n I am wanting to reconfig a bit and need some suggestions. Some items I have been considering:\n  \nupdate RAM from 8gb to 16gb\n add additional SSD for boot drive and use full 1TB HDD as storage only\n TBD add external Nvidia GPU\n get a short floor case / shelving to house PC and boot drives\n TBD power backup (storm season in my area)\n  \nAny suggestions on SSD / Nvidia shelving combos? What other upgrades for this server have I not considered? Not looking to buy expensive NAS, routers, or racks at this time. (Moving in April so my setup is temporary-ish)\n Any advice as I reconfig my boot drive and migrate? I may be early enough that I could just start from scratch but prefer to learn migration process.\n I’m going to post a separate post on my hosting challenges lol.\n    submitted by    /u/unmyxtic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq0a70/need_ideas_for_pc_upgrade_shelving_and_server/",
          "publishedOn": "2022-12-19T19:00:38.000Z",
          "wordCount": 16738,
          "title": "Need Ideas for PC Upgrade, Shelving, and Server Migration",
          "imageUrl": "https://preview.redd.it/ujn5e09m1y6a1.jpg?auto=webp&s=33f0ea8f00bd3d5f99bf71964592c1a130a3ae02"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq07vb/what_are_cover_blank_caddy_fillers/",
          "author": null,
          "description": "Hi, I'm looking forward buying a used server. I found a Dell PowerEdge R320 for a good price.\n I'm not very familiar with server hardware, but as far as I understand I have to buy a Drive Caddy for each drive I'm going to use to keep them in place.\n I looked for caddies on the same website where the server is, and I found these: https://www.interbolt.eu/en/spd/009666/Dell-PowerEdge-SFF-2-5-Cover-Blank-Caddy-Filler-De\n They're way less expensive than these trays I found on the same website: https://www.interbolt.eu/en/spd/007596/Dell-PowerEdge-SFF-2-5-SAS-SATA-HDD-Hot-Swap-Tray\n Now my question is: are cover blank caddy fillers just something to cover empty drive slots? Is there a way to use them with a Hard Drive? If not, do I really have to buy the more expensive caddies?\n Thanks A LOT in advance!\n    submitted by    /u/DFalconD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq07vb/what_are_cover_blank_caddy_fillers/",
          "publishedOn": "2022-12-19T18:58:33.000Z",
          "wordCount": 14620,
          "title": "What are \"cover blank caddy fillers\"?",
          "imageUrl": "https://external-preview.redd.it/0YtuhbUqmMcWcICgeCqCpKPql0bhZUE6Tc-GngDYAgY.jpg?auto=webp&s=548ca7d6bec0a5b38cc7b404e82120a903e11d83"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq03ju/lab_build_rfc/",
          "author": null,
          "description": "Hi, Guys (and any Gals that are here).\n After a long hiatus due to work and personal issues, I'm back to building my first homelab.\n A quick recap: I'm building a moderate size physical cluster consisting of 9 m-ITX blades each with an i3-10105T, 32Gb DRAM and 512Gb NVME boot drive. Two of the blades have four 2.5\" hot swap bays in which I'll have a total of eight 2Tb SSDs.\n There are also two mini-PCs (Bee-link Gti11s that are i5-11s with 16Gb DRAM and 512Gb NVME boot drive). One of them will be a dedicated pfSense firewall (have to use the development build of pfSense 2.7 so it will recognize my i225 NICs) and the other will be running Ubuntu Desktop for an inside the lab management interface.\n When I say inside the lab, I want the everything from the pfSense FW down on its own IP range …",
          "link": "https://www.reddit.com/r/homelab/comments/zq03ju/lab_build_rfc/",
          "publishedOn": "2022-12-19T18:54:00.000Z",
          "wordCount": 14954,
          "title": "Lab Build RFC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq0291/home_nasserver_a_quick_check_before_i_bite_the/",
          "author": null,
          "description": "PCPartPicker Part List\n  \n Type Item Price \n  \n CPU Intel Core i5-12400 2.5 GHz 6-Core Processor $328.99 @ PB Technologies \n  CPU Cooler Deepcool AK400 66.47 CFM CPU Cooler $58.99 @ PB Technologies \n  Motherboard MSI PRO B660M-A WIFI DDR4 Micro ATX LGA1700 Motherboard $245.00 @ 1stWave Technologies \n  Memory Corsair Vengeance LPX 32 GB (2 x 16 GB) DDR4-3200 CL16 Memory $179.00 @ 1stWave Technologies \n  Storage Crucial BX500 1 TB 2.5\" Solid State Drive $98.99 @ PB Technologies \n  Storage Seagate BarraCuda 1 TB 3.5\" 7200 RPM Internal Hard Drive $65.00 @ Computer Lounge \n  Storage Seagate BarraCuda 1 TB 3.5\" 7200 RPM Internal Hard Drive $65.00 @ Computer Lounge \n  Storage Seagate IronWolf Pro 18 TB 3.5\" 7200 RPM Internal Hard Drive $589.95 @ Newegg New Zealand \n  Storage Seagate IronWolf Pro …",
          "link": "https://www.reddit.com/r/homelab/comments/zq0291/home_nasserver_a_quick_check_before_i_bite_the/",
          "publishedOn": "2022-12-19T18:52:34.000Z",
          "wordCount": 17936,
          "title": "Home NAS/Server - a quick check before I bite the bullet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpz8k7/will_this_hurt_anything_long_term/",
          "author": null,
          "description": "submitted by    /u/RickoT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpz8k7/will_this_hurt_anything_long_term/",
          "publishedOn": "2022-12-19T18:22:28.000Z",
          "wordCount": 15931,
          "title": "will this hurt anything long term?",
          "imageUrl": "https://preview.redd.it/mb3ztszsux6a1.jpg?auto=webp&s=0fb6ad5e5b7e0a427b9777b53e3413f641885148"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpy0qf/best_approach_for_ssl/",
          "author": null,
          "description": "Greetings,\n In my homelab, I have a synology NAS that has docker running on it with a bunch of containers. One of those containers is a NGINX reverse proxy. Currently, the various UIs for a number of containers, as well as for the synology itself, are running over http. It's all internal, so it's not the end of the world if it isn't https, but I'd like to fix it so that everything does use https. I've noticed in some cases that chrome assumes that sites are https and that things don't work as a result.\n The problem is, none of these things are exposed to the open internet (and I don't want to expose them), so it looks like Let's encrypt is out. Further complicating things, their hostnames are all configured to be subdomains of my main domain (which does have a website out there with a Let's Encrypt cert on it). What's the sanest approach here?\n 1) Do whatever shenanigans Let's Encrypt needs at the domain level to get a wildcard cert? What would I need to do to keep child domains updated in this case?\n 2) Make a self-signed certificate and trust it on all my devices. How hard will it be to keep NGINX updated with this cert?\n Just needing a bit of guidance here, because when I've dealt with certs, it has either been in a production web environment with a \"real\" certificate authority or it has been Let's Encrypt provided by a webhost. Not sure what to do in a homelab.\n    submitted by    /u/williamwgant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpy0qf/best_approach_for_ssl/",
          "publishedOn": "2022-12-19T17:38:02.000Z",
          "wordCount": 16374,
          "title": "Best approach for SSL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpx2bx/suggestions_to_replace_my_cherry_g844400_usb/",
          "author": null,
          "description": "I kept a Cherry G84-4400 (USB version) keyboard in my 'head tote' with an LCD panel, power strip, and odds and ends for when a headless box needs direct attention.\n Eventually the cord went bad and the Cherry got recycled. I'd like to get another, but $80+ is a bit steep for very occasional use.\n Perix has a couple trackball and touchpad keyboards - any thoughts on those, or other options in the sub US$50 price range?\n    submitted by    /u/ggibby  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpx2bx/suggestions_to_replace_my_cherry_g844400_usb/",
          "publishedOn": "2022-12-19T17:02:49.000Z",
          "wordCount": 15205,
          "title": "Suggestions to replace my Cherry G84-4400 USB keyboard with integrated trackball?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpvw8j/unifiopenvpndell_poweredgeproxmoxtruenasrsyncplex/",
          "author": null,
          "description": "The last 6 or so months (through a busy summer and sick kids) I've been working my way through creating creating my own off-site backup at my dad's house. Cause if one home lab is good then 2 is definitely better! I deployed it a few days ago and everything is operational which was a huge validation to a lot of \"I'm pretty sure I can do this\" a long the way. \n  \nHome Site: \n UDMP\n UNVR-Pro\n RPS\n Dell PowerEdge T440 - Proxmox \n TrueNAS\n 2x PiHole\n Plex\n Home Assistant\n Docker Portianer\n \n 2x UPS\n \n Remote Site \n UDMP-SE\n Dell PowerEdge T320 - Proxmox (with X-windows for local GUI access to VMs if needed) \n TreuNAS\n 2x PiHole\n Plex (Because why not have a Plex Mirror)\n \n 2x UPS\n \n  \nBoth routers are setup with NoIP DDNS service and since I'm dealing with URLs I used OpenVPN to link them. Eac…",
          "link": "https://www.reddit.com/r/homelab/comments/zpvw8j/unifiopenvpndell_poweredgeproxmoxtruenasrsyncplex/",
          "publishedOn": "2022-12-19T16:19:12.000Z",
          "wordCount": 15841,
          "title": "Unifi-OpenVPN-Dell PowerEdge-Proxmox-TrueNAS-Rsync-Plex and a Partridge in a Pear Tree",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zptkaz/my_mini_homelab_in_a_typical_dutch_fuse_box/",
          "author": null,
          "description": "submitted by    /u/liamhildebrand  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zptkaz/my_mini_homelab_in_a_typical_dutch_fuse_box/",
          "publishedOn": "2022-12-19T14:49:21.000Z",
          "wordCount": 15288,
          "title": "My mini homelab, in a typical dutch fuse box ;)",
          "imageUrl": "https://preview.redd.it/yuwyx05ssw6a1.jpg?auto=webp&s=d652c6578514f11e77da5b9c9f656772c946e5fb"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpsgfv/silencing_a_dell_powerconnect_7024/",
          "author": null,
          "description": "submitted by    /u/lucaci32u4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpsgfv/silencing_a_dell_powerconnect_7024/",
          "publishedOn": "2022-12-19T14:04:38.000Z",
          "wordCount": 15014,
          "title": "Silencing a Dell PowerConnect 7024",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpmvjc/any_help/",
          "author": null,
          "description": "Got my hands on an old Dell EMC CX4-120 storage system connected to the maintenance network but requires password to login which I can’t find and need to reset have tried google but with no luck any suggestions\n    submitted by    /u/Acceptable-Resist-79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpmvjc/any_help/",
          "publishedOn": "2022-12-19T09:18:07.000Z",
          "wordCount": 16459,
          "title": "Any Help",
          "imageUrl": "https://preview.redd.it/61xdeaho5v6a1.jpg?auto=webp&s=2e674ba597c293677a8a70e7c34aa1438cca51d5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpl0zz/does_this_count_lol_opnsense_mini_pc_and_my_first/",
          "author": null,
          "description": "submitted by    /u/tharussianbear  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpl0zz/does_this_count_lol_opnsense_mini_pc_and_my_first/",
          "publishedOn": "2022-12-19T07:21:53.000Z",
          "wordCount": 16500,
          "title": "Does this count? Lol opnsense mini pc and my first switch!",
          "imageUrl": "https://preview.redd.it/ixl2jd2yku6a1.jpg?auto=webp&s=920de47a4965ee481528555e6ec37b8c47f22fa5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpikcv/psa_avoid_sfp_10gbs_connectors_model_ftlx8571d3bcv/",
          "author": null,
          "description": "TLDR: get FTLX8571D3BNL instead of FTLX8571D3BCV SFP+ Transceivers if you don't want to hate your life\n I got some Intel FTLX8571D3BCV-IT SFP+ connectors for my 10gbs fiber homelab setup. I wasted a week trying to get them to work.\n Despite them being listed as 1gbs/10gbs compatible connector, they were never able to actually connect at 10gbs. ethtool even showed supported modes as 10000baseCR/Full and 10000baseSR/Full, but that's a load of BS.\n I compiled the intel ixgbe driver by hand and it still didn't help. Confirmed fiber cables and switch were known good by swapping out parts - it is definitely the FTLX8571D3BCV connectors being dumb.\n After checking online, seems this is a known issue. Want to spread the word here on reddit as well so that no one else gets bit by this buggy hardware.\n    submitted by    /u/vaniaspeedy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpikcv/psa_avoid_sfp_10gbs_connectors_model_ftlx8571d3bcv/",
          "publishedOn": "2022-12-19T05:04:13.000Z",
          "wordCount": 17145,
          "title": "PSA: Avoid SFP 10gbs Connectors model FTLX8571D3BCV",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpduha/can_tripp_lite_ps7192_su1500rtxl2ua_have_extended/",
          "author": null,
          "description": "Could the Tripp Lite SU1500RTXL2UA be wired up with additional batteries to extend the run time without using the Tripp Lite BP48V24-2U battery extender chassis?\n I could certainly try wiring the extra batteries up to the internal pack but it would likely be really ugly as I might have to drill a hole somewhere in the chassis or leave the front panel off.\n    submitted by    /u/CharacterLock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpduha/can_tripp_lite_ps7192_su1500rtxl2ua_have_extended/",
          "publishedOn": "2022-12-19T01:11:39.000Z",
          "wordCount": 14147,
          "title": "Can Tripp Lite PS7192 (SU1500RTXL2UA) have extended batteries without the BP48V24-2U chassis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpdtz2/selfhosted_solution_like_hdhomerun/",
          "author": null,
          "description": "Hi,\n So, like the title says, I would be looking for a self-hostable solution to replace a box like HDHomeRun.\n Basically the idea would be to have a USB or PCIE card adapter to be able to use a TV antenna on my server and basically get the live TV channels it gets and then use them in Plex directly as a DVR exactly as I would with hdhomerun. \n Currently, I am using xteve for iptv, but I'd like to be able to use a TV antenna, but I don't want to buy a proprietary box like the hdhomerun one.\n Is there a solution that exist out there that anyone knows of? And would it be viable compared to a premade solution? \n Thanks in advance for any suggestion, and don't hesitate if I'm missing details.\n    submitted by    /u/jeremyy44  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpdtz2/selfhosted_solution_like_hdhomerun/",
          "publishedOn": "2022-12-19T01:10:59.000Z",
          "wordCount": 14350,
          "title": "Self-hosted solution like HDHomeRun",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpdkhj/dell_r620_pcie_netowrk_card/",
          "author": null,
          "description": "I recently bought a R620, my first rack mount server purchase. It came with a 4-port Broadcom network card but I wanted to add some more ports just for fun and to experiment with Proxmox.\n It is an Intel 4-port PCI-E card I pulled from a Dell Optiplex 7040 desktop where it worked fine.\n When I boot the server it seems to initialize, it shows up in the system inventory, but not in the hardware network devices. When I plug a cable into it I get nothing.\n I tried digging around the Life Cycle Controller thinking maybe it had to be manually enabled but didn't see anything that jumped out at me. It is installed currently in PCI-E slot 1, but I have tried the others as well.\n Oddly, Proxmox sees the card (though I have not made use of it there, yet). Is there anything I need to do to get it to show up within the server itself (iDrac web interface, LCC, etc.) or is this just normal?\n    submitted by    /u/StormStrikes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpdkhj/dell_r620_pcie_netowrk_card/",
          "publishedOn": "2022-12-19T00:58:35.000Z",
          "wordCount": 14327,
          "title": "Dell R620 PCI-E Netowrk Card",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpdek6/how_things_begin_excited_to_go_from_lurker_to/",
          "author": null,
          "description": "submitted by    /u/gusontherun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpdek6/how_things_begin_excited_to_go_from_lurker_to/",
          "publishedOn": "2022-12-19T00:50:29.000Z",
          "wordCount": 14302,
          "title": "How things begin! Excited to go from lurker to homelab beginner!",
          "imageUrl": "https://preview.redd.it/qqigzvza5r6a1.jpg?auto=webp&s=a5506f9742399f4c9ea50fd33d1df9ec0cfb879b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpd9i3/anyone_running_oracle_or_mssql_in_your_lab/",
          "author": null,
          "description": "So one of the things I'm doing in my lab is maintaining a practice and development environment for multiple languages and frameworks, such as Python, PHP, and even *shudders* Ruby, crossed with various Databases, such as PostgreSQL, MariaDB, MongoDB, and other tools like rabbitmq, mqtt, and memcached and redis. So I'm thinking about expanding the database assortment into the 'commercial' realm of applications, so I'm looking at setting up an MS server with IIAS and .NET for web development, and databi for both OracleSQL and MSSQL. But licensing. Does anybody have any practical experience running these in the home lab? Do MS and Oracle make these available under home, lab, or student licenses for free or reduced cost? I couldn't even find a \"Buy it now\" purchase link on Oracle's website, and I'm trudging through their XE process now and finding that the generous '2GB in Memory' limit they place may not be as generous as I thought, since on a stock empty install it's already using over 1.5GB. So how do you license your MSSQL and OracleSQL in your home lab?\n    submitted by    /u/AsYouAnswered  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpd9i3/anyone_running_oracle_or_mssql_in_your_lab/",
          "publishedOn": "2022-12-19T00:43:40.000Z",
          "wordCount": 16209,
          "title": "Anyone running Oracle or MSSQL in your lab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpai9n/help_with_wd_8tb_nas_drive_not_showing_up_in_linux/",
          "author": null,
          "description": "Hello,\n ​\n I am new here and posting as someone from TrueNAS forum suggested I ask for advice here.\n My plan was to use 3 WD 8 TB Red Plus HDD's with TrueNAS Scale. (https://www.bhphotovideo.com/c/product/1731377-REG/wd_wdbc9v0080hh1_wrsn_8tb_red_plus_cmr.html)\n The rest of the hardware is (an old gaming pc):\n msi x79a-gd45 plus (has 6 SATA Slots)\n i7-4930K\n 250GB SSD\n 16 GB RAM\n I could not get the HDD's to show up with that machine and I used TrueNAS Scale and Ubuntu on flash drive. I then tried attaching the HDD's one at a time to a WIN10 machine and still couldn't get them to show up. \n The only way it would show up is in BIOS.\n Then I ordered an external HDD Hub that I plugged into the PC. It showed up and I ran some Linux commands from the TrueNAS Forum recommendations. \n Please see …",
          "link": "https://www.reddit.com/r/homelab/comments/zpai9n/help_with_wd_8tb_nas_drive_not_showing_up_in_linux/",
          "publishedOn": "2022-12-18T22:38:26.000Z",
          "wordCount": 14915,
          "title": "Help with WD 8TB NAS Drive not showing up in Linux",
          "imageUrl": "https://external-preview.redd.it/vWgwg6OS3aoeZDK2xXf6Tfox6WpY-GDoa5xn3Zh9qno.jpg?auto=webp&s=56503d6252338f39a94ca245db651fc383252afe"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpahzn/bought_a_new_case_have_questions_about_sas_hookup/",
          "author": null,
          "description": "Hey I recently bought a supermicro 36 bay server. A 847E16-R1400LPB if it matters. And had a question about the sas cables.\n https://imgur.com/a/1Fp9nfm\n From what I can see there's 4 hookups for the front backplane, and 8 on the rear with only 4 hooked up. With 4 free ports. And only 4 cables to plug into a raid card.\n From what I can tell it looks like two of the front backplane cables goes to the rear backplane, with only two from each free to plug into a raid card.\n I'm coming from a r710 so I'm still a bit of a newbie here. So just want to know if it's all good. I need to get new cables anyhow, as my gear is 8087. So I'll need to buy new cables. Just need to see if I need 4, 8, 12, or what's up.\n Thanks for any and all help!\n    submitted by    /u/Happy-Firefighter-30  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpahzn/bought_a_new_case_have_questions_about_sas_hookup/",
          "publishedOn": "2022-12-18T22:38:05.000Z",
          "wordCount": 15325,
          "title": "Bought a new case, have questions about sas hookup.",
          "imageUrl": "https://external-preview.redd.it/wVKw0Dzy-YJasjUbOyCtSMrX-gY8BVKWD8TOEZDJNNM.jpg?auto=webp&s=8909fa4f45a0a23e7c4cf4fe9ac78480bc3433c1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpahcp/any_problem_with_using_external_25in_hdds_in_a_nas/",
          "author": null,
          "description": "I've been doing back and forth on whether or not I should move away from my current NAS solution that is simply just 2x external HDDs connected to a Lenovo SFF (m710q). It is plenty powerful for my few tasks, but I am not super stoked about having to use external drives, since there is obviously no room for internal upgrades. I only need two drives, as I don't need a whole ton of capacity, but like having the failsafe in case of a drive failure. Currently, I am just using robocopy script to copy any changes made on one drive to the other via a scheduled task but have been tinkering with TrueNAS as a more professional solution with less overhead than windows.\n So, my question: is there any inherent downside to using external HDD enclosures and 2.5in drives in a NAS? Obviously, they are slightly more expensive, but less expensive than building a new machine to do the same tasks...\n    submitted by    /u/Gusmanbro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpahcp/any_problem_with_using_external_25in_hdds_in_a_nas/",
          "publishedOn": "2022-12-18T22:37:14.000Z",
          "wordCount": 15563,
          "title": "Any problem with using external 2.5in HDDs in a NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp9hln/ip_kvm_questions/",
          "author": null,
          "description": "Before I head to the questions, here is what I think that I know so far:\n  \nThe setup - 9 machines in two areas of the house that I would like to be able to manage from a single chair, USB keyboard and mouse, 1920x1200 monitor.\n \nMachines have disparate video connections, so I know I will need adapters from HDMI/DP/VGA to whatever the KVM is using. \n \nI know I should be using IPMI when possible, but only 3 of the 9 machines have this capability.\n \nI understand I can run a remotely switchable KVM into a PiKVM or TinyKVM as an option, and I am looking into that as well, but not really seeing cost savings here with a KVM for each room plus the box.\n \nI would like to do IP KVM rather than RDP or other remote access, as I would like to be able to deal with everything from the BIOS up, and also …",
          "link": "https://www.reddit.com/r/homelab/comments/zp9hln/ip_kvm_questions/",
          "publishedOn": "2022-12-18T21:53:12.000Z",
          "wordCount": 17282,
          "title": "IP KVM Questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp8wwc/gsa_server/",
          "author": null,
          "description": "So, a few weeks ago, I purchased 3 Google Search Application servers. They are just branded Dell servers. 1 is an r710, 1 is a r720xd, and the last is a r730xd. The 710 and 720 boot right into the bios. The 730, on the other hand, boots into a password protected bios. I have tried resetting the cmos and jumping the pins. And none of the instructions on the Google are working either. Does anybody have any ideas. I figure I'm just going to have to replace the motherboard.\n    submitted by    /u/kbhutson868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp8wwc/gsa_server/",
          "publishedOn": "2022-12-18T21:28:09.000Z",
          "wordCount": 14163,
          "title": "GSA Server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp8ina/goodbye_old_friend/",
          "author": null,
          "description": "Bought two identical Hitachi drives in July 2011 for RAID 1 setup.\n After almost 100k hours, one of them showed bad sectors:\n 1989 bad sectors, pulled out to see, if can be salvaged\n other one is still going strong, so far:\n fingers crossed for 100k hours\n    submitted by    /u/_WreakingHavok_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp8ina/goodbye_old_friend/",
          "publishedOn": "2022-12-18T21:10:58.000Z",
          "wordCount": 14655,
          "title": "goodbye old friend",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp8fgp/how_come_i_dont_see_many_people_using_hyperv/",
          "author": null,
          "description": "submitted by    /u/Cody_Cal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp8fgp/how_come_i_dont_see_many_people_using_hyperv/",
          "publishedOn": "2022-12-18T21:07:06.000Z",
          "wordCount": 15536,
          "title": "How come I don’t see many people using Hyper-V server with Windows Admin Center which are both free and enterprise grade? Tried proxmox and it’s quite lackluster in comparison. Hyper-V and WAC you name it, it does it at Enterprise level and no you don’t need a AD domain.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp75ej/this_thing_is_starting_to_get_out_of_hand/",
          "author": null,
          "description": "submitted by    /u/InvisibleCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp75ej/this_thing_is_starting_to_get_out_of_hand/",
          "publishedOn": "2022-12-18T20:11:34.000Z",
          "wordCount": 15120,
          "title": "This thing is starting to get out of hand...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp735z/virtualizing_opnsense_getting_a_wan_and_lan_ip/",
          "author": null,
          "description": "Optiplex 5060 w/ i7-8700, 32gb RAM, 1x i340-T2 for OPNSense specifically, 1x HBA LSI card to passthrough drives to TrueNAS. Proxmox is installed on the bare metal. The purpose of OPNSense is to have my set up like this: BGW210 -> OPNSense -> TL-SG2008P Switch (for wired devices) -> EAP 225 AP (for wireless devices).\n This is also how I have it mapped out: https://drive.google.com/file/d/19dzpxdCUSIhxP3qEwpXexkBlIll7E1Z0/view?usp=sharing\n I recently taken an interest in homelabbing and my latest endeavor is trying to virtualize OPNSense in Proxmox for VLAN features as my current AT&T Uverse BGW210 box doesn't support it. Also, I am forced to use Uverse in order to get internet, I cannot replace it.\n I have been following TechnoTims video on how to do this. It is pfSense but the tutorial sho…",
          "link": "https://www.reddit.com/r/homelab/comments/zp735z/virtualizing_opnsense_getting_a_wan_and_lan_ip/",
          "publishedOn": "2022-12-18T20:08:58.000Z",
          "wordCount": 19234,
          "title": "Virtualizing OPNSense, getting a WAN and LAN IP, but not only unable to access the WebGUI, but I can't get access to Internet through the switch either.",
          "imageUrl": "https://external-preview.redd.it/37ZTvwrMcJF_eLUbOGgs939jnCe73OY4yY9z7LtxxTQ.jpg?auto=webp&s=6da78299ea3c3cd17f6e9b2147a3d441fb8667de"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp552q/ups_hunting/",
          "author": null,
          "description": "I have needed a UPSS for a while but I keep putting it off due to cost, features, lifespan, support, etc. but maybe you can recommend something that meets the criteria I have? \n Features required to make it \"the one for me\":\n  \nNetwork interface for SNMP/alerts/monitoring/etc.\n Battery replacement for when the day comes\n 1 or 2U rack mountable\n  \nPower requirements (what will it run during a power outage):\n  \n1 PA-440 firewall\n 1 Unifi 48 port POE switch\n 1 Arris SB6190 modem (do not care if this gracefully shuts down but needed for any alerts)\n 2 ESX servers running on old low power Dell OptiPlex hardware\n 1 NAS server also running on old low power OptiPlex hardware\n  \nA huge concern I have is that power will go out in the middle of the night so it would be nice to have the UPS be smart enough to trigger some sort of API calls or scripted shutdowns but at the very least send some sort of alert to my phone to wake me up for manual shut downs. If the hardware itself sounds an alarm there is no way I will hear it from 3 floors up while sleeping. Am I just dreaming a perfect UPS or does something exist that can do \"all the things\"?\n    submitted by    /u/orthonovum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp552q/ups_hunting/",
          "publishedOn": "2022-12-18T18:42:23.000Z",
          "wordCount": 14664,
          "title": "UPS Hunting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp3h58/new_a_better_plex_exporter_for_prometheus/",
          "author": null,
          "description": "There are a few Plex exporters out there to track metrics in Prometheus but they have some deficiencies: not differentiating between playing, paused, buffering streams, audio vs. video transcoding, tracking media downloads, and more.\n I decided to roll my own exporter to address these and have been running it in production for a few weeks. Please give it a try if this sounds like something that would improve your Plex dashboards — pull requests are welcome (Ruby)!\n https://github.com/axsuul/plex-media-server-exporter\n    submitted by    /u/Axsuul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp3h58/new_a_better_plex_exporter_for_prometheus/",
          "publishedOn": "2022-12-18T17:22:00.000Z",
          "wordCount": 14554,
          "title": "New: A better Plex exporter for Prometheus",
          "imageUrl": "https://external-preview.redd.it/jCn6IAeoLCOLlc9-4gUlDz5_0TPW3-X69CfPATeo0Pc.jpg?auto=webp&s=368191378aa0f4d55b4169d201c203c40c4d70df"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp1dvb/hard_drive_write_noise/",
          "author": null,
          "description": "I just recently got new 18tb seagate drives. When writing data it’s seems like there’s quite a bit of noise coming from the drive head. I just want to be sure that this noise is either expected or that there is an in fact an issue with the drives here.\n Link to drives: https://www.newegg.com/seagate-exos-x18-st18000nm000j-18tb/p/1B4-00VK-00616?item=1B4-00VK-00616\n Thank you!\n    submitted by    /u/RedditGuru-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp1dvb/hard_drive_write_noise/",
          "publishedOn": "2022-12-18T15:43:38.000Z",
          "wordCount": 15111,
          "title": "Hard drive write noise",
          "imageUrl": "https://external-preview.redd.it/FdDABZFnEgJyNVZ8Ifi08oPJVT9jL8Z_3gSmkC-K5do.png?format=pjpg&auto=webp&s=3ba29b643604c20e56a89d2981c49967a2bf291e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp13dg/help_me_decide_on_first_homelab/",
          "author": null,
          "description": "submitted by    /u/Auburnfan96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp13dg/help_me_decide_on_first_homelab/",
          "publishedOn": "2022-12-18T15:29:31.000Z",
          "wordCount": 16303,
          "title": "Help Me Decide on First homelab",
          "imageUrl": "https://preview.redd.it/md4m01e1vp6a1.png?auto=webp&s=e0222e37c2e869c9b879f24959ebdac38a6f6aa4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zozjq8/homelab_internet_failover_using_an_old_phone/",
          "author": null,
          "description": "submitted by    /u/mrln_bllmnn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zozjq8/homelab_internet_failover_using_an_old_phone/",
          "publishedOn": "2022-12-18T14:13:56.000Z",
          "wordCount": 16295,
          "title": "Homelab Internet Failover using an old phone (OPNsense)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zoue4p/whats_the_best_method_of_rust_removal_from_zinc/",
          "author": null,
          "description": "I've got a Chenbro RM31300 server case but it has some rust spots on it. Normally I would gently sand back, use rust converter and then spray with a zinc paint. \n Are there any better methods to do this in 2022?\n    submitted by    /u/kester76a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zoue4p/whats_the_best_method_of_rust_removal_from_zinc/",
          "publishedOn": "2022-12-18T09:05:12.000Z",
          "wordCount": 15725,
          "title": "Whats the best method of rust removal from zinc server case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zotxzo/macos_content_caching_server_can_old_macos_serve/",
          "author": null,
          "description": "I'm trying to set up a system to host copies of macOS updates locally, so that when a device needs it it will download locally instead of from Apple's servers each time (for download speed reasons, I often have several machines that need the same update). I'm aware Apple's Content Caching feature is meant to do exactly this, but does it have version limitations? As in, can a system running macOS Catalina 10.15.7 store and host updates for macOS 11/12/13? What about for older versions, like 10.11 or 10.13? Does the server OS losing security update support mean it won't be able to fetch updates for peer machines on newer OSes either? Thanks in advance!\n    submitted by    /u/vinaypundith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zotxzo/macos_content_caching_server_can_old_macos_serve/",
          "publishedOn": "2022-12-18T08:35:35.000Z",
          "wordCount": 14734,
          "title": "macOS Content Caching server - can old macOS serve new updates?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zor3dq/i_know_the_cables_could_use_work_but_im_really/",
          "author": null,
          "description": "submitted by    /u/SamPlaysKeys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zor3dq/i_know_the_cables_could_use_work_but_im_really/",
          "publishedOn": "2022-12-18T05:34:11.000Z",
          "wordCount": 15897,
          "title": "I know the cables could use work, but I'm really proud! (details below)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zom6jw/newbie_advice/",
          "author": null,
          "description": "I am new to the subreddit, and new to doing any substantial work involving computers in general. I apologize if I don't express my goals properly / go over something that has already been covered.\n ​\n Bit of a background on me: I hate subscription services. Whether I am paying monthly to watch movies/ tv shows, listen to music, play video games, or even just store data on someone else's computer (\"cloud\"), I hate it. At this point, I would rather spend exponentially more than I ever would for the subscriptions if it means I get to build/own it. Having said that, I don't really have a specific budget in mind, but I am okay with this being a costly venture that takes a couple of years to perfect.\n ​\n These are the things that I want to be able to do with my homelab:\n - NAS\n - Media Server (P…",
          "link": "https://www.reddit.com/r/homelab/comments/zom6jw/newbie_advice/",
          "publishedOn": "2022-12-18T01:16:54.000Z",
          "wordCount": 14947,
          "title": "Newbie Advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zol9hq/local_rdp_alternatives_with_robust_resolution/",
          "author": null,
          "description": "Hello. I have a home lab where I have my main desktop connected to 2 massive 49 inch displays (1 on top of the other) and several servers connected over the local network. \n ​\n Up until now I controlled those servers over windows RDP however now that I have these new screens I want to have finer control over the resolution so I can scale it by clicking and dragging the corner like I would any other window. I tried NoMachine but for some reason that I can't figure out, NoMachine is bugging out on my win server 2019 system (the main server) greying out the \"share screen\" option. I don't need external access I just want something that is locally hosted and is better than the garbage built-in RDP (and free)\n ​\n Any suggestions. Thanks\n    submitted by    /u/NepNep_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zol9hq/local_rdp_alternatives_with_robust_resolution/",
          "publishedOn": "2022-12-18T00:37:29.000Z",
          "wordCount": 14159,
          "title": "Local RDP Alternatives With Robust Resolution Options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zol1ro/installing_a_nvidia_tesla_m10_in_a_dell_r730xd/",
          "author": null,
          "description": "So I'm getting a Nvidia Tesla M10, planning to add it to my Dell R730XD in Riser 2. \n Looking everywhere for the proper cable I cannot find the correct cable... Can someone potentially link me a verified one that won't end up frying the GPU? or a model number... \n Thank You!\n    submitted by    /u/Hexers  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zol1ro/installing_a_nvidia_tesla_m10_in_a_dell_r730xd/",
          "publishedOn": "2022-12-18T00:29:17.000Z",
          "wordCount": 14089,
          "title": "Installing a Nvidia Tesla M10 in a Dell R730XD; need assistance with correct cable.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zojyr5/please_help/",
          "author": null,
          "description": "I have read through all the intro stuff but can’t find just a simple list of what I need for a physical lab set up like computers, routers, switches, etc. I just want something basic to set up with physical devices to dip my toes in to learn with something.\n    submitted by    /u/Sea-Zookeepergame584  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zojyr5/please_help/",
          "publishedOn": "2022-12-17T23:46:29.000Z",
          "wordCount": 14325,
          "title": "Please help.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zojo1t/30_network_drops_how_do_i_make_the_install_look/",
          "author": null,
          "description": "I am in the process of hardwiring all of the tvs; apple tvs; gaming systems and computers. All told, I will have about 30 to 35 drops. \n I have about 10 already completed and have been using a 4 port wall plate at the rack but I don't think I will like the way it looks when I have to have 9 4 port wall ports. What have others done?\n edit prior to the patch panel. I want the cables coming out of the wall to look clean.\n    submitted by    /u/bucket46  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zojo1t/30_network_drops_how_do_i_make_the_install_look/",
          "publishedOn": "2022-12-17T23:34:00.000Z",
          "wordCount": 14398,
          "title": "30 network drops, how do I make the install look clean in my house?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zojmt4/hi_guys_would_love_some_ideas_on_a_homelab/",
          "author": null,
          "description": "I currently wanted to have a home-lab setup on my resume as I am a cyber security student\n I own a RPI-4 I was planning on setting up a hybird setup containing VMs and my PI\n I was going to use ansible to deploy my infastructure\n I plan on creating a DNS-Server (LINUX), SMB server (LINUX), DHCP server (RPI) , I would love some more ideas maybe AD server etc.\n    submitted by    /u/Tilted_Towers33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zojmt4/hi_guys_would_love_some_ideas_on_a_homelab/",
          "publishedOn": "2022-12-17T23:32:33.000Z",
          "wordCount": 14372,
          "title": "Hi guys would love some ideas on a home-lab ,",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zoi0xe/dell_r620_ssd_compatibility/",
          "author": null,
          "description": "I have an r620 with h310 raid controller and I'm having trouble finding compatible ssd's. So far nearly everything I have laying around shows a \"fault detected on drive\" error - even on new drives. The only ones I've found so far that work are teamgroup vulcan g (not z).\n Anyone know of any others that work? Would I have better luck with a different raid controller?\n Edit: Updating to solved. Looks like samsung evo ssds are the way to go - and an update to the h710 or h710p to improve performance. Thanks for the help guys!\n    submitted by    /u/whimsical-wizardry  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zoi0xe/dell_r620_ssd_compatibility/",
          "publishedOn": "2022-12-17T22:22:06.000Z",
          "wordCount": 14357,
          "title": "Dell R620 SSD Compatibility?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zogg9n/how_high_is_your_internet_traffic_per_month/",
          "author": null,
          "description": "submitted by    /u/_c0der  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zogg9n/how_high_is_your_internet_traffic_per_month/",
          "publishedOn": "2022-12-17T21:15:23.000Z",
          "wordCount": 15003,
          "title": "How high is your internet traffic per month?",
          "imageUrl": "https://preview.redd.it/vxb8toq0yi6a1.png?auto=webp&s=0322723bd1b578131dc108df859094705e43f9ad"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zog6n4/the_suitcase_server_project/",
          "author": null,
          "description": "I've been looking for a performant server that can stack 8-16 SSDs, run a handful of VM's, and connect at 10+gbps while fitting in a suitcase. I've got a plan now and want to see if anyone has any feedback before I place the orders.\n  \nCase: PLink IPC-2022M (would remove the 3.5 HDD trays for more room)\n Mobo: AsRock Rack X570D4U\n CPU: AMD Ryzen 9 5950X\n CPU Cooler: Dynatron A24\n RAM: 4x Crucial 32GB DDR4 3200MHz CT32G4DFD832A \n PSU: Seasonic Prime PX-750\n HBA: LSI 9305-16i Low Profile\n NIC: Mellanox MCX314A-BCCT (have 40gbe at home, can adapt to SFP+ as needed)\n Storage: 2x NVMe for boot and VM storage. 1 or 2 ICYDOCK MB998IP-B filled with 8TB Samsung QVO SSDs. \n OS: Proxmox with linux/windows VMs\n  \nAny and all feedback is welcome!\n    submitted by    /u/certifiedintelligent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zog6n4/the_suitcase_server_project/",
          "publishedOn": "2022-12-17T21:04:08.000Z",
          "wordCount": 14206,
          "title": "The suitcase server project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zofoej/new_used_poweredge_r730xd_bootingdisplay_issue/",
          "author": null,
          "description": "I have a VGA to HDMI cord plugged into the front port of the server and a cat5e cable plugged into the idrac port on the back of the server.\n I seem to be unable to have it show up in my router for an ip address or display onto a monitor for bios or anything. Am I missing something super obvious? The activity light on the front is blue which seems to indicate that the server is fine.\n Thanks for any help you can provide.\n    submitted by    /u/CrazyPsychic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zofoej/new_used_poweredge_r730xd_bootingdisplay_issue/",
          "publishedOn": "2022-12-17T20:42:02.000Z",
          "wordCount": 15598,
          "title": "New (Used) Poweredge R730xd Booting/Display Issue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zofn7q/my_beginner_level_homelab/",
          "author": null,
          "description": "submitted by    /u/chrisraydj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zofn7q/my_beginner_level_homelab/",
          "publishedOn": "2022-12-17T20:40:36.000Z",
          "wordCount": 14679,
          "title": "My beginner level homelab",
          "imageUrl": "https://preview.redd.it/fgawot32si6a1.jpg?auto=webp&s=e9f12f7b8853adb34e9077af993ac51887302696"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zofgrp/what_the_best_and_cheapest_10_gbe_switch_from_ebay/",
          "author": null,
          "description": "submitted by    /u/AdslModem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zofgrp/what_the_best_and_cheapest_10_gbe_switch_from_ebay/",
          "publishedOn": "2022-12-17T20:32:48.000Z",
          "wordCount": 14155,
          "title": "What the best and cheapest 10 Gbe switch from Ebay?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zof81x/gpu_options/",
          "author": null,
          "description": "submitted by    /u/BadCoNZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zof81x/gpu_options/",
          "publishedOn": "2022-12-17T20:22:25.000Z",
          "wordCount": 14189,
          "title": "GPU Options?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zoe9qa/proxmox_hosting_pfsense_how_to_update/",
          "author": null,
          "description": "HI all, I'm trying to figure out how to get PVE to stay updated while hosting my router. I've got pfSense running as my main home firewall, virtualized in Proxmox, running on one of those Topton N5015 4-interface boxes. NICs are used as follows:\n  \nWAN (PCI passthrough, to cable modem)\n LAN (PCI passthrough, pfSense at 192.168.1.1)\n (unused)\n Proxmox management (192.160.0.100)\n  \nThe interaction with Proxmox here is kind of clunky. I don't have a management network or anything, so if I want to log into the PVE on this one, I have to go down into the basement where this thing lives, and directly plug in an a cable, and set a static IP and finally connect. That's clunky but workable. The real issue is that PVE can't see the internet, and therefore can't get updates or anything. And if I want to run other services on PVE here, they don't run on my LAN network, and they can't see the internet either.\n The real issue to solve is getting updates for PVE. Any tips on how to do that? It seems like I could use NIC 3 to connect into the LAN - and connect to the internet in a sort of Inception-style labyrinth. Is that wise or even possible? Is there some way to update PVE offline with a usb stick or something?\n (I suppose one solution is to ditch proxmox and run pfSense bare metal. I liked the idea of being able to snapshot my firewall in case anything goes wrong, and the little Topton unit is almost overpowered to just run as a firewall, so I figured it would be nice to use any extra power for other services. But I am open to running bare metal if it makes more sense.)\n    submitted by    /u/macgood  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zoe9qa/proxmox_hosting_pfsense_how_to_update/",
          "publishedOn": "2022-12-17T19:41:27.000Z",
          "wordCount": 15722,
          "title": "Proxmox hosting pfSense - how to update?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zodjfy/wifi_heat_map_for_home/",
          "author": null,
          "description": "Did you make a WiFi heat map for your home? If so what software did you use?\n    submitted by    /u/albertyiphohomei  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zodjfy/wifi_heat_map_for_home/",
          "publishedOn": "2022-12-17T19:08:46.000Z",
          "wordCount": 14185,
          "title": "WiFi heat map for home",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zocqhf/query_homelab_to_find_update_in_osservers/",
          "author": null,
          "description": "Does that things exist ? A program who query your home lab to find update and notify you ? Like some docker , os , installed webserver, proxmox, esx, nas etc… and you receive a nice email with current version vs new version all in one place ?\n    submitted by    /u/toasterqc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zocqhf/query_homelab_to_find_update_in_osservers/",
          "publishedOn": "2022-12-17T18:33:16.000Z",
          "wordCount": 16878,
          "title": "Query homelab to find update in os/servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zocn1x/jailbroke_an_old_surface_2_rt_with_windows_10/",
          "author": null,
          "description": "submitted by    /u/abcmitch123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zocn1x/jailbroke_an_old_surface_2_rt_with_windows_10/",
          "publishedOn": "2022-12-17T18:29:18.000Z",
          "wordCount": 14357,
          "title": "Jailbroke an old Surface 2 RT with Windows 10, repurchased it to be a wall tablet, unfortunately it can't run Lovelace dashboard no matter how hard I tried, but it can at least do HADashboard from Appdaemon!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zoalmk/have_any_hp_gen8_server_owners_done_cpu_upgrades/",
          "author": null,
          "description": "Currently running an e3-1220 v3 on my ML310e and would like to pick up a e3-1275L v3 to reduce power consumption and add some much needed hw encoding igpu. \n The cpu isn’t officially listed as supported and I’m not sure if the motherboard even supports using the igpu. \n I know the HW is kinda old but wondering if anyone else here have gone through the same thing and can confirm the cpu is a drop in replacement. \n Thanks!\n    submitted by    /u/machineglow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zoalmk/have_any_hp_gen8_server_owners_done_cpu_upgrades/",
          "publishedOn": "2022-12-17T16:57:10.000Z",
          "wordCount": 15798,
          "title": "Have any HP Gen8 server owners done CPU upgrades?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zo7toa/small_homelab/",
          "author": null,
          "description": "Hi ! Created my new homelab :) . I hope having finished to connect it, and set configuration with hypervisors in few days.\n    submitted by    /u/Spiritual-Cell-5775  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zo7toa/small_homelab/",
          "publishedOn": "2022-12-17T14:48:52.000Z",
          "wordCount": 14250,
          "title": "Small homelab !",
          "imageUrl": "https://preview.redd.it/xm41ia1uii6a1.jpg?auto=webp&s=7ff31a7284282fbaaf43c5bce75bc7b77730358e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zo5vj7/my_portable_homelab_in_a_box/",
          "author": null,
          "description": "submitted by    /u/itschalee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zo5vj7/my_portable_homelab_in_a_box/",
          "publishedOn": "2022-12-17T13:03:47.000Z",
          "wordCount": 16633,
          "title": "My portable homelab in a box",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zo4g8v/my_basic_setup_pi4_ssd/",
          "author": null,
          "description": "submitted by    /u/yimejky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zo4g8v/my_basic_setup_pi4_ssd/",
          "publishedOn": "2022-12-17T11:31:59.000Z",
          "wordCount": 15494,
          "title": "My basic setup: PI4 + SSD",
          "imageUrl": "https://preview.redd.it/ls4u95cd1g6a1.jpg?auto=webp&s=a074019acb317146c4947ae515ab7b15a0b4b233"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zo13kn/action_required_lastpass_security_incident_email/",
          "author": null,
          "description": "submitted by    /u/ultrahkr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zo13kn/action_required_lastpass_security_incident_email/",
          "publishedOn": "2022-12-17T07:39:07.000Z",
          "wordCount": 18617,
          "title": "Action Required: LastPass Security Incident (Email from LastPass)",
          "imageUrl": "https://external-preview.redd.it/G9jqQ8RKKkA421WBahtFV4b3_3mlgA2H-Iq22bbBPdU.jpg?auto=webp&s=4093177df40355f323662df05b2196068595db62"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znunqf/dont_know_to_match_all_my_needs_beginner/",
          "author": null,
          "description": "Hi to everyone,\n I'm really new here and very newbie at this topic. But I've been reading a lot since some time ago.\n I want to host some services at home, but I really don't know how to match all my ideas.\n First, I'm going to change my router's ISP Provider. I think I'm going to buy a Netgear x4s R7800 and to install OpenWRT on it. I was about to buy a a Turris Omnia for 170€, but it was out of my price range. And I can get the Netgear for just 60€.\n Second, I have a Qnap TS-431P2 with 8GB and 2x10TB HDD. But I'd like to sell it because I'd like to install another OS, like Debian.\n I'd like to have these services at home, only for LAN accessing:\n - OpenMediaVault? I have thousands of photos, and we'd like to backup my photos from our android and laptop devices.\n - Nextcloud.\n - Suricata to monitor all my network.\n - Some application to see the all the photos.\n - Pi-hole.\n Then, I've thought to get a device like a mini-pc to handle all of that. Install a linux on it, and create all that services as containers. Is it possible to do it like that? First I thought to buy a Rpi 4 8GB, but I've seen a Fujitsu Q920, which I think is better, and I can get one second handly even cheaper than a Rpi. Any other better HW solution?\n Please, any comments, advices or links would be really appreciated.\n Thank you in advance.\n    submitted by    /u/t0uxe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znunqf/dont_know_to_match_all_my_needs_beginner/",
          "publishedOn": "2022-12-17T01:21:52.000Z",
          "wordCount": 14150,
          "title": "Don´t know to match all my needs - Beginner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znuaq9/building_my_network_topology/",
          "author": null,
          "description": "I found this very good software for make my network topology (only for MacOS)\n Link: https://ermitacode.com/networkview.html\n ONU: DATACOM DM986-100\n Router: Mikrotik RB750GR3\n Switch: TPLINK 1008G\n WIFI: TLINK DECO M4\n Subnets: 10.1.1.0/24 - DECO WIFI / 192.168.100.1 - RB LAN\n Screenshots\n Physical Infra\n Logical Infra\n Deco Wireless LAN\n Subnet 10.1.1.0/24 LAN\n    submitted by    /u/jraimonxd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znuaq9/building_my_network_topology/",
          "publishedOn": "2022-12-17T01:03:15.000Z",
          "wordCount": 13716,
          "title": "Building my network topology",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znt7ab/got_this_from_work_did_i_score/",
          "author": null,
          "description": "submitted by    /u/BeachOG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znt7ab/got_this_from_work_did_i_score/",
          "publishedOn": "2022-12-17T00:09:11.000Z",
          "wordCount": 14570,
          "title": "Got this from work, Did I score?",
          "imageUrl": "https://preview.redd.it/vspvmpix5e6a1.jpg?auto=webp&s=1d821aa5199d5069d4f4912cc016e063c6f9541e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znt2wz/what_are_some_good_network_documentation_programs/",
          "author": null,
          "description": "Working on a project that will later be manged by different people in the future and i need a good program/services to make my documentation.\n    submitted by    /u/Twitch_Exicor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znt2wz/what_are_some_good_network_documentation_programs/",
          "publishedOn": "2022-12-17T00:03:17.000Z",
          "wordCount": 13768,
          "title": "What are some good network documentation programs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znsvpw/where_to_even_start_looking_for_another_ups/",
          "author": null,
          "description": "I'm pretty burned out after the whole cyberpower fiasco, thank god for costco's 1 year return policy at least.\n I don't think i'll be able to go without a UPS again, the power lines entering my neighborhood will fall if you look at them funny and it's been useful more than a dozen times this year and it saved me from quite an extreme brownout we had a few months ago. I've been looking around online and here's what I've been looking for.\n - ~1500VA\n - 900+W\n - Pure Sinewave \n I've heard quite a lot of good things about Eaton and thus i've been looking at the Eaton 5SC1500 recently, however the only thing holding me back is all the reviews and mentions online about the fan noise. \n Specs are listing 40dB at 1m, that's insane. I have my UPS under my desk and I sleep in the same room, from what I've heard the fan runs 24/7 and not just when the inverter is running, I wouldn't have a problem with that if it weren't so loud though. \n I've heard about some people replacing the fan with a noctuca fan but I'm not sure if i'm comfortable with this, a lot of the posts mentioning this don't specifically mention which model they're working on so I'd rather not just go out and replace the fan off a vague guide. \n It's really a bummer given that everything else about the UPS sounds perfect and is as close as it gets to the cp1500pfclcd.\n Does anyone have any ideas? Either towards the eaton unit or some other recommendations, I'm quite busy day to day and in my spare time i've been trying to look around for something that doesn't break the bank (<$500) but my attempts seem to be futile and it's getting really tiring.\n    submitted by    /u/Distinct-Guidance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znsvpw/where_to_even_start_looking_for_another_ups/",
          "publishedOn": "2022-12-16T23:54:13.000Z",
          "wordCount": 14349,
          "title": "where to even start looking for another UPS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znsqsg/having_issues_with_a_10gb_connection_to_nas/",
          "author": null,
          "description": "About 2 years ago, I decided to start on a homelab of my own beginning with a Dell R720 running TrueNAS. Everything has been running well, but given that I've been throwing 150 gig archives to it constantly, I decided it was time to upgrade from the base nic to one with 10GbE capabilities in a direct attach/peer to peer config with my main desktop. The x540 with 2 RJ45 10GbE and 2 1GbE ports installed nicely and has connected to my 1GbE network albeit limited to the slower speeds.\n My current issue is getting my desktop to connect to the R720. Turns out the card I purchased is an x540 Convergence Network Adapter. After installing the drivers from Intel, I'm not getting any network activity when plugged into the R720 nor when plugged into the switch (I've tried a crossover cable and a patch cable). \n Am I missing anything or do I need to find another NIC?\n    submitted by    /u/iamthesargent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znsqsg/having_issues_with_a_10gb_connection_to_nas/",
          "publishedOn": "2022-12-16T23:47:28.000Z",
          "wordCount": 13966,
          "title": "Having issues with a 10gb connection to NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znsll5/virtualize_cisco_deviceshomelab/",
          "author": null,
          "description": "I'm currently studying for my ccna. I'm about halfway through the content and would like to implement knowledge I've learned in a homelab setup I have on esxi on a Dell server.\n My question is..is their anyway to virtualize a cisco router/switch? All the things I found are deprecated abd no longer supported by esxi. I recognize this is overkill for. Ccna but it'd be a fun project abd would give me lots of practice\n    submitted by    /u/Party-Molasses-6130  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znsll5/virtualize_cisco_deviceshomelab/",
          "publishedOn": "2022-12-16T23:40:57.000Z",
          "wordCount": 13792,
          "title": "virtualize cisco devices...homelab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znrdkq/it_happened/",
          "author": null,
          "description": "I’ve been offered a security position as a promotion from my current “help desk masquerading as Jr sys admin” role that I’ve had. So many of the interview questions weren’t things I encountered in my day to day work life, but are things I’m at least beginning to understand thanks to my homelab and self-hosted projects!\n That’s all I came to say. To everyone else that’s plugging away in their homelabs, never discount the value the knowledge you’re accumulating. \n I’m trying to figure out what my reward should be once this change makes its way to my paychecks… expand the capabilities of my proxmox cluster with another node, with more ram for an existing node, of by getting myself a legacy Unix workstation (Sun or SGI)…. I know what will pay off in the long term; it’s just not nearly as fun sounding compared to other idea, which will be self gratifying but completely useless :)\n    submitted by    /u/AuthenticImposter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znrdkq/it_happened/",
          "publishedOn": "2022-12-16T22:45:23.000Z",
          "wordCount": 14255,
          "title": "It happened!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znqg3l/looking_for_homelab_ideas_to_use_as_playground_to/",
          "author": null,
          "description": "It seems like a lot of the labs on here are focused on personal projects like creating a server to store media for example, and there’s also a pretty overwhelming amount of info on here\n Does anyone have any recommendations or resources to learn and practice as many IT skills as possible? Like a homelab that I can use as a playground to practice sysadmin and networking \n Ideally either virtual or with hardware I can get cheap too\n    submitted by    /u/Altruistic-Carpet-43  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znqg3l/looking_for_homelab_ideas_to_use_as_playground_to/",
          "publishedOn": "2022-12-16T22:05:07.000Z",
          "wordCount": 14478,
          "title": "Looking for homelab ideas to use as playground to learn and practice IT concepts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znphig/storage_redesign_question/",
          "author": null,
          "description": "So currently my homelab is a single R720 running Esxi hosting all my VMs, and a homebuilt 4U storage server running TrueNAS. I recently decided to upgrade my storage and have a NetApp DS4246 on the way.\n ​\n To save rack space, I was considering either virtualizing TrueNAS or using possibly Windows Server Storage Spaces and direct attaching it to the R720 instead. Has anyone have experience with a TrueNAS virtualized and using a disk shelf?\n    submitted by    /u/Ironfox2151  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znphig/storage_redesign_question/",
          "publishedOn": "2022-12-16T21:22:52.000Z",
          "wordCount": 14192,
          "title": "Storage Redesign question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znoui6/home_lab_set_up_help/",
          "author": null,
          "description": "Anyone available to help out with setting up my homelab?\n I created a local server and was advised that I should set up a virtual server instead. So I'm trying to start from scratch. Will I have to reinstall os? \n Is there anyway to go back to the point that I started at. I basically just did the wizard and installed Active directory, DHCP, and DNS. So I suppose i may just need to remove those roles. \n ​\n Any info would be appreciated.\n    submitted by    /u/givenofaux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znoui6/home_lab_set_up_help/",
          "publishedOn": "2022-12-16T20:54:41.000Z",
          "wordCount": 14404,
          "title": "Home lab set up help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znmddb/are_these_any_good_new_workplace_said_i_could/",
          "author": null,
          "description": "submitted by    /u/CaptBobRoss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znmddb/are_these_any_good_new_workplace_said_i_could/",
          "publishedOn": "2022-12-16T19:07:16.000Z",
          "wordCount": 14761,
          "title": "Are these any good? New workplace said I could take it. Thought it might be useful for learning vlans and switch management.",
          "imageUrl": "https://preview.redd.it/qay3dg32oc6a1.jpg?auto=webp&s=a4ec914250915d5c8f1f2832e061d65e0cdca588"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znm26n/finally_caved_in_and_bought_a_2d_printer_and_put/",
          "author": null,
          "description": "submitted by    /u/dheera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znm26n/finally_caved_in_and_bought_a_2d_printer_and_put/",
          "publishedOn": "2022-12-16T18:53:47.000Z",
          "wordCount": 14656,
          "title": "Finally caved in and bought a 2D printer and put it on a sliding drawer",
          "imageUrl": "https://preview.redd.it/ivkhwpq04b6a1.jpg?auto=webp&s=bf99927d89693796384df042572eaf62785df447"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znluuf/is_this_overkill_for_a_home_labnetwork/",
          "author": null,
          "description": "Mikrotik 1072 will handle NAT and most routing\n I am debating whether to use OPNsense as a firewall in front of the Mikrotik or to just use its built in firewall. Suggestions would be greatly appreciated.\n HP 2920 will be used as the core, also have a brocade 6610 available if that is a better option\n Access points will connect to 24 port Ubiquiti switch\n Wired clients will connect to hp 2530\n DHCP and RADIUS servers will live on a Supermicro server.\n Some of the subnets are temporary to keep the family online until RADIUS is fully set up.\n I would love to hear your thoughts on this as well as any suggestions for additional things I should do.\n    submitted by    /u/bigmac_9000__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znluuf/is_this_overkill_for_a_home_labnetwork/",
          "publishedOn": "2022-12-16T18:44:49.000Z",
          "wordCount": 18220,
          "title": "Is this overkill for a home lab/network?",
          "imageUrl": "https://preview.redd.it/ufzyvh82kc6a1.jpg?auto=webp&s=66ee4295d891f82692c70352815e945f5b23f441"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znlgca/cooling_options/",
          "author": null,
          "description": "submitted by    /u/redfoxkiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znlgca/cooling_options/",
          "publishedOn": "2022-12-16T18:26:54.000Z",
          "wordCount": 14425,
          "title": "Cooling options?",
          "imageUrl": "https://preview.redd.it/v6c81y0sgc6a1.jpg?auto=webp&s=5686ea956d8b7ecad7a8d43fda9801e3d834762c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znjlai/homelabnetwork_evolution/",
          "author": null,
          "description": "submitted by    /u/nowhereman1223  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znjlai/homelabnetwork_evolution/",
          "publishedOn": "2022-12-16T17:06:46.000Z",
          "wordCount": 16918,
          "title": "HomeLab/Network Evolution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znibv9/cpu_upgrade_go_with_xeon_e516xx_v4_e526xx_v4_or/",
          "author": null,
          "description": "Are there any other considerations besides TDP, core and thread count, and price?\n They all seem to work in single CPU systems but the prices vary quite a bit on eBay between these. \n Should I go for the best combination of price, cores, TDP or is there more to it than that between single, dual, and quadruple capable Xeons?\n It’s to put in a Z440 workstation with 128GB RAM running proxmox. Currently running an E5-1620v4. \n Main concern is power usage as a kWh is 0.30$ here. Workload is containers and VMs.\n    submitted by    /u/phowntabir  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znibv9/cpu_upgrade_go_with_xeon_e516xx_v4_e526xx_v4_or/",
          "publishedOn": "2022-12-16T16:12:53.000Z",
          "wordCount": 16235,
          "title": "CPU upgrade: go with Xeon E5-16xx v4, E5-26xx v4, or E5-46xx v4?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zngx8b/an_ode_to_obsolescence_lets_appreciate_our_old/",
          "author": null,
          "description": "I see a lot of posts here showing off people's nice-looking racks. You know what I mean, you perverts. Lots of 1U servers and 48 port switches and fiber runs and disk chassis and the like. It's all pretty cool, but I usually find myself wondering \"what in the world are these people doing with all this gear, and also how much is their power bill?\"\n I don't have a rack, but I do have a lot of shelf space, and I have my old workhorse which sits in my basement that deserves some accolades. It's the Ford F150 of virtualization servers. It's running mostly hardware ranging between 2014-2017, but it serves literally everything in my house and has more than enough overhead for anything else I'd require or add to it. The newest thing about it is the case, a Fractal Define 7, that I migrated it in t…",
          "link": "https://www.reddit.com/r/homelab/comments/zngx8b/an_ode_to_obsolescence_lets_appreciate_our_old/",
          "publishedOn": "2022-12-16T15:13:38.000Z",
          "wordCount": 20364,
          "title": "An ode to obsolescence (let's appreciate our old workhorses!)",
          "imageUrl": "https://external-preview.redd.it/EiVhwXJd0pVUZIYSNHgQRZF_EMNDjtt06HeSRyxgV74.jpg?auto=webp&s=0c05e12811231e0e14bfd8978667169c20669561"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zncq1z/found_some_old_pictures_of_my_home_lab_that/",
          "author": null,
          "description": "submitted by    /u/kjp12_31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zncq1z/found_some_old_pictures_of_my_home_lab_that/",
          "publishedOn": "2022-12-16T11:43:10.000Z",
          "wordCount": 15355,
          "title": "Found some old pictures of my home lab that helped me with the CCIE DC Lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znbram/16gb_ram_enough_for_nas/",
          "author": null,
          "description": "I read TrueNAS recommends 32GB RAM So maybe another OS ? OMV?\n Super old HP MicroServer (4bays).\n    submitted by    /u/Inevitable-Cow-7057  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znbram/16gb_ram_enough_for_nas/",
          "publishedOn": "2022-12-16T10:41:56.000Z",
          "wordCount": 15673,
          "title": "16GB RAM enough for NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znbk4c/i_have_quite_a_few_sata_ssds_drives_left_over_all/",
          "author": null,
          "description": "Based in the Netherlands. Give them to a charity? Find other homalabbers in 'need' to send them to? I usually use NVMe's for OS installs, and use SATA ports for either spinning disks or 4/8TTbyte SSDs and these smaller drives are just not worth 'wasting' a SATA port over.\n Anyone have a similar problem? How did you solve it?\n https://preview.redd.it/zk8h59g2m86a1.jpg?width=4080&format=pjpg&auto=webp&s=0de4bcdf0af19e760f71d2e2929f62bcf1e0ca91\n    submitted by    /u/campr23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znbk4c/i_have_quite_a_few_sata_ssds_drives_left_over_all/",
          "publishedOn": "2022-12-16T10:28:20.000Z",
          "wordCount": 15822,
          "title": "I have quite a few SATA SSDs drives 'left over', all 128Gbyte or 256Gbyte, what to do with them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn7n5o/i_only_wanted_a_place_to_put_my_udm_se/",
          "author": null,
          "description": "submitted by    /u/charisbee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn7n5o/i_only_wanted_a_place_to_put_my_udm_se/",
          "publishedOn": "2022-12-16T06:03:51.000Z",
          "wordCount": 15416,
          "title": "I only wanted a place to put my UDM SE",
          "imageUrl": "https://preview.redd.it/uuu8v8bas86a1.jpg?auto=webp&s=0de2c20f5576cbfc57f38a1be4e05bbcd012cf33"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn6k18/home_lab_fail/",
          "author": null,
          "description": "Picked up a P400 Quadro to put in my Dell t440 and pass through to a Plex VM. It was delivered today. Today was also the day I found out that the sole 16x slot on the mobo is tied to CPU2. I don't run a second CPU. 🤬 🤦 \n Needed to share that one.....\n    submitted by    /u/tiberiusgv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn6k18/home_lab_fail/",
          "publishedOn": "2022-12-16T05:00:18.000Z",
          "wordCount": 15036,
          "title": "Home Lab Fail",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn29f4/amd_opteron_6234_not_showing_correct_core_count/",
          "author": null,
          "description": "As the title states, I recently purchased an old HP DL585 G7 to use as a game server. It is posting saying only 8 active cores per chip when it should be 12. Is this something similar to the bulldozer cpu debacle with amd, (Claimed 8 core on a 4 core chip) or is there a bios setting I might be able to access to utilize all cores on all 4 chips?\n Also, is there a way to set the fan speed? It's a bit loud sitting on my desk.\n    submitted by    /u/jwvan82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn29f4/amd_opteron_6234_not_showing_correct_core_count/",
          "publishedOn": "2022-12-16T01:16:25.000Z",
          "wordCount": 14027,
          "title": "AMD opteron 6234 not showing correct core count",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn1hi3/mass_loaded_vinyl_rack/",
          "author": null,
          "description": "I just got my first rack and after some blunders got everything together. It's not obnoxiously loud most of the time, but its noticeable in the background. Got a Dell R620 with dual E5-2643 V2 chips. I read someone had mentioned Mass Loaded Vinyl as an option and I wanted to know if anyone had experience creating a \"wall\" out of one for the sides of the rack, and if that actually dampened the volume. I thought about using the insert holes on the sides of the rack to affix a panel to the side.\n ​\n Secondly, I grabbed a static rack kit from dell not quite realizing what static really implied, which wouldn't be a huge deal but when I attempted to remove the server, I can pull it out about 6 inches and then it almost seems to catch on something and won't come out further. Anyone experience that, is that normal? I pretty much have to remove the rails and make sure there is lots of clearance around the rack if I ever want to take it out all the way (and I'm dreading the thought).\n https://preview.redd.it/50227k60p56a1.jpg?width=1195&format=pjpg&auto=webp&s=87c1e972d8e9902aa89651d3a2f2f0a2ed9d730d\n    submitted by    /u/breadcrumb1977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn1hi3/mass_loaded_vinyl_rack/",
          "publishedOn": "2022-12-16T00:39:10.000Z",
          "wordCount": 14207,
          "title": "Mass Loaded Vinyl Rack",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn1aym/refactored_my_proxmox_terraform_code/",
          "author": null,
          "description": "Hey y'all,\n A while back I got started using terraform to create/manage VMs on my proxmox homelab (thank you to those of you who have shared blog posts about this). \n One thing that bothered me was how I was essentially copy/pasting the resource definitions when I wanted to create a new VM, so I recently went through a big refactor to reduce the amount of configuration required to create a new vm and wanted to share with this community in case others find it useful. With this setup I can now define a new VM with three lines of yaml, push my changes and have them deployed by the gitlab ci/cd pipeline. \n https://github.com/nohbdy1745/proxmox-terraform \n I have this deployed on a gitlab instance running in a proxmox VM, with gitlab managing my terraform state, and have the gitlab ci/cd pipeline setup so I can push changes to my terraform configuration and have them deployed from there. I set it up so that you don't need to have gitlab managed terraform state, you would just have to change the backend in main.tf and you can use the make commands to run everything. \n Hope this is useful to someone else. I'm also not an expert with terraform so if you happen to take a look and have feedback please let me know! \n    submitted by    /u/nbdy1745  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn1aym/refactored_my_proxmox_terraform_code/",
          "publishedOn": "2022-12-16T00:30:46.000Z",
          "wordCount": 2038,
          "title": "Refactored my proxmox terraform code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn13p6/building_first_nas/",
          "author": null,
          "description": "Im going to build my first NAS will this be good?\n ​\n CPU: AMD Ryzen 3 3100 Motherboard: ASUS ROG Strix B550-I Cooling: Stock cooler GPU: GTX 1660 Super Overclocked 6GB PSU: Corsair RMX Series (2021), RM650x, 650 Watt, Gold, Fully Modular Power Supply Drives: Crucial MX500 500GB 3D NAND SATA 2.5 Inch Internal SSD and Western Digital 6TB WD Red Plus NAS Internal Hard Drive HDD Ram: 16gb 3600 Case: Fractal Design Node 804 OS: Will be using unraid\n ​\n Going to use this for storing media, streaming movies/shows, hosting csgo or minecraft servers and seeding torrents\n    submitted by    /u/Mr_TuxCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn13p6/building_first_nas/",
          "publishedOn": "2022-12-16T00:21:19.000Z",
          "wordCount": 14319,
          "title": "Building first NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn0whm/homelab_desktop_choices/",
          "author": null,
          "description": "Hi guys \n Help me choose one of these :\n 1.from Local 2nd hand store : \n Dell OptiPlex 3050 MT Core i7 7th Gen 32 GB ddr4 2400t 16x2 Nvidia gt 730 2gb gddr5\n 330$ \n Or \n 2.From Alibaba : \n x99+2690v4+4*16g DDR4 ECC RAM (64G)+ CPu fan + Power Supply 600w + 512G m.2 = 300$\n The 2nd offer gives Xeon 2690 V4 with 14 cores and 28 threads The first gives 4 cores ...8 threads . .... My build is for : \n 1.media server and I have 4×6TB and I am thinking of running Proxmox with VMs .then Dockers on VMs . \n 2.nextcloud for family . \n 3.NVR sys for house .\n    submitted by    /u/MrJwan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn0whm/homelab_desktop_choices/",
          "publishedOn": "2022-12-16T00:12:30.000Z",
          "wordCount": 14033,
          "title": "Homelab Desktop Choices ..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn0ees/do_sata_power_switches_work_well_power_onoff/",
          "author": null,
          "description": "Do SATA power switches such as these work well or is the feature considered hacky? They don't seem to be popular--does SATA not support this? I would think SATA being hot swappable means this is also a supported feature.\n Basically I have a couple of external drives for cold storage that take up space and I want to chuck them into my case. I was going to shuck them but leave the USB to SATA logic board intact and route the USB and AC power cable through PCIe slot into the case. Unfortunately the logic board prevents the drives from being mounted properly in my Node 304 case (also, somehow my WD Reds and another Seagate drive only support 3 screw mounts? Did Fractal mess up?).\n    submitted by    /u/rofic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn0ees/do_sata_power_switches_work_well_power_onoff/",
          "publishedOn": "2022-12-15T23:50:29.000Z",
          "wordCount": 14103,
          "title": "Do SATA power switches work well? Power on/off drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn0bxi/10gb_or_25gb/",
          "author": null,
          "description": "Hello, I have a Supermicro Unraid server that I would like to connect to my Windows PC. I’ve been researching 10GB over SFP+ and 25GB over SFP28 SFP+. Do you know if the NAS could take full advantage of 25GB or would it be bottlenecked by the hard drive read/write speed of 160MB/s? What speeds could I realistically expect when transferring files between the server and PC? Thank you for any help!\n    submitted by    /u/BlueGalaxy1000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn0bxi/10gb_or_25gb/",
          "publishedOn": "2022-12-15T23:47:27.000Z",
          "wordCount": 14529,
          "title": "10GB or 25GB?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmzske/dell_t330_without_a_service_tag/",
          "author": null,
          "description": "Hi, i recently bought on ebay a used Dell T330 with idrac8 board already installed, but i notice the enterprise license are not present, so i go to check the service tag trough the idrac base menu, i found out this: Service tag: XXXXXXX , i start thinking is not normal. What I can do now?\n    submitted by    /u/Virtual_Surround  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmzske/dell_t330_without_a_service_tag/",
          "publishedOn": "2022-12-15T23:26:14.000Z",
          "wordCount": 14168,
          "title": "Dell T330 without a service tag",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmz508/dell_poweredge_r240_supporting_intel_quick_sync/",
          "author": null,
          "description": "I see the E-2XXXG processors all support it but wondering if anyone tried?\n I'm looking for low powered 1U machines that support QSV.\n    submitted by    /u/keithah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmz508/dell_poweredge_r240_supporting_intel_quick_sync/",
          "publishedOn": "2022-12-15T23:00:53.000Z",
          "wordCount": 13901,
          "title": "Dell PowerEdge r240 supporting Intel Quick Sync using a E-2144G?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmz3ib/proxmox_ve_on_a_server_or_proxmox_ve_on_an_intel/",
          "author": null,
          "description": "I want a homelab for virtual pentesting and a NAS. I'm 16 years old so I still live with my parents, and they take care of the electricity bill. I also have a budget of under 1000.\n    submitted by    /u/MKzlol  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmz3ib/proxmox_ve_on_a_server_or_proxmox_ve_on_an_intel/",
          "publishedOn": "2022-12-15T22:59:41.000Z",
          "wordCount": 14149,
          "title": "Proxmox VE on a server OR Proxmox VE on an Intel® NUC Mini PCs with nas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmym21/workstation_mainboard_for_ryzen_5_5600x/",
          "author": null,
          "description": "My current homeserver is getting too small.\n I currently have a board that barely holds my GPU and ssd extension card. For future plans I need a mainboard that has more slots but I wonder if there is any workstation focused mainboard out there. Or are the gaming mainboards already the best to get when it comes to connectivity?\n ​\n The scenario:\n I have a server that runs Proxmox. I then have a bunch VMs/containers for my workload. All pretty basic except the gaming VM. I passthroguh my GPU, mouse and keyboard and connect to a screen.\n I might need more connectivity for that vm. E.g. to handle sound easily. I was thinking to buy a Thunderbolt extension card, also give that to the VM and then simply connect a docking station to it and be good. But for that I need at least one more card in the system... which does not fit currently.\n    submitted by    /u/soupdiver23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmym21/workstation_mainboard_for_ryzen_5_5600x/",
          "publishedOn": "2022-12-15T22:42:15.000Z",
          "wordCount": 14513,
          "title": "Workstation mainboard for Ryzen 5 5600X?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmxr81/how_have_you_racked_your_raspberry_pis/",
          "author": null,
          "description": "I am currently running two R Pis, and I dont see myself getting anymore (atleast not wired in this rack). Im trying to figure how would I \"rack\" them. Should I just leave them on a rack shelf, or have you people tried these different 3D printed/ metal Pi rack holders?\n ​\n Would love to hear any experiences!\n    submitted by    /u/gilfslayer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmxr81/how_have_you_racked_your_raspberry_pis/",
          "publishedOn": "2022-12-15T22:12:20.000Z",
          "wordCount": 15387,
          "title": "How have you \"racked\" your Raspberry Pis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmx019/powervault_tl2000_lto_library_buying_advice/",
          "author": null,
          "description": "submitted by    /u/31899  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmx019/powervault_tl2000_lto_library_buying_advice/",
          "publishedOn": "2022-12-15T21:43:34.000Z",
          "wordCount": 14338,
          "title": "Powervault TL2000 LTO Library Buying Advice",
          "imageUrl": "https://preview.redd.it/6vg1ryj6t46a1.jpg?auto=webp&s=540e6617780f592ce71cb4bddba4203ebeb335ae"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmv771/done_famous_last_words_haha/",
          "author": null,
          "description": "submitted by    /u/williamd002  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmv771/done_famous_last_words_haha/",
          "publishedOn": "2022-12-15T20:29:47.000Z",
          "wordCount": 16244,
          "title": "'Done'. Famous last words haha",
          "imageUrl": "https://external-preview.redd.it/fnDQxmHWF4428vE99hspVopgbQ1PQUqavL6OTLjTqPs.jpg?auto=webp&s=a90fe65afdb846f3ab9ddc7c95b7e0b93b2c4408"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmu17e/hp_prodesk_400_g4_i_can_install_linux_but_i_cant/",
          "author": null,
          "description": "Hi everyone, I just bought an HP Prodesk 400 G4 to start a home lab, but no matter what I do I can't seem to boot Linux.\n I installed both Proxmox and Ubuntu without any problem, but when I try to boot I just can't.\n I disabled secure boot from the BIOS settings and enabled Legacy mode, I downgraded BIOS firmware, but nothing worked.\n The computer previously had a 1TB hard disk, I installed Ubuntu on it and it won't boot either.\n Before I formatted the hard disk had Windows on it and it worked. My thoughts are that maybe the computer has some Linux block, so it can't boot Linux.\n Is there someone who maybe had the same issue and can help me?\n Thanks!\n    submitted by    /u/templare25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmu17e/hp_prodesk_400_g4_i_can_install_linux_but_i_cant/",
          "publishedOn": "2022-12-15T19:41:34.000Z",
          "wordCount": 15375,
          "title": "[HP Prodesk 400 G4] I can install Linux but I can't boot it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmtxs6/security_scanning/",
          "author": null,
          "description": "Looking for recommendations, either free or cheap to do an external scan for vulnerabilities. Can't seem to find anything that does much more than a basic port scan.\n    submitted by    /u/TechDiverRich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmtxs6/security_scanning/",
          "publishedOn": "2022-12-15T19:37:51.000Z",
          "wordCount": 14263,
          "title": "Security scanning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmtagk/home_nas_issues/",
          "author": null,
          "description": "Hey all.\n TLDR: What do you use for your home NAS (OS or Appliance)? Do you have a separate computer/server to run apps and use your NAS for storage?\n A few months ago, I switched from OMV to TrueNAS SCALE. I wanted stability and ease of use for my NAS because my family also relies on my NAS. I found OMV to be buggy, and not intuitive. In my opinion, I could not trust OMV. Now I am considering going back to OMV.\n TrueNAS SCALE has been great for me, at least if I used the very basic features of having a ZFS pool with a few SMB/NFS shares, but I wanted to run apps as well, such as Plex, Nextcloud, etc..., but that has been the biggest hassle for me, and I miss being able to use Docker Compose and apps just working.\n I added TrueCharts to my NAS to get all the apps I would want to run but li…",
          "link": "https://www.reddit.com/r/homelab/comments/zmtagk/home_nas_issues/",
          "publishedOn": "2022-12-15T19:11:03.000Z",
          "wordCount": 16536,
          "title": "Home NAS Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmt9a4/first_home_lab_build/",
          "author": null,
          "description": "I am building my first homelab, with spare pc part from a previous pc build of mine. Specs:\n Processor: i5 7500k Mobo: ASRock H270M-ITX Cooler: Noctua LH9i RAM:16gb 3200 Storage: WD blue 500gb | Segate 2tb GPU: NVIDIA 1060 3gb PSU: HDPLEX 400w w/ jhax 24pin mod connector Case: S4mini NFC OS: Ubuntu Server\n This would be used for a few thing hosting a Minecraft server for a few friends, hosting some local games emulators for my partner and I, media( tv movies, etc), and finally home assistant. Would the specs as is be able to handle this? And do you have any tips or recourses for set up? I am honestly pretty new when it come to trying to set up the cloud end of the gaming portion.\n    submitted by    /u/trevDaRev_ts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmt9a4/first_home_lab_build/",
          "publishedOn": "2022-12-15T19:09:54.000Z",
          "wordCount": 15572,
          "title": "First home lab build",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmsg10/update_meshlicious_9x_bay_unraid_nas_finally/",
          "author": null,
          "description": "submitted by    /u/stoph007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmsg10/update_meshlicious_9x_bay_unraid_nas_finally/",
          "publishedOn": "2022-12-15T18:36:12.000Z",
          "wordCount": 17302,
          "title": "Update - Meshlicious 9x Bay unRAID NAS Finally Filled!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmmb81/jankiest_setup_ever/",
          "author": null,
          "description": "submitted by    /u/NUCL3ARN30N  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmmb81/jankiest_setup_ever/",
          "publishedOn": "2022-12-15T14:24:59.000Z",
          "wordCount": 14855,
          "title": "Jankiest setup ever",
          "imageUrl": "https://preview.redd.it/c6o7ccbs446a1.jpg?auto=webp&s=2351c8411fedf4bdd1dcd01d8af931b345cb4253"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmhalb/use_my_public_ip_dynamic_as_a_proxy_in_second_pc/",
          "author": null,
          "description": "submitted by    /u/amannarula77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmhalb/use_my_public_ip_dynamic_as_a_proxy_in_second_pc/",
          "publishedOn": "2022-12-15T09:47:49.000Z",
          "wordCount": 18240,
          "title": "Use my Public IP( Dynamic ) as a Proxy in second PC ?",
          "imageUrl": "https://preview.redd.it/soyoqovp916a1.png?auto=webp&s=b7258019480e2df1551cf3ba99106a9ff0d7cf37"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmg3kj/my_home_server/",
          "author": null,
          "description": "submitted by    /u/Outrageous-Painter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmg3kj/my_home_server/",
          "publishedOn": "2022-12-15T08:27:53.000Z",
          "wordCount": 14957,
          "title": "My Home Server",
          "imageUrl": "https://preview.redd.it/f7en0gijv06a1.jpg?auto=webp&s=90eecec5c354b215aff3be90f6848e57cfa0548f"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm8mmp/any_app_on_linux_for_recording_sensor_data_wave/",
          "author": null,
          "description": "I'm looking for an app to real-time receive and plot sensor data (through TCP, sent by MCU with wifi) and save them for future analyzing. Like a PC oscilloscope.\n The features I need are: 1. Real-time receive and plotting 2. Data source can be TCP socket or named pipe (whatever as long as I can write a python script to be a middle converter) 3. Allow me to select a x-axis range to save a part of received data\n I've tried: - PulseView (can't real-time continuously receive) - LabPlot (KDE) (can't select a part of received data to save. And easy to crash) - Audacity (which is a sound wave editing software. Good for range selecting, but, can't set real-time data source to be other than mic. And can't show the wave if Y value larger than 1)\n Thank you guys\n    submitted by    /u/ArtisticJicama3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm8mmp/any_app_on_linux_for_recording_sensor_data_wave/",
          "publishedOn": "2022-12-15T01:38:58.000Z",
          "wordCount": 14193,
          "title": "Any app (on Linux) for recording sensor data (wave plot) sent from TCP ? (like oscilloscope)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm8gdt/should_have_bought_a_proper_rack/",
          "author": null,
          "description": "submitted by    /u/plantinspace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm8gdt/should_have_bought_a_proper_rack/",
          "publishedOn": "2022-12-15T01:30:39.000Z",
          "wordCount": 14865,
          "title": "Should have bought a proper rack...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm7whc/dont_act_so_surprised_ive_moved_on/",
          "author": null,
          "description": "submitted by    /u/Tri_Ban_Had  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm7whc/dont_act_so_surprised_ive_moved_on/",
          "publishedOn": "2022-12-15T01:05:36.000Z",
          "wordCount": 13948,
          "title": "Don’t act so surprised. I’ve moved on.",
          "imageUrl": "https://preview.redd.it/hdsv6746606a1.jpg?auto=webp&v=enabled&s=bddf52f87325fa5b62f48d324819b592cbc6c0b9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm7d5x/email_solutions_ses_vs_selfhosted/",
          "author": null,
          "description": "Hoping my fellow homelab community can weigh in on this. I run a few websites that send email (~1-5k per month) and have a bunch of homelab stuff on different domains that sends transactional emails (~500 per month).\n I have been using Mailgun for the last few years and whilst good, I have started having to pay each month as the amount of emails sent goes over the free tier. This has at most been around $6-$10 in a single month. I have been tying with the thought of switching over to amazon SES as its ridiculously cheaper. I then happened to stumble on the delights of Postal (postalserver.io).\n I am now stuck toying with the idea of SES or do I host my own Postal on a VPS somewhere? I send emails from roughly 20 different domains and would like to utilise security features where possible. I understand the issues with IP reputation that comes from email delivery.\n Am i better off just sticking with SES? Overall it will probably be cheaper. Or do I go Postal with slightly more VPS monthly cost but with the freedom and much better UI / dashboards?\n ​\n OR even better can I host Postal on AWS and get postal to send via SES and utilise the 62k free emails per month (i assume this either wont work or will require each domain to be verified in SES anyway?)\n    submitted by    /u/spudd01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm7d5x/email_solutions_ses_vs_selfhosted/",
          "publishedOn": "2022-12-15T00:41:14.000Z",
          "wordCount": 13803,
          "title": "Email Solutions (SES vs Selfhosted)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm701g/equallogic_type_10_controllers_sfp_10g_to_copper/",
          "author": null,
          "description": "Hello! I'm hacking around with an equallogic system that uses the type 10 controllers. I purchased some FSP+ -> RJ45 (copper) transceivers. I can only get them to link with my 10g switch if I force them 1g; hardly a solution. \n I've just tried them back-to-back with some 10g server ports ( for link/ping tests ) and that doesn't seem to function either. Does anyone have these running with copper interface SFP+ modules? Do you have a part number if so?\n    submitted by    /u/coldnight3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm701g/equallogic_type_10_controllers_sfp_10g_to_copper/",
          "publishedOn": "2022-12-15T00:24:53.000Z",
          "wordCount": 14203,
          "title": "Equallogic type 10 Controllers - SFP+ / 10G to copper woes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm6ll9/dl380_g6_not_posting/",
          "author": null,
          "description": "Hello all,\n I've recently gotten my hands on an HP DL380 G6 that I cannot for the life of me get to post. No matter what I've tried I cannot get any video output, not even as much as seeing the HP splash screen. Any help is greatly appreciated.\n I can't reach iLO by domain name, and does not show up in device list on my router so I cannot find an IP address (server may not even have a valid license).\n Last owner of the server was able to reach the BIOS, and did not make any configuration changes before I got it.\n Front panel indicators:\n  \nServer health indicator: solid green\n Server power indicator: solid green\n DIMMs: off\n Power supplies: off\n Processors: Solid amber\n Hard drive lights: come on for a split second and turn off almost immediately\n Fans: off\n Over temp: off\n Power cap: off\n  \nFixes I've tried are as follows: \n  \nResocketing CPUs, along with running each CPU individually\n Running minimum amount of DIMMs\n Using only 1 power supply\n Resocketing the power supplies\n Swapping the power supplies\n Changing VGA port used \n Did not try a different cable as I know for a fact the one I was using works\n \n Changing to a different monitor\n Flipping DIP switch 6 to on, letting system idle, then flipping it off (turning server off and removing power supplies before flipping it each time obv)\n Flipping DIP switch 1, 5, 6 to on, letting system idle, then flipping them off\n Simply letting it sit for an hour or so to see if it was just taking an absurd amount of time to boot\n  \nIf any more information is needed I'll happily provide it, and once again thank you for your help.\n    submitted by    /u/Typical-Voice-7350  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm6ll9/dl380_g6_not_posting/",
          "publishedOn": "2022-12-15T00:07:15.000Z",
          "wordCount": 15327,
          "title": "DL380 G6 not posting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm6fgw/december_2022_wiyh/",
          "author": null,
          "description": "Acceptable top level responses to this post:\n  \nWhat are you currently running? (software and/or hardware.)\n What are you planning to deploy in the near future? (software and/or hardware.)\n Any new hardware you want to show.\n  \nPrevious WIYH\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm6fgw/december_2022_wiyh/",
          "publishedOn": "2022-12-15T00:00:12.000Z",
          "wordCount": 14147,
          "title": "December 2022 - WIYH",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm68fq/network_map_application_in_docker/",
          "author": null,
          "description": "does anyone know of any application in docker (or no) that it is possible to create interactive network map, such as zabbix?\n    submitted by    /u/jraimonxd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm68fq/network_map_application_in_docker/",
          "publishedOn": "2022-12-14T23:51:28.000Z",
          "wordCount": 13942,
          "title": "Network Map Application in Docker",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm4kno/12v_car_battery_and_12v_device_advice/",
          "author": null,
          "description": "i live in car/camper van. i have some device. like rb4011 。and some poe camera.\n as far as i know all my device is ok with 12v dc. maybe +-25% votage range. \n but my problem is car battery votage change. like 9v-14.2 v . \n do i need DC-DC Converter like \n Victron Orion-TR DC-DC Converter - 12 VDC to 12 VDC - 9AMP Isolated ??????\n or i can connect most 12v device to battery directly. ?????\n i dont want damage my devices..\n but if i use Converter. i will lose some efficiency.... during dc to dc converter....\n    submitted by    /u/AmbulacneXu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm4kno/12v_car_battery_and_12v_device_advice/",
          "publishedOn": "2022-12-14T22:41:29.000Z",
          "wordCount": 14928,
          "title": "12v car battery and 12v device advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm4cj2/how_can_i_limit_internet_on_a_specific_device_for/",
          "author": null,
          "description": "I would like to provide only 1 hour of internet a day for a specific advice. \n What would be the best way and easiest to achieve this?\n    submitted by    /u/nambi_2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm4cj2/how_can_i_limit_internet_on_a_specific_device_for/",
          "publishedOn": "2022-12-14T22:32:20.000Z",
          "wordCount": 14282,
          "title": "How can I limit internet on a specific device for 1 hour a day",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm3za9/do_you_need_traefik_for_docker_swarm/",
          "author": null,
          "description": "I don't understand why so many tutorials and guides tells you to use traefik for docker swarm.\n as docker swarm should have built in load balancing, you would just access any node on the swarm at a certain port and you should be redirected to an active node right? so why the need for traefik?\n    submitted by    /u/BenPoss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm3za9/do_you_need_traefik_for_docker_swarm/",
          "publishedOn": "2022-12-14T22:17:23.000Z",
          "wordCount": 14828,
          "title": "do you need traefik for docker swarm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm0trl/stealth_quiet_rackmount_chassis_with_maximum/",
          "author": null,
          "description": "I have a 42U rack in my office and it needs to be filled! I have a 4U Rosewill 15bay that is 'quiet-ish', but im looking for a massive amount of bays, but it must be quiet.\n Any recommendations?\n --\n Goals:\n  \nRack mount\n Super quiet, upgrades or swapping out for consumer / quiet is fine, but it must be quiet \n The SuperMicro SQ PSU is not that quiet, I have that also, its still loud, but quieter than a jet turbine hahaa\n \n Maximum bays count\n Good build quality, I don't want cheap chassis to kill me with slow death of annoyance and failure\n  \n   submitted by    /u/cs_legend_93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm0trl/stealth_quiet_rackmount_chassis_with_maximum/",
          "publishedOn": "2022-12-14T20:08:12.000Z",
          "wordCount": 15106,
          "title": "Stealth quiet rackmount chassis - with maximum drive bays are the only requirement - any recommendations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm0nu2/uk_ups_sanity_checkrecommendations/",
          "author": null,
          "description": "Hello,\n I'm not sure if this is the right sub, but I tried posting on r/buildapc and it didn't get any responses. I've moved recently, and I'm on a new build estate which seems to be suffering with brown outs a few times a week. I've been told this will stop next year as the other side of the estate is connected, however it's worrying me a little as my NAS, PC and Mac mini have all been unexpectedly shutdown a few times. I'd like to attach:\n  \nSynology DS1817+ (5-60W)\n PC (750wPSU) (70-500W)\n Mac Mini (2-80W)\n Network gear (50-100W complete guess as I've not attached the meter yet)\n  \nI'm not much of a gamer, so the PC is very rarely pulling 500W+, it tends to idle at 70W and normal use may take it to 150W. I've been looking at a few of the calculators and for 3 minutes runtime something rated around the 1500VA/900W seems to be recommended. I've got no experience with UPSs at home, we use Eaton at work, but I've never had much to do with their configs. I think I can budget around £300, but I could stretch that a little. I've got some rack gear, so I'm open to either rack or freestanding units. These models seem to come up, or their rack equivalent:\n  \nCyberPower CP1500EPFCLCD\n Powercool Smart UPS 2000VA\n APC BX1600MI\n Eaton 5P850i\n  \nI'd be grateful for any feedback, recommendations and I can provide any other info if it helps. I'm slightly confused by the price differences for similar headline specs, I'm not sure if this is just a brand thing or some feature I should be focussing on. Any recommendation for the software setup, mainly for the Mac and NAS as they are always on. \n Thanks in advance :-)\n    submitted by    /u/trickster-is-weak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm0nu2/uk_ups_sanity_checkrecommendations/",
          "publishedOn": "2022-12-14T20:01:38.000Z",
          "wordCount": 16389,
          "title": "UK UPS Sanity Check/Recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm0iyw/specs_or_user_feedback_regarding_touch_screens_on/",
          "author": null,
          "description": "submitted by    /u/Relaxybara  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm0iyw/specs_or_user_feedback_regarding_touch_screens_on/",
          "publishedOn": "2022-12-14T19:56:28.000Z",
          "wordCount": 14958,
          "title": "Specs or user feedback regarding touch screens on Dell Optiplex AIO systems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlzwmv/wifi_ap_guest_access/",
          "author": null,
          "description": "I have been looking for a while and I'm a bit confused. As many others, my lab is composed of (close to) free stuff I gathered for years, I'd rather make things work with what I have.\n I recently upgraded my simple network (fritzbox + fritzrepeater, main network + guest access) to a more complex setup: fritzbox (as a vdsl modem), apu4c board running opnsense, Netgear GS324T managed switch, fritz repeater as an AP.\n As you can see, the fritzbox and the repeater are now far apart thus the mesh feature stopped working and with it the guest access, that's to be expected. What I don't understand is the following: for the guest access to work between the fritzbox and the repeater, there has to be some vlan shenningans, I doubt AVM invented a brand new mechanism to separate traffic. My guess was that somehow all fritzbox ports were trunked with the default vlan being for the main network and all traffic from guest access was tagged with a vlan id.\n I tried setting it up like that, but I couldn't identify the vlan id (tried a bunch but that's tedious and I'm unsure how to inspect traffic at the switch, never done port mirroring before, not sure how to use linux to listen to it).\n Anyway, my question is, does anyone know if AVM could be using some other technology? Is there another way to use a fritz repeater to have two separate networks?\n    submitted by    /u/bendem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlzwmv/wifi_ap_guest_access/",
          "publishedOn": "2022-12-14T19:29:35.000Z",
          "wordCount": 14375,
          "title": "Wifi AP guest access",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlzpso/i_need_to_mount_these_in_my_rack_but_i_find_it/",
          "author": null,
          "description": "submitted by    /u/igmyeongui  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlzpso/i_need_to_mount_these_in_my_rack_but_i_find_it/",
          "publishedOn": "2022-12-14T19:21:14.000Z",
          "wordCount": 15054,
          "title": "I need to mount these in my rack but I find it hard to find information about the right brackets online. Any help would be appreciated!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlxqm5/smart_home_and_homelab_network_diagram_after_4/",
          "author": null,
          "description": "submitted by    /u/FoxxMD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlxqm5/smart_home_and_homelab_network_diagram_after_4/",
          "publishedOn": "2022-12-14T18:01:06.000Z",
          "wordCount": 19099,
          "title": "Smart Home and Homelab network diagram after 4 years of evolution",
          "imageUrl": "https://preview.redd.it/8stun1nvkw5a1.png?auto=webp&v=enabled&s=4b6d31911af263643c7e72e1b9f307befef942cc"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlw716/does_anyone_know_what_this_is_the_port_in_red/",
          "author": null,
          "description": "submitted by    /u/daelikon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlw716/does_anyone_know_what_this_is_the_port_in_red/",
          "publishedOn": "2022-12-14T17:00:55.000Z",
          "wordCount": 15429,
          "title": "Does anyone know what this is? (the port in red circle)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlsldx/thats_just_bad_luck_double_battery_failure/",
          "author": null,
          "description": "submitted by    /u/Wobblycogs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlsldx/thats_just_bad_luck_double_battery_failure/",
          "publishedOn": "2022-12-14T14:36:42.000Z",
          "wordCount": 15242,
          "title": "That's just bad luck, double battery failure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlru2z/found_a_nice_low_power_vm_host/",
          "author": null,
          "description": "I needed to replace my older desktop PC that I was using as a VM host due to hardware failure. Wanted something small that could be tucked away in a corner but have enough to run the few VM's I use and came across this (MINIS FORUM U820). Not supper powerful, but out of the box, this thing is quick. I kept the 512 M.2 drive it came with for holding ISO's and so on and added in 2 1TB SSD's and upgraded the RAM to 32GB. The only issue I have so far is vanilla ESXi 7 will not see either NIC, but vanilla ESXi 8 will see the 2.5GB port (which is what I needed). I am sure if I played around with it, I could get the 1GB port working. Just thought I would pass this along for anyone looking at something small.\n    submitted by    /u/fieroloki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlru2z/found_a_nice_low_power_vm_host/",
          "publishedOn": "2022-12-14T14:06:30.000Z",
          "wordCount": 15303,
          "title": "Found a nice low power VM host",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zloit2/how_do_you_all_name_the_hosts_in_your_homelab/",
          "author": null,
          "description": "Everytime I set up a new project in my homelab I am stuck at which host name to assign. For debug and simplicity using the software and/or purpose seems to be the most sane answer.\n What do you do? Generic host names? Numbering? Software names? Anything creative? Do you follow a theme like greek letters/zodiacs/whatever?\n router dot domain is not that creative, neither is media dot domain. I saw someone using planets or stars but I guess that could become messy and not that obvious when debugging stuff not touched for a long time\n    submitted by    /u/carlinhush  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zloit2/how_do_you_all_name_the_hosts_in_your_homelab/",
          "publishedOn": "2022-12-14T11:26:32.000Z",
          "wordCount": 21570,
          "title": "How do you all name the hosts in your homelab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlnfxi/what_measures_are_other_european_homelabbers/",
          "author": null,
          "description": "Hey everyone,\n I'm living in europe and I've noticed that electricity prices in my area (Germany) have been exponentially increasing, thanks to Putin... (0,23€/kWh to 0,44€/kWh)\n I'm looking for ways to reduce my energy consumption and cut down on costs, and I'm wondering what measures other European homelabbers have taken to combat rising electricity prices.\n Currently i setup my Fujitsu Primergy RX600 S6 to only run from 9AM to 1AM so i can at lease save a third of the costs, by running it 16 hours a day im actually awake instead of 24/7. Also i configured power savings mode in iRMC. It is still running at 170 Watts.\n Any further advice, hints or suggestions would be greatly appreciated!\n    submitted by    /u/Alfagun74  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlnfxi/what_measures_are_other_european_homelabbers/",
          "publishedOn": "2022-12-14T10:20:54.000Z",
          "wordCount": 17636,
          "title": "What measures are other European homelabbers taking to combat rising electricity costs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlfjfa/just_moved_my_home_lab_to_the_new_jonsbo_n2/",
          "author": null,
          "description": "submitted by    /u/L680C  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlfjfa/just_moved_my_home_lab_to_the_new_jonsbo_n2/",
          "publishedOn": "2022-12-14T02:59:43.000Z",
          "wordCount": 16476,
          "title": "Just moved my home lab to the new Jonsbo N2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlesb5/homelab_the_before_and_after_the_glow_up/",
          "author": null,
          "description": "submitted by    /u/FoxInATrenchcoat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlesb5/homelab_the_before_and_after_the_glow_up/",
          "publishedOn": "2022-12-14T02:25:21.000Z",
          "wordCount": 15725,
          "title": "Homelab: The before and after (the glow up)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zld1sl/the_fusionio_ssd_original_documentation_so_it/",
          "author": null,
          "description": "submitted by    /u/_Fra_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zld1sl/the_fusionio_ssd_original_documentation_so_it/",
          "publishedOn": "2022-12-14T01:09:41.000Z",
          "wordCount": 13858,
          "title": "The fusion-io SSD original documentation, so it doesn't get lost",
          "imageUrl": "https://preview.redd.it/umkv10e5kr5a1.jpg?auto=webp&v=enabled&s=7c2851fe5d9c41ee3b89181813758562bc1a3b8c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlcycj/linux_mdadm_reduce_disk_count_but_increase_size/",
          "author": null,
          "description": "I have 6 4TB drives in RAID 6 on a server. I want to replace them with 4 14TB drives and keep it as RAID 6.\n Is there a way to increase the size of the array while decreasing the amount of disks, or do I have to rebuild everything.\n    submitted by    /u/Particular-Dog-1505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlcycj/linux_mdadm_reduce_disk_count_but_increase_size/",
          "publishedOn": "2022-12-14T01:05:31.000Z",
          "wordCount": 13958,
          "title": "Linux mdadm: Reduce disk count but increase size of RAID 6",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlcmev/thunderx2_28core_cpus/",
          "author": null,
          "description": "Hello, I have some CN9975 ARM CPUs but have not been able to find motherboards or servers that fit these CPUs. I also don’t know much about these CPUs in general. If anyone would happen to know something more about these, feel free to share.\n TIA\n    submitted by    /u/zeJuaninator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlcmev/thunderx2_28core_cpus/",
          "publishedOn": "2022-12-14T00:51:35.000Z",
          "wordCount": 13918,
          "title": "ThunderX2 28Core CPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlce4s/recipe_for_high_iopsthroughput_storage/",
          "author": null,
          "description": "Has anyone built a homelab storage solution that achieves: \n  \nlarge sized volumes, say 30TB or larger (so simply using expensive SSD arrays isn’t an option)\n high IOPS, say 5-10k (so a simple mechanical array isn’t an option)\n utilizing 2.5GbE network capacity \n  \nOr, if you wanted to build a NAS solution with about 30TB of working data, with lots of small I/O, and fully utilizing a 2.5GbE network, what would you build?\n Synology SSD read-write cache is insufficient, Intel CAS is commercial and is designed for Optane primarily I think, Intel SRT is discontinued, storage spaces with an SSD tier might be an option but they really want you to use an expensive Windows Server install and spaces seems to be unwieldy, Linux bcache might be an option, ZFS or Unraid with an SSD cache might be an option…\n    submitted by    /u/pixlatedpuffin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlce4s/recipe_for_high_iopsthroughput_storage/",
          "publishedOn": "2022-12-14T00:41:39.000Z",
          "wordCount": 14102,
          "title": "Recipe for high IOPS/throughput storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlc7o3/satadom_not_showing_up_on_r730xd/",
          "author": null,
          "description": "I bought a \"02PTHF Dell 64GB SATA 6Gbps SATADOM\" but I can't get it to show up anywhere on my PowerEdge r730xd. It doesn't show in idrac, hardware survey, bios. Even when I boot into gparted, every storage device shows up except the satadom. There are 2 Sata ports in my r730xd and I've tried putting it on both.\n Anyone know how to get this satadom to work? Thank you.\n    submitted by    /u/AwefulUsername  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlc7o3/satadom_not_showing_up_on_r730xd/",
          "publishedOn": "2022-12-14T00:34:06.000Z",
          "wordCount": 14133,
          "title": "Satadom not showing up on R730XD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlal1w/rack_mount_case_recommendations/",
          "author": null,
          "description": "I want to try and build a custom rack mount server (mainly for Plex). So I’ve been looking for cases/chassis with 8-12 hot swap 3.5 bays, but also fits standard PC motherboard sizes and PSUs. The only one I’ve really found is this Silverstone case, and there don’t seem to be many of reviews of it out there. Are there other cases / companies I should look at? Could I salvage something like an old PowerEdge? Any advice is appreciated!\n    submitted by    /u/SubtleToot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlal1w/rack_mount_case_recommendations/",
          "publishedOn": "2022-12-13T23:26:30.000Z",
          "wordCount": 16276,
          "title": "Rack mount case recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zla5pj/proxmox_on_the_edge/",
          "author": null,
          "description": "I'm looking move my homelab from an ubuntu server that just happens to serve my house internet to a pfSense instance in Proxmox. Is it was safe to have the modem plugged into the Proxmox machine and connect the ports to virtual networks (the netgate documentation example) or\n is it better to have the modem connected to a PCIe NIC that is passthrough to the pfSense instance, then connect the internal network via bridging.\n    submitted by    /u/t2thev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zla5pj/proxmox_on_the_edge/",
          "publishedOn": "2022-12-13T23:09:34.000Z",
          "wordCount": 14052,
          "title": "Proxmox on the Edge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl9pu8/a_stupid_question_about_dell_servers/",
          "author": null,
          "description": "I'm looking between an r730 and r730xd. The 730 had an optical drive (which I prefer, don't judge me), and enough 3.5\" bays to satisfy my needs, if I can put the OS elsewhere. The 730xd has more drive space than I know what to do with, no optical bay, but has those fancy rear flex bays.\n I'm wondering if I can take a r730xd and swap the front section for the 8x3.5\" from the r730. This way I can have my OS mirror, optical drive, and not feel bad for using 1/3 of the drive space. I don't see anything online about it though, and wanted to check here before I sacrifice my dvd drive.\n    submitted by    /u/thextallxdude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl9pu8/a_stupid_question_about_dell_servers/",
          "publishedOn": "2022-12-13T22:52:29.000Z",
          "wordCount": 14686,
          "title": "A stupid question about Dell servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl9grw/what_to_upgrade_my_lenovo_sa_120_to/",
          "author": null,
          "description": "So when I started my homelab journey I was dumb and went with a data attached storage and have a Lenovo SA120. I want to upgrade it to a NAS as I'm currently running a an R830 as my home server.\n Any input is appreciated.\n    submitted by    /u/GUI-Discharge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl9grw/what_to_upgrade_my_lenovo_sa_120_to/",
          "publishedOn": "2022-12-13T22:42:50.000Z",
          "wordCount": 13791,
          "title": "what to upgrade my Lenovo SA 120 to?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl90t3/sfp_gpon_with_changeable_sn_and_vendorid_working/",
          "author": null,
          "description": "Recently I purchased a SFP module from FS - GPON-ONU-34-20BI. And after ~1h port management and many other functions on UDM SE just stop working. Restart solves it but restarting a router every hour is extremely stupid. Ubiquiti support literally said to me that they don’t care because it isn’t their module. But the problem is that I can’t use theirs module because I need to change GPON SN and VendorID to get internet connection from my ISP. Do you have any SFP modules with changeable SN and VendorID to recommend? Of course it needs to work with UDM SE.\n TLDR: recommend any module that meets requirements in the title.\n    submitted by    /u/_iMordo_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl90t3/sfp_gpon_with_changeable_sn_and_vendorid_working/",
          "publishedOn": "2022-12-13T22:25:40.000Z",
          "wordCount": 14240,
          "title": "SFP GPON with changeable SN and VendorID working with UDM SE",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl8pwv/someone_gave_me_this_and_said_it_was_working_its/",
          "author": null,
          "description": "submitted by    /u/igmyeongui  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl8pwv/someone_gave_me_this_and_said_it_was_working_its/",
          "publishedOn": "2022-12-13T22:13:58.000Z",
          "wordCount": 14393,
          "title": "Someone gave me this and said it was working. It's been a few weeks in his truck and here it's winter outside. Now it doesn't power up, no lights, nothing. I tried both 20 amps and 15 amps and no luck. Any way to troubleshoot/repair these? Thank you!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl82qh/how_to_connectjoin_my_5g_modem_to_my_ax88u/",
          "author": null,
          "description": "I've been using my RT-AX88U as a one-stop-shop router now for about 1 year. However fiber speeds have never got better than 50mbps here.\n So bit the bullet and today got a ZTE MC8020 5G CPE Router. It's arguably the best 5G router on the market (before ZTEs 6Ghz one drops in a few weeks). Without any tweaking I can get 300/50mbps solid with pings as low as 8ms. On my home fiber I was never offered anything better than 50/5mbps for the same price...\n  \nMy question is how to I properly set up both the devices so they work together?\n I have every ethernet port of the AX88U populated. TV, PS5, 2x Gig Homelab, NV Shield, PC, etc. Previously I just connected the WAN port on the AX88U into the wall ethernet socket.\n My ZTE MC8020 5G Router has 2 Ethernet ports only... WAN/LAN1 & LAN2. The ZTE has…",
          "link": "https://www.reddit.com/r/homelab/comments/zl82qh/how_to_connectjoin_my_5g_modem_to_my_ax88u/",
          "publishedOn": "2022-12-13T21:49:29.000Z",
          "wordCount": 15501,
          "title": "How to connect/join my 5G Modem to my AX88U?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl6eu7/internet_keeps_dropping_isp_router_is_at_fault/",
          "author": null,
          "description": "I have a router from my ISP, that I have put into Modem Mode, and have it connected to a OPNSense router. \n Every now and again (4 times today) the internet will drop completely and will stay down until I reboot the ISP router. \n I know it’s the ISP router as I plug an Ethernet cable directly into it, and there’s no internet. \n Frustratingly, this seems to be happening more and more frequently, and the ISP can’t send an engineer until next week, so I’m looking to see if there’s anything anybody can suggest. \n What’s even more odd is when I’m experiencing the issue the IP I get when plugging into the ISP router is not my WAN IP. When the issue isn’t happening, it is. \n So the issue seems to be down to the ISP router doing something weird/wrong. \n It’s driving me fucking crazy and I can’t handle another week before the engineer comes. The last three times I’ve rebooted, the connection has lasted for about 10-20 minutes and then it goes down again. Same issue as I’ve described above. \n Anybody have any fucking idea?!\n    submitted by    /u/drinkmilkandshit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl6eu7/internet_keeps_dropping_isp_router_is_at_fault/",
          "publishedOn": "2022-12-13T20:45:09.000Z",
          "wordCount": 17277,
          "title": "Internet keeps dropping, ISP router is at fault and it’s driving my crazy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl62re/weird_drops_on_10gb_card_in_windows_10/",
          "author": null,
          "description": "Hey all,\n ​\n I've been testing some stuff with the new 10gb network, and I seem to have hit a strange issue. On Windows 10, running iperf to a TrueNAS box with 2 10Gb ports bondeed together, I am getting 6Gb/s on a single thread, which I don't think is too bad.\n ​\n But when I run multiple tests over time, it eventually drops to 2.4 ish....I thought maybe the NIC was overheating, but I ziptied a fan to it and it still seems to be having trouble. The drivers for this card were absolute dogshit to setup, and I'm to the point I\"m probably going to grab an intel 10gb nic instead....\n ​\n Does anyone else have experience with 10gb that could tell me maybe why I'm getting this weirdly sudden and consistent drop in speed? I'm using an HPNC523SFP on both sides of the connection, with a Mikrotik CRS317 running SWOS in the middle here. The NAS Server is running Proxmox with the 2 ports bonded in lacp mode passed to a bridge that a TrueNAS VM is using. The ports are set both in active mode on the switch, and the client is just a plain ass Windows 10 box.\n ​\n I can't think of anything else significant I have configured here...\n    submitted by    /u/QuirkyKirk96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl62re/weird_drops_on_10gb_card_in_windows_10/",
          "publishedOn": "2022-12-13T20:31:58.000Z",
          "wordCount": 16051,
          "title": "Weird drops on 10Gb card in Windows 10",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl4kd3/bought_a_12_bay_unit_have_8_14tb_wd_red_plus_but/",
          "author": null,
          "description": "Should I wait for the 14TB WD Red Plus to go on sale or should I shuck 14 TB easystore drives? \n Thank you!\n    submitted by    /u/KeBlam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl4kd3/bought_a_12_bay_unit_have_8_14tb_wd_red_plus_but/",
          "publishedOn": "2022-12-13T19:32:07.000Z",
          "wordCount": 15932,
          "title": "bought a 12 bay unit, have 8 14TB WD Red Plus, but looking to fill the rest",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl4fh3/does_anyone_know_where_i_can_find_the_spec_for/",
          "author": null,
          "description": "submitted by    /u/SimplifyAndAddCoffee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl4fh3/does_anyone_know_where_i_can_find_the_spec_for/",
          "publishedOn": "2022-12-13T19:26:44.000Z",
          "wordCount": 14268,
          "title": "Does anyone know where I can find the spec for this 12 pin power connector on the backplane of a Dell PowerEdge R520?",
          "imageUrl": "https://external-preview.redd.it/Am8ItFZ6bcqpi-JUwVKlJmCCVQfvE8TiI1yWs4mrJH8.jpg?auto=webp&v=enabled&s=9a24c9498b7d9cdfd5c5a604853de6d129ccabe1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkwvef/moved_to_a_new_house_but_brought_something_old/",
          "author": null,
          "description": "submitted by    /u/modelop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkwvef/moved_to_a_new_house_but_brought_something_old/",
          "publishedOn": "2022-12-13T14:19:34.000Z",
          "wordCount": 16935,
          "title": "Moved to a new house, but brought something old.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkufgl/server_and_network_rackcabinetcase/",
          "author": null,
          "description": "Almost done, still missing a few details.\n    submitted by    /u/Pedroxns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkufgl/server_and_network_rackcabinetcase/",
          "publishedOn": "2022-12-13T12:23:04.000Z",
          "wordCount": 16397,
          "title": "Server and network rack/cabinet/case",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zktine/need_help_finding_documentationtips_on_how_to_use/",
          "author": null,
          "description": "submitted by    /u/5y5c0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zktine/need_help_finding_documentationtips_on_how_to_use/",
          "publishedOn": "2022-12-13T11:31:41.000Z",
          "wordCount": 17417,
          "title": "Need help finding documentation/tips on how to use this. Not sure where to start as I haven't been able to find much info on this. Would love to use this as a storage server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zksilk/my_modest_living_room_homelab/",
          "author": null,
          "description": "I live in a 2 bedroom flat. No basements, or other suitable places for a server cabinet. I also can't run ethernet cables without drilling lots of holes everywhere. The ISP's coax cable enters the flat on the corner of the living room so all the wired stuff has to live within immediate vicinity of it. \n That means I have to be very careful picking equipment - everything has to be quiet and not very hideous. Enter, my homelab:\n Not too ugly, no?\n The loudest piece here is the big NAS. Everything else is completely silent. The NAS has 12 hard disks generating a noticeable, persistent buzzing sound. Thankfully, it's only audible if the room is entirely silent. If there is anything on the TV I can't hear it at all.\n On the wireless side, most devices are on the TP-Link AP. It supports VLANs and has decent coverage. The Netgear AP only exists to deliver as fast a connection as possible to my desktop PC on the other side of the flat. More on that here.\n Overall, this is what the network map looks like:\n https://preview.redd.it/bgqugnty5n5a1.png?width=3284&format=png&auto=webp&s=094de0edad8d30f9e71ba599d499d69596987afe\n I plan on adding 5G cellular backup at some point, but overall I'm pretty happy with this setup!\n    submitted by    /u/callcifer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zksilk/my_modest_living_room_homelab/",
          "publishedOn": "2022-12-13T10:30:27.000Z",
          "wordCount": 14062,
          "title": "My modest living room homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkj6ia/im_beginning_to_think_im_developing_a_problemesp/",
          "author": null,
          "description": "submitted by    /u/AmSoDoneWithThisShit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkj6ia/im_beginning_to_think_im_developing_a_problemesp/",
          "publishedOn": "2022-12-13T02:07:20.000Z",
          "wordCount": 17247,
          "title": "I'm beginning to think I'm developing a problem....(esp knowing that storage will be at 100TB within the week)",
          "imageUrl": "https://preview.redd.it/ywwwmteopk5a1.jpg?auto=webp&v=enabled&s=f1fbbe3dbf0ae3aa0a1b323623dc0fd27269f51e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkipjw/noise/",
          "author": null,
          "description": "This is stupid I know but does anyone else get annoyed when in movies, they are in a datacenter and it’s perfectly quiet?! Like they are either whispering or not raising their voice at all\n    submitted by    /u/cwfrazier1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkipjw/noise/",
          "publishedOn": "2022-12-13T01:46:53.000Z",
          "wordCount": 14814,
          "title": "Noise",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkhsvo/water_cool_a_home_server/",
          "author": null,
          "description": "Hi everyone. I'm having a difficult time finding water cooling parts for my home server. I can't fit a radiator and pump in my server, but a separate chassis to house the radiators and pump sounds like a great solution. Does anyone know of a chassis that would work well as a dedicated water cooler? I plan to cool an Epyc 7402. That thing gets hot while processing ffmpeg. 54°C while at 20% usage. I'm afraid to allocate more cores.\n    submitted by    /u/Intelligent_Soil_442  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkhsvo/water_cool_a_home_server/",
          "publishedOn": "2022-12-13T01:07:22.000Z",
          "wordCount": 1897,
          "title": "Water cool a home server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkhkhs/3d_printed_cooler_master_n400_case_toolless_hdd/",
          "author": null,
          "description": "submitted by    /u/structuralarchitect  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkhkhs/3d_printed_cooler_master_n400_case_toolless_hdd/",
          "publishedOn": "2022-12-13T00:57:37.000Z",
          "wordCount": 15118,
          "title": "3D Printed Cooler Master N400 Case Toolless HDD Bracket",
          "imageUrl": "https://external-preview.redd.it/ue4QBuHj4k0-LDrV5P_fe3M2xEX2MhN2YlDL61ycUyY.jpg?auto=webp&s=13d2cf752a4230962a2df55c862cf52199797810"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkhhkk/dell_vrtx_blade_interoperability/",
          "author": null,
          "description": "So I've got my hands on a very nice Dell VRTX chassis slap full of drives and other shiny stuff. It has 4x M520 blades which have nice specs, but admittedly are a bit older on LGA1356 with DDR3 and I'm looking to replace the blades. I started looking into Dell's technical guidance and found where it lists M520, 620, 630, 640, 820, 830 blades as options. I found some options on ebay which are listed as PowerEdge M630 through their service tags. Looking at my blades service tags they are reported as: PowerEdge M520 (for PE VRTX). \n I don't know a lot about these VRTX Chassis other than they have some special connectivity and PCIe sharing options. That being said, is there a difference between a normal M630 blade (say from a m1000E chassis) and the M520 from the VRTX?\n    submitted by    /u/irngrzzlyadm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkhhkk/dell_vrtx_blade_interoperability/",
          "publishedOn": "2022-12-13T00:54:00.000Z",
          "wordCount": 14236,
          "title": "Dell VRTX Blade Interoperability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkfq26/nic_and_switch_advise/",
          "author": null,
          "description": "Hey guys,\n Planning on making my first homelab and need some advise.\n Got an Fujitsu FUTRO S920 as router due to this video. Got an NAS which will get RTL8125B nic in either 2.5 or 10 gb. But don't know what NIC to get for my router without breaking the bank, and ofc a good switch behind the router to plug all the devices in. My pc asus mobo already got 2.5 but could a RTL8125B nic in there aswell if needed. \n ISP currently delivers 500mbit download so could I cheap out and use 1gb ethernet port on the thinclient? Single nic's are much cheaper and easier to find than double. \n BTW: I'm thinking of running OpenWrt on the thinclouter/router.\n Would appreciate some suggestion and or tips :)\n    submitted by    /u/itz_game_pro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkfq26/nic_and_switch_advise/",
          "publishedOn": "2022-12-12T23:41:10.000Z",
          "wordCount": 14212,
          "title": "NIC and Switch advise",
          "imageUrl": "https://external-preview.redd.it/NVeSSuFiud1Ksr4aFb9TkkZVaRakPwyl9QnnzbXWQD4.jpg?auto=webp&s=8b045f8c14b69704ef9e88d05d9aa58a7ce772d9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkeuek/how_to_set_docker_container_a_static_ip_andor/",
          "author": null,
          "description": "I want to either the docker container to have a separate IP or separate hostname from the server it is running on. Ex. server is server.local/192.169.1.2 and want the container be container.local/192.169.1.3.\n I see that docker allows you to set the ip for docker's internal networks, but is it possible to be done this way? It is similar to Virtualbox/vmware bridged connection compared to NAT.\n    submitted by    /u/Clawkikker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkeuek/how_to_set_docker_container_a_static_ip_andor/",
          "publishedOn": "2022-12-12T23:06:42.000Z",
          "wordCount": 16409,
          "title": "How to set docker container a static IP and/or hostname on host network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkegf2/best_way_to_begin_segmenting_network_into_vlans/",
          "author": null,
          "description": "Kinda title, but I have a entirely flat network today, NVR Cameras have their own device which controls them, but their management is on the same flat network with the addition of the 50 some VMs that live in my env.\n What is the best way to begin segmenting all these items and getting to a point where I have an IOT network, management network etc?\n    submitted by    /u/Anti_Alphabet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkegf2/best_way_to_begin_segmenting_network_into_vlans/",
          "publishedOn": "2022-12-12T22:51:59.000Z",
          "wordCount": 14510,
          "title": "Best way to begin segmenting network into VLANs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkeg2x/idrac_service_module_v4300_for_ubuntu_2204/",
          "author": null,
          "description": "I have a Dell PowerEdge T330 that I am running Ubuntu 22.04 LTS (Jammy) on, and of course Dell in their standard lack of consideration for Linux users by dragging their feet on updating the ISM software to support current versions, so I decided to research and figure out how to get it installed onto the system myself. Versions given in example are current as of when I did the installation. \n And now, on to the instructions!\n  \nDownload & install libssl1.1:\n  \n​\n cd ~ && wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.16_amd64.deb sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2.16_amd64.deb wget https://dl.dell.com/FOLDER08657945M/1/OM-iSM-Dell-Web-LX-4300-2781_A00.tar.gz tar -xvzf OM-iSM-Dell-Web-LX-4300-2781_A00.tar.gz --one-top-level \n  \nEdit the Installation Script:\n  \n​\n nano ./OM-iSM-Dell-Web-LX-4300-2781_A00/setup.sh \n  \nChange setup.sh line 294 from 20 to 22, and save file:\n  \n​\n if [ \"$OS\" == \"Ubuntu\" ] && [ \"$VER\" == \"22\" ]; then \n  \nFinally, run the setup script, I went ahead and selected 10 (install everything):\n  \n​\n sudo bash setup.sh \n Primary sources of my information:\n https://www.dell.com/support/home/en-us/drivers/driversdetails?driverid=2pk7t&oscode=us008&productcode=poweredge-t330\n https://www.reddit.com/r/homelab/comments/gmln6q/idrac_service_module_ubuntu_2004/\n https://ubuntuforums.org/showthread.php?t=2480893\n *Use of this information is at your own risk. I will not be held liable in the event of any issues or problems that may occur. Be sure to do your OWN due diligence before starting on this project, and do not proceed if you do not feel comfortable working on your system!\n **Please note, this requires you to install libssl1.1, which has been depreciated on 22.04 and you must download it from a previous version repository.\n    submitted by    /u/wb6vpm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkeg2x/idrac_service_module_v4300_for_ubuntu_2204/",
          "publishedOn": "2022-12-12T22:51:40.000Z",
          "wordCount": 14310,
          "title": "iDRAC Service Module v4.3.0.0 for Ubuntu 22.04",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zke40j/advice_for_homelab_server_rack_or_standard/",
          "author": null,
          "description": "Hey, I am trying to figure out for weeks what and how I want to start my Homelab Journey.\n What I basically want to do is to setup a Kubernetes Cluster able to manage some services I want to publish online.\n Virtualisation would be preferred because I don't want to setup 3+ Machines to run K3S on it when I can do it on only one physical machine (well my wife probably would kill me if I but 3 more machines)\n If you go for a complete Server Build: what would you recommend? (I will probably Build it from scratch since I don't have the money to buy it at once)\n If it's a consumer build? What CPU and Mainboard do you recommend? (Power Consumption should not be high!)\n    submitted by    /u/ToxicalToast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zke40j/advice_for_homelab_server_rack_or_standard/",
          "publishedOn": "2022-12-12T22:39:18.000Z",
          "wordCount": 16450,
          "title": "Advice for Homelab Server - Rack or Standard Desktop? Consumer or Enterprise Hardware?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkdvkv/lil_guy_is_running_nextcloud_jellyfin_and_a/",
          "author": null,
          "description": "submitted by    /u/Oha_der_erste  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkdvkv/lil_guy_is_running_nextcloud_jellyfin_and_a/",
          "publishedOn": "2022-12-12T22:31:08.000Z",
          "wordCount": 14848,
          "title": "Lil guy is running Nextcloud, Jellyfin and a minecraft Server on Proxmox",
          "imageUrl": "https://preview.redd.it/kz38y9a9nj5a1.jpg?auto=webp&s=8c605f89bf5f2efb8f55b7091eb10e205c278424"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkdm37/can_i_set_asus_4gac68u_ltemodemrouter_into_bridge/",
          "author": null,
          "description": "I have Asus 4G-AC68U LTE modem/router. It's half ok for my needs, but it's PITA to reset/change settings compared to RT-AC68U router with Asuswrt-Merlin firmware. I used to have some Huawei LTE modem in bridge mode for the router, but it died awhile ago.\n So is there any way (that I'm missing) to set Asus 4G-AC68U to bridge mode, so RT-AC68U router sees internet and acts as sole router?\n ​\n Bonus question:\n Having OpenVPN server on router, and connecting from mobile (not in home WLAN) to router via VPN to access LAN from outside, how safe is it taken account that the phone isnt' lost.\n    submitted by    /u/Maximum-Avocado856  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkdm37/can_i_set_asus_4gac68u_ltemodemrouter_into_bridge/",
          "publishedOn": "2022-12-12T22:22:05.000Z",
          "wordCount": 14100,
          "title": "Can I set Asus 4G-AC68U LTE-modem/router into bridge mode for Asus RT-AC68U router?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkdc7t/if_you_thought_about_making_your_own_35_dell/",
          "author": null,
          "description": "My last post was of the Dell NotAPowerEdge R404 hard drive enclosure. It seemed that a good amount of people enjoyed my creation and now I'd like to share it with those who want to make their own. The STL files are now available on thingiverse. https://www.thingiverse.com/thing:5702969/files\n https://preview.redd.it/18s9rnqzjj5a1.png?width=923&format=png&auto=webp&s=4f5c5eed3e28c9bf6c552e02b50c1a7f521e48b4\n    submitted by    /u/ngarret  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkdc7t/if_you_thought_about_making_your_own_35_dell/",
          "publishedOn": "2022-12-12T22:12:56.000Z",
          "wordCount": 14616,
          "title": "If you thought about making your own 3.5\" dell caddy enclosure.",
          "imageUrl": "https://external-preview.redd.it/fmBOOcHShdUiIsvLiAWj5pp_sPyYQRPpiX_ozn9HkZs.jpg?auto=webp&s=9d4fa6b02e908b22bba5f9ab9e70cfc6da77ae7b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkct4t/fist_server_advice_hp_z820_or_dell_pe_r720/",
          "author": null,
          "description": "First time posting, looking for advice on a first serious server build project. I currently run a media server out of an old windows tower but it's just a full desktop that runs the media server on the side. I want to have a true server that does dedicated tasks. In this case run a Plex server and VM sandbox for professional development.\n I picked up an z820 for a deal and initially was looking to upgrade it to work as a media/sandbox learning server but I'm wondering if it's the best long term option.\n These are the stats of the hardware it came with and what I (pie in the sky) imaged to build it to:\n Hardware as I bought:\n  \n CPU Intel Xeon E5-2630 V2 ST1AM 2.60Ghz MALAY J527C615 \n  \n RAM 8 x 8GB PC3-14900R DDR3-1866MHz ECC REDG 240-Pin DIMM, 4 x 4GB PC3-14900R DDR3-1866MHz ECC REDG 240-Pin DIMM \n  Disk Space 2 x 120 GB SSD \n  Motherboard HP Dual LGA2011 16 RAM memory slots, SAS & SATA connections REV: 1.03 \n  Graphics Card NVIDIA Quadro K600 1GB DDR3 \n  PCIe Cards included NVIDIA TESLA K40, Siemens PETLink Stream Buffer Model: 10251412 \n \n ​\n Ideal Build:\n  \n CPU Intel Xeon E5-2697 v2 x2 \n  \n RAM 128GB DDR3 RECC \n  Disk Space 8 x 8TB SAS drive (RAID 10 to maximize performance and fail tolerance) \n  Graphics Card Nvidia GeForce 2080ti \n \n -Ability to extend storage to a JBOD enclosure\n With all that said. I'm wondering if, for the sake of a long term build, I should just sell it for parts and look for an r720/r720xd to fill it in with less overall footprint? Or is there a better option to consider?\n    submitted by    /u/Azrael5W02D  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkct4t/fist_server_advice_hp_z820_or_dell_pe_r720/",
          "publishedOn": "2022-12-12T21:54:00.000Z",
          "wordCount": 14769,
          "title": "Fist server advice: HP z820 or Dell PE r720?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkcbl6/downgrading_home_lab/",
          "author": null,
          "description": "Hi,\n i currently have a DELL T7910 with\n  \nDual Xeon 2640v4 (10c 20t)\n 128Gb ram\n Nvidia M2000\n 4x 512GB Nvme's in a Dell Ultra-Speed Drive Quad NVMe M.2 PCIe card\n 2x 3TB Ironwolfs\n 2x 6TB WD Reds\n  \nas my home server / Lab.\n I am thinking about selling it and change for something that consumes a bit less power then this setup, currently is consuming about 160w idle.\n I was thinking in changing it for a couple of DELL Optiplex 3060 with i5-8500T 32GB ram, both of them would run proxmox, with 4/5 VM's on them.\n One would be more dedicated to media the other more for learning. the VM's that i would run are some linux server, with docker containers and a windows server acting as a Domain controler.\n Do you guys think that it would be a good change or not?\n Thanks in advance.\n    submitted by    /u/supertostaempo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkcbl6/downgrading_home_lab/",
          "publishedOn": "2022-12-12T21:36:42.000Z",
          "wordCount": 15650,
          "title": "Downgrading home lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkb2is/home_freeradius_lab_cheap_router_with/",
          "author": null,
          "description": "I am trying to set up a RADIUS server on a home lab and am looking for a cheap WPA2-Enterprise capable wireless router. Having WPA3 would be nice as well but it isn't a requirement.\n Does anyone have any recommendations?\n    submitted by    /u/Practical_Bathroom53  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkb2is/home_freeradius_lab_cheap_router_with/",
          "publishedOn": "2022-12-12T20:51:55.000Z",
          "wordCount": 15503,
          "title": "Home FreeRadius Lab - Cheap Router with WPA2-Enterprise?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zk8pcq/is_hardware_raid_still_a_viable_option_in_2022/",
          "author": null,
          "description": "I have multiple enterprise-grade rack mount servers with SAS RAID controllers (such as PERC H710, and P440). I'm just adding this to emphasize that I already have the hardware, and all controllers have a decent sized BBU-backed cache.\n The vast majority of the data is stored on Kingston DC series SSDs.\n Recently, I have heard multiple opinions saying that using hardware RAID with non-SAS drives has no benefits.\n Reasons in a nutshell:\n  \nSAS drives have(/had?) 520 byte sectors, so that they can store an 8-byte checksum alongside the 512-byte sector, with SSD drives lacking that, the controller doesn't have a reliable way to detect issues\n most controllers don't use SMART data to predict SSD failure\n it's more difficult to monitor drive failures if the controller hides the physical drives from the OS)\n moderately modern CPUs have no difficulty calculating parity, even at high IO load, and high speeds\n  \nWhat do you think? Are there any benefits to using a hard RAID as opposed to switching the controller to HBA mode and configuring soft RAID provided by the OS (be it MD/LVM in Linux, or Windows with the classic, drive-level RAID or Storage Spaces)?\n    submitted by    /u/OstentatiousOpossum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zk8pcq/is_hardware_raid_still_a_viable_option_in_2022/",
          "publishedOn": "2022-12-12T19:26:25.000Z",
          "wordCount": 19091,
          "title": "Is hardware RAID still a viable option in 2022?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zk4mho/my_home_lab_progression/",
          "author": null,
          "description": "submitted by    /u/jacobnoori  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zk4mho/my_home_lab_progression/",
          "publishedOn": "2022-12-12T17:00:55.000Z",
          "wordCount": 14410,
          "title": "My Home Lab Progression",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjzmw8/pc_as_first_homelab_server/",
          "author": null,
          "description": "Hi! I'm at the beginning of my homelab journey. I have Raspberry Pi 3 B+ and I have started with some docker containers there. I would like to make step forward and begin with virtualization (experiment with pfsense, networking, guacamole, AD, docker, maybe build small NAS). We rent small flat with my girlfriend and we don't have enough place for rack mounted server or even tower server (She said that 😅). I have an idea to buy PC and use it as first server, and I look for advice.\n My requirements:\n - small and silent,\n - not expensive in reference to power consumption,\n - able to run about 3-5 virtual machines simultaneously and some docker containers,\n - allow to build NAS with that. \n Options which I found, all of them fulfill requirements of size to my flat (sorted from the cheapest one):\n 1. HP EliteDesk 800 G2 Tiny i7-6700T (4x2,8-3,6GHz / 8 threads / 8MB) 16GB 512GB SSD SATA - only 16GB of RAM and probably need to update from 2x8GB to 2x16GB in the future.\n 2. HP Z240 SFF i7-6700 (4x3,4-4,0GHz / 8 threads / 8MB) 32GB 480GB SSD SATA\n 3. Dell OptiPlex 7040 SFF i7-6700 (4x3,4-4,0GHz / 8 threads / 8MB) 32GB 500GB SSD NVMe <- think that it would be the most suitable, but I could be wrong :)\n 4. DELL PRECISION T3420 Xeon E3-1240 v5 (4x3,6-3,9Ghz / 8 threads / 8MB) 32GB 256GB SSD NVMe Nvidia Quadro K1200 - unnecessary graphic's card - I think, but Xeon on board.\n 5. HP Z2 MINI G3 Xeon E3-1225 v5 (4x3,3-3,7GHz / 4 threads / 8MB) 32GB 256GB SSD PCIe Nvidia Quadro M620 2GB GFX - again, unnecessary graphic's card, but I really like design :) \n Thank you in advance :)\n    submitted by    /u/ddavid09  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjzmw8/pc_as_first_homelab_server/",
          "publishedOn": "2022-12-12T13:49:59.000Z",
          "wordCount": 17985,
          "title": "PC as first homelab server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjsroi/wake_on_lan_works_on_25gbps_moca_to_ethernet/",
          "author": null,
          "description": "submitted by    /u/FamiliarMulberry2992  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjsroi/wake_on_lan_works_on_25gbps_moca_to_ethernet/",
          "publishedOn": "2022-12-12T08:38:06.000Z",
          "wordCount": 16248,
          "title": "Wake on Lan? works on 2.5Gbps MoCA to Ethernet Adapter? Asus MA-25",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjrwwl/update_2_my_first_rack_ever/",
          "author": null,
          "description": "submitted by    /u/johnnybegood320  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjrwwl/update_2_my_first_rack_ever/",
          "publishedOn": "2022-12-12T07:58:09.000Z",
          "wordCount": 16514,
          "title": "UPDATE 2: My first rack ever",
          "imageUrl": "https://preview.redd.it/3h22z3e1tg5a1.jpg?auto=webp&s=23defa2a8c918467e1deb3430ce9bf7f46a4f734"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjj8q5/installing_your_kubernetes_homelab_cluster_in/",
          "author": null,
          "description": "For anyone looking to get Kubernetes going in their homelab, I created a guide at Installing your Kubernetes homelab cluster in minutes with Ansible.\n I tried to take a different approach them other guides out there by focusing more on using config as code practices and automating much of the install using ansible and terraform.\n The previous parts of the series focus on installing vmware vsphere 8 and using terraform to create all the virtual machines that kubernetes gets installed on.\n I have been using this process over the last year or two for my own homelab cluster so figured I'd clean up my notes, create a blog, and see if anyone else finds it helpful.\n Let me know what you think so I can try to make the content better.\n    submitted by    /u/tknp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjj8q5/installing_your_kubernetes_homelab_cluster_in/",
          "publishedOn": "2022-12-12T02:08:45.000Z",
          "wordCount": 15933,
          "title": "Installing your Kubernetes homelab cluster in minutes with Ansible",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zji19r/trying_to_finish_my_new_homes_networking_how_do_i/",
          "author": null,
          "description": "submitted by    /u/lokikaraoke  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zji19r/trying_to_finish_my_new_homes_networking_how_do_i/",
          "publishedOn": "2022-12-12T01:26:31.000Z",
          "wordCount": 14397,
          "title": "Trying to finish my new home's networking, how do I hook up to this thing?",
          "imageUrl": "https://preview.redd.it/8fehuanddd5a1.jpg?auto=webp&s=f6fa678008c7d248139309b42c80ab4f46586c7a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjhzwj/building_first_home_server_and_looking_for_advice/",
          "author": null,
          "description": "Hi all! I'm a college student studying IT, and I'd like to build a home server since I currently just have a laptop I use for school. I haven't completely decided all the things I'd like to host on this server, but I know at the very least I'd like to use it as a 24/7 Jellfyin/multimedia server and NAS, along with the capability to run other VMs and containers. The OS would be Unraid or another Linux distro.\n I also want it to be small and as power efficient as possible. Here's my current parts list for this build:\n  \nCPU: Intel Core i3-12100 ($124)\n CPU Heatsink: Noctua NH-L9i-17xx ($45)\n Mobo: ASRock B660M-ITX/AC ($120)\n Memory: G.SKILL Ripjaws V Series 32GB (2 x 16GB) DDR4 RAM ($80)\n Boot Drive: SAMSUNG 970 EVO PLUS M.2 2280 500GB ($67)\n Storage: 3x WD Red 4TB NAS ($210)\n Case: Fractal Design Node 304 ($99)\n PSU: FSP 450W Mini ITX Solution ($80)\n  \nThis is the first computer I've built as a server (rather than for gaming), so any thoughts/suggestions are greatly appreciated. I'm also not against getting anything pre-built, so I'm happy to hear about any alternatives as well.\n    submitted by    /u/plzwakeupmrwest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjhzwj/building_first_home_server_and_looking_for_advice/",
          "publishedOn": "2022-12-12T01:25:11.000Z",
          "wordCount": 14249,
          "title": "Building First Home Server and Looking For Advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjh6lv/subdomains_with_adguard_home/",
          "author": null,
          "description": "Hey everyone,\n I've playing around with my Raspberry Pi and have AdGuard Home running on it. I also have grafana, portainer, NPM, etc... I've added a DNS Rewrite to server.pi to my internal IP (192.168.1.3), but I wanted to add subdomains, for instance if I search \"grafana.server.pi\" it would redirect to my grafana page. I've already added the proxy host on NPM, but I think the problem is related to AdGuard. Has anyone tried something like this and can point me in the right direction? Thanks :)\n    submitted by    /u/LogRepresentative301  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjh6lv/subdomains_with_adguard_home/",
          "publishedOn": "2022-12-12T00:56:47.000Z",
          "wordCount": 14038,
          "title": "Subdomains with Adguard Home",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjg98x/nic_drivers_for_vmware_esxi_installer/",
          "author": null,
          "description": "submitted by    /u/sudo_96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjg98x/nic_drivers_for_vmware_esxi_installer/",
          "publishedOn": "2022-12-12T00:25:26.000Z",
          "wordCount": 14219,
          "title": "Nic drivers for vmware esxi installer",
          "imageUrl": "https://external-preview.redd.it/aLff-Ur6YOlxf-OEz45e7UEmi6Fm-taEHmHQxXcnpzg.jpg?auto=webp&s=5d091f1b0293d9fe5317c5645c1cf7c98b3c9e22"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjfasu/my_homelab_work_in_progress/",
          "author": null,
          "description": "Here’s a photo of my homelab. She’s a work in progress. Any suggestions? Thanks\n My Homelab\n    submitted by    /u/Bosfit89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjfasu/my_homelab_work_in_progress/",
          "publishedOn": "2022-12-11T23:54:36.000Z",
          "wordCount": 13927,
          "title": "My homelab, work in progress.",
          "imageUrl": "https://external-preview.redd.it/myziqHbAGpuozdGzwfBg94yKvEhaH7yclgnnFFlxIsg.jpg?auto=webp&s=0665d78e793744c9081ac2e6ddb35d4a4c819bd4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjej3d/another_debian_vs_ubuntu_server_decision/",
          "author": null,
          "description": "So, yeah, another \"Debian vs. Ubuntu\" thread. I'm asking because a lot of the threads I'm finding are many years old where I guess Ubuntu peeved some people and they moved away from them to Debian. I also know that people generally think Debian is more stable but, again, those threads were quite old. I don't really know if thats much the case anymore.\n Right now, I have a mix of Debian and Ubuntu containers in Proxmox but I want to standardize on one. I'm leaning towards Ubuntu Server for one reason: I have no idea why, but apt update and apt upgrade on my Debian containers is painfully slow. I mean, REALLY slow. I've tried everything and just can't figure out why.\n Another reason I'm leaning towards Ubuntu is because of commercial support. Obviously, I don't need commercial support at home but if we start migrating some services at work to Linux (which I think we may), I'm sure management would want to go with the distro that offers support. I'd prefer to use at work what I'm familiar with at home.\n Other than that, is there any other reason I should stick with Debian that I'm missing?\n    submitted by    /u/IndyPilot80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjej3d/another_debian_vs_ubuntu_server_decision/",
          "publishedOn": "2022-12-11T23:29:46.000Z",
          "wordCount": 15653,
          "title": "Another \"Debian vs. Ubuntu Server\" Decision",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjb975/looking_for_a_good_cloud_service_that_supports/",
          "author": null,
          "description": "I currently use Dropbox when I need a file to quickly sync and frequently update between devices. Right now, I use CopyQ (a cross platform clipboard manager with sync). The clipboard data is stored on dropbox, which updates between devices pretty quickly. I'm looking for an alternative to Dropbox because it's starting plan is too expensive for my usage ($10 / month). Does anyone know of any reliable cloud services that will sync as frequently as Dropbox?\n    submitted by    /u/Antoniopapp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjb975/looking_for_a_good_cloud_service_that_supports/",
          "publishedOn": "2022-12-11T22:03:38.000Z",
          "wordCount": 14283,
          "title": "Looking for a good cloud service that supports lan sync",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjav0j/completely_new_to_home_lab_in_general/",
          "author": null,
          "description": "Hey everyone, Im trying to do something of the following. ISP -> Modem -> 1a Router -> 2b Routers/separate networks -> 8 port Switchs coming off both \n 1a is going to be my Main router with incoming speeds of 2.5 gigs. Is there any way to maintain network separation and still get 2.5 gigs to the other 2b Routers? I was informed VLANS was one, but I have an ASUS ax5700 Router atm and Im unsure where the options to create vlans in the webgui. \n Any assistance is appreciated, if there are other ways to do this, please let me know. I was also informed OPNsense would do exactly what I am trying to do, but I am unclear on how to setup\n    submitted by    /u/blkguylethal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjav0j/completely_new_to_home_lab_in_general/",
          "publishedOn": "2022-12-11T21:53:38.000Z",
          "wordCount": 14802,
          "title": "Completely new to home lab in general!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjakx7/home_lab_nice_rack_filled_with_a_desktop_system/",
          "author": null,
          "description": "bouough the rack to downsize, got a z440 and a pi4 and a couple desktops for NAS and a pfsense box. Am not normal.... I use less power than the z440 alone\n    submitted by    /u/Due_Adagio_1690  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjakx7/home_lab_nice_rack_filled_with_a_desktop_system/",
          "publishedOn": "2022-12-11T21:46:28.000Z",
          "wordCount": 13962,
          "title": "home lab, nice rack filled with a desktop system and a shelf.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjabev/best_place_to_get_ups_batteries/",
          "author": null,
          "description": "Hi All,\n It has come time again to get new UPS batteries for my APC & Triplite UPS's\n Where have you guys got good-quality batteries?\n    submitted by    /u/KevinSoutar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjabev/best_place_to_get_ups_batteries/",
          "publishedOn": "2022-12-11T21:39:48.000Z",
          "wordCount": 14027,
          "title": "Best place to get UPS Batteries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj89xu/new_build_ex_server_or_what/",
          "author": null,
          "description": "Hey\n ​\n I used to have a pentium 6500 ,12GB DDR4, 10TB HDD as my homeserver, sold it and for the last two years I used my gaming PC to complete these tasks;\n Plex, 2x Linux VM running in hyperv.\n ​\n I don't have a problem to be honest with this, apart from that I hate hearing the HDD noise next to me and the 3x ethernet cables it runs out. So I decided, I would like to have a little homeserver , again.\n This time, I looked around and I have seen that I only need Plex to be able to run (no transcoding, everything is in 1080p and my upload is 150mbit/s, only 2 people use it)\n The VMs are: DNS and webserver, both only run very little traffic.\n I would love to listen to suggestions, as Synology is horrible priced, I would like to keep this a super small form factor(HP Prodesk g4??? or mac mini (this would be my favourite tbh, but I don't like the fact that I would need to use USB for the 3.5 HDD) \n Then, I have come across used Proliant gen9 servers. I mean, they seem to be percfect. Apart from that they are outdated, I could probably run proxmox or unraid on them, allocate cores and memory properly and completetly avoid using windows (this would be another big point for me) \n Oh and my budget is maximum £250.(used or new) \n On my previous, I ran Windows and I hated it, Windows for me is only for gaming.\n    submitted by    /u/Bolyki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj89xu/new_build_ex_server_or_what/",
          "publishedOn": "2022-12-11T20:50:39.000Z",
          "wordCount": 14953,
          "title": "New build (ex server or what?)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj54qg/my_rack/",
          "author": null,
          "description": "R410: minecraft host R200: VPN R510: VM host HP DL320e: Kali Linux box R710: back up nas I removed the jbod Dell Poweredge 2900 is my main NAS.\n    submitted by    /u/Pootis_overlord  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj54qg/my_rack/",
          "publishedOn": "2022-12-11T19:29:28.000Z",
          "wordCount": 13960,
          "title": "My Rack",
          "imageUrl": "https://preview.redd.it/j0xutcrg3d5a1.jpg?auto=webp&s=2a5ecb9be3858880952340fce1285b9459b13b61"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj3uma/finally_got_a_rack_now_to_fill_it/",
          "author": null,
          "description": "submitted by    /u/RedTermSession  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj3uma/finally_got_a_rack_now_to_fill_it/",
          "publishedOn": "2022-12-11T18:54:26.000Z",
          "wordCount": 14423,
          "title": "Finally got a rack. Now to fill it.",
          "imageUrl": "https://preview.redd.it/k9f9079jfb5a1.png?auto=webp&s=1d847c78588e08901d78c85402036dad25c439ea"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj3a63/new_rackmountable_ups/",
          "author": null,
          "description": "Finally had my UPS die on me. It was one I got for free many years ago. It worked, but didn't have many features.\n I'd like to replace it with a UPS that I can mount in my rack and monitor/manage from my network/computer. I'd also like to get a top-of-rack power strip that I can monitor/manage from my network/computer.\n What are my options?\n I presently have a Netgear Modem, UDM Pro, Ubiquiti AP, Ubiquiti 8 Port Switch, and Synology NAS in the rack. I plan on getting a server sometime in the future.\n    submitted by    /u/MainStudy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj3a63/new_rackmountable_ups/",
          "publishedOn": "2022-12-11T18:39:14.000Z",
          "wordCount": 14749,
          "title": "New Rackmountable UPS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj0pk2/thinking_of_switching_to_thin_clients/",
          "author": null,
          "description": "I currently have 5 Raspberry Pis in my rack doing various things (Home Assistant, lighter Docker containers, reverse proxy, vpn, PiHole, etc.) and am thinking about swapping them out to a thin client or two. I want to try my hand with Proxmox as a hypervisor (possibly try my hands as a cluster).\n I have been doing a bit of research and found that the main contenders seem to be Lenovo ThinkCentre/ThinkStation, HP EliteDesk/Prodesk, and Dell Micro. The STH article that is getting passed around is a couple of years old and does not look to be updated with any newer recommended models.\n Do you all think that it would be worth swapping out most of my Raspberry Pis for a couple of thin clients? If so, what models should I be looking for? Mainly looking for a good balance between power and performance while being hopefully on the cheaper side. Again, I will hopefully be playing around with Proxmox as a cluster.\n    submitted by    /u/liltrublmakr56  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj0pk2/thinking_of_switching_to_thin_clients/",
          "publishedOn": "2022-12-11T17:29:11.000Z",
          "wordCount": 15341,
          "title": "Thinking of switching to thin clients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ziz9j9/nvr_questions/",
          "author": null,
          "description": "So upon reading up on security cameras with dvr and nvr, I really want to go the nvr route.\n I'm looking at either lorex or night owl.\n My question is if I have the nvr base in my rack, do my cameras need t9 connect directly to it or can I utilize existing wall Jack's? I know I'll need poe.\n My goal is an NVr box that can take ip cameras and wireless.\n I'm also open to non wyze suggestions lol.\n    submitted by    /u/eagle6705  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ziz9j9/nvr_questions/",
          "publishedOn": "2022-12-11T16:50:14.000Z",
          "wordCount": 14234,
          "title": "NVR questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zixkqe/powering_on_server_once_a_week_for_truenas/",
          "author": null,
          "description": "I know this topic comes up often but my situation is a little different. I have four servers total running in my rack and two of them are TrueNAS boxes. One is simply being used as a backup (replication) so I was wondering instead of running this server 24/7, why not power it off and have it turn on once a week, replicate and shutdown? Seems reasonable enough. \n Any downsides other than not having replication running more often? At 325w being drawn at 0.33 cents is around $77 a month for me. I know my wattage is rookie numbers considering what others here are running.\n    submitted by    /u/chench0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zixkqe/powering_on_server_once_a_week_for_truenas/",
          "publishedOn": "2022-12-11T16:02:16.000Z",
          "wordCount": 15021,
          "title": "Powering ON server once a week for TrueNAS replication? (to save on electricity)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zixbac/need_help_with_vm_enviorment/",
          "author": null,
          "description": "I recently setup a VM in virtual box, to create a domain controller and run server 2019 on it. I’m using a windows desktop so I am not able to download the iso that’s needed for the client VM to connect to the domain. How would I acquire an iso to attach to the client. It’s only giving me options to upgrade or download the instillation media. For reference I’m watching Josh madakors powershell home lab tutorial and at about the 47 minute mark is where I’m stuck. Where you have to add the iso to the client. Any feedback would be really helpful! video\n    submitted by    /u/Agitated-Tradition81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zixbac/need_help_with_vm_enviorment/",
          "publishedOn": "2022-12-11T15:54:57.000Z",
          "wordCount": 14638,
          "title": "Need help with VM enviorment",
          "imageUrl": "https://external-preview.redd.it/Ns-NZUII343dKLBQO5nOIqyMgyf3vHS9vmb24sl7XY0.jpg?auto=webp&s=d0f45741e925b9c3075cb2a5da7af1cc0ac3ee53"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ziw5w0/i_saw_one_of_yall_in_the_wild_today/",
          "author": null,
          "description": "submitted by    /u/SeldomRomantic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ziw5w0/i_saw_one_of_yall_in_the_wild_today/",
          "publishedOn": "2022-12-11T15:21:34.000Z",
          "wordCount": 14805,
          "title": "I saw one of y’all in the wild today.",
          "imageUrl": "https://external-preview.redd.it/JCjD2xiO-DR8HXqvCEFc94vMvR9YF61tLHWjUX90pS0.jpg?auto=webp&s=caf16288b583c0c57d4da029a1eeb818fd208999"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ziugm8/onpremise_cloud_gaming/",
          "author": null,
          "description": "submitted by    /u/cloudy_gamer_1383  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ziugm8/onpremise_cloud_gaming/",
          "publishedOn": "2022-12-11T14:37:18.000Z",
          "wordCount": 14375,
          "title": "On-premise 'cloud' gaming?",
          "imageUrl": "https://external-preview.redd.it/1LuV12jkRaY5Ws05OrguPGlmy3euDPvK6GZ1vNSENs0.jpg?auto=webp&s=29b0a5ab88111bb6ca47e27f1e2982fdfb92dfee"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zipwbf/total_run_time_1368_years_246_days_world/",
          "author": null,
          "description": "Total run time: 1,368 years 246 days -- World Community Grid Homelab team stats for Sunday, 12/11/2022\n  \nCurrent Members 249 (#33 in the world)\n Total Run Time (y:d:h:m:s) (Rank) 1368:246:17:39:20 (#146)\n Points Generated (Rank) 2,341,198,829 (#127)\n Results Returned (Rank) 3,819,799 (#132)\n  \nHomelabbers who have joined the Homelab team and are processing datasets for World Community Grid are working on the following projects:\n  \n Project Points Generated Results Returned Total Run Time (y:d:h:m:s) \n  \n OpenPandemics - COVID-19 436,172,461 652,605 204:235:10:58:59 \n  Africa Rainfall Project 28,750,573 6,638 15:177:17:28:32 \n  Help Stop TB 2,624,907 1,068 1:237:01:20:12 \n  Mapping Cancer Markers 1,323,628,778 1,847,385 842:072:15:04:52 \n  Beta Testing 588,775 966 0:125:19:17:04 \n  Microbiome Immunity Project 233,228,063 555,814 126:303:09:50:12 \n  OpenZika 56,754,339 148,682 27:023:07:53:07 \n  FightAIDS@Home - Phase 2 75,951,773 100,228 50:357:19:14:52 \n  Outsmart Ebola Together 61,922,110 115,152 29:077:20:37:22 \n  FightAIDS@Home 4,068,979 67,396 2:152:07:48:41 \n  Smash Childhood Cancer 117,508,071 323,865 67:308:08:05:27 \n \n Join the Homelab team here: \n (if you already participate in World Community Grid)\n https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n (if you are new to World Community Grid)\n https://join.worldcommunitygrid.org?teamId=124DTPZ682\n Link to team statistics: https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n    submitted by    /u/homelabber12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zipwbf/total_run_time_1368_years_246_days_world/",
          "publishedOn": "2022-12-11T12:22:46.000Z",
          "wordCount": 18340,
          "title": "Total run time: 1,368 years 246 days -- World Community Grid Homelab team stats for Sunday, 12/11/2022",
          "imageUrl": "https://external-preview.redd.it/wIj6ygk01ih8oIHxFRQ6FPPWByQkwZHSYkhAwFSPi5g.jpg?auto=webp&s=695923a3c1648c33a1135adf2092e5d80a1fa37d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ziord5/really_small_homelab/",
          "author": null,
          "description": "submitted by    /u/diesus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ziord5/really_small_homelab/",
          "publishedOn": "2022-12-11T11:35:18.000Z",
          "wordCount": 14907,
          "title": "Really Small Homelab",
          "imageUrl": "https://preview.redd.it/12povzyuqa5a1.jpg?auto=webp&s=c567021fe9f9a096ef275dc27be23ecfd0e805f1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zia2qg/what_ethernet_nics_are_you_using_on_esxi_8/",
          "author": null,
          "description": "Has anybody upgraded their servers and swapped out for a dual or quad port NIC that works?\n Looking for something I can pickup, doesn't need to be 10GB\n    submitted by    /u/silver565  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zia2qg/what_ethernet_nics_are_you_using_on_esxi_8/",
          "publishedOn": "2022-12-11T01:37:01.000Z",
          "wordCount": 13947,
          "title": "What ethernet NICs are you using on ESXi 8?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi9gan/my_new_home_server_used_for_virtualization/",
          "author": null,
          "description": "submitted by    /u/renegdewolf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi9gan/my_new_home_server_used_for_virtualization/",
          "publishedOn": "2022-12-11T01:10:33.000Z",
          "wordCount": 15292,
          "title": "my new home server used for virtualization testing, studying for certifications and remote work. my new home server/Lab Asus tuf white edition I7 13700 overclocked to 5.4 MSI PRO Z790P Coolermaster Pl360 flux gskill trident 32gb 4800 corsair rm850 crucial bx500 1tb for os Win 11 Pro 2 6tb WD bl",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi9690/cisco_switch_on_isp_modem/",
          "author": null,
          "description": "Hey guys - I've just purchased a gigabit Cisco 3560, I'd like to try and build a homelab in the future whilst also learning Cisco kit. Ideally, I get a pfSense/OPNSense router feeding the switch, but this will have to wait until I can source some well-priced hardware.\n Right now, I only have the router my ISP provided me with. Is it possible to connect a Cisco managed switch to an ISP router? I (at the moment) don't have any other way of providing IP addresses, other than this router which acts as an AP as well as DNS/DHCP server. \n Total newbie - any advice is well received. Thank you.\n    submitted by    /u/Poots0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi9690/cisco_switch_on_isp_modem/",
          "publishedOn": "2022-12-11T00:58:23.000Z",
          "wordCount": 14091,
          "title": "Cisco Switch on ISP modem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi8vd9/power_company_accidentally_cut_my_fiber_line_from/",
          "author": null,
          "description": "submitted by    /u/scd31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi8vd9/power_company_accidentally_cut_my_fiber_line_from/",
          "publishedOn": "2022-12-11T00:44:33.000Z",
          "wordCount": 14292,
          "title": "Power company accidentally cut my fiber line from the road. ISP isn't fixing it until Monday at the earliest. Packed up the important servers and redeployed at my girlfriend's house",
          "imageUrl": "https://external-preview.redd.it/_AQ38GbrVfJ1EI4y4JtHosQZjnA49oQwjL4eJtQUjgU.jpg?auto=webp&s=eff410e22a3cf4ec3eb55881c35b2f4ecc62d069"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi7fge/dell_r720_bootingdisplay_issues/",
          "author": null,
          "description": "I have a dell r720 that I'm having issues setting up/booting.\n The system powers on when the power button is pressed and the front LCD panel says \"System Booting\" but there is no video output on either the front or back VGA ports. I have tested my VGA cable and monitor on my other r720 and it works. I have also done a NVRAM jumper reset to make sure the embedded video controller wasn't disabled. No error codes show on the LCD and their are no error beeps (unless those can be disabled). When the system finishes \"booting\" the front LCD displays the system name and all other menus properly. Not sure what the issue could be so I'm checking here to see if any of you have any ideas.\n ​\n EDIT: This system does not have the enterprise IDRAC license so I cannot confirm boot or enter the system through there.\n    submitted by    /u/LiamColeE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi7fge/dell_r720_bootingdisplay_issues/",
          "publishedOn": "2022-12-10T23:41:15.000Z",
          "wordCount": 14169,
          "title": "Dell R720 Booting/Display Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi6zfe/updating_intel_me_amt_from_linux/",
          "author": null,
          "description": "Hi all,\n Recently I've been moving away from rackmount hardware to SFF machines to reduce my power usage, heat and noise.\n I've had some good success running Proxmox on HP EliteDesk SFF units and have been finding Intel AMT to be a suitable alternative to iLo/iDrac and am currently experimenting with MeshCommander/MeshCentral.\n On the HP site there is a firmware update tool for updating Intel AMT.However the included firmware is quite old and the tool is designed for either DOS/EFI.\n The newer firmware updates appear to be designed for Windows only.\n Is there a way to flash the Intel AMT firmware from within Linux IE Debian/Proxmox?If so, how I determine which firmware I need?\n The download from HP appears to include two bin files, C0_LP and D0_H.\n Thanks in advance for any help/advice.\n EDIT: I've more or less given up on the idea of doing this from within Linux for now and used this method:\n  \nI formatted a USB disk as fat32.\n Created a folder structure /efi/boot\n Placed the tianocore EFI shell in the boot folder named Boot64.efi https://github.com/tianocore/edk2/blob/UDK2018/ShellBinPkg/UefiShell/X64/Shell.efi\n From the HP flash tool download extracted with 7zip, copied the FWUpdLcl.efi and MEInfo.efifiles from the MEFlash and MEInfo directories to the USB disk.\n From the HP firmware download extracted with 7zip, copied both of the .bin files (H and LP) from the ME directory.\n Booted the machine from the USB Disk to get into an EFI shell\n Ran FS0: to change to the root of the USB disk (dir to check I'm in the right place)\n Ran MEInfo.efi to determine what firmware was running. In the output I saw I was running \"H\" rather than \"LP\".\n Ran FWUpdLcl.efi -f ME_11.8_Corporate_D0_H_Production.bin to flash the \"H\" firmware\n Rebooted and verified I was running the new AMT version with MeshCommander.\n  \n​\n    submitted by    /u/Joe_Pineapples  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi6zfe/updating_intel_me_amt_from_linux/",
          "publishedOn": "2022-12-10T23:22:12.000Z",
          "wordCount": 14449,
          "title": "Updating Intel ME / AMT from Linux",
          "imageUrl": "https://external-preview.redd.it/R3LvUNYzYoInUsVttws2Iys7pv7xulPDzt5n0hBxhcA.jpg?auto=webp&s=2bce80bdd1c922360e40a6a784e85eaa5fdc1b1f"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi6rra/supported_hdd_in_a_proliant_ml350/",
          "author": null,
          "description": "Picked up a Proliant ML350 G6 off of marketplace the other day for $50 and this is my first time working with server hardware. I see that there are multiple slots for hot swap SAS drives and a few for SAYA drives but I don't quite understand what type of drive I should be buying. I'm looking online and I see the HDD and sdd's however they don't have a mounting bracket. In my server I see there's a bunch of blanks. Am I supposed to fit the drives inside those? Also it it only SATA or ISCSI or something? Can someone explain this terminology for me? Thanks!\n Pic: \n https://imgur.com/a/cuDG3et\n    submitted by    /u/sarxlives  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi6rra/supported_hdd_in_a_proliant_ml350/",
          "publishedOn": "2022-12-10T23:13:25.000Z",
          "wordCount": 14907,
          "title": "Supported HDD in a Proliant ML350?",
          "imageUrl": "https://external-preview.redd.it/qgchVyCG3GKwAaKo_orU2k8sVgqepZKU_B6X7OlpDQc.jpg?auto=webp&s=7c586d9ceb1cb2e71910a685dcdb5948ff76df20"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi6oos/opinions_on_replacement_tinyminimicro_machines/",
          "author": null,
          "description": "Up until recently I’ve been running: - Synology NAS (Plex and NFS for other devices) - 3x Mac minis (2011) running Proxmox as a playground and to host a few services for the home - 1x Intel NUC (D54250WYKH i5-4250U) as a Home-Assistant box \n This is great as a playground, but with the current cost of energy, I’m kind of wishing I had just ONE tiny/mini/micro system that could run Proxmox and then my same few VMs to replace the bare minimum of what I need.\n I’ve been reading up on the Serve The Home site and their great video series, and I’ve been considering:\n  \nLenovo ThinkCentre M720Q (9th Gen Intel i5 9400T)\n HP EliteDesk 800 G4 \n Optiplex 3070\n Optiplex 7050\n  \nI DID try experimenting with two Raspberry Pi 4s I had, but they are just 2GB RAM models and I quickly ate that!\n So could anyone recommend a good bang-for-pound 😆 machine that I could pickup for around £200 used? Is it worthwhile to punt for the newer generation chipsets for power efficiency?\n    submitted by    /u/HarmlessSaucer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi6oos/opinions_on_replacement_tinyminimicro_machines/",
          "publishedOn": "2022-12-10T23:09:55.000Z",
          "wordCount": 15441,
          "title": "Opinions on replacement tiny/mini/micro machines for Proxmox?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi6d0y/ceph_overhead_using_rook_vs_proxmox/",
          "author": null,
          "description": "Hi, looking to build proxmox server and k8s cluster at home. Since I don’t have too many nodes, I was going to run either Rook or the Proxmox-managed ceph for storage.\n Can anyone speak to the performance of either? I’ve heard that proxmox ceph suffers from high overhead and is borderline unusable. Sadly my node with the most compute power for virtualization is also the one with the most drive bays.\n    submitted by    /u/tamerlein3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi6d0y/ceph_overhead_using_rook_vs_proxmox/",
          "publishedOn": "2022-12-10T22:56:38.000Z",
          "wordCount": 14019,
          "title": "Ceph: overhead using Rook vs Proxmox",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi64np/need_help_with_raid_and_truenas_scale_pools/",
          "author": null,
          "description": "Hiya, entirely new to the networking space so excuse my lack of knowledge--\n I've recently been working on turning my old Desktop into my own home server and so far it's been going great, at least until I got stuck at creating new pools via TrueNAS Scale..\n I've got an 18tb and another 4tb hard drive and planned to use them in 2 pools:\n One Pool for RAID1, so I'd be using the entire 4tb drive and 4tb of the larger drive to create a pool where I keep my most important data and one using the rest of the 18tb drive as a regular data pool.\n ​\n However after creating the RAID1 Pool, I realized that I can no longer select my 18tb drive to add as a data vdev... could someone tell me how I can use the rest of my 18tb drive alongside RAID1 if that's possible?\n    submitted by    /u/FinalPedro360  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi64np/need_help_with_raid_and_truenas_scale_pools/",
          "publishedOn": "2022-12-10T22:47:19.000Z",
          "wordCount": 14177,
          "title": "Need help with RAID and TrueNAS Scale pools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi5lgn/hp_dl20_gen9_nvme_support/",
          "author": null,
          "description": "Hi there, \n I have an HP DL20 Gen9 which currently has two SATA SSDs installed.\n I'd like to upgrade to two NVMe SSDs installed on two PCIe to M.2 adapters like this one.\n The system doesn't seem to support PCIe bifurcation so I guess I should be fine by just using two separate adapters, right? \n The system has one internal PCIe x16 slot which has a PCIe riser which splits that port into two PCIe x8 ports. Can I just install a PCIe to NVMe adapter in each of them? \n Thank you!\n    submitted by    /u/v3ng00  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi5lgn/hp_dl20_gen9_nvme_support/",
          "publishedOn": "2022-12-10T22:25:56.000Z",
          "wordCount": 14889,
          "title": "HP DL20 Gen9 - NVMe Support",
          "imageUrl": "https://external-preview.redd.it/qhoDUHJ4T6lRFVYCY-9LC6_D9Eq2S0cPXdOpKFukm2A.jpg?auto=webp&s=965af572f573b77cc8e751ba8115cec24cb07842"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi431k/14g_bezels_anything_else/",
          "author": null,
          "description": "submitted by    /u/cjchico  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi431k/14g_bezels_anything_else/",
          "publishedOn": "2022-12-10T21:26:59.000Z",
          "wordCount": 14331,
          "title": "14G Bezels > anything else",
          "imageUrl": "https://preview.redd.it/sbhrgkkij65a1.jpg?auto=webp&s=cab6b670036eae547bbbf10fec50bf2c2fbc2997"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi2rtr/my_first_free_score_on_some_equipment/",
          "author": null,
          "description": "Hey all. Recently my mother's workplace has moved buildings. They found a better place, cleaner, where it already had furniture. I decided that, in hopes of finding something that I could use/learn from, I would go to the old place to tear through the remaining stuff in the office. The equipment was never registered properly and I was told there are no problems if I take them because of that. So I did, and I found some pretty interesting stuff. \n I'm pretty new to homelabbing (not entirely new) but these were the first things I would get for free. \n An HP switch, 48 ports, only 4 are GbE (2 RJ45+2 SFP)\n ​\n Cisco 881, FE ports only\n ​\n There's a VPN sticker on it. I suppose it was used for tunneling to the headquarters.\n ​\n 8 Port GbE PoE switch. Pretty neat!\n Haven't booted this yet, unsure about specs, it just says SA4. I'll use this as the host for my CNC router since it has a LPT port on the back.\n This HP Compaq which - as you will see in the photo below - I called \\\"scrapyard\\\". Sorry for the lurking finger.\n ​\n I tried to install BSD but after flashing the USB it just wouldn't boot from the BIOS.\n I also got a lot of cat5e/cat6 wires. And one single mode fiber, too! (~5m)\n Overall I'd say I could find a use for these. Please let me know what you guys think!\n    submitted by    /u/fortlesss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi2rtr/my_first_free_score_on_some_equipment/",
          "publishedOn": "2022-12-10T20:34:55.000Z",
          "wordCount": 14574,
          "title": "My first free score on some equipment!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi0mza/layer_2_security_at_home/",
          "author": null,
          "description": "I just finished reading BRKSEC-2202 - Understanding and Preventing Layer 2 Attacks in IPv4 Network (2013). I learnt about attacks in layer 2 and ways to mitigate them.\n These attacks seems easy to perform, and also easy to mitigate (just enable things like DHCP snooping, Dynamic ARP inspection and IP source guard in your switch).\n Unfortunately, my current smart switch (Zyxel GS1900) does not offer these security features.\n Then again, these attacks require the malicious actor to be inside my network. They have to physically get into my house to do that (they can also brute force my wifi password or trick me to install some malicious software), and if that's the case then they can do much more than these \"layer 2 attacks\".\n Do you have these layer 2 security features at your homelab? Do you think they are essential to a secure homelab?\n    submitted by    /u/regunakyle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi0mza/layer_2_security_at_home/",
          "publishedOn": "2022-12-10T19:09:13.000Z",
          "wordCount": 14951,
          "title": "\"Layer 2 Security\" at home?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi0enj/baby_lab_3_laptop_proxmox_cluster/",
          "author": null,
          "description": "submitted by    /u/bkm9312  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi0enj/baby_lab_3_laptop_proxmox_cluster/",
          "publishedOn": "2022-12-10T19:00:03.000Z",
          "wordCount": 14644,
          "title": "baby lab: 3 laptop proxmox cluster",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi04mr/3d_printed_a_hot_swap_drive_enclosure_to/",
          "author": null,
          "description": "submitted by    /u/ngarret  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi04mr/3d_printed_a_hot_swap_drive_enclosure_to/",
          "publishedOn": "2022-12-10T18:48:38.000Z",
          "wordCount": 14994,
          "title": "3d printed a \"hot swap\" drive enclosure to troubleshoot dead drives.",
          "imageUrl": "https://preview.redd.it/rm4yyts9r55a1.jpg?auto=webp&s=bcfc3190545ca0a4d4044b4028167975417cee22"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhyqzc/trying_to_install_proxmox_onto_hp_proliant_ml350/",
          "author": null,
          "description": "submitted by    /u/MagicDartProductions  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhyqzc/trying_to_install_proxmox_onto_hp_proliant_ml350/",
          "publishedOn": "2022-12-10T17:53:14.000Z",
          "wordCount": 17336,
          "title": "Trying to install Proxmox onto HP ProLiant ML350 G6 server and get this screen. More in comments.",
          "imageUrl": "https://preview.redd.it/oiq3rbvdh55a1.jpg?auto=webp&s=2ee1ca69b3f8913be1812f8b99b72d8c26200a76"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhxa48/a_bit_dusty/",
          "author": null,
          "description": "UDM Pro UniFi 24 port POE switch PI Zero for Pi-Hole DNS Pi 4B as web server for custom comic book site Synology NAS for Plex and general storage\n What else would be fun to add? This is a bit addicting.\n    submitted by    /u/DagonFelix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhxa48/a_bit_dusty/",
          "publishedOn": "2022-12-10T16:53:58.000Z",
          "wordCount": 14217,
          "title": "A bit dusty",
          "imageUrl": "https://preview.redd.it/vnn5c36t655a1.jpg?auto=webp&s=865ee9663e9ffcc5b967fba986d8f71cbb4d3e6d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhwdmv/updating_proxmox_is_always_an_adventure/",
          "author": null,
          "description": "submitted by    /u/redstonefreak589  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhwdmv/updating_proxmox_is_always_an_adventure/",
          "publishedOn": "2022-12-10T16:15:21.000Z",
          "wordCount": 14875,
          "title": "Updating Proxmox is always an adventure",
          "imageUrl": "https://preview.redd.it/or3rabe9i35a1.png?auto=webp&s=0cb9ded0c31aa63b52659e74038588a7c57b0c3a"
        }
      ]
    },
    {
      "title": "It's A Digital Disease!",
      "feedUrl": "https://www.reddit.com/r/DataHoarder.rss",
      "siteUrl": "https://www.reddit.com/r/DataHoarder",
      "articles": [
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1070uod/google_made_a_tool_like_rsync_which_is_3x_faster/",
          "author": null,
          "description": "It seems to be that the tool is for windows --> linux, there is an issue asking for linux -> linux support. \n I wonder can we incorporate the learnings from this repo to make rsync faster? \n https://github.com/google/cdc-file-transfer\n    submitted by    /u/umbcorp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1070uod/google_made_a_tool_like_rsync_which_is_3x_faster/",
          "publishedOn": "2023-01-09T01:34:57.000Z",
          "wordCount": 15807,
          "title": "Google made a tool like rsync which is 3x faster",
          "imageUrl": "https://external-preview.redd.it/F3gS0keU5u6APy4XFmDVh3rKuENeV73WiCiMVb2dv9c.jpg?auto=webp&s=883bef74661df66b12c436dddd0f17cb1d2cffb2"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10701td/does_anyone_else_watch_their_downloads/",
          "author": null,
          "description": "I'm wondering if I'm weird or not... but I enjoy watching my downloads go and mental place bets on which download will finish first. Does anyone else do this, or am I just... weird?\n    submitted by    /u/ComputingElephant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10701td/does_anyone_else_watch_their_downloads/",
          "publishedOn": "2023-01-09T00:59:28.000Z",
          "wordCount": 15919,
          "title": "Does anyone else watch their downloads?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106zino/backing_up_all_data_ideally_root_folder_from_old/",
          "author": null,
          "description": "I had thought this would be easier since it's an Android device, but my Windows 10 PC does not seem to recognize the phone. I have installed USB drivers from the LG website, and have enabled USB debugging on the phone, but no dice. Are there any utilities that might work or alternative ways to get the files off the phone?\n    submitted by    /u/jehube  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106zino/backing_up_all_data_ideally_root_folder_from_old/",
          "publishedOn": "2023-01-09T00:36:04.000Z",
          "wordCount": 15939,
          "title": "Backing up all data (ideally root folder) from old Android phone (LG P500H)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106yq0m/how_do_you_organize_your_data/",
          "author": null,
          "description": "Considering we are data hoarders, file and directory organization is paramount, so I ask you, the Data Hoarders, how do you organize and classify you data?\n Looking forward to your insights.\n    submitted by    /u/nando1969  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106yq0m/how_do_you_organize_your_data/",
          "publishedOn": "2023-01-09T00:01:47.000Z",
          "wordCount": 16924,
          "title": "How do you organize your data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106xtyp/current_pending_sector_count_seems_to_has_messed/",
          "author": null,
          "description": "First of all, I'm going to post this to r/datarecovery but I thought that I'd try my luck here first.\n I think that I've messed up my backups and need help. I've been dumb enough to make copies of my backups of my files from the first backup that I ever did, and not from the original source. \n I have now noticed that the original drive the backup I have been using to create the other backups with has a C5, current pending sector count of 56. Since it is a lot of images I have been storing, I have never really checked so they haven't been damaged after each copy made, untill now.\n Many image files have their original name and metadata, but both the preview and the image itself are completley black (image).\n I will admit it, I'm really new to this and have never before thougt about checking my drives health. I have several copies, but they are all made from the broken drive, as said. I can't neither access the files on their original source. Is there anything that I can do?\n    submitted by    /u/mediamystery  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106xtyp/current_pending_sector_count_seems_to_has_messed/",
          "publishedOn": "2023-01-08T23:25:07.000Z",
          "wordCount": 15707,
          "title": "Current pending sector count seems to has messed with my backups and some of the photos are black, can they be saved?",
          "imageUrl": "https://external-preview.redd.it/Ij9Kw7xeT5YII1WIuEW4_2Ge-hriYbPfRkYi7oTx_R8.jpg?auto=webp&s=d49125f484592c54741315b15ddc3b975ca366ee"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106uvno/are_there_tools_for_detecting_and_clipping/",
          "author": null,
          "description": "I'm hoarding some audiofiles with looping audio and I want to only save a single loop to save space. Are there any preferrably automated tools to detect loops and clip files?\n    submitted by    /u/Stock-Wolverine-4309  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106uvno/are_there_tools_for_detecting_and_clipping/",
          "publishedOn": "2023-01-08T21:29:19.000Z",
          "wordCount": 15795,
          "title": "Are there tools for detecting and clipping looping audio?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106tvqy/time_frame_copier/",
          "author": null,
          "description": "What I want is a copy program that runs overnight / in a certain time frame, so I can copy a NAS to a backup when the network is not in use. It runs from 11pm to 6am & at 6am it stops transferring until that night. So it doesn't have to be restarted, but pickups up where it left off?\n I know I could use robocopy for starters, then schedule a task to kill it in the morning?\n Anything fanicier? This would be using a Windows host with the NAS shares mapped on the Win box.\n Is there something I could use on UnRAID that would run on the server?\n    submitted by    /u/hacnstein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106tvqy/time_frame_copier/",
          "publishedOn": "2023-01-08T20:50:24.000Z",
          "wordCount": 16735,
          "title": "Time frame copier",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106tcb2/quiet_hdds_for_nas_in_working_room/",
          "author": null,
          "description": "Hi everyone,\n The HDDs will be part of my self built NAS, which is housed in an old Fractal Design Define R6 - a case that comes with some amount of soundproofing. Unfortunately, in my apartment I don't have any space where noise absolutely does not matter. For now, it will be in the working room, where I and the gf spend significant amounts of time trying to be productive. Because of this, I want to buy HDDs that are the most likely to not annoy us too much. Read/Write performance is a secondary concern, so long as they make full use of my gigabit ethernet connection.\n I've done a bunch of research on this; both in this sub and beyond, and unfortunately there is no drive for which I don't find three different people making five contradicting claims about their noise levels.\n For instance, I've heard a bunch of good things about the Ultrastar DC HC550 drives; but other sources say they produce a thudding noise every five seconds or so, which may or may not be quite annoying.\n I also recently got a good deal on two Toshiba MG08ACA16TE drives which are sitting here unused so far, as I'm considering returning them. I've heard people claim they're rather quiet or really loud.\n It would be helpful to hear from people who have tried different HDDs from different companies and thus can give some sort of comparison. I am also totally open to other models or to shucking, if that's still a thing.\n OS Wise I am likely going with True NAS Core for the NAS, if this has any bearing on the question.\n    submitted by    /u/SWHH  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106tcb2/quiet_hdds_for_nas_in_working_room/",
          "publishedOn": "2023-01-08T20:28:56.000Z",
          "wordCount": 19199,
          "title": "Quiet HDDs for NAS in working room?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106t4gb/truenas_scale_error_the_web_interface_could_not/",
          "author": null,
          "description": "Hello!\n I am having issues with my freshly built NAS using TRUENAS Scale. I had an Intel core i7 12700K cpu from a previous build, so I chose to build around that. The other key components are as follows:\n  \nMSI MAG B660M MORTAR WIFI DDR4\n Corsair Vengeance LPX 32GB (2 X 16GB) DDR4 3600\n  \nI successfully installed the iso using a usb stick. I’m at the stage where I should be able to access the web GUI. However, the link/ip address is not there and instead reads “The web interface could not be accessed. Please check network configuration”.\n Here are the other options: 1. Configure network interface 2. Configure network settings 3. Configure static routes 4. Change local administrator password 5. Reset configuration to defaults 6. Open TRUENAS CLI Shell 7. Open Linux Shell 8. Reboot 9. Shutdown\n Frankly, I am not very technologically inclined and feel I’ve made a mistake. I’m not sure what I can do. I’ve attempted looking up solutions and they tend to say it’s a problem with the built in Wi-Fi (2.5G LAN and Intel Wi-Fi 6E Solution). I’m in around 5 hours of research and all I’m seeing is possibly getting a Intel NIC. That would be fine, but my home does not have Ethernet. \n The only thing I can really think of is:\n A) Update the motherboard bios (not sure how to do this given it’s on a NAS os)\n B) Buy a extremely expensive server board with w680 chipset. This would mean spending about 2x the amount of money I already have.\n C) Scrap it and just buy a synology which is still a net negative but at least I know it’ll work. \n I wanted to be able to mess around with Linux and it’s capabilities but this is beyond frustrating and frankly a bit demoralizing being my first experience with it.\n    submitted by    /u/Karizmology  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106t4gb/truenas_scale_error_the_web_interface_could_not/",
          "publishedOn": "2023-01-08T20:20:07.000Z",
          "wordCount": 17044,
          "title": "TRUENAS scale error: The web interface could not be accessed. New to NAS and could use some advice.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106rt8q/is_there_any_software_or_website_for_scraping_or/",
          "author": null,
          "description": "Basically looking to sort and tag 1000s of porn links, wish to input a URL, and to get a scraped image/thumbnail, so i dont have to do it manually. I dont think pornOrganizer, Stash and similar can do this.\n    submitted by    /u/PORNforORC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106rt8q/is_there_any_software_or_website_for_scraping_or/",
          "publishedOn": "2023-01-08T19:27:57.000Z",
          "wordCount": 16499,
          "title": "Is there any software or website for scraping or categorizing online links for videos and thumbnails",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106rn2p/advice_on_which_hdd_to_buy/",
          "author": null,
          "description": "Hello everyone, I wanted to buy a new HDD to replace my WD Elements 4TB that lately gives me some problems. I am undecided whether to buy the same model or an alternative model in which case I would not know which one. Would someone be able to advise me on valid alternatives :)\n    submitted by    /u/xXx_F3D3_xXx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106rn2p/advice_on_which_hdd_to_buy/",
          "publishedOn": "2023-01-08T19:21:07.000Z",
          "wordCount": 16145,
          "title": "Advice on which HDD to buy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106oxb7/wayback_machine_error/",
          "author": null,
          "description": "I tried recovering a lost video using the Wayback Machine, but I get the error \"Attempts to archive this video failed.\". Somehow, I'm still able to see slides if I hover over the bar that shows how much of the video has passed. What can I do?\n This is the video:\n https://web.archive.org/web/20200618135626/https://www.youtube.com/watch?v=LMlFwHpqEpU\n    submitted by    /u/Adriana_Istrate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106oxb7/wayback_machine_error/",
          "publishedOn": "2023-01-08T17:33:28.000Z",
          "wordCount": 15607,
          "title": "Wayback Machine Error",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106ovpx/question_about_viewing_files_in_foldersubfolder/",
          "author": null,
          "description": "I have an external hard drive with a LOT of folders and subfolders and would like to be able to collectively and simultaneously view all of the files and folders in one of the main folders (for the purposes of sorting by date). Is that possible?\n    submitted by    /u/tucson_throwaway1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106ovpx/question_about_viewing_files_in_foldersubfolder/",
          "publishedOn": "2023-01-08T17:31:46.000Z",
          "wordCount": 16082,
          "title": "Question about viewing files in folder/subfolder tree all at once",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106ojil/help_me_upgrade_my_storage_setup/",
          "author": null,
          "description": "I just had an external hard drive become corrupted and unreadable. I thought this would be a good opportunity to upgrade my setup, but I have some questions.\n ​\n  \nI was thinking of getting regular hard drives and a hard drive toaster rather than external drives. Is there a consensus as to which setup is better?\n  \n​\n  \nI need to transfer data between linux and windows computers. I was using the ExFat file system for this. Is this a good idea or is there a better file system?\n  \n​\n  \nI was told recently that drives larger than 2TB are far more susceptible to corruption. Is this true? \n  \n​\n  \nWhat programs would you recommend for data recovery on a hard drive?\n  \n​\n Thank you\n    submitted by    /u/archmage24601  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106ojil/help_me_upgrade_my_storage_setup/",
          "publishedOn": "2023-01-08T17:18:13.000Z",
          "wordCount": 21140,
          "title": "Help me upgrade my storage setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106np9e/sata_usb_dock_with_supporteasy_solution_for_33v/",
          "author": null,
          "description": "Like most of you, I've got tons of hard drives floating around. I've got a good 20+ drives sitting in a bin that I need test and determine if I want to keep or not (most are 4tb-8tb), including some which are shucked drives. For both these and future drives, I've been looking at picking a handy USB dock that I can hook up to my main workstation, and stick drives in from to time to slow clear out the back log. \n Something like this: https://www.amazon.com/gp/product/B00CE65C4W?th=1 , or possibly the two drive version of it. \n Task-wise, I'm looking at testing the drive, basic power on and SMART tests, pulling data off the drive (not a common occurrence), and securely wiping the drive. Performance is not a real concern at all. \n Two possible issues with a setup like this, whether I can access the raw SMART diagnostics of the drive and if I'll have any issues with the PWDIS/3.3V pin. I haven't used many USB/SATA bridges over the years, so not sure of the SMART data is a problem or not. \n Regarding the 3.3V pin, handling it in server/PC/whatever is easy enough. I generally just make sure the power for that pin is disconnected/cut up stream of the drive. Would rather not have to deal with figuring out which drives it will be an issue with and putting tape over the pins. Do USB docks even have power on that pin and/or proper support for it? \n What are people's experiences with this stuff? Do I need to worry about either thing, any recommendations for or against a given dock/brand would also be appreciated.\n (Searching for info on r/DataHoarder and the rest of reddit didn't provide much solid information on the 3.3V pin with USB dock issue)\n    submitted by    /u/dnabre  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106np9e/sata_usb_dock_with_supporteasy_solution_for_33v/",
          "publishedOn": "2023-01-08T16:44:56.000Z",
          "wordCount": 17571,
          "title": "SATA USB Dock with support/easy solution for 3.3V Pin (PWDIS) and SMART tests",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106m302/using_rclone_to_copy_folder_to_folder/",
          "author": null,
          "description": "I seem to have Rclone setup properly, but Im a bit confused on how I would clone an entire folder of my external drive(connected to my mac) into a specific folder in my Google drive account. My Rclone account name will be NAME for the purpose of this post\n The folder that I'm looking to copy is in this chain \"4tb>offloaded footage>categorized>DJI>2021\n and I'm looking to copy this to my google drive \"My Drive>Categorized footage>DJI>2021\n Here is the terminal command that I'm using\n rclone -v sync /Volumes/4TB\\ Offloaded\\ Footage/Categorized/DJI/2021 NAME: \n Then what do I put after this to get the contents copied into \n  \nMy Drive>Categorized footage>DJI>2021\n  \n   submitted by    /u/AllAboutGadgets  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106m302/using_rclone_to_copy_folder_to_folder/",
          "publishedOn": "2023-01-08T15:37:15.000Z",
          "wordCount": 16783,
          "title": "Using RClone to copy folder to folder?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106m2yz/best_windows_app_for_combining_multiple_mp3s_into/",
          "author": null,
          "description": "I have quite a collection of MP3 audio books that I have collected over the decades. Some are divided by chapter. Some are even divided by chapter in different CD folders. I am looking for a good Windows app that will take a folder of MP3s (with even subfolders) and convert them into a single M4B. OpenAudible lets me import the MP3s, but I can't figure out how to combine and convert them using that, so I'm looking for suggestions.\n    submitted by    /u/djeaton  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106m2yz/best_windows_app_for_combining_multiple_mp3s_into/",
          "publishedOn": "2023-01-08T15:37:13.000Z",
          "wordCount": 16687,
          "title": "Best Windows app for combining multiple MP3s into single M4B",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106j8ia/digitising_thousands_of_35mm_photo_slides/",
          "author": null,
          "description": "Hi folks,\n Not sure if this is the right place to post this question, but here goes.\n I have boxes and boxes of photography slides that I'd like to digitise. Currently, my solution is to buy something like https://www.amazon.co.uk/dp/B0074H6NTO, but that involves me having to fill the trays with 4 slides at a time. Obviously not totally feasible with thousands of slides.\n Does anyone have any experience with a project like this? Or ideas on how to proceed?\n Cheers.\n    submitted by    /u/thisismyfirsttime123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106j8ia/digitising_thousands_of_35mm_photo_slides/",
          "publishedOn": "2023-01-08T13:26:47.000Z",
          "wordCount": 18117,
          "title": "Digitising thousands of 35mm photo slides",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106g20g/software_for_finding_duplicate_files_based_on_a/",
          "author": null,
          "description": "I need help finding duplicates of my JAV collection, the problem is that some files have their titles in different format like:\n a) GVG-001.mp4\n b) GVG001.mp4\n c) GVG001 - additional movie title\n What software would you recommend to find dupes? Duplicate files might have different lengths so CRC search will not work. I need some way to analyze the first few letters of a filename keeping in mind that there may or may not be \"-\" sing in there. Can you help me out?\n I have total commander but I'm not sure if its search function is as powerful.\n    submitted by    /u/wooshaq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106g20g/software_for_finding_duplicate_files_based_on_a/",
          "publishedOn": "2023-01-08T10:28:37.000Z",
          "wordCount": 16866,
          "title": "Software for finding duplicate files based on a similar filename.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106fwt4/just_published_my_guide_for_microsoft_teams_users/",
          "author": null,
          "description": "Constructive feedback very much appreciated.\n Here is the guide:\n https://medium.com/@goughgough/the-best-way-for-microsoft-teams-users-without-administrator-rights-to-save-export-print-copy-8212aa9e5f11\n TL;DR: To export Teams chat messages without Microsoft Teams admin rights, download Gildas Lormeau's (GL) browser extension at https://github.com/gildas-lormeau/single-file-export-chat.\n By the way, this extension is based on their excellent Singlefile browser extension.\n Assumptions: You are not very tech-savvy.\n You can log into Microsoft Teams in a browser at https://teams.microsoft.com/\n In Teams, you do not have admin rights for a group chat. Nevertheless, you still need to export the messages from that specific group chat.\n You want to use noncommercial software and do the exporting for free.\n You want to export messages from the Chat section (in Microsoft Teams left column). NOT the Team section (in Microsoft Teams left column).\n You wish to export Teams messages in their entirety, including any body text that contains clickable links.\n You want to export Teams messages to a searchable final output rather than an image file.\n You do not want to waste time manually copying and pasting individual Teams messages, which is one of the techniques in quite a few of the online guides. This manual copying and pasting makes sense if you only have a few Teams messages to export.\n You do not want to use the GoFullPage browser extension. Even though it is not as effective as GL’s solutions, it does let you export Teams messages as images (e.g., a non-searchable PDF file). Before I came across GL’s methods, the GoFullPage browser extension was the best method I tried. Unfortunately, the final product is not searchable due to its image format.\n    submitted by    /u/cashpayer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106fwt4/just_published_my_guide_for_microsoft_teams_users/",
          "publishedOn": "2023-01-08T10:19:51.000Z",
          "wordCount": 15011,
          "title": "Just published my guide for Microsoft Teams users (without administrator rights) to save, export, print, copy, archive, back up, or migrate Teams conversation threads, messages, chat history. Hope you like it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106fh0r/looking_for_a_solution_for_a_multi_m2_drive/",
          "author": null,
          "description": "I have a a 1TB SanDisk 520s and I am looking for a solution to expand my storage capacity. Obviously I could just get another 1TB, but then I would then have multiple drives I need to eject when I move my MacBook about.\n Looking at YouTube videos it does look like it has an M2 NVME drive installed, so this got me thinking. For the same price of another 1TB sandisk I can get a 2tb M2 drive.\n Is there some enclose preferably unpowered (or type c) that can hold multiple M2s? I suppose two drives would be ok, but would prefer four. I have looked on Amazon and they either seem to be exposed, too big and also need power.\n Raid capability isn't necessary. Portability is fairly important though.\n ​\n https://preview.redd.it/j2bssghsbvaa1.jpg?width=1500&format=pjpg&auto=webp&s=41d07a33f39622a5df81dac42d95e4fed58059a9\n    submitted by    /u/matmah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106fh0r/looking_for_a_solution_for_a_multi_m2_drive/",
          "publishedOn": "2023-01-08T09:53:53.000Z",
          "wordCount": 17290,
          "title": "Looking for a solution for a multi M2 drive storage with a single cable. Have a 1TB SanDisk and want to expand.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106exgz/looking_for_insight_from_those_whove_been_there/",
          "author": null,
          "description": "I'm currently at a point in my journey where I'm looking to start planning out my storage config for my first homelab. This isn't a post asking EXACTLY what I should do but moreso trying to get a feel for what first timers don't really think about. What are common regrets you've heard or experienced when setting up the storage for homelab for the first time? I'm still deciding how much extra storage I plan on having(I know I need more than 10TB). Still deciding on a file system(I'm definitely leaning towards ZFS). Deciding whether I want to virtualize my NAS or not. For context, I plan on using this lab as part \"production\"(things like Plex, pihole, Home Assistant and a steam cache) and part testing to get more familiar with all kinds of things, from setting up a Windows domain controller to familiarizing myself with kubernetes.\n    submitted by    /u/RiggedyWreckt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106exgz/looking_for_insight_from_those_whove_been_there/",
          "publishedOn": "2023-01-08T09:20:14.000Z",
          "wordCount": 17855,
          "title": "Looking for insight from those who've been there.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106elia/outback_cctv_system_with_limited_internet/",
          "author": null,
          "description": "I'm interested in setting up a CCTV system, 1 security camera only.\n Where I'm at in the middle of nowhere (Australia) there isn't fixed line, and there is barely any data signal with most carriers.\n What I'd like is to have the security camera recording to a local system, let's say a simple computer setup with some HDDs that constantly records with a set retention.\n But I'd also want to be able to remotely view what's happening when I am not at the location, and being limited with internet options (cellular plans only) the cost of 24/7 streaming online would not be viable. So, I thought about a system that: records locally, then every 1 hour (more or less) uploads 1 photo to a cloud service, let's say back blaze (from a portable wifi router connected via SIM). That way, I can look to check to see if there is anything gone occasionally without having to livestream which would use a huge amount of data, and if something did happen, I can go check the local storage and see what exactly happened.\n Ideally, the only monthly costs would be:\n SIM data plan\n Backblaze\n If anyone has some knowledge on what cameras are the best option or how I could achieve this, if i'm on the right track etc please feel free to share!\n    submitted by    /u/Competitive-Wing9364  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106elia/outback_cctv_system_with_limited_internet/",
          "publishedOn": "2023-01-08T09:00:31.000Z",
          "wordCount": 17969,
          "title": "Outback CCTV system with limited internet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106d1dr/lossless_image_hosting/",
          "author": null,
          "description": "I am looking for an image host (like imagur) that does not compress the image I upload. 100% lossless. I don't really care about features other than I would need to be able to see it from anywhere so would other people. Thanks.\n    submitted by    /u/PuzzleheadedTennis23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106d1dr/lossless_image_hosting/",
          "publishedOn": "2023-01-08T07:27:09.000Z",
          "wordCount": 16976,
          "title": "Lossless Image Hosting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1065slv/time_to_recover_gsuite_files/",
          "author": null,
          "description": "I screwed a script and deleted 4000+ files, about 1800 of which were MP4/MKV of various sizes.\n Using the admin console I requested a data restore which produces a message like, the data will be restored shortly. \n It's getting on 2 days with no data restored. Does anyone have any experience with this, and how long it might take?\n (The deleted files are not in the trash).\n    submitted by    /u/cn8fly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1065slv/time_to_recover_gsuite_files/",
          "publishedOn": "2023-01-08T01:24:00.000Z",
          "wordCount": 16117,
          "title": "Time to recover Gsuite files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10632g5/rosewill_rsvl4500u_filter_replacement/",
          "author": null,
          "description": "Maybe I'm incredibly dense, but I can't seem to figure out how to remove the dust filter from the front of the case to give it a wash.\n Manual says nothing, and my google-fu has failed me.\n    submitted by    /u/djtodd242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10632g5/rosewill_rsvl4500u_filter_replacement/",
          "publishedOn": "2023-01-07T23:26:58.000Z",
          "wordCount": 17226,
          "title": "Rosewill rsv-l4500u filter replacement",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/106260d/need_to_read_a_15tb_drobo_beyondraid/",
          "author": null,
          "description": "The disks should be fine, but the NAS itself seems to have failed. I'm curious if anyone knows an ideally free way to mount the disks on Linux or Windows?\n It's 5 disks, single parity, so 12GB usable.\n    submitted by    /u/Krutonium  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/106260d/need_to_read_a_15tb_drobo_beyondraid/",
          "publishedOn": "2023-01-07T22:49:56.000Z",
          "wordCount": 16294,
          "title": "Need to read a 15TB Drobo \"BeyondRAID\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1061efc/is_there_some_easy_way_to_extract_comments_from/",
          "author": null,
          "description": "Hi, im quite newbie to datahoarding, so basically i am mass downloading bunch of image albums for my little archive but some of these images have useful comments that would also be handy to have in txt file for further reference. \n I learned to use JDownloader2 for image batch downloading, I was wondering if there is something similar that I could use for comments/text on webpage?\n    submitted by    /u/Kuznetsov063  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1061efc/is_there_some_easy_way_to_extract_comments_from/",
          "publishedOn": "2023-01-07T22:17:31.000Z",
          "wordCount": 16159,
          "title": "Is there some easy way to extract comments from website into txt/docx files or such?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10607ro/creating_a_huge_adult_swim_playlist/",
          "author": null,
          "description": "Hi there fellow DataHoarders! I searched both Google and this sub for an answer to this quandary, but couldn't find anything. Maybe what I want to do is impossible and I should just accept it. \n I like to game on one monitor and halfheartedly watch videos on the other in the evenings, and I wanted to see if there was a way I could consolidate all 389 GB of my locally stored video files into a single playlist that can play them randomly.\n I made the attempt with VLC, but it chokes on it about halfway through adding the files to the playlist. I don't know if there is a numerical limit, or if it goes by file size, not sure. Is there another application, extension, or maybe something out there in GitHub world that you know of that can accomplish this?\n I really appreciate any help, and thank you in advance!\n    submitted by    /u/TropicalDruid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10607ro/creating_a_huge_adult_swim_playlist/",
          "publishedOn": "2023-01-07T21:28:35.000Z",
          "wordCount": 16367,
          "title": "Creating a Huge Adult Swim Playlist",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10605yt/maximum_file_size_on_hetzner_storagebox/",
          "author": null,
          "description": "Happy new year!\n Is any of you aware of a maximum file size limit on Hetzner storage boxes?\n I have tried to upload a ~100G disk backup to my storage box over the holidays and that failed with some non-descript error. After the fact I found out that I had a local HDD failure that might have caused this...\n before I commit to uploading again (my ISD outgoing speed is quite low) I thought I'd check with the wisdom in this subreddit...\n    submitted by    /u/biochronox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10605yt/maximum_file_size_on_hetzner_storagebox/",
          "publishedOn": "2023-01-07T21:26:17.000Z",
          "wordCount": 15900,
          "title": "maximum file size on Hetzner storagebox?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105yeet/hotswap_problem_on_supermicro_backplane/",
          "author": null,
          "description": "I've encountered an issue that I don't know how to troubleshoot, and have come here (what I suspect to be the highest concentration of Supermicro 846 owners on the internet) in the hope that one of you has seen something similar. When I try to connect a new drive to my Supermicro BPN-SAS2-846EL2, it spins up but does not appear to actually connect to anything. I see the following in dmesg on my Openmediavault 6 system:\n [ 756.914588] mpt2sas_cm0: handle(0x45) sas_address(0x5003048001215814) port_type(0x1) [ 757.461716] mpt2sas_cm0: log_info(0x31110101): originator(PL), code(0x11), sub_code(0x0101) [ 757.529208] mpt2sas_cm0: log_info(0x31110101): originator(PL), code(0x11), sub_code(0x0101) [ 757.597212] mpt2sas_cm0: log_info(0x31110101): originator(PL), code(0x11), sub_code(0x0101) [ 757.7…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105yeet/hotswap_problem_on_supermicro_backplane/",
          "publishedOn": "2023-01-07T20:12:29.000Z",
          "wordCount": 20444,
          "title": "Hot-swap problem on Supermicro backplane",
          "imageUrl": "https://external-preview.redd.it/UiIPF2mqA_DFQCLEDWvkDDxPFwNwPdql7LOx5xV-euw.jpg?auto=webp&s=bbfd64870f33bdb05e624063cdefbb5b9d58a33a"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105ya4l/how_to_see_all_results_in_amazon_search/",
          "author": null,
          "description": "When searching for a general keyword in the search bar, usually some 30 or 50k books show up. However, only about 1k can actually be seen. That is more or less until page 100. Past that... no more pages and thousands of books we can't acess. I thought this was the place to post the question because the results are surely in their system, it shows the numbers. Tried on different browsers and platforms, so it's definitely an intentional feature. \n    submitted by    /u/Freibetto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105ya4l/how_to_see_all_results_in_amazon_search/",
          "publishedOn": "2023-01-07T20:07:22.000Z",
          "wordCount": 16436,
          "title": "How to see all results in Amazon search?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105wz2l/for_backup_why_is_write_speed_important_to_you/",
          "author": null,
          "description": "I often see people complaining about slow transfer speeds for backups, but have always been curious as to why it's important to some?\n The only real concern I can think of is the possibility of something happening to the original drive and data before the backup is completed. Otherwise, for me I set up my transfer and ignore it until it's done.\n Right now I'm backing up ~8TB to another drive. With verification it's taking over a day. But other than that, I'm ignoring it and it will be done when it's done.\n After this is complete, I'll be starting on the other 100TB+ and accept that it will take months for it to be done. But that's perfectly fine with me. My minor concern is that since I'm migrating the drives from my third backup to primary and backup, I'll only have two sets of my data fo…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105wz2l/for_backup_why_is_write_speed_important_to_you/",
          "publishedOn": "2023-01-07T19:13:11.000Z",
          "wordCount": 18628,
          "title": "For backup, why is write speed important to you?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105wtcx/does_seagate_reset_smart_data_on_manufacturer/",
          "author": null,
          "description": "After reading some of the opinions of folks in this subreddit, I decided to take a chance on some refurbed Exos X18 12TB drives for my NAS, ordered from Server Part Deals. I've swapped in two of them so far, and the SMART data looks good, but only show 25 and 15 power on hours and a start/stop count of 2. Assuming I trust the seller, does anyone know if Seagate resets SMART data when they refurbish drives? I know a lot of these drives may have never seen much or any actual use before they were rejected for one reason or another, but I'm curious if these *really* are low mileage or if Seagate reset the stats.\n By the way, I have to say Server Part Deals was great to deal with. They really do ship these things well, and they shipped them fast. Thanks for the recommendation!\n    submitted by    /u/compulov  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105wtcx/does_seagate_reset_smart_data_on_manufacturer/",
          "publishedOn": "2023-01-07T19:06:36.000Z",
          "wordCount": 16584,
          "title": "Does Seagate reset SMART data on manufacturer refurbs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105v27f/diskstation_usb_copy_issue/",
          "author": null,
          "description": "Hi everyone I'm having issues exporting about 6.5TB of data from my DS214 to an external drive. I have a 14TB drive I partitioned to 7TB for NTFS and the other 7TB to Mac OS Extended. I was using the USB Copy app since rsync was going to take to long but after getting to about the final 300GB or so it ran out of space. Now realizing I should have just given myself more space to work with is there any way to resume where the data transfer left off?\n    submitted by    /u/klnadler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105v27f/diskstation_usb_copy_issue/",
          "publishedOn": "2023-01-07T17:53:49.000Z",
          "wordCount": 16634,
          "title": "Diskstation USB Copy Issue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105usnz/how_to_get_faster_read_speeds_for_raid_1_on/",
          "author": null,
          "description": "I have backups on my NAS and the cloud, so I'm not doing this as a backup.\n Which method of setting up RAID1 on a windows desktop will get the best read performance? The files are mostly 12+TB of photos and lots of 4k videos. \n My aim is uptime (If one drive fails I won't have to spend days copying files from my NAS backup) and read performance for photo and video editing programs like Lightroom and Davinci Resolve \n Did some googling and it seems I can use \n  \nWindows Storage Spaces \n Windows Disk Management\n Intel RST on my B560 Steel Legend motherboard\n StableBit DrivePool\n  \n   submitted by    /u/lonereaction  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105usnz/how_to_get_faster_read_speeds_for_raid_1_on/",
          "publishedOn": "2023-01-07T17:42:46.000Z",
          "wordCount": 16361,
          "title": "How to get faster read speeds for RAID 1 on windows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105upzb/cable_name_for_camcorder_digitization/",
          "author": null,
          "description": "I'm looking to transfer some miniDVs onto my computer, the camcorder i have with me is a JVC GR-D200EK and was wondering if anyone knew the name of the cable i would need for my camcorder (if there is one), or if i'd have to buy a seperate camcorder with the regular firewire cable connection for the pci card method. \n The cable\n The input\n I've searched through google for what cable it could and i've seen nothing that resembles it. I haven't got much knowledge of these sorts of cables, some websites are saying its a VC-VDV204U DV (Firewire) Cable and other spec sites are listing it as a regular firewire cable but it doesnt look like either. Thanks for any info\n    submitted by    /u/Alexsls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105upzb/cable_name_for_camcorder_digitization/",
          "publishedOn": "2023-01-07T17:39:41.000Z",
          "wordCount": 15795,
          "title": "cable name for camcorder digitization",
          "imageUrl": "https://external-preview.redd.it/4u_yT4UW4_xnmSsN-z8fgwTPi7MMvHjihTCwx0wvmM4.jpg?auto=webp&s=1f1472d41bb73696a256e11b63b13b871e1ff680"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105uk8j/bought_a_cheap_drive_for_a_backup/",
          "author": null,
          "description": "$60 for a 2TB seagate. im getting roughly 60mb/s and im backing up 1.6TB itll be a while. does drive speed dictate reliability any? it's slow as shit but the cheapest option for a backup.\n    submitted by    /u/QualitySound96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105uk8j/bought_a_cheap_drive_for_a_backup/",
          "publishedOn": "2023-01-07T17:33:03.000Z",
          "wordCount": 15710,
          "title": "bought a cheap drive for a backup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105txiy/one_of_the_oldest_known_version_of_runescape_has/",
          "author": null,
          "description": "submitted by    /u/AnApexBread  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105txiy/one_of_the_oldest_known_version_of_runescape_has/",
          "publishedOn": "2023-01-07T17:06:37.000Z",
          "wordCount": 16198,
          "title": "One of the oldest known version of RuneScape has officially been found",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105sjex/temporary_cheap_10tb_cloud_storage_for_migration/",
          "author": null,
          "description": "Hi All! I want to move away from xpenology shr to something else but have no intermediary server to store data. Any tips on a cloud storage with 10tb to keep my stuff there for a month?\n    submitted by    /u/nightrave  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105sjex/temporary_cheap_10tb_cloud_storage_for_migration/",
          "publishedOn": "2023-01-07T16:07:49.000Z",
          "wordCount": 16179,
          "title": "temporary cheap 10tb cloud storage for migration?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105s4n5/anyone_know_what_going_on_with_bitdeals/",
          "author": null,
          "description": "I purchased a drive from them almost a month ago and all I've gotten is the confirmation email.\n I've purchased from these guys plenty of times. They even sent me the wrong drive and fixed it right away.\n contacting is leading nowhere since nobody is responding to emails or the chat bot.\n was hoping someone knew if something was up before i just issued a chargeback and went somewhere else.\n    submitted by    /u/Hairless_Human  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105s4n5/anyone_know_what_going_on_with_bitdeals/",
          "publishedOn": "2023-01-07T15:50:06.000Z",
          "wordCount": 15255,
          "title": "Anyone know what going on with bitdeals?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105nx6q/datahoarder_why_i_started/",
          "author": null,
          "description": "Not a massive datahoarder but got interested when I realised I had several old Windows profiles I'd backed up over the years. Thought I had issues until I found this subreddit. I also feel I fully justified why I started saving bits and pieces. I used to watch ITIdiots back in the day until they gave it up as they weren't making money from it. I'd managed to download pretty much all their videos they'd done (sadly not much of their mac videos as have/had no interest in Apple) until one day they disappeared for a bit. Turns out, if I remember right, they were with 123reg and it was the only place they had copies of their videos. 123reg had a big outage with corrupt backups so no data could be restored so they lost them all. Thats when I actually did something with my YouTube channel and just stuck them all on there. Even offered to send them a copy on Blu-ray which Nick was interested in but then never heard back.\n Now of course, they can just run yt-dlp on my channel to grab them.\n    submitted by    /u/steviefaux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105nx6q/datahoarder_why_i_started/",
          "publishedOn": "2023-01-07T12:27:38.000Z",
          "wordCount": 16420,
          "title": "Datahoarder why I started",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105nh6o/is_there_an_alternative_to_this_aic_sas_2u/",
          "author": null,
          "description": "submitted by    /u/sffpc_qa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105nh6o/is_there_an_alternative_to_this_aic_sas_2u/",
          "publishedOn": "2023-01-07T12:02:27.000Z",
          "wordCount": 16006,
          "title": "Is there an alternative to this AIC SAS 2U short-depth JBOD?",
          "imageUrl": "https://preview.redd.it/xrwykt6r2maa1.jpg?auto=webp&s=220e7f37b27c1d17906a8fe8fafce036e5d9d3ee"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105gvti/judyrecords_full_text_search_on_many_million_us/",
          "author": null,
          "description": "judyrecords is a free nationwide search engine that lets you instantly search hundreds of millions of United States court cases and lawsuits.\n Disclaimer: I have no connection to this site. I found it via:\n https://old.reddit.com/r/InternetIsBeautiful/comments/103jxmv/full_text_search_on_650_million_us_court_cases/\n Also, it has previously been mentioned on DataHoarder two years ago:\n https://old.reddit.com/r/DataHoarder/comments/jeov9h/101_new_court_systems_added_to_judyrecords/\n PLEASE: If you are interested in mirroring/archiving, don't hammer their search engine; contact the site: judyrecordssite@gmail.com.\n From: https://www.judyrecords.com/info\n  \nUpdate (10/10): I'll be posting an update regarding data exchanges shortly. Yes, I'm exhausted.\n  \nLooks like a one-person enterprise, please be considerate.\n All that being said, really interesting story here:\n https://www.judyrecords.com/what-happened-with-tyler-technologies\n Frightening. Could have turned out a lot worse. Spare a thought for Aaron Swartz.\n    submitted by    /u/schneedledee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105gvti/judyrecords_full_text_search_on_many_million_us/",
          "publishedOn": "2023-01-07T05:28:49.000Z",
          "wordCount": 16838,
          "title": "Judyrecords: Full text search on (many) million US court cases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105btv5/finally_found_this_sub/",
          "author": null,
          "description": "Good day fellow hoarders. \n After getting fed up of Cloud services such as Google Drive and their bugs and bills, I have now decided to store and hold on to every bit and byte of my personal and professional data on a Network Attached Storage. A few answers if you could please:\n 1.) Am I on the right track? Is NAS the right solution to become independent of cloud services? Or does there exist any other method or tech or hardware for doing so?\n 2.) Synology? Did my fair share of research and seems like a good choice to go hardcore on data hoarding. Are there any ones better than this brand? \n 3.) Apart from the standard media and files I would want to store literally everything like passwords and WhatsApp backup on my NAS. Is it possible?\n    submitted by    /u/NASIRCISSISTIC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105btv5/finally_found_this_sub/",
          "publishedOn": "2023-01-07T01:23:18.000Z",
          "wordCount": 16417,
          "title": "Finally! Found this Sub!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105bpde/question_regarding_encrypting_file_before/",
          "author": null,
          "description": "So here is my situation: I’m looking to backup personal documents to the cloud. Google Drive, One Drive or iCloud. I now see that iCloud has End to End encryption which is a big plus. However I’m a mac and windows user and an iPhone and android user. That means I need some way to access files on any device. I decided to upload an encrypted zip file to Google drive which is available on all platform. I’m using Keka on MacBook as multiple users have suggested. However after looking at their website they mention : “Using AES-256 encryption specification for your 7z files and Zip 2.0 legacy encryption specification for your Zip files.” from which I understand that only the 7z format is protected by AES-256. How do I verify which encryption the compressed folder is using? What would be a cross platform suggestion? Thank you\n    submitted by    /u/Zeckzyl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105bpde/question_regarding_encrypting_file_before/",
          "publishedOn": "2023-01-07T01:17:47.000Z",
          "wordCount": 16467,
          "title": "Question regarding encrypting file before uploading them to the cloud",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/105abdo/best_way_to_digitize_lots_of_old_photos/",
          "author": null,
          "description": "I have about 500 old family photos as prints ranging from 2\" x 2\" up to 8\" x 10\", as well as at least five boxes of slide photos. I'd like to digitize them. Some are in color, some in black and white.\n ​\n What's the best way to go about doing that? I have a DSLR camera, but cropping hundreds of photos manually is rather inefficient. Is there some type of scanner I can get for this? Like something with a scanning bed maybe (feed-through seems like a bad idea)\n ​\n Not sure exactly what resolution I need, but I'd almost certainly want a minimum of 4k\n    submitted by    /u/cocomac42  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/105abdo/best_way_to_digitize_lots_of_old_photos/",
          "publishedOn": "2023-01-07T00:17:29.000Z",
          "wordCount": 16173,
          "title": "Best way to digitize lots of old photos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1059tj1/3_tier_storage_for_windows_pc_possible/",
          "author": null,
          "description": "Hi. Not sure if this is the best subreddit for this kind of question but here we go anyway.\n I would like to combine all my drives (NVME SSDs, SATA SSDs and spinning rust HDDs) into a single tiered pool, where the NVME takes care of the most used files, the SATA SSDs take care of the majority of files and the HDDs act as \"hot archive\", taking care of the files I very rarely use. Backups would go on a separate file server.\n I currently have a 500GB NVME SSD partitioned into two 250GB partitions and use a 500 GB SATA SSD and a 1TB SATA SSD as a storage pool. I'm planning on adding an 4TB HDD as well.\n Like I said, preferably I would like to have everything in one singel \"drive\" with Windows intelligently allocating the files depending on frequency of use.\n Is it possible to do this in Windows 10/11?\n    submitted by    /u/cadmiumcadamium  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1059tj1/3_tier_storage_for_windows_pc_possible/",
          "publishedOn": "2023-01-06T23:57:16.000Z",
          "wordCount": 16463,
          "title": "3 tier storage for Windows PC possible?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10595ct/i_cant_stop_looking_at_this_beast/",
          "author": null,
          "description": "Supermicro SSG-6049P-E1CR60H SuperStorage | Supermicro eStore \n ​\n I'm debating between that with some FreeNas or something or New QNAP\n    submitted by    /u/TomLongIsland  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10595ct/i_cant_stop_looking_at_this_beast/",
          "publishedOn": "2023-01-06T23:29:26.000Z",
          "wordCount": 15170,
          "title": "I can't stop looking at this beast",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1057iih/what_do_you_wish_existed_storage_software/",
          "author": null,
          "description": "I used to work for an enterprise storage vendor. I wrote test software that could hit 75GB/s. I know a thing or two about speed. With the new Zen4 X3D chips being confirmed, I plan to build myself a nice little NAS to hold my movies, music, and blockchains (BTC and XMR). I've been considering writing my own storage software for a while. My own personal goals are:\n  \nZFS or LVM Pool-like operation (as in, tell it what drives to use, and it packs the drives full of capacity)\n Much easier and more intuitive redundancy (setting 'copies=2' will mean that two different drives, preferably on different storage controllers, have your data; no more vdevs!)\n Automatic de-duplication at a block level.\n SSD-first mentality (spinning rust is ok, but I'd rather have a filesystem designed from the ground up to support 550MB/s to each individual drive)\n Support for an Optane or battery-backed up config mode where write-through caching is allowed for maximum write performance. (have 10 550MB/s drives? Enjoy 5.5GB/s writes!)\n Block-based performance teiring? (Actually, probably won't do this, or would do it in a different product. Conflicts with core design I have in mind).\n  \nI have 0 manufacturing connections or experience, so selling a pre-built NAS is not in my scope. But what are some storage features you wish existed or were easier?\n    submitted by    /u/my21streddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1057iih/what_do_you_wish_existed_storage_software/",
          "publishedOn": "2023-01-06T22:24:16.000Z",
          "wordCount": 16936,
          "title": "What do you wish existed (storage software).",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1056s6m/finally_ready_to_build_myself_a_nasplex_server/",
          "author": null,
          "description": "I built my gaming PC in 2008 and still use it as my primary desktop. I mostly do photo editing and I'm finally ready to replace it since NVMe drives will really speed up my process.\n This got me thinking about finally building a NAS/Plex server. I have about 15TB of data already (mixed between photos and movies) scattered about on various internal and external drives and it's truly a mess. As my photography has become more storage intense (currently running a Sony A1), I'm running out of space with my current setup and I'm tired of buying externals.\n Is my hardware okay for the job? My PC is built with an ASUS Sabertooth P67 board and a Sandy Bridge i7 2600K with 16GB of RAM that has been rock solid since I first built it. My thought is to pull it out and put it in a case with room for at least 5 drives (or hotswap bay) and to run it with TrueNAS on a small SSD. Since I think I would only need to buy the new case, this would be the most budget-conscious decision and I could put my money towards new drives.\n Is this a dumb idea? Is my hardware just too old? I'm willing to invest in something new if I must, but I'm also okay with running this until it dies and then replacing whatever needs to be replaced. Should I be looking in another direction entirely? Thank you kindly for the help.\n    submitted by    /u/NateRT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1056s6m/finally_ready_to_build_myself_a_nasplex_server/",
          "publishedOn": "2023-01-06T21:56:00.000Z",
          "wordCount": 16945,
          "title": "Finally ready to build myself a NAS/Plex server and need some advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1056mci/some_people_say_you_should_leave_room_free_on_a/",
          "author": null,
          "description": "submitted by    /u/AshleyUncia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1056mci/some_people_say_you_should_leave_room_free_on_a/",
          "publishedOn": "2023-01-06T21:49:23.000Z",
          "wordCount": 16334,
          "title": "Some people say you should leave room free on a drive. ...I prefer to see a hard drive as a Tetris like challenge, where I have to fill every gap as best I can.",
          "imageUrl": "https://preview.redd.it/zmcno0mcuhaa1.png?auto=webp&s=6615d93e62818f145e1971572712867d7b369ea4"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1055rqf/synology_ds220j_vs_ds220_for_work_graphic/",
          "author": null,
          "description": "Hi, I want to find the right NAS that is not too expensive. Of course DS220+ is better, but with a higher price, so I also consider DS220j which may be enough for us.\n My wife has DS214se, but as far as I remember, it was never fast enough for my liking (I didn't care at the time because I don't really use it and it's hers).\n Purpose\n  \nHome storage: Mainly family photos, and documents.\n Work storage: As a graphic designer, the files are not that big. Some time can be up to 2-4 Gb.\n We don't really have movies, big media files like 4k, etc. or music files. So, somehow not really anything to stream out from it (if that's the term?)\n We plan to use 2x WD 2TB Red Plus NAS HDD 5400RPM from my wife's Synology DS214se, is that good?\n Will DS220j stay good for a while before becoming obsolete?\n Mainly I'd love a nice responsive storage/server to move/save files around, especially for work.\n  \nDo you think the DS220j would already be enough for us? the price is much better than 220+ where I live. Thanks everyone!\n    submitted by    /u/Pizzacooper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1055rqf/synology_ds220j_vs_ds220_for_work_graphic/",
          "publishedOn": "2023-01-06T21:16:06.000Z",
          "wordCount": 16685,
          "title": "Synology DS220j vs. DS220+ for work (graphic designer) & home files storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1054py0/fellow_data_hoarders_what_does_your_average/",
          "author": null,
          "description": "submitted by    /u/blueskyn01se  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1054py0/fellow_data_hoarders_what_does_your_average/",
          "publishedOn": "2023-01-06T20:34:38.000Z",
          "wordCount": 15071,
          "title": "Fellow data hoarders: what does your average monthly data usage look like? I’m usually right around 10TB",
          "imageUrl": "https://preview.redd.it/f57xx3lsyiaa1.jpg?auto=webp&s=ab2d36a6b59b865ca7c95a1743928ab450c419c0"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1054nb9/in_need_of_file_server_looking_at_community/",
          "author": null,
          "description": "As the title says, i am running into issues having all of my files accessible locally. I am in need of a nas. I currently have an amd system from 2012 that can be used, i can also buy parts and build a server, or i can buy a prebuilt nas.\n View Poll\n    submitted by    /u/grinder323  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1054nb9/in_need_of_file_server_looking_at_community/",
          "publishedOn": "2023-01-06T20:31:50.000Z",
          "wordCount": 16573,
          "title": "in need of file server, looking at community suggestions for how to proceed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10543ur/just_starting_out/",
          "author": null,
          "description": "I would like to start saving music, pictures, videos, movies. I do not know what type of drive I should be looking at. What would you suggest?\n    submitted by    /u/J0866  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10543ur/just_starting_out/",
          "publishedOn": "2023-01-06T20:10:26.000Z",
          "wordCount": 16139,
          "title": "Just starting out...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1053tiw/guide_for_a_quiet_lowpower_diy_2bay_nas/",
          "author": null,
          "description": "Do you have a good guide for a quiet, low-power DIY 2-Bay NAS? I only want to use it for Backups and maybe a server for practicing JS and Python. I have seen a video about a Raspberry Pi as a NAS but it was too complicated with Linux, consoles, SSH and very difficult RAID setup. I don't want to deal with stuff like drive pools or VMs I just want to safe money and power (which is money again). I think I would like to use RAID 1 or SHR. I like that I can use different old drives for SHR and add more drives in the future. I think 4 TB total capacity are enough to begin with.\n    submitted by    /u/Rationale-Glum-Power  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1053tiw/guide_for_a_quiet_lowpower_diy_2bay_nas/",
          "publishedOn": "2023-01-06T19:59:41.000Z",
          "wordCount": 17344,
          "title": "Guide for a quiet, low-power DIY 2-Bay NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1051z79/best_way_to_verify_data_after_full_freenaszfs/",
          "author": null,
          "description": "Hello,\n I've recently upgraded my NAS to a larger server and to transfer from my old Freenas box I used a one time snapshot, like you might do if you were setting up a backup server, since it seems to work pretty cleanly.\n The transfer completed so I now have what appears to be a copy of the data on both sides, and the sizes match up (17.79TB on one side, 17.8TB on the other). But before I delete the snapshot and start working with this as my primary system I'd like to see what the best practices would be to verify there wasn't any corruption during the transfer. \n Thinking I could use rsync to verify the files on both sides, but wondering if there's anything deeper I could do to verify nothing got messed up. It's a wide variety of files so I know there's probably not a simple \"Are any files corrupt\" scan I could do, any thoughts?\n Thanks,\n    submitted by    /u/BrownNote  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1051z79/best_way_to_verify_data_after_full_freenaszfs/",
          "publishedOn": "2023-01-06T18:46:13.000Z",
          "wordCount": 16339,
          "title": "Best way to verify data after full Freenas/ZFS snapshot?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1051cpl/archiving_dd_ogl_10_community_resources_before/",
          "author": null,
          "description": "Long time lurker to this community, thanks to everyone for the combined knowledge I've benefitted from!\n Wizards of the Coast are updating their Open Gaming License to v1.1, and are attempting to eliminate a lot of 3rd party resources the community has been using for, in some cases, decades. It's technically not legal, but the community thinks they're going to try anyways, and a lot of free resources just won't be able to fight back.\n I would like to create functional offline copies of these websites so if they get taken offline permanently, they'll still be accessible to the community at large.....but I've never done anything more advanced than use 4KDownloader to monitor YouTube channels before. \n Where do I start? I'm reading Wayback Machine's site, but I don't really know what I'm doing.\n    submitted by    /u/Riadnasla  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1051cpl/archiving_dd_ogl_10_community_resources_before/",
          "publishedOn": "2023-01-06T18:21:48.000Z",
          "wordCount": 18286,
          "title": "Archiving D&D OGL 1.0 community resources before they're taken offline",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1051baj/looks_like_dropbox_always_keeps_a_trace_of_your/",
          "author": null,
          "description": "I didn't use my Dropbox account for quite some time (7+ years). Before stopping using it I deleted all my data. I recently logged it again, and saw under the \"Recents\" page, files from 2014, which I deleted in 2015:\n https://preview.redd.it/08jxrg16tgaa1.png?width=1204&format=png&auto=webp&s=4ca845d89d735894c15c6529612dde7185993e2c\n Why does Dropbox keeps metadata about 7-8 years old files?\n    submitted by    /u/Issam2204  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1051baj/looks_like_dropbox_always_keeps_a_trace_of_your/",
          "publishedOn": "2023-01-06T18:20:12.000Z",
          "wordCount": 15203,
          "title": "Looks like Dropbox always keeps a trace of your deleted files",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1050s1i/google_workspace_enterprise_new_accounts/",
          "author": null,
          "description": "some back story - was on an unlimited account for years, panicked months ago when I was forced over to new plans and migrated everything locally. Intrigued to hear some people are still using the unlimited accounts, I decided to sign up for a Google Workspace Enterprise Standard account and see what if anything was being enforced. \n 20 USD a month - capped at 5TB. If you have 5 accounts on the 1 plan you are entitled to request additional storage above the 5TB however this needs to be approved by google and incremental storage upgrades are available. Just wanted to put this out there with the chance it might help someone.\n    submitted by    /u/Everything-Bagel-33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1050s1i/google_workspace_enterprise_new_accounts/",
          "publishedOn": "2023-01-06T17:59:35.000Z",
          "wordCount": 16842,
          "title": "Google Workspace Enterprise - New Accounts...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104zsls/can_my_14_year_old_hdd_corrupt_my_backup_drive/",
          "author": null,
          "description": "I have a 14 year old (22500 power-on-hours) HDD that is used twice a week just for copying its contents to a newer HDD. I have important data on it..i kept it all these years because i very rarely use it...maybe once a week to add new data..and thought it can last a lifetime under such conditions.\n If the 14 year old drive gets data corruption...will it transmit corrupted data to the newer backup HDD? Or is the data safe in such a case (because it is twice-weekly copied to the backup hdd?)?\n I would replace the drive but it was such a bother to automate the twice-weekly backup to the other drive..\n    submitted by    /u/RandomHandle31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104zsls/can_my_14_year_old_hdd_corrupt_my_backup_drive/",
          "publishedOn": "2023-01-06T17:20:51.000Z",
          "wordCount": 17592,
          "title": "Can my 14 year old HDD corrupt my backup drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104ve0r/dumb_question_how_do_a_turn_the_extension_jpeg_to/",
          "author": null,
          "description": "Dumb question: How do a turn the extension .jpeg to .jpg without inadvertently damaging the files or making them unreadable somehow?\n I'm a hobbyist/semi-pro photographer. Over the years and several terabytes later, some files are .jpeg and some are .jpg. I'd like to make these all the same. What's the best way to do this?\n    submitted by    /u/broken1384  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104ve0r/dumb_question_how_do_a_turn_the_extension_jpeg_to/",
          "publishedOn": "2023-01-06T14:22:01.000Z",
          "wordCount": 16378,
          "title": "Dumb question: How do a turn the extension .jpeg to .jpg without inadvertently damaging the files or making them unreadable somehow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104v9j9/what_open_backupsoftware_for_nontechsavy_user/",
          "author": null,
          "description": "Okay, I admit this is more \"small time data hoarding\" but I hope you might be able to help nevertheless. I'm looking for a \"newbie friendly\" backup-software.\n I finally convinced my girlfriend that it might be a good idea to do a backup of her laptop once in a while and now I'm looking for the right software for the job. Nothing fancy or professional - just that she has a copy of here most important documents if her laptop should fail. Since I'm not a windows user I've no idea where to start. I've taken a look at the Wiki, but all recommendations seem a bit to complicated/professional for my case. These are the requirements:\n  \nWindows Software for local Backups to external USB-Drive (she doesn't want tom put her data into a cloud)\n Easy to use, should take care of everything once set up\n Should work gracefully with an removable hard-drive (best case: should keep quite if disk is not connected and do a backup when she is at home and connects the drive)\n Open Data Format - In case of an emergency I want to be able to pull files from the backup without having to install the software again\n should look reasonably \"pretty\" - yeah, I know... But I also know that she will not use it, if it looks ugly/complicated/dated\n  \nSo basically just a tool that regularly checks for changed files and copies them to the disk. Any tipps what I should get for her? (I know that this is not a perfect failsafe Backup-Strategy, but I think it is the best I can get her to do).\n    submitted by    /u/AllesMeins  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104v9j9/what_open_backupsoftware_for_nontechsavy_user/",
          "publishedOn": "2023-01-06T14:16:27.000Z",
          "wordCount": 16844,
          "title": "What \"open\" Backup-Software for Non-Tech-Savy user?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104nc5h/im_very_happy_right_now_with_my_server_situation/",
          "author": null,
          "description": "My current house comes with a server room-- yeah, it's really the walk in closet for my bedroom, but the comms panel is there so I have data, power, there's an overhead vent for cooling, and I can't hear my server running if I shut the door. \n I tossed a server with 32GB of ECC onto a shelf in there and now have an excuse to have a NAS. Time to start shopping for more drives and feed the addiction. \n I'm thrilled that running headless, the server burns 18W with an 80+ gold unit. Now just to get some drives to shuck, a UPS, and I guess I need to admit defeat and buy a case. Right now I'm justifying the expense of getting the server going because it has homeassistant running on proxmox, I'm in the process of getting trueNAS going in another VM on the server so I don't have to burn more power.\n    submitted by    /u/I_burn_stuff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104nc5h/im_very_happy_right_now_with_my_server_situation/",
          "publishedOn": "2023-01-06T06:50:17.000Z",
          "wordCount": 15700,
          "title": "I'm very happy right now with my server situation.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104m5ad/webp_is_the_bane_of_my_existence/",
          "author": null,
          "description": "submitted by    /u/ElonTastical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104m5ad/webp_is_the_bane_of_my_existence/",
          "publishedOn": "2023-01-06T05:43:35.000Z",
          "wordCount": 28388,
          "title": ".Webp is the bane of my existence",
          "imageUrl": "https://preview.redd.it/cyn0n6itjeaa1.jpg?auto=webp&s=0379051cbc0e9fa0a20510c50789325c896d136b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104m40g/nobody_here_is_falling_for_this_but_why_are_they/",
          "author": null,
          "description": "submitted by    /u/itsaride  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104m40g/nobody_here_is_falling_for_this_but_why_are_they/",
          "publishedOn": "2023-01-06T05:41:40.000Z",
          "wordCount": 16982,
          "title": "Nobody here is falling for this but why are they being sold on Amazon so openly when they’ll just be returned?",
          "imageUrl": "https://preview.redd.it/ldhfgvnt1daa1.jpg?auto=webp&s=21f6bec9e661df79bc2968652678bd7289abf46e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104l576/national_library_of_australias_free_digital/",
          "author": null,
          "description": "submitted by    /u/eyrryr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104l576/national_library_of_australias_free_digital/",
          "publishedOn": "2023-01-06T04:52:09.000Z",
          "wordCount": 14909,
          "title": "National Library of Australia’s free digital archives may be forced to close",
          "imageUrl": "https://external-preview.redd.it/vuEw8yeLsWtGPaCI8tfjs-k7DNWyJBAz7uV5hUzIcUU.jpg?auto=webp&s=5eab8291f59a0f3f8075c283c4f401b15cdb5f82"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104ev3n/how_much_data_do_you_guys_have_on_backblaze/",
          "author": null,
          "description": "I've heard mixed reviews on this, I was considering getting backblaze just because i'm scrap for cash at the moment and need a cheap alternative for backing up my data (for now).\n I see they offer \"unlimited\" seen not many but a few people say that they were capped at a certain amount of storage or their account got terminated because of this... I have a desktop PC with 12 HDD slots, Only 5 of them i think are in use atm but want to eventually store all the data from all available slots on Backblaze, Is it feasable or do you think they could decide to terminate my account based on excessive storage?\n    submitted by    /u/BadFixMate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104ev3n/how_much_data_do_you_guys_have_on_backblaze/",
          "publishedOn": "2023-01-06T00:08:11.000Z",
          "wordCount": 17295,
          "title": "How much data do you guys have on backblaze \"unlimited\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104dz9w/komputer_%C5%9Bwiat_a_polish_magazine_of_25_years/",
          "author": null,
          "description": "Please, we can't lose Komputer Świat.\n https://ksplus.komputerswiat.pl/\n    submitted by    /u/NTxC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104dz9w/komputer_%C5%9Bwiat_a_polish_magazine_of_25_years/",
          "publishedOn": "2023-01-05T23:32:10.000Z",
          "wordCount": 16671,
          "title": "Komputer Świat, a Polish magazine of 25 years, shuts down on the 31st of January 2023 shutting down all PDF downloads",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104bwwf/need_help_picking_the_right_drive/",
          "author": null,
          "description": "I have 1.6TB of music files I want to back up. The 2 options I’m looking at is the 2TB LaCie external. Problem is that I see the speeds are up to 120mb/s. My other options is the 2TB WD Black drive and then I’ll have to buy an enclosure/dock to power it. It’s a 7200 rpm drive and speeds are over triple the LaCie. Both setups cost around $100. I just don’t know if the enclosure will slow speeds being there are several enclosure options for 3.5 drives.\n    submitted by    /u/QualitySound96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104bwwf/need_help_picking_the_right_drive/",
          "publishedOn": "2023-01-05T22:12:21.000Z",
          "wordCount": 16048,
          "title": "Need help picking the right drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104bfar/i_want_to_archive_the_titles_and_other_data_of/",
          "author": null,
          "description": "Are there any programs which I could use to scrape the playlists every hour or so and store on my computer or would I have to code something?\n    submitted by    /u/smefTV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104bfar/i_want_to_archive_the_titles_and_other_data_of/",
          "publishedOn": "2023-01-05T21:54:18.000Z",
          "wordCount": 16143,
          "title": "I want to archive the titles and other data of videos in a YouTube playlist periodically and store it in a text document on my computer. How would you go about that?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104auzf/should_i_be_concerned_about_these_smart_values/",
          "author": null,
          "description": "submitted by    /u/lemmeanon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104auzf/should_i_be_concerned_about_these_smart_values/",
          "publishedOn": "2023-01-05T21:32:43.000Z",
          "wordCount": 15970,
          "title": "Should I be concerned about these SMART values",
          "imageUrl": "https://preview.redd.it/0cus060pmaaa1.png?auto=webp&s=a7fc8dca1cafc8c84851c9ee9929627228a95bb3"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104ar0y/cheap_cloud_backup_solutions/",
          "author": null,
          "description": "I'm looking for a cheap cloud backup solution, I'm not in a great financial situation so can't afford anymore HDDs at this current moment in time. Have about 15tb I want to backup and looking to expand even more as time goes on.\n Any solutions, also one that doesn't care about inactivity, as I won't be doing much accessing the files, it's purely for backup purposes as currently I'm running on a ticking time bomb as I have nothing backed up.\n TIA\n    submitted by    /u/BadFixMate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104ar0y/cheap_cloud_backup_solutions/",
          "publishedOn": "2023-01-05T21:28:29.000Z",
          "wordCount": 16411,
          "title": "Cheap cloud backup solutions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104ag9a/possible_to_backup_sms_from_old_nonandroid_nonios/",
          "author": null,
          "description": "I've been going through my old devices and if possible, wanted to save my text messages from my old phones. This is easy enough with Android and iPhones, but I have an old Nokia flipphone that I used to use with a bunch of SMS on it. Is there a way to non-manually back up the messages? (In any format, preferably in JSON or something similar).\n    submitted by    /u/jehube  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104ag9a/possible_to_backup_sms_from_old_nonandroid_nonios/",
          "publishedOn": "2023-01-05T21:17:05.000Z",
          "wordCount": 15660,
          "title": "Possible to backup SMS from old (non-Android, non-iOS) phone?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104a2rd/whats_ur_favorite_filecollection_of_files/",
          "author": null,
          "description": "Whats ur favorite file/file collection you own this could be something that doesnt exist on the internet anymore or something else!\n    submitted by    /u/MoonyRedditt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104a2rd/whats_ur_favorite_filecollection_of_files/",
          "publishedOn": "2023-01-05T21:02:36.000Z",
          "wordCount": 15121,
          "title": "Whats ur favorite file/collection of files",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1049zo3/how_bad_is_western_digitals_shippingcustomer/",
          "author": null,
          "description": "For context, I bought 2 12TB wd red pro drives for my new Synology DS220+ directly from WD's website near new year's (either on the 30 or 31st, the site says both), and I still haven't gotten a shipping notification after 3-4 business days. So I tried to call customer support but it just says every rep is busy. Then I try to make a support ticket, but their site is broke so I can't even put one in. I'm wondering if anyone had the same experience with customer support.\n ​\n Also how long does it normally take to get a shipping notification? It's been almost a week, and I paid extra for UPS 2 day shipping.\n    submitted by    /u/Deathstalkr1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1049zo3/how_bad_is_western_digitals_shippingcustomer/",
          "publishedOn": "2023-01-05T20:59:30.000Z",
          "wordCount": 15878,
          "title": "how bad is Western Digital's shipping/customer support?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1049blw/need_recommendation_for_4tb_hdd_for_simple_weekly/",
          "author": null,
          "description": "Howdy folks.\n ​\n Like the title says. I don't care about noise or speed, the files I'll be backing up are usually not too big. As long as the thing is cheap and has a low chance of randomly bricking on me I'm okay with it.\n ​\n I've heard that the seagate barracuda or wd blue are good choices for what I'm looking for, but I'd rather hear it from people whom, like myself, also had their del key removed from their keyboards.\n ​\n I'm also thinking of getting an Orico enclosure, what do you guys think?\n    submitted by    /u/dietpills42  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1049blw/need_recommendation_for_4tb_hdd_for_simple_weekly/",
          "publishedOn": "2023-01-05T20:32:58.000Z",
          "wordCount": 16308,
          "title": "Need recommendation for 4tb HDD for simple weekly backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1048ymr/is_there_a_way_to_bulk_download_in_pdfdrive/",
          "author": null,
          "description": "hello, happy new year.\n I want to download all ebook from a search \n example i use this from https://github.com/kaushalpurohit/Bookdl\n i use termux with the bookdl command but only i can download one book for command i want download all ebook \n example\n https://www.pdfdrive.com/search?q=learn+japanese+&pagecount=&pubyear=&searchin=&em=\n thanks very much...(☞ﾟヮﾟ)☞\n    submitted by    /u/Learningjapanese007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1048ymr/is_there_a_way_to_bulk_download_in_pdfdrive/",
          "publishedOn": "2023-01-05T20:19:05.000Z",
          "wordCount": 15474,
          "title": "Is there a way to bulk download in Pdfdrive?",
          "imageUrl": "https://external-preview.redd.it/CDZ-MP_swNJ-_lRlStf04daNlOLRHa8m4BCH9EFBwpM.jpg?auto=webp&s=81db03250af17940e54b25be8d4f52359d26a651"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1047t45/tool_for_downloading_and_managing_youtube_videos/",
          "author": null,
          "description": "submitted by    /u/cocacola1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1047t45/tool_for_downloading_and_managing_youtube_videos/",
          "publishedOn": "2023-01-05T19:33:11.000Z",
          "wordCount": 15641,
          "title": "Tool for downloading and managing YouTube videos on a channel-by-channel basis",
          "imageUrl": "https://external-preview.redd.it/r0vz3fojLdhycw6jumB4Ao8GjRgBcKHoH14aNN4VpbA.jpg?auto=webp&s=6d528a43513ef2e5b0a52a4c53641fd71ca16723"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1047t2s/looking_for_a_new_case_to_replace_my_node_804/",
          "author": null,
          "description": "Hi my node 804 from fractal makes some discs go BRRRR from vibrations and it's really loud. I got 11 discs in it and some discs just make tons of noise due to vibrating against the case. Does anyone have a better case than this one to recommend?\n I don't need more space specifically, just something that's more silent. Electricity is expensive in Belgium so I don't need server unit recommendations :-)\n    submitted by    /u/Gangbangjoe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1047t2s/looking_for_a_new_case_to_replace_my_node_804/",
          "publishedOn": "2023-01-05T19:33:09.000Z",
          "wordCount": 17277,
          "title": "Looking for a new case to replace my Node 804",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1045pa1/why_dont_usb_drive_enclosures_power_on_after/",
          "author": null,
          "description": "So, I have my server set to auto-on after power failure and the UPS depletes. But the last time that happened, I learned the hard way that my USB drive enclosure doesn't auto-on. When the server spun up, Plex didn't see about half my library and removed everything, which screwed up the whole .arr aparratus too and required significant time to rebuild those databases. \n So, I went looking for an enclosure that will auto-power-on like my computer after failure, but I can't seem to find one. Is there a reason why not? Some electrical code thing? I could home-brew a PC case and jumper the PSU but I'd much rather have a quality purpose-built enclosure -- and something that can handle like eight drives without all the space needed for the motherboard and the rest. Even better if it took mini-SAS cables from my HBA card. Thoughts? Appreciate any help.\n    submitted by    /u/memorablenuts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1045pa1/why_dont_usb_drive_enclosures_power_on_after/",
          "publishedOn": "2023-01-05T18:10:02.000Z",
          "wordCount": 16652,
          "title": "Why don't USB drive enclosures power on after power failure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1045ii1/is_there_a_way_to_bulk_download_photos_and_videos/",
          "author": null,
          "description": "Is there a way to do this without having to download them one by one?\n I have tried many options but they have stopped working.\n    submitted by    /u/davidpmv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1045ii1/is_there_a_way_to_bulk_download_photos_and_videos/",
          "publishedOn": "2023-01-05T18:02:34.000Z",
          "wordCount": 16432,
          "title": "Is there a way to bulk download photos and videos from an Instagram profile?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/104536m/would_it_be_a_terrible_idea_to_keep_nas_in/",
          "author": null,
          "description": "I’m in the process of building a DIY NAS, but am struggling with where to place it. I want it to be connected via Ethernet, but the problem is the smart panel in my house is in the laundry room and I’m not sure how much that would impact the NAS. My thought was to keep it in the lower cabinets in the room. The room is a decent size (about 10ft x 8ft), has a large fan, and I haven’t noticed much of a difference in temperature when doing laundry. Would that be a terrible idea? I would prefer to keep it in the office, but the Ethernet wiring is only in the laundry room and I’m not sure how difficult/expensive it would be to move it to the office since it’s on the opposite side of the house (home is about 3300sq ft).\n    submitted by    /u/JustLiz26  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/104536m/would_it_be_a_terrible_idea_to_keep_nas_in/",
          "publishedOn": "2023-01-05T17:45:27.000Z",
          "wordCount": 17132,
          "title": "Would it be a terrible idea to keep NAS in laundry room?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1043gnw/file_backup_software_suggestions/",
          "author": null,
          "description": "hi, I had a spare server that I used for gaming and testing stuff and I want to use it as a storage server now but I'm a bit lost regarding the software. I was using a simple windows install with samba shares before and ideally I would want that + something like either Dropbox sync or more like just reliable incremental file backups over the net(I was looking at nextcloud/owncloud for that), it doesn't have to be windows so I was also looking at something like trueNas or open media vault. I'd like to know what software or system would suit my needs best, or any suggestions or opinions since I never used any of those before. Thanks. Ps: I'd also like to know if it's possible/easy to scale or migrate those systems but that's not something I need right now, just looking for some info.\n    submitted by    /u/nengon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1043gnw/file_backup_software_suggestions/",
          "publishedOn": "2023-01-05T16:40:01.000Z",
          "wordCount": 16829,
          "title": "file backup software suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1042g9j/nvme_pcle_m2_ssd_to_usb_adapterenclosure/",
          "author": null,
          "description": "Hi, I have a NVME PCLE m.2 ssd (i think 2280, m key) and need an adapter to usb (a or c) to plug into my laptop. I am in Australia and im looking for suggestions or affordable and good options, amazon aus is fine aswell as other places.\n    submitted by    /u/NekoNiru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1042g9j/nvme_pcle_m2_ssd_to_usb_adapterenclosure/",
          "publishedOn": "2023-01-05T15:58:19.000Z",
          "wordCount": 18602,
          "title": "NVME PCLE m.2 ssd to usb adapter/enclosure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103yc1b/my_new_drive_arrived_what_do_you_guys_think_of/",
          "author": null,
          "description": "submitted by    /u/lemmeanon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103yc1b/my_new_drive_arrived_what_do_you_guys_think_of/",
          "publishedOn": "2023-01-05T12:58:30.000Z",
          "wordCount": 15430,
          "title": "My new drive arrived. What do you guys think of this packaging? It's CMR and paid 10.5 usd/tb too! SMART values are fine. I am running a surface scan right now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103xvo7/any_way_of_identifying_from_the_properties_below/",
          "author": null,
          "description": "submitted by    /u/mariusmoga_2005  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103xvo7/any_way_of_identifying_from_the_properties_below/",
          "publishedOn": "2023-01-05T12:34:25.000Z",
          "wordCount": 17297,
          "title": "Any way of identifying from the properties below which of the 2 video files below has a better quality?",
          "imageUrl": "https://preview.redd.it/2ujbqybiy7aa1.jpg?auto=webp&s=d43c112a7041557031939e68fe2677457b24a525"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103vluw/rant_smr_was_born_as_a_high_density_solution/",
          "author": null,
          "description": "Nowadays, you must pay a premium to have low capacity drives with CMR, which is a covert price uplift while playing dirty marketing tricks like changing JUST ONE ZERO on the product number to differenciate CMR from SMR (looking at you seagate).\n    submitted by    /u/zezoza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103vluw/rant_smr_was_born_as_a_high_density_solution/",
          "publishedOn": "2023-01-05T10:21:21.000Z",
          "wordCount": 30864,
          "title": "RANT: SMR was born as a high density solution. Instead, it has plagued low capacity drives while biggest ones are still CMR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103rz0h/external_rats_nest_to_a_proper_bay/",
          "author": null,
          "description": "submitted by    /u/FrankMagecaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103rz0h/external_rats_nest_to_a_proper_bay/",
          "publishedOn": "2023-01-05T06:38:16.000Z",
          "wordCount": 17234,
          "title": "External Rat's Nest to a Proper Bay",
          "imageUrl": "https://preview.redd.it/35mbgnfk66aa1.jpg?auto=webp&s=4d7127fce5423661e7c86ff5eca396a53ce2381e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103l34p/suggestions_for_reliable_and_silent_external_8tb/",
          "author": null,
          "description": "Hi data hoarders,\n (if this is not the right place for this kind of question, please kindly let me know)\n I'm looking for a reliable drive (and enclosure) for quiet media usage. It will be mostly used to hold and serve media, and will hold files from 1GB up to 90GB, for streaming (Plex or NFS), connected to a laptop. Essentially a poor man's NAS. Noise is a concern, from the drive itself or from enclosure fan, as this drive would be in a living room. 5400RPM would be enough. Not frequently written to either. Any suggestions considering the use case? \n FYI, I did some research on this, but I think it's time to ask the experts. I know about SMR vs CMR, and that Helium-filled drives are supposedly from silent. Thought of perhaps buying a decent CMR drive, and put it in a fan-less 3'rd party enclosure, but I'm having a hard time choosing the hardware. There's too many options around and it's tricky to get full specs on everything, not to mention a lot of contradicting information, gets confusing fast.\n Thanks in advance!\n    submitted by    /u/WeirdlyDrawnBoy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103l34p/suggestions_for_reliable_and_silent_external_8tb/",
          "publishedOn": "2023-01-05T01:06:42.000Z",
          "wordCount": 17068,
          "title": "Suggestions for reliable and silent external 8TB HDD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103kzi6/thinking_about_my_first_raid_qnap_tr004_4x_8tb_ssd/",
          "author": null,
          "description": "I am looking to set up my first RAID. I have (4) Samsung 870 QVO 8TB SSDs. I was thinking about getting a QNAP TR-004 and installing them. Thoughts on RAID 5 / 6 (if supported) / 10 in this situation? Alternately, I could sell 3 of the SSDs and buy (4+) 18TB Ironwolf drives in RAID 10 (due to the risk of URE?). My priority is data security and minimizing the possibility of ever needing to restore from backups. Speed is not important.\n Does anyone happen to know if the QNAP TL-D800C be used as a DAS? Or other affordable 8 bay options?\n Any suggestions in general?\n    submitted by    /u/AccurateCoconut1739  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103kzi6/thinking_about_my_first_raid_qnap_tr004_4x_8tb_ssd/",
          "publishedOn": "2023-01-05T01:02:21.000Z",
          "wordCount": 17907,
          "title": "Thinking about my first RAID ... QNAP TR-004 + 4x 8TB SSD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103kdyf/how_to_download_from_xtapesto/",
          "author": null,
          "description": "I’ve tried many different chrome extensions, allow right click, 9xbuddy etc. Any ideas how to download from xtapes.to (NSFW warming)\n    submitted by    /u/labrume  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103kdyf/how_to_download_from_xtapesto/",
          "publishedOn": "2023-01-05T00:36:35.000Z",
          "wordCount": 16725,
          "title": "How to download from xtapes.to?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103iujj/uncorrectable_and_pending_sector_count_values/",
          "author": null,
          "description": "I had a Hard Drive with 64 uncorrectable and pending sectors (or at least this is what CrystalDiskInfo has been showing for a year), now after formatting the disk, CrystalDisk shows no problems with 0 pending and uncorrectable sectors.\n The thing is... Is it in a good state or I should be worried about it anyway?\n    submitted by    /u/DarthRickraft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103iujj/uncorrectable_and_pending_sector_count_values/",
          "publishedOn": "2023-01-04T23:33:01.000Z",
          "wordCount": 16438,
          "title": "uncorrectable and pending sector count values gone after formatting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103gyh7/how_to_establish_ssd_as_writecache_for_hdds/",
          "author": null,
          "description": "Windows 10, 10th gen i7, 32GB DDR4, RTX 2060\n Volumes:\n C: 1TB NVMe SSD - OS\n D: 1TB NVMe SSD - Spare volume\n E: 18TB Mirrored SATA3 HDDs \n F: 120GB SATA3 SSD\n I want F to be an automatic write-cache for E, for large media transfers from C or D.\n I'd prefer a built-in windows method, but open to new software/driver options.\n Anyone know how to achieve this?\n    submitted by    /u/maycontainduck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103gyh7/how_to_establish_ssd_as_writecache_for_hdds/",
          "publishedOn": "2023-01-04T22:19:45.000Z",
          "wordCount": 15753,
          "title": "How to establish SSD as write-cache for HDDs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103gx9s/i_present_disc_mongerenstein/",
          "author": null,
          "description": "submitted by    /u/TheMatchlighter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103gx9s/i_present_disc_mongerenstein/",
          "publishedOn": "2023-01-04T22:18:27.000Z",
          "wordCount": 17209,
          "title": "I Present: Disc Monger-enstein",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103g5k4/category_download_from_archive/",
          "author": null,
          "description": "Hello All,\n Is there any way to download an entire category on Archive org? This was asked three years ago with no definitive answer.\n Many thanks,\n Many Marco\n    submitted by    /u/manymarco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103g5k4/category_download_from_archive/",
          "publishedOn": "2023-01-04T21:49:14.000Z",
          "wordCount": 16684,
          "title": "Category Download from Archive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103g12q/basic_user_seeking_cloud_storage_advice/",
          "author": null,
          "description": "Occasional luddite here - I don't have a need for full back-up services. I have made do with saving photos on this flash drive and resumes that one. But I know I need to beef up my game. Additionally most of my \"stuff\" can probably be tossed but that will be a long-term weeding project.\n With that said, here is my situation: I am currently working with a surface pro 4 tablet. I have roughly 1.5 TB of data (including system files) in Windows and 23 GB of photos and things in Google Drive.\n What I'm looking for in cloud storage - Ease, Cheap, options to both automate and manual back-up as needed, and ability to access a file from any device should I not have mine on-hand.\n Appreciate any advice. I've been reading about iDrive, backblaze and carbonite. I suspect any of these will do but just wanted to get some more info. Thanks!\n    submitted by    /u/francie15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103g12q/basic_user_seeking_cloud_storage_advice/",
          "publishedOn": "2023-01-04T21:44:12.000Z",
          "wordCount": 16339,
          "title": "Basic user seeking cloud storage advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103f8sk/failed_wd_easystore_ext_14tb/",
          "author": null,
          "description": "Looks like my external WD 14TB gave it up. Purchased Nov 21. Only plugged it in three times and moved about 7GB of data. Seems it could be the cheap power supply at fault. Front of the case Led will blink on and instantly off when plugging in 120V adapter. Drive never powers up. Drag. Drive was always packed away in factory box and tucked away in a safe area never disturbed. Claims to have a two year warranty on the box, will see what becomes of that.\n    submitted by    /u/rr777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103f8sk/failed_wd_easystore_ext_14tb/",
          "publishedOn": "2023-01-04T21:14:06.000Z",
          "wordCount": 17708,
          "title": "Failed WD easystore EXT 14TB",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103em6h/new_drives_burnin_with_badblocks_not_000/",
          "author": null,
          "description": "I have 2 new 12tb drives and have run badblocks destruction as burnin with the error results 0/0/2 and 0/0/1. SMART short and long tests were run and is not showing any signs of a bad drive like reallocated sectors, pending sectors or uncorrectable sectors. I'm running the test again in case the errors were false positives so might take some time to come across the errors again. \n I understand the last digits are corruption errors, where there is a discrepancy between what is written and read for that block. Are these minor and will the drives be fine to use or should the results for new drives always score a perfect 0/0/0 with badblocks? Worth RMA even if SMART results are fine? Thanks!\n    submitted by    /u/bob__sponge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103em6h/new_drives_burnin_with_badblocks_not_000/",
          "publishedOn": "2023-01-04T20:50:06.000Z",
          "wordCount": 16857,
          "title": "New drives burnin with badblocks not 0/0/0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103e5vn/this_may_be_of_interest_to_any_uk_datahoarders/",
          "author": null,
          "description": "submitted by    /u/Plebius-Maximus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103e5vn/this_may_be_of_interest_to_any_uk_datahoarders/",
          "publishedOn": "2023-01-04T20:32:38.000Z",
          "wordCount": 15387,
          "title": "This may be of interest to any UK datahoarders. Low capacity drives, but at £5 they're a steal",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103d1rm/8_core_vs_4_core_sas2008/",
          "author": null,
          "description": "why one lsi sas2008 card reports\n no of cores: 8, max_msix_vectors: -1\n vs another saslsi2008 that reports\n no of cores: 4, max_msix_vectors: -1\n thx\n    submitted by    /u/kocoman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103d1rm/8_core_vs_4_core_sas2008/",
          "publishedOn": "2023-01-04T19:49:26.000Z",
          "wordCount": 15870,
          "title": "8 core vs 4 core sas2008?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103c3xn/patrion_vpn110_2tb_delivers_much_worse/",
          "author": null,
          "description": "Hi, I have a Patriot Viper VPN110 2TB PCIE3 NVME SSD and am currently writing some heavy workloads from a video cutting software on it (I am cutting my movie collection). \n Now the problem: When I do the first 2 or 3 runs (~180GB each), the ssd works fine at >1GBps write speed (uncompressed avi video). after that the speed stays only a couple seconds at >1GBps and then drops down to ~150MBps which lets the entire process take much longer (20 instead of 3 minutes).\n I know the SSD first fills the cache, but sometimes it writes 80GB quick before cutting down to 150MBps.\n Here is a benchmark from a review site (for the 1TB disk), even in the real-world-performance test the disk barely went under 500MBps write speed.\n I tought about thermal throttling but after addding a server fan which keeps the ssd below 35 degree C under full load I dont think thats the problem.\n Something interesting too is that even after waiting 2 hours, the ssd wont let me write a \"long\" time at >1GBps again, only when I shut down the computer.\n Can someone explain this weird behaviour?\n    submitted by    /u/PyroRider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103c3xn/patrion_vpn110_2tb_delivers_much_worse/",
          "publishedOn": "2023-01-04T19:13:20.000Z",
          "wordCount": 17787,
          "title": "Patrion VPN110 2TB delivers much worse performance than in tests / unexplainable write speed drops?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103an1u/ea_says_it_cant_recover_60_of_players_corrupted/",
          "author": null,
          "description": "submitted by    /u/retrac1324  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103an1u/ea_says_it_cant_recover_60_of_players_corrupted/",
          "publishedOn": "2023-01-04T18:17:06.000Z",
          "wordCount": 16401,
          "title": "EA says it can’t recover 60% of players’ corrupted Madden franchise save files due to a temporary \"data storage issue\"",
          "imageUrl": "https://external-preview.redd.it/nR3ggMXS17Q4wX84GQdKHfmnmcpng4goagITMO1Uhng.jpg?auto=webp&s=2518a04fa113bc55e29185f2d23f24853f1b52cf"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/103753b/i_just_got_spam_emailed_by_storaxa_all_looks/",
          "author": null,
          "description": "Anyone have any experience with it? I’m always hesitant to try anything that isn’t tested. Or “peer reviewed”. Could be a pile of junk. Thoughts?\n    submitted by    /u/ithyle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/103753b/i_just_got_spam_emailed_by_storaxa_all_looks/",
          "publishedOn": "2023-01-04T16:01:07.000Z",
          "wordCount": 16107,
          "title": "I just got spam emailed by Storaxa. All looks promising but I’ve never heard anything about it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10373ag/advice_for_1st_off_site_setup_for_a_newb/",
          "author": null,
          "description": "Hello - I am a video editor with about 80tb of data. Originals are on two qnap four bay DAS, working files are on a 50tb OWC thunderbolt, and everything gets backed up to a 8 bay 70tb qnap (with a 4 bay qnap as overflow) . I need off site but money is an issue. It’s taken me a lifetime to acquire the drives and enclosures I have. I was considering buying 5 WD 20tb mybooks , and storing them at my parents a few miles away. But I know u won’t like that so I wanted to hear this subs better ideas. That would cost me 1500-2000 which is kinda absolute max. I’ve also considered idrive for cloud instead , but I’m not sure that will be economical . Especially over long term. I originally wanted another server at my parents house that I could back up to over the internet. But I don’t think It makes sense for me to spend that kind of money. I have very basic knowledge of this stuff based on just using my qnap. I don’t know anything about advanced IT. I am using a Mac.\n    submitted by    /u/SausageGrenade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10373ag/advice_for_1st_off_site_setup_for_a_newb/",
          "publishedOn": "2023-01-04T15:59:29.000Z",
          "wordCount": 17016,
          "title": "Advice for 1st off site setup , for a newb",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1036d9b/what_are_some_examples_of_content_that_has_been/",
          "author": null,
          "description": "I came across this thread in the Malcolm in the Middle subreddit, and it got me thinking about other instances of shows or movies being censored, modified, or otherwise changed from the original. Some other examples:\n  \nStranger Things creators changed previous seasons\n \nNetflix removing the suicide scene from 13 Reasons Why\n \nNetworks speeding up shows to fit more ads\n \nSouth Park’s “banned” episodes\n \n    submitted by    /u/AlbinoAlex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1036d9b/what_are_some_examples_of_content_that_has_been/",
          "publishedOn": "2023-01-04T15:29:31.000Z",
          "wordCount": 19245,
          "title": "What are some examples of content that has been censored or altered and you’re glad you have an original copy?",
          "imageUrl": "https://external-preview.redd.it/eM1767lLrkcoZObtBQp-0KvCJ4A3SRYHEjOI43Qb0Rg.jpg?auto=webp&s=8b42c8134cab82c09f48a836708d969375b438fa"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1035y09/automatically_download_photos_from_veracross/",
          "author": null,
          "description": "Our children’s school uses Veracross as their parent portal and posts weekly photos. I always manually go through the posts at the end of the semester to download the photos. Is anyone aware of a Chrome extension or other tool that can automate the process? Thanks!\n    submitted by    /u/Stan_Stanman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1035y09/automatically_download_photos_from_veracross/",
          "publishedOn": "2023-01-04T15:11:40.000Z",
          "wordCount": 16380,
          "title": "Automatically Download Photos from Veracross",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102zvne/ssd_data_longevity_unpowered_1234_years_experiment/",
          "author": null,
          "description": "Since another user recently posted their test for checking data longevity in flash storage (https://www.reddit.com/r/DataHoarder/comments/102razr/flash_media_longevity_testing_3_years_later/) I figured I'd share mine as well.\n I'm doing something similar but didn't use the clever pseudo-random algorithm used by the other user vanceza. I just formatted ExFAT and dumped the same set of randomly generated data stored as txt files to each drive.\n The intent is to check if data is lost while SSD remains unpowered over 1,2,3,4 years time both on a well worn and fresh SSD.\n Test disks are four 128GB 2.5\" SATA SSD's. Some cheap Chinese Leven SSD (JS600). I grabbed a five pack for like $60. Disassembling the last non-test disk SSD revealed some Leven branded NAND flash (JA28A2TB00 - 2148).\n Test fi…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102zvne/ssd_data_longevity_unpowered_1234_years_experiment/",
          "publishedOn": "2023-01-04T10:09:42.000Z",
          "wordCount": 18150,
          "title": "SSD Data Longevity - Unpowered, 1,2,3,4 years experiment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102zpm8/another_hong_kong_media_outlet_purges_its_content/",
          "author": null,
          "description": "https://hongkongfp.com/2023/01/04/one-year-after-its-closure-hong-hong-media-outlet-citizen-news-removes-all-online-content-as-firm-winds-up/\n    submitted by    /u/HKDrewDrake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102zpm8/another_hong_kong_media_outlet_purges_its_content/",
          "publishedOn": "2023-01-04T10:00:21.000Z",
          "wordCount": 15710,
          "title": "Another Hong Kong media outlet purges its content",
          "imageUrl": "https://external-preview.redd.it/8zwV58JKe3ofXI1inqsBlTEhdbh2g3jhjWq15mmADdI.jpg?auto=webp&s=6921d275e63108d1f15abe72ddbedac5df39870b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102ubye/searching_for_an_older_intel_bios_not_the_latest/",
          "author": null,
          "description": "Hi everyone,\n So I've been searching for a day or two for an older Intel BIOS for my DQ77KB motherboard. I know Intel pulled everything from their site years ago and an effort was made to grab everything available as fast as possible. \n Unfortunately, the massive 342GB archive has my bios, but version 0061 which is extremely buggy (broken LAN, voltage, temp monitoring). Intel even went as far as removing the forum sections on their community page so I can't even find workarounds to these issues.\n So with this in mind, I'm wondering if someone here might have Intel DQ77KB BIOS v0058? The filename would be KB0058.BIO and the Intel download mirror number would have been 25621. \n For now I'm going to slap another NIC in the machine, but really hoping to go back to the last stable BIOS.\n    submitted by    /u/nikdaquik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102ubye/searching_for_an_older_intel_bios_not_the_latest/",
          "publishedOn": "2023-01-04T04:51:21.000Z",
          "wordCount": 16174,
          "title": "Searching for an older Intel BIOS (not the latest)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102razr/flash_media_longevity_testing_3_years_later/",
          "author": null,
          "description": "Year 0 - I filled 10 32-GB Kingston flash drives with random data.\n Year 1 - Tested drive 1, zero bit rot. Re-wrote drive 1 with the same data.\n Year 2 - Tested drive 2, zero bit rot. Re-tested drive 1, zero bit rot. Re-wrote drives 1-2 with the same data.\n Year 3 - Tested drive 3, zero bit rot. Re-tested drives 1-2, zero bit rot. Re-wrote drives 1-3 with the same data.\n  \nThis year they were stored in a box on my shelf.\n Will report back in 1 more year when I test the fourth :)\n FAQ: https://blog.za3k.com/usb-flash-longevity-testing-year-2/\n    submitted by    /u/vanceza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102razr/flash_media_longevity_testing_3_years_later/",
          "publishedOn": "2023-01-04T02:27:10.000Z",
          "wordCount": 18703,
          "title": "Flash media longevity testing - 3 Years Later",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102q5aa/do_different_audiovideo_capture_cards_produce/",
          "author": null,
          "description": "Let me start by saying I have had no experience with any of this sort of thing prior to this project, so please explain like I'm 5 :)\n I'm trying to convert a whole bunch of 8mm tapes for my family. Half of them play on a Sony Handycam I have, which I'm using a firewire cable to transfer to my computer. Due to the format of the tapes, the other half will only play on an older camcorder, which just I ordered off of eBay. Problem is that the older model (Sony Handycam CCD-TRV37) has no micro USB port to use firewire. From what I understand, the best way to convert these tapes is with the use of an audio/video capture card (essentially just composite to usb). I know that using this method will lead to some quality loss of the footage, but if it's the only way then it's better than nothing.\n These capture card cable thingies range from like 10 to 100 dollars online. Has anyone used this method to convert old tapes? Does it matter which one I buy, or can I just get a cheaper one? Do you have any recommendations for what software is best for this process? \n Thank you for your help!\n    submitted by    /u/laurenasda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102q5aa/do_different_audiovideo_capture_cards_produce/",
          "publishedOn": "2023-01-04T01:35:03.000Z",
          "wordCount": 16847,
          "title": "Do different audio/video capture cards produce different video qualities when digitizing 8mm tapes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102pd41/actual_quiet_nas/",
          "author": null,
          "description": "Quick question here, I''ve noticed my QNAP NAS does constant HD access. It cannot enter sleep/suspend because of the amount of background programs running on newer QTS. Investigating Synology seems similar, sleep functions might work, but tons of constant HD Access ticks, no matter what. \n I am not a very complex user, I just use it as a file server. I do love the form factor and easy functionality of these NAS' but I can't stand the constant noise it makes. All the \"quiet nas\" reviews and videos focus on quietest hard drives and the most sound proof NAS case/enclosures. It seems like almost no one is focusing on the operating system these run on and how much noise is created when you aren't accessing the NAS at all ! \n My question is: Is there any NAS that doesn't run a ridiculous amount of background tasks, asustor or terramaster etc ? anyone have experience with these operating systems ? As hilarious as it may sound, I would like the drives to operate in the way windows operates, in the sense that, if you aren't accessing the drives, they don't make a single sound. Why can't any NAS be like this ?\n    submitted by    /u/setzer_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102pd41/actual_quiet_nas/",
          "publishedOn": "2023-01-04T01:01:00.000Z",
          "wordCount": 16793,
          "title": "Actual quiet NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102ov02/samsung_t7_touch_samsung_t7/",
          "author": null,
          "description": "Does both the Samsung - T7 Touch and Samsung - T7 require software to be loaded onto my windows or mac machine/pc before reading the content of the drive if it is secure with encryption ?\n    submitted by    /u/ng4ever  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102ov02/samsung_t7_touch_samsung_t7/",
          "publishedOn": "2023-01-04T00:39:50.000Z",
          "wordCount": 16161,
          "title": "Samsung - T7 Touch & Samsung - T7",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102ouo3/alvros_collection/",
          "author": null,
          "description": "Anyone know where to get Alvro's entire rom collection?, I'm looking for it all but specifically xbox 360 roms, In which all the links i came across are dead.\n ​\n TIA\n    submitted by    /u/BadFixMate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102ouo3/alvros_collection/",
          "publishedOn": "2023-01-04T00:39:27.000Z",
          "wordCount": 16449,
          "title": "Alvro's Collection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102neep/convert_blu_ray_live_concert_to_flac_album/",
          "author": null,
          "description": "I'm not sure what subreddit this should go in, if someone has a better suggestion please let me know.\n I have a Blu-ray video of a live concert. I used mkvtoolnix to export the audio by chapter giving me basically an .mka for each track.\n I then used eac3to to convert those to flac, but for some reason the software doesn't like a couple of the tracks and throws an error. I was able to play with the app a bit and get those tracks to convert, but it dropped them from 96khz to 48 and cut the bitrate in half.\n Does anyone have a better way of doing this?\n    submitted by    /u/light5out  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102neep/convert_blu_ray_live_concert_to_flac_album/",
          "publishedOn": "2023-01-03T23:38:59.000Z",
          "wordCount": 16194,
          "title": "Convert Blu ray live concert to flac album?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102mtuf/how_long_should_cloning_a_drive_take/",
          "author": null,
          "description": "Hello friends, I thought this would be the place to go.\n I am cloning my desktop ssd to a new ssd that I intend to put in my pc using Macrium reflect. It has been 2.5 hours and my cloning is only 34% done. Is this normal?\n (`400gb ssd to 2tb ssd)\n    submitted by    /u/IMABOSSSOGG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102mtuf/how_long_should_cloning_a_drive_take/",
          "publishedOn": "2023-01-03T23:15:56.000Z",
          "wordCount": 16564,
          "title": "How long should cloning a drive take?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102l844/sandisk_extreme_2tb_vs_samsung_t7_2tb_they_are/",
          "author": null,
          "description": "My 2TB external HDD is starting to act weird and both of these external SSD's are on sale for $179 I really like the size of the Sandisk but I'm still not sure. Anyone have experience with these?\n    submitted by    /u/osowavy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102l844/sandisk_extreme_2tb_vs_samsung_t7_2tb_they_are/",
          "publishedOn": "2023-01-03T22:13:53.000Z",
          "wordCount": 16191,
          "title": "SanDisk Extreme 2TB vs Samsung T7 2TB... they are the same price and I'm stuck",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102l25s/wd_red_plus_8tb_fine_for_noise_and/",
          "author": null,
          "description": "I plan to get a large drive, as my current one is only 1TB and is almost full. I don't plan to run a NAS server or anything, just a drive to put into my PC. I was considering going 10TB+, but was concerned about the noise as I've heard it gets alot noisier at 7200 RPM. Will the 8TB drive be fine in terms of noise and will the 5400rpm affect me at all for my use case of just watching media on?\n    submitted by    /u/aDeathBoy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102l25s/wd_red_plus_8tb_fine_for_noise_and/",
          "publishedOn": "2023-01-03T22:07:38.000Z",
          "wordCount": 16337,
          "title": "WD Red Plus 8TB fine for noise and storing/watching media in a PC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102jzav/audio_cd_backup/",
          "author": null,
          "description": "Hello, how to copy a disc with music in audio cd format on a PC as clearly as possible.\n Do I need any programs for this or is a unix DD sufficient?\n    submitted by    /u/kovach_ua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102jzav/audio_cd_backup/",
          "publishedOn": "2023-01-03T21:27:09.000Z",
          "wordCount": 16536,
          "title": "audio cd backup!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102jyfo/syncbackup_solution_for_windows_and_linux/",
          "author": null,
          "description": "Hello,\n I'm looking for a sync/backup solution that works on windows and linux.\n For the longest while I just used linux for everything and I'd used rsync to backup all my data (photos, code, projects, configurations, etc.) to a local NAS device. This was simple and easy as I just had the one machine and rsync was simple.\n In recent years I now have a couple of linux machines and a couple windows machines at home that I'd like to keep synced/backed up. I see there are some solutions to using rsync on windows but I thought I'd see if there is some more robust cross-platform solution, or if not more robust, more tailored to this scenario.\n My requires are essentially:\n  \nI can sync a local folder with a local network folder (ssh, smb, or something else) \n e.g. I can say photos folder on devi…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102jyfo/syncbackup_solution_for_windows_and_linux/",
          "publishedOn": "2023-01-03T21:26:11.000Z",
          "wordCount": 17420,
          "title": "Sync/Backup solution for Windows and Linux",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102jwds/cdr_vs_dvdr_vs_bdr_longevity/",
          "author": null,
          "description": "Is there any inherent advantage to a CD-R, DVD-R, or BD-R compared to the others when it comes to expected or likely longevity? I need to archive some digital documents (about 100MB) in a read only form and wondering if it might be better to use a DVD-R or BD-R instead of a CD-R even though they fit just fine on a CD-R.\n    submitted by    /u/HarryMuscle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102jwds/cdr_vs_dvdr_vs_bdr_longevity/",
          "publishedOn": "2023-01-03T21:24:00.000Z",
          "wordCount": 18376,
          "title": "CD-R vs DVD-R vs BD-R Longevity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102iv2n/original_or_remastered_editions/",
          "author": null,
          "description": "When you’re archiving a show, movie, album, whatever, do you tend to go for the original release or remasters? It’s a hard choice for me. I tend to go remastered, I know there are some “remasters” out there that look/sound worse than the original, but I don’t have the patience to go comparing each version to find the best one, nor do I have the space to justify having multiple copies of what is essentially the same thing.\n    submitted by    /u/bobisnotmyuncIe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102iv2n/original_or_remastered_editions/",
          "publishedOn": "2023-01-03T20:44:31.000Z",
          "wordCount": 15433,
          "title": "Original or remastered editions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102hhfs/brand_new_seagate_ironwolf_drive_has_bad_sectors/",
          "author": null,
          "description": "Hi there,\n I just recently bought my first NAS (Asustor 6 Gen 2) and some seagate Ironwolfs (4TB HDDx4) with it.\n After setting everything up and the RAID 5 syncing drive, one reported bad sectors: https://imgur.com/v1jI2kx \n I searched it up a little and as far I can tell, HDD drives have fault tolerances and as long as the bad sector count doesn't increase it is not a problem, but no definitive answer on what should I do.\n Is this enough for me to return the Drive to the vendor and request a new one? Should I?\n    submitted by    /u/Perkovax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102hhfs/brand_new_seagate_ironwolf_drive_has_bad_sectors/",
          "publishedOn": "2023-01-03T19:49:28.000Z",
          "wordCount": 26323,
          "title": "Brand new Seagate Ironwolf drive has bad sectors, return?",
          "imageUrl": "https://external-preview.redd.it/DpLwHoNxuwd7JJvmY4SR7HksF7YaezF4XnQf5g-sS3c.jpg?auto=webp&s=0435cda288cadce16a78bdf444bf7b7d34e6710d"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102h6dz/downloading_from_any_flip/",
          "author": null,
          "description": "Hi everyone, I'm trying to figure out how to download something from anyflip but cant seem to work it out. \n I've used the searchbar and looked online but I'm comming up short. \n I want to download this:\n https://online.anyflip.com/ziisf/jobq/mobile/index.html \n I believe I can download something if I can find it nativley on the anyflip website but the only way I can find this is by googling \"Age of Rebellion PDF\". \n Can anyone assist me please in finding how to hord this data? On the other hand, if anyone knows where I can download these starwars RPG's easily then that would be greatly appreciated :) \n Thanks!\n    submitted by    /u/X1nfectedoneX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102h6dz/downloading_from_any_flip/",
          "publishedOn": "2023-01-03T19:37:03.000Z",
          "wordCount": 16247,
          "title": "Downloading from Any flip?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102ggui/backing_up_multiple_oses/",
          "author": null,
          "description": "Hi there, I would like to backup multiple OSes (macOS, windows, linux). For now I just bought 2 HDD's that I plan to use to mirror my backups.\n From what I've read online I could do something like this:\n  \nUse exFAT format on my HDDs so each OS can read-write on them natively, but this format type gets easily corrupted.\n Maybe use my Windows machine to set up the HDD as a network drive through SMB and just use NTFS. (use Windows machine as proxy to write/read from each OS)\n  \nI think that a NAS is overkill since I don't need the data to be always online. I just want to backup important data on the HDDs and forget about it, but would like to be able to access it from each machine that I own.\n ​\n Is there a better way to do this?\n    submitted by    /u/TopGrind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102ggui/backing_up_multiple_oses/",
          "publishedOn": "2023-01-03T19:08:53.000Z",
          "wordCount": 16586,
          "title": "Backing up multiple OSes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102g0qm/weird_flickering_when_capturing_with_elgato/",
          "author": null,
          "description": "submitted by    /u/h3ku  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102g0qm/weird_flickering_when_capturing_with_elgato/",
          "publishedOn": "2023-01-03T18:51:34.000Z",
          "wordCount": 15574,
          "title": "Weird flickering when capturing with Elgato",
          "imageUrl": "https://external-preview.redd.it/eGa7hhQ1GOLol5HiWYx9kN9_cll6mS8jcuQgeQPTvGA.png?format=pjpg&auto=webp&s=94a211f1213d47b4d9c0f920f0ee63c08677fa89"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102euta/google_drive_network_error_when_download_larger/",
          "author": null,
          "description": "Anyone here got the problem of cant conplete te download of large files on google drive and get network error ?\n ​\n Im downloading and i try from 3 pcs and the 3 got error. The file is large is an account dump.\n    submitted by    /u/chaos4455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102euta/google_drive_network_error_when_download_larger/",
          "publishedOn": "2023-01-03T18:06:50.000Z",
          "wordCount": 16740,
          "title": "Google drive network error when download larger file",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102e8cp/why_did_you_become_a_data_hoarder/",
          "author": null,
          "description": "Me personally I grew in a place where the internet cuts off randomly and sometimes for days and thus I had it with this shit and started to collect stuff I need or partially even tho I moved to a different town where the network is pretty much available at all time. I’ve started collecting from the start of 2020 and it felt so good to have everything available on my computer and other storage devices. Projects, YouTube videos, entertainment, software, games, arts, OC content and more and I mean MORE! That means MORE terabytes! I became obsessed of buying hard drives and storing data! Edit within just 1 millisecond the post is already downvoted lmao\n    submitted by    /u/ElonTastical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102e8cp/why_did_you_become_a_data_hoarder/",
          "publishedOn": "2023-01-03T17:43:04.000Z",
          "wordCount": 17843,
          "title": "Why did you become a Data Hoarder?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102e78h/question_is_there_any_4tb_25_hdd_compatible_with/",
          "author": null,
          "description": "And is it even woth it over ssd?\n I work with a big amount of files that I need to acces daily so I really don't want to use external drives for that matter. My 1TB drive is always full and 2TB just won't be enough in a long run (yes I want to use it for games too)\n I am keeping the m.2 purely for OS and some essentional programs so my only option is to replace the 2,5\" drive.\n Are there any high capacity hdd for laptops or should I just cash out 500€+ for ssd?\n I know about the Seagate barracuda 2,5\" but they aren't the most reliable and it may not even fit to my laptop due to it's height.\n Thanks for any suggestions :)\n    submitted by    /u/Burrito667  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102e78h/question_is_there_any_4tb_25_hdd_compatible_with/",
          "publishedOn": "2023-01-03T17:41:51.000Z",
          "wordCount": 16696,
          "title": "Question.: Is there any 4TB 2.5\" hdd compatible with laptops?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102d21j/cooling_pad_to_keep_external_hard_drive_cool/",
          "author": null,
          "description": "I have a 4TB lacie eternal drive I'm looking for a way to keep it cool. I know there are plenty of laptop/gaming cooling pads out there but I'm looking for something smaller for my desk. The only small one I've found with a decent rating was this. I was wondering if anyone uses one they like?\n    submitted by    /u/nanananiki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102d21j/cooling_pad_to_keep_external_hard_drive_cool/",
          "publishedOn": "2023-01-03T16:56:13.000Z",
          "wordCount": 17059,
          "title": "cooling pad to keep external hard drive cool?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/102cecs/questions_about_mirroring_fandomwiki_sites/",
          "author": null,
          "description": "I was looking at this post which seems to have some workarounds to a problem I was facing with certain fandom sites. This one for example, the special:statistics page doesn't seem to provide anything useful unless I'm missing something. The dump at the bottom seems to be missing, but I think I've found it here.\n My goal is to have an offline copy of many wiki sites with images, I can do this with wget but it takes ages and I'm thinking there has to be an easier way. This comment thread seems to have some good information but I can't figure out where to start, is there a good beginners guide for stuff like this?\n    submitted by    /u/erik530195  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/102cecs/questions_about_mirroring_fandomwiki_sites/",
          "publishedOn": "2023-01-03T16:29:44.000Z",
          "wordCount": 17746,
          "title": "Questions about mirroring fandom/wiki sites",
          "imageUrl": "https://external-preview.redd.it/hCNydqiZK5rAgNJ2hw6sgHpzIau7zTkVMPo24iguMMc.jpg?auto=webp&s=c0f3b41d4ca54a75d5c1a9ecce06e5c9c47218db"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10264jc/how_do_you_use_a_jbod/",
          "author": null,
          "description": "How do I use a Dell PowerVault MD1000?\n A while back I got a Dell PowerVault MD1000 and a Dell External HBA (0M778G) to go with my Dell Poweredge R710 running Fedora 37.\n I have not got any of the final drives (2TB DELL SAS) for it yet, but when I do and if it is correctly connected can I use the drives as if they were connected in any other way?\n I know it is a stupid question, but I just want to be 100% sure.\n    submitted by    /u/FinalFir137  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10264jc/how_do_you_use_a_jbod/",
          "publishedOn": "2023-01-03T11:50:01.000Z",
          "wordCount": 16262,
          "title": "How do you use a JBOD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1025giw/how_do_i_make_the_best_of_a_11mbs_down_connection/",
          "author": null,
          "description": "Yes I know it's 2023 and I live in London but unfortunately this is the fastest internet you can get in the basement apartments. My neighbours upstairs have Gigabite but for whatever reason the ISP decided not to install to the basement apartments so I'm stuck with good ol' Coax. \n ​\n How can I make the best of this connection for my data hording needs? I run a nextcloud instance for my family and also download every movie I watch.\n    submitted by    /u/utabain1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1025giw/how_do_i_make_the_best_of_a_11mbs_down_connection/",
          "publishedOn": "2023-01-03T11:14:08.000Z",
          "wordCount": 17019,
          "title": "How do I make the best of a 11Mb/s down connection?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10259iu/i_swapped_the_acrylic_side_panel_on_my_node_804/",
          "author": null,
          "description": "submitted by    /u/ItsBarney01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10259iu/i_swapped_the_acrylic_side_panel_on_my_node_804/",
          "publishedOn": "2023-01-03T11:03:15.000Z",
          "wordCount": 15823,
          "title": "I swapped the acrylic side panel on my node 804 to the side with the drives!",
          "imageUrl": "https://preview.redd.it/uesz5r9d8t9a1.png?auto=webp&s=d171fb663bbbf497235f7e099ec1d3cf5603b2fc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101tnr4/library_for_3d_models_of_real_world_objects/",
          "author": null,
          "description": "Do you guys know an archive/library of 3D models/scans of real world objects e.g. vehicles, buildings, animals, landscapes and so on?\n The common 3D printing sites are mainly technical parts and toys. \n Suggestions are appreciated!\n    submitted by    /u/MakitaFlex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101tnr4/library_for_3d_models_of_real_world_objects/",
          "publishedOn": "2023-01-03T01:06:15.000Z",
          "wordCount": 16948,
          "title": "Library for 3D Models of real world objects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101tmwf/anyone_have_any_experience_with_this_chinese_no/",
          "author": null,
          "description": "submitted by    /u/GUI-Discharge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101tmwf/anyone_have_any_experience_with_this_chinese_no/",
          "publishedOn": "2023-01-03T01:05:14.000Z",
          "wordCount": 16862,
          "title": "anyone have any experience with this Chinese no name ssd",
          "imageUrl": "https://external-preview.redd.it/PZHPMGbh5yG-Q_EWorYM0IyU6GClXQiXtugaGVhn10k.jpg?auto=webp&s=99a8b4fc48693b3283390633628c09b82ca67093"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101t82o/my_collection/",
          "author": null,
          "description": "submitted by    /u/jonnypockets1121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101t82o/my_collection/",
          "publishedOn": "2023-01-03T00:47:28.000Z",
          "wordCount": 17785,
          "title": "My Collection.",
          "imageUrl": "https://preview.redd.it/cb8h4v39or9a1.jpg?auto=webp&s=43edf2a4fc5b01ac4446337526f6fc513cfb723c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101t5x5/im_looking_to_dig_up_the_elite_dangerous/",
          "author": null,
          "description": "this wayback page has a chunk of it, but i fear the rest has been lost to time along with the youtube channel back in 2019.\n hell the only way i determined it concretely existed in the first place was because i found an old bit of internet news talking about it, search engines did a shockingly good job burying reference to its existence since then.\n    submitted by    /u/pyr0kid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101t5x5/im_looking_to_dig_up_the_elite_dangerous/",
          "publishedOn": "2023-01-03T00:44:50.000Z",
          "wordCount": 17102,
          "title": "im looking to dig up the elite dangerous machinima series \"DarkenSpace\" aka \"Draven Darken\", does anyone have a copy or know of archives projects other then archive.org that cover youtube?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101rvoj/photo_sync_and_management/",
          "author": null,
          "description": "Hi all,\n I'm looking for some input and feedback or ideas on how to best backup photos/videos from my mobile devices(a Android phone and iPad) and manage them.\n My current setup is that I use resilio sync to copy the files to my home server(a headless debian server) and this part works excellent. I really like resilio. Resilio dumps all the files into one folder and I then use a cli app(sortphotos) to organize the photos. I then use photoprism to view and review/delete crappy photos.\n My issue is: \n When I delete bad photos within photoprism, the next time I use sortphotos to copy new images over, it will recopy the crappy photos as well. \n Is my setup/workflow just not that good? I want to be able to keep most the images on the devices as well since it's faster/easier to show people the photos when I'm not at home. \n Thanks!\n    submitted by    /u/Rickie_Spanish  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101rvoj/photo_sync_and_management/",
          "publishedOn": "2023-01-02T23:51:16.000Z",
          "wordCount": 17605,
          "title": "Photo Sync and Management",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101rbvo/downloading_newspapers/",
          "author": null,
          "description": "Does anyone know of a way of backing up an entire newspaper off of something like newsbank.com or genealogybank.com?\n    submitted by    /u/iryuskii  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101rbvo/downloading_newspapers/",
          "publishedOn": "2023-01-02T23:28:44.000Z",
          "wordCount": 16896,
          "title": "Downloading newspapers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101qt2a/tips_on_digitizing_numerous_cdrs_and_8mm_tapes/",
          "author": null,
          "description": "I got a box containing 210 MB Memorex Pocket CD-R's and TDK HS120 8 mm Metal Particle Tapes containing years of memories for my family and myself. How would I begin the process of digitizing them? I know the cassettes work on a Handycam Video 8 and the CD-R's work on on a Sony MVC-CD400, both of which I have on hand. Any help would be much appreciated. Thanks!\n    submitted by    /u/Gopal6600  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101qt2a/tips_on_digitizing_numerous_cdrs_and_8mm_tapes/",
          "publishedOn": "2023-01-02T23:07:44.000Z",
          "wordCount": 16624,
          "title": "Tips on Digitizing Numerous CD-R's and 8mm Tapes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101pecc/does_anyone_know_how_to_download_from/",
          "author": null,
          "description": "This is an example. The ways I normally download videos aren't working.\n    submitted by    /u/onlytoask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101pecc/does_anyone_know_how_to_download_from/",
          "publishedOn": "2023-01-02T22:11:46.000Z",
          "wordCount": 16471,
          "title": "Does anyone know how to download from watch.videodelivery.net?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101m4x7/thoughts_on_using_8tb_wd_blues/",
          "author": null,
          "description": "I'm slowly rebuilding my file server, which right now has a single WD80EMZZ I shucked from an EasyStore enclosure. Currently I'm looking at the WD Blue 8TB, which has the model # WD80EAZZ. What are y'alls thoughts on these drives? They don't seem that bad on paper, with the only immediately obvious difference to my EMZZ being 128MB of cache instead of 256MB (they even have the same kinda weird 5640RPM spindle speed).\n For what it's worth, I'll be starting out with 9 drives installed in a Define 7 and going from there, so there is certainly some vibration tolerance that I feel should be taken into consideration.\n The price on them is certainly right, but if they're not a good match for a server use-case then I'll just have to suck it up and hold off on an EasyStore/Elements to go on an equally-good sale.\n    submitted by    /u/flibberdipper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101m4x7/thoughts_on_using_8tb_wd_blues/",
          "publishedOn": "2023-01-02T20:05:12.000Z",
          "wordCount": 17054,
          "title": "Thoughts on using 8TB WD Blues?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101le00/trying_to_avoid_visual_artifacts_on_bluray_burn/",
          "author": null,
          "description": "I'm trying to burn a video file onto a blu-ray disc. I've figured out how to convert everything into a blu-ray friendly ISO and I'm burning it using ImgBurn, and all that seems to be working. But every time I test the disc in a player, about 10 minutes in (not always the exact time, but around there) there's about one second of crazy visual artifacts around the screen.\n It looks like this: https://i.imgur.com/eJN8BN0.jpg\n I of course checked the original video file and it's not there, so it seems to be happening during the burning process. Is there some common thing that causes this, and a good way to avoid it? I tried burning at 2x instead of 4x speed and it's still showing up, which was the only idea I had.\n    submitted by    /u/Draekwon2000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101le00/trying_to_avoid_visual_artifacts_on_bluray_burn/",
          "publishedOn": "2023-01-02T19:36:02.000Z",
          "wordCount": 16853,
          "title": "Trying to avoid visual artifacts on blu-ray burn",
          "imageUrl": "https://external-preview.redd.it/opYcTp3Va8V92Gt-_YceHffl1KjT3IRqC21DkGy8lKI.jpg?auto=webp&s=f3a1e7ddec0fa39f93ad241e836f00878787b564"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101ka39/whats_the_best_way_to_browse_a_magazines/",
          "author": null,
          "description": "Hello everyone,\n I guess I'm not the only magazine hoarder and since the files are much smaller than say movies or iso files, those add up really fast.\n I would like to find a way to be able to browse this collection a bit like a Plex server, to be able to browse the covers, mark a magazine as read, add tags etc.\n I specify that I tested the Komga server which is perfect for comics/manga but not at all suitable for magazines. This is because Komga can only support (in magazine display and processing) one level of folders. Thus, in the case of a tree structure organized by year of publication, it will consider each year as a different magazine...\n Maybe a simpler solution exists. How do you do it dear hoarders?\n    submitted by    /u/Feeling_Usual1541  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101ka39/whats_the_best_way_to_browse_a_magazines/",
          "publishedOn": "2023-01-02T18:52:08.000Z",
          "wordCount": 16408,
          "title": "What's the best way to browse a magazines collection?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101k34i/trying_to_back_up_my_entire_uni_classes_best_50to/",
          "author": null,
          "description": "I'm trying to back up my uni classes because im dropping out to work for a bit and would still like to study on the side. I have about 200-250 videos each roughly 650MB. I was gonna go with degoo but on their reddit the first three posts were about degoo deleting people's stuff due to copyrights issues (movies and such). idk if what im trying to do is legal but I don't think uni classes have copyrights issues for private use since the uni allows us to dl them anyway ?\n anyway does anyone of you guys have an idea what cloud storage I should use for that ? I've looked at some stuff and it was like 1k a year..\n    submitted by    /u/NoPromotion5408  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101k34i/trying_to_back_up_my_entire_uni_classes_best_50to/",
          "publishedOn": "2023-01-02T18:44:13.000Z",
          "wordCount": 16003,
          "title": "trying to back up my entire uni classes -best 50to cloud storage ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101jjif/resell_bin_donate/",
          "author": null,
          "description": "what is the ethics or laws on the physical media or you don't want the actual discs?\n so I own something on physical media like a cd or dvd and I make a backup of it digitally. but what if I don't own the dvd or cd anymore? what can I do with the physical media? do I have to bin it? and can't resell it, right? can a person give it away for free to someone? I know its possible to buy software licence's from other people who bought a digital serial number to unlock software and no longer wish to own it. in those instances the software is transferred and that original owner no longer owns it, is the same principle applied to cd's and dvds? if the person sells it on then they can't keep a copy (?)\n I mean, it's far less clutter to just store all that media on a hard drive and then just get rid of the discs! I have had people give music and films to me for free, I don't want to keep the discs but wouldn't mind having a digital copy, should I bin the disc, donate it, or sell it?\n    submitted by    /u/Single-Inevitable154  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101jjif/resell_bin_donate/",
          "publishedOn": "2023-01-02T18:21:55.000Z",
          "wordCount": 17847,
          "title": "resell, bin, donate?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101hsjm/recover_video_from_wayback_machine/",
          "author": null,
          "description": "Hello Ladies and Gentlemen,\n I've found the link to a youtube video from a long lost banned account.\n When I visit the link it loads the Youtube page and then the video keeps loading, I've seen people say it can take hours before the video has finished loading, so I have it in the background and have my fingers crossed.\n ​\n However... If I try and download the video via https://web.archive.org/web/2oe_/http://wayback-fakeurl.archive.org/yt/ICvB8ptbNEE I get the message :\n \"Hrm.\n The Wayback Machine has not archived that URL.\n This page is not available on the web\n because of server error\"\n ​\n So, does the video even exist at all? Clearly it is loading something ?\n Link to the snapshot : https://web.archive.org/web/20210204000214/https://www.youtube.com/watch?v=ICvB8ptbNEE\n ​\n Link to the download failing : https://web.archive.org/web/2oe_/http://wayback-fakeurl.archive.org/yt/ICvB8ptbNEE\n ​\n Thanks in advance.\n    submitted by    /u/Gozzah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101hsjm/recover_video_from_wayback_machine/",
          "publishedOn": "2023-01-02T17:13:02.000Z",
          "wordCount": 18084,
          "title": "Recover video from Wayback Machine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101ggu6/sans_digital_4_bay_esata_conversion_to_sas/",
          "author": null,
          "description": "I have a bunch of Sans Digital 4 bay eSATA external cases. I also just recently went through and upgraded a the drives in my servers. So I also have a bunch of unused hard disks. I was wondering if anyone knew of a way to convert the Sans Digital 4 bay eSATA cases to SAS. When I open up one of the Sans Digital cases, I see that there is a single eSATA to SATA cable running to the backplane. There is another ribbon cable for the activity lights and a couple molex connectors to the backplane. \n Would this be worthwhile or just more trouble than its worth? If so, what are some decent, inexpensive, alternatives for an external 4/8bay SAS enclosures? I have about 20 drives I'd like to repurpose. \n Thanks!\n    submitted by    /u/Dan_Gun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101ggu6/sans_digital_4_bay_esata_conversion_to_sas/",
          "publishedOn": "2023-01-02T16:18:25.000Z",
          "wordCount": 15964,
          "title": "Sans Digital 4 bay eSATA conversion to SAS ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101gby4/transcend_or_western_digital_external_hard_drive/",
          "author": null,
          "description": "I want to get a 2TB external hard drive and I've limited my choices to these two after a bit of consideration. Which would you consider as the better brand and why? \n ​\n View Poll\n    submitted by    /u/mimobrown  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101gby4/transcend_or_western_digital_external_hard_drive/",
          "publishedOn": "2023-01-02T16:12:39.000Z",
          "wordCount": 17534,
          "title": "Transcend or Western Digital External Hard Drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101b234/how_should_i_go_about_upgrading_my_current_setup/",
          "author": null,
          "description": "Hey everyone,\n I currently have a Plex server running on a mini Windows desktop PC with an i5-8500 CPU and 8 gigs of RAM. It has a 256gb SSD and then all of my media is stored in two external drives of 1TB and 4TB.\n To be honest, this set up has done really well for me and changing it is not 100% necessary. However, 5TB of storage is no longer viable and I need to upgrade. Adding more external drives would be an option, but I don't really like the idea of having a bunch of drives laying around attached to my PC.\n So, I considered buying a hard drive dock, that would allow me to put in multiple drives and plug all into my computer with a single cable. However, at this point, I started to think that maybe it would just be worth it to go all the way and set up a NAS.\n Now, I have no idea on how NAS work other than watching a video or two on the subject. I also do not know what benefits I stand to gain from using one.\n As I said, my setup has worked well in terms of performance (I have at most 3 people watching at once). I do not have any 4k media, nor do I plan on having it anytime soon, but I would like for this to be viable.\n To sum up, I think it all boils down to this question - Do I go the dock route and keep everything simple or go all out and go for a NAS? What benefits does one have over the other? If it helps, my budget for this upgrade sits between 300-500€.\n Thank you!\n    submitted by    /u/Supertriu1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101b234/how_should_i_go_about_upgrading_my_current_setup/",
          "publishedOn": "2023-01-02T12:06:59.000Z",
          "wordCount": 17976,
          "title": "How should I go about upgrading my current setup?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/101aazl/archiving_games_reliable_drives_question/",
          "author": null,
          "description": "For the last few years, I've been using shucked drives and have come up with 2x 4tb hdds, with an additional 1tb nvme boot, 1 nvme gaming and 1 tb sata ssd for gaming as well. I'd like to either consolidate, and update the drives, because at the end of the day, they were of unknown backgrounds and I've started getting some warning signs like explorer freezing when opening text or .rar files.\n I saw a crucial mx500 4tb for $289, but would this be better than a hdd for my purpose? The hdds are to archive steam games mainly, so I won't have to download again, and blu-ray archiving.\n Thanks in advance.\n    submitted by    /u/rsdj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/101aazl/archiving_games_reliable_drives_question/",
          "publishedOn": "2023-01-02T11:21:15.000Z",
          "wordCount": 16750,
          "title": "archiving games, reliable drives question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10197uf/do_you_always_go_for_the_highest_available/",
          "author": null,
          "description": "There are times where it’s obviously preferable to have the highest quality version of a piece of content you can find, especially if it’s harder to come by. but sometimes it feels wasteful. It’s not like I have unlimited storage space, especially if I want to keep backups of everything. Like do I really need 200 GBs worth of Lost? I’ll go for the highest quality versions of movies or TV shows that have special meaning to me, but for content I’m less interested in and just want to have around, 720p is fine. Lowest I’ve gone is 360p, mainly for long-running old shows that never had great picture quality to begin with.\n    submitted by    /u/bobisnotmyuncIe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10197uf/do_you_always_go_for_the_highest_available/",
          "publishedOn": "2023-01-02T10:15:08.000Z",
          "wordCount": 23539,
          "title": "Do you always go for the highest available quality version of everything?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1016chi/gallerydl_folder_iteration_how_to_create_variable/",
          "author": null,
          "description": "Finally throwing in the towel here; spent hours trying to figure this out to no success. Any help? Imgur album at https://imgur.com/a/4lUMDfC. Site in question's NSFW, but the content I'm looking for help with isn't.\n Idea here is that I'd like to use gallery-dl's extractor to REPLICATE aryion's gallery folder structure up to four levels deep; they're structured where individual artists are able to organize works into individual custom folders akin to local storage, so you'll often encounter content that's subcatergorized via multiple iterations (IE 'gallery', 'content type', 'work sequence'). \\Gallery_DL\\gallery-dl.exe -K https://aryion.com/*** will show you quick that this information is sent from the api via the 'path[N]' container...\n But the problem is, I simply cannot reverse enginee…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1016chi/gallerydl_folder_iteration_how_to_create_variable/",
          "publishedOn": "2023-01-02T07:17:25.000Z",
          "wordCount": 17368,
          "title": "Gallery-DL Folder Iteration - How to Create Variable Sub-Directories / continue past null api calls?",
          "imageUrl": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?auto=webp&s=6a09fa9a44ef8d270e85eb9fce036c635a27c9c6"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1012unv/cable_management_is_overrated_when_you_have_27/",
          "author": null,
          "description": "submitted by    /u/iamcts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1012unv/cable_management_is_overrated_when_you_have_27/",
          "publishedOn": "2023-01-02T04:09:01.000Z",
          "wordCount": 16666,
          "title": "Cable management is overrated when you have 27 drives in a case to cable up",
          "imageUrl": "https://preview.redd.it/tll16p189r8a1.jpg?auto=webp&s=4955f34473be257ad52740705bf174c7dd3ea796"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100ziri/how_can_i_back_up_my_iphones_gallery_to_my_pc/",
          "author": null,
          "description": "I don’t want to pay for iCloud as buying actual storage is much cheaper, at least in the long run. I have a Windows PC that’s on 24/7 and it has a 1TB SSD, which has ~500GB free, more than enough for my photos and videos.\n    submitted by    /u/ffsstfualready  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100ziri/how_can_i_back_up_my_iphones_gallery_to_my_pc/",
          "publishedOn": "2023-01-02T01:27:52.000Z",
          "wordCount": 19488,
          "title": "How can I back up my iPhone’s gallery to my PC automatically?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100zihf/i_need_help_optimizing_storage/",
          "author": null,
          "description": "I currently have 10 Terabytes of drive capcity But I am in process of upgrading my pc.\n Not Sure If I should take drives and build cheap server or buy nas most of the storage is HDD.\n My concern is power but engegy prices are so high in the United Kingdom would it just be cheaper to a buy a nas?\n    submitted by    /u/drjonsmith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100zihf/i_need_help_optimizing_storage/",
          "publishedOn": "2023-01-02T01:27:27.000Z",
          "wordCount": 16105,
          "title": "I need help optimizing storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100yx7i/dvd_burning/",
          "author": null,
          "description": "Can I burn DVDs to keep my show and movies off my hard drive I use. since I don't have that much money and I already have all the hardware and software needed? and if so can I have a Recommendation on where to buy good quality disks from?\n    submitted by    /u/SirWillem1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100yx7i/dvd_burning/",
          "publishedOn": "2023-01-02T01:00:30.000Z",
          "wordCount": 14891,
          "title": "DVD Burning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100xgs1/can_i_scan_4_photos_at_once_on_my_flatbed_scanner/",
          "author": null,
          "description": "I have hundreds and possibly thousands of older photos I want to digitize and save. The Epson FastPhoto seems like the way to go, but is expensive. \n My thought is that I could put 4 pictures on my flatbed scanner then divide them up once I scan it. Seems like it would be faster than scanning one picture at a time. \n Has anyone used a flatbed scanner to save old photos? What do you recommend? \n EDIT: forgot to add.... I would like to buy an external HD to save the photos on. Is there a plug and play HD that I can move from one computer to another if needed? The last one I had many years ago was a major pain to use and required one to use western digital a software and I hated it. Thank you\n    submitted by    /u/EverySingleMinute  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100xgs1/can_i_scan_4_photos_at_once_on_my_flatbed_scanner/",
          "publishedOn": "2023-01-01T23:56:01.000Z",
          "wordCount": 14947,
          "title": "Can I scan 4 photos at once on my flatbed scanner then divide them into individual pictures to save them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100wo01/do_not_purchase_these_ssds_that_are_coming_from/",
          "author": null,
          "description": "submitted by    /u/Cynical-Pessimistic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100wo01/do_not_purchase_these_ssds_that_are_coming_from/",
          "publishedOn": "2023-01-01T23:20:36.000Z",
          "wordCount": 16824,
          "title": "Do not purchase these SSDs that are coming from China. They are worthless, learn from my mistake.",
          "imageUrl": "https://preview.redd.it/ap1ezyk6mi9a1.jpg?auto=webp&s=c7d5428321221e24015d3037060814212801c832"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100w2io/help_with_smart_data/",
          "author": null,
          "description": "PR4100 reporting 2x bad disk. Can you help me diagnose what I am looking at? Can I just reboot this and hope it goes away, or should I be buying new disk? Thanks\n    submitted by    /u/CactusJ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100w2io/help_with_smart_data/",
          "publishedOn": "2023-01-01T22:56:21.000Z",
          "wordCount": 15568,
          "title": "Help with SMART data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100v3q5/would_someone_here_be_kind_enough_to_help_archive/",
          "author": null,
          "description": "https://iwataasks.nintendo.com/\n Recently, Nintendo started unlisting some of their other pages. I worry that these interviews are at risk.\n The site consists of a series of static pages that are all linking to each other, like a mini encyclopedia.\n I tried backing them up before, but I am not good enough at scripting to pull it off.\n Would really love it if someone could do this and maybe end up with a folder with all the htmls in there.\n    submitted by    /u/mekilat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100v3q5/would_someone_here_be_kind_enough_to_help_archive/",
          "publishedOn": "2023-01-01T22:14:40.000Z",
          "wordCount": 16019,
          "title": "Would someone here be kind enough to help archive the Iwata Asks interviews ? they're at risk",
          "imageUrl": "https://external-preview.redd.it/bcqp--ico1bkbdkyXM3VsvPpZZHVWVWbdKfevw_FULU.jpg?auto=webp&s=76cd6bb483523bbbeb55273d09b420f83e34ac60"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100ul8z/a_few_questions_about_blurays/",
          "author": null,
          "description": "Ok, so I've been looking into ripping my blu-rays for a bit. From my understanding you may need to flash specific drives if you intend on ripping 4k UHD disks. I found the MakeMKV post about flashing drives but I'm still a bit confused\n  \nI intend on only ripping non-UHD disks for the forseeable future. Do I need to flash the drive anyways, or is that only for ripping UHD?\n I saw that I could use an LG WH14NS40 or LG WH16NS40. I would need an enclosure. Would buying them straight from Amazon be an okay method?\n  \n   submitted by    /u/delasislas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100ul8z/a_few_questions_about_blurays/",
          "publishedOn": "2023-01-01T21:53:42.000Z",
          "wordCount": 15866,
          "title": "A few questions about Blu-rays",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100tu5q/das_drawer_recommendations/",
          "author": null,
          "description": "Any recommendations for a DAS drawer? Looking for 12-40 bays. Currently using an MSA60 that I've had forever and 4 lanes of 3Gb SAS is a bit of a choke. 6G would be fine, 12G preferred.. I remember there was a Lenovo that also had a couple 2.5\" bays that might be good for what I'm doing, but I don't know what the model # was.\n    submitted by    /u/frankd412  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100tu5q/das_drawer_recommendations/",
          "publishedOn": "2023-01-01T21:22:36.000Z",
          "wordCount": 16111,
          "title": "DAS drawer recommendations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100t2ol/nas_advice/",
          "author": null,
          "description": "I want to have a NAS with two requirements. It must have ECC memory and ZFS. I'm looking at TrueNAS software for the ZFS, but I am a bit lost on the ECC part.\n I am considering getting one of the TrueNAS systems, but that's a big splurge. $1000+ and that's not even including the cost of the drives themselves.\n I have seen on PC Part Picker that I can get ECC compatible processors in the $50 range, but the motherboards are in the $500 range (yikes). Still better than buying a TrueNAS machine, but once I've bought all the other parts (RAM, power supply, graphics card, case) I could see it being closer in price to the expensive TruaNAS.\n I think I've discovered a good option. On both Amazon and eBay are a lot of refurbished Dell and HP Xeon desktops. They vary in price from $100-500. The Xeon…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100t2ol/nas_advice/",
          "publishedOn": "2023-01-01T20:50:52.000Z",
          "wordCount": 16071,
          "title": "NAS Advice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100stk0/3tb_backup_advice/",
          "author": null,
          "description": "hello hoaders , \n I am relatively new to this community and I have the most basic question but I still gotta ask \n I have a large movie/tv series library on me , till now I am storing the data on 5tb WD external hardrive I bought but I don't feel reliable on the hardrive since it is a physical one and my only source of backup for now\n So my question is what are the reliable ways of backing my 3tb data securely and In a controlled budget though. As I told I new to this community so Kindly explain your responses as much as you can \n thanks and a very happy new year\n    submitted by    /u/Maleficent_Artist_95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100stk0/3tb_backup_advice/",
          "publishedOn": "2023-01-01T20:39:27.000Z",
          "wordCount": 15900,
          "title": "3Tb backup advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100spir/external_vs_internal_hard_drives/",
          "author": null,
          "description": "I've been data hoarding for about a year now. I've bought several external hard drives ranging from 1TB-5TB to store everything (Seagate and WD). I didn't have too much data at first, and I like how they are portable and easy to plug and play on other devices.\n My question is, would it be more cost effective to buy internal hard drives like 3.5\" NAS HDDs and buy a cheap enclosure to go with it? For example I've seen 10TB+ Internal Drives sell for cheaper than pre-enclosed external ones, but I dont know if I would need an extra power source other then the USB plug that comes with a portable enclosure. I also wouldn't be opposed to go with a smaller drive if the extra power is needed on larger drives.\n I am no where near setting up a home server or using a cloud based system, just looking to plug into the TV through USB for now.\n    submitted by    /u/wtfhmmm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100spir/external_vs_internal_hard_drives/",
          "publishedOn": "2023-01-01T20:34:30.000Z",
          "wordCount": 16392,
          "title": "External Vs. Internal Hard Drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100sly7/backblaze_style_backup_software_but_selfhosted/",
          "author": null,
          "description": "I really like the Idea of Backblaze Personal Backup, where you just install their client and the entire computer gets synced to a remote location.\n So you guys know of similar software to this, which I could connect to my own private network drive? I don't seem to find anything that does \"whole pc backup, no questions asked\". \n Thanks in advance!\n    submitted by    /u/sideprojects1337  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100sly7/backblaze_style_backup_software_but_selfhosted/",
          "publishedOn": "2023-01-01T20:30:13.000Z",
          "wordCount": 15820,
          "title": "Backblaze style backup software (but selfhosted?)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100s3lw/new_server/",
          "author": null,
          "description": "Hi, I just bought a refurbished R720xd with 2 SSD, 12 HDD and a PERC H710p raid controller. I plan to used some of the HDD for backup.\n At day 1 the raid controller was working and I configured the RAID. But after rebooting to install the OS, the controller fell into fault state 'F/W in fault state - MFI Register State 0xF0010002. Adapter at Baseport is not responding'. \n I tried several things such as removing the HDD, removing the controller, the battery and plugging back, also a video on how to recover a H710 on YT but nothing worked at the moment. Do you have any idea on what to do ?\n    submitted by    /u/jeansami  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100s3lw/new_server/",
          "publishedOn": "2023-01-01T20:08:09.000Z",
          "wordCount": 16047,
          "title": "New server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100r4er/recommendation_for_multichannel_message_backup/",
          "author": null,
          "description": "Looking for recs for a way to merge different backups (whatsapp, signal, text message databases) into a central offline db with some sort of search ability. Can anyone suggest the best way to go about this?\n I'm comfortable with tech-heavy solutions and can get all the data from my encrypted backups.\n    submitted by    /u/Thund3r_Struck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100r4er/recommendation_for_multichannel_message_backup/",
          "publishedOn": "2023-01-01T19:26:34.000Z",
          "wordCount": 15744,
          "title": "Recommendation for multi-channel message backup solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100qb56/a_slightly_different_case_of_storing_videos_on/",
          "author": null,
          "description": "First, I would like to apologize for the wall of text below. It's tough to digest since English is not my native language.\n Using YouTube to store videos: I have done my homework and agree with the consensus. This is a bad idea. A significant risk of a ban at any moment without ever getting a chance to appeal or interact with a human being, let alone a chance to recover the data, a significant drop in quality across the board, the sudden apparition of exotic formats compatible with nothing, it goes on and on. Some have tried and are here to tell their horror stories on this sub.\n My case is a bit different, though.\n A bit of background for you to get a rough picture of where I'll be standing for the next 18 months-ish (hopefully less than that).\n In 48 hours, I will be homeless. I sold my …",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100qb56/a_slightly_different_case_of_storing_videos_on/",
          "publishedOn": "2023-01-01T18:51:10.000Z",
          "wordCount": 21498,
          "title": "A slightly different case of storing videos on YouTube. Comments and alternative solutions welcome.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100plvd/anyone_having_problem_archiving_bitchute_channels/",
          "author": null,
          "description": "Hey fellas, I have a few channels I scrape occasionally on Bitchute using a custom script I wrote and using yt-dlp. I've noticed that a lot of older videos no longer archive, and when I check the videos on Bitchute they no longer load - so it's not an issue with my script or yt-dlp. The latest channel I tried to archive cut off at a video on December 3, 2019 - and all videos older than that are no longer playing on the website. \n Is this an issue with Bitchute automatically no longer hosting videos once they've been uploaded for a certain amount of time? Anyone else run into this problem? Any input is helpful. Thanks guys.\n    submitted by    /u/TCIE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100plvd/anyone_having_problem_archiving_bitchute_channels/",
          "publishedOn": "2023-01-01T18:20:42.000Z",
          "wordCount": 15638,
          "title": "Anyone having problem archiving Bitchute channels using yt-dlp?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100o9fo/reasons_for_why_data_hoarding_is_important_and/",
          "author": null,
          "description": "There are many reason for why data hoarding is more than just stockpiling publicly available information. Most people see content on the internet as continuous. However, take 5 pages from 10 different websites, comeback in 3 months and you will quickly realize half the links are broken, content has changed or has been completely lost. Everyday thousands of new websites are created and shut down.\n Below is a short summery of how information or access to information can be lost forever and why its important to save everything that is relevant, inspirational or entertaining to you.\n There are a number of external factors that can impact or influence the availability of information on the internet.\n ​\n  \nGovernments may seize entire websites or implement internet shutdowns without notice. Take…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100o9fo/reasons_for_why_data_hoarding_is_important_and/",
          "publishedOn": "2023-01-01T17:20:52.000Z",
          "wordCount": 19705,
          "title": "Reasons for why data hoarding is important and why you should start",
          "imageUrl": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?auto=webp&s=c387f574702b9ed7c68f698f7fa60d3c32211671"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100m09a/is_mtbf_the_same_as_reliability_cycles/",
          "author": null,
          "description": "Is MTBF the same as \"Reliability\" Cycles...?\n Hello\n I wanna buy a new HDD, im choosing between:\n ​\n Toshiba P300 6TB (HDWD260UZSVA)\n and\n Seagate BarraCuda 6TB ( ST6000DM003)\n ​\n In the shop in my country, in my language (not english) it says for Toshiba: \"MTBF 600000 hours\" and for Seagate: \"Reliability 300000 cycles\".\n ​\n Is \"MTBF\" (Mean time Before Failure) the same as \"Reliability Cycles\"...? I did the translation from my language to english as good as i can.\n Are they the same?\n If not, which one is Better?\n ​\n 600 000 Hours MTBF\n or\n 300 000 Reliability Cycles?\n ​\n Thanks\n    submitted by    /u/ThomasHasThomas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100m09a/is_mtbf_the_same_as_reliability_cycles/",
          "publishedOn": "2023-01-01T15:33:39.000Z",
          "wordCount": 16032,
          "title": "Is MTBF the same as \"Reliability\" Cycles...?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100ikdy/some_questions_on_compression/",
          "author": null,
          "description": "First, a disclaimer: I'm aware media is generally already compress. Storage capacity is not an issue currently, but it's something I'm curious about and want to learn. \n 1) Do any of you use compression, in any form, for either backups, local storage, or cloud?\n Files I'm considering compressing:\n 2) I have a LOT of games downloaded, which I do not currently play, but plan on returning to. One example would me Skyrim +150 Mods, which took weeks to figure out the right combination of mods \n 3) I have about 500 GB - 1TB or so of old data that I'm slowly going through, and deleting or saving anything that's personally important. The data is from either: My old harddrives, my deceased dad's PC, an old WD passport, and an old backup folder that is partially corrupt but has some salvigable impor…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100ikdy/some_questions_on_compression/",
          "publishedOn": "2023-01-01T12:23:39.000Z",
          "wordCount": 18055,
          "title": "Some questions on compression",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100h1bm/need_advise_home_backup/",
          "author": null,
          "description": "Hello sub Please advise what's a cheap Nas adapter that can help me put my 16tb wdd USB HDD on my own as a network drive?\n I'd eventually like to use rclone on my PCs/phone to backup content into it.\n Thanks\n    submitted by    /u/justbflat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100h1bm/need_advise_home_backup/",
          "publishedOn": "2023-01-01T10:34:40.000Z",
          "wordCount": 16394,
          "title": "Need advise : home backup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100gw0k/reddit_account_scraper/",
          "author": null,
          "description": "Hiya, I'm looking for any tool that downloads all images from a Reddit account, cheers\n    submitted by    /u/LunaKindaExists  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100gw0k/reddit_account_scraper/",
          "publishedOn": "2023-01-01T10:23:52.000Z",
          "wordCount": 15457,
          "title": "Reddit account scraper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100e0xk/put_10tb_lifetime_in_perspective_for_me/",
          "author": null,
          "description": "I was researching NAS options and came across an offer for cloud storage priced at $1200 for 10TB lifetime. One time payment. By comparison that cost will get you 2 years of Google Drive storage. Based on that alone it looks like a win but what other factors do you consider when gauging the cost of data storage. I'm not talking about the pros and cons of cloud vs. local storage. I already get that. I'm asking, IF cloud storage could work for you, how valuable will 10TB be in 5, 10, 20 years. As media file sizes get bigger with 8K and photos grow in megapixels, will 10TB in the future get you what 500GB gets you today? Will the failure rate of NAS drives become a non issue when pricing storage? I have no use for 10TB of cloud storage now but down the line I probably will. If so, is this deal worth it?\n    submitted by    /u/Jaded-Function  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100e0xk/put_10tb_lifetime_in_perspective_for_me/",
          "publishedOn": "2023-01-01T06:57:35.000Z",
          "wordCount": 18304,
          "title": "Put 10TB lifetime in perspective for me",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1009h4u/hi_guys_im_just_starting_here_4x8tb_raid5_for_my/",
          "author": null,
          "description": "submitted by    /u/TheCharon77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1009h4u/hi_guys_im_just_starting_here_4x8tb_raid5_for_my/",
          "publishedOn": "2023-01-01T02:08:21.000Z",
          "wordCount": 16748,
          "title": "Hi guys, I'm just starting here. 4x8TB, RAID5, for my terramaster nas. I'll put linux on it.",
          "imageUrl": "https://preview.redd.it/afkn3m1cbc9a1.jpg?auto=webp&s=07d6b1e1c1036c7830bd6db0b7f0ca8a67b92b40"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1008ih5/how_to_read_smartctl/",
          "author": null,
          "description": "I am automating some alerts and want to figure how to read smartctl.\n ​\n Does this section ever actually change?\n === START OF READ SMART DATA SECTION ===\n SMART overall-health self-assessment test result: PASSED\n My current plan is to run short tests once a week and check that passed. I know this will mean not paying attention to things like increasing read or write errors but seems to be something I can reasonably automate.\n In more detail I'll be looking at:\n smartctl -j -a /dev/sda|jq .smart_status\n {\n \"passed\": true\n }\n ​\n Anyone have any thoughts?\n    submitted by    /u/fireduck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1008ih5/how_to_read_smartctl/",
          "publishedOn": "2023-01-01T01:15:10.000Z",
          "wordCount": 15688,
          "title": "how to read smartctl",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1007ooi/which_cheap_nvme_large_writes/",
          "author": null,
          "description": "Hey fellow Hoarders,\n A couple of year-ish back, the WD Blue SN550 with the go-to, with a nice fast 1.2TB or so per second write, and sustaining a respectable 850MBps post cache.\n Ever since the chip swap in 2021, it remains fast (faster, in fact) for the SLC portion, then drops to 370MBps. Not acceptable.\n Does anyone know who the budget king of NVME currently is?\n I'm really only looking for one key feature:\n sustained writes that are notably faster than SATA, after cache is exhausted\n 750MB-1000MB would be nice. Price is a key factor.\n Thanks all!\n    submitted by    /u/Master_Scythe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1007ooi/which_cheap_nvme_large_writes/",
          "publishedOn": "2023-01-01T00:30:03.000Z",
          "wordCount": 15159,
          "title": "Which cheap NVME, large writes.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1007fo0/drivepool_unraid/",
          "author": null,
          "description": "Wondering if anyone has used Drive Pool and knows what happens to the data on the HDDs when you disable the pool. I want to put the 2 disks I currently have in Drive Pool into my new Unraid server.\n    submitted by    /u/Dementedjohn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1007fo0/drivepool_unraid/",
          "publishedOn": "2023-01-01T00:16:30.000Z",
          "wordCount": 15216,
          "title": "DrivePool + Unraid",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10076nf/canada_is_this_too_good_to_be_true/",
          "author": null,
          "description": "submitted by    /u/cseye420  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10076nf/canada_is_this_too_good_to_be_true/",
          "publishedOn": "2023-01-01T00:03:29.000Z",
          "wordCount": 15721,
          "title": "[Canada] Is this too good to be true?",
          "imageUrl": "https://preview.redd.it/1sgndwxhob9a1.png?auto=webp&s=e89515c467b7444c786ee7c4b52f94643bca129c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/10064az/hard_drive_sometimes_makes_a_grinding_noise_that/",
          "author": null,
          "description": "​\n https://reddit.com/link/10064az/video/j2w4y4t4eb9a1/player\n Is this something to be concerned about? It only sometimes makes this louder version of what would be considered normal hard drive noises when reading/writing to it. You can even hear at the end of the video it quiets down and returns to normal. The disk passed a SMART test and there's no values in the SMART output that would indicate any kind of failure or damage.\n    submitted by    /u/sigtrap  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/10064az/hard_drive_sometimes_makes_a_grinding_noise_that/",
          "publishedOn": "2022-12-31T23:07:39.000Z",
          "wordCount": 15270,
          "title": "Hard drive sometimes makes a grinding noise that sounds like normal hard drive noises but only louder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1005jr0/do_i_understand_correctly_that_all_recent_4tb/",
          "author": null,
          "description": "and there are no CMR.\n    submitted by    /u/Rude-Engine440  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1005jr0/do_i_understand_correctly_that_all_recent_4tb/",
          "publishedOn": "2022-12-31T22:38:38.000Z",
          "wordCount": 15575,
          "title": "Do I understand correctly that all *recent* 4TB 2.5inch HDDs are SMR only?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1005exs/drive_shucking/",
          "author": null,
          "description": "I bought a Dell MD1000 and a Perc H800. I have 8 x 3tb drives, seagate SAS. Can I add additional drives to the raid 10 as I acquire these drives or should I buy all fifteen now ? For future expansion can I replace a 3tb with a 10tb drive with no downtime?\n    submitted by    /u/gimpygoat498  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1005exs/drive_shucking/",
          "publishedOn": "2022-12-31T22:31:59.000Z",
          "wordCount": 14951,
          "title": "Drive Shucking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1003r9f/advice_on_case_vs_enclosure/",
          "author": null,
          "description": "I was building a new NAS system and I was looking at the Fractal Design 804 because it's compact and has 10 bays. But one of the things I really like about my Synology is that I can hot swap the drives and if the drives fail there are lights on the front and the system beeps.\n That got me wondering if there are hard drives enclosures for multiple drives that would provide the hot swap capability and visual notifications. A quick search either found NAS system or small 4 bay enclosures.\n Suggestions please\n    submitted by    /u/tortuga3385  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1003r9f/advice_on_case_vs_enclosure/",
          "publishedOn": "2022-12-31T21:09:51.000Z",
          "wordCount": 15710,
          "title": "Advice on case vs enclosure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1002wnm/any_way_to_delete_the_background_page_image_from/",
          "author": null,
          "description": "I've just been moving the top image \"text\" from one page to another, deleting the background, then moving it back. Does anyone know if there's a quicker and more efficient way to do this?\n Also (different but related question) -- is there a way to download pdfs from IA at higher image quality or as such that the pages don't get separated into mulitple separate \"layers\" in the case for books with a lot of pictures or illustrations?\n    submitted by    /u/fiocobra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1002wnm/any_way_to_delete_the_background_page_image_from/",
          "publishedOn": "2022-12-31T20:29:09.000Z",
          "wordCount": 15902,
          "title": "Any way to delete the background page image from Internet Archive pdfs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1002831/audio_hoarder/",
          "author": null,
          "description": "Over the years I have amassed music & audiobooks and have saved them places willy- nilly. I’ve started to corral them in one place to weed out duplicates and keep the best versions, but I’m stuck on one thing. How do I download things I’ve purchased from various sites that are hosted on those sites and not my device. For example, I buy audiobooks from Chirp. I can listen to them using their app, but I want to get them saved so I can listen to them even if I don’t have an internet connection.\n    submitted by    /u/CoveredInBeez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1002831/audio_hoarder/",
          "publishedOn": "2022-12-31T19:56:20.000Z",
          "wordCount": 16583,
          "title": "Audio hoarder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/100271m/how_to_launch_automations_based_on_incoming_emails/",
          "author": null,
          "description": "I receive a few different periodic emails that I would like to use as input to automations like downloading data provided in a link in the email, or adding a newsletter to my wallabag.\n I could (but would rather not) write a python script to poll my actual email account, but I'd rather find free email account that I can automatically forward the emails to and then pull from that, then run an automation for each new email that comes in. There must be a solution out there already, how are people getting this done? I don't want to run an email server myself, that's a whole can of worms I don't want to deal with, and I don't need to be event-based; polling a couple times a day would be enough.\n I did a bit of searching here and /r/selfhosted, but mostly people are talking about syncing/archiving emails, which is not what I'm trying to solve; as soon as I grab the input and launch the automation I'll trash the email.\n    submitted by    /u/often_wears_pants  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/100271m/how_to_launch_automations_based_on_incoming_emails/",
          "publishedOn": "2022-12-31T19:54:57.000Z",
          "wordCount": 16362,
          "title": "How to launch automations based on incoming emails?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1001l6y/hdd_on_a_budget_not_a_seagate_barracuda/",
          "author": null,
          "description": "Jesus! I have several Seagate Barracuda drives - ST2000DM001-1ER164. Granted I've had them a few years now but all have started to fail. The first that failed was in my dad's PC. Then suddenly I turned my PC on one day, that had 3 of them in and although working the day before just fine, one of them failed. So it was time to backup the rest. I purchased Hard Disk Sentinel and checked the remaining drives. All fine. I turn the PC on today and check out qtorrent for some ongoing archive downloads and it keeps freezing. Odd, seems to be doing it on just one torrent so I'm trying to delete but can't.\n I realise something similar was happening when one died early in the year so run Hard Disk Sentinel and it flags the drive health at 26%. JESUS! I've only copied 2 new folders to it recently so back those up. There is another one in the machine still showing 100% heath but Jesus they have been poor. All purchased round the same time roughly, all dying roughly round the same time!\n Never buying Seagate again.\n    submitted by    /u/steviefaux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1001l6y/hdd_on_a_budget_not_a_seagate_barracuda/",
          "publishedOn": "2022-12-31T19:25:32.000Z",
          "wordCount": 20090,
          "title": "HDD on a budget - NOT a Seagate Barracuda!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1001jp6/is_there_a_backup_cloud_service_where_i_can/",
          "author": null,
          "description": "I have Google drive now and the videos are compressed to 360p . I’m watching my 720p-1440p videos in 360p. Looking for service that will allow me to stream original quality. Doesn’t need to be top level secure. It’s just lectures and movies and car videos. I need high quality to read everything. \n Also, looking for a way to just transfer from Google Drive to that service. I know that you can download a Zip and then upload it. I’m wondering if you download a Zip and then upload it if you will have the original quality of when it was uploaded?\n    submitted by    /u/Marilize_Legajuanaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1001jp6/is_there_a_backup_cloud_service_where_i_can/",
          "publishedOn": "2022-12-31T19:23:29.000Z",
          "wordCount": 15661,
          "title": "Is there a backup cloud service where I can upload videos with 720p or higher HD and have streaming quality not compressed?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1001coy/looking_for_adf_scanner_laser_printer_combo/",
          "author": null,
          "description": "I am hoping to digitize/archive some old photos but my laser printer also just went kaput. \n I am looking around to no avail and wondering if anyone knows of an ADF scanner and printer?\n TIA\n    submitted by    /u/MILFHunterHearstHelm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1001coy/looking_for_adf_scanner_laser_printer_combo/",
          "publishedOn": "2022-12-31T19:14:06.000Z",
          "wordCount": 16424,
          "title": "Looking for ADF Scanner + Laser Printer Combo. Unicorn?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1001ak3/how_to_burn_in_24tb_raid_on_truenas_scale_is/",
          "author": null,
          "description": "Hi, all! \n I'd like to 'burn in' my RAID for several hours (or days) before I start to copy data over. I'm still new to all this, but had a blast setting up my first NAS server with a 24TB RAID (4x8TB RAID-Z) on TrueNAS Scale. This will eventually be a media server. \n One of the reasons why I want to burn-in at the RIAD level, rather than the disk level (e.g. SMART test or badblocks), is because I'm concerned about my PSUs ability to power multiple drives running simultaneously. All of my issues over the last few weeks have been when the disks passed both SMART and badblocks, but the RAID failed over and over. I followed advice online and since upgraded my PSU and power cables. \n I had the idea that I could just torrent a massive amount of data for a week. This would effectively stress the I/O in proportion to its anticipated use. Is there a free torrent that would accomplish this? I don't want to sign up for any sites where maintaining a ratio is a concern: If the RAID fails, I'd like to be able to repeat the test. \n I'm open to other suggestions as well.\n    submitted by    /u/Interesting_Passion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1001ak3/how_to_burn_in_24tb_raid_on_truenas_scale_is/",
          "publishedOn": "2022-12-31T19:11:11.000Z",
          "wordCount": 15598,
          "title": "How to burn in 24TB RAID on TrueNAS Scale? Is there a torrent that would do this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/1000qsc/need_to_host_150tb_for_my_research_group/",
          "author": null,
          "description": "Our research group has about 150TB of data we're currently storing with some cloud service that's costing us a lot monthly. We also have a new project starting in 2025 which will generate a similar amount of data. I've been tasked with building a file server to be housed somewhere on campus to hold this data.\n Data access pattern:\n  \nCopy a 500GB chunk of data to the campus compute cluster (about 1h transfer time at 1Gb/s)\n Do some computation on the cluster over this 500GB of data (takes about 30h)\n Delete the 500GB chunk from the cluster and move on to the next chunk\n  \nPurchase list:\n  \nData hosting ($12000)\n  \n45Drives Storinator Q30 ($7000)\n 14x 16TB Seagate Exos drives w/ RAID-Z2 ($5000)\n \n \nData backup ($5750)\n  \nSymplypro SYPRO-DT3L8H1B-A0 desktop tape drive ($5000)\n 14x 12TB HPE LTO-8 tapes ($750)\n \n  \nI've left half the drive bays empty for building another array a few years from now.\n Questions:\n  \nApproximately what's the likelihood that a drive will fail in 5 years?\n How complex is the replacement? I may not always be around to fix the server\n About how long would a rebuild take if a drive fails, and is double-parity enough to prevent another drive from failing during this time?\n  \n   submitted by    /u/Evidlo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/1000qsc/need_to_host_150tb_for_my_research_group/",
          "publishedOn": "2022-12-31T18:44:59.000Z",
          "wordCount": 19320,
          "title": "Need to host 150TB for my research group. Suggestions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzwcyw/2_disks_synology_basic_raid_type_should_i_create/",
          "author": null,
          "description": "Hi,\n I have a 2-disk synology, each has 2TB disk. My usage is to store mp3, movie. and if data is lost I am Ok.\n I'd like to leverage full capacity of total 4 TB disk and don't want to go with SHR.\n if one disk fail, I hope the data on another disk survive.\n should I\n option 1: create \"basic\" raid type, and create 2 storage pool (each has 1 volume, pointing to one of the disk), or\n option 2: 1 storage pool with 2 volume?\n I am open to other options. \n Thank you!\n    submitted by    /u/hiacbanks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzwcyw/2_disks_synology_basic_raid_type_should_i_create/",
          "publishedOn": "2022-12-31T15:22:27.000Z",
          "wordCount": 15871,
          "title": "2 disks synology, \"basic\" raid type, should I create 1 storage pool with 2 volumes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzw25z/tools_for_monitor_changes_in_backup_source_files/",
          "author": null,
          "description": "Hey,\n Looking for some monitoring software that keeps track of any changes of my file that I want to back up. My most important files are the irreplaceable home videos and pictures for the last 25 years or so. I have multiple backups of these and keep them up-to-date, doing a full new backup every now and then. \n Was just doing a new full backup today and it occurred to me that what if something happens to the original files, like some file accidentally deleted or corrupted. I might notice it years later (or maybe never). When doing new full backups, said files would be eventually lost. \n I know file versioning would be an option, but eventually that will hit a wall over the years and doesn't really help if I don't notice the changes and make a new full back up.\n So basically I want to have some kind of monitoring software that looks for changes and integrity in the background and informs me of any changes that happen. \n Something light, easy to use and of course free would be nice. ;)\n    submitted by    /u/backdraft83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzw25z/tools_for_monitor_changes_in_backup_source_files/",
          "publishedOn": "2022-12-31T15:07:56.000Z",
          "wordCount": 15435,
          "title": "Tools for monitor changes in backup source files",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzv3zh/fully_3d_printed_16_bay_hard_drive_enclosure/",
          "author": null,
          "description": "submitted by    /u/FreshBlueberry3857  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzv3zh/fully_3d_printed_16_bay_hard_drive_enclosure/",
          "publishedOn": "2022-12-31T14:20:42.000Z",
          "wordCount": 15873,
          "title": "Fully 3D printed 16 bay hard drive enclosure, thoughts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzv0km/tool_for_downloading_mit_opencourseware_resources/",
          "author": null,
          "description": "submitted by    /u/helphunting  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzv0km/tool_for_downloading_mit_opencourseware_resources/",
          "publishedOn": "2022-12-31T14:15:50.000Z",
          "wordCount": 15821,
          "title": "Tool for downloading MIT OpenCourseWare resources at ease",
          "imageUrl": "https://preview.redd.it/ehoyfnjfp39a1.gif?format=png8&s=d2dd2811e96eae512a3e2ddc85db126bb72496fc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzurea/this_subreddit_was_mentioned_in_the_new_york_times/",
          "author": null,
          "description": "“Digital self-storage has gotten more complex as I discovered when I visited the DataHoarder subreddit. Posts there with technical advice for the best home setup were jargon-filled to the point of incomprehension for a newbie. A sample post: “Started with single bay Synology Nas and recently built a 16TB unRAID server on a xeon 1230. Very happy with result.”\n    submitted by    /u/brothertax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzurea/this_subreddit_was_mentioned_in_the_new_york_times/",
          "publishedOn": "2022-12-31T14:02:19.000Z",
          "wordCount": 16863,
          "title": "This subreddit was mentioned in the New York Times!",
          "imageUrl": "https://external-preview.redd.it/C2mAU3Gr1kRSa3qU80OH9uVxn_EOURj2nVi5MwAH4ZU.jpg?auto=webp&s=f6550731cb119bc281d50d3389168740bed97638"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzrocf/potential_seagate_firecuda_520_hardware_revision/",
          "author": null,
          "description": "Not sure how relevant those drives are to big data hoarders considering that they are NVME SSDs topping out at 2TB, however I was having a look at the data sheet looking at their endurance and there seems to be two different hardware revisions currently in circulation with way different endurance.\n The earlier/older Firecuda 520 drives had ZP2000GM30002, ZP1000GM30002, ZP500GM30002 product codes and used to have an endurance of 3600TBW, 1800TBW and 850TBW respectively. As far as I am aware these drives used to use Toshiba Bics Flash.\n Meanwhile, if you browse the data sheet of the current Firecuda 520 drives page on Seagate's website, these drives now carry the ZP2000GV3A012, ZP1000GV3A012 and ZP500GV3A012 product codes with an endurance of 1200TBW, 600TBW and 300TBW respectively.\n It also seems to me like the new \"Firecuda 520\" drives have a different packaging, and a different label on the drives itself with a white notch and line on top right corner of the label while the older version with much higher endurance have a thick orange line at the bottom of the label with \"520 series PCIe Gen4 SSD\" written on it instead.\n Here are the two PDFs / data sheets on Seagate's website :\n Older revision with Toshiba NAND and higher endurance : DATA SHEET (seagate.com)\n Newer revision with lower endurance : Upgrade Your Gaming Experience (seagate.com)\n Not sure how relevant this is to you data hoarders considering the rather low capacity of the drives, but I thought that this might be an interesting piece of information nonetheless.\n How common is it for drive manufacturers to sneakily revise and change the hardware on their drives while selling them under the same name ? I vaguely remember that happening a couple of years ago with a couple of manufactures such as Adata, Crucial, WD or even Samsung.\n I might cross-post this to the hardware subreddit if there is any interest in that discussion and if I manage to figure out how to do so.\n    submitted by    /u/OneTouchDisaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzrocf/potential_seagate_firecuda_520_hardware_revision/",
          "publishedOn": "2022-12-31T11:02:07.000Z",
          "wordCount": 19079,
          "title": "Potential Seagate Firecuda 520 hardware revision / SSD Manufacturers silently swapping components",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzqijs/question_about_large_10tb_hard_drives/",
          "author": null,
          "description": "Hello, let me tell you that I am not a Data Hoarder, but I thought this question was probably suited best for this community.\n I want to get a fat-ass hard drive (>10TB) so I can keep a full backup of my Steam account, just in case, something happens to steam. The hard drive would sit inside of my computer case, and it will be connected as a separated drive in my computer.\n However I have heard that large hdd are (very) noisy. which makes sense, if they are thought to be in a data center and not inside of a personal computer.\n Do you have any additional information, on how loud they are, which one are best, what is a good Tb/$ price?\n Also, maybe there is another cheaper solution that I have not considered?\n ​\n The HDD that I have in mind is this one: https://www.cclonline.com/st16000nm000j-seagate-exos-x18-16tb-sata-iii-3-5-hard-drive-7200rpm-256mb-384942/\n ​\n PS: In principle it would be only one given the steep price. Might need to add a second backup eventually.\n    submitted by    /u/katorce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzqijs/question_about_large_10tb_hard_drives/",
          "publishedOn": "2022-12-31T09:46:35.000Z",
          "wordCount": 19499,
          "title": "Question about large >10TB hard drives",
          "imageUrl": "https://external-preview.redd.it/uEpB9hd-QuV28bfoRQl0ZZDzZAHIfAy7JDJ4ojjx-Qk.jpg?auto=webp&s=ee170f7b0c88ab0a0e580ee2fe292fbfaf85c050"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzoit0/do_i_use_raid_10/",
          "author": null,
          "description": "submitted by    /u/chisato2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzoit0/do_i_use_raid_10/",
          "publishedOn": "2022-12-31T07:31:45.000Z",
          "wordCount": 17381,
          "title": "Do I use raid 10?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzhj38/what_useful_data_to_hoard/",
          "author": null,
          "description": "Hey Guys imma make it quick. Even after opening a Cloudservice with free Storage, Storj and everything i kinda find useful, i still have around 100 TB to Fill. \n Please let me know what you hoard and if you have any good suggestions how i can still fill my space ^\n    submitted by    /u/No_Dragonfruit_5882  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzhj38/what_useful_data_to_hoard/",
          "publishedOn": "2022-12-31T01:22:44.000Z",
          "wordCount": 15623,
          "title": "What 'useful' Data to hoard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzh6ll/apple_itlp_itunes_lp_nonmusic_media_archive/",
          "author": null,
          "description": "Background: https://en.wikipedia.org/wiki/ITunes_LP, which includes a good list of all of the albums which were released with ITLP content. Since the format has been deprecated as of 2018, and with (what I assume is) the progression of web browsers, the few I have no longer \"play\" in Apple Music or as HTML content. But it was really good and informative content when used well by the studios. \n I've tried to find an archive of these but so far been unsuccessful. Anyone save and archive ITLP content (not the music, just the .itlp media directories for albums where they were available via iTunes)?\n    submitted by    /u/TheRiZZoTTo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzh6ll/apple_itlp_itunes_lp_nonmusic_media_archive/",
          "publishedOn": "2022-12-31T01:06:36.000Z",
          "wordCount": 15581,
          "title": "Apple ITLP (iTunes LP) Non-Music Media Archive?",
          "imageUrl": "https://external-preview.redd.it/DQHlgrP5GxKb6k3GKkVSltcjxiCxcemvcyvZ-8-i8bY.jpg?auto=webp&s=4dc21f8572a5e52d144e3e9940a3ecb26cab78fc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzgyva/transfer_data_from_googledrive_to_s3_compatible/",
          "author": null,
          "description": "Not sure which is the most appropriate sub but this seemed to be closest…\n I have approx 1.5TB in my Google Drive (Workspace, single-user) I’d like to transfer over to Backblaze. I’m trying to work out all possible options, but looking for some advice ideally from someone who’s done this/something similar before\n Option 1 Download all data From Google Drive onto home server, then upload to Backblaze. No cost involved but with 10mb/s upload speed will take a long time\n Option 2 Spin up VPS on AWS EC2, rclone copy from google drive to B2. Not an expert on rclone, would I have to assign 1.5TBs EBS storage to the VPS to complete the sync? Will also get hammered on ingress/egress charge\n Option 3 Multcloud/Cloudfuze. Waiting to hear on a quote from Multcloud, and Cloudfuze do not support Backblaze (despite it being S3 compatible…)\n    submitted by    /u/louisjms  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzgyva/transfer_data_from_googledrive_to_s3_compatible/",
          "publishedOn": "2022-12-31T00:57:15.000Z",
          "wordCount": 15815,
          "title": "Transfer data from GoogleDrive to S3 (compatible)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzfwsb/60_days_left_to_download_1_large_file_from_google/",
          "author": null,
          "description": "My university alumni gmail edu account provides unlimited storage via google drive\n In october 2022, i received a notification that there will be a 1tb limit enforced starting march 1 2023\n I only have 2 files in my google drive:\n  \n file-1 is an encrypted disk image = 60 gigs\n file-2 is an encrypted disk image = 3 TB\n  \n Last week, i bought a 5TB external HD to put the files on.\n I am on a 1gbps ethernet fiber connection. Going to fast.com shows me that my DL speed is 850 mbps. My occasional torrenting reaches 100 mB/s without issue.\n I downloaded file-1 (the 60 gig file) relatively quickly.\n I am struggling to download file-2 (the 3TB file) and need guidance.\n  \n----------------\n  \nAttempt 1) I downloaded the file in google chrome through google drives website. I right clicked on the fil…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzfwsb/60_days_left_to_download_1_large_file_from_google/",
          "publishedOn": "2022-12-31T00:09:57.000Z",
          "wordCount": 16428,
          "title": "60 days left to download 1 large file from Google Drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzfor0/what_size_aio_can_you_fit_on_the_top_of_a_fractal/",
          "author": null,
          "description": "The title basically says it all. I am contemplating putting an aio into my DIY NAS. I am not sure what size would fit in there however when it is fully stocked with hard drives. From videos I've seen, space is definitely lost. So, I just want to confirm before buying one.\n    submitted by    /u/Karizmology  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzfor0/what_size_aio_can_you_fit_on_the_top_of_a_fractal/",
          "publishedOn": "2022-12-31T00:00:29.000Z",
          "wordCount": 16205,
          "title": "What size AIO can you fit on the top of a Fractal Design 7 XL full of HDDs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzfft9/data_integrity_on_windows_10_pro_storage_spaces/",
          "author": null,
          "description": "I'm building a NAS with windows storage spaces (NTFS, not Refs as it is being removed from windows 10 pro) but I'm wondering how can I achieve some level of data integrity to avoid backing up corrupted files. I know snapraid has bit rot protection but can't find any examples on using storage spaces with snapraid (no, I don't want to use stablebit drivepool). Should I use individual drives instead and manually manage what's data and what's parity? What are some good tools to check for data integrity?\n    submitted by    /u/gr4viityy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzfft9/data_integrity_on_windows_10_pro_storage_spaces/",
          "publishedOn": "2022-12-30T23:50:04.000Z",
          "wordCount": 15904,
          "title": "Data integrity on Windows 10 Pro storage spaces",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzf8fe/uploading_to_google_drive_consistently_saturating/",
          "author": null,
          "description": "submitted by    /u/EugeneHaroldKrabs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzf8fe/uploading_to_google_drive_consistently_saturating/",
          "publishedOn": "2022-12-30T23:41:09.000Z",
          "wordCount": 15732,
          "title": "Uploading to Google Drive consistently saturating 10Gbps line. Thought some of you might appreciate",
          "imageUrl": "https://preview.redd.it/4gqxahqxf49a1.png?auto=webp&s=e387f511cb2c21b6786abd0d07bd3142ebca796d"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzf4tu/single_bay_nas/",
          "author": null,
          "description": "Hello! I had an Iomega NAS from 2011 but the fan failed last year. I changed them 2 times but the new fans don't last (it's the same ID model but they doesn't work the same). I would like to salvage my 2tb drive and put it in another enclosure, I can format the drive to another file allocation table as I can still access files and move them on my current USB drives. I don't need raid or any server capacities, I just want the HDD available over my network. Only important stuff are pictures but those are backup in 3 places in 3 different spaces (2 USB drives + Cloud). My main usage is purely ease of use for my family; instead moving files around over USB drive, I prefer to have a single network IP that every device can access via SMB. Thanks a lot for your help!\n    submitted by    /u/gifred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzf4tu/single_bay_nas/",
          "publishedOn": "2022-12-30T23:36:51.000Z",
          "wordCount": 15970,
          "title": "Single bay NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzdeku/ive_started_archiving_my_blurays_and_other_4k/",
          "author": null,
          "description": "I dont have the money to build or buy one now, but itd be a good goal to move towards.\n I dont plan on storing anything above maybe... 30TB? I currently run my main net off 8TB and I have 24TB total over various active drives. (Though I prefer not to use those for archival / media)\n Is there something relatively affordable that would be a decent starter NAS? Ive never bothered delving into the costs / efficiencies, and in the past Ive just boughten a relatively cheap HDD or SSD I found at a store if I needed one.\n    submitted by    /u/SkylerSpark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzdeku/ive_started_archiving_my_blurays_and_other_4k/",
          "publishedOn": "2022-12-30T22:23:50.000Z",
          "wordCount": 16114,
          "title": "Ive started archiving my blurays and other 4k+ content. Im realizing now that my storage probably wont last long. What would be a good beginner NAS to start building / buying?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzccmq/can_someone_help_with_viewing_or_downloading_this/",
          "author": null,
          "description": "So this video is saved 8 times, only 1 of them opens the youtube link, but when I hit play it says error occurred, does that mean it is expired or something ? Can it be download or at least played once ?\n Also, it is a Kate Upton video, so I guess possibly NSFW just in case.\n    submitted by    /u/colderbooze  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzccmq/can_someone_help_with_viewing_or_downloading_this/",
          "publishedOn": "2022-12-30T21:40:17.000Z",
          "wordCount": 15697,
          "title": "Can someone help with viewing or downloading this youtube video from Wayback machine? It is archived but can't download it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzc3qa/datahoarder_discussion/",
          "author": null,
          "description": "Talk about general topics in our Discussion Thread!\n  \nTry out new software that you liked/hated? \n Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n Come show us how much data you lost since you didn't have backups!\n  \nTotally not an attempt to build community rapport.\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzc3qa/datahoarder_discussion/",
          "publishedOn": "2022-12-30T21:30:09.000Z",
          "wordCount": 15446,
          "title": "DataHoarder Discussion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzb9xu/expansion_options/",
          "author": null,
          "description": "Hello,\n I'm currently using my 2 x 16Tb disk in RAID1 setup build on Synology 918. I'm looking for expansion options. I have considered so far following: - adding new 16Tb drive and building RAID5 - adding new 16Tb drive on side as standalone - adding 2 x new 4Tb in RAID1 and building RAID0 2x16Tb - adding 2 x new 4Tb in RAID1 and leaving 2 x 16Tb each standalone\n My critical data (documents, photos etc) are around 3Tb in size, currently placed on 16Tb volume together with some unnecessary data like movies, TV shows, ISO data store for ESXi etc. \n I'm slowly increasing critical data, but the non critical one is growing really fast.\n In first option, I will have one volume, but with RAID5. Considering my critical data is being backed up to USB, I could take risk of potential rebuild of 32Tb volume, but still it's RAID5. In last option, my critical data would move to separate volume, while non critical data could spin on standalone 2x16Tb drives.\n Which would you recommend to me? Is that RAID5 really a risk if the critical data is backed up? I'm also worried about speed in RAID5, but maybe nvme cache is an option?\n Guys please advise, as I'm bit lost.\n    submitted by    /u/Slushfall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzb9xu/expansion_options/",
          "publishedOn": "2022-12-30T20:56:22.000Z",
          "wordCount": 16369,
          "title": "Expansion options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzb9fk/plex_server_for_a_dummy/",
          "author": null,
          "description": "I have been using WD Easystore 14TB HDs USB connected to my laptop for over a year. Plex works swimmingly and I've never had any issues. Recently I decided I wanted a bit more of a legit setup and am tired of the USB clutter and WD enclosures. I plan to shuck these and use them in the new server (aware of the white label drive's pin, etc).\n I am lazy and not a hardware techy, so I bought this previously owned server from someone. Here's the description:\n \"Built this to run my plex server using unraid. have upgraded my system. No harddrives included. This holds 5 harddrives. Small and compact. Asrock H97M -ITX/AC motherboard Intel i5 -4590 Processor Crucial Balistic 16GB Ram Corsair CX500M Power Supply Lian Li - PC-Q25 Case 2 Noctua Fan Case\" \n I do NOT plan to use UNRAID or TRUEnas. I will use Windows and this thing will be a Plex server exclusively.\n Here's the images of it: https://ibb.co/jbsD83r https://ibb.co/09pTdcy https://ibb.co/3S0st6M https://ibb.co/YWrs2Jk https://ibb.co/J5jZNcw\n So my questions are:\n  \nHow plug and play ready is this once I put my HDs in? \n Can I use this with my existing laptop? \n What are things I must know besides the obvious Plex oriented things?\n Advice??\n  \nThanks in advance!\n    submitted by    /u/ryPods  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzb9fk/plex_server_for_a_dummy/",
          "publishedOn": "2022-12-30T20:55:47.000Z",
          "wordCount": 16602,
          "title": "PLEX Server for a Dummy",
          "imageUrl": "https://external-preview.redd.it/KdVBmUzYJLlGjhbLHdCvjppX7mEFdppOuoKY9oWFGQ8.jpg?auto=webp&s=21f1646fcc6a1bd554e7eaa87115061d29f679e8"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzb792/storage_suggestions/",
          "author": null,
          "description": "Hello! I’m hoping that this is the correct community to ask in, but if I’m in tht wrong place I apologize in advance \n I need to drastically increase the storage on my home network and also want to add redundancy. \n I was looking at older Drobo models, which looked fantastic. I like the idea of a NAS that just uses the available disk space without needing have all the drives match exactly. I’ve read that Linux support is lacking, though. Ext3 is fine, but ext4 isn’t, apparently. \n I also appreciate that they come with USB and network connectivity. That way you don’t have to decide whether it’ll be connected directly to a server or hosted on the network. \n Can anyone suggest another consumer grade enclosure or NaS that’s comparable? USB and Ethernet, with support for mix and match drives, And is compatible with ext4?\n A while ago, I found a Linux application that could do the mismatched drives, but forgot the name. But because it could only be used as network storage it didn’t seem compelling \n My reading about synologies indicates that they need identical sized drives, so that nixes them. \n What else is out there? Any suggestions appreciated!\n    submitted by    /u/lucasjkr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzb792/storage_suggestions/",
          "publishedOn": "2022-12-30T20:53:10.000Z",
          "wordCount": 15720,
          "title": "Storage suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zzalzd/western_digital_store_return/",
          "author": null,
          "description": "Does anyone has WD store return experience to share? They told me the return shipping is free as long as it's within 30 days of purchase.\n I did have to do a warranty replacement with them a while back and they didn't give me any trouble, so I'm wondering about purchasing from their online store.\n    submitted by    /u/JustStranger6803  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zzalzd/western_digital_store_return/",
          "publishedOn": "2022-12-30T20:28:25.000Z",
          "wordCount": 17266,
          "title": "Western Digital Store Return?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zza4d6/reliable_backup_for_windows_10_file_level_and/",
          "author": null,
          "description": "What program should I use for reliable automated backups? I don't mind paid but would prefer to avoid subscriptions.\n I have a home desktop running Windows 10. One SSD to run Windows, assorted programs, and a Linux virtual machine, and three HDDs full of personal data. I'm backing up to an external WD Elements HDD.\n I'd like to have a image backup of my SSD without the Linux VM, another image backup of just the VM, and a file level backup of my multiple data drives.\n A couple other questions:\n If I run incremental backups can I eventually consolidate those files on the backup drive and be able to compare the consolidated full backup files against my local files?\n Final question for anyone patient and kind enough to still be reading this, if I rename local files on my local data drives and reorganize their folders, would a file level backup program end up making duplicates or be able to track the name/folder changes?\n    submitted by    /u/yodathewise  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zza4d6/reliable_backup_for_windows_10_file_level_and/",
          "publishedOn": "2022-12-30T20:08:26.000Z",
          "wordCount": 17060,
          "title": "Reliable backup for Windows 10? File level and image/volume level backups?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zz8wp7/10tb_wd_red_nas_drive_wd101efbx_15999_sold_by_wd/",
          "author": null,
          "description": "submitted by    /u/Dorbiman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zz8wp7/10tb_wd_red_nas_drive_wd101efbx_15999_sold_by_wd/",
          "publishedOn": "2022-12-30T19:19:28.000Z",
          "wordCount": 15646,
          "title": "10TB WD Red NAS Drive (WD101EFBX) $159.99 -- Sold by WD on Amazon",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zz8abo/what_cloud_backupstorage_option_is_best_for_this/",
          "author": null,
          "description": "I think I can sum up my cloud storage needs with two 2 points...\n 1. I don't want continuous backup, I want to do it manually.\n I don't have enough changing data on my desktop to need any sort of continuous backup. The data I'm looking to backup is mainly just 1) decades of old photos, videos, documents that aren't ever being changed/updated, 2) a handful of documents I update from time to time (e.g. weekly, monthly), and 3) new documents that show up infrequently and don't get updated after that (e.g. yearly tax documents).\n So, I basically just have a bunch of stuff I'd like to manually upload somewhere and store as a backup (in addition to the external drive I already do this with), and then I'd like to manually upload some additional stuff or an updated version of a file that's already being stored on occasion.\n 2. I do want zero-knowledge encryption. \n For all the usual security/privacy reasons.\n What would be the best option(s) for this purpose? \n Thanks in advance for any advice.\n    submitted by    /u/andleaveatrail  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zz8abo/what_cloud_backupstorage_option_is_best_for_this/",
          "publishedOn": "2022-12-30T18:53:57.000Z",
          "wordCount": 16922,
          "title": "What cloud backup/storage option is best for this purpose?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zz7jqd/extra_drive_cages_for_corsair_900d/",
          "author": null,
          "description": "Im not sure if I should ask this here or r/buildapc. Please remove if it is against the rules\n I found a good deal on a second hand corsair 900d and thinking of getting it. But I may need additional drive cages later on. Since it is a pretty old case, I think it is impossible to get it from corsair or find it online.\n How compatible are drive cages from other cases would be with this one? Or would it be possible to get it 3d printed? I don't care for the looks, I just would like to be able to add more drive cages when I need it.\n This will be my first time building a pc so, sorry if it is a stupid question\n Also if you have other comments on the case itself, please share\n    submitted by    /u/lemmeanon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zz7jqd/extra_drive_cages_for_corsair_900d/",
          "publishedOn": "2022-12-30T18:22:36.000Z",
          "wordCount": 16328,
          "title": "Extra drive cages for Corsair 900D",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zz6pml/is_there_a_tool_that_can_download_all_of_the/",
          "author": null,
          "description": "I want to download all the image from someone twitter profile just need tool similar to Instaloader which is for instagram.\n    submitted by    /u/Firm-Bunch-5049  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zz6pml/is_there_a_tool_that_can_download_all_of_the/",
          "publishedOn": "2022-12-30T17:49:51.000Z",
          "wordCount": 15882,
          "title": "Is there a tool that can download all of the images that someone tweets over time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zz64yc/adventure_time_removed_game/",
          "author": null,
          "description": "a lot of years back i remember playing this Adventure Time game where Finn is in a dungeon and unlocks swords etc, this game was a 3d game and i think it was top view, i spent the whole day looking for it but Wikis, wayback machine, etc dont show this game, am i crazy?, i could swear i played this.\n    submitted by    /u/Phokyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zz64yc/adventure_time_removed_game/",
          "publishedOn": "2022-12-30T17:26:48.000Z",
          "wordCount": 15560,
          "title": "Adventure Time Removed Game?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zz21n4/haystack_your_own_google_search_for_personal_data/",
          "author": null,
          "description": "tl;dr: a natural language search engine for personal data archives .\n Iv'e pulling a lot of old stuff from my archive lately, the thing is, the HDD (10tb seagate) is way too slow for searching in realtime, more over, I can't actually search with natural language so to find what I'm looking for I need to try a couple of searches.\n That's why I decided to build haystack, a search engine for data, meant for finding technical details or relevant paragraphs..\n It enables you to search large HDDs or slack, confluence, email all in one place.\n no internet connection required.\n It supports natural language queries so a query like: \"where was I last spring?\"yields:\n 4 documents, 3 photos, and two emails \n haystack stores user data locally, so there's no security risk - only you have access to internal docs, I didn't want to deal with security compliance headaches caused from storing user data in the cloud.\n Rolled it out to my co-workers and friends a week ago and they thought it's a hit, and also less bugging, so I'm planning on releasing it publicly on March 2023.\n Early access\n If you want to try it out before March 2023 - Early access\n or Github\n Thanks, Yuval\n    submitted by    /u/yuvalsteuer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zz21n4/haystack_your_own_google_search_for_personal_data/",
          "publishedOn": "2022-12-30T14:36:56.000Z",
          "wordCount": 15511,
          "title": "haystack - your own google search for personal data archives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zz112y/elon_musk_orders_closure_of_one_of_twitters_3/",
          "author": null,
          "description": "submitted by    /u/GimmeSomeSugar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zz112y/elon_musk_orders_closure_of_one_of_twitters_3/",
          "publishedOn": "2022-12-30T13:51:15.000Z",
          "wordCount": 16047,
          "title": "Elon Musk orders closure of \"one of Twitter's 3 main computing storage facilities\". Where might the gear resurface?",
          "imageUrl": "https://external-preview.redd.it/hQaBTilr7KyaQ6gqI_Yml2_A2iSVj8WQQaIcNk9x8yE.jpg?auto=webp&s=323a827f9d8c2de2c2a5cbee6b34d8acdec82337"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zyq5vw/hoarders_remember_no_library_is_complete_unless/",
          "author": null,
          "description": "You can download it from Xowa or Kiwix.\n They allow you to download specific language, or even specific wiki, such as Movies' topics or Medicine, or Computer or top 50,000 entries (check other selections at Kiwix library page).\n Once you have the database (wiki set) you just need the application (launcher) which is available in Windows, Mac, Android, Linux formats. The size varies from 1-90GB. You can choose between no-pic, no-video, or full (maxi).\n    submitted by    /u/tecepeipe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zyq5vw/hoarders_remember_no_library_is_complete_unless/",
          "publishedOn": "2022-12-30T03:51:58.000Z",
          "wordCount": 19757,
          "title": "Hoarders, Remember, no library is complete unless you have Wikipedia for offline access!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zymivp/wd_red_drives_sleeping_after_moving_them_to_lsi/",
          "author": null,
          "description": "I also moved from mdadm to ZFS RAID, so it's possible that this RAIDZv1 array idles more than the RAID10 array I used to have with the same four disks and I am noticing the spindown now vs before.\n I don't understand why the drives are spinning down. I've used hdparm to set the -B value to 255 but it gets reset to 20 after a while. I set it in a udev rule so its set at boot up, but again, after a while, it's back at 20.\n I don't have TLP or any other power management script/tool that I know of. The logs don't show anything interesting. I've tried searching but there's not a lot of info about not wanting the drives to sleep, usually it's the opposite.\n I've tried setitng -S 0 along with -B 255 with hdparm. I updated /etc/hdparm.conf to set the APM value to 255 for each of my spinning drives. \n Is there something else I'm missing that is changing the APM value of the drives?\n    submitted by    /u/motoridersd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zymivp/wd_red_drives_sleeping_after_moving_them_to_lsi/",
          "publishedOn": "2022-12-30T01:07:47.000Z",
          "wordCount": 15695,
          "title": "WD Red drives sleeping after moving them to LSI HBA on Ubuntu 22.04",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zymgbg/the_73_apple_internal_iso_images_that_i_uploaded/",
          "author": null,
          "description": "submitted by    /u/MrFahrenheit_451  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zymgbg/the_73_apple_internal_iso_images_that_i_uploaded/",
          "publishedOn": "2022-12-30T01:04:48.000Z",
          "wordCount": 15190,
          "title": "The 73 Apple internal ISO images that I uploaded last week are now downloadable on Macintosh Garden - links in comments",
          "imageUrl": "https://preview.redd.it/dec1h2fvsy8a1.jpg?auto=webp&s=e5660ca762272c2d62bdb8ea399cf45590d2c3d0"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zykyph/buy_jewel_case_inserts/",
          "author": null,
          "description": "I still use optical media for certain things and the one thing that I've never been able to find for sale but always use are the paper inserts that go into jewel cases, especially the front one (or the only one if you're using slim jewel cases). I'm not a fan of making my own so I was wondering if anyone has ever come across nice lined jewel case inserts for sale (the slightly glossy ones like what you would get if you're buying Verbatim DVD-R discs individually packaged in jewel cases)?\n    submitted by    /u/HarryMuscle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zykyph/buy_jewel_case_inserts/",
          "publishedOn": "2022-12-30T00:02:25.000Z",
          "wordCount": 15786,
          "title": "Buy Jewel Case Inserts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zykujf/a_master_reading_order_i_have_compiled_of_western/",
          "author": null,
          "description": "So I didn't really know where to share this but I thought I should mention.\n So when one of the big problems I have with western comic books in comparison to manga is that I just don't know where to start. I'd like to read the in universe collection I just don't know how to.\n And this is where this reading order comes in.\n https://comicbookreadingorders.com/\n I've compiled the entire list in several cbz for a more seamless experience. \n I have done marvel master reading order part 1-10,Marvel Now, all new all different marvel, Marvel Legacy, A Fresh Start.\n and for Dc master reading order part 1-7, The new 52, DC you, rebirth.\n Marvel's has many more comics and is monstrously larger than DC. \n I don't want you guys to think that I'm asking to archive it for me to use later. I have my own digital archive. I am keeping it careful. But i thought I should mention it for the comic book fans that are interested.\n Its on Torrentgalaxy.\n    submitted by    /u/shellshock321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zykujf/a_master_reading_order_i_have_compiled_of_western/",
          "publishedOn": "2022-12-29T23:58:14.000Z",
          "wordCount": 15523,
          "title": "A Master Reading order I have compiled of western comic books.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zykj49/corruption_when_file_transfer_is_interrupted/",
          "author": null,
          "description": "Hi all,\n This sub has helped me a great deal with backing up my work, so I thought I’d ask a question here. I often make huge backups overnight. As I’m fairly clumsy, I’ll occasionally knock a wire or something, and the process will be interrupted. In todays instance, I knocked the off button in my new hard drive enclosure. I had some errors on screen (“unable to move movie.mp4”) but turning it back on again, I could click “try again” and the process resumed as before. My question is, will it be corrupted, or will windows simply move the whole file from the start again? I can always check the files are the same size after the move perhaps, just to check. Should I be worried? Would I need to start the process over?\n Thanks, Harry\n    submitted by    /u/harryking_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zykj49/corruption_when_file_transfer_is_interrupted/",
          "publishedOn": "2022-12-29T23:45:31.000Z",
          "wordCount": 16625,
          "title": "Corruption when file transfer is interrupted",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zyj82m/this_old_house_insider_subscription/",
          "author": null,
          "description": "Has anyone been able (or attempted) to grab files from TOH Insider? I've been trying to fill out my collection with seasons 13-30 but I can't quite figure out how to grab the videos from this site. It doesn't look like they use Youtube any longer for their older episodes.\n    submitted by    /u/Berkyjay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zyj82m/this_old_house_insider_subscription/",
          "publishedOn": "2022-12-29T22:53:53.000Z",
          "wordCount": 15427,
          "title": "This Old House Insider /subscription",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zyhtfg/terramaster_d3400_questionable_deal/",
          "author": null,
          "description": "I purchased a Terramaster D3-400 a few months ago so that I could set up a home server with a ZFS pool. I put four Toshiba N300 4TB drives in the box and set it up with TrueNAS on an Intel NUC. It works pretty well except the disk drives spun constantly: they never went to sleep.\n It wasn't the fastest thing on two feet though, so I decided: let's just use it as it was intended, a direct attach storage device. I hook it up to my Windows 11 laptop, and... it seems to power off randomly. In order to bring the device back up I have to unplug the DAS and then it can be recognized by the OS again. This morning I tried writing about half a terabyte to it and it turned itself off after a few dozen gig.\n I am not 100% sure I trust this thing. I know it was a bargain, many of the reviews were positive, but I'm not putting my life's work on it in the meantime.\n Has anyone else had a similar experience? Any way to spin down the disks or keep the box awake?\n    submitted by    /u/thatwombat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zyhtfg/terramaster_d3400_questionable_deal/",
          "publishedOn": "2022-12-29T21:59:26.000Z",
          "wordCount": 15557,
          "title": "Terramaster D3-400: Questionable Deal",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zyhi0d/14tb_wd_drive_for_199_at_bby/",
          "author": null,
          "description": "https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303&ref=app_ios&loc=pdpShare\n    submitted by    /u/whitley-photo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zyhi0d/14tb_wd_drive_for_199_at_bby/",
          "publishedOn": "2022-12-29T21:46:54.000Z",
          "wordCount": 15187,
          "title": "14TB WD Drive for $199 at BBY",
          "imageUrl": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?auto=webp&s=0d9dc09b0ad8bb581b3f12d19a61f850933bb13d"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zyh49h/cheapest_way_to_share_documents_between_2/",
          "author": null,
          "description": "Bit of context: we have 2 computer at home that we use for running a business, some simple video editing, graphic design, etc. and we need to share and keep a few folders of commissioned arts, short videos, assets and projects synced or accessible between these 2 computers to make it easy to work with. These 2 computers are plugged into our provided combo router/modem provided by our ISP (it doesn’t have any other ports sadly)\n While acquiring or building a NAS sounds fun in a geeky way, I am looking into the best value option to handle this task, even if it mean using built-in Windows features.\n    submitted by    /u/StereoMissile  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zyh49h/cheapest_way_to_share_documents_between_2/",
          "publishedOn": "2022-12-29T21:31:54.000Z",
          "wordCount": 16438,
          "title": "Cheapest way to share documents between 2 computers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zygvcx/can_you_tell_me_of_a_tool_that_will_download_a/",
          "author": null,
          "description": "Hello i tried downloading a sub reddit with wget and I think it started downloading all of reddit subs lmao, can give me a tool that will work on linux?\n    submitted by    /u/Tempestofchoas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zygvcx/can_you_tell_me_of_a_tool_that_will_download_a/",
          "publishedOn": "2022-12-29T21:22:23.000Z",
          "wordCount": 15891,
          "title": "can you tell me of a tool that will download a whole sub",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zyg96d/same_price_for_hba_and_raid_card_which_one_should/",
          "author": null,
          "description": "I just want to add more SATA port to my motherboard. I currently have only 6 SATA and I need to connect to 12 SATA HDD. \n I have never tried RAID before. And I want to merge some of the HDD together as one drive. Which one should I choose ?\n    submitted by    /u/Sebisquick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zyg96d/same_price_for_hba_and_raid_card_which_one_should/",
          "publishedOn": "2022-12-29T20:58:53.000Z",
          "wordCount": 15995,
          "title": "Same price for HBA and RAID card Which one should I choose ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zyfnj0/question_about_18_tb_western_digital_drives/",
          "author": null,
          "description": "I got two WD 18 TB drives that I shucked from WD My Book, and they are WDC WD120EDBZ-11B1HA0. However, both of them make this weird periodic thumping sound when they are running. I do not know if this is a normal behaviour of the drives, or I am just unlucky enough to have two defective drives. When I touch the drive, it feels like very gentle baby kicks. I have already zero-filled the drive to check if there's anything wrong, but nothing seems to stand out in SMART tests. Should I be concerned? I can send audio samples of what it sounds like, if it helps.\n    submitted by    /u/IWillBiteYourFace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zyfnj0/question_about_18_tb_western_digital_drives/",
          "publishedOn": "2022-12-29T20:34:22.000Z",
          "wordCount": 15819,
          "title": "Question about 18 TB Western Digital Drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zyeuhg/arm_making_iso_files/",
          "author": null,
          "description": "Not sure where to ask this, so I figured I'd start in the place I learned about ARM. After getting Automatic Ripping Machine set up on an old server of mine running a fresh install of Debian 11, I put in a DVD and it ripped it to an ISO file. I tried a second one and got the same result. \n I'm not finding anything in the discussions on their GitHub page and it doesn't seem like a particularly active community.\n    submitted by    /u/rtuite81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zyeuhg/arm_making_iso_files/",
          "publishedOn": "2022-12-29T20:01:55.000Z",
          "wordCount": 15096,
          "title": "ARM making ISO files",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zyelqw/help_please_i_want_to_image_a_lerge_number_of/",
          "author": null,
          "description": "I did a search of the sub and every post that talks about archiving floppy disks talks about making images but the only software I've found mentioned is $60 (us) (or making images by reading magnetic flux directly with hardware).\n Is there an open source windows app to do this or should I just install linux on a box and use dd?\n Thanks\n EDIT: argh... lerge is somewhere between 1 and 4 k\n    submitted by    /u/Captain_Patchy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zyelqw/help_please_i_want_to_image_a_lerge_number_of/",
          "publishedOn": "2022-12-29T19:52:44.000Z",
          "wordCount": 16406,
          "title": "Help please? I want to image a lerge number of msdos/win floppies, I have hardware and need software advice.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zye85o/20tb_wd_elements_30999_at_amazon_usa/",
          "author": null,
          "description": "submitted by    /u/HTWingNut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zye85o/20tb_wd_elements_30999_at_amazon_usa/",
          "publishedOn": "2022-12-29T19:38:05.000Z",
          "wordCount": 15981,
          "title": "20TB WD Elements $309.99 at AMAZON USA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zycivv/decent_cloud_storage_right_now/",
          "author": null,
          "description": "Was supposed to have lifetime unlimited GDrive from my uni, but Google is ending their contracts with UK schools in 2023. A NAS is not an option for me for various reasons, so I'm looking for cloud storage to replace gdrive.\n How I intend to use it is to have all my files on several external SSDs and to back those up. I can't use a service where the backup has to reflect the files on my computer, as I use a desktop and laptop.\n Looking for about 4TB minimum. Able to spend about £10 a month. Anyone have any suggestions?\n    submitted by    /u/dysfunctionalbrat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zycivv/decent_cloud_storage_right_now/",
          "publishedOn": "2022-12-29T18:33:02.000Z",
          "wordCount": 16949,
          "title": "Decent cloud storage right now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zycegf/seeking_advice_on_academic_pdf_hoarding/",
          "author": null,
          "description": "Hi, I'm currently a researcher and am fortunate to be at an institution with an excellent library system. However, this will likely not always be the case, and I'd like to archive about as much of the academic literature as possible (particularly relevant to my work, but also in some other fields of interest). The dream would be to create an \"antilibrary\" in the style of Umberto Eco. \n I use Zotero on an unlimited storage plan and have ~4.5 TB of total available open space (working on filling this!). Papers don't take up that much space at all; the limiting factor is my own throughput. It'd be great to find an automated workflow so as to download & organize papers. My access to journals is generally mediated through EZProxy, but this is avoidable on local WiFi. Does anyone have experience with the Zotero API and/or EZProxy to do this (or similar tools)?\n    submitted by    /u/complex_pleasures  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zycegf/seeking_advice_on_academic_pdf_hoarding/",
          "publishedOn": "2022-12-29T18:28:04.000Z",
          "wordCount": 16823,
          "title": "Seeking advice on academic PDF hoarding",
          "imageUrl": "https://external-preview.redd.it/bHOWcqwFdYJzEvfmeDZ3kHuuk2ZvN6yBM7ktP-9hepw.jpg?auto=webp&s=2f95e931a8c0185bd5859763319269ac0167b721"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zybxkp/nas_or_das/",
          "author": null,
          "description": "Hello everyone,\n I'm currently using an old desktop PC (i5-3570k) as a simple home server with Ubuntu and ZFS. The only purpose of the server is to archive a bunch of data that I rarely access and to act as a Time Machine (macOS backup) target. For this reason, it spends 90% of its time suspended.\n My problem is that the server is in the hall together with my home router, but I have no way to connect to it through Ethernet from my PC in my bedroom, so I have to use Wi-Fi and this causes the Time Machine backups to be unbearably slow.\n I thought about 2 possible \"solutions\":\n  \nMove the server in my bedroom, in order to connect it to my laptop via Ethernet to make things faster and to reduce latency. This would also mean having to connect to the AP via Wi-Fi (i.e. much slower and less reliable Internet access).\n Remove everything from the case apart from the PSU and the disks and turn the PC into a poor man's USB DAS (located in my bedroom). This would mean higher speed and lower power consumption.\n  \nFor my current situation, it looks like solution 2 is the better deal. A NAS is certainly more flexible, but right now I only use a single PC and I don't see that changing in the near future.\n What do you guys think? Am I missing anything / are there other smarter solutions?\n    submitted by    /u/OchMn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zybxkp/nas_or_das/",
          "publishedOn": "2022-12-29T18:08:56.000Z",
          "wordCount": 16937,
          "title": "NAS or DAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zya4jo/proper_way_to_keep_backups_of_multiple_servers/",
          "author": null,
          "description": "I'm looking for a backup solution for 100TB of data. I only have one 60TB server available at the moment, but am planning to add more storage, the only problem is that it's going to be on a separate server. What would be the best way to make sure both servers are backed up, preferably separate drives for off site backups or something similar. Is there any way to easily keep track of the data and make backups, what's the best practice in this instance to keep the data safe?\n    submitted by    /u/ElementaryZX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zya4jo/proper_way_to_keep_backups_of_multiple_servers/",
          "publishedOn": "2022-12-29T16:56:13.000Z",
          "wordCount": 17735,
          "title": "Proper way to keep backups of multiple servers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zy884q/at_what_percent_left_of_an_ssds_lifetime_do_you/",
          "author": null,
          "description": "Im curious if you guys just wait for the drive to just die on you or you guys have a threshold like if it goes below 20-30% left you just backup everything and throw it away\n    submitted by    /u/i0bzdnahw0lz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zy884q/at_what_percent_left_of_an_ssds_lifetime_do_you/",
          "publishedOn": "2022-12-29T15:36:25.000Z",
          "wordCount": 16270,
          "title": "At what percent left of an SSD's lifetime do you guys throw it away?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zy7ojw/building_or_buying_new_nas_200tb/",
          "author": null,
          "description": "Hey guys,\n This sub has been very good to me giving me advice for my first server build. Well I am back and in true DataHorder style, I'm out of space on that server so I'm in the process of planning my new NAS/Server and need your advice again.\n My current setup:\n  \nIts is a custom built Hyper-V server with a big storage pool and a few VMs on it (including Plex).\n The pool is a triple mirror pool with about 45TB effective capacity.\n VMs run Centos (in case that matters).\n  \nWhat I'm looking for:\n  \n~200TB effective storage\n 2 disk redundancy (meaning I can lose 2 disks and not loose the pool). I am open to a 'raid-6' config or similar for efficiency.\n don't need a lot of horsepower here to run VMs as that is and will be handled on my existing server.\n Minimum- Storage needs to be fast enough to stream 4K HDR movies (about 200Mbps) but ideally would like it to be able to handle gigabit read and writes.\n  \nOption 1: Buy a NAS\n  \nI was considering buying a Synology 12 bay unit and filling it with (12) 20TB Exos drives but know they made a change recently where their NAS's only support their Synology branded drives and these 20TB drives wouldn't fit that. Not sure how advisable it is to run non-supported drives on these units. Also not sure if I would bump up against the Maximum Volume size. I think I would need the DS3622XS+ due to said limit.\n I'm also open to other manufacturers if you have one to recommend.\n  \nOption 2: Build a NAS\n  \nThe other option is to build my own. Admittedly I will need some help with this specifically with software and hardware recommendations. I'm not sure how much hardware horsepower ill need to handle this much storage. With regard to software, what's the preferred choice for a pool of this size?\n  \nI am very open to any info or feedback that you have and am happy to provide any more details.\n Thanks in advance!\n JM\n    submitted by    /u/awildjm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zy7ojw/building_or_buying_new_nas_200tb/",
          "publishedOn": "2022-12-29T15:12:37.000Z",
          "wordCount": 18952,
          "title": "Building (or buying) new NAS 200TB+",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zy7dvs/looking_to_become_an_organized_hoarder_need_some/",
          "author": null,
          "description": "I know I can view and rename a file. \n I know I can view and add tags into file properties in Windows Explorer.\n .\n Those all take a lot of time for hundreds if not thousands of files.\n .\n Can I have a self-hosted web interface where I am presented videos/pdf/jpg and I can just type in, \"red car California road mountain\" press enter and move onto the next file, a PDF. \"electric bill January 2021 NYSEG\" press enter. a JPG pops up and I click a button and it sends the image to Google for a quick reverse image search in case I need help with Keywords or want a better resolution. \n Does this exist? Do I need to make it? Do I need to sell it? I've done a decent search but can't find one that has Google reverse image and is fast and does PDF's and videos and just assults my eyes with media. I have to click on each file with my mouse...\n    submitted by    /u/rileymorgan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zy7dvs/looking_to_become_an_organized_hoarder_need_some/",
          "publishedOn": "2022-12-29T14:59:57.000Z",
          "wordCount": 17292,
          "title": "Looking to become an Organized Hoarder, need some help with tagging videos/PDFs/JPGs.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxze28/my_homeserver/",
          "author": null,
          "description": "Since ppl are posting their setups, i have to do the same\n usage (hyper-v): \n NAS with VPN; Nextcloud; Openhab; Gameserver for several games; remote (gaming) pc for me and my girlfriend; emby to stream all the linux isos and transcode if needed\n hardware:\n AMD Threadripper 3970 32c/64t\n 256GB Samsung ECC DDR4 RAM\n Asus Zenith II Mainboard\n 2x RTX 3070 (for gaming | GPU-P in Hyper-V)\n 1x GTX 970 (for transode | GPU-P in Hyper-V)\n 4TB SSD for VMs; 50TB HDD netto (beause of redundancy) for linux isos\n 500GB NVMe Cache | 500GB NVMe System Drive\n https://preview.redd.it/i6jreqyzjs8a1.jpg?width=1284&format=pjpg&auto=webp&s=fc04f97e5ec8fe457d081e3731897137fe2ae443\n Edit---------------\n Case: deep silence 5 revision b\n    submitted by    /u/caffeineshock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxze28/my_homeserver/",
          "publishedOn": "2022-12-29T07:41:42.000Z",
          "wordCount": 18613,
          "title": "My Home-Server",
          "imageUrl": "https://external-preview.redd.it/71hTCrYd-xnkJ05aGU2-YLyerTdz3NPQRnxWn1ZA6fs.jpg?auto=webp&s=901a7a423249e8b6706125e676a6568616a1c500"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxroij/if_youre_a_fan_of_new_yankee_workshop_and_norm/",
          "author": null,
          "description": "submitted by    /u/GubmintTroll  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxroij/if_youre_a_fan_of_new_yankee_workshop_and_norm/",
          "publishedOn": "2022-12-29T01:30:56.000Z",
          "wordCount": 15410,
          "title": "If you're a fan of New Yankee Workshop and Norm Abram, they just started a YouTube channel where they are uploading all of their videos. Pure nostalgia for me.",
          "imageUrl": "https://external-preview.redd.it/js_6OKp1K24h_iMzY7QNT0MpEBKHkhKIob_PpAJ1CwI.jpg?auto=webp&s=81d2170f1d9955317769c140ecbcd27f25f092da"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxr3gc/how_can_i_save_fypttto_videos/",
          "author": null,
          "description": "How can I save fyptt.to videos?\n    submitted by    /u/district999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxr3gc/how_can_i_save_fypttto_videos/",
          "publishedOn": "2022-12-29T01:06:11.000Z",
          "wordCount": 15376,
          "title": "How can I save fyptt.to videos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxpwkz/family_member_wants_to_stress_test_4x20tb_drives/",
          "author": null,
          "description": "So folks, I'm the designated \"IT\" person in the family. And my google-fu is weak on this one. \n This family member has them in 2 OWC enclosures that houses 2x20TB drives each. I only have access to their macbook and the connection will be via thunderbolt.\n So far, I've done the badblocks route for 50% of the drives, only to learn that I cannot run the remaining 50% of the drive because the end block value exceeds the 32bit integer. I've also tried to do my homework and now understand that changing the -b argument of badblocks to exceed the 4096 block size will render the badblocks result questionable. So silly me for not researching too much into it before running badblocks on all four drives simultaneously (the first 50% for all four drives passed without any incident).\n So, my questions is, how can I at test the remaining 50% or what are some other tests that are available to me that does not involve spending $$$ for paid solutions? \n I saw a passing comment about encrypting the drive fully via Disk Utility and then checking the SMART status. Is this a viable approach to checking the drives? This family member just wants to know that the drives will not die prematurely. I, personally, think that the drives will be fine, but these drives will be used to store their livelihood, so I understand where they are coming from.\n Any input anyone can provide would be great. Thank you in advance!\n    submitted by    /u/schemingraccoon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxpwkz/family_member_wants_to_stress_test_4x20tb_drives/",
          "publishedOn": "2022-12-29T00:17:28.000Z",
          "wordCount": 16428,
          "title": "Family member wants to stress test 4x20TB drives before using them. Need help....",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxoi63/new_wd_blue_cant_be_initialized_by_windows_and/",
          "author": null,
          "description": "I just purchased a WD Blue HDD used off of FB marketplace. The date on the drive is 6/19/22, and it has this error. From what I can tell, it has not been used before. I checked the smart data and power off retract count is abnormally high. What should I do in this situation?\n    submitted by    /u/donutdoode  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxoi63/new_wd_blue_cant_be_initialized_by_windows_and/",
          "publishedOn": "2022-12-28T23:22:06.000Z",
          "wordCount": 15306,
          "title": "New WD Blue can’t be initialized by Windows and partition table can’t be made on Linux",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxoi1u/udma_crc_error_count_22_proactively_replace/",
          "author": null,
          "description": "14TB UltraStar WD140EDGZ - Output of smartctl after running a short test indicates this error. As well, Scrutiny (UnRAID plugin) lists the drive as failed.\n Should I run a long test to investigate further or just go ahead and replace the drive. Replacing it is a pricey proposition for me right now but if I have to I will.\n Thanks for your thoughts/advice.\n 1 Raw_Read_Error_Rate 0x000b 100 100 001 Pre-fail Always - 0\n 2 Throughput_Performance 0x0004 133 133 054 Old_age Offline - 108\n 3 Spin_Up_Time 0x0007 085 085 001 Pre-fail Always - 242 (Average 381)\n 4 Start_Stop_Count 0x0012 093 093 000 Old_age Always - 3047\n 5 Reallocated_Sector_Ct 0x0033 100 100 001 Pre-fail Always - 0\n 7 Seek_Error_Rate 0x000a 100 100 001 Old_age Always - 0\n 8 Seek_Time_Performance 0x0004 128 128 020 Old_age Offline - 18\n 9 Power_On_Hours 0x0012 099 099 000 Old_age Always - 11443\n 10 Spin_Retry_Count 0x0012 100 100 001 Old_age Always - 0\n 12 Power_Cycle_Count 0x0032 098 098 000 Old_age Always - 152\n 22 Helium_Level 0x0023 100 100 025 Pre-fail Always - 100\n 192 Power-Off_Retract_Count 0x0032 100 100 000 Old_age Always - 4616\n 193 Load_Cycle_Count 0x0012 100 100 000 Old_age Always - 4616\n 194 Temperature_Celsius 0x0002 048 048 000 Old_age Always - 34 (Min/Max 20/47)\n 196 Reallocated_Event_Count 0x0032 100 100 000 Old_age Always - 0\n 197 Current_Pending_Sector 0x0022 100 100 000 Old_age Always - 0\n 198 Offline_Uncorrectable 0x0008 100 100 000 Old_age Offline - 0\n 199 UDMA_CRC_Error_Count 0x000a 100 100 000 Old_age Always - 22\n    submitted by    /u/ripeart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxoi1u/udma_crc_error_count_22_proactively_replace/",
          "publishedOn": "2022-12-28T23:21:58.000Z",
          "wordCount": 15822,
          "title": "UDMA CRC Error Count 22, proactively replace?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxo9e3/whats_faster_amds_storemi_software_or_windows_own/",
          "author": null,
          "description": "I have a Gaming-focused PC with a 1TB PCIe 3.0 NVME drive in addition to a 2TB HDD that I basically tossed in there since I had it lying around.\n Now I'm considering putting a 2TB PCIe 4.0 NVME drive into the second available NVME slot I have on the motherboard, and doing a fresh Window install on it, after which I'll move what little important data I have onto it from the 1TB NVME and then format that drive.\n At this point I'll have the 2TB boot drive, plus the 1TB NVME and 2TB HDD used as data overflow of sorts. I'd like to go ahead and get those later two drives combined into one volume for ease of use, and I'm wondering what's the best \"cheap-to-free\" way to go about this.\n I'm using a AMD CPU and motherboard, so I have their StoreMI software available to me, plus Windows own \"storage spaces\" solution built into the OS.\n Has anyone done any sort of comparison between these two options to see which performs better? I'm not looking for any sort of nitty-gritty numbers but I figure I may as well lean into whichever works better.\n Thanks.\n Late Edit: OR should I just scrap the ol' spinner entirely and just use the two NVME drives manually?\n    submitted by    /u/BurntWhiteRice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxo9e3/whats_faster_amds_storemi_software_or_windows_own/",
          "publishedOn": "2022-12-28T23:12:30.000Z",
          "wordCount": 16319,
          "title": "What's faster? AMD's StoreMI software or Windows' own built-in \"Storage Spaces\" feature.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxmtpv/grab_a_specific_fileytpe_from_a_website_for/",
          "author": null,
          "description": "Hello, one question.\n Do someone of you knows such a Programm?\n I want to use it to backup nzbs like nzbking or something.\n Thanks for the Help!\n Greetings\n    submitted by    /u/Scirazza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxmtpv/grab_a_specific_fileytpe_from_a_website_for/",
          "publishedOn": "2022-12-28T22:17:07.000Z",
          "wordCount": 15278,
          "title": "Grab a specific Fileytpe from a website for docker/debian headless",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxlon0/script_on_windows_for_sorting_7zip_slt_output/",
          "author": null,
          "description": "Hello, does anyone have a script on Windows that can sort the output from 7z l -slt into CRC PATH for each file in the archive? I'd greatly appreciate it if you could share or help make such a script, I don't know much about scripting.\n Example: https://pastebin.com/Wk3HJR3s\n Result:\n 11FF11FF D:\\test\\test\\[test]\\test\\[2021-01-01].7z\\folder\\1.psd 99D59E9A D:\\test\\test\\[test]\\test\\[2022-01-01].7z\\redlof\\redlof2\\2.psd \n Each line should have a CRC value at the start and a space between it and the full path of the file, I want this done for any file in the output.\n    submitted by    /u/Jungy1eong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxlon0/script_on_windows_for_sorting_7zip_slt_output/",
          "publishedOn": "2022-12-28T21:32:47.000Z",
          "wordCount": 15386,
          "title": "Script on Windows for sorting 7-zip SLT output?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxl865/upgrading_my_nas_capacity_and_tactic_from/",
          "author": null,
          "description": "My current NAS SPAN has a 2TB, 1TB, and two 500GB drives for a total of just <4TB capacity and I'm upgrading to a 12TBx4 for RAID 5. \n My QUESTION is if I pull my drives from my NAS bays, swap them with my new drives, will I be able to use, say, my usb-to-sata cable to copy the contents of my old drives to the new ones? \n My worry is that because the disks are spanning, file contents are split amongst all four drives and that copying one drive at a time will result in corruption. I feel I may be confusing spanning with striping, or RAID 0, where data is written to both drives simultaneously; reason why you lose data when one drive fails. \n The easy answer is to just buy an external HDD I can copy my NAS to, I'd just like to not buy more HDDs (for now).\n    submitted by    /u/Spongebobs_Quotes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxl865/upgrading_my_nas_capacity_and_tactic_from/",
          "publishedOn": "2022-12-28T21:15:04.000Z",
          "wordCount": 15891,
          "title": "upgrading my NAS capacity and tactic from JBOD/BIG/SPAN to a 4 disk RAID 5.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxk4uj/how_can_i_bulk_download_from_leakedzone/",
          "author": null,
          "description": "I want to to download an entire artists webpage from leakedzone but the site seems to have lots of protection. I was able to individually download photos and videos one by one with idm integration module... But there's no way to download all photos and videos at once... I've tried Jdownloader, Extreme photo finder, yt dlp... Nothing seems to work. Plz help... Warning: it's a nsfw site.\n    submitted by    /u/John_Eathan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxk4uj/how_can_i_bulk_download_from_leakedzone/",
          "publishedOn": "2022-12-28T20:32:36.000Z",
          "wordCount": 15466,
          "title": "How can I bulk download from leakedzone?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxk4m4/placed_thousands_of_photos_in_the_same_folder/",
          "author": null,
          "description": "Now I have all the pictures are mixed together and sorting them has been been a nightmare. Is there a way or a program that will sort them out maybe with some meta data?\n Thanks in advance\n    submitted by    /u/TroothBeToldPodcast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxk4m4/placed_thousands_of_photos_in_the_same_folder/",
          "publishedOn": "2022-12-28T20:32:20.000Z",
          "wordCount": 15837,
          "title": "placed thousands of photos in the same folder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxjf71/whats_up_with_these_different_variants_of_wd_red/",
          "author": null,
          "description": "I'm looking to upgrade from 2x2TB WD Red (WD20EFRX), but got super confused with current red plus drives.\n WD80EFZZ $129, 5640 RPM, 128 MB cache.\n WD80EFBX $249, 7200 RPM, 256 MB cache (specs seem to be the same as red pro WD8003FFBX $179)\n WD80EFAX $199, 5400 RPM, 256 MB cache\n    submitted by    /u/chekie12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxjf71/whats_up_with_these_different_variants_of_wd_red/",
          "publishedOn": "2022-12-28T20:04:47.000Z",
          "wordCount": 15193,
          "title": "What's up with these different variants of WD red plus 8TB?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxiaoy/hopefully_i_will_be_able_to_join_your_ranks_i_was/",
          "author": null,
          "description": "submitted by    /u/Sphinx8632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxiaoy/hopefully_i_will_be_able_to_join_your_ranks_i_was/",
          "publishedOn": "2022-12-28T19:20:35.000Z",
          "wordCount": 15368,
          "title": "Hopefully I will be able to join your ranks! I was just given a Netgear rn10400 from a friend. I looked online, and they don’t seem to be reliable. Is there anything that can be done, or a different OS that might make this more reliable with data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxi6dx/should_i_go_for_one_of_these_over_a_seagate/",
          "author": null,
          "description": "submitted by    /u/bluejeans90210  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxi6dx/should_i_go_for_one_of_these_over_a_seagate/",
          "publishedOn": "2022-12-28T19:16:07.000Z",
          "wordCount": 15146,
          "title": "Should I go for one of these over a seagate barracuda 8tb, or to hitachi have the dreaded smr too?",
          "imageUrl": "https://external-preview.redd.it/dRWBqvYS0uf7Uc9cp65SNB13u834lG5WLMpjXeUjCVA.jpg?auto=webp&s=8db1fbebba9d87d9717c2a25fc0d87e78c030e6f"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxi0qa/i_have_a_backup_drive_that_i_just_noticed_has_a/",
          "author": null,
          "description": "As the title says.\n Yes, I've become aware of the 3-2-1 backup solution but I'm just finding out about of how to actually take care of my data.\n Better late than never, I hope :/\n    submitted by    /u/mediamystery  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxi0qa/i_have_a_backup_drive_that_i_just_noticed_has_a/",
          "publishedOn": "2022-12-28T19:10:00.000Z",
          "wordCount": 15070,
          "title": "I have a backup drive that I just noticed has a C5 warning (56). When I've copied the contents to a new drive, is there a program to check if some of the files have become damaged in any way without having to compare to their source files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxhuos/organize_digital_files_for_small_office/",
          "author": null,
          "description": "We are a small business with only 3 people. Looking to setup some kind of File Management system so we can have everything nice and organized like files, documents, bank statements, QuickBooks files, invoices, etc. Right now everything is stored on our main PC and if we need to transfer a file we just email it or something but I'm looking to have it so whatever device you are on you can just open the Files app and have everything you need. I'm open to cloud based or local storage. If local storage is needed I am advanced in computers can set it up.\n We have many things on paper like Receipts, Invoices, Documents. I want to find a way to just digitize everything securely as we have done everything on paper and want to go digital. We have the top of the line equipment Computers, Printers, Receipt & Document Scanners, but just need better organization and ideas. \n Devices we use regularly:\n 3 Desktop PCs\n 1 MacBook Pro\n 1 iPad Pro\n iPhones for Mobile\n Applications & Software:\n Gmail\n QuickBooks\n Google Sheets\n Adobe Acrobat (PDF)\n ​\n If anyone has any suggestions for ways to just link up all of these apps and files that would be great. I'm also open to paying a little bit for any alternatives to any apps or ways to use our computers to make sure everything works flawless. Example, if its better to use Office 365 instead of Google etc I can change that. Thank you for any suggestions.\n    submitted by    /u/Denyell23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxhuos/organize_digital_files_for_small_office/",
          "publishedOn": "2022-12-28T19:03:26.000Z",
          "wordCount": 16633,
          "title": "Organize Digital Files for Small Office",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxhsj5/biggest_25_inch_cmr_hdd/",
          "author": null,
          "description": "How big in size do the 2.5 inch drives get before SMR is used? Any 1 tb cmr 2.5 hdds out there? 500gb? Or are all 2.5 inches smr?\n If you know any specific models that would be really helpful\n edit: turns out built in 1tb hdd in my old laptop is actually cmr (HTS541010B7E610) \n    submitted by    /u/lemmeanon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxhsj5/biggest_25_inch_cmr_hdd/",
          "publishedOn": "2022-12-28T19:01:05.000Z",
          "wordCount": 15718,
          "title": "biggest 2.5 inch cmr hdd?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxhcch/need_a_raid_5_card_that_works_under_windows_10/",
          "author": null,
          "description": "Hi. I am looking for a RAID 5 card with some goodISH performance that works under Windows 10. I was going to change my environment to use UNraid for six 10TB Ultrastar disks I happen to have but there are a few applications on this box that need Windows and regular old NTFS. I see many cards floating around but I am sure there are better ones to look for. I tried a few different software raids and even the intel Optane mono raid and the writes are too slow 30mb per second will not cut it. \n Thanks!\n    submitted by    /u/ThickBaker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxhcch/need_a_raid_5_card_that_works_under_windows_10/",
          "publishedOn": "2022-12-28T18:43:22.000Z",
          "wordCount": 15587,
          "title": "Need a Raid 5 card that works under Windows 10",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxgjoe/bulk_download_only_certain_pdfs_from_a_collection/",
          "author": null,
          "description": "Internet gave out and I got halfway through a bulk download on IA. Is there a way to download PDF's from a collection at a certain start point? For example: \n -collection has 400 PDF's\n -I stopped downloading at 250\n -I now want to download PDF's 251-400\n Any help is greatly appreciated.\n    submitted by    /u/isifjaiwheibdbd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxgjoe/bulk_download_only_certain_pdfs_from_a_collection/",
          "publishedOn": "2022-12-28T18:12:31.000Z",
          "wordCount": 15109,
          "title": "Bulk download only certain pdf's from a collection on Internet Archive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxfiln/move_from_a_synology_to_what/",
          "author": null,
          "description": "I have a Synology 6 bay NAS with a 5 bay expander. I was thinking about what I would do when I max out my current setup.\n I was wondering if getting a 12 bay Synology would be the best option or should I look at going custom and using something like TrueNas or Unraid?\n I have a NUC with Ubuntu running Docker for Plex, Unifi, etc. \n The thing I love about my Synology or any NAS is that it's small and is just a case for drives. They are also quiet and are pretty good with power consumption. And after spending all day working in IT, I don't want to spend hours and hours on setup and configuration. I love the ease of set up. With that said, I have built my own PC for 20 years so I'm no stranger to assembling hardware or setting up systems.\n Suggestions?\n    submitted by    /u/tortuga3385  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxfiln/move_from_a_synology_to_what/",
          "publishedOn": "2022-12-28T17:32:29.000Z",
          "wordCount": 17852,
          "title": "Move from a Synology to what?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxbrzv/filedriller_identify_file_types_using_siegfried/",
          "author": null,
          "description": "Hi,\n I wrote a tool that could be handy for some of you.\n filedriller walks a directory tree and identifies all regular files by type with siegfried. Furthermore it creates UUIDv4s, hash sums (md5, sha1, sha256, sha512 or blake2b-512), gathers some metadata and can check whether the file is in the NSRL.\n It is beta, it is open source, useful feedback welcome!\n https://github.com/steffenfritz/filedriller\n    submitted by    /u/ampoffcom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxbrzv/filedriller_identify_file_types_using_siegfried/",
          "publishedOn": "2022-12-28T15:04:18.000Z",
          "wordCount": 16406,
          "title": "Filedriller: Identify file types using siegfried and the NSRL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zxaqkt/swapping_x264avc_video_library_with_x265hevc/",
          "author": null,
          "description": "This past month I've been replacing most of the x264 files on my 4TB external HDD because it started showing signs of filling up. Some of the older 1080p videos were as large as 20GB+ which made me gasp when I compared them to the newer x265 ones which were only 3-5GB in size.\n While looking for major differences in quality, I didn't really notice anything drastic but I'm probably just not looking in the right places. I understand things like bitrate etc will be the main culprits here, but am I on the right track in believing that x265 can truly be this efficient when it comes to the ratio of file size / quality?\n If there are any handy guides / videos about this topic, I would really appreciate the links.\n    submitted by    /u/TomBromeo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zxaqkt/swapping_x264avc_video_library_with_x265hevc/",
          "publishedOn": "2022-12-28T14:20:56.000Z",
          "wordCount": 18602,
          "title": "\"Swapping\" x264/AVC video library with x265/HEVC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zx4noo/built_this_custom_server_for_encoding_multiple_4k/",
          "author": null,
          "description": "submitted by    /u/teejay818  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zx4noo/built_this_custom_server_for_encoding_multiple_4k/",
          "publishedOn": "2022-12-28T08:42:15.000Z",
          "wordCount": 17747,
          "title": "Built this custom server for encoding multiple 4K Plex streams with subtitles",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwv87h/can_someone_help_me_with_how_to_compare_two/",
          "author": null,
          "description": "As the title says, \n I'm new to this and tried downloading Filesync but I don't know if it's the right program for me?\n I've been trying to use Diffmerge but there I only seem to be able to copy one file at a time!\n    submitted by    /u/mediamystery  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwv87h/can_someone_help_me_with_how_to_compare_two/",
          "publishedOn": "2022-12-28T00:31:25.000Z",
          "wordCount": 16240,
          "title": "Can someone help me with how to compare two folders with files and then extract the difference to a third, new folder? I've only been able to find programs that sync the two first folders, but I need the difference by itself",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwv35j/starwind_san_and_nas_free/",
          "author": null,
          "description": "Anyone here use it? How does it compare to omv unraid rockstor and truenas?\n I’m looking for something like unraid with the apps and btrfs but free without having to configure something and hope for the best if there is a failure.\n    submitted by    /u/Steeler_Train  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwv35j/starwind_san_and_nas_free/",
          "publishedOn": "2022-12-28T00:25:27.000Z",
          "wordCount": 15288,
          "title": "Starwind San and nas free",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwupoe/sd_card_help/",
          "author": null,
          "description": "Hey! \n I had a camera format an SD card on me mid shoot earlier. I tried using disk drill to try and recover some of the content but had no luck. \n Does anyone here have any suggestions?\n Thanks\n    submitted by    /u/Hairy_Megan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwupoe/sd_card_help/",
          "publishedOn": "2022-12-28T00:09:27.000Z",
          "wordCount": 15684,
          "title": "SD Card help?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwunk6/need_help_finding_an_archived_version_of_a/",
          "author": null,
          "description": "I'm trying to retrieve a Github repository that used to be public, but has since been deleted.\n There was a project from the Storj team called \"GitBackup\" that was meant to archive all public repos. (https://www.storj.io/blog/architecting-a-decentralized-github-backup)\n Unfortunately, it looks like the project has been shut down.\n Does anyone know if there is a Github archive somewhere?\n    submitted by    /u/Sevauk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwunk6/need_help_finding_an_archived_version_of_a/",
          "publishedOn": "2022-12-28T00:06:52.000Z",
          "wordCount": 15486,
          "title": "Need help finding an archived version of a deleted public Github repo",
          "imageUrl": "https://external-preview.redd.it/L_5x1EOWcErfdwNF3Mzp4QXP1xzrm2xQVOc614s10b8.jpg?auto=webp&s=a22a3aa45c1c895320d59e8a9a65fda127d87072"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwuctv/cross_country_move_advice/",
          "author": null,
          "description": "Got thirty-some 3.5 HDDs I need to transport. A lot are in external enclosures like a QNAP NAS or crappy Mediasonic 8-bays.\n  \nDo the enclosures provide adequate safety if they're sitting in a box on a truck?\n Are Pelican knockoffs on Amazon reliable? I can technically afford whatever is necessary but I'm feeling some sticker shock for what looks like to me are foam inserts in a box.\n  \nWhen I fly to my destination, I may carry-on a drive case to mitigate the risk for some of the drives.\n    submitted by    /u/TootSweetBeatMeat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwuctv/cross_country_move_advice/",
          "publishedOn": "2022-12-27T23:54:17.000Z",
          "wordCount": 15342,
          "title": "Cross Country Move Advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwu8ef/annyone_has_a_large_music_library_i_can_download/",
          "author": null,
          "description": "idk if its the right subreddit, but yeah as the title says or how to download large music libraries myself\n    submitted by    /u/GuestPlayer66  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwu8ef/annyone_has_a_large_music_library_i_can_download/",
          "publishedOn": "2022-12-27T23:48:57.000Z",
          "wordCount": 15428,
          "title": "annyone has a large music library i can download?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwsxk0/looking_for_recommendations_for_a_high_bandwidth/",
          "author": null,
          "description": "Hello, I need a 12 bay solution to high bandwidth reading and writing, so probably raid 5. \n Is there a prebuilt nas I can purchase like this, or does anyone have any build guides?\n    submitted by    /u/high_on_onions  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwsxk0/looking_for_recommendations_for_a_high_bandwidth/",
          "publishedOn": "2022-12-27T22:55:37.000Z",
          "wordCount": 16095,
          "title": "Looking for recommendations for a high bandwidth storage system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwsvt9/what_programs_can_i_use_to_download_youtube/",
          "author": null,
          "description": "Pretty much what the tittle says. \n I pretty much grew up on YouTube, and as such there’s a lot of really old YouTubers that I watched that have either stopped uploading, or have kinda just gone on a deleting spree and deleted a bunch of videos.\n And I would like to go and save a bunch of those videos from getting further lost to time, but I’m not sure which program I should use. Any suggestions?\n    submitted by    /u/GodIsNotAiveChild  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwsvt9/what_programs_can_i_use_to_download_youtube/",
          "publishedOn": "2022-12-27T22:53:46.000Z",
          "wordCount": 16512,
          "title": "What programs can I use to download YouTube videos onto my computer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwrk7x/lto_faq/",
          "author": null,
          "description": "Is there an faq or buyers guide to picking up used LTO drives from eBay? I want in on the fun.\n    submitted by    /u/dhalem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwrk7x/lto_faq/",
          "publishedOn": "2022-12-27T22:01:18.000Z",
          "wordCount": 15382,
          "title": "LTO FAQ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwrb9y/organize_photosvideos_by_watermark_after_external/",
          "author": null,
          "description": "bit of a long shot.. but, my Seagate external hard drive crashed and I was able to recover about 90% of the data. The only problem is, I have files(photo and video) that are in random names. Not categorized by a file name structure at all. The files however are watermarked at the bottom right or top left. \n is there some sort of program or python script I can run so that it can detect the watermark and possibly help me organize the files by watermark name detected?\n    submitted by    /u/Dabberdabs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwrb9y/organize_photosvideos_by_watermark_after_external/",
          "publishedOn": "2022-12-27T21:51:29.000Z",
          "wordCount": 15735,
          "title": "Organize photos/videos by watermark after external crashed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwr8bq/any_recommendations_for_a_budget_1012_bay_hotswap/",
          "author": null,
          "description": "I'm contemplating doing a rebuild of my plex server and would like to simplify my storage solution. Any recommendations for a case that includes a hot-swap backplane for 10-12 HDDs? It can be big and ugly but I'd like to keep it under $200 if possible. Also I'll need an internal SATA expansion card too so a recommendation there would be appreciated (6 port).\n Current hardware:\n  \nRyzen 5 1600\n MSI X470 Gaming Plus Max (6x SATA ports)\n 32GB DDR4-3200\n GTX 1050 ti\n SATA: 8x 4TB, 1x 256GB SSD (cache drive)\n M.2 NVMe boot drive\n  \nThe plan is to have the 8TB drives in a mergerfs + snapraid pool. I would also consider selling the CPU, mobo and GPU and switching to Intel QSV solution too which might be easier.\n Edit: Silverstone CS380B looks perfect but prices have gone waaayyy up. Was less than $140 a few years ago.\n    submitted by    /u/Perfect_Sir4820  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwr8bq/any_recommendations_for_a_budget_1012_bay_hotswap/",
          "publishedOn": "2022-12-27T21:48:21.000Z",
          "wordCount": 15879,
          "title": "Any recommendations for a budget 10-12 bay, hot-swap case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwquk5/converting_hi8_tapes_to_digital_having_a_problem/",
          "author": null,
          "description": "Hi, I bought the elgato video capture device to convert hi8 tapes from an old school camcorder that the hi8 tapes were recorder on and then playing them on the camcorder while capturing the video. The connection is via the Red,yellow, white cables. The video is fidgeting and terrible quality when converting. I tried it on both a Mac and a PC with the same terrible quality.\n However, I plugged the camcorder directly into my TV with the RCA cables and the quality was excellent. Now the question is how do I get that good quality onto digital? I'm thinking the issue is that the quality is getting messed up going through the conversion device but when its directly on the tv its fine. \n I'm thinking I need to find a dvd recording device to convert the tapes to dvd and then to digital? Want to get some help on if that's the right thinking and right next step?\n    submitted by    /u/Business-Homework-14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwquk5/converting_hi8_tapes_to_digital_having_a_problem/",
          "publishedOn": "2022-12-27T21:32:30.000Z",
          "wordCount": 17339,
          "title": "Converting Hi8 tapes to Digital (having a problem) I'm an amateur.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwqlgp/for_zfs_ibm_m1015_card_what_is_the_difference/",
          "author": null,
          "description": "I'm provisioning a new 2U Xeon server with 3x 4TB SAS 6gb disks. Following advice, I'm running these disks off an IBM M1015 card. I haven't yet cross-flashed the card to run LSI9211 firmware in IT-mode (again, following advice from good folks on here), and am wondering what kind of performance hit I'd take if I just left the M1015 card with stock firmware and ran the disks in \"JBOD\" mode? Has anyone tried both approaches? The disks will be doing storage for a proxmox host as RAIDZ1, so key issue for me is getting most stable ZFS performance possible.\n    submitted by    /u/Kidwellj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwqlgp/for_zfs_ibm_m1015_card_what_is_the_difference/",
          "publishedOn": "2022-12-27T21:22:16.000Z",
          "wordCount": 15648,
          "title": "(for ZFS) IBM M1015 card, what is the difference between using JBOD mode disks in stock 9220-8i firmware and... running disks in IT-mode with card cross-flashed to LSI9211-IT mode?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwqhy3/what_is_your_321_backup_solution/",
          "author": null,
          "description": "I have recently built myself a Linux NAS for centralising and storing a large amount of scattered data I had over several systems and storage mediums at home. The thing is humming along nicely and set up to serve my home, providing with 8TB ZFS backed storage which is, for now, plenty for my needs - all the initial data over the years amounts to ~3TB so I have some headroom still. This is mostly archival data - media, documents, etc. Things that I store once, I read every now and then and are never deleted. \n Now I'm turning my attention to backup solutions. I have gone through the sub's wiki on the subject (great resource) and I have a few ideas of my own for local and offsite, but I'd be interested on what your particular set up is - whether you're using ZFS send/receive and into what, online storage and how you sync your data in there, costs. Whatever's working well for you I'm interested to know about.\n Thanks all.\n    submitted by    /u/Ariquitaun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwqhy3/what_is_your_321_backup_solution/",
          "publishedOn": "2022-12-27T21:18:30.000Z",
          "wordCount": 16398,
          "title": "What is your 3-2-1 backup solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwq1fl/short_depth_2u_8_bay/",
          "author": null,
          "description": "Currently have an 8 bay QNAP desktop, but looking to switch to their 2U NAS shortdepth. \n A lot recommend self build, but I can’t find a 2U 8 bay shortdepth.\n Any recommendations?\n    submitted by    /u/CleanCup1798  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwq1fl/short_depth_2u_8_bay/",
          "publishedOn": "2022-12-27T21:00:47.000Z",
          "wordCount": 15412,
          "title": "Short depth 2U 8 bay",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwpst4/what_is_currently_the_best_value_per_tb_in_terms/",
          "author": null,
          "description": "I have an ever growing archive of photos with dozens of external disks. I was looking at Synology products but I am not sure whether I can use 20tb per slot (at reasonable cost) in a raid 5 array.. Any help would be much appreciated!\n    submitted by    /u/EriEri2020  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwpst4/what_is_currently_the_best_value_per_tb_in_terms/",
          "publishedOn": "2022-12-27T20:51:20.000Z",
          "wordCount": 15602,
          "title": "What is currently the best value per TB in terms of disks for long term storage (photos etc)? How does this change if one has to take into account a good NAS system? I am thinking of implementing a system with at least 20 tb (and potential to 50 tb) - any ideas?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwpo9s/just_got_a_new_wd_red_drive_what_now/",
          "author": null,
          "description": "Building my own NAS and I just got some WD Red pros and wanted to know what I should do prior to install? Like checking if the drive is good, etc. and what software(s) to use to do so. \n Thanks in advance!\n    submitted by    /u/Wooden-Photo-2783  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwpo9s/just_got_a_new_wd_red_drive_what_now/",
          "publishedOn": "2022-12-27T20:46:17.000Z",
          "wordCount": 15376,
          "title": "Just got a new WD Red drive, what now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwp3ol/renewed_drive_came_with_linux_installed/",
          "author": null,
          "description": "Hi all, the 14tb drive I got off amazon has a linux image and docker installed on it. I've added the crystal disk info and wanted to see what my next move should be to insure this drive is safe to use. Was planning on doing a slow format and then an extended smart test. https://imgur.com/a/ww861Lt\n UPDATE: Apologies! The docker/linux image was leftover on me and I just didn't realize it. Otherwise how does the drive look on its crystal info?\n    submitted by    /u/klnadler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwp3ol/renewed_drive_came_with_linux_installed/",
          "publishedOn": "2022-12-27T20:23:03.000Z",
          "wordCount": 15407,
          "title": "Renewed Drive Came With Linux Installed",
          "imageUrl": "https://external-preview.redd.it/X_ArNN8NQj5a3rmEMOqUNfuWtPV6mobSvCnWP2ylaHU.jpg?auto=webp&s=b4a7c3ee16e5c5a42e50730ea10c9343b635c63d"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwozu7/anyone_familiar_with_everything_but_stromboli/",
          "author": null,
          "description": "Looking to purchase quite a few micro sd cards, and was looking to see if I could get a bulk discount somewhere. Found bulkmemorycards.com but I can't find anything detailing whether it's trustworthy or not. The pricing on that website seems too good to be true. Anyone have experience with it?\n    submitted by    /u/Carson740  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwozu7/anyone_familiar_with_everything_but_stromboli/",
          "publishedOn": "2022-12-27T20:18:37.000Z",
          "wordCount": 16055,
          "title": "Anyone familiar with Everything But Stromboli? (BulkMemoryCards.com)",
          "imageUrl": "https://external-preview.redd.it/GdlDRAKywzh6pS2r6HBfdtzKdY5KchXueg5ZZJ7ezWg.jpg?auto=webp&s=bcfa3cca7f6efd8ca0adc403ab70dbec37c43689"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwmko0/the_king_of_data_hoarding_needs_our_aid/",
          "author": null,
          "description": "Dead fellow hoarders,\n Our venerable king requires aid!! Will you take up arms and heed the call?\n (please consider a donation to them, i believe they are even more important than Wikipedia)\n https://archive.org/\n    submitted by    /u/Paultimate79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwmko0/the_king_of_data_hoarding_needs_our_aid/",
          "publishedOn": "2022-12-27T18:37:23.000Z",
          "wordCount": 16001,
          "title": "The King Of Data Hoarding Needs Our Aid! (https://archive.org/)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwiz0z/i_got_an_untested_lto_drive_off_ebay_and_actually/",
          "author": null,
          "description": "submitted by    /u/TechShocked  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwiz0z/i_got_an_untested_lto_drive_off_ebay_and_actually/",
          "publishedOn": "2022-12-27T16:03:28.000Z",
          "wordCount": 16504,
          "title": "I got an untested LTO drive off eBay and actually got LTFS to work on it!",
          "imageUrl": "https://preview.redd.it/udyt87yhrg8a1.jpg?auto=webp&s=1dd6f2325d40f3cc4f757f4976c49bb591315eaf"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwf25k/does_the_nas_market_really_suck_or_did_i_miss/",
          "author": null,
          "description": "Soo... For a long time I was using my pc as a data storage but recently decided that it is time to get some new fancy NAS. My requirements were quite simple (as I thought): Plug-n-play box, 4 hard drives, 2 m2 slots, and can run Plex with hardware encoding. \n After some research, I came to the conclusion that there is no simple solution for a reasonable price. \n QNAP seems to collect all security breaches in the recent two years - no, thank you.\n Asustor offers good hardware but very mediocre soft. \n Synology was the most promising among \"big players\" DS920 + looks good, but m2 can only be used for caching, fortunately, DS923+ has just been released. And it's worse than the previous model?? If I understand correctly, they made it possible to use m2 as storage but switched to Ryzen CPU without hardware encoding. Also, 1GbE ports in the 2023 model, just why? \n Other Synology models that match my simple needs are in the 1k USD range, at this point I might as well say fuck the environment and keep my PC running 24/7 \n Please, share your wisdom, what is worth buying in 2023?\n    submitted by    /u/Ok-Leopard200  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwf25k/does_the_nas_market_really_suck_or_did_i_miss/",
          "publishedOn": "2022-12-27T12:57:11.000Z",
          "wordCount": 23794,
          "title": "Does the NAS market really suck or did I miss something?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zwerl1/looking_to_backup_photos_that_are_only_stored_in/",
          "author": null,
          "description": "My dad is a hobbyist photographer for a long time and shot on film up until around 2011 so we have a load of physical photo albums, anything post 2011 was shot digitally and has been stored in my file servers. \n We have an old Epson flatbed photo scanner but the results that it gave off weren't very good and would require a load of correcting on my part. I was wondering if I should buy a top load photo scanner and be very careful with pulling the photos out of the sleeves (as the plastic has become stuck to the photos) or is there a better way of doing it (i.e. a different type of scanner or a photo scanning service that you would recommend in the UK)\n    submitted by    /u/ARandomGuy_OnTheWeb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zwerl1/looking_to_backup_photos_that_are_only_stored_in/",
          "publishedOn": "2022-12-27T12:40:24.000Z",
          "wordCount": 18147,
          "title": "Looking to backup photos that are only stored in photo albums but they've been there for so long that the plastic of the albums have become stuck to the photos. How should I scan them or should I give it to a professional to scan them? (UK)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zw2pf6/my_porn_vault_im_prepared_for_a_zombie_apocalypse/",
          "author": null,
          "description": "submitted by    /u/EscapeStrict69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zw2pf6/my_porn_vault_im_prepared_for_a_zombie_apocalypse/",
          "publishedOn": "2022-12-27T01:20:00.000Z",
          "wordCount": 15210,
          "title": "My porn vault. i'm prepared for a zombie apocalypse.",
          "imageUrl": "https://preview.redd.it/7i9nt2jfdc8a1.png?blur=40&format=pjpg&auto=webp&s=ff56672e18bf29c8a28105799e8ad8e9c10816b8"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zw1988/any_of_you_managed_to_disable_the_aggressive/",
          "author": null,
          "description": "https://m.media-amazon.com/images/I/41fJs1xw6bL._AC_SL1080_.jpg\n The constant spin up causes serious performance issues when trying to work from it.\n It does not respect Windows power plan, 'Allow the computer to turn off this device to save power' in Device Manager is disabled by default and the WD Elements is not supported by the WD utility.\n To keep it awake I resorted to using a script to touch an empty file every 20 seconds. But this workaround is a bit hacky, not to mention it is still a problem when using the drive somewhere else.\n Is there any hope to disabling the aggressive hardware sleep on this thing?\n    submitted by    /u/CripplingPoison  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zw1988/any_of_you_managed_to_disable_the_aggressive/",
          "publishedOn": "2022-12-27T00:14:11.000Z",
          "wordCount": 16102,
          "title": "Any of you managed to disable the aggressive hardware sleep of the WD Elements?",
          "imageUrl": "https://external-preview.redd.it/ztIZjCHZODzyhcRwcc0htzXXCeyjgfujkxuw0A8Ulj4.jpg?auto=webp&s=12174fdafcc51262097a1c742c20a4e68058e6cb"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvzpsd/bluray_drive_wh14ns40_external_not_working_and/",
          "author": null,
          "description": "I've been ripping CDs and DVDs for awhile using cheap external drives because they were cheap and were portable.\n Now I bought the WM14NS40 with the UGreen 12v Sata to USB 3 adapter. Reviews from Amazon says it should work but its Amazon. I also 3D Printed a case in PETG.\n ​\n Issues I've been having:\n Drive not showing up at all,\n Drive showing up but crashing the file explorer which then makes Windows completely unstable until reboot,\n Drive working and plays 2 seconds of a CD and unable to play Blu-rays.\n ​\n I've downloaded the latest firmware from LG but it was already at the latest.\n In Device Manager it says it using the driver cdrom.sys Version 10.0.19041.1266.\n I done some search of people having the same issues but they never say what IS the problem.\n Now I'm just hoping you guys will know anything about this to point me to another subreddit that may know.\n    submitted by    /u/DallenDestroyer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvzpsd/bluray_drive_wh14ns40_external_not_working_and/",
          "publishedOn": "2022-12-26T23:06:40.000Z",
          "wordCount": 15571,
          "title": "Blu-Ray Drive WH14NS40 (External) Not working and crashing explorer/computer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvyhao/looking_to_upgrade_advice_would_be_appreciated/",
          "author": null,
          "description": "I started data hoarding in 05. My collection mostly exists on external tape drives and other bulk storage solutions. In total I think I have some 50 tb of stuff. Photos, videos, games, music, shows, Wikipedia other sites I deem valuable tools. However I am wanting to upgrade to something more modern. \n I am considering making a new Nas borderline just a server. Because I want to segment it with a few vm's to hoast things like websites and email etc but I am unsure what to use (hardware) to meet these desired goals. I would like to use plex with it for my media locally but im not seeing a solution with a high core/thread count and it being viable with plex. I only need plex to stream steadily at 1080p ideally but 720 will do. Any suggestions to look at would be great.\n    submitted by    /u/earthly_leopard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvyhao/looking_to_upgrade_advice_would_be_appreciated/",
          "publishedOn": "2022-12-26T22:13:41.000Z",
          "wordCount": 16777,
          "title": "Looking to upgrade. Advice would be appreciated",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvxrx6/i_bought_one_of_those_109_12tb_mdd_drives/",
          "author": null,
          "description": "If you've been to diskprices.com recently, chances are you've noticed these 12TB drives by MDD or MaxDigitalData for $109. \n They are sold with a 3-year warranty from MD TECH INC. They do not appear to have a website, however their support email \"cs@mdtechusa.com\" appears to be valid and uses Microsoft Outlook for their MX servers. \n diskprices is labeling these drives as \"new.\" I'm not sure why, because the amazon page makes no such claims. While they don't explicitly state that their drives are refurbished, the fact that they don't call them new should give credit to the claims that they are refurbished drives. \n I decided to buy one, because my data is unimportant and easily replaceable. \n The drive came in a box, which was inside an amazon bag. Inside of the box, the only protection for the drive are two thin HDPE plastic molding on either end of the drive. Pic 1, Pic 2 Edit: The drive was in an anti-static bag.\n Here is the smart data for the drive, with 10 Decimal values.\n Here is a benchmark of the drive.\n Let me know if there's any other information you'd like about the drive and i'll do my best to provide it.\n    submitted by    /u/KloudAlpha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvxrx6/i_bought_one_of_those_109_12tb_mdd_drives/",
          "publishedOn": "2022-12-26T21:43:48.000Z",
          "wordCount": 16368,
          "title": "I bought one of those $109 12TB MDD drives",
          "imageUrl": "https://external-preview.redd.it/-X9p-ny6m6ni5bLUGApB7_wFWHoNqhrHspGahEg78fM.png?auto=webp&s=629c419d4336dac41db0a226d50d999dc06d63cc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvx8ry/diy_nas_help_me_pick_an_os_openmediavault_vs/",
          "author": null,
          "description": "Hi guys,\n I'm still running my first NAS built in 2008 which at the time was built off Windows Home Server. Over time as that no longer became supported, I upgraded to Windows 10 using Storage Spaces as an easy to use redundancy option for my drives. I backup my NAS every few months to an offline external drive and this strategy has worked well over the years. I've barely had to touch my NAS for many years.\n I'm slowly trying to ween myself off the comfort of a Windows based NAS, and have been playing with the Linux options. Hoping to get steered in the right direction based on my requirements:\n  \nPower savings - Hard Drives. I want something that is power efficient. Outside of hardware design choices, one important item is spinning down the drives. I know this one is controversial, but my…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvx8ry/diy_nas_help_me_pick_an_os_openmediavault_vs/",
          "publishedOn": "2022-12-26T21:20:48.000Z",
          "wordCount": 17074,
          "title": "DIY NAS: Help me pick an OS? OpenMediaVault vs TrueNAS. Migrating from Windows 10",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvwubz/i_currently_have_2_4tb_drives_as_a_zfs_mirror_and/",
          "author": null,
          "description": "Hi!\n So, currently I have 2x4TB on a mirrored ZFS pool but I need more space. I'm just not sure where to go from here. I could get another 4TB drive and go for raidz1 but is that a good idea? Should I just get two and mirror it? Or is raidz1 enough with a good backup? I currently only backup super important data encrypted to cloud storage (Hetzner Storage Box) but haven't thought about a good backup for all the data. raidz1 doesn't seem to have a good reputation but I'm not sure how warranted that is for data that is mostly blurays where I have the physical disk anyway.\n So, do I get 1 extra disk for ~7TB storage and one disk for parity and a large external drive for nightly backups? Do I get two for stripped and mirrored? I'm not really sure...\n BTW the two disks I have are SRM. I read about the SRM/CRM WD Red thing too late. The new disk(s) would be CRM. There have not been any issues writing data yet. So I thought about just replacing the two SRM drives with 2 8TB crm drives but that seems like a dumb financial decision...\n    submitted by    /u/Asyx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvwubz/i_currently_have_2_4tb_drives_as_a_zfs_mirror_and/",
          "publishedOn": "2022-12-26T21:03:25.000Z",
          "wordCount": 16661,
          "title": "I currently have 2 4TB drives as a ZFS mirror and don't know how to upgrade.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvwn2s/i_recently_downloaded_a_complete_n64_rom_set_with/",
          "author": null,
          "description": "submitted by    /u/EonikAnimation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvwn2s/i_recently_downloaded_a_complete_n64_rom_set_with/",
          "publishedOn": "2022-12-26T20:54:43.000Z",
          "wordCount": 17376,
          "title": "I recently downloaded a complete n64 rom set with all regions and some betas and prototypes, surprisingly it's only 17.9GB.",
          "imageUrl": "https://preview.redd.it/bwnpibgt2b8a1.png?auto=webp&s=e2f3cb39d5ea4008fdebd4b1835c3b5087fb6c98"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvvixm/confused_with_wd_red_pro_health_status/",
          "author": null,
          "description": "Hi All,\n I have been noticing some issues with my plex server and decided to run some tests on all my equipment. I was checking the status of my HDD, and I first used Crystal disk info, which gave me a caution message, I then downloaded the Western Digital Dashboard, and it says it's healthy, I then ran an extensive 6+ hour smart test, and no errors came up. This left me needing clarification and guidance and wondering what program to trust. I later found out about HD Tune and tried that, and it matches what Crystal Disk stated. Is it safe to say I have a dying HDD? It is still under warranty, so I am considering claiming an RMA and shipping it out. What do you all think I should do?\n ​\n This is the health status from the Western Digital Dashboard\n ​\n ​\n https://preview.redd.it/2nfepqlsta8a1.png?width=684&format=png&auto=webp&s=081c996233450d0a9d8ef951373ee11d769ab72f\n ​\n https://preview.redd.it/13g2elotta8a1.png?width=676&format=png&auto=webp&s=0af2e0783ffaa46be6592d46c2ce29a244c548e5\n    submitted by    /u/Kaikaze  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvvixm/confused_with_wd_red_pro_health_status/",
          "publishedOn": "2022-12-26T20:05:01.000Z",
          "wordCount": 16637,
          "title": "Confused with WD Red Pro Health Status",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvuuqz/how_do_i_archive_my_steam_replay_long_dynamic_web/",
          "author": null,
          "description": "If you didn't see it, Steam has a big page where you can see all sorts of interesting stats of your Steam usage, here it is: https://store.steampowered.com/replay/\n I really like this idea and execution of it but I don't expect it will stay up until the 2023 replay..\n They give you some nice sharable images but how do I archive the entire page? I tried the \"save page as\" in Firefox and it gave me a pretty small html file that doesn't seem to display correctly.\n So what is the best way for me to save this big long dynamic web page?\n    submitted by    /u/Forcen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvuuqz/how_do_i_archive_my_steam_replay_long_dynamic_web/",
          "publishedOn": "2022-12-26T19:34:45.000Z",
          "wordCount": 17817,
          "title": "How do I archive my Steam Replay? (long dynamic web page)",
          "imageUrl": "https://external-preview.redd.it/tlZpQmD0sNgwFIBJzJnqTtFTJ_c0EXCXfHf3LxCXfDA.jpg?auto=webp&s=40baf9c430dfff83c736098fbfb186ca49e9973b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvu0k8/quick_question_about_music_for_phone/",
          "author": null,
          "description": "hi,\n i'm currently copying my music into flacs on foobar2k (i somehow dont get EAC, and accuterip is available for my drive on foobar); anyway i'm also converting my music to opus files for my phone, as it's supported by vlc i use to play them- anyway, what are the settings you guys use? something that does save space on sdcard yet it does sound good. or should i not bother with opus and use aac (although i do prefer open standards)?\n    submitted by    /u/ViolatorOfVirgins  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvu0k8/quick_question_about_music_for_phone/",
          "publishedOn": "2022-12-26T18:57:40.000Z",
          "wordCount": 15209,
          "title": "quick question about music for phone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvttwq/free_and_open_source_or_not_backup_software_with/",
          "author": null,
          "description": "I've been looking into several options to backup my data instead of using regular Windows copy such as robocopy or software like freefilesync but neither seems to support actual file integrity verification during or after copying (ideally both since then I can run a new backup and have it verify on fly and next time I can verify if any files became mismatched) with MD5 hashes, robocopy seems to only do copy since it's a simple utility in Windows and FreeFileSync compares files between source and target based on size and timestamp which is not good enough as it could allow file to become corrupted and not detected since timestamp and size would not change.\n The software must also have the option to backup both entire drives, large folder trees regardless of how many foldes and files are ini…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvttwq/free_and_open_source_or_not_backup_software_with/",
          "publishedOn": "2022-12-26T18:49:36.000Z",
          "wordCount": 16093,
          "title": "Free and open source (or not) backup software with file integrity verification. GUI optional",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvt3k3/supermicro_jbod_storage_45x_hotswap_35/",
          "author": null,
          "description": "I'm going to buy this jbod: Supermicro JBOD Storage 19\" 4U 45x HotSwap 3,5\" LFF 6G SAS S-ATA 847E16-RJBOD1 2x 1400W PSU 4x SAS SFF-8088.\n I need to know if 6gb connections will be enough for 45x 20tb hdd. I understand that back plane have 2 port in 2 port out.\n ​\n https://preview.redd.it/q2i596hmaa8a1.png?width=729&format=png&auto=webp&s=04227b3d68994bebb8de7b99b89e51dee39cd08d\n    submitted by    /u/Reddolo80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvt3k3/supermicro_jbod_storage_45x_hotswap_35/",
          "publishedOn": "2022-12-26T18:17:06.000Z",
          "wordCount": 16189,
          "title": "Supermicro JBOD Storage 45x HotSwap 3,5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvszdk/16tb_sheduled_cloning/",
          "author": null,
          "description": "henlo, noob questions : \n a 16TB HDD for Data Storage + a 2nd 16TB as a 1:1 clone \n Cloning shedule HDD -> HDD every Week \n + using a 1TB HDD with daily filtered Backup to store only new Data that is not yet on the Clone HDD\n Should the 16TB break one day , I will pop in the cloned 16TB + Merge data from the 1TB HDD \n any pitfalls ? benefit would be reduced wear of clone drive ...\n    submitted by    /u/VikBTC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvszdk/16tb_sheduled_cloning/",
          "publishedOn": "2022-12-26T18:12:07.000Z",
          "wordCount": 15497,
          "title": "16TB + sheduled Cloning ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvs8hz/local_backup_done_via_single_diskexternal_usb/",
          "author": null,
          "description": "I've been doing some reading on this subreddit and a couple other subreddits trying to iron out my data/backup solutions for the new year. I found a few trails of thinking that backing up to a single disk, primarily an external is nearly, or if not worse, than not at all. This is stemmed from the idea of data corruption, mainly, by not having a filesystem like ZFS or BTRFS with checksumming in an array to fix bitrot, coupled with potential problems with USB devices. \n While I'm sure there may be more wiggle room, and it probably is fine to have a couple extra backup drives (cold storage etc) as single disk/USB, but if you're main backup device is USB, it does start to make sense. \n For instance, I've got a Synology 1621+ with 4 disks in an SHR1 array, with BTRFS and checksumming, cool. That device is used as my centralized datastore, so I should back it up locally, at least the data that I care about losing. I would need, at least, another two disks to have an array with parity and a checksumming filesystem for this to be a valid local backup (not just cold storage, but automated local backup). This doesn't take into account the offsite backup. \n It also brings up another topic for me is cloud solutions, and maybe leaning on them a bit more due to the natural resiliency and such to make sure bitrot doesn't occur. This could be fed back into my local solution, and then backed up offsite to a more archival solution. \n Does anyone have any insight or suggestions for this so I can actually start making headway?\n    submitted by    /u/StrongCommission  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvs8hz/local_backup_done_via_single_diskexternal_usb/",
          "publishedOn": "2022-12-26T17:39:09.000Z",
          "wordCount": 18288,
          "title": "Local Backup done via single disk/external USB useless?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvrwl9/looking_for_some_deals_on_external_hard_drives_at/",
          "author": null,
          "description": "I missed out on that 14TB WD for $200 a while back that I saw on here and now kicking myself for it bc one of my drives just corrupted. I'm looking for any deals on any external drives (that ship to the USA) no matter the size as long as the price is reasonable. Please let me know if you find anything. Thanks guys!\n    submitted by    /u/4LTERED_5TATES  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvrwl9/looking_for_some_deals_on_external_hard_drives_at/",
          "publishedOn": "2022-12-26T17:24:01.000Z",
          "wordCount": 14971,
          "title": "Looking for some deals on External Hard Drives at the moment. Any recommendations are wanted!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvrqfv/i_dont_have_enough_hard_drive_bays_so_i_decided/",
          "author": null,
          "description": "submitted by    /u/Aresius_Lowland  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvrqfv/i_dont_have_enough_hard_drive_bays_so_i_decided/",
          "publishedOn": "2022-12-26T17:16:01.000Z",
          "wordCount": 16791,
          "title": "I don't have enough hard drive bays, so I decided to do this... Wish me luck.",
          "imageUrl": "https://preview.redd.it/ilkba2tbhb8a1.jpg?auto=webp&s=36d0a5843b59fe68069a914cccd4aa2c7275bb14"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvriij/remote_access_for_files/",
          "author": null,
          "description": "I'm currently traveling for work for half a year and was wondering what the best solution would be for accessing all of the files on my desktop at home. It's not feasible for me to bring the desktop along (as much as I would like to). I would prefer to keep my 16tb of storage safe and secure at home, but be able to access them remotely. NAS isn't an option for me at the moment since Christmas gifts drained me. Would it be feasible to leave my computer running 24/7? If so, what would be the most secure/fastest option for accessing my files from my laptop? \n Thank you and happy holidays everyone!\n    submitted by    /u/charliezard7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvriij/remote_access_for_files/",
          "publishedOn": "2022-12-26T17:05:44.000Z",
          "wordCount": 17638,
          "title": "Remote Access for Files",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvqz16/20tb_wd_easystore_external_usb_30_30999/",
          "author": null,
          "description": "submitted by    /u/reallynotnick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvqz16/20tb_wd_easystore_external_usb_30_30999/",
          "publishedOn": "2022-12-26T16:40:32.000Z",
          "wordCount": 15394,
          "title": "20TB WD Easystore External USB 3.0 - $309.99",
          "imageUrl": "https://external-preview.redd.it/IVz3n6D6ghIaAsJ0KrEn1k5Ov33TnIHGYvz9evjDkZ0.jpg?auto=webp&s=8946b25f745e633b7f826eb7d667cbec37005a95"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvjdzt/hoard_your_relatives_data/",
          "author": null,
          "description": "Hi everyone, long time lurker, first time poster. Right now I am pushing to S3 all of my grandpa’s documents, he has a lot of them as he takes pictures and writes history books. I’m visiting him for the holidays and I thought it would be good to do a backup of his computer. I also thought it would be good to share this idea with you, my fellow hoarders. So do a good deed and help your family with our passion :)\n    submitted by    /u/stfn1337  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvjdzt/hoard_your_relatives_data/",
          "publishedOn": "2022-12-26T09:14:08.000Z",
          "wordCount": 17297,
          "title": "Hoard your relatives’ data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvgj74/just_got_my_first_lto_library/",
          "author": null,
          "description": "I know LTO3 is rather old at this point, but I got the library in full working condition with 50 sealed tapes for $150. I’ve never used a tape library so I figured it would be fun to learn on for the price, and maybe if I’m lucky upgrade the drive to a newer version. It’s a Tandberg Storage Magnum 2x24, holding 24 tapes for a whopping ~10TB active storage, now all it needs is a good clean. :)\n    submitted by    /u/Barentineaj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvgj74/just_got_my_first_lto_library/",
          "publishedOn": "2022-12-26T06:03:12.000Z",
          "wordCount": 17264,
          "title": "Just got my first LTO library!",
          "imageUrl": "https://preview.redd.it/j0vualca588a1.jpg?auto=webp&s=ce724aceb982f8db47ec4fe91094628d24874750"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvfiqy/just_got_my_first_nas_for_christmas_synology/",
          "author": null,
          "description": "submitted by    /u/2Michael2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvfiqy/just_got_my_first_nas_for_christmas_synology/",
          "publishedOn": "2022-12-26T05:00:57.000Z",
          "wordCount": 17902,
          "title": "Just got my first NAS for Christmas! Synology DS923+ (Ignore the temporary location)",
          "imageUrl": "https://preview.redd.it/05ae49x5u78a1.png?auto=webp&s=79f7a1b9834374a400250c584ff63eb85a7ca9d7"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zveaty/project_deluge_presenting_207_microsoft_xbox_360/",
          "author": null,
          "description": "submitted by    /u/NXGZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zveaty/project_deluge_presenting_207_microsoft_xbox_360/",
          "publishedOn": "2022-12-26T03:48:02.000Z",
          "wordCount": 16038,
          "title": "Project Deluge: presenting, 207 Microsoft Xbox 360 prototypes and 114 Nintendo Wii prototypes!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvaoz0/best_way_to_back_up_images_on_an_apple_device_to/",
          "author": null,
          "description": "First off, hi everyone. I have only today stumbled across your beautiful subreddit and have already spent hours on it. This is a Christmas gift in itself. I am absolutely going to implement this 3-2-1 storage method, but before I do:\n I have had a query (title) for years and it is getting to the stage where my devices are dying and I NEED a solution.\n I have attempted to transfer images and videos from an iPhone to a USB stick via a laptop before in the past but when transferring from an iPhone to a Windows laptop I noticed some videos/images were left out, despite me standing over the transfer for HOURS. Does anybody have a tried and trusted solution for this situation? If it works for this, it will probably work for all my other files stored locally on my laptop too.\n This will be for cold storage. I have read that HDDs perform better than USBs for this, is anybody able to verify that?\n Thank you.\n    submitted by    /u/butterman888  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvaoz0/best_way_to_back_up_images_on_an_apple_device_to/",
          "publishedOn": "2022-12-26T00:29:26.000Z",
          "wordCount": 17151,
          "title": "Best way to back up images on an Apple device to an external storage device?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv8z0s/transferring_and_backing_up_games_and_mod_folders/",
          "author": null,
          "description": "i've had my gaming laptop for a couple years now. after losing my mod folder for one of my favorite games (~16GB) last year, i began keeping a backup on my second internal ssd. i recently scored a surprisingly cheap pre-built gaming desktop and finally got around to transferring my mods over there.\n a small problem i encountered was my flash drive was slightly too small to move the now 28.6GB folder. i have a second flash drive handy so i just split the folder in half to complete the transfer. this has now lead me down a small rabbit hole of trying to find a convenient way of both keeping the folders on both PCs identical while also having a backup not connected to either. \n i have an old 120GB ssd that i think still works. in the morning i plan to run to best buy and acquire either an enclosure or a sata-usb adapter cable or dock to utilize this ssd as a short term transfer/backup drive. \n moving forward, i'd like a better setup for backing up and transferring all my game files as needed. not overly fond of using a NAS as it seems overly expensive and and honestly overkill for my use case (plus i'd rather not have to keep it powered). i'm leaning towards a few cheap SSDs, possibly setup to be exclusive to specific games or genres.\n both computers have 1.5TB of internal storage (all NVME in the laptop, 500GB NVME and 1TB HDD in the desktop) which is also a limiting factor (steam library is currently closer to 2TB, and i plan on buying a few more large games when i get paid on friday). i'd ideally like to be able to play some of the smaller, less demanding games straight off the external drives (more minecraft and goat simulator, less skyrim and GTA5). \n what do you experienced hoarders recommend?\n    submitted by    /u/moron88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv8z0s/transferring_and_backing_up_games_and_mod_folders/",
          "publishedOn": "2022-12-25T23:00:01.000Z",
          "wordCount": 17266,
          "title": "transferring and backing up games and mod folders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv8rvj/publicbookshelf_will_be_shut_down_123022_is_this/",
          "author": null,
          "description": "https://www.publicbookshelf.com/index.html\n  \nThank you for visiting our website. Due to unforeseen circumstances, our website will be shut down starting 12/30/2022. We appreciate your understanding. For any questions or concerns please reach out to us at: admin@publicbookshelf.com\n  \n   submitted by    /u/InfiniteSpaceIPH  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv8rvj/publicbookshelf_will_be_shut_down_123022_is_this/",
          "publishedOn": "2022-12-25T22:50:04.000Z",
          "wordCount": 17436,
          "title": "PublicBookshelf will be shut down 12/30/22. Is this backed up already?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv73h7/external_usb_drive_bay_vs_dedicated_nas/",
          "author": null,
          "description": "Hello all. If this isn't the right spot for this kind of post, please let me know. Also, sorry for the wall of text. Just wanted to provide some context and background for why I'm asking for help/advice. Let me know if you have any questions or want any additional info about my setup/plans. Thanks! \n  \nA week or so ago, I purchased an ORICO two bay USB 3 external HDD enclosure to house two 8TB WD Red Plus NAS hard drives. I had the drive bay connected to my HP ProDesk 600 G2, and then setup as a RAID 0 array via mdadm. That idea worked fine, and I was pretty happy with things. The ProDesk works perfectly fine for what I want out of a little home server, and I figured connecting some HD's via an external drive bay and creating my own little NAS storage setup would be more interesting and co…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv73h7/external_usb_drive_bay_vs_dedicated_nas/",
          "publishedOn": "2022-12-25T21:26:49.000Z",
          "wordCount": 19205,
          "title": "External USB drive bay vs dedicated NAS suggestions",
          "imageUrl": "https://external-preview.redd.it/jBMt1mKrvAFA0Dfg7IoywvZBJ8rD2ziTvxQevC7g2Jg.jpg?auto=webp&s=00660dbb479c6b72a33dfa36714a50932f8e0913"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv6z8u/whats_the_state_of_usbs_now/",
          "author": null,
          "description": "It seems like USB's are much cheaper than 10 or so years ago which is awesome, $10 for a 64gb on Amazon. I currently have one 32gb USB and for backing up the essentials, it's running low on space.\n I'm hoping to buy on Amazon, probably just 32 or 64 gb. Is there anything I should pay attention to for looking for a new USB? Any types that are maybe a bit faster and reliable without being too expensive?\n    submitted by    /u/viber34  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv6z8u/whats_the_state_of_usbs_now/",
          "publishedOn": "2022-12-25T21:20:51.000Z",
          "wordCount": 16783,
          "title": "What's the state of USBs now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv60ga/looking_for_an_archive_of_the_song_petey_pablo/",
          "author": null,
          "description": "This song is from an album called \" Spike TV Best Of Video Game Music Hits Vol. 1 \" which I can only find on archive.org. However, the full .flac and .mp3 files there are restricted and even after logging in I cannot download them. The only versions I can find online are in very low, compressed quality as they are ripped from a game Need For Speed Underground.\n If anyone has this CD or song in good quality (320 kbp/s mp3 or FLAC) then please send it to me.\n    submitted by    /u/GDShadept  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv60ga/looking_for_an_archive_of_the_song_petey_pablo/",
          "publishedOn": "2022-12-25T20:32:07.000Z",
          "wordCount": 17044,
          "title": "Looking for an archive of the song Petey Pablo – Need For Speed in good quality.",
          "imageUrl": "https://external-preview.redd.it/213OeAYZNyKDf1Co1GVsS8Qr9wrMV8f2HAXfli2Vi-o.jpg?auto=webp&s=f5ee83954be078bff4294f3746c7cb1c2c6feb31"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv5yk3/2x_16tb_segate_exos_489_1530tb/",
          "author": null,
          "description": "submitted by    /u/19wolf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv5yk3/2x_16tb_segate_exos_489_1530tb/",
          "publishedOn": "2022-12-25T20:29:38.000Z",
          "wordCount": 17033,
          "title": "2x 16TB Segate EXOs - $489 ~~ $15.30/TB",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv4u03/what_is_the_best_cloud_based_storageencryption/",
          "author": null,
          "description": "Good afternoon, I've been reading a lot of posts here and want to keep to the 3-2-1 rule, especially as I've had a recent scare trying to hunt down data that was stored on an account that was deleted a while ago. I have 2 forms of local storage (my 1TB Windows 10 laptop and 2TB external WD easy store drive) but am now trying to figure out a good cloud solution.\n I don't have a clear estimate on how much I plan to store online, but I think around 40 GB or more might be a good approximate. I do care about my privacy though, and understand that no cloud based storage can offer me true privacy so I would need to encrypt my files before uploading. I've heard of mega.io , google drive, and tarsnap. I'd like to stay away from drive for obvious reasons.\n My question is, what is a good cloud based service for the (relatively) small amount of data I want to back up that gives me options if I want to scale up in the future, and what encryption programs should I download to encrypt my files before I upload them. Thank you.\n    submitted by    /u/FullAd419  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv4u03/what_is_the_best_cloud_based_storageencryption/",
          "publishedOn": "2022-12-25T19:32:14.000Z",
          "wordCount": 18589,
          "title": "What is the best cloud based storage/encryption for privacy for around 40+ GB of data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv49qy/is_it_worth_to_convert_2tb_data_from_zip_to_7z/",
          "author": null,
          "description": "I have about 400 zips in varying sizes (100MB-100GB) laying on a drive in .zip format.\n I heard 7zip format is much better than zip regarding performance, efficiency and so on.\n So my Quesiton is: Do you think it is worth converting them all to .7z?\n EDIT: I should mention the zips are zipped by the linux-default \"zip\" command and i would use -mx=9 compression on 7zip when recompressing the files.\n    submitted by    /u/Alfagun74  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv49qy/is_it_worth_to_convert_2tb_data_from_zip_to_7z/",
          "publishedOn": "2022-12-25T19:04:29.000Z",
          "wordCount": 16921,
          "title": "Is it worth to convert 2TB data from .zip to .7z?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv40ac/data_hoarding_4tb_drives_at_a_time/",
          "author": null,
          "description": "So I don't really have a NAS Setup, just don't have the funds or knowledge to set it up or the space to really keep anything on my desks and don't want it on the floor.... and don't want to risk losing my data. Eventually when I have more time I Will look into it more and when I have the funds I will try and build something. \n Right Now, I have 2 nas servers in my current PC which I download and organize all my media and when I am done, and have everything set up right, I use my old laptop with 2 docks plugged in with 4 drives. I sync everything over from my internal 4tb to a docked 4tb drive so its one right and one read when transfering the data over. and I just leave it on the dock on my laptop for my Plex server... \n I keep the nas servers internal both are 4tb RED Nas WD drives.. when…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv40ac/data_hoarding_4tb_drives_at_a_time/",
          "publishedOn": "2022-12-25T18:51:15.000Z",
          "wordCount": 18743,
          "title": "Data Hoarding 4tb Drives at a Time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv3z9g/need_help_choosing_ssds_for_my_nas_upgrade/",
          "author": null,
          "description": "I was wondering if 1TB Western Digital SA510 SSD’s would work or should I spend the extra money on SSD’s that are made for NAS use (such as the WD SA500)?\n The WD SA510’s are about 45$ cheaper (here in Canada) than the WD SA500’s. Is the extra cost worth it in the long run? \n I plan to use Raid 10, starting with 6 SSD’s. My NAS has 10G networking, and is mostly used for media storage. \n Thanks in advance!\n    submitted by    /u/Blabliblou22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv3z9g/need_help_choosing_ssds_for_my_nas_upgrade/",
          "publishedOn": "2022-12-25T18:49:53.000Z",
          "wordCount": 16120,
          "title": "Need help choosing SSD’s for my NAS upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv2swv/seatools_what_is_self_test/",
          "author": null,
          "description": "I think It’s a new thing. Self Test?\n ​\n What‘s the difference between Self Test and the Generic Test?\n    submitted by    /u/mainecoon364  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv2swv/seatools_what_is_self_test/",
          "publishedOn": "2022-12-25T17:49:25.000Z",
          "wordCount": 15085,
          "title": "SeaTools - What Is Self Test?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv2nij/whats_the_best_way_to_transfer_my_files_to/",
          "author": null,
          "description": "I just got a new laptop and I plan to move all of my files and apps from my old laptop to the new one\n    submitted by    /u/FlareTDS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv2nij/whats_the_best_way_to_transfer_my_files_to/",
          "publishedOn": "2022-12-25T17:41:33.000Z",
          "wordCount": 16200,
          "title": "What's the best way to transfer my files to another laptop?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv1nte/mdisc_is_really_underrated/",
          "author": null,
          "description": "I'm in my mid 30's so I had my fair share of dealing with CD's back in the day. But In my mind optical media seemed to have become a completely obsolete technology by now. So I was surprised to learn about M-disc when a someone on this sub brought it to my attention as a means to archive data. \n And it turns out that it's the only way to archive data in a way that's legitimately durable long term and immune to bitrot. The second best would be LTO Tape drives. But the drives are really expensive and then the tech is still inherently not immune to bit rot, just less so that hhd and ssd and has a shelf life of about 30 years compared to the 1000 of M-Disc. \n So M-Disc is for anyone that wants to archive data in the most straight forward way. As in put you data on some medium that you can store away and know for a fact that some process of degradation wont be destroying it. No other storage medium can make a claim that comes even close to M-Discs durability and projected life expectancy. M-Disc literally engraves on a rock like layer so not that different from the Assyrian clay tablets that we still have from over 1000 years ago.\n    submitted by    /u/x0y0z0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv1nte/mdisc_is_really_underrated/",
          "publishedOn": "2022-12-25T16:51:03.000Z",
          "wordCount": 21981,
          "title": "M-Disc is really underrated.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv1htu/how_to_auto_organize_and_keep_track_of_movies_and/",
          "author": null,
          "description": "I have a new collection ~2TB but I just got ahold of a 24TB NAS (TrueNAS Scale) and I want to expand my collection and I want to know if there is some software which will re organize my file structure (optional) write all the missing metadata and have some portal where I can look over what I have. Thanks!\n    submitted by    /u/Humehaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv1htu/how_to_auto_organize_and_keep_track_of_movies_and/",
          "publishedOn": "2022-12-25T16:42:06.000Z",
          "wordCount": 16595,
          "title": "How to auto organize and keep track of Movies and TV Shows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv1dua/spinup_time_of_brand_new_hc560_on_desktop/",
          "author": null,
          "description": "Got it brand new, installed properly into bay, initialized in disk management then did a quick format. Then check the status on crystal disk info and all was ok. But every time i shut the pc down and power it up again, i see the spinup time going lower. It started on 100, then it goes down by 2 every time. Finally ended up on 84 and the worst is 84 as well.\n I know what spinup time is but why does it keep on going down? I havent even begun to populate it with data.\n    submitted by    /u/Adventurous_Wind2947  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv1dua/spinup_time_of_brand_new_hc560_on_desktop/",
          "publishedOn": "2022-12-25T16:36:10.000Z",
          "wordCount": 16870,
          "title": "spinup time of brand new HC560 on desktop",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuyyyq/14tb_wd_red_plus_cheaper_than_easystore_right_now/",
          "author": null,
          "description": "submitted by    /u/NickLandis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuyyyq/14tb_wd_red_plus_cheaper_than_easystore_right_now/",
          "publishedOn": "2022-12-25T14:20:42.000Z",
          "wordCount": 17046,
          "title": "14TB WD Red Plus cheaper than EasyStore right now: $224.20",
          "imageUrl": "https://external-preview.redd.it/BlvhQdD1xp9qH3AsKthtbIoYhUc5KdbVp44hI9MsY9g.jpg?auto=webp&s=d97691cea494165813a7ac066a7ac67107e35054"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuukia/is_there_an_usb_type_c_powered_35_enclosure/",
          "author": null,
          "description": "Merry Christmas everyone! \n I’ve done some search, but the question and answers are generally a few years old. With Type C being so much more common these days, are there now 3.5” enclosures that are powered via USB C? I’m not keen to have to use a dedicated power adapter.\n    submitted by    /u/baineteo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuukia/is_there_an_usb_type_c_powered_35_enclosure/",
          "publishedOn": "2022-12-25T09:09:52.000Z",
          "wordCount": 15971,
          "title": "Is there an USB Type C powered 3.5” Enclosure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zus9i9/how_does_terabox_provide_1_tb_free_space_for_each/",
          "author": null,
          "description": "I've been looking for a place to stash my hoarded shit and I found Terabox. It looks so unusually good that it's suspicious. What's the catch ? \n For my purpose, I don't really need privacy or security or something. None of what I want to hoard can be considered sensitive/personal content. Is Terabox (free version) a good solution for that ?\n    submitted by    /u/Sadman_Pranto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zus9i9/how_does_terabox_provide_1_tb_free_space_for_each/",
          "publishedOn": "2022-12-25T06:21:34.000Z",
          "wordCount": 16862,
          "title": "How does Terabox provide 1 TB free space for each account when none of their competitors get even close ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zus8tv/randomly_stumbled_upon_this_video_this_evening/",
          "author": null,
          "description": "The whole video is worth watching, but the link starts at the SMR vs CMR chapter.\n https://youtu.be/wtdnatmVdIg?t=733\n    submitted by    /u/wh33t  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zus8tv/randomly_stumbled_upon_this_video_this_evening/",
          "publishedOn": "2022-12-25T06:20:17.000Z",
          "wordCount": 16730,
          "title": "Randomly stumbled upon this video this evening. Thought it was really well done and I love how it finally explained the difference between SMR and CMR to me in a way that makes sense. I wanted to share!",
          "imageUrl": "https://external-preview.redd.it/KPkqWElnz5FD35c5IkEXydsH9DLINcdKie7HqT-JDkI.jpg?auto=webp&s=fff5cf51b80fb6115ee1bf729f63b5535c23aa0b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuo1gz/warhammer_universe_collection_updated_december/",
          "author": null,
          "description": "Welcome to the Warhammer Collection,\n this is the seventh update (December 2022) we're doing on the WH lore and thanks to the feedback received we managed to archive:\n - an improved sorting\n - added new released books\n - replaced/deleted many non-retail\n ALL the books have been renamed with Author's Name Surname - Book title (Series) for an easy search.\n The retail tag means how the book was ripped\n [Retail] - Books that i have bought myself and i have removed the DRM thru calibre\n (Retail) - Books shared by other users whom DRM has been remove correctly thru calibre\n (retail) - Books shared by other users who purchased the books but not drm'ed correctly with calibre\n With this I'm hoping to give the reader a complete collection of WH books in their best available format and somehow well sorted.\n If you enjoyed this and found some issues such as typos, bad scans/conversions, misplaced books and pretty much anything please send me a message.\n Lastly a huge thanks goes to all the people that helped out with this project. Thank you!\n Torrent\n magnet:?xt=urn:btih:ce271c2c106af88f97f7dc2b875f5667131fd5f0\n MEGA\n Will upload an updated link in few days \n ​\n PS: i obviously forgot to add the last short while making the torrent,\n Jude Reid - The Shel'tain Affair (Amendera Kendel) [Retail]\n    submitted by    /u/RedHeadedKhajiit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuo1gz/warhammer_universe_collection_updated_december/",
          "publishedOn": "2022-12-25T01:51:33.000Z",
          "wordCount": 15609,
          "title": "Warhammer Universe Collection [Updated December 2022]",
          "imageUrl": "https://external-preview.redd.it/6g1jVIXhQQNfQR-lwUCo-vxWtwHlKYpV-zg897aZ3yA.jpg?auto=webp&s=0031e2ecd0934f69ff1bc1629201507017ff3448"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuniqw/bibliotheca_alexandrina_a_600_gb_hoard_of_history/",
          "author": null,
          "description": "link to the previous post to make some light on the project \n 2021 Update \n Bibliotheca Alexandrina - 602 GB\n magnet:?xt=urn:btih:5b407389216bb686e7d2f7ecf8aeb1e960f53154 \n Variorum Collected Studies - 116 GB\n magnet:?xt=urn:btih:f9f10ded2a254eacfefa4deeef040d8aa56ed18b \n The series is published by Ashgate and since it was established in 1970, over 1000 volumes have been produced. https://en.wikipedia.org/wiki/Variorum_Collected_Studies \n FAQ\n what's included in these 600GB?\n Classical and medieval academic books, something early modern (1600s), some archeology/prehistory \n what's the difference between this collection and libgen/zlibrary/archive/..?\n quality of the books. Many of my books are tagged as retail, i can vouch for each of them \n why zipped folders?\n all the folders have been z…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuniqw/bibliotheca_alexandrina_a_600_gb_hoard_of_history/",
          "publishedOn": "2022-12-25T01:19:58.000Z",
          "wordCount": 16847,
          "title": "Bibliotheca Alexandrina - a 600 GB+ hoard of history books [December 2022]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zum7je/why_is_my_external_hdd_so_slow/",
          "author": null,
          "description": "I have an external HDD 3.0. When I copy files from the HDD to the PC (NVMe) the speed is 38MB/s. Is it normal? \n And if I copy from PC to HDD, the speed is 130MB/s but after 2 seconds drop down to 34MB/s.\n I searched the internet but nothing seems to improve speed.\n    submitted by    /u/ALE2000XVX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zum7je/why_is_my_external_hdd_so_slow/",
          "publishedOn": "2022-12-25T00:04:14.000Z",
          "wordCount": 16229,
          "title": "Why is my external HDD so slow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zum47k/does_converting_lossy_audio_to_flac_stop/",
          "author": null,
          "description": "I found a bunch of .amr files in one of my archives of past voice mails. After doing some copying and replacing I learned they are a lossy file type. I couldn't find any documentation on .amr files specifically, but I assume they suffer generation loss the same way .mp3s do.\n I know that you can't increase quality by converting a lossy file to a lossless file, but can you prevent it from losing any more quality? These are sentimental files and I'm wondering if they'd be better preserved as .flacs\n    submitted by    /u/fishswimminginatank  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zum47k/does_converting_lossy_audio_to_flac_stop/",
          "publishedOn": "2022-12-24T23:59:41.000Z",
          "wordCount": 15785,
          "title": "Does converting lossy audio to .flac stop generation loss, and quality degradation over time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zulp5s/datahoaders_i_need_help_preserving_about_5tb_of/",
          "author": null,
          "description": "https://www.reddit.com/r/DataHoarder/comments/a6ah2q/so_we_spent_175_usd_to_purchase_a_5tb_drive/\n It's been four years since I made this post, where I acquired a drive holding a 2014 dump of animemusicvdieos.org including an export of it's database. I'm gonna be honest here... It's collected dust since. I've made a few attempts to upload it to Archive.org via FTP but I just get errors. Tried different PCs and FTP clients, I start getting hung transfers and it all goes to hell. This is a huge amount of data so it's not like I can just toss it on Gdrive.\n So I'm looking for other people who can help. People I can send this data too and hopefully they can upload to archive.org and share by other means if they want. This drive won't function forever, I really need to get around to duplicating it's contents and propagating it across the internet and into other individual's collections.\n Ideas?\n    submitted by    /u/AshleyUncia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zulp5s/datahoaders_i_need_help_preserving_about_5tb_of/",
          "publishedOn": "2022-12-24T23:36:31.000Z",
          "wordCount": 15810,
          "title": "Datahoaders, I need help preserving about 5TB of Anime Music Videos and a database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zukpxk/whats_the_rarest_piece_of_data_you_have_preserved/",
          "author": null,
          "description": "Anyone have any stories of lost media or cool pieces of your data stores?\n    submitted by    /u/Dirtrubber  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zukpxk/whats_the_rarest_piece_of_data_you_have_preserved/",
          "publishedOn": "2022-12-24T22:44:49.000Z",
          "wordCount": 16281,
          "title": "What’s the rarest piece of data you have preserved?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zukb60/how_a_coverless_drives_looks_in_operation/",
          "author": null,
          "description": "submitted by    /u/1DonBot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zukb60/how_a_coverless_drives_looks_in_operation/",
          "publishedOn": "2022-12-24T22:23:21.000Z",
          "wordCount": 16256,
          "title": "How a coverless drives looks in operation (surrounded by +180TB drives)",
          "imageUrl": "https://external-preview.redd.it/4-AnQuoO7qlpSyCMx7GRdx_Jbp5J4xn-7U_WhOv5e_4.jpg?auto=webp&s=986731e30b99255e7fb3c0c115752787bd5fa782"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuk6kz/any_way_to_not_upload_duplicates_on_google_drive/",
          "author": null,
          "description": "So, i like to backup files very often from my computer or hard drive to google drive. It would be an absolute pain to go in to every folder and search to see which files have not been uploaded, and upload those files every time. \n I like to just go to google drive and drag all the files into a folder and let them upload. Problem is, there are many. When I do this, google never asks me if I want to replace the files or whatever. It always just reuploads the files that already exist and adds a number to the end of the name.\n Is there any way to stop this so that it does not upload file with the same name?\n    submitted by    /u/AllAboutGadgets  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuk6kz/any_way_to_not_upload_duplicates_on_google_drive/",
          "publishedOn": "2022-12-24T22:16:43.000Z",
          "wordCount": 15213,
          "title": "Any way to not upload duplicates on Google Drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zujv5t/what_systems_do_you_use_to_store_your_data/",
          "author": null,
          "description": "I am using debian+zfs+docker\n    submitted by    /u/kovach_ua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zujv5t/what_systems_do_you_use_to_store_your_data/",
          "publishedOn": "2022-12-24T22:00:32.000Z",
          "wordCount": 16100,
          "title": "What systems do you use to store your data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zufyy1/i_failed/",
          "author": null,
          "description": "Today is my first day home since thanksgiving. Sitting in the garage at my mom’s place when I walked in her garage is my Black Friday order. A 16tb western digital red. Just sitting in a static bag. She reminded me the box was wet so she opened it.\n Plug it into the computer, pull up disc management. \n And promptly formatted the wrong drive. Poof. Around 15tb of movies and tv shows.\n The only backup is a list in meta media manager of the movies. \n Plex should be able to tell me what tv shows I had.\n I should be able to recover everything, but man some of those shows/seasons were low seeded and took forever.\n The best part? The 16tb red drive won’t initialize. And I bought it from newegg.\n 🤷‍♂️ merry Christmas 🎁🎄\n    submitted by    /u/Ok-Professional3832  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zufyy1/i_failed/",
          "publishedOn": "2022-12-24T18:45:33.000Z",
          "wordCount": 16747,
          "title": "I failed.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zufhmp/how_to_archive_a_website_to_host_it/",
          "author": null,
          "description": "there's a forum that i've been a part of since 2011 and there is a high chance that the owner isn't going to continue supporting the site, is there a way to completely archive everything in the website to make it easy to launch another website without losing the content ? \n its literally the one and only active forum in my language.\n    submitted by    /u/sohailoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zufhmp/how_to_archive_a_website_to_host_it/",
          "publishedOn": "2022-12-24T18:21:53.000Z",
          "wordCount": 15732,
          "title": "how to archive a website to host it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zueequ/gallerydl_tweet_ratelimiter_breaking_program/",
          "author": null,
          "description": "While attempting to back up a bunch of twitter accounts, I noticed that for some reason the Rate-Limit Reset error that it gives after ripping a bunch of programs effectively freezes it forever. If I wait out the 15 minutes, it'll give the exact same error again. I haven't seen it get past a rate limit reset. Anyone know how to either slow it down enough that it doesn't trigger the rate limit reset, or how to make it keep ripping after the reset is over?\n    submitted by    /u/SomeHusky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zueequ/gallerydl_tweet_ratelimiter_breaking_program/",
          "publishedOn": "2022-12-24T17:28:38.000Z",
          "wordCount": 15790,
          "title": "Gallery-DL Tweet Rate-Limiter Breaking Program",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zudr4x/download_and_search_your_own_selection_of_books/",
          "author": null,
          "description": "submitted by    /u/TheoGrd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zudr4x/download_and_search_your_own_selection_of_books/",
          "publishedOn": "2022-12-24T16:56:53.000Z",
          "wordCount": 17921,
          "title": "Download and search your own selection of books from libgen with linux",
          "imageUrl": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?auto=webp&s=bfb2aa514cefbde75d81d86deb33251e320c8faa"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zudm3e/need_help_with_a_seagate_internal_hard_drive_that/",
          "author": null,
          "description": "I have a 500GB Seagate hard drive (ST500DM009) which I have bought around 2 years ago produce this sort of click in random intervals. The first time the drive clicked was when I was freshly installing windows 10 on it for the first time with the media creation tool, At first I thought nothing of it as the installation went without a hitch, However after installing a few games and playing them, The drive suddenly clicked in rapid succession which caused a BSOD, Windows 10 was able to boot again but that's where it all went downhill as the clicking never went away till to this day of me writing this, Sometimes it doesn't click for a day or two but I will ultimately reoccur again, As it clicks most of the time when the drive is in heavy use, I have originally thought that It was the hard drive's APM feature acting up that was causing this issue, That's why I followed this Youtube video guide on how to permanently disable the APM feature within the drive(https://www.youtube.com/watch?v=p4UrnP38T0w) But alas, It's all futile, As the clicking of the drive still persists, The drive is still usable and still in perfect health(surprisingly). What on earth could be causing this?\n Hard drive click audio:https://vocaroo.com/14qXHSyhIHlZ\n Hard disk sentinel status:https://imgur.com/a/QhJj9q5\n    submitted by    /u/borjie_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zudm3e/need_help_with_a_seagate_internal_hard_drive_that/",
          "publishedOn": "2022-12-24T16:49:52.000Z",
          "wordCount": 16705,
          "title": "Need help with a Seagate internal hard drive that clicks randomly then makes a sudden spin up noise",
          "imageUrl": "https://external-preview.redd.it/f42_5FnrwXjfFEh0wjuCD17TMuDKAIuPf0uEE2v7Vzc.jpg?auto=webp&s=3590cd9f797035eac6cca709c796211148eaffc7"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuc8fo/can_someone_help_this_noob/",
          "author": null,
          "description": "I have an 8tb hard drive that I got 5 years ago, but I recently heard hard drives only last 3-5 years and Google seemed to confirm it so I'm panicking on what to do. Do they really just fail over time or maybe that's just for smaller hard drives? I'm not too techy when it comes to computer parts so I don't really know these things. It's made by seagate and it's one that needs to be plugged into the wall. I'm pretty sure it's this one: Seagate Backup Plus Hub 8TB Desktop Hard Drive with Rescue Data Recovery Services https://a.co/d/9YmSkMP\n    submitted by    /u/oharacopter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuc8fo/can_someone_help_this_noob/",
          "publishedOn": "2022-12-24T15:38:55.000Z",
          "wordCount": 15728,
          "title": "Can someone help this noob?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuc0z9/google_enterprise_without_vat_id/",
          "author": null,
          "description": "So, I'm using Google Workspace Enterprise Standard now for storage, ~30TB but I will have to soon close my VAT ID and I understand it is required now. Can I make an account for it without one? Or is there anything similar I could use for a similar price point?\n Is the only solution in my future just a bunch (more) drives for local storage?\n    submitted by    /u/TehBard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuc0z9/google_enterprise_without_vat_id/",
          "publishedOn": "2022-12-24T15:28:06.000Z",
          "wordCount": 15499,
          "title": "Google Enterprise without VAT ID?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zubr9u/wd_easystore_18tb_x_4/",
          "author": null,
          "description": "My GF went to best buy and bought 4 of these for one of her clients who halted the project for their office refresh. They let her keep the external drives and asked if I wanted them. I've shucked a drive before to use in a Linux PC, any reason why these won't work in a ds920+?\n They cannot be returned as they were purchased by her client and setup for her to pickup.\n Wanted to know if anything to look out for before I tear them apart. Otherwise if there's problems I'll have her sell them or just use them as externals with a UnionFS\n    submitted by    /u/blitzblitzblutz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zubr9u/wd_easystore_18tb_x_4/",
          "publishedOn": "2022-12-24T15:14:13.000Z",
          "wordCount": 16214,
          "title": "WD Easystore 18tb x 4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuawmx/i_bought_a_external_hard_drive_but_it_made_noise/",
          "author": null,
          "description": "submitted by    /u/Elliott_The_Chicken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuawmx/i_bought_a_external_hard_drive_but_it_made_noise/",
          "publishedOn": "2022-12-24T14:28:51.000Z",
          "wordCount": 15762,
          "title": "I bought a external hard drive but it made noise so i opened it. This was loose. Does anyone know if it is important or crucial?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuaql7/lost_access_to_my_servers_files_through_smb/",
          "author": null,
          "description": "i have been using the same windows server (windows 10 pro), with the same drives for 2 years now, and SMB had been working wonderfully.A few days ago i got a new PSU, with more sata connectors, so i added 2 other HDDs to the mix, and made sure that the drive letter for the older ones didn't change.That's really the only major change that happened, besides that all i did was remove my password, so the server would login automatically, and given that i have password protected sharing turned off, it shouldn't have been a problem. Either way after ii noticed all my network drives had been disconected, both from my windows laptop, and my android phone, i tried reverting the passowrd just to be sure, but it didn't work\n https://preview.redd.it/zwsf13h4tu7a1.png?width=650&format=png&auto=webp&s=09383a95c57a8b57969bc4d96ea43efc4c45270d\n https://preview.redd.it/cqj7qua5tu7a1.png?width=745&format=png&auto=webp&s=013123aad4f5ae1590136cb4024b654fe3d37040\n Example of shared drive\n Windows Defender firewall\n All and all, i'm out of ideas,\n i should mention that if i set those same settings on my laptop, and share one of its folders, my server can easily find it in the network, and mount it with no problem, but not the other way around\n any ideas?\n given that a good chunk of the time i'm messing with files on the server, is working with video files, this is really bothersome\n (last note, that same day all of that happened, i opened the computer management app, but i changed absolutely nothing in there, i only clicked on the Users and profiles tab > Users, after that i changed absolutely nothing in said \"users\" folder) \n this will probly turn out to be revelant, so\n https://media.discordapp.net/attachments/589454320005808133/1056224734301388870/image.png\n https://cdn.discordapp.com/attachments/589454320005808133/1056225542963208293/image.png \n    submitted by    /u/peugamerflit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuaql7/lost_access_to_my_servers_files_through_smb/",
          "publishedOn": "2022-12-24T14:19:24.000Z",
          "wordCount": 16481,
          "title": "lost access to my server's files through SMB network storage, and i don't why. I'm out of ideas",
          "imageUrl": "https://external-preview.redd.it/gobaNcQvAahafY86eih0PYuVpSXb-bvGRxoWhsdPyiA.png?auto=webp&s=3fbfa4d2cb5c53ea6e464a8b421ca7572a663e6e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zu74ma/seagate_expansion_14tb_external_hard_drive_19999/",
          "author": null,
          "description": "submitted by    /u/Viknee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zu74ma/seagate_expansion_14tb_external_hard_drive_19999/",
          "publishedOn": "2022-12-24T10:22:02.000Z",
          "wordCount": 15759,
          "title": "Seagate Expansion 14TB External Hard Drive - $199.99 - $14.28/TB",
          "imageUrl": "https://external-preview.redd.it/nI-Yr1Eb668Ujra70Z2m4G-_R5DY13lMvMbeULO9VPI.jpg?auto=webp&s=689278e484ad9c4c83d4df70e18048e82725e8dc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zu3lqp/i_just_realized_i_am_the_owner_of_a/",
          "author": null,
          "description": "submitted by    /u/wyatt8750  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zu3lqp/i_just_realized_i_am_the_owner_of_a/",
          "publishedOn": "2022-12-24T06:22:37.000Z",
          "wordCount": 16611,
          "title": "I just realized I am the owner of a currently-working IBM 75GXP \"Death Star.\" (It's still Friday somewhere)",
          "imageUrl": "https://preview.redd.it/geurrufahs7a1.jpg?auto=webp&s=a790a3c9180e95f9516117e0ac84d3658d0a30e0"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zu2zng/a_massive_australian_archive_of_newspapers_and/",
          "author": null,
          "description": "submitted by    /u/King_Millez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zu2zng/a_massive_australian_archive_of_newspapers_and/",
          "publishedOn": "2022-12-24T05:45:36.000Z",
          "wordCount": 15413,
          "title": "A massive Australian archive of newspapers and documents at the National Library of Australia's funding runs out in July 2023 – and the National Library is threatening to pull the plug. Can we help?",
          "imageUrl": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?auto=webp&s=b316a8d27d8e138ab76327e2b6375a72d18fc35d"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zu0qod/how_do_you_easily_accessbrowse_and_organize/",
          "author": null,
          "description": "I have hardware infrastructure in place and have a folder structure I like. All that is fine.\n It would be cool to have an app that made it easier to search and go through content. I'd like to be able to tag similar things instead of relying only on using folders. I'm imagining something like Plex where there is a database of information and you can browse or search.\n I've heard of stash but don't have any experience with it.\n Two additional challenges:\n  \nMost of my content are videos posted online, so these aren't like official released media. There probably isn't an easy database that exists with all the info. I assume I'd have to build that db myself.\n For privacy's sake, I keep all of the data encrypted with VeraCrypt. I am not tied to this solution, but I do want to restrict access, ideally at the file storage layer (but not required). So any solution either has to work directly with some form of encrypted storage, or as part of starting up needs to be able to mount and then access storage otherwise decrypted and made available (maybe something with ZFS?). \n App ideally also requires authentication to access.\n \n  \n   submitted by    /u/DontCryForMeThrowAwa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zu0qod/how_do_you_easily_accessbrowse_and_organize/",
          "publishedOn": "2022-12-24T03:37:01.000Z",
          "wordCount": 16324,
          "title": "How do you easily access/browse and organize stored NSFW content?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztxa59/link_preservation_for_jan_6_report/",
          "author": null,
          "description": "(No political opinion expressed. Please be civil in this venue)\n I was skimming the Jan 6th House report and it concerns me how many links go to web pages. These links can rot very easily. \n Has anyone tried to archive all of the links so it may be persevered?\n    submitted by    /u/jwink3101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztxa59/link_preservation_for_jan_6_report/",
          "publishedOn": "2022-12-24T00:38:20.000Z",
          "wordCount": 16579,
          "title": "Link preservation for Jan 6 report",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztwotw/i_need_help_with_fox35_embedded_video/",
          "author": null,
          "description": "I was trying to get the video from this story: https://www.fox35orlando.com/news/ucf-professor-allegedly-dressed-up-used-accent-during-recorded-video-lessons-students-say.\n However, none of my current tools have Fox35 as a supported website, and the one that did was only allowing me to get the ads.\n Through developer tools I managed to find a link to an .amp version of the page, but I still couldn't get it: https://www.fox35orlando.com/news/ucf-professor-allegedly-dressed-up-used-accent-during-recorded-video-lessons-students-say.amp\n Are there any extentions that have Fox35 as a supported website, or some technique or tool that I'm missing.\n    submitted by    /u/aslfingerspell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztwotw/i_need_help_with_fox35_embedded_video/",
          "publishedOn": "2022-12-24T00:09:27.000Z",
          "wordCount": 17758,
          "title": "I need help with Fox35 embedded video.",
          "imageUrl": "https://external-preview.redd.it/sx47WIAJc9xaRsXlxd7BRZOguEUWWT_KQtiQ0oThR-U.jpg?auto=webp&s=0fe25eddb1f1b744386004e2b001c2f63c6bc5bc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztvxe1/lsi_92118i_vs_92078i/",
          "author": null,
          "description": "I just need more SATA ports for my desktop. I will be using just hard drives with it. Any reason I should go with a 9207 over a 9211?\n    submitted by    /u/al93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztvxe1/lsi_92118i_vs_92078i/",
          "publishedOn": "2022-12-23T23:32:55.000Z",
          "wordCount": 16110,
          "title": "LSI 9211-8i vs 9207-8i",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztudvd/rsync_speeds_around_15_to_17mbs_over_10gb_nic/",
          "author": null,
          "description": "I'm using this rsync command on my new debian/openmediavault server in order to get all data moved from the old one onto this one:\n rsync -hazP --stats -e \"ssh -T -c aes256-gcm@openssh.com -o Compression=no -x\" root@10.10.10.15:/srv/27829c9c-dbc1-4408-a111-56dbcd8f0ec0/media/ /srv/mergerfs/norman_pool2/media\n In both instances, the data is in a unionfs or mergerfs pool. 10.10.10.15 is the IP of the NIC on the source server which should make it communicate over 10Gb only since that port is plugged into the 10Gb NIC on the new server with a DAC cable. The only other interfaces are the main 1GB NICs which each have a line going to my router/switch\n The new server is intel I3 12100 with 32GB ram, the old is Dell R710 with dual xeon L5664 CPUs and 32 GB ram. They both show low CPU utilization and ram utilization during the process, but I'm not seeing more than 15MB/s on larger files, 5-10MB on smaller ones. I think the highest I've seen is 18MB/s which seems insanely slow for a direct 10Gb connection\n Is there anything I'm not thinking of, or anything the command could use to speed things up even more\n    submitted by    /u/FourTimesRadical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztudvd/rsync_speeds_around_15_to_17mbs_over_10gb_nic/",
          "publishedOn": "2022-12-23T22:22:31.000Z",
          "wordCount": 17106,
          "title": "Rsync speeds around 15 to 17MB/s over 10Gb NIC from server to server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztu194/i_have_enjoyed_being_a_statistical_anomaly_far/",
          "author": null,
          "description": "submitted by    /u/bmanalpha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztu194/i_have_enjoyed_being_a_statistical_anomaly_far/",
          "publishedOn": "2022-12-23T22:08:11.000Z",
          "wordCount": 15497,
          "title": "I have enjoyed being a statistical anomaly far too long. Good night sweet prince.",
          "imageUrl": "https://preview.redd.it/uxtjjyxlzp7a1.jpg?auto=webp&s=d197d4ef2e76dad32fa8b70cae8c651cde6a92db"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zttvkg/searching_cloudstorage_testers/",
          "author": null,
          "description": "Searching Cloudstorage Testers\n Hey Guys, might be Offtopic as f***. But hey thats reddit. As the Title is saying iam searching a few people from different Locations around the World that are willing to test a Cloud Storage Service in Terms of Upload/Download Speed / Loading Times and usability.\n Time to test 3 Months. Storagespace to test with: 50GB (able to do more) What you need to do: Just give me a quick Update on how things are working out etc every 2 weeks\n You can keep the Storage after the tests if you want Just reply in here with your Destination and imma get in Touch with you.\n Wish you some nice holidays. Also could someone please tell me what section this post would be? ;)\n    submitted by    /u/No_Dragonfruit_5882  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zttvkg/searching_cloudstorage_testers/",
          "publishedOn": "2022-12-23T22:01:25.000Z",
          "wordCount": 16097,
          "title": "Searching Cloudstorage Testers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zttt6f/seagate_x18_sale/",
          "author": null,
          "description": "submitted by    /u/Mlitz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zttt6f/seagate_x18_sale/",
          "publishedOn": "2022-12-23T21:58:52.000Z",
          "wordCount": 15326,
          "title": "Seagate X18 Sale",
          "imageUrl": "https://preview.redd.it/v2efa282hr7a1.jpg?auto=webp&s=24f742fb09d17e3624cdb0c3c7f44e834340a74e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztsaye/open_source_simple_reddit_post_downloader_that/",
          "author": null,
          "description": "submitted by    /u/turntwice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztsaye/open_source_simple_reddit_post_downloader_that/",
          "publishedOn": "2022-12-23T20:51:13.000Z",
          "wordCount": 15656,
          "title": "Open source simple Reddit post downloader that doesn't require OAUTH. Downloads all post types, converts GIFs to MP4, and enables downloading any subreddit(s) on repeat at set intervals (download new posts every minute, every hour, etc.)",
          "imageUrl": "https://external-preview.redd.it/feGsVmUB-usKVUgg0HSSGzo1Wfbq7Ys5D3f6z9hUgU4.jpg?auto=webp&s=86604eae3cadd87d8ff5ecafd3973ea88f5a4af9"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztrfcn/my_nas_is_ruined_need_help/",
          "author": null,
          "description": "I own a Terramaster f2-221. I'm the guy asking about single disk nas a few days ago.\n Yesterday night, while the nas was turned off, my electricity went away for a few minutes.\n Since this morning, my NAS doesn't work anymore. \n Using tnas the NAS results as Uninitialized, if i try to connect to it's IP via browser it shows me the setup wizard, makes me create a new account and delete all previous data. If i try to connect via file manager, internet explorer, winscp or whatever it always open the setup Wizard or it asays connection refused \n Connecting the add on pc shows several partitions, all healty, but there is no way for my pc to show the contents on the hdd, it only appears in the partition tool of windows \n I try connecting via SSH with Putty (https://forum.terra-master.com/en/viewtopic.php?f=75&t=2350), and it worked...but it said it created a new folder for my admin user (that already existed). The NAS does remember the name i've given to it tho, so i'm confused if the data is there or got partially deleted.\n Anyway, i followed this guide (https://forum.terra-master.com/en/viewtopic.php?f=79&t=2575&p=13904#p13904) but, the results were completely different: no red or any colored text, only white text that more or less looks fine from my very limited knowledge, i coulnd't spot any error message \n I literally don't know what to do apart from wiping my drive, i want to recover the data since there are still important things that i still have to back up elsewhere, and also over a terabyte of hard to find content. \n Can anyone help me?\n    submitted by    /u/TheXade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztrfcn/my_nas_is_ruined_need_help/",
          "publishedOn": "2022-12-23T20:12:01.000Z",
          "wordCount": 16974,
          "title": "My nas is ruined. Need help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztq570/archive_a_youtube_playlist_not_the_videos/",
          "author": null,
          "description": "I have a few YouTube playlists that I've built up over the last few years that I would like to archive off and delete. Some have a 100+ videos in them and it would take days to manually select the video, copy its URL and paste this and the title into a file...\n I do not want to download the videos (most are the copyright of the creators) but would like to create a file with the title, author (channel name) and URL though the channel name could be dropped.\n Searching just seems to give me lots of tool for downloading the videos themselves but not just the playlist...\n    submitted by    /u/ADB-UK  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztq570/archive_a_youtube_playlist_not_the_videos/",
          "publishedOn": "2022-12-23T19:15:38.000Z",
          "wordCount": 16218,
          "title": "Archive a YouTube playlist NOT the videos themselves",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztph8b/how_to_archive_entire_subreddit/",
          "author": null,
          "description": "So we all know that reddit lists are limited to 1000 posts at a time, but push shift archives everything so theoretically you should be able to use that website to get all post submissions from a subreddit.\n Now the real question is, how would you be able to archive an entire subreddit(including the media posted). I have seen things like telegram bots but they will only archive stuff from the date they are added, not useful at all for getting stuff that's already been posted.\n    submitted by    /u/overratedcabbage_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztph8b/how_to_archive_entire_subreddit/",
          "publishedOn": "2022-12-23T18:46:46.000Z",
          "wordCount": 15541,
          "title": "How to Archive Entire Subreddit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztpg7z/is_it_possible_to_clone_a_dying_hdd_to_a_new_one/",
          "author": null,
          "description": "This old HDD has 40k hours on it, has 100% usage all the time (slow as hell), and is \"Caution\" on CrystalDiskInfo. I wonder if it's possible (albeit slow) or the process would just kill the old HDD \n Edit: CDI data https://pastebin.com/EhatQnTS\n    submitted by    /u/lkusen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztpg7z/is_it_possible_to_clone_a_dying_hdd_to_a_new_one/",
          "publishedOn": "2022-12-23T18:45:30.000Z",
          "wordCount": 16060,
          "title": "Is it possible to clone a dying HDD to a new one using Macrium?",
          "imageUrl": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&s=07c121a0180003f7373863af66192b6ff6a937da"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztok6e/resyncing_a_single_bay_synology_nas_with_two/",
          "author": null,
          "description": "Hello,\n I reached out to Synology about this but the tech wasn’t sure how to answer it.\n I use a Synology single-bay NAS and the Cloud Sync application to mirror all of my data (one root folder with all data inside) to both Backblaze B2 and Google Drive. The syncing is up to date, so Backblaze and Google Drive have copies of every piece of data I own, and further, so does a WD 16TB external drive. The really important stuff is further backed up on my PC, laptop, bluray discs, other external drives (one being at a friend’s house), Microsoft OneDrive, and Mega.io, so I’m not concerned about data loss.\n I am wondering, though, if my Synology hard drive fails permanently, is anyone here able to outline the least time consuming workflow it would take to setup a brand new Synology NAS (or new drive in the original Synology tower) to sync up with both Backblaze B2 and Google Drive the way the original Synology drive did, so that anything I add to the root folder will continue being seamlessly backed up to both cloud services as before? Since I have the a WD external drive with the entirety of my data (same exact data as on Backblaze B2 and Google Drive), could I transfer that root folder with all of my data from the WD external to the new Synology NAS, and then can Cloud Sync compare the contents between that folder, Backblaze and Google drive and consider them to be synced up without the need for mass upload / download again?\n Thank you for your time. Please let me know if I may clarify anything I’ve outlined above.\n    submitted by    /u/Arachnatron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztok6e/resyncing_a_single_bay_synology_nas_with_two/",
          "publishedOn": "2022-12-23T18:06:36.000Z",
          "wordCount": 18131,
          "title": "Re-syncing a single bay Synology NAS with two cloud storage providers via Cloud Sync after total disc failure.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zto65b/a_true_story/",
          "author": null,
          "description": "submitted by    /u/AshleyUncia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zto65b/a_true_story/",
          "publishedOn": "2022-12-23T17:49:52.000Z",
          "wordCount": 16913,
          "title": "A True Story",
          "imageUrl": "https://preview.redd.it/5vvromd1ro7a1.jpg?auto=webp&s=960b94026c50417a3d5d7bc508c63d6792b5d0dd"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztnw4x/looking_for_an_18tb_hard_drive/",
          "author": null,
          "description": "I am looking for an 18TB external hard drive for my movie storage for PLEX and am wondering what the best option is. Just asking for opinions. I have been seriously considering the WD Gold as I have one and it is rock solid after 5 years\n    submitted by    /u/kewlncguy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztnw4x/looking_for_an_18tb_hard_drive/",
          "publishedOn": "2022-12-23T17:44:00.000Z",
          "wordCount": 15217,
          "title": "Looking for an 18TB Hard drive.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztnuta/lto_setup_where_are_all_the_drivers/",
          "author": null,
          "description": "I'm trying to set up a Quantum HP LTO-6 drive. Removed it from the chasey and installed in the optical bay. Using a Dell LightPulse (now known as Emulex) PCI-E card. \n Dell has a section for Emulex drivers but can't recognize my PC so it won't give me any drivers. Their assistant tool only works with Dell PCs. \n I've seen some other folks here with similar HP LTO setups. Hopefully someone here encountered this same roadblock and can help!\n    submitted by    /u/Plebsolute  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztnuta/lto_setup_where_are_all_the_drivers/",
          "publishedOn": "2022-12-23T17:43:16.000Z",
          "wordCount": 16310,
          "title": "LTO setup, where are all the drivers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztmnyn/toshiba_website_says_5_years_warranty_for_hdd_but/",
          "author": null,
          "description": "Hello, I'll be buying a couple Toshiba 18TB MG09ACA18TE in Europe. Toshiba's website says this drive has 5 years warranty, while the seller says it has 2 years.\n https://www.toshiba-storage.com/wp-content/uploads/2021/02/MG_Series_Datasheet_B2C_Website.pdf\n Will I get my full 5 year warranty from Toshiba if I buy from this seller?\n    submitted by    /u/jakuri69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztmnyn/toshiba_website_says_5_years_warranty_for_hdd_but/",
          "publishedOn": "2022-12-23T17:10:51.000Z",
          "wordCount": 16511,
          "title": "Toshiba website says 5 years warranty for HDD, but 3rd party seller says 2 years warranty?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztmlcl/would_it_be_possible_to_download_an_entire_tv/",
          "author": null,
          "description": "What I mean is would it be possible to download a TV show's, for instance Nickelodeon, entire run? I realise this would be colossal in GB, but still.\n    submitted by    /u/Voldy256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztmlcl/would_it_be_possible_to_download_an_entire_tv/",
          "publishedOn": "2022-12-23T17:07:50.000Z",
          "wordCount": 15482,
          "title": "Would it be possible to download an entire TV channel?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztjxwc/nvmeof_with_two_clients/",
          "author": null,
          "description": "Hi!\n Has anyone ever created an nvme-of host (target) where two clients connect to it? Is that a supported use case?\n Thank you!\n    submitted by    /u/SnooPaintings709  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztjxwc/nvmeof_with_two_clients/",
          "publishedOn": "2022-12-23T15:47:56.000Z",
          "wordCount": 15742,
          "title": "Nvme-OF with two clients?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztjglm/the_dream/",
          "author": null,
          "description": "submitted by    /u/DragoniteChamp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztjglm/the_dream/",
          "publishedOn": "2022-12-23T15:30:51.000Z",
          "wordCount": 17816,
          "title": "The dream 🙏",
          "imageUrl": "https://preview.redd.it/pu1zeq3ujp7a1.jpg?auto=webp&s=85d167af2b15262a706af7cb4ad1c8939c9a1a75"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zth54k/newbie_hard_drive_question/",
          "author": null,
          "description": "I'm thinking of getting my first external hard drive for the purpose of storing stuff I don't necessarily need but don't want to delete, like videos I've recorded that are several gigabytes big. (My computer only has a few gigabytes left to spare out of ~1.1 terabytes of storage which is why I'm doing this, lol) \n I'm considering getting a 6 TB Seagate Expansion Hard Drive, would that be a good for this purpose or are there any better options?\n    submitted by    /u/BeepityBot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zth54k/newbie_hard_drive_question/",
          "publishedOn": "2022-12-23T14:30:51.000Z",
          "wordCount": 17304,
          "title": "Newbie hard drive question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt3sng/looking_for_an_image_sorting_program/",
          "author": null,
          "description": "My Girlfriend has a hard drive with about 250Gbs of pictures, all in a single folder. \n We are working on getting these organized and put onto our NAS.\n Years ago, I had a program that would show you each image, and you would select a number from 1-9, which mapped to a folder, and it was easy to speed through and quickly sort large amounts of photos. \n Has anyone heard of software like this? I can't for the life of me remember what it was called.\n    submitted by    /u/Mofks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt3sng/looking_for_an_image_sorting_program/",
          "publishedOn": "2022-12-23T02:11:52.000Z",
          "wordCount": 15850,
          "title": "Looking for an image sorting program",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt2kfl/can_i_download_all_instagram_reels_at_once_from_a/",
          "author": null,
          "description": "I use WFDownloder and it doesn't download multiple reels\n    submitted by    /u/district999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt2kfl/can_i_download_all_instagram_reels_at_once_from_a/",
          "publishedOn": "2022-12-23T01:10:16.000Z",
          "wordCount": 15669,
          "title": "Can I download all instagram reels at once from a profile?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt2guw/how_should_i_set_my_scan_settings_to_digitize/",
          "author": null,
          "description": "submitted by    /u/lamy1989  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt2guw/how_should_i_set_my_scan_settings_to_digitize/",
          "publishedOn": "2022-12-23T01:05:17.000Z",
          "wordCount": 16350,
          "title": "How should I set my scan settings to digitize over 1,000 photos using Epson Perfection V600? 1200 vs 600 DPI makes a huge difference, but takes up a lot more space.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt1wha/setting_up_a_wd_2_tb_easystore_for_a_complete/",
          "author": null,
          "description": "Hello,\n I am very new to the world of data storage and just bought a 2 TB hard drive after I noticed I was running out of space on my laptop. I bought the external HDD hard drive because I wanted to be able to back up important game projects I've worked on as well as software (everything will dissapear on the internet one day, etc) and have looked through this subreddit.\n I've already deleted the installer that comes with the hard drive but I really am not sure what to do next. I think I need to wipe and partition(?) the HDD and run tests to make sure it's ok but I'm not sure what software I'd need to download for all that. I'd also appreciate any tips to make sure I can keep this alive for long to the best of my ability. Thank you\n    submitted by    /u/FullAd419  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt1wha/setting_up_a_wd_2_tb_easystore_for_a_complete/",
          "publishedOn": "2022-12-23T00:37:29.000Z",
          "wordCount": 16705,
          "title": "Setting up a WD 2 TB Easystore for a complete beginner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt0n8b/game_faqs_download_txt_bookmarklet/",
          "author": null,
          "description": "in case someone wants do download faqs or have inspiration how to scrape site, you can use this bookmarklet\n just open game's faq list, run bookmarklet, when link turns into red border you can click it and save txt file\n (as is it will work only for txt files, it can be modified to include html files and with more time even with images embedded as data urls)\n javascript:(function(){ [...document.querySelectorAll('.list.guides .content a.bold')] .forEach(a=>get_faq(a.href).then(f=>dl_faq(a,a.parentElement.innerText,f))); function get_faq(url) { return fetch(url) .then(r=>r.text()) .then(t=>t.match(/<pre.*?>(.+)<\\/pre>/s)) .then(m=>m&&m[1]||'') .then(f=>f.replaceAll(/<\\/?pre.*?>/g,'')) .then(f=>f.replaceAll('&lt;','<')) .then(f=>f.replaceAll('&gt;','>')) .then(f=>f.replaceAll('&quot;','\"')) .then(f=>f.replaceAll('&amp;','&')); } function dl_faq(a,name,txt) { a.href = 'data:text/plain;charset=utf-8,'+encodeURIComponent(txt); a.download = name+'.txt'; a.style.border = '1px solid red'; } })() \n [edit] added replacing entities with actual characters, license is public domain\n    submitted by    /u/KHRoN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt0n8b/game_faqs_download_txt_bookmarklet/",
          "publishedOn": "2022-12-22T23:39:54.000Z",
          "wordCount": 16681,
          "title": "game faqs download txt bookmarklet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zszyrq/the_internet_archive_is_down_for_maintenance/",
          "author": null,
          "description": "Update: it’s back.\n Does anyone have any inside information? I can’t remember the last time that it went completely inaccessible.\n    submitted by    /u/EHypnoThrowWay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zszyrq/the_internet_archive_is_down_for_maintenance/",
          "publishedOn": "2022-12-22T23:17:15.000Z",
          "wordCount": 15865,
          "title": "The Internet Archive is Down For Maintenance (12-22-22, 17:14 CST)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zszjx2/looking_for_an_old_british_tv_show/",
          "author": null,
          "description": "I have the first 2 seasons of Watching (1987) but I cannot find the other 5 anywhere! Is there anywhere I can try that I might not have heard of (or thought of)?\n    submitted by    /u/michaelprstn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zszjx2/looking_for_an_old_british_tv_show/",
          "publishedOn": "2022-12-22T23:00:11.000Z",
          "wordCount": 16634,
          "title": "Looking for an old British TV show",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsyfic/a_storm_is_coming/",
          "author": null,
          "description": "So I'm resilvering my 4th of 4 drives that I'm upgrading in my truenas scale nas. I'm at 60% completed with about 3.3 (of 9) days left to go. I don't have a ups and there's a good chance we'll have a power outage because of the storm headed to my part of the US tonight into tomorrow evening. Can/should I power down the nas now? Will it pickup where it left off when I boot it up again?\n Any insights are appreciated. TIA\n    submitted by    /u/SurenAbraham  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsyfic/a_storm_is_coming/",
          "publishedOn": "2022-12-22T22:12:25.000Z",
          "wordCount": 15801,
          "title": "A storm is coming",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsy7uj/help_me_build_a_server/",
          "author": null,
          "description": "Yeah, the time finally came. My \"gaming PC\" that was converted to a home server isn't enough anymore. I just mounted a hard drive in a cooler slot, and feel terrible about it.\n It's about time that I get a proper server rack and the components inside it.\n My use:\n  \nStorage. I'm now at the 10TB mark, but that's not nearly enough. Not to mention, I do not have backups for everything, just for the really important stuff.\n Jellyfin. Lots of bluray 2160p videos, the server should be capable of streaming at least 3 at a time.\n 2x Minecraft Servers with mods. I noticed this isn't really heavy on my server (besides RAM usage), so I need to have some RAM available for that.\n  \nWhen built, I also want to selfhost Nextcloud, Vaultwarden and archive odd videogame ROMs, besides all of the previously mentioned.\n I cannot have a big server rack. It simply doesn't fit in my home. Maybe in the future, but for now I want something on the smaller side. I'm also not with a lot of money, so if possible, something cheap will be great :P (Used server equipment?)\n So, I need help. What do I need to buy? What do I need to understand? I'm not from the US\n    submitted by    /u/OliveEar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsy7uj/help_me_build_a_server/",
          "publishedOn": "2022-12-22T22:04:01.000Z",
          "wordCount": 17086,
          "title": "Help me build a server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsx8cn/buying_used_hdd_smart_report_interpretation/",
          "author": null,
          "description": "I saw a relatively good deal for 2 HDDs and the seller was kind enough to attach a SMART report. \n Is anyone able to help interpret this data? One thing that has me concerned is the Reallocated sector count. Any help would be greatly appreciated, thanks!\n    submitted by    /u/kaygee420  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsx8cn/buying_used_hdd_smart_report_interpretation/",
          "publishedOn": "2022-12-22T21:22:20.000Z",
          "wordCount": 16159,
          "title": "Buying used HDD SMART report interpretation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zswt4g/thunderbolt_34_nvme_multi_drive_enclosure/",
          "author": null,
          "description": "I’m a video editor and I frequently work with huge files (8K RedRaw or Phantom CineRaw etc). I’m looking for a fast storage solution that I can edit off of. I was looking at the OWC Express 4M2 which allows large capacity storage running at 2.8GBs with four drives running RAID 0. (https://eshop.macsales.com/item/OWC/TB3EX4M2/ )\n I was digging into its specs and it says it requires four drives in RAID 0 because the drives inside are limited to 700MBs due to being a 1-lane PCIe connection. \n There are single drive thunderbolt 3/4 enclosures out there which offer similar speeds but I’m looking for large capacity along with speed. \n Before I pull the trigger, I was wondering if there was anything else out there that could be faster that would better fit my needs?\n (Yes I realize in my hunt for speed this is probably overkill, but I’d like to do my due diligence).\n    submitted by    /u/Canadian__Tired  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zswt4g/thunderbolt_34_nvme_multi_drive_enclosure/",
          "publishedOn": "2022-12-22T21:04:30.000Z",
          "wordCount": 17413,
          "title": "Thunderbolt 3/4 NVMe multi drive enclosure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zswrq5/how_to_pull_files_from_a_txt_file/",
          "author": null,
          "description": "I have a bunch of files listed in a txt file. They are names of photos the clients want. What is the fastest way to find these jpg files and copy to a new folder? I could use Everything but it would take forever. Pls help\n Updated with example: Windows 10 folder A has 5000 photos. File.txt has the file names of about 200 photos we need, also in same folder A. Would be great to auto copy these 200 photos into folder B.\n    submitted by    /u/tungvu256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zswrq5/how_to_pull_files_from_a_txt_file/",
          "publishedOn": "2022-12-22T21:02:49.000Z",
          "wordCount": 17119,
          "title": "how to pull files from a txt file?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsw1hw/where_could_i_find_my_favorite_books_and_shows/",
          "author": null,
          "description": "If this isn't allowed please don't ban me I like y'all. \n I want to be able to get a hold of all my favorite books, shows and movies and I'm not afraid of the high seas but I am a new sailor. Can anyone point me to the right direction or sub. \n Thanks.\n    submitted by    /u/TroothBeToldPodcast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsw1hw/where_could_i_find_my_favorite_books_and_shows/",
          "publishedOn": "2022-12-22T20:31:38.000Z",
          "wordCount": 16207,
          "title": "where could I find my favorite books and shows",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsvta6/rsync_on_debian_nothing_is_copying_but_only/",
          "author": null,
          "description": "I'm copying items from one debian server to another and trying to use Rsync for the process. I had issues getting it working over 10GB lanes but finally fixed that. My issue now is the command is coming back with 'Receiving incremental file list' and then quits but nothing is copied.\n For reference, if I ssh into either one I land in the root folder and have to do cd ../srv/disk/ in order to get into my shares. On the destination server (in the command below) I have an empty directory called Music. The source server has the Music directory full of folders and files and I'm trying to copy all contents into the empty Music folder on the dest.\n The command:\n rsync -ahP --chmod=D777,F666 --address=10.10.10.15:./srv/27829c9c-dbc1-4408-a111-56dbcd8f0ec0/media/Music/ [root@10.10.10.13](mailto:root@10.10.10.13):/srv/27829c9c-dbc1-4408-a111-56dbcd8f0ec0/media/Music\n is coming back with:\n receiving incremental file list\n drwxrwxrwx 4.10K 2022/12/18 13:00:29 Music\n What am I doing wrong?\n    submitted by    /u/FourTimesRadical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsvta6/rsync_on_debian_nothing_is_copying_but_only/",
          "publishedOn": "2022-12-22T20:21:43.000Z",
          "wordCount": 15583,
          "title": "Rsync on debian, nothing is copying but only receiving file list",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsv93m/i_miss_when_vcrs_were_common_and_the_attitude/",
          "author": null,
          "description": "people would just tape shit off TV that they liked or might wanna see later. sports games, films, TV episodes, whatever\n nowadays people seem to willingly kneel to the streaming gods -- you will own nothing, and you will be happy. everything is DRMed, you can't even take a fucking screenshot! \n if you told someone 'i'm gonna record this off hulu' they'd get pissy because you're not meant to do that\n    submitted by    /u/spacewalk__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsv93m/i_miss_when_vcrs_were_common_and_the_attitude/",
          "publishedOn": "2022-12-22T19:57:48.000Z",
          "wordCount": 18949,
          "title": "I miss when VCRs were common, and the attitude they fostered",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsujt0/backup_program_for_windows/",
          "author": null,
          "description": "Hello,\n I recently switched from windows 10 to windows 11 which has made filehistory an even bigger mess to use so I want to look for an alternative that works better. \n What I want to accomplish:\n Incremental back-ups (don't want it to create a full back-up everytime)\n Have it automatically back-up to my NAS\n Able to select which folders to back-up\n A nice to have would also be a filehistory way where I can go back to a version X days ago.\n Anyone have a recommendation for software able to accomplish this (preferably something lightweight)\n    submitted by    /u/StarLines  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsujt0/backup_program_for_windows/",
          "publishedOn": "2022-12-22T19:27:40.000Z",
          "wordCount": 16264,
          "title": "Back-up program for windows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zst0ro/i_made_an_reddit_post_unsaver_bot_that_you_guys/",
          "author": null,
          "description": "submitted by    /u/Wari0-_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zst0ro/i_made_an_reddit_post_unsaver_bot_that_you_guys/",
          "publishedOn": "2022-12-22T18:23:20.000Z",
          "wordCount": 14615,
          "title": "I made an reddit post unsaver bot that you guys can use with a downloader like BDFR to make archiving easier and not have struggle with RedderManager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zssckz/nas_drive_noises_warranty/",
          "author": null,
          "description": "Hey folks, \n bought 2x 4tb seagate ironwolf and now after finding time to build my proxmox homelab with a truenas VM on it I noticed that one of the drives is making interesting noises. I would consider the type of noise \"normal\" for a hard drive but not this frequent. s.m.a.r.t test says everything is fine though. \n They have still warranty but because I'm not an expert I wanted to ask you guys what to do maybe someone here had the same issue and there is a easier way than contacting seagate and sending the drive to them. Or maybe im just paranoid but I don't think that this is normal. \n Many thanks in advance :) \n ​\n https://reddit.com/link/zssckz/video/fpaz5whmmh7a1/player\n    submitted by    /u/beluga030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zssckz/nas_drive_noises_warranty/",
          "publishedOn": "2022-12-22T17:55:56.000Z",
          "wordCount": 15752,
          "title": "NAS Drive noises (warranty?)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zss3cp/downloading_bookmarks_as_individual_html_files/",
          "author": null,
          "description": "I have quite a bit of websites bookmarked and was wondering if there's an efficient way to save those websites for offline viewing? \n I know I can just go through and individually download websites with webcopy or a similar app, but I wanted to ask if there's any way to do it faster.\n If you need to know my browser, I currently use Brave.\n Thank you in advance.\n Edit : forgot to mention, I'm a windows user if that matters.\n    submitted by    /u/noxwolfdog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zss3cp/downloading_bookmarks_as_individual_html_files/",
          "publishedOn": "2022-12-22T17:45:36.000Z",
          "wordCount": 15253,
          "title": "Downloading bookmarks as individual HTML files",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsryk2/wd_elements_desktop_16tb_external_hard_drive/",
          "author": null,
          "description": "submitted by    /u/Viknee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsryk2/wd_elements_desktop_16tb_external_hard_drive/",
          "publishedOn": "2022-12-22T17:40:12.000Z",
          "wordCount": 14685,
          "title": "WD Elements Desktop 16TB External Hard Drive - $239.99 ($15/TB) (US)",
          "imageUrl": "https://external-preview.redd.it/Y0XFFKydAOckP0wTkH_8Taf5Un5j6xMy1vfIV7-7j3A.jpg?auto=webp&s=c7f8368496484ab2fea5fe68384ccf822a3fd5f2"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsoy2p/321_2nd_local_copy_does_this_need_to_be_automated/",
          "author": null,
          "description": "Assuming you have all data centralized and you have an automated offsite backup, would you consider an effective 3-2-1 backup solution to have an automated local backup as well, or would a simple rotated cold storage solution suffice?\n    submitted by    /u/StrongCommission  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsoy2p/321_2nd_local_copy_does_this_need_to_be_automated/",
          "publishedOn": "2022-12-22T15:39:10.000Z",
          "wordCount": 15036,
          "title": "3-2-1: 2nd local copy, does this need to be automated?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsfgt5/why_we_hoard_nintendo_minute_videos_are_being_set/",
          "author": null,
          "description": "submitted by    /u/Brancliff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsfgt5/why_we_hoard_nintendo_minute_videos_are_being_set/",
          "publishedOn": "2022-12-22T07:11:56.000Z",
          "wordCount": 16314,
          "title": "Why We Hoard: Nintendo Minute Videos Are Being Set To Private On Nintendo's YouTube Channel",
          "imageUrl": "https://external-preview.redd.it/I20YQAH3bXT3Qgz9LKnF3lCszWhe5cR_FZuMIc4DPeU.jpg?auto=webp&s=dc6122900e685997b5974f3ecfaae6e00861033b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsac6s/hdd_prices_too_good_to_be_true_on_facebook/",
          "author": null,
          "description": "There's a Facebook marketplace post near me that claims to have a box of 14TB Western Digital HC530 drives. They're selling them around $100 USD each. The serial numbers shown in the photos return no warranty, but they show up as WD products with the following model number: 0F31156 and description: LEE Drive ASM 14.0TB, 512e, SATA P3_PWDIS_Support, Amazon, Secure Erase.\n Would these be safe to buy? What can I do to check they truly are the capacity they claim they are?\n I would like to do a full check with H2testw, but I've been told it takes a while. What would you do?\n Thanks in advance.\n Edit: they also show crystal disk info screenshots\n Edit 2: there seem to be 2 sellers, one that is a clearance warehouse, and the other that has a physical retail location and offers a 6 month warranty, so I'll add updates as I go\n    submitted by    /u/LNR_Music_Curation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsac6s/hdd_prices_too_good_to_be_true_on_facebook/",
          "publishedOn": "2022-12-22T03:06:09.000Z",
          "wordCount": 17841,
          "title": "HDD prices too good to be true on Facebook Marketplace",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs837e/syncing_folders_between_hard_drives_on_the_same/",
          "author": null,
          "description": "The right way would probably be to raid 2 drives together and mirror them, but i don't really like the idea of having a backup, but at the same time, said backup is destroyed whenever i accidentally completely delete a file on a hard drive, since it mirrors the action on the other\n also, i don't have 2 equal hard drives, so i'd get the worse writting and the worse reading speeds from both \n either way, i wanna sync a folder every night, so that every change i made to a folder on one drive during the day, gets copied over to the other drive during the night at a specified hour\n New files, Edited files, different files with the same file name, deleted files, all completely mirrored from the drive i used during the day, but only perform the changes at night, or maybe every other day even\n ​\n what program could i use to do that?\n    submitted by    /u/peugamerflit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs837e/syncing_folders_between_hard_drives_on_the_same/",
          "publishedOn": "2022-12-22T01:27:53.000Z",
          "wordCount": 15775,
          "title": "syncing folders between hard drives on the same comuter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs7gpu/i_need_help_gathering_data_on_opinioms_about/",
          "author": null,
          "description": "https://docs.google.com/forms/d/e/1FAIpQLSc-y_AjvI5j2kAczbN57mYqaLiyROa3639qMKzmRjVabom5jw/viewform?usp=sf_link\n It's just 3 questions but any answers are appreciated\n    submitted by    /u/Ok-Thought-3962  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs7gpu/i_need_help_gathering_data_on_opinioms_about/",
          "publishedOn": "2022-12-22T01:01:12.000Z",
          "wordCount": 15345,
          "title": "I need help gathering data on opinioms about digital twin technology",
          "imageUrl": "https://external-preview.redd.it/imz3IIfOe5tS0izphogzvSyXP4XTpjWYWm_HIoM9NNQ.jpg?auto=webp&s=30f69e5f53aabf8d4985b0871d5f04653d855dbd"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs6kb7/data_versioning_between_2_pc_over_network/",
          "author": null,
          "description": "Honestly, not sure if this is even the right sub, but anyways....\n Got 2 pc on local network, both windows 11 pc. Is there a way to do this\n  \npc gets a new file/folder in a monitered directory\n \nProgram checks pc 2 over network to see if that same folder or file is already in pc 2 watched directories\n \nIf new file or folder is not in those watched directories, ask if it wants to move it to a folder on pc 2\n \n I mean even if it's just a batch script that's be cool.\n    submitted by    /u/DR4LUC0N  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs6kb7/data_versioning_between_2_pc_over_network/",
          "publishedOn": "2022-12-22T00:24:31.000Z",
          "wordCount": 15414,
          "title": "Data versioning between 2 pc over network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs6gz8/where_to_find_old_footballnbanfltennis_matches_in/",
          "author": null,
          "description": "I love watching sports, and want to watch classic matches especially for football and tennis. Is there a way to watch and download them?\n    submitted by    /u/godeater123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs6gz8/where_to_find_old_footballnbanfltennis_matches_in/",
          "publishedOn": "2022-12-22T00:20:45.000Z",
          "wordCount": 16287,
          "title": "Where to find old football/nba/nfl/tennis matches in full hd quality?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs3dam/how_to_download_a_video_thats_hosted_on_netutv_i/",
          "author": null,
          "description": "Netu.tv has some serious content protection. There are some videos on a website (nsfw but irrelevant because its only the videos hosted on Netu.tv that are the problem) I'm trying to download that use Netu.tv as their host, and require the user to manually click a play button that shows up somewhere in a rectangular area (random spot so a bot couldn't click the center of the video area) before the video even loads into the site. I can't right click anything in the video player area, opening up developer tools causes the video to disappear without a trace in the \"Elements\" section, disabling JavaScript does nothing to stop the removal of said video once Developer Tools opens. JDownloader picks up nothing because the webpage its on has no video technically, only after the user's manual input does the Netu.tv media appear. Extensions on Google Chrome like CocoNut don't pick it up, even with \"force download\". Certainly someone amongst the data hoarding hivemind can find a way to fetch these videos? Preferably in their raw form and not just via screen-recording?\n    submitted by    /u/GamingDragon27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs3dam/how_to_download_a_video_thats_hosted_on_netutv_i/",
          "publishedOn": "2022-12-21T22:26:51.000Z",
          "wordCount": 15839,
          "title": "How to download a video that's hosted on netu.tv? I see some articles/threads from a while back on successful ways to but they all seem outdated. Jdownloader, developer tools, and browser extensions don't pick it up. Looks as if its truly unhoard-able?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs20nz/djing_usb_stick_maybe_corrupted/",
          "author": null,
          "description": "While I was playing my last track of my DJ set the next dj accidentally bumped into my stick and it got ejected :( the final song even had a weird cut in the end. Should I now directly format it or can I somehow salvage this situation? I really don't want to download all the music manually again and make thousand new playlists aaaa\n Thanks in advance!\n    submitted by    /u/MarionberryEnough658  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs20nz/djing_usb_stick_maybe_corrupted/",
          "publishedOn": "2022-12-21T21:48:54.000Z",
          "wordCount": 16732,
          "title": "DJing USB Stick maybe corrupted?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs1jel/youtube_videos_on_wayback_machine/",
          "author": null,
          "description": "Hey folks.\n This one is annoying me! - There's a historic Youtube video that has been made unavailable for copyright - There are a few other copies on YouTube, but as I recall this was the only one that is in any decent definition.\n https://www.youtube.com/watch?v=w_8dafLxLcI\n On Wayback machine, it goes back to 2008, but those older versions all seem to want Flash and I can't work out how on earth to download them anyway. It's nice of Archive.org to have it archived, but if you can't use it, that's annoying.\n https://web.archive.org/web/20110227200859/http://www.youtube.com/watch?v=w_8dafLxLcI\n Am I just missing something obvious?\n    submitted by    /u/Hacklet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs1jel/youtube_videos_on_wayback_machine/",
          "publishedOn": "2022-12-21T21:30:40.000Z",
          "wordCount": 15637,
          "title": "Youtube videos on Wayback Machine",
          "imageUrl": "https://external-preview.redd.it/e7IUn6nxc_nqwfY-luK-p82DX8uFkO5QSuc7YFZSz4U.jpg?auto=webp&s=1480d38c15d03358efd98d0ced110a122ab840ed"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs1j6p/how_to_clean_up_400gb_data/",
          "author": null,
          "description": "Following a family death I’ve ended up with about 400gb of data pulled from around a dozen mixed drives. I’ve transferred it onto my NAS and stored it in folders by source. (It was easier to harvest it into one location for my wife to pull some family photos from). The storage was chaotic!!! There were recent (i.e newish) drives that had some old stuff, but not all the old stuff, as well as some stuff that appears to be the only copy. Some drives even contained the same data multiple times buried in folders inside folders. 🤯\n I’m running synology DS920+. What’s the easiest way to pull data out by type and remove duplicates? E.g. pull all the photos out into a single folder. I don’t want to lose anything but I don’t need 40 copies of a school nativity from 20 years ago.\n    submitted by    /u/WeirdPerception1984  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs1j6p/how_to_clean_up_400gb_data/",
          "publishedOn": "2022-12-21T21:30:27.000Z",
          "wordCount": 17308,
          "title": "How to clean up 400gb data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs180e/purchasing_a_2_bay_nas_wd_mycloud/",
          "author": null,
          "description": "So the title says it all. I am looking at the WD MyCloud 2bay Expert EX2 NAS. I currently have 2 separate 2tb externals hooked up to my Linux server and my wife directly backs her phones photos to it via the wifi network connection. Plus we stream some media and use it for backup files, etc. I currently run rsync to copy one HD to the other every few months for redundancy. One main feature I want in a NAS is the raid option so I don't have to continue to manually back up the redundancy.\n Is this a good device for me to upgrade to?\n Here is the link for Best Buy. Also, I'd love other suggestion but I need to stay at the $160ish price point. \n https://www.bestbuy.com/site/wd-my-cloud-expert-ex2-ultra-2-bay-0tb-external-network-attached-storage-nas-charcoal/5061402.p?skuId=5061402#anchor=productVariations\n    submitted by    /u/onebasix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs180e/purchasing_a_2_bay_nas_wd_mycloud/",
          "publishedOn": "2022-12-21T21:18:52.000Z",
          "wordCount": 17713,
          "title": "Purchasing a 2 Bay NAS, WD MyCloud?",
          "imageUrl": "https://external-preview.redd.it/mIhJl4qMhF4MpRmW0zdDoIuqLZKEP3kykEatkPxZrUU.jpg?auto=webp&s=91f72b2dd6ba8f7c0eedbd6273c145f0142be761"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs0ice/how_would_i_download_a_video_from_a_website_that/",
          "author": null,
          "description": "The video stops playing and a notice appears instead basically removing it from the page. I've tried JDownloader and it doesn't pick up the video either.\n    submitted by    /u/GamingDragon27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs0ice/how_would_i_download_a_video_from_a_website_that/",
          "publishedOn": "2022-12-21T20:52:27.000Z",
          "wordCount": 17444,
          "title": "How would I download a video from a website that doesn't allow opening \"developer tools\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrz9yw/do_you_have_a_lot_of_media_on_your_phone_at_all/",
          "author": null,
          "description": "Movies/music/books/comics/manga? \n What type?\n How much GB?\n    submitted by    /u/warrenmax12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrz9yw/do_you_have_a_lot_of_media_on_your_phone_at_all/",
          "publishedOn": "2022-12-21T20:06:07.000Z",
          "wordCount": 15226,
          "title": "Do you have a lot of media on your phone at all times?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zry24l/is_there_any_software_that_lists_all_files/",
          "author": null,
          "description": "Okay so, I'm found a couple inconsistencies between my two Hard Drives (seems I did a bad job of kerlong them consistent) with docs that were updated in one but not updated accordingly in the other. They were easy fixes but I wanna check for more inconsistencies including file moves. However I don't wanna be checking through so many files one by one.\n I know windows explorer can list all files of a type, showing modification dates for each, but that doesn't include folders and there could be some file types I'm forgetting. Is there a software that would list everything for each hard drive, with the modification dates so I can go through and compare lists for both?\n Bonus points if they can list everything with a number, to make things even easier.\n    submitted by    /u/ToqKaizogou  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zry24l/is_there_any_software_that_lists_all_files/",
          "publishedOn": "2022-12-21T19:20:28.000Z",
          "wordCount": 15954,
          "title": "Is there any software that lists all files, folders and subfolders on a hard drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrxw1m/i_posted_a_couple_of_days_ago_some_smart_errors/",
          "author": null,
          "description": "submitted by    /u/skeptibat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrxw1m/i_posted_a_couple_of_days_ago_some_smart_errors/",
          "publishedOn": "2022-12-21T19:13:58.000Z",
          "wordCount": 16650,
          "title": "I posted a couple of days ago some SMART errors on my drives... I scandisk'd and zero'd and wrote random bits and it seems... a little better?",
          "imageUrl": "https://preview.redd.it/yknxbmq3wa7a1.png?auto=webp&s=d79fef170a961e80ed103f427725b434bd1568cd"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrxoj7/shipping_bdr_discs_in_freezing_temps/",
          "author": null,
          "description": "I just placed an order for a bunch of 50gb and 100gb BD-R discs. Where I'm located the temperatures at this time of the year are below freezing. Should I be concerned about the discs getting damaged during shipping due to the temps?\n    submitted by    /u/HarryMuscle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrxoj7/shipping_bdr_discs_in_freezing_temps/",
          "publishedOn": "2022-12-21T19:06:01.000Z",
          "wordCount": 15452,
          "title": "Shipping BD-R Discs in Freezing Temps?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrx77d/how_do_i_download_this_website_that_only_works_on/",
          "author": null,
          "description": "https://promo.shonenjump.com/jujutsu/shibuya/\n Can’t access it on pc.\n    submitted by    /u/xkilluaaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrx77d/how_do_i_download_this_website_that_only_works_on/",
          "publishedOn": "2022-12-21T18:47:56.000Z",
          "wordCount": 16260,
          "title": "How do I download this website that only works on mobile?",
          "imageUrl": "https://external-preview.redd.it/5J-ylWj9tdrF6T7N3ooMybGtX1JyctCDJP_aOc0PqTQ.jpg?auto=webp&s=c46a9fdb234c092bbf02ccdf8f2bc65d68113713"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrwymq/is_there_a_way_to_searching_multiple_epub_and_pdf/",
          "author": null,
          "description": "So I have recently gotten into hoarding cookbooks. However when I am looking for a recipe for let's say \"apple pie\" it seems that I have open one by one to search. Is there a way to search every index at once? Currently using calibre 64bit.\n ​\n Sorry I am not sure this is right place to ask...\n    submitted by    /u/overimbibe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrwymq/is_there_a_way_to_searching_multiple_epub_and_pdf/",
          "publishedOn": "2022-12-21T18:39:48.000Z",
          "wordCount": 15474,
          "title": "Is there a way to searching multiple epub and pdf?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrvsms/current_situation_about_shucking_wd_elementsmy/",
          "author": null,
          "description": "Hello,\n last time I shucked an external drive years ago, they were pretty much WD Red drives. \n I am planning to have one again as an internal drive.\n How is the situation now? Is it recommended? Does it have any downsides? Are they still red ones? Do I have to tape that one pin for both versions (Elements/My Book)?\n Do you suggest to buy other brands? I was pretty happy about WD Red ones but maybe there are better ones considering price-performance?\n Thanks.\n    submitted by    /u/SleepyTimeNowDreams  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrvsms/current_situation_about_shucking_wd_elementsmy/",
          "publishedOn": "2022-12-21T17:58:50.000Z",
          "wordCount": 18488,
          "title": "Current situation about shucking WD Elements/My Book 8/10/12/14 TB? Reds? Pins?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrv72b/europe_segate_rma_what_the_hell/",
          "author": null,
          "description": "So, here in southern europe the RMA process for segate disks is running poorly or simply replacing the goods with other similar but not technically the same.\n This time the victim was me: Sent them a dead-still-under-warranty Ironwolf 6TB 7200 RPM disk (ST6000VN0033) and received an Ironwolf 6TB 5400 RPM (ST6000VN001). Sent them an email regarding this issue (have the support number), escalated the issue, and nobody replied. It has been now several days.\n Is this even legal? How can i best assure my rights as a consumer?\n Thanks for your help!\n    submitted by    /u/xupetas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrv72b/europe_segate_rma_what_the_hell/",
          "publishedOn": "2022-12-21T17:34:18.000Z",
          "wordCount": 15284,
          "title": "Europe Segate RMA?! What the hell?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrtfr1/should_i_mix_hdd_brandsmodels_raid_5_with_4_hdd/",
          "author": null,
          "description": "Building a 4 bay raid 5 storage for stoeing raw film.\n Choosing between 18TB red pro and ironwolf pro (beat peice per tb, red being slightly more expensive). Should I mix my purchase, 2 of each, to attempt to minimize failure?\n    submitted by    /u/andreifasola  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrtfr1/should_i_mix_hdd_brandsmodels_raid_5_with_4_hdd/",
          "publishedOn": "2022-12-21T16:34:59.000Z",
          "wordCount": 15905,
          "title": "Should I mix HDD brands/models? Raid 5 with 4 HDD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrslu4/pcie_x1_sata_controller/",
          "author": null,
          "description": "hello,\n im looking for a cheap pci e x1 sata controller with as many SATA ports as possible.\n found this one: \n https://www.amazon.de/Syba-SI-PEX40064-PCI-EXPRESS-Controller-Karte/dp/B00AZ9T3OU\n which controller would you recommend\n    submitted by    /u/reicto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrslu4/pcie_x1_sata_controller/",
          "publishedOn": "2022-12-21T16:14:31.000Z",
          "wordCount": 15504,
          "title": "PCI-E x1 SATA Controller",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrqeti/new_rclonebased_backup_tool_i_created_rirb/",
          "author": null,
          "description": "Executive Summary (TL/DR)\n Mimic \n $ rclone sync source: dest:curr --backup-dir dest:back/<date> \n but store the file listing to greatly speed it up. Also automatically store logs, diffs, etc.\n Main Post\n I am a huge fan of using rclone with --backup-dir (docs) for backups.\n It is not the most efficient, most featureful, advanced, sexy, fastest, etc. of the different backup solutions. But it makes up for all of this in a key area: simplicity. \n When it comes to backups, there is a lot to be said for being simple and easy. Easy to understand, easy to restore, easy to verify.\n However, there is a major problem with rclone backups: it needs to list the destination every time which can be very slow. (There are others too but this is the main one).\n So I created rirb: reverse incremental rclone…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrqeti/new_rclonebased_backup_tool_i_created_rirb/",
          "publishedOn": "2022-12-21T15:23:31.000Z",
          "wordCount": 17711,
          "title": "New rclone-based backup tool I created, rirb: reverse incremental rclone backups, which may interest some in this community",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrotd9/its_a_long_shot_but_does_anyone_have_a_copy_of/",
          "author": null,
          "description": "I've been using this for a long time, and I made a backup like any good data hoarder would. Today, however, my USB stick died. I went to load the backup up, and to my horror, it just wouldn't work. This tool (and its backup) are pretty ancient; my copy was from 2015, version 7.4.0.132. \n I'm looking for the USB POS Diagnostics Key. However, they seem to have locked it away since I last used it. \n Anyway, any help would be greatly appreciated.\n    submitted by    /u/libraholes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrotd9/its_a_long_shot_but_does_anyone_have_a_copy_of/",
          "publishedOn": "2022-12-21T14:46:32.000Z",
          "wordCount": 15454,
          "title": "It's a long shot but does anyone have a copy of Toshiba USB POS Diagnostics key?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrobif/backblazes_hard_drive_stats_are_a_broad_resource/",
          "author": null,
          "description": "submitted by    /u/themadprogramer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrobif/backblazes_hard_drive_stats_are_a_broad_resource/",
          "publishedOn": "2022-12-21T14:35:19.000Z",
          "wordCount": 22913,
          "title": "Backblaze's Hard Drive Stats are a broad resource for comparing drive stats from industry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zr3xtv/no_one_pirated_this_cnn_christmas_movie/",
          "author": null,
          "description": "submitted by    /u/AshleyUncia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zr3xtv/no_one_pirated_this_cnn_christmas_movie/",
          "publishedOn": "2022-12-20T23:57:30.000Z",
          "wordCount": 15962,
          "title": "No one pirated this CNN Christmas Movie Documentary when it dropped on Nov 27th, so I took matters into my own hands when it re-ran this past weekend.",
          "imageUrl": "https://preview.redd.it/eh5uk5hm557a1.jpg?auto=webp&s=feee18bf372a6f5030a0716b2c438a56567730f7"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zr2gv4/my_file_management_has_gone_absolutely_chaotic_on/",
          "author": null,
          "description": "So I have an unraid server that I used to manage very well with plenty of storage and redundancy but since my situation has changed and I’ve had to take my server offline my desktop PC file management has gone ridiculous. I don’t even know where to begin. Recently bought a bigger SSD because I was desperate and didn’t have time to sift through files so just cloned my drive and now I have some head room and a spare drive. I have program installers, random text file notes, music, films, software, games, files for modifying things, it’s just chaos since not been able to have my server. \n Any tips?\n    submitted by    /u/GiggleStool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zr2gv4/my_file_management_has_gone_absolutely_chaotic_on/",
          "publishedOn": "2022-12-20T22:57:19.000Z",
          "wordCount": 15983,
          "title": "My file management has gone absolutely chaotic on my main desktop PC since I haven’t had my server help and advice needed.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqzwgu/hey_guys_looking_for_suggestions/",
          "author": null,
          "description": "Hi im an aussie that lives in the bush with crappy wifi was originally looking into getting a NAS but i would beleive it would be too slow to load games off it which will be the main purpose so was thinking instead getting an 8 bay hardrive enclosure and installing all my games/media to that instead.going external due to building an itx rig. Any help/reccomendations are welcome thanks in advance\n    submitted by    /u/TIZ_245  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqzwgu/hey_guys_looking_for_suggestions/",
          "publishedOn": "2022-12-20T21:14:57.000Z",
          "wordCount": 15431,
          "title": "Hey guys looking for suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqzi9w/adding_more_bays/",
          "author": null,
          "description": "Context: I own a \"Antec 4U22EPS650 4U Rackmount Case\" with no mobo whatsoever in it I have found a pretty good deal on a Synology DS413 with 4x ironwolf. \n I am aware it is not advised but, Is it possible to gut the DS413, frankenstein it into my rackmount case and effectively \"add more bays\"\n    submitted by    /u/Razial36  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqzi9w/adding_more_bays/",
          "publishedOn": "2022-12-20T20:59:49.000Z",
          "wordCount": 16991,
          "title": "adding more bays?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqyz76/considering_picking_up_from_a_local_seller_what/",
          "author": null,
          "description": "submitted by    /u/RandomDelta06  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqyz76/considering_picking_up_from_a_local_seller_what/",
          "publishedOn": "2022-12-20T20:38:13.000Z",
          "wordCount": 17445,
          "title": "Considering picking up from a local seller, What should I look out for?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqyima/does_nvme_data_overwrite_prevent_recovery/",
          "author": null,
          "description": "When overwriting a NVMe completely with useless files, can the data be recovered? I want to securely erase them.\n  \nI’m planning to sell it and can afford the TBW.\n Don’t have the right mainboard for secure erase\n Don’t have parted magic\n I set the blocks to 0% with tunefs\n  \n   submitted by    /u/Germandude81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqyima/does_nvme_data_overwrite_prevent_recovery/",
          "publishedOn": "2022-12-20T20:19:37.000Z",
          "wordCount": 16204,
          "title": "Does NVMe data overwrite prevent recovery?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqx90b/how_to_convert_epub_to_gitbook/",
          "author": null,
          "description": "hi, I have a lot of e-pub books that i would like to publish on gitbook (or similar) but I can't seem to find a tool (online or otherwise) than can do it. Any idea? \n Thanks!\n    submitted by    /u/pompeii-eo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqx90b/how_to_convert_epub_to_gitbook/",
          "publishedOn": "2022-12-20T19:28:50.000Z",
          "wordCount": 15479,
          "title": "How to convert E-Pub to GitBook?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqwday/great_deal_on_gen4_2tb_nmve_in_canada_how_are/",
          "author": null,
          "description": "Hello,\n I'm in the market for 4x 2tb NVMe Gen4. Going to put them in a PCIe NVMe bay eventually. Do these specs check out? Only think I'm worried about is how drives tend to slow down over time.Not sure how important VNAND is compared to TLD, QLC, cache etc., in regards to speed and longevity.This price and speed seem too good to be true. All these drives are just for storage, OS will be on a Samsung Pro.\n Also, these drives will solely be used for music production and reading, not writing; loading many heavy files/samples simultaneously, if that helps.\n https://www.amazon.ca/dp/B0B2CYTQ1H/ref=as_sl_pc_tf_til?tag=&linkCode=w00&linkId=&creativeASIN=B0B2CYTQ1H\n Thanks!\n    submitted by    /u/MarkGeraz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqwday/great_deal_on_gen4_2tb_nmve_in_canada_how_are/",
          "publishedOn": "2022-12-20T18:54:10.000Z",
          "wordCount": 18745,
          "title": "Great deal on Gen4 2tb NMVe in Canada. How are these specs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqva76/trying_to_open_but_not_break_external_usb_seagate/",
          "author": null,
          "description": "I have an external USB powered drive thats 2TB and I'd like to open the housing to put in a 4TB SSD but I cant figure out how to open it but not break it. Any ideas? I feel like the people in this sub open up drive housings a LOT more than I do so probably have good experience.\n ​\n its this style: Amazon.com: Seagate Ghost-Spider Special Edition FireCuda External Hard Drive 2TB - USB 3.2 Gen 1, customizable LED RGB lighting Pink, with Rescue Services (STKL2000418) : Electronics\n    submitted by    /u/IntegraType-S  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqva76/trying_to_open_but_not_break_external_usb_seagate/",
          "publishedOn": "2022-12-20T18:10:48.000Z",
          "wordCount": 15698,
          "title": "Trying to open but not break external USB Seagate Firecuda housing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqttzv/old_computer_needs_new_storage_how_can_i_safely/",
          "author": null,
          "description": "I have a rather elderly computer from around 2007-08 and it has one 250gb HDD, the drive is almost completely full (pc has been in a basement for about 6 years so not much space was taken up until recently) and I don't know whether simply adding another drive would be effective. I don't use much storage, I figure a terabyte would be more than enough, but should I just add a drive or is there something else I can do? (Windows7 Home Premium, btw) The other specs are okay for what I need, but I want to upgrade the storage and processor. 8gb DDR2 800, GT 730, Athlon x64 Dual Core 4200+ in case this info is useful. Pls ask if you need more info, I'm not particularly experienced regarding storage.\n    submitted by    /u/throwawayaccnt14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqttzv/old_computer_needs_new_storage_how_can_i_safely/",
          "publishedOn": "2022-12-20T17:12:39.000Z",
          "wordCount": 17489,
          "title": "Old computer needs new storage, how can I safely add more?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqt96g/should_a_hard_drive_still_work_after_being/",
          "author": null,
          "description": "I am new to NAS stuff and have an ASUSTOR AS1102T 2 bay NAS. Been using it quite smoothly for the past month. Then I attempted an experiment. After making sure all data is backed up, I powered off the NAS, took out the hard drive, and plugged it into a windows computer. I wanted to see if it’s possible to see the files directly on a desktop (because I intend to use hard drives as Cold Storage as I don’t have much to spend on NAS with many bays). To no avail, windows didn’t recognise it. Also ran a quick health check and all sectors green. I plugged it back into the NAS (another SATA port) and booted up the NAS, but it showed disk errors. I powered off the NAS, and switched the hdd to the original port, and booted it up again, but was met with disk errors again. \n So my questions are: 1) are NAS hdd supposed to be allowed to be plugged out? 2) when they are plugged back in, does port matter? 3) will windows “corrupt/override” the file system that the NAS has written?\n I believe the answer to at least one of these is the reason for the results of my experiment. It would be disappointing if (1) turned out to be “no”, as that was my intended usage. What do you guys think? :)\n Perhaps I need to click on “repair” as mentioned here? https://www.reddit.com/r/synology/comments/ijbac9/disk_drive_order/g3chu61/?utm_source=share&utm_medium=ios_app&utm_name=iossmf&context=3\n    submitted by    /u/tch1001  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqt96g/should_a_hard_drive_still_work_after_being/",
          "publishedOn": "2022-12-20T16:49:44.000Z",
          "wordCount": 16973,
          "title": "Should a hard drive still work after being removed from a NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqsgzg/setting_up_storage/",
          "author": null,
          "description": "Hey!\n I’m fairly new to data hoarding and it’s not something I’ve been able to do much due to Wi-Fi bandwidth caps, but now I’m on a plan with much higher bandwidth with a pretty eh download speed (which is capped to max 50mbps)\n I have a 1 TB ssd, a 1 TB HDD in my laptop (no pc atm), and a 5 TB external HDD. I bought a 2012 Dell OptiPlex 790 earlier this year and have regretted buying it ever since. I can’t sell it since no one would pay for what it cost me. $50 for the machine itself and little over $100 to get it shipped to me, I don’t live in the western world and the OptiPlex came from the US.\n The OptiPlex has a single hard drive bay and seeing as it is from a decade ago, I doubt m.2 ssd is an option. Came with a 4 GB stick and a user here or over in the NAS subreddit recommended that I get either 8 or 16 GB which I’m planning on doing.\n But the main issue at hand is using hard drives. Now, the option that I’ve been considering for a while is using external hard drive dock. Would any of you recommend me going this route or should I count my losses and look for another option?\n    submitted by    /u/Sycrixx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqsgzg/setting_up_storage/",
          "publishedOn": "2022-12-20T16:16:57.000Z",
          "wordCount": 16136,
          "title": "Setting up storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqs8zi/does_anyone_know_a_mirror_possibly_p2p_of_the/",
          "author": null,
          "description": "In short, cygwin is a great niche project but it doesn't keep all the versions online and thus Win systems that go EOL get unsupported.\n That is a shame as one may still want to use old system for vintage projects, fortunately there is one project, the cygwin time machine, that tries to save all the notable releases.\n http://www.crouchingtigerhiddenfruitbat.org/Cygwin/timemachine.html\n The question is, that site may go down (because internet forgets, not immediately, but it does), are there p2p resources to keep mirrors of it alive?\n  \nEdit: a bit surprised by the downvotes. I though the sub was for trying to save things, also (especially?) niche things that are legal to share, rather than mostly \"download a lot of Linux ISOs that at the end are pirated films\". I guess that it mostly dedicated to mainstream data and I expected a bit more.\n    submitted by    /u/pier4r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqs8zi/does_anyone_know_a_mirror_possibly_p2p_of_the/",
          "publishedOn": "2022-12-20T16:07:43.000Z",
          "wordCount": 15604,
          "title": "Does anyone know a mirror (possibly p2p) of the cygwin time machine?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqrwi9/wd_drives_for_nas_20tb/",
          "author": null,
          "description": "Hello,\n Im currently using many 18tb drives in my synology ds1520+, Ds920 and Ds1522+ (still new experience with this one) And happy with the noise levels. Was about to upgrade one nas to 20tb using a wd sale assuming similar experience …however heard some chatter about some noise issues. Either the design of the drive itself isnt the same experience, or i heard theres some new feature around lubrication causing some noise?\n Anyway, anyone with low noise requirements upgrade any of their nas units to 20tb and been happy? If not why?\n    submitted by    /u/Jman5150mib  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqrwi9/wd_drives_for_nas_20tb/",
          "publishedOn": "2022-12-20T15:53:31.000Z",
          "wordCount": 15452,
          "title": "Wd drives for NAS, 20tb?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqrup0/need_some_help_with_a_drive_strategy/",
          "author": null,
          "description": "Ok... so I need some help here.\n I'm planning on upgrading my UNRAID setup.\n Currently I have 24TB total, 10TB free.\n I've got two newer 8TB drives as parity (one shucked, one WD Gold). The rest of the drives are junky sas/sata used drives from ebay 3TB each.\n These drives are all in a Supermicro CSE-846 case, Supermicro X9DR3-F mobo with Dual Xeon E5-2620's 2.00GHz\n I am moving to a single e5-2680v3, probably going to spring for a Fractal Define R5 (unless you have other recommendations?)\n ANYWAYS,\n So I'd like to basically rebuild the whole NAS while I'm at this. What does that mean? Well...\n I'm unhappy with the 3TB drives. They are too noisy and suck up too much power for what they are. I'd like to replace them with a couple 8 TB drives, or maybe even redo my parity setup?\n I really like having dual parity. I know it would be cheaper to just go to single parity but I feel like dual is worth it?\n I guess what I'm wondering is if I should upgrade my parity drives to 12-14TB, and then just buy at least one more 8 TB drive\n OR\n Just get 3 8TB drives and go from there.\n I REALLY won't need all the storage I currently have right away as I plan on reorganizing and starting my linux ISO collection from scratch, so I can slowly acquire drives as needed (outside of parity of course)\n ​\n Recommendations on strategy, specific drives, and cases would be super awesome!\n ​\n Thanks!\n    submitted by    /u/jamalstevens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqrup0/need_some_help_with_a_drive_strategy/",
          "publishedOn": "2022-12-20T15:51:19.000Z",
          "wordCount": 17056,
          "title": "Need some help with a drive strategy.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqrpqi/download_wiki_article_plus_cited_pages/",
          "author": null,
          "description": "So, I know downloading Wikipedia for offline viewing is possible, but is it also possible to download the cited articles/pages/etc? I wasn't sure if there's already a tool out there for this. Ideally macOS/Linux based.\n    submitted by    /u/machone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqrpqi/download_wiki_article_plus_cited_pages/",
          "publishedOn": "2022-12-20T15:45:37.000Z",
          "wordCount": 15790,
          "title": "Download Wiki article PLUS cited pages?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqr6r7/how_are_you_protecting_against_fire_and_water_can/",
          "author": null,
          "description": "Hi All, \n I'll begin by stating that all of my data is backed up off site and in the cloud. \n Now that that is out of the way...I'm wanting to protect what I keep in my office. I have 300+/- tb of data spread across single drives, raid enclosures, etc. I'd like to protect these from fire and water, but am struggling to find the right thing(s). \n As of now I'm looking at a fireproof safe for long guns, and adding shelves inside to stack things. But those are usually waterproof so I'm also looking at placing everything inside of waterproof boxes and then into the safe. \n Are there options I'm overlooking? Thanks for any help, insight, or experience.\n    submitted by    /u/LosinCash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqr6r7/how_are_you_protecting_against_fire_and_water_can/",
          "publishedOn": "2022-12-20T15:23:24.000Z",
          "wordCount": 17440,
          "title": "How are you protecting against fire and water? Can you recommend anything?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqqk80/folder_archiving_best_practices/",
          "author": null,
          "description": "Hi all thanks for reading.\n This is kindof a mixed post asking for some specific answers to get me on my way for this particular project, but also looking for resources to study up for the future. No pressure to run the gauntlet on all these questions, I am just grateful for any help you may offer.\n My lingering questions include:\n  \nIs it worth it to break a large archive into parts, or is it best to leave it as one archive? If its better to break it into parts, what is the best practice volume size all things considered? (I will have this archive backed up on mac, windows and linux machines, online, and will be distributed to a handful of people).\n \nIs there a in depth user level best practices resource on file compression? Something that outlines use cases i.e. best method for speed com…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqqk80/folder_archiving_best_practices/",
          "publishedOn": "2022-12-20T14:56:47.000Z",
          "wordCount": 17590,
          "title": "Folder Archiving Best Practices",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqnbko/why_did_you_start_hoarding_data_in_the_first_place/",
          "author": null,
          "description": "For me it was reducing my pile of 1000 blu rays to a 2.5inch HDD. Digital Storage is way cleaner and easier to handle than physical storage.\n    submitted by    /u/richiethestick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqnbko/why_did_you_start_hoarding_data_in_the_first_place/",
          "publishedOn": "2022-12-20T12:35:41.000Z",
          "wordCount": 19698,
          "title": "Why did you start hoarding data in the first place?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqmtqx/the_smart_dataset_is_a_great_resource_for/",
          "author": null,
          "description": "submitted by    /u/themadprogramer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqmtqx/the_smart_dataset_is_a_great_resource_for/",
          "publishedOn": "2022-12-20T12:12:52.000Z",
          "wordCount": 16134,
          "title": "The SMART dataset is a great resource for comparing device reliability",
          "imageUrl": "https://external-preview.redd.it/yVP3vwhETXXwiTW3Q1OCf1JgmWCic9hdHBizeQazgeE.jpg?auto=webp&s=3c6a322f1f79e7fff3d72ed8779ca3ecfcac0b43"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqm0no/probably_to_keep_track_of_my_archives/",
          "author": null,
          "description": "Hi, I was wondering if there was a program that helped people keep track of where are their backups in multiple places, whether they be high quality original data, or junk data that may be important... someday?\n I'd use Google Sheets and one of the programs that does a full directory search with hashes, but there's an issue.\n I simply don't have the self-discipline to use the peicemeal approach for long before giving up and just throwing things on my drives.\n So I know I need a program that at the very least holds my hand as I archive data, I was wondering if such a useful software might exist?\n    submitted by    /u/ElephantAmore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqm0no/probably_to_keep_track_of_my_archives/",
          "publishedOn": "2022-12-20T11:27:59.000Z",
          "wordCount": 16894,
          "title": "Probably to keep track of my archives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqaax6/how_to_backup_across_multiple_external_usb_devices/",
          "author": null,
          "description": "I have a 32T (total) UnRaid server. Never thought I'd fill up my 12TB USB external device as a backup. Now that its filled up, I would like to purchase another 12+TB external USB, but how do I not backup the already backed up files? \n Ideally, I would write all the backed up files to a text file, then tell 'rsync' to exclude all the files and directories in that file. Certainly I'm not the first one, so curious how others have done this? TIA\n    submitted by    /u/leonj1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqaax6/how_to_backup_across_multiple_external_usb_devices/",
          "publishedOn": "2022-12-20T01:33:07.000Z",
          "wordCount": 16742,
          "title": "How to backup across multiple external USB devices?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqa5al/does_anyone_have_a_iso_of_the_halo_2_i_love_bees/",
          "author": null,
          "description": "I have been looking for it for the past week now and i cannot find it.\n    submitted by    /u/StevenIsCool2004  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqa5al/does_anyone_have_a_iso_of_the_halo_2_i_love_bees/",
          "publishedOn": "2022-12-20T01:27:02.000Z",
          "wordCount": 16626,
          "title": "Does anyone have a ISO of the Halo 2 I love bees disc?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqa55x/shucked_enclosures/",
          "author": null,
          "description": "Anyone have any shucked enclosures they would like to get rid of? OWC used to sell them, but I can't find them anymore. Looking for 3.5\" USB enclosures.\n    submitted by    /u/shumandoodah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqa55x/shucked_enclosures/",
          "publishedOn": "2022-12-20T01:26:53.000Z",
          "wordCount": 16667,
          "title": "Shucked Enclosures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq7v1u/is_it_possible_to_compress_videos_for_storage/",
          "author": null,
          "description": "I have about 25 TB of data which I want to store for potential use in the future. The way I see it is I have 2 options, with option 2 being uncertain around its possibility...\n ​\n Option 1: I painstakingly go through all my footage and delete anything I know I will never use.\n Option 2: Put all the footage into a folder and compress it down so that I can store it. With this option, I want to be able to decompress it in the future without losing any video quality whatsoever. \n ​\n Is option 2 possible?\n ​\n Thanks in advance!\n    submitted by    /u/iscottjones  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq7v1u/is_it_possible_to_compress_videos_for_storage/",
          "publishedOn": "2022-12-19T23:54:22.000Z",
          "wordCount": 16570,
          "title": "Is It Possible To Compress Videos For Storage Without Losing Quality When Decompressing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq6g22/external_hard_drive_goes_to_sleep_if_i_do_not/",
          "author": null,
          "description": ".\n    submitted by    /u/nbcs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq6g22/external_hard_drive_goes_to_sleep_if_i_do_not/",
          "publishedOn": "2022-12-19T22:59:05.000Z",
          "wordCount": 17191,
          "title": "External hard drive goes to sleep if I do not access any files within 20s. Is it normal? And if it is normal, then is it healthy for the drive if I have a program that automatically writes an empty file every 10s to prevent it from going to sleep?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq5u2p/im_not_smart_enough_to_know_whatwhere_to_start/",
          "author": null,
          "description": "I know, I'm sorry. I tried looking but frankly I just don't even know what I'm looking for. Sorry. \n I want to have a folder on my computer that my father in a different state can also access and add to. We're trying to share about 2Tbs of STLs and DnD stuff into a single working folder that we can both access. Is this possible? \n I initially tried creating a google drive and sharing it with my dad, but that didn't work out like we had hoped. We'd rather not spend $10 each to share files with each other. \n Again, sorry. I tried looking myself, I searched the internet, but I don't know what to even search to find a solution and I need someone smarter to help point me in the right direction.\n    submitted by    /u/running_in_spite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq5u2p/im_not_smart_enough_to_know_whatwhere_to_start/",
          "publishedOn": "2022-12-19T22:34:32.000Z",
          "wordCount": 18072,
          "title": "I'm not smart enough to know what/where to start looking for answers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq4xjk/what_are_some_good_alternatives_to_cyberduck_on/",
          "author": null,
          "description": "Before everyone starts saying rclone, please read on.\n Currently I use cyberduck along with carotdav to upload files to google drive. I am not looking to mount it as a drive or to setup sync. I want to manually upload different files from different directories at different times manually. I need it to be able to drag and drop to upload multiple files (which I wasn't able to do with rclone browser and I don't want to upload it as a folder, correct me if I'm wrong)\n My current issue with cyberduck is for some reason, it uses much more CPU compared to other programs. The issue with carotDAV is it only upload files one by one even if you dump in a bunch of files, which I cannot max out my connection.\n To what I understand, rclone doesn't fit my needs. If anyone knows how to setup rclone to work like I how I need it, I would happily use rclone. Filezilla Pro doesn't have a trial so I can't test how well it would work for me.\n ​\n Are there any alternative programs on windows for this use case or how do I properly setup rclone for this use case? I'm ready to learn.\n ​\n Thanks.\n    submitted by    /u/chorong761  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq4xjk/what_are_some_good_alternatives_to_cyberduck_on/",
          "publishedOn": "2022-12-19T21:59:55.000Z",
          "wordCount": 17239,
          "title": "What are some good alternatives to Cyberduck (on windows) for uploading to GDrive? (please read before commenting rclone)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq4bv3/efficient_method_to_rip_5000_audio_cds_onsite/",
          "author": null,
          "description": "My dad passed recently, and he left behind a treasured collection of 5,000+ CD's. I'd like to archive it all as I have many fond memories of listening to them; MP3's are sufficient.\n I was originally thinking of setting up something similar to this, with many drives. Problem is my main machine which has the space and processing power is at my own home; moving either the machine or the CD's between my house and my dad's isn't practical, and the work involved in setting it up starts to sound blocking.\n I also considered just cataloguing them and feeding that into a torrent/Usenet/purchasing script, but many of these are old and do not exist online (and are not sorted), so that doesn't sound any faster.\n How do you suggest I go about this? I'm open to jerry-rigging something together, buying a commercial solution, etc, just not sure what's most efficient. My biggest constraint is I don't get much time at his house, so I want a solution with a high CD throughput. Should I just be ripping images, and then transporting those to my own home for transcoding/tagging/etc?\n Thanks all!\n EDIT: As many of you have mentioned, tagging and metadata is a big problem, especially since many of these CD's have no online presence and can't be auto-tagged. Since the CD's aren't sorted (and I don't want to upset the physical state of things too much), retrieving a disc after ripping isn't feasible. So whatever strategy is used needs to record disc data (e.g. photographs of the case) when it's ripped.\n    submitted by    /u/Gatherix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq4bv3/efficient_method_to_rip_5000_audio_cds_onsite/",
          "publishedOn": "2022-12-19T21:36:39.000Z",
          "wordCount": 20481,
          "title": "Efficient method to rip 5,000 audio CD's on-site?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq3k0o/looking_to_move_from_hetzner/",
          "author": null,
          "description": "I currently rent a 40tb box from Hetzner for around 50 euro a month, however the box is located hundreds of miles from my location so over a SMB connection tunnelled over a VPN product i'm only hitting about 4-6mb/s when my home network connection is 120mb/s. The server has about 20TB of data on it at the moment\n ​\n I do have a server locally with Proxmox installed, however the high capacity drives are out of my price range at the moment\n ​\n Is there anything I can do to improve throughput? I thought about getting a cloud storage solution and mounting it via SMB or some other protocol to a Linux machine within my Proxmox however I'm unsure what solutions are available to me apart from buying high capacity drives and then cloning the Hetzner box\n ​\n I would ideally like to stream old game ROMS to emulators and such via the solution\n    submitted by    /u/sadboy2k03  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq3k0o/looking_to_move_from_hetzner/",
          "publishedOn": "2022-12-19T21:06:21.000Z",
          "wordCount": 16887,
          "title": "Looking to move from Hetzner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq3cbe/tips_for_my_bad_drive/",
          "author": null,
          "description": "I finally received a dud drive. Never happened before to me. Sold and shipped by newegg, the 16TB Seagate EXos drive I received wouldn't even spin up. It was packed decently well but I guess not well enough. I have to wait until tomorrow to start the return process. \n Originally I thought it must be a bum external drive dock so tried popping it in my single drive synology to test and it wouldnt show up at all. Glad I didnt jump straight into degrading the pool it is supposed to go into.\n Are there any tips for making sure I get a replacement quickly and efficiently? I am planning on returning the drive to newegg under the replacement option rather than RMA through Seagate.\n    submitted by    /u/haloid2013  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq3cbe/tips_for_my_bad_drive/",
          "publishedOn": "2022-12-19T20:58:27.000Z",
          "wordCount": 16273,
          "title": "Tips for my bad drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq3aej/reddit_archive_simular_to_ihsoyct/",
          "author": null,
          "description": "I don’t particularly enjoy socialgrep and ihsoyct seems to be down. Anyone have an answer lol\n    submitted by    /u/Impressive_Bass_1537  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq3aej/reddit_archive_simular_to_ihsoyct/",
          "publishedOn": "2022-12-19T20:56:18.000Z",
          "wordCount": 16480,
          "title": "Reddit Archive Simular To Ihsoyct?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq2srv/downsides_to_a_renewed_drive_and_a_3rd_party/",
          "author": null,
          "description": "Are there any downsides to using a renewed drive like this and a 3rd party enclosure like this as long as precautions are taken such as running the drive to check for bad sectors and runtime.\n    submitted by    /u/klnadler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq2srv/downsides_to_a_renewed_drive_and_a_3rd_party/",
          "publishedOn": "2022-12-19T20:36:58.000Z",
          "wordCount": 16425,
          "title": "Downsides to a renewed drive and a 3rd party enclosure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq2kaw/external_usb3_case_vantec_inateck_ugreen_or_which/",
          "author": null,
          "description": "Hi everybody,\n have you got some experiences with the kind of items in the title?\n There are tons of models for each vendor and except vantec I dont know others. I've seen some vantec products - I have and old pata nexstar, it's still doing the job when needed), but some amazon clients' online reviews seem to say that old quality has gone (and they cost 3x, compared with other firm).\n I had two sabrent but after a couple year, one after another, stop to work.\n Plus: they should work good with linux and ssd disks, some chip may have trim problems (sob). It seems so complicate build an external 2.5 usb disks (I dont trust the ones sale by wd or seagate or toshiba... there are hdd smr disk; I also prefer to not buy a \"usb ssd\" like Sandisk Extreme, because they are a finished product and I cannot shuck them or change the disk, if needed).\n Some one of you has tested / evaluated these case? Should I evaluate a solution like the FANTEC QB-35US3R. Please note I would not buy a NAS, I have already have enough pc (family says...) and they are too expansive.\n Thanks a lot for reporting you experiences!\n ​\n ----\n edit: added the fantec paragraph.\n    submitted by    /u/wireless82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq2kaw/external_usb3_case_vantec_inateck_ugreen_or_which/",
          "publishedOn": "2022-12-19T20:27:40.000Z",
          "wordCount": 17971,
          "title": "external usb3 case: vantec, inateck, ugreen or... which one? No sabrent please, I've already had bad experiences with them.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq1vy9/these_be_dead_right_dont_use_them_any_more/",
          "author": null,
          "description": "submitted by    /u/skeptibat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq1vy9/these_be_dead_right_dont_use_them_any_more/",
          "publishedOn": "2022-12-19T20:01:10.000Z",
          "wordCount": 16678,
          "title": "These be dead, right? Don't use them any more?",
          "imageUrl": "https://preview.redd.it/f7mmndvtuw6a1.png?auto=webp&s=d161aa9dc58f3b8a269ebf5aacaf460184b3d81c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq1oer/got_this_lto5_drive_off_ebay_inside_of_it_is/",
          "author": null,
          "description": "How would I go about cleaning this out properly? I figured all this dust cant be good for the tape or the drive\n    submitted by    /u/JustKeKe23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq1oer/got_this_lto5_drive_off_ebay_inside_of_it_is/",
          "publishedOn": "2022-12-19T19:53:36.000Z",
          "wordCount": 15421,
          "title": "Got this LTO-5 Drive off eBay, inside of it is pretty dusty",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpykxu/are_nas_drives_not_overkill_for_desktop/",
          "author": null,
          "description": "i am quite out of the loop with computer technology, with reliable brands and etc. my computer is from 2011, and will only be ugraded in 2025 when windows 10 dies. but i do need hard drives as i am running out of space.\n i tried searching but could not find a simple and realistic comparrison showing that NAS disk are really better for desktop storage.\n it's mostly for flac and wave music, png, svg and jpg images and mkv, avi and mp4 movies going to migrate to (03) 4tb hard disks , so actually i need to buy 6 for backup reasons, \n i keep hearing i should buy the seagate ironwolf instead of barracuda, and begs the quesiton if its not overkill? with 6 drives i would spend u$ 120 more with ironwolf. from what i read NAS drives are made to run hot and not get affected from vibrations. isn't that because nas drives are all cramped together in a tiny box?\n so in a big server case both vibrations and temperature will not be a concern right?\n my computer runs rather cold, hard disks usually around 30~35 celsius, (a big old server case from the 2000's) \n thanks!\n ps: not raid, just manual backup using software that does incremental copy\n    submitted by    /u/vanderzee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpykxu/are_nas_drives_not_overkill_for_desktop/",
          "publishedOn": "2022-12-19T17:58:59.000Z",
          "wordCount": 16954,
          "title": "are nas drives not overkill for desktop?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpwmt5/gallerydl_twitter_is_there_a_way_to_skip_all/",
          "author": null,
          "description": "I've been using gallery-dl to download media and metadata for a list of people I follow. However, despite using an archive file, it still iterates through their entire tweet history. It does skip downloading old tweets, but I'd rather it just get everything new and then move onto the next URL once it encounters a tweet it already has. That would save me a TON of time (and rate limits).\n All the documentation and suggestions I've found thus far involve skipping downloads, which it's already doing.\n Also, since moving to a new computer and setting things up again, files it already downloaded are displaying as ./gallery-dl/twitter/[user]/? in the terminal output instead of showing the filenames. Not sure why that is happening.\n Config is below. Any suggestions?\n { \"extractor\": { \"twitter\": { \"cookies\": { \"auth_token\": \"[redacted]\" }, \"archive\": \"~/twitter/archive-twitter.sqlite3\", \"postprocessors\": [ { \"name\": \"metadata\", \"event\": \"post\", \"filename\": \"{tweet_id}.json\" } ], \"expand\": false, \"cards\": false, \"quoted\": false, \"retweets\": false, \"text-tweets\": false, \"unique\": true, \"videos\": true, \"timeline\": { \"strategy\": \"media\" } } } } \n I run with the following command: gallery-dl -c ./gallery-dl.no-text.conf -i urls.txt\n    submitted by    /u/turaiel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpwmt5/gallerydl_twitter_is_there_a_way_to_skip_all/",
          "publishedOn": "2022-12-19T16:47:08.000Z",
          "wordCount": 17121,
          "title": "[gallery-dl / Twitter] Is there a way to skip all remaining tweets for a user once everything new has been collected?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zptm0k/wd_mycloud_ex2_ultra_max_capacity/",
          "author": null,
          "description": "Surprisingly few sources on this - officially WD say it's 16 TB, which after some time magically became 20 TB on a 2-bay NAS.\n I don't get what's imposing the limitation though - it's the same controller, same power - what is there to stop me from putting 2x 16 TB drives in there? Or is it just a hard-limit set by WD for whatever reasons and the NAS simply will not boot with such drives?\n One theory is that the \"advertised\" capacity is what it is, going by the maximum available HDD size at that time. I can't confirm that though.\n I'd like to find out if maybe someone's already tried it before I buy the drives. Thoughts ?\n    submitted by    /u/Teacan83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zptm0k/wd_mycloud_ex2_ultra_max_capacity/",
          "publishedOn": "2022-12-19T14:51:09.000Z",
          "wordCount": 16641,
          "title": "WD MyCloud EX2 Ultra - max capacity ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zptksv/is_there_a_way_to_download_tv_tropes_for_offline/",
          "author": null,
          "description": "Hello everyone!\n Recently, I've learned about the Kiwix project that lets you download valuable sites completely in one \".zim\" file that can be browsed offline. I found several interesting zims in the Kiwix library, such as ArchWiki, StackExchange, AllTheTropes. I wonder, is there a way to have a local TV Tropes copy for offline browsing?\n    submitted by    /u/ChrysoliteAzalea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zptksv/is_there_a_way_to_download_tv_tropes_for_offline/",
          "publishedOn": "2022-12-19T14:49:55.000Z",
          "wordCount": 16861,
          "title": "Is there a way to download TV Tropes for offline browsing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zptkha/cloud_storage_wo_install/",
          "author": null,
          "description": "Howdy, fellow hoarders!\n I'm looking for a solution to use to store about 2 TB of data (family photos and videos backup) online that does not require me to install an application to do so.\n I've looked at some of the other posts here and have an idea of the major suppliers already, but not which ones offer an option to just map a drive (open to any protocols sorted by linux).\n Does anyone else have this use case and doing this with a provider, please?\n Ideally I'll go with the cheapest cost/year. I don't want nor need anything fancy, just storage space I can map to have another backip of family photos and videos. \n Thank you in advance.\n Ps- I asked iDrive and tgey responded that I must have their app installed.\n    submitted by    /u/trancekat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zptkha/cloud_storage_wo_install/",
          "publishedOn": "2022-12-19T14:49:33.000Z",
          "wordCount": 16828,
          "title": "Cloud Storage w/o Install",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpt6es/long_term_storage_ssds_vs_hdd/",
          "author": null,
          "description": "I make this post to get an update of current state of the storage technology and also seek to find answer for wheather i should make backups to HDDs vs SSD.\n Current Situation:- I have around 500 gb of Family photos from 2001 on a Seagate external HDD, it lasted for 7 years and data is well and good right now.\n I already have backups on 2 different machines and the external HDD. It's now time again to migrate my external HDD to new Hardware and I am conflicted on what should I choose moving further.\n Until now my photos have been jumping CDs to HDD and I am at a crossroads again weather to switch from HDD to SSD or HDD are still better for cold storage long term.\n I did fair bit of research and I am aware Optical Media would be my best bet, namely M Disk or BD disks. Unfortunately where I live I cannot source them reliably and affordably enough.\n I browsed reddit threads from past few years. Like this from 2 years ago which says SSDs are better.\n I have consistently found a narrative that newer SSDs are better alternative than HDDs.\n My primary concern is not number of read writes in SSDs. Often they are in 100s of TBW which I presume I won't hit because of the nature of my storage needs.\n I fear data corruption and chip failure rather than running out of read writes.\n The disk I chose weather SSD or an HDD will probably be left on shelf with about twice a year plugging into PC to add new photos.\n What do you guys think would be a good choice ?\n Should I keep moving forward with a new HDD or are SSD a smarter choice?\n Whatever I choose I would probably rely on for at least next 4-5 years, with backups of course.\n    submitted by    /u/alsu2launda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpt6es/long_term_storage_ssds_vs_hdd/",
          "publishedOn": "2022-12-19T14:33:25.000Z",
          "wordCount": 20936,
          "title": "Long term storage: SSDs vs HDD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpg3d8/aws_storage_without_egress_chargesan_intended/",
          "author": null,
          "description": "All AWS storage products charge outrageous egress fees, to the extend that backing up to AWS doesn't seem feasible for me. It's like Hotel California: upload is free, storage cost is okay, but you want your data back? Payback!\n For example: s3 glacier us-east-1: $0.0036 per GB + $0.09 per GB egress (for first 10tb).\n https://aws.amazon.com/s3/pricing/\n So if I backup 10 tb to aws and download it back at end of 1 year, it'll cost (0.0036 * 1024 * 10 * 12)+(0.09 * 1024 * 10)=442+921, i.e. 67% of my expense goes to egress. \n I'm like...no f way. Until I saw something else they offered: workdoc! Apparently there's no charge on egress. I reread it trice but yeah. $5 per user with 1tb included. You can allocate more storage per user but that'll cost more than creating a second user, so just create 10 users. That works out to 5 * 10 * 12=$600, less than half of glacier, and you don't have to wait 12 hours. Oh and there's a web gui.\n https://aws.amazon.com/workdocs/pricing/\n Are they doing this to compete with gdrive? I cannot imagine they omitted egress charges by mistake.\n    submitted by    /u/lmux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpg3d8/aws_storage_without_egress_chargesan_intended/",
          "publishedOn": "2022-12-19T03:00:09.000Z",
          "wordCount": 16731,
          "title": "AWS storage without egress charges...an intended loophole?",
          "imageUrl": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?auto=webp&s=8e3eb77ba905bb641af80fcf3efe1de0190ac8c2"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpdnok/looking_for_storage_softwareplatform/",
          "author": null,
          "description": "Just wasted a day messing about with UNRAID to realize it's limited to 30 drives. :-/\n I have a sizable pile of 5TB, 4TB, 3TB and 2TB drives. I live somewhere where power is cheap and cooling is fresh air for 9 out of 12 months. I have JBODs and \"IT\" flashed controllers to run more than I have. All told, it's around .5 PB... someday, I'd like to break the PB barrier, but today is not that day.\n Can someone recommend a single software platform to support various disk sizes, reasonable (N+2) resillency and easy growth/failure replacement?\n UNRAID, too few disks. TrueNAS, would need a seperate pool for each disk size, replacement blows. I know next to nothing about OpenMediaVault but am going to fire that up here soon to poke about. I see people complaining about NFS speeds, but in general, I don't need this to be super fast.\n I run a plex server (I actually won't run that as a plugin, even if the platform supports it) that servers up and transcodes 4K HDR content, a few infrastructure VMs and some game servers, but outside of my plex server being a consumer of large disk, I don't have significant performance needs. My VMs I'll either run local or if I feel the need to go back to multiple VM hosts, I'll come up with something seperate from my bulk storage.\n Thanks for perusing my wall of text. Curious what other folks are using for large drive count systems. \n I'll head off the \"12TB refurbs are cheap\" response with \"there's nothing cheaper than what you already have.\"\n    submitted by    /u/Thranx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpdnok/looking_for_storage_softwareplatform/",
          "publishedOn": "2022-12-19T01:02:33.000Z",
          "wordCount": 16039,
          "title": "Looking for Storage Software/Platform Recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpd7sa/pair_of_shucked_20tb_wd200edgz_wd_elements_drives/",
          "author": null,
          "description": "Just moving my Unraid server across to new hardware based around an ASRock Z790 Pro RS MoBo (have flashed the latest stable BIOS). \n I originally set up Unraid last month on an old/ repurposed Xeon based Thinkserver TS140.\n I moved the drives across (6TB Seagate, 8TB Seagate, 10TB WD, 18TB WD)\n Plus I'd been running the 2 x 20TB WDs unshucked as the parity drives via USB, so I shucked these and put them in the new case as I now have the PSU and drive bays to handle them.\n When I first turned the new PC on, only the Seagates were detected, both in BIOS & Unraid.\n So I tried taping pin 3 on the WD drives. The 10TB & 18TB are now being detected in BIOS & Unraid, but the 20TBs still aren't being detected.\n The Thinkserver was running in Legacy BIOS mode. The ASRock doesn't have a legacy option (that I can find), so is running as UEFI. Would that affect this?\n Any suggestions of something else I can try to get the 20TBs working?\n Are others using these drives with a recent UEFI only motherboard?\n    submitted by    /u/ceestars  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpd7sa/pair_of_shucked_20tb_wd200edgz_wd_elements_drives/",
          "publishedOn": "2022-12-19T00:41:22.000Z",
          "wordCount": 15704,
          "title": "Pair of shucked 20TB WD200EDGZ WD Elements drives not detected with new motherboard, even with pin 3 masked",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpbwmp/should_i_keep_using_this_external_hdd/",
          "author": null,
          "description": "The sequence of events:\n  \nI have this hdd (TOSHIBA HDTB420EK3AA) and i want to use it to backup some internal drives on a desktop. I write a bash script to do this, i mess up, i corrupt the data, and i have to format it. \n Trying to format this thing makes my pc freeze so badly i have to hard reset. I try the same with other machines, and different operating systmes, each one freezing aswell. The winner is an old laptop on lubuntu that manages to successfully format the drive in just over an hour. \n I go back to the first desktop and modify the script, i run it and it kinda works. By looking at rsync output i notice that the average speed is 500 kb/s, reaching 40kb/s at some points. At some point it starts copying an .IPCH file that makes it reach 0 byte/s and then nothing. \n I decide to exclude this file and other folders containing very large amount of small files, since it looks that the speed slows down especially in these cases. For what i know HDDs are ass in this type of operations but this is just ridiculous. \n So i stop the rsync, and everything freezes again. I can't even open the file explorer. I boot windows and use diskpart this time, then i install DiskInfo.\n \n https://preview.redd.it/20pxjo5urq6a1.png?width=670&format=png&auto=webp&s=5f70d06a653ae8e4fda4bbd6e43376a6e578c157\n To me it looks very ok, but in the 20 minutes it took me to write this, diskpart managed to go from 0% to 2% in the process of formatting the disk. \n The disk is almost factory new, but i can't send it back anymore. Any ideas?\n    submitted by    /u/Cute_Rub_9074  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpbwmp/should_i_keep_using_this_external_hdd/",
          "publishedOn": "2022-12-18T23:40:57.000Z",
          "wordCount": 17424,
          "title": "Should i keep using this external hdd?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpapw6/coldonly_storage_solution_with_database_indexing/",
          "author": null,
          "description": "Aloha! Among other things I'm a YouTube archivist on Linux system, with lots of videos to store, lots of HDDs of varying sizes, capacity (80-500GB) and age (several disks with BAD sectors that I wanna use as 3rd data duplicates). Then I have a single gaming PC with 2 HDD hotswap ports free. I'm looking for a hoarding setup solution, some guidance towards tools maybe? How could I improve my operation in relation to my low knowledge levels?\n How I have it running currently, is I have a 1TB inside the PC that acts as \"landing\" for incoming data, which I manually process (rename, move around, compare files, remux), then I connect HDDs that I decide should pick them up. I keep track of all data in LibreOffice Spreadsheet: on HDD arrival I sometimes measure its SMART data and update it in the sp…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpapw6/coldonly_storage_solution_with_database_indexing/",
          "publishedOn": "2022-12-18T22:47:57.000Z",
          "wordCount": 16135,
          "title": "Cold-only storage solution with database indexing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpancs/using_vpn_to_bypass_file_hoster_limits/",
          "author": null,
          "description": "Hello internet,\n I commonly use sites like keep2share to download files and have been using mullvad to bypass data limitations. Some videos are broken into multiple parts and I often pull my phone out to download simultaneously.\n I was wondering if there was a more efficient way to do this from one device and if I could do something like linking different browser windows to different IP addresses. I am constantly downloading files and am perfectly fine with the time investment it may take to set something like this up.\n I thought of Jdownloader but I think that uses proxies versus a VPN correct? \n Sorry for the newbie questions\n    submitted by    /u/ForeignEfficiency401  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpancs/using_vpn_to_bypass_file_hoster_limits/",
          "publishedOn": "2022-12-18T22:44:45.000Z",
          "wordCount": 15736,
          "title": "Using VPN to bypass file hoster limits",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpafii/this_christmas_i_join_you_15tb_strong/",
          "author": null,
          "description": "Will be building my first server rack using spare parts and new parts with about 10TB new storage in addition to my pc’s original 5TB. Will be using a spare BM450 motherboard, any recommendations for the CPU?\n    submitted by    /u/Op2-0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpafii/this_christmas_i_join_you_15tb_strong/",
          "publishedOn": "2022-12-18T22:35:06.000Z",
          "wordCount": 16538,
          "title": "This Christmas I join you 15TB strong!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp8uag/i_am_trying_to_view_my_older_youtube_history_from/",
          "author": null,
          "description": "submitted by    /u/Kristiangarzon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp8uag/i_am_trying_to_view_my_older_youtube_history_from/",
          "publishedOn": "2022-12-18T21:24:58.000Z",
          "wordCount": 15598,
          "title": "I am trying to view my older youtube history from 2017, 2018 etc, But it only goes back to August of 2020, Not sure if I paused/deleted my history at all, Is there any solution to fix this and retrieve my old history??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp7foz/fastest_way_to_go_about_calculating_hamming/",
          "author": null,
          "description": "I feel like I'll know what the unfortunate answer is, but the million dollar question is has anyone found a fast way to calculate the hamming distance between a very very very large set of hashes?\n I have a dataset (that will continue to grow) that I'm planning on granting limited access to the public via way of allowing the user upload an item, then the server checks against the database of hashes, and shows information from similar hashes. The issue is that the database of hashes will be over 500 hundred million.\n From my understanding of finding similar/identical content, hamming distance is the fastest approach in calculating the difference between items? The issue I am seeing is that this must be calculated for each query? So the server is checking the 500 hundred million images each and every time someone wants to check?\n Is there any way to speed this process that I'm not seeing in my research? How do things like deduplication software, or reverse/similiar image searches work so fast? What's their secret? Just more compute and they're harnessing a shit ton of compute for each query? TinEye claims to be able to \"search a 57.6 billion web image index in real-time.\" but how?? This must be the KFC's secret herbs and spices or the Coke recipe and I'm just shit out of luck?\n    submitted by    /u/AdamLynch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp7foz/fastest_way_to_go_about_calculating_hamming/",
          "publishedOn": "2022-12-18T20:23:56.000Z",
          "wordCount": 17743,
          "title": "fastest way to go about calculating hamming distance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp6mi6/8tb_disks_unable_to_write_but_both_can_read/",
          "author": null,
          "description": "Hi everyone,\n Background: I have 2 external HDDs (WD My Book) bought from BestBuy. They have both been formatted as MacOS Extended or HFS+. I own both a Windows laptop and a Macbook Pro; I use my Macbook Pro more, which is why I chose an Apple filesystem. I have historically been able to write to both of these disks using both laptops (I use Paragon HFS+ to write to the disk using my Windows laptop; I've done this for 2 years now with various other hard drives). Both hard drives have only been in use for a few months; one is constantly used for file scraping, the other is purely for backup use... the file scraping one only started having problems 2 days ago. The backup hard drive started having problems 2 months ago. (I thought it was only a one-off thing, but seems to be a recurring issue…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp6mi6/8tb_disks_unable_to_write_but_both_can_read/",
          "publishedOn": "2022-12-18T19:48:57.000Z",
          "wordCount": 18022,
          "title": "8TB Disks Unable to Write But Both Can Read, CrystalDiskInfo says Health Status is \"Good\" (no %)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp6fxy/using_aws_s3_glacier_instead_of_building_a_nas/",
          "author": null,
          "description": "Hey all, I'm pretty new to actually organizing my storage. I have loads of stuff that I've collected through the years in several HDDs and SSDs, maybe a dozen or more in total. I was considering getting a NAS so that I can lower the risk of losing anything and also make everything accessible to me easily. \n What I'm most concerned about is availability/reliability. AWS guarantees 99,999999999%. That's not something you can get at home. There are so many ways to just mess up. The cost to scale is also very linear for AWS, compared to a home system.\n I have unlimited Internet already.\n    submitted by    /u/piponwa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp6fxy/using_aws_s3_glacier_instead_of_building_a_nas/",
          "publishedOn": "2022-12-18T19:40:52.000Z",
          "wordCount": 17817,
          "title": "Using AWS S3 Glacier instead of building a NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp6fr4/mediafire_bulk_downloader_site/",
          "author": null,
          "description": "i put a folder on media fire 613 files a while ago and removed it from my computer for some more space i cant redownload it because of the bulk download feture i will go insane please help\n    submitted by    /u/TheEurekaEffect_64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp6fr4/mediafire_bulk_downloader_site/",
          "publishedOn": "2022-12-18T19:40:38.000Z",
          "wordCount": 15449,
          "title": "mediafire bulk downloader site?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp66w9/ratehelp_my_backup_strategy/",
          "author": null,
          "description": "I'm working on trying to solidify my backup strategy. I do think it's fairly solid, but there are a couple things I know that I can do better. \n Current strategy: Centralized storage via Synology NAS (1621+ w/ 32GB ECC RAM) with btrfs. NAS snapshots hourly and maintains snapshot through typical pruning measures. NAS backs up to connected Seagate Backup 8TB drive and Backblaze B2 via Hyper Backup. NUC11 running Windows with read-only user connects to shares and backs up to connected external hard drive via Arq 7. Have rotational cold-storage via Arq as well. \n A couple things I'd like to fix: \n  \nNUC11 running Windows (will likely convert to Hypervisor of some sort, even if just HyperV), was part of a project.\n Potentially move the external drive hanging off of the NUC to an internal 2.5 HDD.\n Add a backup tool that is open source, even if it's just a cold backup. \n Potentially remove NUC11 in general, as I'm running less on it and have a beefy desktop, and far fewer full-time running services than I did. Would move the service or two to run off of the NAS. Though, this would mean trying to incorporate my desktop into initiating a backup process of some sort, potentially manually, which makes it less desirable.\n  \nThe amount of data that I would consider critical is very low, somewhere in between 200-300GB\n Any suggestions on how I could make this more solid?\n    submitted by    /u/StrongCommission  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp66w9/ratehelp_my_backup_strategy/",
          "publishedOn": "2022-12-18T19:29:43.000Z",
          "wordCount": 20651,
          "title": "Rate/Help My Backup Strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp5leo/mount_multiple_mega_accounts_as_drivesremovable/",
          "author": null,
          "description": "Title\n    submitted by    /u/Robotic8040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp5leo/mount_multiple_mega_accounts_as_drivesremovable/",
          "publishedOn": "2022-12-18T19:03:04.000Z",
          "wordCount": 17849,
          "title": "Mount multiple MEGA accounts as drives/removable storage on Windows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp569i/new_tech_job_found_a_box_full_of_hdd_boss_said_i/",
          "author": null,
          "description": "submitted by    /u/wicodly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp569i/new_tech_job_found_a_box_full_of_hdd_boss_said_i/",
          "publishedOn": "2022-12-18T18:44:00.000Z",
          "wordCount": 18062,
          "title": "New Tech Job! Found a box full of HDD. Boss said I can keep them. I’m happy",
          "imageUrl": "https://preview.redd.it/8uf4g6iqtq6a1.jpg?auto=webp&s=742f439986c868c421687ae06390ddd309ff173b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp4h3n/high_tbw_ssds_for_low_power_nas/",
          "author": null,
          "description": "I have a NAS for backup, media server, VMs, etc. It's only serving myself, so I don't like the idea of spinning 6+ spinning up drives up/down when I occasionally need to access a few media files daily when when I reboot for maintenance, testing, or just don't use it for maybe weeks at a time max.\n As I understand, SSDs rarely fail aside from reaching write limit, which is something measurable (and even then, I've heard of people having Samsung SSDs that are nearly twice the TBW that's in the spec). I don't plan on running RAID, since downtime and access to massive amount of data isn't important to me--instead, I prefer frequent incremental backups, occasional full backups, as well as longer life of drives and lower power consumption.\n I will only ever deal with 8-16TB worth of data I want online at the moment, rest is cold storage (combined total of ~100TB hard limit for the foreseeable, I only have 60TB data total). I prefer high TBW because performance is not important for me and backing up constant flow of new large media files is.\n Assuming high TBW SSDs are suitable for such a use case, what high TBW SSDs do you recommend? I was initially looking at Samsung SSDs because they are the gold standard in general, but I've come across Intel DC S3610 as a recommendation that is spec'd ~5x TBW more (10.7PB). I'm not normally one to look for used storage but people seem to have success with used ones from Ebay that are probably pulled from servers after their intended service and they usually a reasonable amount of remaining life at a great price. Unless these somehow fail in other ways, I don't see how they aren't very popular. This model is 7 years old though, so I'm thinking there might be better options (not necessarily price/TB).\n Any thoughts and suggestions are much appreciated.\n    submitted by    /u/rofic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp4h3n/high_tbw_ssds_for_low_power_nas/",
          "publishedOn": "2022-12-18T18:12:10.000Z",
          "wordCount": 17127,
          "title": "High TBW SSDs for low power NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp4gac/is_it_possible_to_transfer_files_from_an_external/",
          "author": null,
          "description": "Title.\n    submitted by    /u/-Sh33ph3rd3r-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp4gac/is_it_possible_to_transfer_files_from_an_external/",
          "publishedOn": "2022-12-18T18:11:04.000Z",
          "wordCount": 15322,
          "title": "Is it possible to transfer files from an external SSD to Google Drive without first having to download them on your PC/smartphone?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp3w62/need_help_reading_an_old_msdos_hdd/",
          "author": null,
          "description": "Hello! I recently got an old Toshiba T1000LE from a relative. Unfortunately I opened it up and there are a lot of bad caps and corrosion on the main board, but the hard disk seems fine (model is JVC JDE2825P30-7, a standard 2.5\" IDE) so I removed it from the machine to recover the files.\n Problem is my w10 computer can't seem to recognize or read anything from this drive. Assuming it's still working (it powers on and spins up) is there a way to recover files on it? Or to make it readable?\n I usually do this procedure for machines that mount more recent os (from w95 on) so I'm not really practical with hard drives this old. Original computer mounts MS-DOS 3.3, it's from 1990, the HDD is 20 mb.\n Thanks a lot in advance!! \n https://preview.redd.it/x7zdvrye0p6a1.jpg?width=1280&format=pjpg&auto=webp&s=357cf72c82ea79c06e142584216efcc84d99373b\n https://preview.redd.it/j47n1vye0p6a1.jpg?width=1280&format=pjpg&auto=webp&s=713c08f17d28faa6f003696c04b2a57c50bbdceb\n https://preview.redd.it/n3tkhtye0p6a1.jpg?width=1126&format=pjpg&auto=webp&s=c0b4c0ce66bd197097ad93e302cbf0e74543e655\n    submitted by    /u/Ska_arj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp3w62/need_help_reading_an_old_msdos_hdd/",
          "publishedOn": "2022-12-18T17:43:05.000Z",
          "wordCount": 16189,
          "title": "Need help reading an old ms-dos hdd",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp3qv8/how_much_does_just_reading_data_from_hddssd/",
          "author": null,
          "description": "I'm seeding torrents and always wondered how this affects lifetime of hard disk?\n    submitted by    /u/Bear_with_a_hammer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp3qv8/how_much_does_just_reading_data_from_hddssd/",
          "publishedOn": "2022-12-18T17:35:19.000Z",
          "wordCount": 17043,
          "title": "How much does just reading data from HDD/SSD affect their life compared to writing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp3oml/trying_to_obtainconvert_files_of_obscure_songs/",
          "author": null,
          "description": "hi! so i have what i think is a pretty obscure question/problem to (hopefully) solve lol. there are some songs i downloaded on apple music earlier this year by a certain artist, and recently (i'm not sure exactly when, but within the last few weeks) that artist removed some of those songs (their earliest releases) from all streaming platforms, rendering me unable to play them on my computer or phone.\n ordinarily, if this happened (and i've certainly had it happen before) i would just find those songs on the internet and download the files to reupload to my apple music library on my computer so i could continue to be able to listen to them normally, but in this case, the artist isn't well known enough for their songs to be on any mp3 sites (trust me, i've checked) or soulseek, and if they w…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp3oml/trying_to_obtainconvert_files_of_obscure_songs/",
          "publishedOn": "2022-12-18T17:32:16.000Z",
          "wordCount": 17490,
          "title": "trying to obtain/convert files of obscure songs removed from streaming (potentially using apple music drm protected m4p files from time machine backup)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp2srs/wife_bought_me_a_10tb_drive_for_christmas_it_was/",
          "author": null,
          "description": "submitted by    /u/joebaes1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp2srs/wife_bought_me_a_10tb_drive_for_christmas_it_was/",
          "publishedOn": "2022-12-18T16:49:35.000Z",
          "wordCount": 16040,
          "title": "wife bought me a 10tb drive for Christmas, it was mislabelled at the factory and it's actually a 12tb drive!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp02be/how_do_you_name_your_tv_series_folder_and_files/",
          "author": null,
          "description": "Hi, I'm doing it in this way: I create a folder with the TV serie's name, then I create a folder foreach season, and there I put the files with the name of TV serie - episodie number - episodie title\n If the TV series name is for example \"DataHoarder\":\n DataHoarder/Season 1/DataHoarder - 1x01 - Episodie title.ext DataHoarder/Season 2/DataHoarder - 2x01 - Episodie title.ext \n I'm curious, which is your naming convention?\n    submitted by    /u/secon25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp02be/how_do_you_name_your_tv_series_folder_and_files/",
          "publishedOn": "2022-12-18T14:39:25.000Z",
          "wordCount": 16792,
          "title": "How do you name your TV series folder and files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zopioc/how_books_are_scanned/",
          "author": null,
          "description": "submitted by    /u/ReturnMuch9510  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zopioc/how_books_are_scanned/",
          "publishedOn": "2022-12-18T04:07:39.000Z",
          "wordCount": 17709,
          "title": "How books are scanned.",
          "imageUrl": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?auto=webp&s=453f126fde1ad0e9f21a2cd50134a5a072df752a"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zom4ik/hdd_enclosure_supporting_sata/",
          "author": null,
          "description": "I'm currently building a NAS and have an LSI SAS 9200 to support more storage (my NAS is a SSF optiplex). Are there any options for enclosures that I could connect a SAS-to-SATA cable to?\n    submitted by    /u/Similar_Source5962  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zom4ik/hdd_enclosure_supporting_sata/",
          "publishedOn": "2022-12-18T01:14:14.000Z",
          "wordCount": 15922,
          "title": "HDD enclosure supporting SATA?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zole6m/psa_check_your_new_drives_warranties/",
          "author": null,
          "description": "I ordered a bunch of hard drives over there last month with so many great deals. Some of these came from the WD Store - so I thought they would be okay. But I checked the warranties just to be safe\n Already expired. For two of them.\n I'd have been screwed if I found this out a year from now if they died. Make sure that doesn't happen to you! Test your new drives' warranties!\n    submitted by    /u/ThatFireGuy0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zole6m/psa_check_your_new_drives_warranties/",
          "publishedOn": "2022-12-18T00:43:03.000Z",
          "wordCount": 16374,
          "title": "PSA: Check Your New Drives' Warranties!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoj9z8/strange_problem_with_new_hdd/",
          "author": null,
          "description": "So I just received my new HDD (ULTRASTAR 4TB) It was working just fine and I did transfer some file on it. Then I turned off my pc, when I went to turn it on again it won't boot. It will keep having a black screen and as soon as I disconnect the data cable from my new HDD it will boot.\n I tried many times and I really don't understand what happened. I tried searching online but can't find a fix to my problem.\n Any idea ? \n P.s. I can see it in the bios Edit: I did boot my pc and then connected the sata to the HDD, it took a while but then it showed in disk manager as RAW. I still can't access it and anything I try to do to it takes forever and never gets done.\n Thank you !\n    submitted by    /u/Cris257  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoj9z8/strange_problem_with_new_hdd/",
          "publishedOn": "2022-12-17T23:16:24.000Z",
          "wordCount": 15988,
          "title": "Strange problem with new HDD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoj61l/very_loud_vibrating_hdd_should_i_replace/",
          "author": null,
          "description": "Been using a ST2000DM008 seagate 7200 rpm drive and didnt notice it was the source of the sound until recently.\n It constantly vibrates which creates enough sound alone to be heard from the room next to me. currently I am using cables as a cousion unscrewed as adding foam in between the case and hdd was ineffective but still makes a lot of sound\n Is this expected sound level I need to live with or something not right about it? I have another damages sector hdd but it doesbt vibrate that bad\n    submitted by    /u/Felyne1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoj61l/very_loud_vibrating_hdd_should_i_replace/",
          "publishedOn": "2022-12-17T23:11:25.000Z",
          "wordCount": 15930,
          "title": "Very loud vibrating HDD, should I replace?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoidr3/any_wellwritten_articles_andor_guides_on_a/",
          "author": null,
          "description": "I want a robust set-up for exactly three things:\n - Backing up my computer and lap-top. Right now, I use Acronis to back them both up to the same external hard drive and to the Acronis cloud.\n - Backing up very large (hundreds of GBs, into TBs) of .csv data. These are very large health-care database sets that I use professionally. Right now, I store them on an external hard drive (separate from the computer back-up one) and on Google Cloud Storage.\n - I would like to start a personal PLEX media server.\n I am new to home networking and data-hoarding but my ideal set-up would include some of the following features:\n - As much automation as possible. I have a desktop (hard-wired to network) and a laptop (WiFi). Ideally, my desktop backups will occur on a regularly scheduled basis and my laptop whenever on my home network and/or docked at home.\n - Robust to failure; I think I want on-site, off-site, and remote (cloud) back-ups.\n - The ability to access my storage remotely (i.e., access my PLEX server while traveling for work, etc.).\n I'm prepared to read a lot and make purchases and effort as necessary, I just can't figure out where to start, the sheer amount of information and terms are overwhelming.\n    submitted by    /u/catinyourwall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoidr3/any_wellwritten_articles_andor_guides_on_a/",
          "publishedOn": "2022-12-17T22:37:29.000Z",
          "wordCount": 16931,
          "title": "Any well-written articles and/or guides on a complete home data server set-up?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoi16k/elon_musk_is_trying_to_erase_this_wikipedia/",
          "author": null,
          "description": "submitted by    /u/aladdin_the_vaper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoi16k/elon_musk_is_trying_to_erase_this_wikipedia/",
          "publishedOn": "2022-12-17T22:22:24.000Z",
          "wordCount": 15737,
          "title": "Elon Musk is trying to erase this Wikipedia article from the internet. Join the discussion so the article can stay up",
          "imageUrl": "https://external-preview.redd.it/Od3-uHHgpWBdprrA80Hi-GVnNQZMgcSfL2oE-mBTJEw.jpg?auto=webp&s=0ed1afbd61166f5cf8eaeab98e63e5296174d939"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoi0cx/any_ideas_how_i_can_really_rename_my_flash_drives/",
          "author": null,
          "description": "I have some Sandisk Cruzer Fit usb flashdrives. I want to rename them for my TV. \"video\" \"audio\" \"pictures\" etc. When I rename them, the name still says Cruzer Fit in the properties in my PC and on my TV. \n I can get a new name to show on the computer when looking at my drives, but it's the Cruzer Fit that I am trying to change. \n Any ideas how I could do this?\n    submitted by    /u/synaptic-flow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoi0cx/any_ideas_how_i_can_really_rename_my_flash_drives/",
          "publishedOn": "2022-12-17T22:21:23.000Z",
          "wordCount": 1903,
          "title": "any ideas how I can \"really\" rename my flash drives? it's not working right.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zohn4h/case_suggestions_for_hybrid_build_gaming_pc_plex/",
          "author": null,
          "description": "I'm looking for a case that will hold at least 6 3.5\" drives while simultaneously holding a full gaming PC build. I won't be using liquid cooling so no need of a radiator. I don't want to do a separate build due to power consumption and physical space limitations. I'm the only one that uses the server so I don't need a separate NAS.\n I've been looking at the Fractal Design Define 7 XL but I'm not sure I like the price and the size. I don't really need 18 drives so I could do fine with something smaller but middle-ground options seem to be somewhat limited.\n I would also prefer light tempered glass to dark if possible and I definitely want a side window.\n Any suggestions?\n    submitted by    /u/-CJF-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zohn4h/case_suggestions_for_hybrid_build_gaming_pc_plex/",
          "publishedOn": "2022-12-17T22:05:50.000Z",
          "wordCount": 15627,
          "title": "Case suggestions for hybrid build (Gaming PC + Plex Server)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zohe44/advice_needed/",
          "author": null,
          "description": "TLDR: need help deciding on how to upgrade my system. 1: utilize JBOD W/ UnRaid 2: new server system (specs at bottom)\n Hey guys, I have been hoarding on a system I build last year which is utilizing Linux mint as the OS. It has served me well but I’m running out of space (seems like a common issue here) and only have enough sata connections and power for 2 more drives in the current case and configuration. When I set everything up I basically had no clue what I was doing and everything is all over the place and hard to find/archive my data. After about a year of researching what my needs/wants are I’m wanting to switch to running UnRaid on my system which would mean a complete wipe of everything as far as I understand. I am contemplating buying a second computer and setting everything up and then migrating over to it with the old system used as a back up for my important files. I found a local built NAS for sale for $400 (specs below) or can I utilize Unraid on a small HP computer and add drive via a usb JBOD?\n Processor: AMD FX 4300\n Motherboard: ASUS M6A97 (Supports DDR3 ECC memory)\n RAM: 16 GB (4X4GB) DDR3 ECC 1333Mhz\n Video Card: Nvidia Quadro 510S\n Dell PERC 710 RAID Card (Supports RAID 0,1,5,6,10,50)\n Hard Drives: 2x Samsung 860 EVO 500GB, 6x HGST 4TB HDD, and 1x Western Digital 6TB HDD.\n    submitted by    /u/Randomness54321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zohe44/advice_needed/",
          "publishedOn": "2022-12-17T21:55:18.000Z",
          "wordCount": 16219,
          "title": "Advice needed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoh72f/my_onn_256gb_external_ssd_died/",
          "author": null,
          "description": "I was using it as my SSD for my Ubuntu server and this morning my server was off and there screen was black. I restarted it and I keep getting an error message. I'm asking here because you guys might know how to check if an SSD is dead dead. I can't get any of my machines to read it. Is it dead dead?\n The error was literally \"error\"\n    submitted by    /u/TroothBeToldPodcast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoh72f/my_onn_256gb_external_ssd_died/",
          "publishedOn": "2022-12-17T21:46:50.000Z",
          "wordCount": 15801,
          "title": "My onn 256GB external SSD died",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoh0qa/current_state_of_desktop_use_drives/",
          "author": null,
          "description": "Hello,\n just wanted to ask around a little bit regarding regular home use drives that are currently available.\n I was looking to expand my regular PC storage with something like a 2TB drive. Then I noticed that my current 5y/o WD Blue 1TB did accumulate some bad sectors and image backup failed due to some read errors.So it was time to get a new drive not just to expand but to replace that drive. The use of this drive being as a secondary drive for installing programs and stuff that doesn't need SSD levels of speed, but certainly not just storing data long term.\n Looking into what drives are currently available I quickly came upon the SMR vs CMR debacle and noticed that all WD Blue drives above 1TB use SMR (same for larger seagate barracudas). I did some research on that and really heard so…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoh0qa/current_state_of_desktop_use_drives/",
          "publishedOn": "2022-12-17T21:39:22.000Z",
          "wordCount": 16723,
          "title": "Current state of desktop use drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zofor0/off_site_backup_solution/",
          "author": null,
          "description": "Hi reddit fam,\n ​\n I have a question that I could use some advice. I have a 4 bay Synology Nas with 32TB configured with RAID 5 I think, with 1 drive parity so I have 24TB of usable storage. I have over 20tb backed up to BackBlaze with retention of 14 days. I am paying like $140 a month right now. I also got a T-Mobile promotion which gives me 2TB + Unlimited Google Photos for $15 a month and since I use the 2TB for work, I thought it was a no brainer.\n ​\n I am wanting to change my offsite backup storage. I am thinking of purchasing another 4 bay NAS or building a cheap one, storing at my parent's business, which is a motel, and using that as a backup target over paying for BackBlaze. I was thinking of making it a bit beefier and having more storage so they can store their surveillance footage on the NAS locally and I can use it as a backup target. Curious on pros/cons of getting rid of BackBlaze and taking care of my own offsite backup.\n ​\n I have 2Gig up/down at my home, and my parents business has a 400/40 mbps internet connection.\n    submitted by    /u/Ready-Artist9285  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zofor0/off_site_backup_solution/",
          "publishedOn": "2022-12-17T20:42:29.000Z",
          "wordCount": 16371,
          "title": "Off Site Backup Solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zofj0k/repairing_hard_drives_with_bad_sectors_by/",
          "author": null,
          "description": "I set up a USB TTL connection to the serial port on some Seagate hard drives and managed to 'repair' some that had bad sectors (G-list entries) by issuing a low level format command that tested every sector. \n This process took twice as long as a normal erase or format and any sectors that were deemed unsatisfactory were placed into the 'resident G-list' (which is similar to the factory defect list aka P-list in that the sectors are skipped over rather than reassigned so there is no performance loss).\n One drive had only a handful of bad sectors while the other had a few thousand. I am wondering if these 'refurbished' drives are now 'good as new' or should still be sent to recycling.\n More info on Seagate terminal commands here. warning issuing the wrong command or making a typo could lead to data loss so do not connect to the serial port of a drive containing important data\n Note: this only works on older drives that do not have the serial port locked\n    submitted by    /u/denpa_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zofj0k/repairing_hard_drives_with_bad_sectors_by/",
          "publishedOn": "2022-12-17T20:35:26.000Z",
          "wordCount": 16530,
          "title": "Repairing hard drives with bad sectors by low-level formatting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zofdid/i_got_tds_reply_to_my_fcc_complaint_491gb_is/",
          "author": null,
          "description": "submitted by    /u/TheMonDon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zofdid/i_got_tds_reply_to_my_fcc_complaint_491gb_is/",
          "publishedOn": "2022-12-17T20:28:59.000Z",
          "wordCount": 19488,
          "title": "I got TDS' reply to my FCC complaint. 491GB is normal usage apparently.",
          "imageUrl": "https://preview.redd.it/ji8ql081qi6a1.jpg?auto=webp&s=1190681c8505556a9a4f4c47a6bb18f480e1ff1e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoex02/how_to_download_a_mod_page_off_nexusmodscom/",
          "author": null,
          "description": "I have about 300GBs of fallout 4 mods on my computer. Said mods are organized with the same folder structure thats on nexus. I want to download the mod pages for the mods that I own. How would I do That?\n    submitted by    /u/Coralsix25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoex02/how_to_download_a_mod_page_off_nexusmodscom/",
          "publishedOn": "2022-12-17T20:09:11.000Z",
          "wordCount": 16000,
          "title": "How to download a mod page off Nexusmods.com",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoes5z/gallerydl_is_unable_to_download_from_instagram/",
          "author": null,
          "description": "[instagram][error] HttpError: '401 Unauthorized' for 'https://i.instagram.com/api/v1/users/web_profile_info/' \n I was messing around in my config file trying to add the path to my cookies when I tried to download an Instagram story for testing. It did not work and now I can not download any Instagram page/media at all. What's up?\n    submitted by    /u/doll985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoes5z/gallerydl_is_unable_to_download_from_instagram/",
          "publishedOn": "2022-12-17T20:03:19.000Z",
          "wordCount": 16109,
          "title": "gallery-dl is unable to download from Instagram and prints following error",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zodwu5/do_larger_hdds_have_a_higher_chance_of_failing/",
          "author": null,
          "description": "I'm currently trying to decide between getting two Seagate IronWolf 4TB hard drives for extra pc storage or the 8TB IronWolf. I have heard many times that the larger the hard drive is, the higher chances it has of failing.\n How true is this statement and why is that the case if so? would I be better off buying the 4TB drives to last me the longest? Goal: To download movies/shows, pictures, music and other entertainment\n    submitted by    /u/overratedcabbage_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zodwu5/do_larger_hdds_have_a_higher_chance_of_failing/",
          "publishedOn": "2022-12-17T19:25:14.000Z",
          "wordCount": 17319,
          "title": "Do Larger HDDs have a Higher Chance of Failing ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zodvqm/got_a_used_wd_red_hard_drive_what_can_i_do_to/",
          "author": null,
          "description": "I've searched this question, but not sure what is the best one. I've seen crystal disk info and victoria, etc. Which one do most of you use here? My preference would be something that is open source. This is for a WD Red 8TB drive.\n    submitted by    /u/Wooden-Photo-2783  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zodvqm/got_a_used_wd_red_hard_drive_what_can_i_do_to/",
          "publishedOn": "2022-12-17T19:23:54.000Z",
          "wordCount": 16359,
          "title": "Got a used WD red hard drive, what can I do to make sure it won't fail and/or is in good condition?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zodap1/synology_nas_8x_savings_by_switching_to_glacier/",
          "author": null,
          "description": "Hi all. It's been a while since I've used Glacier, the last time it being such a pain I deleted my account just to get rid of it. It seems its usability has improved with its rework into S3 Glacier Deep Archive and when I just compared the pricing to the Synology C2 service I've been using for years to take care of my few TB of media, it's 8x cheaper! Not considering the hefty but rare to incur retrieval costs, of course.\n So far everything has been going swimmingly, my Synology NAS just configured to use the Glacier Backup app (first time I use it, so far used only Hyper Backup to Syno C2) service with a small test folder into my new AWS account. I know enough to be suspicious of Glacier, so I'd love you people's advice on a few points...\n VERSION CONTROL:\n If I have to full restore from backup, I want to restore to the last daily state I backed up, not every file I've ever had, so I've disabled the following:\n https://preview.redd.it/doxpu31g4i6a1.jpg?width=816&format=pjpg&auto=webp&s=3866059ae4ec6409c40c957d9fefa569f4d9b490\n Is VC something I'd be giving up, with only the last point to restore from unless I choose to never delete from Glacier locally deleted files? That would be a fatally flawed concept for retrieving accidentally deleted files!\n Currently I benefit from version controlled backups in C2, with deduplication making it possible to not pay insane amounts for that.\n MOVING FILES = DUPLICATION?\n When I move a folder around my NAS, does that schedule it for deletion in Glacier then recreate it next time a backup kicks off? If so, it could prove very pricy with Glacier's \"pay 3 months minimum\" storage model...\n Thanks in advance, I appreciate partial answers too, as well as advice about other Gotchas I may not have thought of!\n    submitted by    /u/Lycanka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zodap1/synology_nas_8x_savings_by_switching_to_glacier/",
          "publishedOn": "2022-12-17T18:58:11.000Z",
          "wordCount": 18154,
          "title": "[Synology NAS] 8x savings by switching to Glacier - too good to be true?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoagqo/just_a_reminder_if_you_own_directory_opus_it_has/",
          "author": null,
          "description": "Just wanna mention this cause I almost bought an extra software to do this when it's already in the default file manager I'm using. That said, it's only available in the Pro (paid) version.\n    submitted by    /u/AndalusianGod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoagqo/just_a_reminder_if_you_own_directory_opus_it_has/",
          "publishedOn": "2022-12-17T16:50:47.000Z",
          "wordCount": 18857,
          "title": "Just a reminder: If you own Directory Opus, it has a built-in synchronize function to mirror files between two drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoafd8/hard_drive_sounds_yes_they_sound_like_this_all/",
          "author": null,
          "description": "submitted by    /u/alexkidd4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoafd8/hard_drive_sounds_yes_they_sound_like_this_all/",
          "publishedOn": "2022-12-17T16:49:08.000Z",
          "wordCount": 18679,
          "title": "Hard Drive Sounds - Yes, they sound like this, all the time!! LOL",
          "imageUrl": "https://external-preview.redd.it/mKoApiBrIvG2bsWE3vnhxypnGrKHIwr4jvmnBJg4BHc.png?format=pjpg&auto=webp&s=c0d19d7e3bcd519eab1cc4d6c3c86d514fdc0f87"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoa8jl/10tb_seagate_exos/",
          "author": null,
          "description": "submitted by    /u/splago  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoa8jl/10tb_seagate_exos/",
          "publishedOn": "2022-12-17T16:40:28.000Z",
          "wordCount": 16206,
          "title": "10/TB Seagate EXOS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zo88pg/hp_ultrium_920_lto3_scsi_firmware_upgrade/",
          "author": null,
          "description": "Hey Hoarders,\n Recently I've purchased two HP Ultrium 920 tape drives with a single IBM lto-3 ultrium tape. One of those drives accepted my LTO tape, but got fried shortly afterwards (remember kids, modular power supplies can have mirrored 12V-5V if you're not using original cabling~ ) The second one powers up fine, but rejects the tape, basically, ejects it few seconds after inserting it and flashes the \"Tape\" LED.\n I'm thinking that aside from worn out drive it might be the cause of old firmware. I was wondering if anybody has that firmware. HP has the download blocked behind extended support.\n ​\n HP Library and Tape Tools sees the drive as below:\n  \nProduct ID : Ultrium 1-SCSI [HH] \n Drive Technology : LTO \n Mech. Serial Number : HU10927KPF \n Firmware Rev : P61D/Standalone \n Target ID : 3 \n Target LUN : 0 \n OBDR Capability : Supported \n WORM Capability : Not Supported \n Firmware : P61D\n  \n   submitted by    /u/Arszerol  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zo88pg/hp_ultrium_920_lto3_scsi_firmware_upgrade/",
          "publishedOn": "2022-12-17T15:08:56.000Z",
          "wordCount": 16453,
          "title": "HP Ultrium 920 LTO-3 SCSI firmware upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znufp4/google_workspace_storage_dashboard_no_longer/",
          "author": null,
          "description": "Went to check my Workspace storage dashboard out of curiosity to see how much I was using and I noticed that the previous \"5TB Limit\" and the \"xxx% over\" language were gone. It went back to looking at how the dashboard did months ago before the alleged storage limit was put in place. I'm on the Enterprise Plus plan.\n I'm a single-user organization.\n Can anyone else verify that the limit language is gone for them (Enterprise Standard and Enterprise Plus only)?\n https://preview.redd.it/zt0p43gsyc6a1.png?width=2087&format=png&auto=webp&s=65eaa08a79766b0edff231b27a8f3b6c27abfc96\n    submitted by    /u/parker_step  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znufp4/google_workspace_storage_dashboard_no_longer/",
          "publishedOn": "2022-12-17T01:10:23.000Z",
          "wordCount": 15756,
          "title": "Google Workspace Storage Dashboard No Longer Shows Limit (Enterprise Plus)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znu3tx/wd_mycloud_home_1tb_ssd_upgrade_and_repasted/",
          "author": null,
          "description": "submitted by    /u/TrustTheHuman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znu3tx/wd_mycloud_home_1tb_ssd_upgrade_and_repasted/",
          "publishedOn": "2022-12-17T00:53:43.000Z",
          "wordCount": 15742,
          "title": "WD mycloud home 1TB ssd upgrade and repasted.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znqifi/18tb_wd_red_pro_at_319_for_you_muricans_but_569/",
          "author": null,
          "description": "submitted by    /u/Tobarson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znqifi/18tb_wd_red_pro_at_319_for_you_muricans_but_569/",
          "publishedOn": "2022-12-16T22:07:46.000Z",
          "wordCount": 17424,
          "title": "18TB WD Red Pro at $319 for you 'muricans. But €569 for us Euros :/",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znpnjh/datahoarder_discussion/",
          "author": null,
          "description": "Talk about general topics in our Discussion Thread!\n  \nTry out new software that you liked/hated? \n Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n Come show us how much data you lost since you didn't have backups!\n  \nTotally not an attempt to build community rapport.\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znpnjh/datahoarder_discussion/",
          "publishedOn": "2022-12-16T21:30:11.000Z",
          "wordCount": 15662,
          "title": "DataHoarder Discussion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znoj34/critique_my_plans/",
          "author": null,
          "description": "I have one bay unused in my NAS. The other 4 bays are each 3.6 Tb Drives. I am using only 3.55 TB of storage.\n The drives are formatted as SHR 1 in a Synology DS1515+ but I don’t believe they are using BTFRS because the NAS they came from did not support it.\n I am thinking of getting three 10TB Drives and putting one in the open bay then copying the data to that drive, dropping the system from 4 drives to 3 and using the old drives in another NAS that will be offsite. \n If this is a good ideas what are some recommendations on drives\n    submitted by    /u/AnOriginalName2021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znoj34/critique_my_plans/",
          "publishedOn": "2022-12-16T20:41:11.000Z",
          "wordCount": 17674,
          "title": "Critique my plans",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zno9cr/is_this_drive_dead_whenever_i_try_to_do_anything/",
          "author": null,
          "description": "submitted by    /u/750Y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zno9cr/is_this_drive_dead_whenever_i_try_to_do_anything/",
          "publishedOn": "2022-12-16T20:29:55.000Z",
          "wordCount": 17489,
          "title": "Is this drive dead? Whenever i try to do anything with it, it says that it's write protected(even though diskpart says otherwise). The only thing i can do with it is wipe it and create partitions with diskpart, but those partitions remain unwriteable. Sorry for the image quality",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znnibs/are_sata_power_switches_reliable/",
          "author": null,
          "description": "Anyone have experiences with or thoughts on SATA power switches like these (not necessarily that brand)--are they simple and foolproof or considered hacky and not worthy of risking your disks on? I would assume SATA is conducive to this if hotswapping is a thing that can be supported.\n I have external drives for cold storage littered on my workspace and I want to chuck them in my server (Node 304 case). Unfortunately, the USB-SATA logic board on the WD Reds from the Easystores don't fit into the mounting system of the case, hence I'm wondering if the SATA power switch allows me to turn on the drives every few months or so for the occasional access.\n Alternatively I'm thinking of something like this USB-SATA adapter (https://www.amazon.com/Indicators-External-Converter-Computer-Transfer/dp/B017CO5FJM/) (not necessarily this particular brand) and hook up the AC adapter to a power strip with switches for individual outlets to turn the drives on/off. This seems to be the same as the builtin logic boards in functionality but should be drive brand agnostic (e.g. WD logic boards may not necessarily be compatible with Seagate drives, at least without some mods). It is messier and uses USB3, but I should still be able to wire the cables through the PCIe slot and plug in the AC adapters to a power strip with a toggle on/off feature.\n Slight concern is drives not receiving stable power and potentially inducing more wear and tear as a result. \n I should note I am not interested in spinning down the drives--the drives will be used for months at a time and I will be rebooting the system probably biweekly for maintenance and testing, which will inevitably spin up the disks on startup only for them to be spun down again.\n If neither options are suitable then I suppose I just have to live with the drives on top of the server.\n    submitted by    /u/rofic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znnibs/are_sata_power_switches_reliable/",
          "publishedOn": "2022-12-16T19:58:10.000Z",
          "wordCount": 17817,
          "title": "Are SATA power switches reliable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znn5s4/best_approach_for_sync_between_backups/",
          "author": null,
          "description": "Right now when I am keeping media on two separate backups I just run a a rsync script I created for doing a checksum comparison. Are there any tools out there specifically for validating backups? Say you have three stores, at least two of them should have the same checksum for a vmware image. All three should be the same but if one is off the other two match, then I'd have the script refresh it from one of the other two.\n    submitted by    /u/TheIllusioneer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znn5s4/best_approach_for_sync_between_backups/",
          "publishedOn": "2022-12-16T19:42:27.000Z",
          "wordCount": 16936,
          "title": "Best approach for sync between backups?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znl6qx/what_are_some_alternative_to_google_drive/",
          "author": null,
          "description": "Looking for some alternative of drive because Google's privacy policey.Sometimes it deletes on its own.please give me suggestion of some alternative of drive.Tia\n    submitted by    /u/Emad_341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znl6qx/what_are_some_alternative_to_google_drive/",
          "publishedOn": "2022-12-16T18:15:20.000Z",
          "wordCount": 17528,
          "title": "what are some alternative to google drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znl4la/how_to_recover_unplayable_video_or_photo_in/",
          "author": null,
          "description": "I uploaded them and checked they seemed ok after that I deleted from my device.But now it can't play video. It says \"Cannot play this video\". How can I solve this because the raw file is no more\n    submitted by    /u/Emad_341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znl4la/how_to_recover_unplayable_video_or_photo_in/",
          "publishedOn": "2022-12-16T18:12:48.000Z",
          "wordCount": 17886,
          "title": "How to recover unplayable video or photo in google drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znkww3/yall_might_appreciate_this/",
          "author": null,
          "description": "submitted by    /u/ian9921  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znkww3/yall_might_appreciate_this/",
          "publishedOn": "2022-12-16T18:03:35.000Z",
          "wordCount": 17053,
          "title": "yall might appreciate this",
          "imageUrl": "https://preview.redd.it/hzwguhoocc6a1.jpg?auto=webp&s=695b8098fba032cbfc2d005b668d17a28a923ac9"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znkgdg/any_working_methods_for_pluralsight_downloading/",
          "author": null,
          "description": "Hoping to download these Pluralsight courses so that I can watch it later because I am out of time.\n Does YouTube-DLG work?\n Thank you.\n    submitted by    /u/appletreeyum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znkgdg/any_working_methods_for_pluralsight_downloading/",
          "publishedOn": "2022-12-16T17:44:15.000Z",
          "wordCount": 16122,
          "title": "Any working methods for Pluralsight downloading? YouTube-DLG?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znkb10/trying_to_find_solution_to_store_isosroms/",
          "author": null,
          "description": "Hi everyone!\n Been doing a ton of reading/research this morning on the topic, but I can’t seem to get on firm ground for a game storage strategy.\n Currently, I have a desktop PC which I built and use to emulate like 8 consoles worth of games. Many of these games are ISOs or folders that take up a lot of space per game.\n I no longer have access to a free unlimited google drive account which I had about 1.5Tb of data on so I need a migration plan.\n I also plan on adding much more data to emulate some of my PS3 games. I’ll probably ideally love to have upwards of 4-5Tb of storage. But I know the SSD price point sucks there. Open to a hybrid drive like Barracuda. I have an internal Barracuda drive and it’s fast to me!\n I’m not overly concerned about redundancy per se as I have the original discs for many of these games. I can get them all ripped again but it would be annoying. I’m primarily concerned about dependability/longevity with performance second.\n I just ordered a 2Tb 2.5 SATA SSD and a USB 3.0 enclosure for it. My PC does not use USB-C ports. I also have available space internally for another M.2 and another 2.5 drive.\n I’d appreciate some insight. I figured external is the way to go for game storage and continue to store the emulator executables on my system (c) m.2 SSD.\n    submitted by    /u/Nigel-Powers  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znkb10/trying_to_find_solution_to_store_isosroms/",
          "publishedOn": "2022-12-16T17:37:38.000Z",
          "wordCount": 18860,
          "title": "Trying to find solution to store ISOs/ROMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znjgca/just_a_daily_reminder_to_always_have_backups/",
          "author": null,
          "description": "submitted by    /u/_lay4play  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znjgca/just_a_daily_reminder_to_always_have_backups/",
          "publishedOn": "2022-12-16T17:00:53.000Z",
          "wordCount": 16250,
          "title": "Just a daily reminder to always have backups.",
          "imageUrl": "https://preview.redd.it/smy2rquh1c6a1.png?auto=webp&s=bebb8dd5612b22a93cb212176b5ad11517a29f41"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znj0eg/leakedzone_download_method/",
          "author": null,
          "description": "I've tried to download from this site few different ways. JDownloader, firefox download helper, I tried inspecting element but as soon as you do this the site jumps to the main url and the inspector doesn't have the time to load up the data from the original URL. I've tried some online downloaders but they don't seem to work. Yt-dlp + vid link also doesn't work. Is there anything?\n    submitted by    /u/zzzzzzzzzaaaaaaaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znj0eg/leakedzone_download_method/",
          "publishedOn": "2022-12-16T16:41:34.000Z",
          "wordCount": 16242,
          "title": "Leakedzone download method?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znhysj/i_manually_archived_the_entire_free_for_personal/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znhysj/i_manually_archived_the_entire_free_for_personal/",
          "publishedOn": "2022-12-16T15:58:02.000Z",
          "wordCount": 16055,
          "title": "I Manually Archived the Entire (free for personal use) Prado Museum Collection - Here's my Journey and Download Link",
          "imageUrl": "https://external-preview.redd.it/EPqg5vhTYzrq0b1dG_hSOBLHypI8--X0zqvQMzFg-Gg.jpg?auto=webp&s=b9d6231be540534c6c7c7592742a535c78378c88"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znhfql/official_december_seagate_ironwolf_giveaway/",
          "author": null,
          "description": "You know the drill, it's giveaway time again! For this one, we are giving away an IronWolf Pro 125 1.92TB SSD to one lucky winner in this thread!\n Happy Holidays! We love participating in the r/DataHoarder community and want to help further someone's data hoarding ways.\n The prize is: one IronWolf Pro 125 1.92GB SSD\n How to enter:\n Just reply to this post once with a comment that includes the terms RunWithIronWolf and Seagate telling us what you're most excited for in 2023.\n Selection process/rules\n One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until December 30th 2022, 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, a…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znhfql/official_december_seagate_ironwolf_giveaway/",
          "publishedOn": "2022-12-16T15:36:08.000Z",
          "wordCount": 19454,
          "title": "Official December Seagate IronWolf Giveaway",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znhebt/not_sure_if_this_is_a_good_deal_but_def_the/",
          "author": null,
          "description": "submitted by    /u/GUI-Discharge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znhebt/not_sure_if_this_is_a_good_deal_but_def_the/",
          "publishedOn": "2022-12-16T15:34:35.000Z",
          "wordCount": 16025,
          "title": "not sure if this is a good deal but def the lowest price on a 14tb drive I've ever seen",
          "imageUrl": "https://external-preview.redd.it/R5G1gmVh3ppMiBmbMMqCoPc6HtSk6Y8rTEXzQdfjtbI.jpg?auto=webp&s=27b34b1277d573c8fa7b384f4080b2d09b7da216"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zngbib/i_really_hate_it/",
          "author": null,
          "description": "submitted by    /u/pinkLizstar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zngbib/i_really_hate_it/",
          "publishedOn": "2022-12-16T14:46:33.000Z",
          "wordCount": 15815,
          "title": "I really hate it",
          "imageUrl": "https://preview.redd.it/if1ybvlzv96a1.jpg?auto=webp&s=dbd1f465cb12c7cc5cd2c2cb2a6e3d1324c5e952"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zng2sr/redoing_zfs_pool_over_holidays_should_i_stay/",
          "author": null,
          "description": "So backstory: I have 2 NAS systems in my house, one is a Synology box that I'm getting close to 8yrs old on, and another TrueNAS custom made using a Rosewill RSV-L4500 case. One of the drives on my Synology started reporting bad sectors, so I decided to take this as an opportunity to move everything over to TrueNAS and sell off the Synology NAS, just to simplify everything to just one device and to finally go full ZFS.\n My current setup on TrueNAS is a striped pool of mirrored vdevs of 2 8 TB drives each, so about ~28TB of usable space. I want to add another 4 drives, which maxes out the case's drive capacity.\n Adding those 4 drives in the same mirrored pool will give me 46TB in usable space, but it got me thinking if I want to use RAIDZ pools instead for this may drives (12 Total).\n Some basic calculations I did were:\n  \nMIRROR 6 Groups of 2 8TB drives: 46TB -- adding to existing pool\n RAIDZ1 3 Groups of 4 8TB drives: 67TB \n RAIDZ1 2 Groups of 6 8TB drives: 74TB \n RAIDZ1 1 Group of 12 8TB drives: 82TB \n RAIDZ2 3 Groups of 4 8TB drives: 44TB\n RAIDZ2 2 Groups of 6 8TB drives: 61TB\n RAIDZ2 1 Group of 12 8TB drives: 70TB\n  \nI understand that mirrored is would be better because rebuilds on failures would be faster than relying on parity etc, but would redoing the pool groups of RAIDZ be better longevity vs usable space? Mostly considering that at this point I can never upgrade this pool again physically (unless I get a different chasis/case but thats a whole other project in itself) but I obviously care about redundancy on failures as well.\n ​\n Does anyone have any recommendations/insights/experiences?\n    submitted by    /u/adamzwakk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zng2sr/redoing_zfs_pool_over_holidays_should_i_stay/",
          "publishedOn": "2022-12-16T14:35:21.000Z",
          "wordCount": 18862,
          "title": "Redoing ZFS pool over holidays, should I stay mirrored or go RAIDZ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znewid/i_took_apart_a_hdd_and_made_a_sticker/",
          "author": null,
          "description": "submitted by    /u/TechSquidTV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znewid/i_took_apart_a_hdd_and_made_a_sticker/",
          "publishedOn": "2022-12-16T13:38:58.000Z",
          "wordCount": 14749,
          "title": "I took apart a HDD and made a sticker",
          "imageUrl": "https://preview.redd.it/56mv2zovj96a1.jpg?auto=webp&s=4251b5798eb9684536fda86590cb1d81eb526be6"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znbk3f/large_file_set_dup_finders_for_nass/",
          "author": null,
          "description": "I've tried a handful of programs so far and they either won't look at network drives and freeze up part way through (even if I limit the area it is searching), any suggests (i have about 3.5 tb of mixed data) \n i've searched reddit somewhat already and not had any luck yet, linux or windows is fine\n    submitted by    /u/Potential_Ad4240  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znbk3f/large_file_set_dup_finders_for_nass/",
          "publishedOn": "2022-12-16T10:28:17.000Z",
          "wordCount": 17662,
          "title": "large file set dup finder(s) for NAS's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn92nf/cracking_the_password_on_a_msdos_62_msbackup_set/",
          "author": null,
          "description": "Way back in 1995 I backed up a machine onto a sizeable stack of floppies using MS-DOS 6.2 MSBACKUP.EXE. I've imaged the discs, pulled them into a VM and confirmed that they're readable... so that's cool. The only issue is that I have no idea what password I would have set on them 27 years ago.\n Since the passwords were max 8 characters, I'm presuming if I could put the set through a password cracker it shouldn't take too long to break it. Problem is I have no idea where to start.\n I've looked to see if the file format is well known (it does not appear to be documented). \n I've considered trying to write/build some type of automation that runs on top of the VM to automate the keyboard input/screen reading, but I'm not sure what toolset to start with to build that. I'm reasonably technical enough to string together tools with some code/script if someone could point me in the right direction.\n At this point, I'm more curious than anything else as to what's on those disks and if they're truly recoverable this many years later.\n Any thoughts, direction would be appreciated.\n    submitted by    /u/rollinghunger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn92nf/cracking_the_password_on_a_msdos_62_msbackup_set/",
          "publishedOn": "2022-12-16T07:34:26.000Z",
          "wordCount": 18475,
          "title": "cracking the password on a MS-DOS 6.2 MSBACKUP set",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn6zqt/why_is_there_no_high_capacity_25_hdd_any_more/",
          "author": null,
          "description": "The highest capacity 2.5\" spin-disk HDD I can find is only 5TB at about $290. It really has very little if any advantage over 2.5\" SSD 4TB, which are retailed at $237 the cheapest. The fact is 3.5\" HDD are still growing toward higher capacity, while 2.5in HDD market just silently died.\n I'm thinking about to make an offline backup with a 2.5\" HDD, but it seems this is not a viable path any more.\n    submitted by    /u/--dany--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn6zqt/why_is_there_no_high_capacity_25_hdd_any_more/",
          "publishedOn": "2022-12-16T05:25:23.000Z",
          "wordCount": 17593,
          "title": "Why is there no high capacity 2.5\" hdd any more?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn1ukh/refurbed_seagate_drive_errors_question/",
          "author": null,
          "description": "Recently purchased a refurbed Exos 16TB drive. I cleared the drive, ran stress tests on it, then threw it in my array. SMART data was fine etc.\n 2 Days later, while trying to add another drive to my array, this drive starts throwing out errors every second. I reached out to the vendor who said they'd replace it no problem. Trouble is, the drive has highly sensitive data, and DBAN fails when trying to scrub. How comfortable would you be at that point sending the drive back?\n    submitted by    /u/sIlverbulette  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn1ukh/refurbed_seagate_drive_errors_question/",
          "publishedOn": "2022-12-16T00:56:30.000Z",
          "wordCount": 16869,
          "title": "Refurbed Seagate drive errors, question.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn0yii/homelab_desktop_choices/",
          "author": null,
          "description": "submitted by    /u/MrJwan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn0yii/homelab_desktop_choices/",
          "publishedOn": "2022-12-16T00:14:59.000Z",
          "wordCount": 16948,
          "title": "Homelab Desktop Choices ..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn0wws/tool_for_incremental_backups/",
          "author": null,
          "description": "Which tool, cli or non-cli, do you all suggest for doing incremental backups? Data is about 500gb, and backup will go to an external. deleting and transferring the whole thing doesnt seem a good idea as the size increases lol. Also it should run periodically (every 14 days I'd say?) whenever the external is connected, how can I make sure of that?\n Edit: I'm on Macos\n    submitted by    /u/TetheredToHeaven_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn0wws/tool_for_incremental_backups/",
          "publishedOn": "2022-12-16T00:13:05.000Z",
          "wordCount": 17960,
          "title": "Tool for incremental backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn02i3/looking_for_a_good_quality_usb_vhs_transfer/",
          "author": null,
          "description": "Hey all, I’ve been looking for a new analog transfer device for a while to transfer hi-8 and VHS tapes. I bought a cheap easy-cap like device, and it sucked. It was causing a lot of artifacting, frame drops, highlight blowout and just something I wouldn’t trust to transfer several hours worth of important footage.\n With Christmas around the corner, I’ve decided to treat myself with a good quality transfer device. Only problem is, I can’t find the right one. Most of the suggestions I’ve found online and on Reddit are extremely dated or way too advanced for my current setup.\n I’ve heard good things about the Hauppage HD PVR, elgato analog capture, and black magic intensity shuttle cards, but so many people have suggested different approaches that I don’t know which one to try. Everything from TBCs, scalers, passthroughs, to PCIs, I don’t even know if I’m getting the right thing.\n I want to get a good quality device that I can use with my laptop and camcorder without having to drop hundreds of bucks and uproot my entire setup. My main goal is to save these videos to a digital format while losing as little of the picture quality as possible. I’d greatly appreciate any suggestions for what I should invest in.\n    submitted by    /u/urnotmydad23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn02i3/looking_for_a_good_quality_usb_vhs_transfer/",
          "publishedOn": "2022-12-15T23:36:00.000Z",
          "wordCount": 18044,
          "title": "Looking for a good quality USB VHS transfer device, any suggestions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmy0sy/best_way_to_increase_my_data_hoarding/",
          "author": null,
          "description": "I recently decided to up my game and build a NAS. It took a decent amount of convincing, but the biggest thing I used to get my SO on board was that there would be less downtime for our media server. To acquire new material, I need to be connected to a VPN. Is there a way to have my server on a VPN while leaving it accessible to the world outside my network? If not, is it possible to have a directory auto backup to the server, and would this be easier accomplished on windows or Linux?\n    submitted by    /u/Alucard2051  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmy0sy/best_way_to_increase_my_data_hoarding/",
          "publishedOn": "2022-12-15T22:21:31.000Z",
          "wordCount": 17085,
          "title": "Best way to increase my data hoarding?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmxo7l/safe_place_to_store_pirate_library/",
          "author": null,
          "description": "Hey there ! I guess this request is kind of strange but I've been thinking about downloading the whole pirate library (most books from Zlib and Libgen) mirror to have a local copy of almost every books I can think of (around 30TB). I have a safe where I put HDDs with some accounting records and for that matter it has work for years. I know that it isn't the best way to store data that I don't need to access often so what would the alternative be ? Can I put data on Hard Drives and let them unused for years ? Thanks !\n    submitted by    /u/AnyInsurance2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmxo7l/safe_place_to_store_pirate_library/",
          "publishedOn": "2022-12-15T22:09:36.000Z",
          "wordCount": 17677,
          "title": "Safe place to store Pirate Library",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmx7wj/ok_so_not_all_modern_7200_rpm_hdds_got_similar/",
          "author": null,
          "description": "Trying to understand my HDD Read Speeds and why the middle drive is so much slower and the last one so much faster when they are all 7200 RPM. Thank you for input.\n ​\n WDC WD121KRYZ-01W0RB0 12000.1 GB 7200 RPM (Internal SATA)\n Aproximately: 237(MB/s)\n ST18000NM000J-2TV103 18000.2 GB 7200 RPM (Internal SATA))\n Aproximately: 183(MB/s)\n WDC WD201KFGX-68BKJN0 20000.5 GB 7200 RPM (External DAS)\n Aproximately: 276(MB/s)\n    submitted by    /u/nando1969  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmx7wj/ok_so_not_all_modern_7200_rpm_hdds_got_similar/",
          "publishedOn": "2022-12-15T21:52:39.000Z",
          "wordCount": 17052,
          "title": "Ok, so not all modern 7200 RPM HDDs got similar speeds, questions below.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmw281/whats_the_most_reliable_ssd/",
          "author": null,
          "description": "I spent all afternoon trying to get stuff off my old WD drive which is an HDD. I managed to get it spinning and open. But if I’m trying to get everything to a sizable SSD, what should I get?\n    submitted by    /u/quantumcatreflex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmw281/whats_the_most_reliable_ssd/",
          "publishedOn": "2022-12-15T21:04:57.000Z",
          "wordCount": 1860,
          "title": "What’s the most reliable SSD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmw0yi/backup_for_20tb_of_video_footage/",
          "author": null,
          "description": "Hey guys, New at this. I have an archive or video interviews from Holocaust survivors that I need to better secure. Currently, I have them on a few drives but looking for another place to store long term. We don't need to edit or view the footage often it's just a worse-case backup. \n ​\n Any ideas? \n Not looking to spend much. \n Does AWS or some cloud site make sense?\n    submitted by    /u/movingfowards  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmw0yi/backup_for_20tb_of_video_footage/",
          "publishedOn": "2022-12-15T21:03:30.000Z",
          "wordCount": 18535,
          "title": "Backup for 20tb of video footage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmvskq/wd_easystore_bricked/",
          "author": null,
          "description": "Hi everyone, not sure if this is the right place to ask but I'm going to try.\n I have a 14TB WD easystore that's been working for just over a year now. Yesterday, I noticed it was mounting and unmounting rapidly, so I ejected it and restarted the computer. \n When I turned the computer back on it would no longer mount, the discs aren't spinning and there was a slow, white flashing from the LED indicator. I immediately looked up all the troubleshooting guides and did the following. \n  \nSwitched USB cables (used my other easystore's usb)\n plugged into a dedicated wall outlet\n checked windows device manager and un-checked \"allow the computer to turn off this device to save power\" - restarted pc\n opened disc management, where it is not visible and there is no drive letter for it at all\n updated drivers \n allowed hidden items in serial bus drivers\n  \nAfter frustration I stopped everything all together. This morning I plugged it in and there is still no disc spinning activity, and now the LED blinks rapidly. Is this thing bricked? I have 13.9 TBs on it and would really hate to lose it all. I had it propped up on fans and it was well maintained, and of course there is no power or reset button on these things.\n Any suggestions? It's still warrantied for another year. Thanks in advance.\n    submitted by    /u/ryPods  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmvskq/wd_easystore_bricked/",
          "publishedOn": "2022-12-15T20:54:07.000Z",
          "wordCount": 17385,
          "title": "WD Easystore Bricked? :(",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmvovg/help_improveexpand_my_current_backup_setup_please/",
          "author": null,
          "description": "Hi,\n I have personal data (general, plus DSLR and GoPro photos/videos for Lightroom/Final Cut Pro), business data (including lots of big image files, say 1GB per file, 200GB currently), and my computer setup to back up. I don't generally save images/videos on my internal SSD.\n My current setup looks like this:\n  \n2TB external HD for photo/video storage 2.5\"\n 5TB external HD for business data storage 2.5\"\n I also have a 2TB external SSD for temporary photo/video storage for faster editing. This only ever contains duplicates from the 2TB HD\n 4TB external HD for backing up both the 2TB and the 5TB external HDs (yeah, the 4TB was here first, when I had 2x 2TB, but my business 2TB failed so I upgraded that to a 5TB... thus the stupid size relations)\n 1TB time machine external HD for backing up my Mac setup/internal SSD\n iDrive Cloud for backing up my Time Machine, 2TB photo and 5TB business HD.\n  \n​\n Problem: My photo/video 2TB external HD is getting really full, only 10% space left... I started taking more videos, which take up a huge amount of space.\n Now I'm really torn as to how to smartly upgrade my backup setup.\n  \nShould I get a big external HD, maybe 6TB, to replace the current stupid 4TB backup HD, and use the 4TB backup HD for photos and videos instead?(I could even use the 4TB just for videos, leave my photos on the current 2TB photo/video HD). If so, should I get a 2.5\" or 3.5\" for the 6TB? I don't really need to move it, it should stay on my desk, but is there still an advantage to 3.5\" these days at all?\n Or should I rather get a second smallish (2TB) external HD to put the videos on, so that the current photo/video HD only contains photos, and leave the backup 4TB as is for now?\n  \n​\n Trying to save money atm, but also want a sustainable solution...\n Which option do you suggest and why?\n Feel free to also add other sensible options that I'm missing here!\n ​\n Thanks so much!\n ​\n View Poll\n    submitted by    /u/4symmetry  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmvovg/help_improveexpand_my_current_backup_setup_please/",
          "publishedOn": "2022-12-15T20:49:59.000Z",
          "wordCount": 18826,
          "title": "Help improve/expand my current backup setup - please",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmv2yg/is_there_a_calibre_or_stash_like_program_i_can/",
          "author": null,
          "description": "Hi everyone.\n Does anyone know if there are any programs like stash that i can use to acess my downloaded youtube videos from my web browser on my lan in an aesthetically pleasing way?\n I do not want to use plex as while i have that setup and it is good on the tv i would love something a bit more browser focussed for accessing in web browsers on my computers to go along with stash, calibre, kiwix, sonarr, radarr etc.\n    submitted by    /u/therealbabyshell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmv2yg/is_there_a_calibre_or_stash_like_program_i_can/",
          "publishedOn": "2022-12-15T20:24:46.000Z",
          "wordCount": 17632,
          "title": "Is there a Calibre or Stash like Program i can use for videos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmtpnr/photo_deduplication_with_heic_support/",
          "author": null,
          "description": "I'm looking for a photo deduplication app that looks at heic photos also. Platform doesn't really matter as I can work with any. Doing searching for one they seem to be older apps that doesn't support heic. Any suggestions?\n    submitted by    /u/Ryanrk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmtpnr/photo_deduplication_with_heic_support/",
          "publishedOn": "2022-12-15T19:28:29.000Z",
          "wordCount": 16785,
          "title": "Photo Deduplication with heic support?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmqqyo/its_offsite_backup_day/",
          "author": null,
          "description": "submitted by    /u/pizzatreeisland  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmqqyo/its_offsite_backup_day/",
          "publishedOn": "2022-12-15T17:26:25.000Z",
          "wordCount": 17454,
          "title": "it's offsite backup day!",
          "imageUrl": "https://preview.redd.it/bt4vehj5156a1.png?auto=webp&s=da507144b4c15e885db309415e7ee2a15afbd98f"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmqmnz/best_way_to_measure_hdd_vibrations_in_a_server/",
          "author": null,
          "description": "Whats the easiest way to measure the vibration level of hdds in different servers?\n I am currently building multiple diy jbods and want to test which design works best.\n    submitted by    /u/Pommes254  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmqmnz/best_way_to_measure_hdd_vibrations_in_a_server/",
          "publishedOn": "2022-12-15T17:21:46.000Z",
          "wordCount": 17035,
          "title": "Best way to measure hdd vibrations in a server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmqkm9/minecraft_offline/",
          "author": null,
          "description": "Not sure if anyone here archives games, or has experience with Minecraft, but is there any way to have a Minecraft launcher, such as the titan launcher, for offline use? What I mean is, if you use the titan launcher you still have to download any version you might want to play. What I'm looking for is a launcher that already has ALL Minecraft versions built in so I can just play it wherever and whenever and require no internet connection whatsoever. I want this for purposes of archiving the game on an external HDD, since I'm a big data hoarder.\n    submitted by    /u/Voldy256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmqkm9/minecraft_offline/",
          "publishedOn": "2022-12-15T17:19:30.000Z",
          "wordCount": 16998,
          "title": "Minecraft offline.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmpo9h/screen_recorder_software_or_stream_downloader/",
          "author": null,
          "description": "I'm wondering, for the people that have experience with it, whether you prefer to use screen recorder software or something else to save the video stream directly when archiving video from websites? \n I'm specifically looking to archive video from the History channel's website because I can't find it anywhere else and don't want it to just disappear one day.\n    submitted by    /u/PiMan3141592653  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmpo9h/screen_recorder_software_or_stream_downloader/",
          "publishedOn": "2022-12-15T16:43:17.000Z",
          "wordCount": 16830,
          "title": "Screen recorder software or stream downloader?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmo078/ive_started_down_the_path_of_data_hoarding/",
          "author": null,
          "description": "submitted by    /u/NessDan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmo078/ive_started_down_the_path_of_data_hoarding/",
          "publishedOn": "2022-12-15T15:35:37.000Z",
          "wordCount": 17328,
          "title": "I've started down the path of Data Hoarding 😇 Downloaded my data from services, backing up photos and vids from my phone, and archiving my YouTube playlists!",
          "imageUrl": "https://preview.redd.it/ru7po5tiz26a1.png?auto=webp&s=04d976eef515a1d9c361ffc5bf3b992c3c118d4c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmnw7d/advice_on_50_sealed_500gb_hdds/",
          "author": null,
          "description": "I have the opportunity to buy around 50 500GB HDDs still sealed in their original packaging (about USD 4.50 per drive), and was wondering if it would be worth getting any. \n Based on this thread, it seems that the best use would be to just (re)sell the drives or offer upgrade services; and that building something with them would be quite inefficient due to high power requirements relative to the storage space available. Any other ideas on what else could be done with these drives? Or would those two suggestions still be the best advice today? \n Also, these drives are somewhat old (manufactured 2015, ~7 years ago). If the HDDs have been factory sealed all this time, would they still be very likely to work, or would there be some form of degradation?\n    submitted by    /u/drowsy_kitten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmnw7d/advice_on_50_sealed_500gb_hdds/",
          "publishedOn": "2022-12-15T15:31:18.000Z",
          "wordCount": 19057,
          "title": "Advice on 50+ sealed 500GB HDDs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmniue/backblaze_adds_us_east_region/",
          "author": null,
          "description": "https://www.backblaze.com/blog/backblaze-adds-us-east-region-expanding-location-choices-and-cloud-replication-options/\n Also a nice read about behind-the-scenes of the new DC. https://www.backblaze.com/blog/a-behind-the-scenes-look-at-our-us-east-data-center/\n    submitted by    /u/newcbomb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmniue/backblaze_adds_us_east_region/",
          "publishedOn": "2022-12-15T15:16:03.000Z",
          "wordCount": 16652,
          "title": "Backblaze Adds US East Region",
          "imageUrl": "https://external-preview.redd.it/0_QuLEGPgNcIsXFu26NpD73Z3az5ljQOk-aUKXQ-6KI.jpg?auto=webp&s=57c4c18e15c2b569039247fe5cf178606417cbaf"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmf0cu/a_newspaper_vanished_from_the_internet_did/",
          "author": null,
          "description": "submitted by    /u/ChasingTheRush  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmf0cu/a_newspaper_vanished_from_the_internet_did/",
          "publishedOn": "2022-12-15T07:16:08.000Z",
          "wordCount": 29346,
          "title": "A newspaper vanished from the internet. Did someone pay to kill it? | *digs into link rot and the loss of digital archives*",
          "imageUrl": "https://external-preview.redd.it/tGfNHUfJWWvlnVyfRQu2pQGOFrpPN4LQLxUyn6Gcajs.jpg?auto=webp&s=24459ff9106ed4a064443f3f8ea8707194978405"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmedz1/downloading_all_saved_reddit_media_from_specific/",
          "author": null,
          "description": "GitHub - shadowmoose/RedditDownloader: Scrapes Reddit to download media of your choice. \n can anyone tell me how to use the rmd shadowmoose tool? im looking at the ui, How do I make it download every post i saved from a specific reddit? How do I make it all save in a folder in a specific download location?\n    submitted by    /u/I-am-ocean  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmedz1/downloading_all_saved_reddit_media_from_specific/",
          "publishedOn": "2022-12-15T06:38:57.000Z",
          "wordCount": 17798,
          "title": "Downloading all saved reddit media from specific subreddit",
          "imageUrl": "https://external-preview.redd.it/vYgR2foukwVDiXH_KtWnPanT3Syjz7NFrQk9zcRI0JM.jpg?auto=webp&s=3cfea73d59cb576f67023b7ccf56ac614f56f05d"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zma47m/my_drive_is_making_weird_grinding_noises_and_50/",
          "author": null,
          "description": "NO, NO IT'S NOT. \n If you care about your data, trash or RMA any drives with ANY errors no matter how small. It will only get worse.\n    submitted by    /u/Royal-Ad-2088  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zma47m/my_drive_is_making_weird_grinding_noises_and_50/",
          "publishedOn": "2022-12-15T02:49:32.000Z",
          "wordCount": 17434,
          "title": "My drive is making weird grinding noises and 50% of the clusters show bad sectors. It’s ok to keep using it though, right?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm7a5d/i_need_help_with_storage/",
          "author": null,
          "description": "Hello Folks, I have an important thing that I figure y'all \n can help me with (please do)\n    submitted by    /u/Mansiontrash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm7a5d/i_need_help_with_storage/",
          "publishedOn": "2022-12-15T00:37:19.000Z",
          "wordCount": 18459,
          "title": "I need help with storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm74yq/what_are_the_best_ways_to_mass_download_safe_for/",
          "author": null,
          "description": "Currently downloading 1 at a time\n    submitted by    /u/wallpapersdance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm74yq/what_are_the_best_ways_to_mass_download_safe_for/",
          "publishedOn": "2022-12-15T00:30:55.000Z",
          "wordCount": 16681,
          "title": "What are the best ways to mass download safe for work pictures of non-nude female fitness pictures from subreddits onto my ipad mini 5?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm6cs0/should_i_replace_this_drive_soon/",
          "author": null,
          "description": "submitted by    /u/aaronwei5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm6cs0/should_i_replace_this_drive_soon/",
          "publishedOn": "2022-12-14T23:56:53.000Z",
          "wordCount": 19319,
          "title": "Should I replace this drive soon?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm6b4b/downloading_large_amount_of_images_from_forums/",
          "author": null,
          "description": "I'm searching for a tool that can download images linked in forum posts. Cyberdrop-dl (python) is quite good, but it has issues with forum posts. If you try to download it by direct link to specific post, it will download a bunch of random images, from that topic, but I can't find any rule how it works.\n    submitted by    /u/Vichex52  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm6b4b/downloading_large_amount_of_images_from_forums/",
          "publishedOn": "2022-12-14T23:54:51.000Z",
          "wordCount": 17098,
          "title": "Downloading large amount of images from forums",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm54b3/what_would_be_the_best_way_to_back_up_a/",
          "author": null,
          "description": "So, I've created a dual-boot PC for myself so I can learn how to use Linux and hopefully transition away from Windows. \n I want to have my PC automatically backup all its data. However, there are a lot of different ways to backup PCs, and I'm not sure which methods/programs would work best for my situation. \n I've looked through the r/DataHoarder Wiki and I have a rough idea of what a backed-up PC should look like, but my problem is that there are a lot of backup tools and programs out there and I don't know which I should use. \"I'm trapped by overchoice.\" \n I also can't seem to find any guides on what can and can't be done when trying to backup a dual-boot PC. Can one operating system backup both itself and the other operating system, or do both operating systems need to have their own backups? \n As to my current situation. I have about 1TB of personal data (I save a lot of movies, music, and images). I currently have all my data saved on a 2TB external USB HDD. My dual-boot PC is set up, but I haven't installed anything on it yet because I want to make sure I have a backup system all set up first. I have a bit of a \"hodgepodge\" of drives. I have:\n  \nTwo 500GB SSDs as my boot drives for Linux and Windows respectfully\n One 500GB HDD I salvaged from my mom's old desktop.\n One 750GB HDD I salvaged from my old Toshiba laptop\n One 2TB HDD that serves as my PC's internal \"bulk storage\" drive for all the music, videos, and images. \n One external USB 2TB HDD that I've been using as my backup drive.\n  \n   submitted by    /u/Alexander-369  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm54b3/what_would_be_the_best_way_to_back_up_a/",
          "publishedOn": "2022-12-14T23:03:57.000Z",
          "wordCount": 17189,
          "title": "What would be the best way to back up a dual-booting Windows and Linux PC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm3yfp/f_for_this_poor_terabyte_i_have_filled_up_with_my/",
          "author": null,
          "description": "submitted by    /u/OfficialXtraG07  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm3yfp/f_for_this_poor_terabyte_i_have_filled_up_with_my/",
          "publishedOn": "2022-12-14T22:16:21.000Z",
          "wordCount": 16612,
          "title": "F for this poor terabyte I have filled up with my childhood dreams.",
          "imageUrl": "https://preview.redd.it/9jkken9gux5a1.jpg?auto=webp&v=enabled&s=f41da4758496a047bf6ba703d073260596c3284b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm3p3f/how_should_i_evaluate_disk_health_given/",
          "author": null,
          "description": "I have a couple dozen drives, all their own volume (virtualized as one via DrivePool) of various sizes and models.\n Following a a power...blip? the other day, StableBit Scanner is reporting a handful of them with unreadable sectors.\n Every single drive where damage was reported is in a single QNAP enclosure.\n Number of sectors unreadable on all affected drives: 1, 1, 1, 8, 61, 44240\n Only two media files were affected (99%+ intact) and were recovered via Scanner. The \"most damaged\" drive amounted to 21MiB in terms of storage.\n Scanner reports all drives as otherwise healthy, and no SMART flags to check\n I manually confirmed that all affected drives are reporting 0 for Reallocated Sectors, Reallocation Events, Pending Sectors, Uncorrectable Sectors (I guess that last one doesn't make sense to me)\n My two questions are:\n Should I treat this as \"the beginning of the end\" for these drives, or not?\n Would a UPS have probably avoided this event?\n    submitted by    /u/TootSweetBeatMeat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm3p3f/how_should_i_evaluate_disk_health_given/",
          "publishedOn": "2022-12-14T22:05:50.000Z",
          "wordCount": 17362,
          "title": "How should I evaluate disk health given unreadable sectors but otherwise healthy SMART?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm3443/the_datahoarder_showoff_thread_december_2022/",
          "author": null,
          "description": "I got my storage start on HardForums storage showoff threads in around 2008 and I miss that format quite a lot so I think it's about time we recreate it here. The basic idea is to post pictures of your setup, detail the spec and tell us what you use your storage for.\n Here's an example post format...\n  \n Amount of total storage (Raw/Formatted/Config)\n Case\n PSU\n CPU\n RAM\n Motherboard\n Controller Cards (if any)\n Drives (include full model numbers)\n Operating System\n A paragraph or two describing what you use your storage for and how you handle backups and organizing and maybe future upgrade plans.\n Gallery of images (use imgur gallery format not separate image links)\n  \n We will run this thread every 6 months or so and update the post to feature the most upvoted, discussed and interesting systems! Have fun!! \n P.S. Some of you may remember where I was when I first joined DH, from this thread and it's about time I post a new one so I'll join you in posting my current setup should this go well.\n    submitted by    /u/-Archivist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm3443/the_datahoarder_showoff_thread_december_2022/",
          "publishedOn": "2022-12-14T21:42:23.000Z",
          "wordCount": 18749,
          "title": "The DataHoarder Showoff Thread | December 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm2431/mediasonic_probox_questions_changing_filesystem/",
          "author": null,
          "description": "I have a Mediasonic Probox that has 3 drives on HFS+ and data on them. File permissions have been ridiculously annoying while on linux and I wanted to change to ext4. I have had success in some ways with hfsplus mounting but I can not share the drives or do anything I really want lol.\n Does the Probox work as ext4 or zfs? I did not want to do NTFS but...I would prefer it to HFS+ at this point. \n If yes to ext4 and/or NTFS: If I format one drive at a time, would that work? Or would I lose/corrupt data on the other 2 drives? I am asking because I was hoping to copy as much data to 2 of the drives, wipe, then transfer data back. Do this for all 3\n Do I manually remove the drive from the enclosure or can I format a drive, one at a (I have no idea how raid really works or if this is actually a raid setup). \n Thank you guys!\n    submitted by    /u/path0l0gy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm2431/mediasonic_probox_questions_changing_filesystem/",
          "publishedOn": "2022-12-14T21:02:08.000Z",
          "wordCount": 16929,
          "title": "MediaSonic Probox Questions (changing filesystem type)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm1zol/what_are_the_pros_and_cons_of_the_file_sync/",
          "author": null,
          "description": "So, I've been looking at the different file backup programs in the r/DataHoarder wiki, and I came across freefilesync.org. This program looked like an ideal file sync program for me. However, I discovered that one of my favorite YouTubers made a nice tutorial about file syncing using a program known as \"Resilio\". I don't know which of these two programs to pick, so I was wondering if anyone here has used Resilio and could give a review of the program, and maybe talk about how it compares to other file sync programs.\n    submitted by    /u/Alexander-369  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm1zol/what_are_the_pros_and_cons_of_the_file_sync/",
          "publishedOn": "2022-12-14T20:57:16.000Z",
          "wordCount": 16520,
          "title": "What are the pros and cons of the file sync program\"Resilio\"?",
          "imageUrl": "https://external-preview.redd.it/bGNkRmqxaDnL61FoZqA4bJpXreeSY-cdeupnwt9qqHU.jpg?auto=webp&v=enabled&s=67ae00d73ee4fdbc8e16a8ed11606e96899675d6"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm1469/recommendations_on_free_lto4_tape_backup_software/",
          "author": null,
          "description": "I recently got a LTO-4 tape drive and 15 tapes to backup my Plex torrents. I'm waiting for a pcie SAS HBA to be delivered, but in the meantime, does anyone have any suggestions or recommendations for free backup software? I found EaseUS Todo Backup and plan on using it, but maybe there's some better free software out there. \n I'd like to hear if there are some cheaper, paid solutions out there too.\n    submitted by    /u/20cstrothman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm1469/recommendations_on_free_lto4_tape_backup_software/",
          "publishedOn": "2022-12-14T20:20:02.000Z",
          "wordCount": 17291,
          "title": "Recommendations on free LTO-4 tape backup software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlzzyw/seagate_ironwolf_14tb_60_off_neweggcom/",
          "author": null,
          "description": "submitted by    /u/root54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlzzyw/seagate_ironwolf_14tb_60_off_neweggcom/",
          "publishedOn": "2022-12-14T19:33:34.000Z",
          "wordCount": 17177,
          "title": "Seagate IronWolf 14TB 60% off - Newegg.com",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlzez7/best_place_to_upload_multiple_terabytes_of_twitch/",
          "author": null,
          "description": "I've got multiple terabytes of now-deleted or muted-via-DMCA VODs from Twitch but I have no idea what to do with them. I want them to be accessible to the public, but I'd hate for them to just get DMCA'd somewhere like YouTube. Does the Internet Archive accept stuff like that, and if so, what's the most efficient (CLI preferred) way to upload that much?\n    submitted by    /u/RocketSLC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlzez7/best_place_to_upload_multiple_terabytes_of_twitch/",
          "publishedOn": "2022-12-14T19:08:22.000Z",
          "wordCount": 16980,
          "title": "Best place to upload multiple terabytes of Twitch archives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlyqjo/i_have_2_copies_of_the_same_data_in_separate_hdds/",
          "author": null,
          "description": "I have 2 copies of the same data in 2 HDDs. One of them is 12 years old. Other is 6. I will make one more copy soon. Which copy should I use to create the 3rd one?\n It's all pictures and videos. Is there a way to verify the files to make sure they are still not corrupted?\n    submitted by    /u/streamlinkguy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlyqjo/i_have_2_copies_of_the_same_data_in_separate_hdds/",
          "publishedOn": "2022-12-14T18:40:23.000Z",
          "wordCount": 19494,
          "title": "I have 2 copies of the same data in separate HDDs. Which copy should I use to create the 3rd one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlxvc0/how_can_i_extract_the_3d_model_from_vr_viewer_on/",
          "author": null,
          "description": "I wanted to know if there is a way to download the 3D file from the viewer on a webpage. I feel like this should be possible since I am looking at the model but I don't know how to get to it. I use Google Chrome btw.\n    submitted by    /u/GroundBreakingEye44  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlxvc0/how_can_i_extract_the_3d_model_from_vr_viewer_on/",
          "publishedOn": "2022-12-14T18:06:14.000Z",
          "wordCount": 17106,
          "title": "How can I extract the 3D model from VR viewer on a webpage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlwlcn/rate_my_fugly_storage_setup_raw_288_tb/",
          "author": null,
          "description": "I know y'all will put my head on the pike due to piss poor cable management. Please roast my setup.\n Computer specs -\n  \nAsus WS C621E SAGE\n 2 x Xeon Bronze 3104\n 2 x SK hynix 64GB/4Gx4 DDR4 2400MHz (128 GB total)\n LSI MegaRAID 9271-8i\n Asus 2080 Ti Geforce 11 GB\n IcyDock 3-in-2 (supports 3 hard drives)\n IcyDock 5-in-3 (supports 5 hard drives)\n 18 x 16 TB Exos \n 8 x 16 TB via RAID 0 Array #1 (main boot drive & primary storage)\n 8 x 16 TB via RAID 0 Array #2 (secondary storage)\n 2 x 16 TB via RAID 0 Array #3 (tertiary & temporary storage)\n \n  \nhttps://preview.redd.it/h7gm8rl7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=89a63eafb0c7706ab4389ba0a6c591547c48c2ad\n https://preview.redd.it/wj4xgyl7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=c7d29da0a5819dbd4b19b3674773218f363ca5aa\n https://preview.redd.it/r6b7y0m7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=0aae9f11a52f6704a7a4ed979ac10494a03d9a63\n https://preview.redd.it/l4xx41m7dw5a1.jpg?width=2000&format=pjpg&auto=webp&s=dce2d20a5a2acff95f16a57ce71c8bc2e57d368d\n https://preview.redd.it/p8fwosm7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=2d60d93c7ba751974e912055180a3072be0e374f\n https://preview.redd.it/01wifdm7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=b95ffe69c15b28f7104ec969d9e1515ae2670d6c\n    submitted by    /u/DeafAccessibility  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlwlcn/rate_my_fugly_storage_setup_raw_288_tb/",
          "publishedOn": "2022-12-14T17:16:39.000Z",
          "wordCount": 17251,
          "title": "Rate my fugly storage setup (raw 288 TB)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlwesd/crystaldisk_info_not_detecting_any_drives/",
          "author": null,
          "description": "Hi everyone, As the title says, suddenly CrystalDisk Info does not detect any drives (not even the C drive). It shows Drive not detected. Could a recent powerloss or a Windows update have caused the issue? All the drives work fine actually.\n    submitted by    /u/terminasitor24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlwesd/crystaldisk_info_not_detecting_any_drives/",
          "publishedOn": "2022-12-14T17:09:30.000Z",
          "wordCount": 15819,
          "title": "CrystalDisk Info not detecting any drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlv7t8/file_naming_for_artwork_kodi_plex_and_jellifin/",
          "author": null,
          "description": "Hello, as far as I know Kodi uses this naming scheme for covers:\n + Name of Movie (YEAR) - Name of Movie (YEAR).mp4 - Name of Movie (YEAR)-poster.jpg \n https://kodi.wiki/view/Movie_artwork#Local_Artwork\n I'm wondering what \"poster\" is. Is it the front cover of the DVD case? like this https://i.ebayimg.com/images/g/e8EAAMXQAx9RN3Lq/s-l500.jpg ? I'm asking because Kodi doesn't use \"cover.jpg.\"\n Also do you prefer the naming scheme above or you just use \"cover.jpg\", like so:\n + Name of Movie (YEAR) - Name of Movie (YEAR).mp4 - cover.jpg \n    submitted by    /u/zoliky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlv7t8/file_naming_for_artwork_kodi_plex_and_jellifin/",
          "publishedOn": "2022-12-14T16:21:17.000Z",
          "wordCount": 18300,
          "title": "File naming for artwork. Kodi, Plex, and Jellifin.",
          "imageUrl": "https://external-preview.redd.it/qVq41jZ9CFuaITfKsY22BNLEY6Eh8ooaHLLzMG8T1Ss.jpg?auto=webp&v=enabled&s=9c2ce1702df42ca5feed11aa3613b99b12d39e5f"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlu1sr/how_to_download_all_files_from_a_website_linux/",
          "author": null,
          "description": "I found a website with a lot of “.pdf.gz” “.py” “.cvs” “.webp” and a lot more different file types That i want to keep offline\n Iknow (a little)$wget $curl $httrack They give me after download an offline webpage mirror were none of the files are downloaded.. just a bluetext that isn’t referring to anything\n How do i, best way, download all this without manually clicking everything\n Also saw kiwix mentioned a view times on this r/ but would like it more to download it myself and so being able to put it on hdd or something\n    submitted by    /u/reditje  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlu1sr/how_to_download_all_files_from_a_website_linux/",
          "publishedOn": "2022-12-14T15:33:55.000Z",
          "wordCount": 16708,
          "title": "How to download all files from a website? (Linux)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zltyb6/need_advice_for_new_nas_drive/",
          "author": null,
          "description": "Hi, I'm looking for a huge drive (12TB+) and came across Seagate Exos which seem to be cheaper than WD Reds, however, I wanted to have 5400 RPM. Currently I have WD Red Plus (4TB) and it's quite silent.\n What's the best drive I can find regarding power consumption + silent and preferably 5400 RPM for 12TB+?\n Thanks!\n    submitted by    /u/RuivoM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zltyb6/need_advice_for_new_nas_drive/",
          "publishedOn": "2022-12-14T15:30:04.000Z",
          "wordCount": 18109,
          "title": "Need advice for new NAS drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlt2ew/trains_and_hard_drives/",
          "author": null,
          "description": "Hey. So I just moved into a new place and I'm close enough to some railroad tracks that the entire house vibrates occasionally when a train goes by. How is this going to affect the two 18TB platter drives in my server?\n Thanks.\n    submitted by    /u/Huecuva  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlt2ew/trains_and_hard_drives/",
          "publishedOn": "2022-12-14T14:55:31.000Z",
          "wordCount": 17780,
          "title": "Trains and hard drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlrw0l/since_2018_the_total_volume_of_data_across_the/",
          "author": null,
          "description": "submitted by    /u/yourdp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlrw0l/since_2018_the_total_volume_of_data_across_the/",
          "publishedOn": "2022-12-14T14:08:47.000Z",
          "wordCount": 17644,
          "title": "Since 2018, the total volume of data across the world has nearly doubled in size every two yrs; it currently sits at ~94T gigabytes and is projected to reach 175T by 2025",
          "imageUrl": "https://external-preview.redd.it/UyPlvt-4ueMd5L2HwRHfpzK_7wzIDZHZzt6HY_ELgnQ.jpg?auto=webp&v=enabled&s=877db3e109f769e922c2cec01a73cbf24c97f6ad"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlc8bz/backblaze_expects_001_per_gb_hds_by_2025/",
          "author": null,
          "description": "https://www.tomshardware.com/news/backblaze-expects-one-cent-per-gb-hdds-by-2025\n ​\n Let's hope inflation, crypto, wars, and mother nature don't interfere with this prediction.\n    submitted by    /u/wbs3333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlc8bz/backblaze_expects_001_per_gb_hds_by_2025/",
          "publishedOn": "2022-12-14T00:34:54.000Z",
          "wordCount": 17874,
          "title": "Backblaze Expects $0.01 per GB HDs by 2025",
          "imageUrl": "https://external-preview.redd.it/BrJKiUC6_NdpNa7rDiEX0UOCCOyac2z4fxB0ZliO5ko.jpg?auto=webp&v=enabled&s=a581ae7e1f8711a67dbed39fec91a03b26d7feca"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlc3qs/apologies_for_any_mistakes_im_quite_new_to_this/",
          "author": null,
          "description": "submitted by    /u/Riley79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlc3qs/apologies_for_any_mistakes_im_quite_new_to_this/",
          "publishedOn": "2022-12-14T00:29:32.000Z",
          "wordCount": 17051,
          "title": "Apologies for any mistakes, im quite new to this, my power went out and when my pc came back on I noticed my hard drive was a lot louder so I checked Crystal Disk Info and saw this, is this something to be concerned about and I should start backing up?",
          "imageUrl": "https://preview.redd.it/evvlk97adr5a1.png?auto=webp&s=8f8e38ed362c5c74086af52495e753d2557c4680"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlaq5d/mycloud_alternative_remote_access/",
          "author": null,
          "description": "I work for a small business that uses MyCloud for our in-office network; can anyone suggest an alternative for our network that also allows remote access? I'm not especially good with computers or anything like that, so I'm hoping for something that will be relatively easy to implement and that doesn't require me to set up a VPN or anything. Hope this is the right subreddit!\n    submitted by    /u/normopathy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlaq5d/mycloud_alternative_remote_access/",
          "publishedOn": "2022-12-13T23:32:00.000Z",
          "wordCount": 17282,
          "title": "MyCloud Alternative - remote access?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl9m7h/reliability_in_the_long_run_possibly_a_noob/",
          "author": null,
          "description": "Hey all, long time, first time.\n I built a new NAS a couple of months ago with a i3-10100 CPU @ 3.60GHz (Gigabyte B560M) and a number of WD Red HDDs based on TrueNAS Scale. It's fast and quiet, and really does everything that I could need it for.\n However, I also have a Synology DS920+ on the way from a friend who got a newer 923 from his work. He's only had the 920 for about 6 months. Knowing what I know about Syno, it'll also do the trick.\n My question is this: which one will last longer? Which is a better value proposition for things like Plex, the 'arr suite, and simple Time Machine/cold storage?\n I'm a little worried that what is essentially a gaming motherboard is going to wear out at a certain point, but I'm calling on all of your years experience: go with the DIY solution for the long run, or trust in the Syno, which I've seen people running for 8 years or so?\n    submitted by    /u/chinomage83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl9m7h/reliability_in_the_long_run_possibly_a_noob/",
          "publishedOn": "2022-12-13T22:48:35.000Z",
          "wordCount": 18442,
          "title": "Reliability In The Long Run (possibly a noob question)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl8v24/hosting_a_website_with_dozens_of_terabytes_of/",
          "author": null,
          "description": "I asked this in /r/webdev and they suggested you folks could help me more:\n I have a niche website that currently has about a dozen TB of storage. As the website has started to grow, the data has started to become an issue....the hard drive I use to hold the files is no longer going to be able to hold it all. I'm estimating the storage will be 25-50TB, with about 50-100GB in daily bandwidth, at a minimum. So I need solutions with unlimited traffic.\n I am cheap, so using cloud providers like Azure, AWS is not really an option. I have noticed that Hetzner has cheap servers, with large hard drives (and empty slots for future growth). The issue I now see is the practical question of...how do I merge the hard drives while maintaining some level of protection against disk failure? If I have 3 HD…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl8v24/hosting_a_website_with_dozens_of_terabytes_of/",
          "publishedOn": "2022-12-13T22:19:23.000Z",
          "wordCount": 18215,
          "title": "Hosting a website with dozens of terabytes of storage. how to keep the data safe for cheap. how to pool the multiple disks, or other options available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl8c02/optane_memory_buy_now_for_a_later_zfs_build/",
          "author": null,
          "description": "Intel is discontinuing Optane memory, and there are some good deals to be had on smaller Optane M.2. modules. I saw a YouTube video that says Optane modules are great for ZFS metadata storage.\n I don't have a ZFS server, but plan to build a modest one sometime in the future - so should I grab some Optane modules now before they are gone for good?\n Background: Optane solid state memory is great for write caching because unlike standard SSD storage it really won't wear out in any reasonable amount of time.\n    submitted by    /u/CarlGustav2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl8c02/optane_memory_buy_now_for_a_later_zfs_build/",
          "publishedOn": "2022-12-13T21:59:29.000Z",
          "wordCount": 18153,
          "title": "Optane memory - buy now for a later ZFS build?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl65th/download_all_of_my_icloud_photos_with_metadata/",
          "author": null,
          "description": "Hi all,\n I recently asked about downloading iCloud photos - You can find my post here.\n As I am now using gimme-iphoto for regularly downloading all of my photos, I found that there's certain metadata missing from certain files... What I found missing:\n  \nAny geolocation data - missing from any photo or video\n Date taken - missing from any screenshot or imported picture\n  \nI have also tried using a Mac and exporting the photos (by hand), but this information is also missing, whereas if I look at the photos' info boxes, even screenshots have dates attached to them.\n Is there any solution to download / export the files with this missing data?\n    submitted by    /u/KRider92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl65th/download_all_of_my_icloud_photos_with_metadata/",
          "publishedOn": "2022-12-13T20:35:17.000Z",
          "wordCount": 18734,
          "title": "Download all of my iCloud photos with metadata",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl4dpj/raspi_network_idea/",
          "author": null,
          "description": "Looking for feedback and possible issues with this idea. For this case example there’s 3 raspberry pi all connected to a 1tb ssd with a stable internet connection.\n Mount each raspberry pi onto eachother via an rclone sftp mount.\n on each raspi settup jellyfin to read from the remote raspi drives and their own local drive.\n Now each raspberry pi is connected to eachother and each person with a raspberry pi can play media from it.\n But now let’s say I would want to add a 4th raspi remotely. Since each person lives separately what would be a good way to make it to auto-connect a 4th raspi?\n    submitted by    /u/BitterSweetcandyshop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl4dpj/raspi_network_idea/",
          "publishedOn": "2022-12-13T19:24:45.000Z",
          "wordCount": 17907,
          "title": "Raspi Network Idea",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl31gw/need_help_identifying_the_right_power_cable_to/",
          "author": null,
          "description": "What type of power cable is this? Thanks.\n    submitted by    /u/chufenschmirtz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl31gw/need_help_identifying_the_right_power_cable_to/",
          "publishedOn": "2022-12-13T18:32:10.000Z",
          "wordCount": 18586,
          "title": "Need help identifying the right power cable to buy for a long lost hard drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl2tsh/using_a_pixel_1_for_another_backup_location_of/",
          "author": null,
          "description": "Just wondering if anyone else is using this method. I just got my Pixel 1 in from ebay.\n I plan to keep and host all family videos / photos on my server, and have backups on and off site of that server. \n Planning on using something like syncthing to get pics from our phones to the pixel, and then from the pixel to our \"family\" google account.\n Questions:\n  \nWhat is the best way to get pictures from our phones (android and iphone) to my server? Syncthing? Some other app im not thinking of?\n \nIs it really unlimited full res for the life of the phone? I used the \"reduced quality\" for a long time and was never disappointed with the quality of the pictures saved - should I just use that to not piss google off?\n \nAny other tips to get this to work flawlessly? (auto delete from phone after it uploads to google, etc)\n \n    submitted by    /u/bringo24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl2tsh/using_a_pixel_1_for_another_backup_location_of/",
          "publishedOn": "2022-12-13T18:23:49.000Z",
          "wordCount": 17601,
          "title": "Using a Pixel 1 for another backup location of pictures/videos - advice needed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl1vp5/amazon_hdd_not_packed_very_well_tests_fine/",
          "author": null,
          "description": "So I got one of those BF deals for a big external HDD. Inside the outer Amazon box was the inner manufacturer box, but that was actually loose inside of the outer box. HDD itself seemed well packed / protected inside of the Manufacturer box though. \n I documented the way it arrived and ran the an extended SMART driver test using the Manufacturer's utility. Took a couple of days due to size of the drive, but passed with no issues. Ran a few short tests with the same results. \n So my question for my fellow Datahorders is what would you do? Return the drive and hope replacement is packed better or be satisfied with inner box protection + testing? Just curious.\n    submitted by    /u/robbiejay86  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl1vp5/amazon_hdd_not_packed_very_well_tests_fine/",
          "publishedOn": "2022-12-13T17:47:50.000Z",
          "wordCount": 18132,
          "title": "Amazon HDD not packed very well - tests fine - sketchy or no?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl11q3/same_files_take_up_more_space_on_a_different/",
          "author": null,
          "description": "So this may be really basic stuff to some of you but I'm just trying to wrap my head around this..\n I have a music library that measures 59.7gb on my windows 10 laptop SSD. When I have transferred my library to my android phone it suddenly measures 63.97gb (when viewed via the phone's file explorer) and 59.8gb (when the phone is connected by usb and viewed via windows file explorer).\n ​\n Is this normal? Is it just due to differences in the filesystem or formatting or something? I tried searching around a little but I'm struggling to find a solid answer on this and would appreciate some assistance.\n ​\n thankya\n EDIT: appreciate the answers folks. thankyou!\n    submitted by    /u/layzeelightnin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl11q3/same_files_take_up_more_space_on_a_different/",
          "publishedOn": "2022-12-13T17:15:43.000Z",
          "wordCount": 18422,
          "title": "Same files take up more space on a different device?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl0x1o/how_to_scale_from_a_mitx_8bay_setup_silverstone/",
          "author": null,
          "description": "Hello all.\n ​\n I have a NAS in a SilverStone DS380 (8-hotswap bay) along with some external USB 3.0 disk enclosures, making a total of 12x10TB but the pool is starting to get full and I am thinking of adding 4x20TB in short-term (Q1 2023) getting to 12x20TB in the mid-term (Q4 2024).\n ​\n SilverStone DS380 8-bay\n I do not have space for jumping to a rack solution (which is always on my mind and I will do for sure once i move home) so I need to stick in the meantime with tower-based NAS/DAS solutions. The ideal case would be the 12-bay Synology model of the pic, with the possibility to daisy-chain another 12-bay model to it, but I cannot ID it or find a non-rack alternative.\n ​\n ​\n Synology DS 12-bay\n ​\n Basically, I am trying to find a tower-size 8-bay (minimum) to 12-bay (preferable) DAS (no need to be hot-swap) with USB connection to attach it to my DS380 NAS until I move to a real rack solution (early 2025). \n ​\n I have found some solutions from Orico, Mediasonic, Fantec, OWC, Sabrent... but I read a lot of connectionand cooling issues from this solutions I need to avoid as my system is on 24/7 as a backup and media server to 4 users. Plus I find them too overpriced for just a steel case with trayless bays ($50?), 150w low-efficiency PSU ($30?) and a bunch of SATA to USB adapters ($15?).\n ​\n ​\n Mediasonic 8-bay\n ​\n The best option I manage is another DS380 as a JBOD DAS, with a 300W gold SFX PSU, a pair of SSF-8088 connectors and SFF-8087 cables, but I would need to adress the dual-PSU synchronism with a Supermicro JBOD power control board for example and I would need to buy a JBOD card on my main system with external SSF-8088 connectors.\n ​\n Any thoughts on this? I live in Europe so the available solutions may be reduced.\n ​\n Thanks in advance.\n    submitted by    /u/jfromeo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl0x1o/how_to_scale_from_a_mitx_8bay_setup_silverstone/",
          "publishedOn": "2022-12-13T17:10:48.000Z",
          "wordCount": 18030,
          "title": "How to scale from a mITX 8-bay setup (SilverStone DS380)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl0acu/telegram_scraper_help/",
          "author": null,
          "description": "Does any one know a tool to scrap users from telegram groups and add them to your preferred group\n    submitted by    /u/Big-Initiative-2030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl0acu/telegram_scraper_help/",
          "publishedOn": "2022-12-13T16:46:34.000Z",
          "wordCount": 17942,
          "title": "Telegram scraper help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkz6py/is_anyone_else_having_issues_downloading_from/",
          "author": null,
          "description": "Everything is up to date and authorized, cookies and cache has been cleared, etc. \n We get this error - https://i.imgur.com/KVZEwfW.png when getting a .acsm from archive.org and trying to download/view via Adobe Digital Editions. \n Anyone else having this issue?\n    submitted by    /u/QuestPirate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkz6py/is_anyone_else_having_issues_downloading_from/",
          "publishedOn": "2022-12-13T16:03:29.000Z",
          "wordCount": 17027,
          "title": "Is anyone else having issues downloading from archive.org? Since this morning, we've been getting an error in Adobe Digital Editions that prevents download.",
          "imageUrl": "https://external-preview.redd.it/r_T9gs_zFLqBSGoM1rz1nvBsfEYOeONQfkG-8f2IRDQ.png?auto=webp&v=enabled&s=34dea8060d311f4ec5a5de86fb78b28af8af2864"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkz0qj/read_error_rate_is_marked_as_red_and_ive_been/",
          "author": null,
          "description": "submitted by    /u/V0idH3art  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkz0qj/read_error_rate_is_marked_as_red_and_ive_been/",
          "publishedOn": "2022-12-13T15:55:51.000Z",
          "wordCount": 18496,
          "title": "Read Error Rate is marked as Red, and i've been facing difficulty to run operations on this HDD. Any suggestions?",
          "imageUrl": "https://preview.redd.it/7pgy7i0bto5a1.png?auto=webp&s=560a325243b9d2aff11bc020090caa29ef2ab31a"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkw4y6/wd_14tb_easystore_for_19999_1429_tb_at_best_buy/",
          "author": null,
          "description": "submitted by    /u/unsuspectingcueball  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkw4y6/wd_14tb_easystore_for_19999_1429_tb_at_best_buy/",
          "publishedOn": "2022-12-13T13:46:37.000Z",
          "wordCount": 19605,
          "title": "WD 14TB Easystore for 199.99 ($14.29 / TB) at Best Buy and BestBuy eBay Store. Ends 11:59PM Dec 13th",
          "imageUrl": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?auto=webp&v=enabled&s=9b56c069465770cc70354fba8fa2c16490cd485e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkvvsn/plugin_or_tool_to_ping_google_services_affected/",
          "author": null,
          "description": "Hi all,\n As you know Google will start to delete files on in-active accounts starting from January 2023. I was wondering if there is a tool that can login to the account and do some activity so the 2 year policy resets? A simple one to ping the google services like gdrive gmail or other g services so that the inactivity timer resets?\n https://support.google.com/googleone/answer/10214036#activity \n A plugin or a tool that can create and delete a folder on gdrive every 30 days and keeps a track record for example will do the magic I think.\n Thank you\n    submitted by    /u/Jolly-Caramel233  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkvvsn/plugin_or_tool_to_ping_google_services_affected/",
          "publishedOn": "2022-12-13T13:33:50.000Z",
          "wordCount": 17349,
          "title": "Plug-in or tool to ping Google services affected by 2 years inactivity policy by Google.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkvovh/i_want_a_hard_drive_thats_netflix_like_but_does/",
          "author": null,
          "description": "So I was staying at my uncles place, he's in pretty ruff shape was really sick can't leave the house much he's got a shit bag. So he's basically broke but he let us stay at his place for our grandpa's funeral, he doesn't have internet basically has a big stack of DVDs and some Japanese Chanel.\n So basically I want to buy him a hard drive or computer, upload as much as I can fit on it. Then have it set so he can just plug it in, plug an HDMI. If anyone knows what my best route would be I haven't downloaded a torrent in a few years so any tips would help. Thanks\n    submitted by    /u/Pure-Cartographer230  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkvovh/i_want_a_hard_drive_thats_netflix_like_but_does/",
          "publishedOn": "2022-12-13T13:24:41.000Z",
          "wordCount": 19741,
          "title": "I want a hard drive that's Netflix like but does need to be connected to the internet.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkvkik/unreliable_hardware_and_the_false_sense_of/",
          "author": null,
          "description": "Let me spin you a tale as old as time about a man and his data. Hopefully, you can learn that without a solid main setup, even backups cannot save you. \n The story starts in 2016 when I bought my first RAID controller and drives to build my first storage server. Being of young age and with limited means, I opted to cheap out on the controller and buy the (as I later figured out) awful HighPoint Rocketraid 840A, then going for about $300. Compared with an LSI card with 16 ports, that was approximately a third of the price when buying new (Stupid me didn't even consider buying used). Of course, it later turns out that the hardware RAID6 capabilities I bought the card for are not even present, but that is another story for another day. \n So I set up a volume in the card's BIOS, and install so…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkvkik/unreliable_hardware_and_the_false_sense_of/",
          "publishedOn": "2022-12-13T13:18:45.000Z",
          "wordCount": 20792,
          "title": "Unreliable hardware and the false sense of security of backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zktf4k/is_this_normal_92_tb_total_nand_writes_on_a/",
          "author": null,
          "description": "submitted by    /u/Interesting_Sink_254  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zktf4k/is_this_normal_92_tb_total_nand_writes_on_a/",
          "publishedOn": "2022-12-13T11:26:12.000Z",
          "wordCount": 18379,
          "title": "is this normal? 92 TB total NAND writes on a month-old WD Blue SSD",
          "imageUrl": "https://preview.redd.it/7y024rg2zo5a1.png?auto=webp&v=enabled&s=60e62ecde22031a4af4b197504436f74f6ce81b1"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkt9hc/how_to_download_an_entire_wiki/",
          "author": null,
          "description": "I'd like to download the entire SCP wiki so I can browse it offline, but WITHOUT download the comment sections. Is there a software that can do this? How would I limit the software to only download this wiki and any pages closely related to it, without following any possible links to other wikis and downloading those?\n    submitted by    /u/Voldy256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkt9hc/how_to_download_an_entire_wiki/",
          "publishedOn": "2022-12-13T11:17:23.000Z",
          "wordCount": 17603,
          "title": "How to download an entire wiki?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkt3gu/what_nas_to_buy_budget_800/",
          "author": null,
          "description": "Hello all,\n on recommandation of : u/halbzu\n I will post my question here.\n Hello niece and nephews, its testlab01 with a new question and advise needed.\n I want to buy as in the TS says an NAS. a 4bay nas to have it in RAID-5 for fail over. The reason for this is because we are running out of cloud storage on my device as my families devices. Google etc, and when i want to expand the cloud storage i need to pay a lot for something what is not mines. And if i dont pay anymore i still need to store all the files to something local. So in this case an NAS would be the best solution.\n So i know only two brands Synology the number(1) famous NAS brand, and QNAP what is more for professionals i think. My preference self goes to Synology because the software DSM.\n But i am still not really convinced which one to buy. In my shopping cart (eBay) i have added DS920+ and 4x 2tb IronWolf ST4000VN006 in total i will have 12TB of storage with fail over of 1 disk of 4tb.\n In the meantime 923+ came out in November 2022 and is a upgrade compared to the ds920+Pro\"s- 2.5gbps Ethernet port.- upgrade to 16gb ram, not official only upgrade to 8gb with an extra so-dimm 4GB.- new CPU AMD this time (but no GPU processing power, so PLEX will not be the great solution)- now you can have nvme storage pools.\n I am not a big watcher because of work (not that much time) but it would be always good when i have time to watch something without problems.\n My budget is about 800€ less is always better, i have a voucher of 300€ discount so from 966€ will be like 699€ what a good price is for NAS + storage 16GB.\n still to take the 923+ that one is more expensive as well. But getting longer updates as well, or to stay with the 920+ + or even a QNAP to take?\n building a NAS etc, will not be the choice because it will never give you all the bells an whisels what you get with an NAS.\n    submitted by    /u/testlab01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkt3gu/what_nas_to_buy_budget_800/",
          "publishedOn": "2022-12-13T11:07:28.000Z",
          "wordCount": 18686,
          "title": "What NAS to buy? Budget 800€",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkeoig/iso_backups_of_scene_it_discs/",
          "author": null,
          "description": "I used DVDFab to try and backup my Nick scene it dvd and i noticed it ripped extremely quickly. It even says its a large file like a dvd iso should be. Upon booting the iso file the intro screens worked fine but when i select play game it either crashes the video player, or restarts the iso from the start. \n It seems most of the disc doesn’t copy as it should at all, and i cant find any information online on how to fully rip these interactive dvd games. Any ideas?\n    submitted by    /u/Slonkweed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkeoig/iso_backups_of_scene_it_discs/",
          "publishedOn": "2022-12-12T23:00:19.000Z",
          "wordCount": 16427,
          "title": "Iso backups of “scene it?” Discs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zke3o5/western_digital_rma_help_red_pro_nas/",
          "author": null,
          "description": "Hello, I generally lurk and rarely posts here.\n ​\n I saw the Western Digital sale post during Black Friday for the Red Pro NAS drives so I jumped on the chance. Bought 2, and then realized I needed more so bought 2 more. The first 2 drives came perfectly fine, passed SMART and had no problems with stress tests. \n The second batch had huge problems. One, they delivered only ONE drive instead of the two I ordered. Next, the one drive that did arrive was dead on arrival. SMART wasn't even working when I plugged it in. So I tried RMAing it, but that requires registering it. So I tried registering the drive and lo and behold, I get\n \"Sorry! Product registration failed, please try later. (STATCODE108)\" \n Customer support is just running me around the ringer. They keep promising me updates with no updates given after their promised deadline of \"24-48 hours.\" I have gone through both their chat system, garnering me the generic\n (\"Please allow me to inform you that your issue has already been forwarde to our team and they are looking iinto the issue.\")\n and calls - what else can I do? \n I registered the previous 2 drives just fine. All drives were bought directly from the WD online store.\n    submitted by    /u/RockyX123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zke3o5/western_digital_rma_help_red_pro_nas/",
          "publishedOn": "2022-12-12T22:38:57.000Z",
          "wordCount": 2028,
          "title": "Western Digital RMA Help - Red PRO NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkdqq7/a_datahoarding_attempt_that_has_proven_to_be/",
          "author": null,
          "description": "My apologies if this topic does not belong to this group, but I ran out of options and this is my last resource. \n There is in BBC Sounds a podcast called Night Tracks. Each episode is a beautiful collection of classical and rare experimental music. The episodes are only available for certain amount of time and then they are removed from the website. \n I want to collect every single episode but I haven't found any way to download them. I've tried with multiple ad-ons, extensions, and software but it is just imposible. \n Perhaps someone here knows a way. I would deeply appreciate any help.\n    submitted by    /u/Melancholic-Beast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkdqq7/a_datahoarding_attempt_that_has_proven_to_be/",
          "publishedOn": "2022-12-12T22:26:30.000Z",
          "wordCount": 16274,
          "title": "A datahoarding attempt that has proven to be almost impossible",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkcprp/i_cant_copy_a_particular_file_from_dvd/",
          "author": null,
          "description": "first: i didnt grow up with dvds so im a noob.\n i'm trying to rip a video from DVD. but all of the dvd ripping softwares i've tried gave error at exactly 40th minute of the video. i think its becouse VTS_013.VOB file. so i copied other files with DVD Decrypter and skipped VTS_013.VOB to manually copy it with file explorer. but it also gave error. i can run VTS_013.VOB with vlc no issues.\n ​\n ​\n ​\n [00:58:00] hb_init: starting libhb thread # Starting Scan ... [00:58:00] CPU: [00:58:00] - logical processor count: 8 [00:58:00] Intel Quick Sync Video support: no [00:58:00] hb_scan: path=D:\\VIDEO_TS\\VTS_01_3.VOB, title_index=0 udfread ERROR: ECMA 167 Volume Recognition failed src/libbluray/disc/disc.c:333: failed opening UDF image D:\\VIDEO_TS\\VTS_01_3.VOB src/libbluray/disc/disc.c:437: error op…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkcprp/i_cant_copy_a_particular_file_from_dvd/",
          "publishedOn": "2022-12-12T21:50:38.000Z",
          "wordCount": 15902,
          "title": "i cant copy a particular file from DVD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkc7jv/just_accidentally_nuked_90_of_my_video_library/",
          "author": null,
          "description": "submitted by    /u/randombystander3001  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkc7jv/just_accidentally_nuked_90_of_my_video_library/",
          "publishedOn": "2022-12-12T21:32:37.000Z",
          "wordCount": 18144,
          "title": "Just accidentally nuked ~90% of my video library",
          "imageUrl": "https://preview.redd.it/guh9oj5gaj5a1.png?auto=webp&s=8d4162e08a0eb95f5808b839c879287c8e88657b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkbvih/turkish_movies_which_are_hard_to_find_on_torrent/",
          "author": null,
          "description": "submitted by    /u/Sacrer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkbvih/turkish_movies_which_are_hard_to_find_on_torrent/",
          "publishedOn": "2022-12-12T21:20:33.000Z",
          "wordCount": 19521,
          "title": "Turkish movies which are hard to find on torrent are being uploaded with English subtitles to Youtube. Go ahead and back them up.",
          "imageUrl": "https://external-preview.redd.it/ru_AMlstSs-CGi-1_U-UXoek4nQGAg_xK8luucv6hFc.jpg?auto=webp&s=bd24de6703c0cea3f6934e6e3e87ec331933771a"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkbhrv/used_samsung_evo_860_4tb_ssd_buy_or_no/",
          "author": null,
          "description": "I have the opportunity to bulk buy these disks for about $40 a piece. I presume they have been used extensively but have no way to check them before buying. They do guarantee all of them are in working condition. Is this a good deal or is it best to avoid used SSDs like this?\n    submitted by    /u/pain_vin_boursin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkbhrv/used_samsung_evo_860_4tb_ssd_buy_or_no/",
          "publishedOn": "2022-12-12T21:07:02.000Z",
          "wordCount": 16180,
          "title": "Used Samsung EVO 860 4TB SSD - buy or no?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkaexa/synology_nfs41_netshare_headaches/",
          "author": null,
          "description": "Hello data hoarders please spread some knowledge\n I thought I'd burn all my saved up cash during a recession and got myself a decent starter NAS - DS720+, which had some \"new\", read; suspectedly S.M.A.R.T wiped disks from 2014, included.\n My idea was to run my current linux.iso server with the NAS mounted in NFS4.1 and just smack all the sweet linux iso's right onto there.\n Quickly realized I'm getting bottlenecked bigtime, despite running the newest storage tech in RAID 0 for double the speed etc (I kid, don't hurt me). I know Raid0 is stupid but I'll take any performance wins as this will only host data I don't care about losing - not much of a data hoarder, eh.\n Anyways I'm getting cache overloaded to infinity and beyond.\n With some linux.iso testing I did manage to max my gigabit line …",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkaexa/synology_nfs41_netshare_headaches/",
          "publishedOn": "2022-12-12T20:28:36.000Z",
          "wordCount": 18995,
          "title": "Synology NFS4.1 NetShare headaches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zka5fj/wdd_max_digital_data_thoughts_on_increasing/",
          "author": null,
          "description": "https://www.amazon.com/dp/B0BGYV6B9V?psc=1\n A non-\"renewed\" disk drive at a reasonable price! I'm completely unfamiliar with the company however, are these bad signs? Do you guys have any thoughts on this company or this disk in particular? Any recommendations for me? I've been looking on diskprices.com and I'm kind of hung up on buying new/renewed, more drives, lower storage OR less drives, higher storage each... I'm looking to increase my storage capacity for my main rig PC, it's only got a 1TB NVME and an external USB HDD with 4TB. My goal is to hoard the entire Z-Library archive (23TB) and to maybe host my own cloud storage, but until then I'll just piece it together one at a time until a drive fills up or my PC runs out of space. inb4 read the wiki thank you thank you\n    submitted by    /u/Goberoberto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zka5fj/wdd_max_digital_data_thoughts_on_increasing/",
          "publishedOn": "2022-12-12T20:18:56.000Z",
          "wordCount": 17483,
          "title": "WDD (Max Digital Data?) Thoughts on increasing storage for main rig PC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zka49j/data_recovery/",
          "author": null,
          "description": "If an SSD has been formatted can data still be covered from the drive and if so what free software can i use to try and retrieve the data ?\n    submitted by    /u/CumsockFinder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zka49j/data_recovery/",
          "publishedOn": "2022-12-12T20:17:41.000Z",
          "wordCount": 13301,
          "title": "Data recovery",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk98yu/simple_and_comprehensive_approach_to_youtube/",
          "author": null,
          "description": "Hey all, apologies for asking a question I know has been asked a million times. In fact I saw what I'm pretty sure was the answer to my Q a couple weeks ago but have searched and searched and unfortunately can't find it again (shoulda archived it, heh.)\n I'm just starting to become a datahoarder and picked up a Synology NAS. My main motivation was the huge collection of tutorials and other knowledge I've saved on YouTube that may up and disappear one day.\n First Goal: I'm looking for really simple no-code (or very low code - I code all day long, and don't want to have to write/maintain a bunch of this stuff too) way to automatically archive anything I add to a specific YouTube playlist to my Synology NAS. I'd ideally like it to save thumbnails and descriptions as well.\n Second Goal: Some sort of easy interface for browsing, searching, and watching those archived videos, so I'm not just using crummy Windows search to try and find a video in the future.\n Does anyone have suggestions that can address 1 or 2, or both?\n Thanks in advance!\n    submitted by    /u/turn-down-for-what  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk98yu/simple_and_comprehensive_approach_to_youtube/",
          "publishedOn": "2022-12-12T19:45:56.000Z",
          "wordCount": 18202,
          "title": "Simple and comprehensive approach to YouTube archiving + browsing/searching?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk7y1j/any_dedicated_pcie_40_nvme_quad_adapters/",
          "author": null,
          "description": "Looking for something dedicated but less expensive like this for my Windows PC, don't need to have Raid:\n https://eshop.macsales.com/item/OWC/SSDACL4M208T/#customer-reviews\n Thanks!\n    submitted by    /u/MarkGeraz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk7y1j/any_dedicated_pcie_40_nvme_quad_adapters/",
          "publishedOn": "2022-12-12T18:59:25.000Z",
          "wordCount": 17240,
          "title": "Any dedicated PCIe 4.0 NVMe quad adapters?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk7un4/quick_way_to_grab_direct_links_for_discord_uploads/",
          "author": null,
          "description": "i've been using a dead discord channel for random occasional file uploads for like a year, and would like to back them up. anybody know how I could extract the direct attachment urls from the entire channel without manual labor?\n thank\n    submitted by    /u/pbdrizz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk7un4/quick_way_to_grab_direct_links_for_discord_uploads/",
          "publishedOn": "2022-12-12T18:55:54.000Z",
          "wordCount": 16244,
          "title": "quick way to grab direct links for discord uploads?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk7hm7/i_need_help_with_my_first_backup_of_everything/",
          "author": null,
          "description": "So I just bought a ULTRASTAR DC HC310 4TB to use for a backup of everything that's important to me and I'm looking for advices and tips on how to store it.\n I did read different opinions... Someone say to store it powered off in an antistatic bag and wrapped in pluriball. Others instead say that having it powered off corrupt faster the data and also the lubricant on the moving parts dries out so that when you power it on again it will put the drive under extreme friction.\n I have not enough knowledge about this to take a decision on my own so I'm here asking for help. \n Also any other advice will be welcome (such as what to choose when formatting it or anything else that I might not know)\n Thank you to everyone who will help me !\n    submitted by    /u/Cris257  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk7hm7/i_need_help_with_my_first_backup_of_everything/",
          "publishedOn": "2022-12-12T18:43:42.000Z",
          "wordCount": 18621,
          "title": "I need help with my first backup of everything that's important to me",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk7aa0/huge_thanks_to_seagate_and_useagate_surfer_for/",
          "author": null,
          "description": "submitted by    /u/Clawz114  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk7aa0/huge_thanks_to_seagate_and_useagate_surfer_for/",
          "publishedOn": "2022-12-12T18:36:49.000Z",
          "wordCount": 16943,
          "title": "Huge thanks to Seagate and u/Seagate_Surfer for running the IronWolf Pro SSD giveaway! It has found a good home and replaced an ancient OCZ relic.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk788r/best_u2_enclosure/",
          "author": null,
          "description": "I am a moron and have some 15.36tb used enterprise ssd's in U.2 format lying around. What's the best case for them? They get kinda hot so I'd like a fan, replaceable ideal so I can swap it with a moctua\n I don't care about throughput that much but I'd like more than 2 drives stored\n    submitted by    /u/Spirited-Guidance-91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk788r/best_u2_enclosure/",
          "publishedOn": "2022-12-12T18:34:42.000Z",
          "wordCount": 16703,
          "title": "Best U.2 enclosure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk77qt/cloud_solution_for_huge_files_that_cannot_be/",
          "author": null,
          "description": "Hi \n I'm trying to find an online backup solution for my veracrypt container that is around 300GB and growing. Ideally, I want a provider that doesn't require you to split the large file in parts. I'm not certain, but my current understanding is that I cannot split up the container into separate parts...\n ​\n I don't need any syncing. I intend on uploading the entire container once per week. \n ​\n Any suggestions would be much appreciated. \n    submitted by    /u/user44566829  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk77qt/cloud_solution_for_huge_files_that_cannot_be/",
          "publishedOn": "2022-12-12T18:34:11.000Z",
          "wordCount": 17056,
          "title": "Cloud solution for huge files that cannot be split up?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk6efk/upgrading_nas/",
          "author": null,
          "description": "Long time lurker first time posting. Also English is not my first Language so please bear with me. I currently have Synology NAS with 2 bays with 2 4TB hard drives. I want to expand because I'm quickly approaching 7TB. I have my previous desktop computer that has about 8 drive bays that I would like to expand over time. I would like to get some opinions from the experts before I begin throwing time and money at this project.\n What OS/software should I use to manage/initialize my NAS? -- so far I have heard of TrueNAS, FreeNAS, ZFS and Unraid. Note:not even sure if I know what i am talking about here or if there are differences i am not aware of.\n Is expanding my \"pools\" for future additional drives going to be an issue? I don't want to be moving around several TB.\n I also read that my drives would have to be matching in size or I won't be able to use the drive to their fullest extent. I was thinking about going to 12-14 TB drives right away but maybe I should by smaller capacity drives to start out? It just seems that in the future my lower capacity drives with hold me back.\n Thoughts about backups - just looking for some suggestions? I read about snapshots but I'm not sure that applies here. I am familiar with the 3-2-1 rule but with the TB amounts of data I have I can't reasonably buy duplicates of all drives just to have 1 to 1 backups (if that makes sense) but maybe there is no way around this.\n I started off my journey with my synology NAS just to see if it would work and now that I have become a little more serious about my data-hoarding I would like a better setup with more storage as well as implement best practices. I see this as the next logical step before I get something that is rack mounted. Let me know all of your thoughts as I am sure I have missed something or have not thought a position through. Thank you for your help!\n    submitted by    /u/TheKingMongo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk6efk/upgrading_nas/",
          "publishedOn": "2022-12-12T18:04:35.000Z",
          "wordCount": 15962,
          "title": "Upgrading NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk6491/made_myself_python_tooling_to_download_threads/",
          "author": null,
          "description": "Hello everyone,\n As I frequently see interesting threads on Reddit, and I want to get them offline to 1) find them again easily, and 2) preserve them in case messages get removed, I made myself some time ago a Python script to \"download\" threads off Reddit.This script does not only download the thread, but generates a nice HTML file, so it can be opened in a browser and the thread navigated around conveniently. Here is an example of such HTML file.\n Recently, I told myself it would be better to have a web frontend for that tooling, since I am sometimes on the go and do not have the script and/or the Python interpreter on my machine.\n This therefore led to RedditArchive, a Flask self-hosted app to archive and download Reddit threads (screenshots available in the README):https://github.com/Ailothaen/RedditArchiver\n You can install it on a small server of yours, such as a Raspberry Pi or a VPS. Installations instructions are provided if you want to try it on.\n If you do not want to deal with the hassle of setting a web server up, worry not! I also made the original script available here:https://github.com/Ailothaen/RedditArchiver-standalone\n Do not hesitate to comment and make suggestions – I have ideas for further features, but that's probably for another time. 🦉\n    submitted by    /u/Ailothaen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk6491/made_myself_python_tooling_to_download_threads/",
          "publishedOn": "2022-12-12T17:55:16.000Z",
          "wordCount": 17527,
          "title": "Made myself Python tooling to download threads off Reddit (available in Web UI and standalone script)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk62zn/who_are_you_by_profession/",
          "author": null,
          "description": "because date hoarding is quite an expensive hobby.\n    submitted by    /u/kovach_ua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk62zn/who_are_you_by_profession/",
          "publishedOn": "2022-12-12T17:54:04.000Z",
          "wordCount": 17753,
          "title": "Who are you by profession?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk4g75/is_the_write_speed_for_raid_0_normal/",
          "author": null,
          "description": "​\n https://preview.redd.it/57p1d5l0zh5a1.jpg?width=1212&format=pjpg&auto=webp&s=06439c41fe91a67d125fb543db66df7914e6b5fb\n ​\n For background, I am quite new to this. I am a photographer and have been using simple external hard drives to edit and view my photos from. A few months ago, I purchased a 10TB WD Elements desktop hard drive, and the pursuit of having faster read/write speeds (without using SSDs) and joining this subreddit has only heightened that \"passion\" (or addiction?).\n I recently acquired 2x WD Gold 12TB and I have them in the OWC Gemini Dual Thunderbolt 3 enclosure. I have a large amount of photos in which I'd like to use the two drives to store and edit from (I have the appropriate backup system just in case). I would have never thought to go the Raid 0 route but this subred…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk4g75/is_the_write_speed_for_raid_0_normal/",
          "publishedOn": "2022-12-12T16:54:36.000Z",
          "wordCount": 17433,
          "title": "Is the write speed for Raid 0 normal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjrqpl/new_8tb_wd_easystore_the_drive_seems_to_run_great/",
          "author": null,
          "description": "submitted by    /u/fuckAraZobayan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjrqpl/new_8tb_wd_easystore_the_drive_seems_to_run_great/",
          "publishedOn": "2022-12-12T07:50:00.000Z",
          "wordCount": 18903,
          "title": "New 8TB WD easystore: The drive seems to run great, but what is with this crazy raw value for spin up time?",
          "imageUrl": "https://preview.redd.it/hikmqcl0af5a1.png?auto=webp&s=b7344a0069a08a45d7bc90c303ca545c430b63f5"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjo83r/wd_14tb_elements_desktop_usb_30_external_hard/",
          "author": null,
          "description": "submitted by    /u/buhwhytho  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjo83r/wd_14tb_elements_desktop_usb_30_external_hard/",
          "publishedOn": "2022-12-12T05:18:04.000Z",
          "wordCount": 17431,
          "title": "WD 14TB Elements Desktop USB 3.0 External Hard Drive $209.99 ($379.99-$170.00 for $15/TB",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjhnbn/whats_a_good_standalone_dedicated_nas_to/",
          "author": null,
          "description": "Hi, I am looking for a server that I can use to host and stream <2TB worth of videos, which may later expand to 4TB, but I doubt it may expand over that, these are the types of videos I have want that I want to stream.\n  \none-on-one zoom consultations I've done\n \nripped youtube videos \n \nVideos ripped from online courses I've paid for\n \npersonal recorded videos recorded using my phone\n \n My idea is to have a dedicated media(video) library where I can have it all in one dashboard. Instead of having to open up multiple tabs or files (i.e. youtube, google chrome, etc.). \n I don't want to host these videos on any cloud services (i.e. OneDrive, Google Drive, mega.nz, etc.). For fear thay my files/videos get flagged as copyright and my account suspended.\n I'd also like to have the ability to create embedded video links, to put onto my Personal Knowledge Management System (PKM System), which would most likely be a combination of Notion, OneNote and Nimbus Note.\n I already have a Synology NAS DS218+ that I use for cold storage back-up, but it's not suited to host media. I also don't want to have a NAS were I store sensitive files and at the same time open to the web with media hosting. I want these two things, physically compartmentalized.\n I will be the only dedicated-user of these media files being streamed, so there is no worry of bandwidth, when streaming video files.\n    submitted by    /u/ApolloRising434  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjhnbn/whats_a_good_standalone_dedicated_nas_to/",
          "publishedOn": "2022-12-12T01:12:58.000Z",
          "wordCount": 15893,
          "title": "What's a good stand-alone dedicated NAS to host/stream media?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjhcte/i_am_becoming_a_hoarder/",
          "author": null,
          "description": "submitted by    /u/WhyIsIsTakenTaken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjhcte/i_am_becoming_a_hoarder/",
          "publishedOn": "2022-12-12T01:02:34.000Z",
          "wordCount": 15403,
          "title": "I am becoming a hoarder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjg7g2/sas_drives_not_recognized_in_windows_11/",
          "author": null,
          "description": "A few months ago, I accidentally bought the SAS version of a 16TB Seagate Exos, when I meant to get SATA.\n I knew I was planning a new living room PC soon, and having it double as a NAS, so I kept it. I ordered another 16TB SAS drive and a SAS RAID controller a couple weeks ago to put the new computer together. I want to make a basic RAID 1.\n Windows shows the controller as \"Avago adapter sas3 3008 fury - StorPort\" and says the driver is good, but I don't see any sign of the connected drives, or any UI to set up the controller.\n Are there any good guides for this? Any guides I've found assume SATA drives and either the RAID support on the motherboard or Windows virtual volumes -- and that you can actually see that the drives exist before you get started.\n    submitted by    /u/PstScrpt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjg7g2/sas_drives_not_recognized_in_windows_11/",
          "publishedOn": "2022-12-12T00:23:53.000Z",
          "wordCount": 17620,
          "title": "SAS drives not recognized in Windows 11?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjcsp9/wallhaven_organiser/",
          "author": null,
          "description": "Hi All\n I tend to find myself having weird 'me only' issues when hoarding. Im currently sat at over 1m images, from deviantart, pixiv, pinterest but then i discovered wallhaven.....you can see where this is going.\n Assuming you are using gallery-dl with the '--write-metadata' option to download an ID search or batch of single images it will check the json for the file for the username, create a folder structure and then sort the files for that user to the correct folder.\n it'll then add the user account to a txt file for batch downloading of that users uploads. Eventually, ill no doubt have all the user accounts (if they have uploaded) but i then use this for more downloads.\n As an example, i download all the images tagged for cyberpunk 2077 lets say around 300, this is parsed i then have 90 users ready to go and end up with 100k images after running that list. They state they only have about 1m images themselves so shouldn't take long to get it all then just append to my collection.\n I couldn't find a list of all users, a search all(*) or a list of how many IDs they have. But if you know, let me know. I could have just iterated over IDs in a loop 1 to 999999 but thats possibly a lot of waste.\n Anyway......\n As i say, this fits my need for how i scrape stuff from there but thought id share it should someone want to improve/make use of it. Its powershell btw\n https://pastebin.com/q6JXgTL7\n    submitted by    /u/Obvious-Viking  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjcsp9/wallhaven_organiser/",
          "publishedOn": "2022-12-11T22:39:35.000Z",
          "wordCount": 16248,
          "title": "Wallhaven Organiser",
          "imageUrl": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&s=07c121a0180003f7373863af66192b6ff6a937da"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjbo3e/thinking_of_moving_my_copied_blurays_to_external/",
          "author": null,
          "description": "I have about 250-300 blurays that I have made over time. I do not have originals any longer as I sold them off when Bluray was \"hot\". These are now 5+ years old and worried about bluRay rot.\n 90+% of the blurays are LTH 25gb\n Would a 8TB be good enough to store all them? Since streaming is so abundant now and looks to be for the forseeable future unless something serious happened to the world ( nowadays who can say, would it be better to find them on the net when I want?\n Will an external HD be ok if written to and then only accessed when needed ( once or twice a month) and then shut off? \n I am getting older and plan on retiring in next 10 years. I will have plenty of time to watch all my \"classic\" movies a that time. So I am wanting to store all this until I retire. Then my family can deal with it when I pass.... HAHA dont know what they are in for\n 32TB so far not including blurays\n    submitted by    /u/cmdrmcgarrett  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjbo3e/thinking_of_moving_my_copied_blurays_to_external/",
          "publishedOn": "2022-12-11T22:13:35.000Z",
          "wordCount": 16454,
          "title": "Thinking of moving my copied BluRays to external hard drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjbi2f/advice_for_starting_down_the_path_of_a_hoarder/",
          "author": null,
          "description": "After losing a couple SSD's the pain of losing my files was too great. I started doing some research and bought a TerraMaster D4-300 and two 12Tb HDD. I am unsure what would be the best next steps for backing up my files. \n My initial strategy was to start backing up on one HDD 1 and then set up HDD 2 as a mirrored backup. Now that I have it all plugged in, I am unsure about the best way to do that and looking for advice. I am working from a 4TB Macbook Pro that will go back and forth to work with me and ideally, the TM will be a part of a desk/monitor set up I can just connect laptop to when working from home. \n Something like drivepool seems perfect for what I need but I can see from other posts that's not an option for Mac. Should I just set up a ChronoSync task to mirror HDD 1 to HDD 2 and sync whenever I add files?\n I'm a noob at all this so any advice would be greatly appreciated, thanks!\n    submitted by    /u/DaBeigeMage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjbi2f/advice_for_starting_down_the_path_of_a_hoarder/",
          "publishedOn": "2022-12-11T22:09:30.000Z",
          "wordCount": 16966,
          "title": "Advice for starting down the path of a hoarder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjbah6/any_pixiv_scraper_that_can_target_my_follow_list/",
          "author": null,
          "description": "Every pixiv scraper I can find is purely for scraping tags, but I want to bulk download all my followings, coz I follow over 1k people. Any suggestions?\n    submitted by    /u/MayonnaisalSpray  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjbah6/any_pixiv_scraper_that_can_target_my_follow_list/",
          "publishedOn": "2022-12-11T22:04:33.000Z",
          "wordCount": 16761,
          "title": "Any pixiv scraper that can target my follow list or list of users?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjavhw/external_enclosure_question/",
          "author": null,
          "description": "Not sure if this is the right place to ask. At the moment just have a small Pi nas running openmediavault with a 4tb 3.5\" hdd in a sabrent powered enclosure. My one issue: the enclosure has a built in power save/sleep function that I cannot disable. Tried going through and making sure APM was disabled, spindown was disabled, etc, but after exhausting all resources I am fairly sure this is a function of the enclosure(even though it is not listed in the product info anywhere I can find). this causes extremely slow load times for Plex initially and can cause temporary hangups browsing files, etc. Anyone know of a good 3.5\" enclosure that does not have a sleep function? I have been looking online and this was the best option that did not list powersave, and ended up having it anyway. Not ready to pull the trigger on an add-on board yet for the Pi. Thanks for any replies!\n    submitted by    /u/dyno241  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjavhw/external_enclosure_question/",
          "publishedOn": "2022-12-11T21:54:00.000Z",
          "wordCount": 17323,
          "title": "External enclosure question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj9hmh/how_much_space_would_it_take_to_hold_all_of_the/",
          "author": null,
          "description": "Also, would being able to hold this content make it harder for the authorities to deal with book piracy? See here: \n https://join.substack.com/p/copyrights-costs\n  \nAnna’s Archive is active on the normal internet—no need for Tor—and has an “About” page that says: “This website was created by Anna, the person behind the Pirate Library Mirror, which is a backup of the Z-Library shadow library.” And I estimate that people with 300 terabytes of disk space have the ability to personally mirror the totality of the shadow-library material that exists—maybe that’s irrelevant, but the fact that people can personally mirror the totality of the content in question might make it harder to crack down on shadow libraries.\n  \n   submitted by    /u/LinguisticsTurtle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj9hmh/how_much_space_would_it_take_to_hold_all_of_the/",
          "publishedOn": "2022-12-11T21:19:36.000Z",
          "wordCount": 15904,
          "title": "How much space would it take to hold all of the shadow-library content in existence?",
          "imageUrl": "https://external-preview.redd.it/iMgAG5khu2IybQzzkE1u5WD9_vAJy2WSuYo8Ter7P-A.jpg?auto=webp&s=1dac45b95bcde1a6a11afb045a681ba428dc15a4"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj4zl1/found_my_old_yahoo_account_from_2007_and_it_has/",
          "author": null,
          "description": "Is there a way to download the contents of my account in case yahoo goes belly up unexpectedly or something..\n    submitted by    /u/Perfect_Salamander_2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj4zl1/found_my_old_yahoo_account_from_2007_and_it_has/",
          "publishedOn": "2022-12-11T19:25:14.000Z",
          "wordCount": 18100,
          "title": "Found my old yahoo account from 2007 and it has some old emails between my and some family members I'd like to keep.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj4w86/hi_how_to_download_from_internet_archive_using_ia/",
          "author": null,
          "description": "submitted by    /u/mataka54321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj4w86/hi_how_to_download_from_internet_archive_using_ia/",
          "publishedOn": "2022-12-11T19:22:34.000Z",
          "wordCount": 15659,
          "title": "Hi! How to download from Internet Archive using ia downloader, but files keep their original title and not be renamed by doc file \"identifier\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj4dlx/hdd_sentinel_hates_a_drive/",
          "author": null,
          "description": "I've got an ST18000NE000 and it's passed doing 2 read/write surfaces scans and such but it causes the program to die.\n This is the drive before being scanned. \n And after 2 full read/write scans in HDD Sentinel. \n It seems fine to me?\n    submitted by    /u/Eagle1337  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj4dlx/hdd_sentinel_hates_a_drive/",
          "publishedOn": "2022-12-11T19:08:24.000Z",
          "wordCount": 16109,
          "title": "HDD Sentinel Hates a Drive.",
          "imageUrl": "https://external-preview.redd.it/BJO_olifyouTxfmN4HgPgwVa4Sh3jG0C7lgRdbdkKUY.png?auto=webp&s=9a0693ca263083a1bcce3544afcb15301b65a7bc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj4bsc/hdd_transfer_speeds_question/",
          "author": null,
          "description": "I was a little disappointed when I installed a new external HDD in an enclosure and it maxed out at 50 mb/s copying data from my internal nvme SSD, but accepted it for what it was. I just purchased a second external HDD and am copying between the two and have hit 180+ mbs per second which I was not expecting.\n To add further confusion the new drive is plugged into my slower USB port which (they are both 3.0) ruled so by testing an external drive in each port on opposite sides of the laptop, this slower port gets 15 mb/s when transferring from my internal drive.\n Wondering what the bottleneck could be and if there's anything I can do.\n    submitted by    /u/Artifact-O  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj4bsc/hdd_transfer_speeds_question/",
          "publishedOn": "2022-12-11T19:07:01.000Z",
          "wordCount": 16737,
          "title": "HDD transfer speeds question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj1in9/how_to_convert_digitize_mini_cds/",
          "author": null,
          "description": "I’m not too sure where to post this but my Aunts birthday is coming up and I wanted to suppose her by digitizing a huge collection of Mini CDs we had from recording in the Sony Handicam. The problem is I have no idea how to accomplish this. Ive been looking online saying I have to finalize the disks but we lost the Camera a long time ago. And the DVD player I have now is too big for the disk and it doesn’t reach the laser for it to be read. i’ve submitted some pictures for context. Links to products I could use and just advice in general would be much appreciated. I thank any and all who answer in advance. \n https://imgur.com/a/XxFOpAU/\n    submitted by    /u/SuperSpirito  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj1in9/how_to_convert_digitize_mini_cds/",
          "publishedOn": "2022-12-11T17:52:23.000Z",
          "wordCount": 18372,
          "title": "How to Convert / Digitize Mini CDs?",
          "imageUrl": "https://external-preview.redd.it/IFCCfA1gzcM3rYXncct0pGnXMtPEHimLbTZv4SAwghE.jpg?auto=webp&s=2eb91746775e5c5b9d8ae9968bf0cac1d051e989"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziyy34/does_anyone_not_use_raid_in_their_setups/",
          "author": null,
          "description": "I am thinking of buying 30 hard drives because they are so cheap right now, and not doing RAID... maybe backing up on tape or cold storage in the cloud. This is a Plex server for only me and one other family member.\n I'm thinking of assigning each drive to a letter in the alphabet.\n  \nDrive 1 - A [ movies / tv shows / anime ]\n Drive 2 - B [ movies / tv shows / anime ]\n ...\n Drive 26 - Z [...]\n Drive 27 - 0 - 9 [ ... ]\n  \nor\n  \nDrive 1 - A through C [tv shows]\n Drive 2 - ...\n Drive x - A - C [movies] ..\n  \nI have gigabit symmetrical internet and if I ever need to rebuild it's not too painful?\n    submitted by    /u/DigitalSpeed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziyy34/does_anyone_not_use_raid_in_their_setups/",
          "publishedOn": "2022-12-11T16:41:05.000Z",
          "wordCount": 19316,
          "title": "Does anyone not use RAID in their setups?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziyrse/httrack_what_does_happen_if_i_leave_the_scan/",
          "author": null,
          "description": "When I start a new project there are these filters: \n +*.png +*.gif +*.jpg +*.jpeg +*.css +*.js -ad.doubleclick.net/* -mime:application/foobar \n I delete these filters because I am worried that by leaving them then only .png .gif .jpg .jpeg .css .js files will be downloaded and all the other files won't be downloaded, am I correct? \n So I delete the filters and I leave the page blank, but what does happen when the page is left blank? I tried to use the filter +* to see if it is the same thing but then other files are downloaded if I leave the page blank and different files are downloaded if I use the +* filter.\n My question is what is downloaded when no filter is used?\n Another question, what's the difference between this filters:\n +*.png +*.gif +*.jpg +*.jpeg +*.css +*.js -ad.doubleclick.net/* -mime:application/foobar \n and this filters:\n -*\n +*.png +*.gif +*.jpg +*.jpeg +*.css +*.js -ad.doubleclick.net/* -mime:application/foobar\n    submitted by    /u/fjnk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziyrse/httrack_what_does_happen_if_i_leave_the_scan/",
          "publishedOn": "2022-12-11T16:35:56.000Z",
          "wordCount": 16701,
          "title": "HTTrack, what does happen if I leave the Scan Rules (filters) page blank?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziwl8o/psa_to_anyone_who_used_memorex_dvdr_from_2005/",
          "author": null,
          "description": "Pretty sure Memorex isn't a recommended brand anyway, but I figured it can't hurt to put it out there in case someone just didn't know.\n I received a stack of 19 Memorex DVDs from a relative to put them on a flash drive for Christmas. I've gone through 13 so far and 6 have come back with issues.\n In MakeMKV, all but one disc reported:\n Error 'Scsi error - MEDIUM ERROR:L-EC UNCORRECTABLE ERROR' occurred while reading\n The other disc had a different error I don't remember and haven't seen since. Some others were completely unreadable. Some discs were accessible through other means, but any video I could retrieve are severely corrupted so I'll have to copy a bunch of tapes as well to fill in the gaps.\n No discs had any visible damage. No bit rot no scratches. They've been untouched since 2005.\n I'm not asking for any advice, just recording my experience with these discs for others to reference and maybe kick their butt into gear to update their storage situation.\n    submitted by    /u/DeckardTBechard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziwl8o/psa_to_anyone_who_used_memorex_dvdr_from_2005/",
          "publishedOn": "2022-12-11T15:34:03.000Z",
          "wordCount": 18561,
          "title": "PSA to anyone who used Memorex DVD-R from 2005",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziozxs/why_is_it_recommended_to_partition_drives_in_raid/",
          "author": null,
          "description": "I was just reading the arch wiki on setting up RAID and it mentions it's highly recommended to partition the device used for RAID. But it doesn't really explain why. Could someone enlighten me please? Aside from the later suggestion of leaving 100 MiB on the end to make replacement easier is there a reason I should partition the drive before putting it into RAID?\n https://wiki.archlinux.org/title/RAID#Partition_the_devices\n Note: yesterday I did just this but using LVM. So I had 2 18TiB drives, I created 32 partitions about 0.5TiB each and then put them into an LV with total size 18TiB and RAID1 across each device.\n    submitted by    /u/emax-gomax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziozxs/why_is_it_recommended_to_partition_drives_in_raid/",
          "publishedOn": "2022-12-11T11:46:26.000Z",
          "wordCount": 17632,
          "title": "Why is it recommended to partition drives in RAID?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziognu/how_45_drives_open_source_houston_command_center/",
          "author": null,
          "description": "submitted by    /u/It_Is1-24PM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziognu/how_45_drives_open_source_houston_command_center/",
          "publishedOn": "2022-12-11T11:21:30.000Z",
          "wordCount": 15497,
          "title": "How 45 Drives Open Source Houston Command Center Makes ZFS On Linux Easy",
          "imageUrl": "https://external-preview.redd.it/QSt43o6FlOwL5od-fJPC1lDVthKeGhjoK068srqkQG4.jpg?auto=webp&s=306b7ddfb448fcc8423057c899d248ff84d6ab0c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zidk9g/the_archive_of_a_vanishing_world_albert_kahn/",
          "author": null,
          "description": "submitted by    /u/kraft-skunk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zidk9g/the_archive_of_a_vanishing_world_albert_kahn/",
          "publishedOn": "2022-12-11T03:41:06.000Z",
          "wordCount": 17550,
          "title": "The Archive Of A Vanishing World | Albert Kahn sought to preserve a world he perceived to be disappearing. A century later, his “Archives de la Planète” connects disparate lands, dying ecosystems and cultures, and a world being utterly transformed by modernity.",
          "imageUrl": "https://external-preview.redd.it/9DHJeuVooPCWGojgtHm0Z1F2uco5p8696ZdBP0CMx-8.jpg?auto=webp&s=7c691a8611e98b99ec097d693c83a7b7a408e5c8"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi8x68/is_there_a_way_to_archivedownload_all_of_someone/",
          "author": null,
          "description": "Pretty self explanatory, just wanna download my deceased Grandpas whole facebook page for photos and videos - any help would be appreciated!\n    submitted by    /u/Hellboymeep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi8x68/is_there_a_way_to_archivedownload_all_of_someone/",
          "publishedOn": "2022-12-11T00:46:45.000Z",
          "wordCount": 16508,
          "title": "Is there a way to archive/download all of someone elses photos & videos from facebook?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi5r9d/archiving_photos_how_to_copy_and_rename_with/",
          "author": null,
          "description": "I have a flatbed scanner and will use CmdTwain so you only have to click the .bat once and it will scan without having to enter anything or do any settings.\n Now cmdtwain overwrites the output file everytime if I dont change the filename before, so my plan is to use the \"running\" bash file to copy the scanned image into a destination folder, and rename it with an incrementing number (like scan00000, scan00001, scan00002,....)\n Is there a not too complex way of doing this?\n    submitted by    /u/PyroRider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi5r9d/archiving_photos_how_to_copy_and_rename_with/",
          "publishedOn": "2022-12-10T22:32:10.000Z",
          "wordCount": 15501,
          "title": "Archiving photos, how to copy and rename with incrementing number one by one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi4hc0/seagate_ironwolf_truenas_showing_lots_of/",
          "author": null,
          "description": "submitted by    /u/SumSnowMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi4hc0/seagate_ironwolf_truenas_showing_lots_of/",
          "publishedOn": "2022-12-10T21:42:10.000Z",
          "wordCount": 16139,
          "title": "Seagate Ironwolf, TrueNAS Showing lots of read/write/checksum errors shows as faulted, but SMART data is good?",
          "imageUrl": "https://preview.redd.it/jjs5f67l455a1.png?auto=webp&s=d672426ef5b4ff3f980c27126a4b3381cbfbd376"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi430s/backing_up_audible_purchases/",
          "author": null,
          "description": "Is there a tool out there that I can use to help backup my Audible purchases in an open audio format?\n    submitted by    /u/Shazzbot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi430s/backing_up_audible_purchases/",
          "publishedOn": "2022-12-10T21:26:57.000Z",
          "wordCount": 15063,
          "title": "Backing up Audible purchases?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi3yla/replacing_3_disk_apfs_fusion_pool_reference_to/",
          "author": null,
          "description": "Thinking about consolidating several spanned AFS Fusion drives “3 disk pool” to a single disk.\n Anyone that understands read times from a sleep state to fully being able to read the entire file system , how should I select a disk if that is my biggest focus to try and resolve without wanting deep enough pockets to go full SSD?\n Are there drives I should be targeting, so when good deals come up I can confidently select a disk?\n    submitted by    /u/rotarypower101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi3yla/replacing_3_disk_apfs_fusion_pool_reference_to/",
          "publishedOn": "2022-12-10T21:22:16.000Z",
          "wordCount": 15372,
          "title": "Replacing 3 disk APFS Fusion Pool, Reference to learn which ~20TB drives to select for wake/fully readable times?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi3fyz/wd_14_tb_wdbwlg0140hbkeesn_shuckable_shuchworthy/",
          "author": null,
          "description": "Found on https://www.amazon.com.tr/gp/product/B07Y3KDVZH , sold by Amazon Turkey itself, wondering if i should shuck it or just use as usb? Anyone has any experience with this particular hdd?\n ​\n official link is https://www.westerndigital.com/en-gb/products/external-drives/wd-elements-desktop-usb-3-0-hdd#WDBWLG0020HBK-EESN\n    submitted by    /u/ares0027  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi3fyz/wd_14_tb_wdbwlg0140hbkeesn_shuckable_shuchworthy/",
          "publishedOn": "2022-12-10T21:02:28.000Z",
          "wordCount": 15504,
          "title": "WD 14 TB WDBWLG0140HBK-EESN Shuckable? Shuch-worthy for 287$/272€?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi36ao/process_to_get_a_shucked_easystore_rmaed/",
          "author": null,
          "description": "Finally had a drive fail. Have like 50 drives running 24/7 so I guess I can’t complain. \n It’s a 14tb WD easystore from bestbuy I bought 12 months ago. I have a bunch of easystore boxes and the housing and stuff, but I don’t know which housing and box matches the one that died. Does that matter? Or can I just put any other housing and box on it?\n    submitted by    /u/sittingmongoose  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi36ao/process_to_get_a_shucked_easystore_rmaed/",
          "publishedOn": "2022-12-10T20:51:36.000Z",
          "wordCount": 15345,
          "title": "Process to get a shucked Easystore rmaed?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi2k60/question_about_potential_bad_drive_in_nas/",
          "author": null,
          "description": "Hello r/DataHoarder, first time long time.\n I have two hard drives I need some quick help with.\n Drive #1\n First is a Western Digital (I know) Red 3TB drive in my PR4100 NAS (I know, I know). Right now the software flags it but does not tell me why. When I check the SMART data via the NAS software, it seems to give me the same info for all 4 drives. (Clicking SMART on 2,3,4 all give the same numbers) This drive is under warranty, so I plan to buy a Seagate and use the RMA WD as a cold backup. But any info on how to get a SMART dump from that individual drive, or figure exactly why it's showing as bad, would be appreciated. This is my second WD drive to die within a year of purchase.\n Drive #2\n Second is a 4TB Western Digital (I know, I know, I know) Blue sitting inside my desktop. This one is giving me an Uncorrectable Sector Count. CrystalDisk just flags it as caution, but I'm not very familiar on the risk here. Also WD's software gives it a cleanbill of health. Should I just replace it, or is it fine for the time being? There is nothing really critical on that drive, so it's not a big problem if it just bites the dust out of the blue. But I would rather avoid it if possible.\n Thanks in advance.\n    submitted by    /u/Jim777PS3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi2k60/question_about_potential_bad_drive_in_nas/",
          "publishedOn": "2022-12-10T20:26:26.000Z",
          "wordCount": 16542,
          "title": "Question about potential bad drive in NAS",
          "imageUrl": "https://external-preview.redd.it/8aLzPI5zMH1z30pQOJ6RR9XvYbvYjQ0BG6U9nkSz9Yg.jpg?auto=webp&s=4a179790006ead8fd186c89a1d4df50d9d32189b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi18rt/question_about_tbw_for_samsung_980_pro/",
          "author": null,
          "description": "I recently installed a 2 TB Samsung Pro 980 M.2 Nvme to use as my boot drive. I cloned my original boot drive which was about 250 GB to the M.2. After a week of computer use, my M.2 states it has 1.2 TB written to it in Samsung magician. Is this normal? I have not installed anything else other than to copy the boot drive to the Nvme.\n    submitted by    /u/Insanity8016  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi18rt/question_about_tbw_for_samsung_980_pro/",
          "publishedOn": "2022-12-10T19:34:32.000Z",
          "wordCount": 16451,
          "title": "Question about TBW for Samsung 980 Pro",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi0pff/are_you_ready_the_cern_released_200_tb_from_the/",
          "author": null,
          "description": "submitted by    /u/sersoniko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi0pff/are_you_ready_the_cern_released_200_tb_from_the/",
          "publishedOn": "2022-12-10T19:11:57.000Z",
          "wordCount": 16246,
          "title": "Are you ready? The CERN released 200 TB from the LHC to the public",
          "imageUrl": "https://external-preview.redd.it/9dMGnerLVSXi5wKf-9Wj9zrx7GZbjxheGslxHFRbli4.jpg?auto=webp&s=a41d07dd00dd16510e84be529836a2c19c715aaa"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi00j3/has_unas_gone_out_of_business/",
          "author": null,
          "description": "Not hearing back from their sales team at all, their website has said 'will be back in stock Mid-July' since June of this year. Getting more and more discouraged that my hopes for a SFF NAS are shot. The NSC-810 seems one-of-a-kind (cheap knockoffs notwithstanding).\n    submitted by    /u/stempoweredu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi00j3/has_unas_gone_out_of_business/",
          "publishedOn": "2022-12-10T18:43:57.000Z",
          "wordCount": 15868,
          "title": "Has U-NAS gone out of business?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhyp59/wd_registration_issues/",
          "author": null,
          "description": "submitted by    /u/root54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhyp59/wd_registration_issues/",
          "publishedOn": "2022-12-10T17:51:14.000Z",
          "wordCount": 16514,
          "title": "WD Registration Issues",
          "imageUrl": "https://preview.redd.it/xviaonpez35a1.png?auto=webp&s=1cc51c8acbf4d0d584c1ed83cb8f7f50b97c29b1"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhym9p/wd_red_pro_serial_number_not_found/",
          "author": null,
          "description": "I bought a few 16TB Red Pro drives from the WD store during the WD Black Friday sale. I tried to register them, but 2 drives came back saying invalid S/N. Has anyone run into this lately? \n The drives arrived in good condition, correct packaging and sealed anti-static bags. Unfortunately, one of the bad serial numbers is from a DOA drive that needs to be exchanged. I will call support on Monday. I'm just interested if anyone else has experienced this from WD Store fulfilled drives. Thanks\n    submitted by    /u/GroundWireNeutral  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhym9p/wd_red_pro_serial_number_not_found/",
          "publishedOn": "2022-12-10T17:48:01.000Z",
          "wordCount": 15786,
          "title": "WD Red Pro serial number not found",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhyex1/ig_story_downloading/",
          "author": null,
          "description": "So what’s the latest way to download stories without getting your account locked and temp banned? All the sites I was using the past few years all now trigger the account lock instantly. Anyone have a solution to this?\n    submitted by    /u/haggard929  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhyex1/ig_story_downloading/",
          "publishedOn": "2022-12-10T17:39:43.000Z",
          "wordCount": 15107,
          "title": "IG story downloading",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhxv1x/twitter_to_begin_purging_accounts/",
          "author": null,
          "description": "submitted by    /u/themadprogramer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhxv1x/twitter_to_begin_purging_accounts/",
          "publishedOn": "2022-12-10T17:17:45.000Z",
          "wordCount": 15651,
          "title": "Twitter to begin purging accounts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhxcl1/mechanical_startup_failure_in_gsmartcontrol/",
          "author": null,
          "description": "I bought 20tb WD Elements HDD on Black Friday, run smartctl short & long test and used GSmartControl to view the results. All the stats seemed to be alright and the HDD passed the test. Except in the statistics tab, I found that the HDD had \"Number of Mechanical Start Failures\" value 29. I haven't found much info online and so I contacted WD support and they advised me to replace the HDD, which I did. Yesterday I (finally) received new HDD, and already, after running short test (not sure if I even had to run the test TBH), I am seeing that the NoMSF is 28.\n What the hell, I need to populate my media server!\n Should I replace it again, risk it, repair it (yeah, nah)? Does anyone have any similar experience, or knowledge that can help?\n ​\n Also. I have some crazy RAW values for 2 \"unknown attributes\", but I guess that's some proprietary WD thingie which GSC can't read?\n ​\n ​\n GSC\n GSC \n    submitted by    /u/Zeebedee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhxcl1/mechanical_startup_failure_in_gsmartcontrol/",
          "publishedOn": "2022-12-10T16:57:09.000Z",
          "wordCount": 15336,
          "title": "Mechanical startup failure in GSmartControl",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhxaqb/accidentally_deleted_300_music_sessions_please/",
          "author": null,
          "description": "Hello, in a bit of shock.\n I just noticed I accidentally deleted almost all of my Logic sessions this week.\n To clean up my desktop I put everything in a folder, and by mistake I deleted that folder.\n I have some backups, but not of recent sessions and not of component files like drum kits.\n Please, give me all your suggestions for what I should do to go about recovering my life’s work. I have contacted a local data recovery service about an appointment. NYC area. 2016 MBP OS Catalina.\n This post may be slightly orthogonal to the subreddit but this is devastating to me.\n    submitted by    /u/quick_advert  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhxaqb/accidentally_deleted_300_music_sessions_please/",
          "publishedOn": "2022-12-10T16:54:44.000Z",
          "wordCount": 17717,
          "title": "Accidentally deleted 300 music sessions. Please help.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhx6zw/best_way_to_refresh_data_on_an_ssd_for_long_term/",
          "author": null,
          "description": "I might be mistaken here but is refreshing the charges in SSD NAND as easy as reading the files? Could we not just run something like dd if=/dev/{SSD} of=/dev/null periodically to ensure the data is healthy?\n    submitted by    /u/oeCake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhx6zw/best_way_to_refresh_data_on_an_ssd_for_long_term/",
          "publishedOn": "2022-12-10T16:50:04.000Z",
          "wordCount": 17019,
          "title": "Best way to refresh data on an SSD for long term storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhwimk/made_a_python_script_to_download_your_wattpad/",
          "author": null,
          "description": "submitted by    /u/MRtecno98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhwimk/made_a_python_script_to_download_your_wattpad/",
          "publishedOn": "2022-12-10T16:21:08.000Z",
          "wordCount": 15701,
          "title": "Made a python script to download your Wattpad library in EPUB format",
          "imageUrl": "https://external-preview.redd.it/rGCC9rRPs4fHX-So2Xfsisq-f2R2Aaqbs6efxFmT8lo.jpg?auto=webp&s=c2cb9d755e0645a136c9babedeeb91878a5fa87b"
        }
      ]
    },
    {
      "title": "Hacker News",
      "feedUrl": "https://news.ycombinator.com/rss",
      "siteUrl": "https://news.ycombinator.com/",
      "articles": [
        {
          "id": "https://www.agriculture.com/news/business/kansas-research-shows-reintroducing-bison-on-tallgrass-prairie-doubles-plant-diversity",
          "author": null,
          "description": "Comments",
          "link": "https://www.agriculture.com/news/business/kansas-research-shows-reintroducing-bison-on-tallgrass-prairie-doubles-plant-diversity",
          "publishedOn": "2023-01-09T00:03:59.000Z",
          "wordCount": 2938,
          "title": "Reintroducing bison on tallgrass prairie doubles plant diversity",
          "imageUrl": "https://static.agriculture.com/styles/width_550/s3/image/2021/12/20/buffalo-standing-in-front-of-herd.jpg"
        },
        {
          "id": "https://archive.org/details/furby-source",
          "author": null,
          "description": "Comments",
          "link": "https://archive.org/details/furby-source",
          "publishedOn": "2023-01-09T00:00:11.000Z",
          "wordCount": 4087,
          "title": "Furby source code (1998)",
          "imageUrl": "https://archive.org/services/img/furby-source"
        },
        {
          "id": "https://donhopkins.medium.com/alan-kay-on-should-web-browsers-have-stuck-to-being-document-viewers-and-a-discussion-of-news-5cb92c7b3445",
          "author": null,
          "description": "Comments",
          "link": "https://donhopkins.medium.com/alan-kay-on-should-web-browsers-have-stuck-to-being-document-viewers-and-a-discussion-of-news-5cb92c7b3445",
          "publishedOn": "2023-01-08T23:39:23.000Z",
          "wordCount": 17040,
          "title": "Alan Kay on web browsers, document viewers, Smalltalk, NeWS and HyperCard",
          "imageUrl": "https://miro.medium.com/max/505/0*Wvl03NoTLMGlj5Fa"
        },
        {
          "id": "https://donmelton.com/2013/01/10/safari-is-released-to-the-world/",
          "author": null,
          "description": "Comments",
          "link": "https://donmelton.com/2013/01/10/safari-is-released-to-the-world/",
          "publishedOn": "2023-01-08T23:26:00.000Z",
          "wordCount": 1294,
          "title": "Safari is released to the world (2013)",
          "imageUrl": null
        },
        {
          "id": "https://davidesnotes.com/shorts/1/",
          "author": null,
          "description": "Comments",
          "link": "https://davidesnotes.com/shorts/1/",
          "publishedOn": "2023-01-08T23:07:52.000Z",
          "wordCount": 272,
          "title": "Unbricking a Bios-Bricked Motherboard",
          "imageUrl": null
        },
        {
          "id": "https://github.com/google/cdc-file-transfer",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/google/cdc-file-transfer",
          "publishedOn": "2023-01-08T21:46:29.000Z",
          "wordCount": 2766,
          "title": "CDC File Transfer",
          "imageUrl": "https://opengraph.githubassets.com/8a6ed653aadde4e34f1de40a44f25ee424b8c3211bff08ae0da1bdecb28376a1/google/cdc-file-transfer"
        },
        {
          "id": "https://inference-review.com/article/smells-spanners-and-switches",
          "author": null,
          "description": "Comments",
          "link": "https://inference-review.com/article/smells-spanners-and-switches",
          "publishedOn": "2023-01-08T21:29:48.000Z",
          "wordCount": 5370,
          "title": "Smells, Spanners, and Switches (2016)",
          "imageUrl": "http://inference-review.com/assets/img/meta/smells-spanners-switches.jpg"
        },
        {
          "id": "https://longform.asmartbear.com/docs/fulfillment/",
          "author": null,
          "description": "Comments",
          "link": "https://longform.asmartbear.com/docs/fulfillment/",
          "publishedOn": "2023-01-08T20:55:50.000Z",
          "wordCount": 3648,
          "title": "Finding Fulfillment",
          "imageUrl": "https://longform.asmartbear.com/docs/fulfillment/HWW-JasonCohen-v8-30m-SaaStr-transparent-edges.png"
        },
        {
          "id": "https://www.holoniq.com/notes/2022-climate-tech-vc-funding-totals-70-1b-up-89-from-37-0b-in-2021",
          "author": null,
          "description": "Comments",
          "link": "https://www.holoniq.com/notes/2022-climate-tech-vc-funding-totals-70-1b-up-89-from-37-0b-in-2021",
          "publishedOn": "2023-01-08T20:14:09.000Z",
          "wordCount": 2832,
          "title": "2022 Climate Tech VC funding totals $70.1B, up 89% on 2021",
          "imageUrl": "https://assets-global.website-files.com/620ed79721f9271deec09721/63b21838941bfa05a9044e64_Slide3.png"
        },
        {
          "id": "https://pr0g.github.io/mathematics/matrix/2022/12/26/column-row-major.html",
          "author": null,
          "description": "Comments",
          "link": "https://pr0g.github.io/mathematics/matrix/2022/12/26/column-row-major.html",
          "publishedOn": "2023-01-08T19:42:04.000Z",
          "wordCount": 4347,
          "title": "Column major and row major vectors and matrices (for games)",
          "imageUrl": null
        },
        {
          "id": "https://words.filippo.io/dispatches/whoami-updated/",
          "author": null,
          "description": "Comments",
          "link": "https://words.filippo.io/dispatches/whoami-updated/",
          "publishedOn": "2023-01-08T18:40:23.000Z",
          "wordCount": 1518,
          "title": "ssh whoami.filippo.io",
          "imageUrl": "https://words.filippo.io/content/images/2023/01/photo---1-1.jpeg"
        },
        {
          "id": "https://blog.waleedkhan.name/git-ui-features/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.waleedkhan.name/git-ui-features/",
          "publishedOn": "2023-01-08T18:17:58.000Z",
          "wordCount": 1490,
          "title": "Where are my Git UI features from the future?",
          "imageUrl": null
        },
        {
          "id": "https://hexdocs.pm/owl/readme.html",
          "author": null,
          "description": "Comments",
          "link": "https://hexdocs.pm/owl/readme.html",
          "publishedOn": "2023-01-08T17:13:45.000Z",
          "wordCount": 193,
          "title": "Owl: A toolkit for writing command-line user interfaces in Elixir",
          "imageUrl": null
        },
        {
          "id": "https://journal.paoloamoroso.com/my-encounter-with-medley-interlisp",
          "author": null,
          "description": "Comments",
          "link": "https://journal.paoloamoroso.com/my-encounter-with-medley-interlisp",
          "publishedOn": "2023-01-08T17:05:26.000Z",
          "wordCount": 1340,
          "title": "My encounter with Medley Interlisp",
          "imageUrl": "https://i.snap.as/JfkNiEHe.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=ZpCrBBj6AWE",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=ZpCrBBj6AWE",
          "publishedOn": "2023-01-08T17:01:36.000Z",
          "wordCount": null,
          "title": "Playing Zork with AI-generated imagery [video]",
          "imageUrl": null
        },
        {
          "id": "https://www.the-scientist.com/foundations/universe-25-1968-1973-69941",
          "author": null,
          "description": "Comments",
          "link": "https://www.the-scientist.com/foundations/universe-25-1968-1973-69941",
          "publishedOn": "2023-01-08T15:20:34.000Z",
          "wordCount": 1716,
          "title": "Universe 25, 1968–1973 (2022)",
          "imageUrl": "https://cdn.the-scientist.com/assets/articleNo/69941/aImg/45793/article-foundations-mayd1-2022-m.jpg"
        },
        {
          "id": "https://www.theverge.com/2022/12/26/23519605/tiktok-viral-videos-privacy-surveillance-street-interviews-vlogs",
          "author": null,
          "description": "Comments",
          "link": "https://www.theverge.com/2022/12/26/23519605/tiktok-viral-videos-privacy-surveillance-street-interviews-vlogs",
          "publishedOn": "2023-01-08T14:57:32.000Z",
          "wordCount": 9594,
          "title": "Please don’t film me in 2023",
          "imageUrl": "https://cdn.vox-cdn.com/thumbor/qWu6mVEcsT156Q8frwiXPamhUv0=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23318437/akrales_220309_4977_0292.jpg"
        },
        {
          "id": "https://fanpu.io/blog/2023/latex-tips/",
          "author": null,
          "description": "Comments",
          "link": "https://fanpu.io/blog/2023/latex-tips/",
          "publishedOn": "2023-01-08T14:22:30.000Z",
          "wordCount": 4378,
          "title": "The Art of LaTeX: Common mistakes and advice for typesetting proofs",
          "imageUrl": null
        },
        {
          "id": "http://steamtraen.blogspot.com/2021/10/a-bug-and-dilemma.html",
          "author": null,
          "description": "Comments",
          "link": "http://steamtraen.blogspot.com/2021/10/a-bug-and-dilemma.html",
          "publishedOn": "2023-01-08T11:34:53.000Z",
          "wordCount": 4744,
          "title": "A bug and a dilemma (2021)",
          "imageUrl": "https://lh3.googleusercontent.com/--Twnct13bQU/YX6kRpCeU6I/AAAAAAAAGY4/VHYD63BPE6U8HJKnLrS7DlOjWmKGCk5WACLcBGAsYHQ/w1200-h630-p-k-no-nu/image.png"
        },
        {
          "id": "https://prospect.org/world/best-tax-system-on-earth-faroe-islands/",
          "author": null,
          "description": "Comments",
          "link": "https://prospect.org/world/best-tax-system-on-earth-faroe-islands/",
          "publishedOn": "2023-01-08T11:34:52.000Z",
          "wordCount": 5629,
          "title": "Tax System in the Faroe Islands",
          "imageUrl": "https://prospect.org/downloads/18863/download/DEC22%20Cooper%20home.jpg?cb=66e26dc69d693bba95d8b1c2300dc43c&w=1200"
        },
        {
          "id": "https://www.openstenoproject.org/plover/",
          "author": null,
          "description": "Comments",
          "link": "https://www.openstenoproject.org/plover/",
          "publishedOn": "2023-01-08T11:01:39.000Z",
          "wordCount": 497,
          "title": "Plover: free, open-source stenography engine",
          "imageUrl": null
        },
        {
          "id": "https://mitxela.com/projects/dotfiles_management",
          "author": null,
          "description": "Comments",
          "link": "https://mitxela.com/projects/dotfiles_management",
          "publishedOn": "2023-01-08T05:38:57.000Z",
          "wordCount": 1102,
          "title": "Dotfiles Management",
          "imageUrl": null
        },
        {
          "id": "https://nostalgebraist.tumblr.com/post/705192637617127424/gpt-4-prediction-it-wont-be-very-useful",
          "author": null,
          "description": "Comments",
          "link": "https://nostalgebraist.tumblr.com/post/705192637617127424/gpt-4-prediction-it-wont-be-very-useful",
          "publishedOn": "2023-01-08T01:08:14.000Z",
          "wordCount": 3461,
          "title": "GPT-4 prediction: it won’t be useful",
          "imageUrl": null
        },
        {
          "id": "http://cseo-coherence.microsoft.com/",
          "author": null,
          "description": "Comments",
          "link": "http://cseo-coherence.microsoft.com/",
          "publishedOn": "2023-01-08T00:16:45.000Z",
          "wordCount": 133,
          "title": "Microsoft subdomain takeover",
          "imageUrl": null
        },
        {
          "id": "https://eriugenareview.com/posts/f/is-ireland-still-ireland",
          "author": null,
          "description": "Comments",
          "link": "https://eriugenareview.com/posts/f/is-ireland-still-ireland",
          "publishedOn": "2023-01-07T23:53:48.000Z",
          "wordCount": 7485,
          "title": "Is Ireland Still Ireland?",
          "imageUrl": "https://img1.wsimg.com/isteam/ip/907c3825-f593-4759-b627-d9ffd7724cac/Eriugena%20Photo%20Cover.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=oponIfu5L3Y",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=oponIfu5L3Y",
          "publishedOn": "2023-01-07T22:56:37.000Z",
          "wordCount": null,
          "title": "Afroman – Will You Help Me Repair My Door (Official Music Video)",
          "imageUrl": null
        },
        {
          "id": "https://www.theatlantic.com/books/archive/2023/01/turn-every-page-documentary-robert-caro-robert-gottlieb/672651/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theatlantic.com/books/archive/2023/01/turn-every-page-documentary-robert-caro-robert-gottlieb/672651/",
          "publishedOn": "2023-01-07T22:42:36.000Z",
          "wordCount": 2681,
          "title": "A civil war over semicolons: Robert Caro and his editor",
          "imageUrl": "https://cdn.theatlantic.com/thumbor/tUD-18GppXfw7egLywoDQ3pqLmQ=/76x1593:2160x2678/1200x625/media/img/mt/2023/01/civil_war_over_semicolons_2/original.jpg"
        },
        {
          "id": "https://www.jamesshore.com/v2/projects/testing-without-mocks/testing-without-mocks",
          "author": null,
          "description": "Comments",
          "link": "https://www.jamesshore.com/v2/projects/testing-without-mocks/testing-without-mocks",
          "publishedOn": "2023-01-07T22:26:07.000Z",
          "wordCount": 12719,
          "title": "Testing Without Mocks: A Pattern Language",
          "imageUrl": null
        },
        {
          "id": "https://github.com/Airblader/i3",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Airblader/i3",
          "publishedOn": "2023-01-07T21:26:34.000Z",
          "wordCount": 1346,
          "title": "The i3-gaps project has been merged with i3",
          "imageUrl": "https://opengraph.githubassets.com/40e8dfb49a2718822e5ba4523bd2bd80f8ec4fbc25f6f8d02397d264305bda9f/Airblader/i3"
        },
        {
          "id": "https://worthdoingbadly.com/macappsios/",
          "author": null,
          "description": "Comments",
          "link": "https://worthdoingbadly.com/macappsios/",
          "publishedOn": "2023-01-07T21:06:25.000Z",
          "wordCount": 2872,
          "title": "Jailbroken iOS can't run macOS apps – I spent a week to find out why (2021)",
          "imageUrl": null
        },
        {
          "id": "https://henrikwarne.com/2023/01/07/there-is-no-software-maintenance/",
          "author": null,
          "description": "Comments",
          "link": "https://henrikwarne.com/2023/01/07/there-is-no-software-maintenance/",
          "publishedOn": "2023-01-07T20:06:43.000Z",
          "wordCount": 3687,
          "title": "There Is No Software Maintenance",
          "imageUrl": "https://henrikwarne1.files.wordpress.com/2023/01/img_20230106_124326.jpg"
        },
        {
          "id": "https://embeddeduse.com/2023/01/06/using-qt-5-15-and-qt-6-under-lgplv3/",
          "author": null,
          "description": "Comments",
          "link": "https://embeddeduse.com/2023/01/06/using-qt-5-15-and-qt-6-under-lgplv3/",
          "publishedOn": "2023-01-07T19:31:33.000Z",
          "wordCount": 7886,
          "title": "Using Qt 6 under LGPLv3",
          "imageUrl": "https://i0.wp.com/embeddeduse.com/wp-content/uploads/2023/01/qt6-licensing.png?fit=900%2C638&ssl=1"
        },
        {
          "id": "https://www.algolia.com/blog/ai/why-chatgpt-wont-replace-search-engines-any-time-soon/",
          "author": null,
          "description": "Comments",
          "link": "https://www.algolia.com/blog/ai/why-chatgpt-wont-replace-search-engines-any-time-soon/",
          "publishedOn": "2023-01-07T19:18:08.000Z",
          "wordCount": 9422,
          "title": "ChatGPT won’t replace search engines any time soon",
          "imageUrl": "https://res.cloudinary.com/hilnmyskv/image/upload/q_auto,f_auto/v1672911177/Algolia_com_Blog_assets/Featured_images/ai/why-chatgpt-wont-replace-search-engines-any-time-soon/sy4hhqtb0hxqthnoijfo.png"
        },
        {
          "id": "https://www.marineinsight.com/environment/aral-sea-disaster-why-one-of-the-biggest-inland-seas-dried-up/",
          "author": null,
          "description": "Comments",
          "link": "https://www.marineinsight.com/environment/aral-sea-disaster-why-one-of-the-biggest-inland-seas-dried-up/",
          "publishedOn": "2023-01-07T19:04:14.000Z",
          "wordCount": 9039,
          "title": "The Aral Sea has shrunk because of the re-routing of its source rivers (2022)",
          "imageUrl": "https://www.marineinsight.com/wp-content/uploads/2011/10/f04683f1701b9a4d3e30ab850dfa_grande.jpg"
        },
        {
          "id": "https://scalibq.wordpress.com/2023/01/07/when-is-a-pc-not-a-pc-the-pc-98/",
          "author": null,
          "description": "Comments",
          "link": "https://scalibq.wordpress.com/2023/01/07/when-is-a-pc-not-a-pc-the-pc-98/",
          "publishedOn": "2023-01-07T18:54:24.000Z",
          "wordCount": 4855,
          "title": "When is a PC not a PC? The PC-98",
          "imageUrl": "https://scalibq.files.wordpress.com/2023/01/800px-pc9800_set.jpg"
        },
        {
          "id": "https://thume.ca/2023/01/02/one-machine-twitter/",
          "author": null,
          "description": "Comments",
          "link": "https://thume.ca/2023/01/02/one-machine-twitter/",
          "publishedOn": "2023-01-07T18:46:51.000Z",
          "wordCount": 8018,
          "title": "Production Twitter on one machine? 100Gbps NICs and NVMe are fast",
          "imageUrl": null
        },
        {
          "id": "https://hbr.org/2016/09/excess-management-is-costing-the-us-3-trillion-per-year",
          "author": null,
          "description": "Comments",
          "link": "https://hbr.org/2016/09/excess-management-is-costing-the-us-3-trillion-per-year",
          "publishedOn": "2023-01-07T17:46:05.000Z",
          "wordCount": 2756,
          "title": "Excess management is costing the U.S. $3T per year (2016)",
          "imageUrl": "https://hbr.org/resources/images/article_assets/2016/09/sept16-05-hbr-juan-diaz-faes-managing-people.jpg"
        },
        {
          "id": "https://researchbuzz.me/2022/12/28/mastodon-web-space-search/",
          "author": null,
          "description": "Comments",
          "link": "https://researchbuzz.me/2022/12/28/mastodon-web-space-search/",
          "publishedOn": "2023-01-07T17:01:27.000Z",
          "wordCount": 2696,
          "title": "Mastodon Web Space Search Tool",
          "imageUrl": "https://i0.wp.com/researchbuzz.me/wp-content/uploads/2022/12/DALL·E-2022-12-28-11.58.45-A-mastodon-dressed-like-Sherlock-Holmes.-He-is-facing-you.-He-is-looking-through-a-magnifying-glass.-Colorful-pop-art-1.png?fit=715%2C719&ssl=1"
        },
        {
          "id": "https://futurecoder.io/",
          "author": null,
          "description": "Comments",
          "link": "https://futurecoder.io/",
          "publishedOn": "2023-01-07T16:29:30.000Z",
          "wordCount": 556,
          "title": "Show HN: Futurecoder – A free interactive Python course for coding beginners",
          "imageUrl": "https://futurecoder.io/static/logo/bordered.png"
        },
        {
          "id": "https://nautil.us/will-we-know-alien-life-when-we-see-it-256501/",
          "author": null,
          "description": "Comments",
          "link": "https://nautil.us/will-we-know-alien-life-when-we-see-it-256501/",
          "publishedOn": "2023-01-07T16:24:13.000Z",
          "wordCount": 7988,
          "title": "Will we know alien life when we see it?",
          "imageUrl": "https://assets.nautil.us/sites/3/nautilus/Feehly_HERO.png?auto=compress&fm=png&ixlib=php-3.3.1"
        },
        {
          "id": "https://obyford.com/posts/the-safari-bug-that-never-was/",
          "author": null,
          "description": "Comments",
          "link": "https://obyford.com/posts/the-safari-bug-that-never-was/",
          "publishedOn": "2023-01-07T16:06:23.000Z",
          "wordCount": 1325,
          "title": "The Safari bug that never was (2022)",
          "imageUrl": null
        },
        {
          "id": "https://lsc.cornell.edu/how-to-study/taking-notes/cornell-note-taking-system/",
          "author": null,
          "description": "Comments",
          "link": "https://lsc.cornell.edu/how-to-study/taking-notes/cornell-note-taking-system/",
          "publishedOn": "2023-01-07T16:05:02.000Z",
          "wordCount": 1101,
          "title": "The Cornell Note Taking System",
          "imageUrl": null
        },
        {
          "id": "https://www.nationalgeographic.co.uk/history-and-civilisation/2022/08/the-science-of-why-you-have-great-ideas-in-the-shower",
          "author": null,
          "description": "Comments",
          "link": "https://www.nationalgeographic.co.uk/history-and-civilisation/2022/08/the-science-of-why-you-have-great-ideas-in-the-shower",
          "publishedOn": "2023-01-07T15:51:22.000Z",
          "wordCount": 3501,
          "title": "The science of having ideas in the shower",
          "imageUrl": "https://static.nationalgeographic.co.uk/files/styles/image_3200/public/h_15513285.jpg?w=400&h=400&q=75"
        },
        {
          "id": "https://static.roland.com/assets/media/pdf/guitar_effects_guidebook_vol_20.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://static.roland.com/assets/media/pdf/guitar_effects_guidebook_vol_20.pdf",
          "publishedOn": "2023-01-07T14:43:57.000Z",
          "wordCount": 149238,
          "title": "Guitar Effects Guidebook, Vol. 20 [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://constructionphysics.substack.com/p/the-rise-of-steel-part-i",
          "author": null,
          "description": "Comments",
          "link": "https://constructionphysics.substack.com/p/the-rise-of-steel-part-i",
          "publishedOn": "2023-01-07T13:51:25.000Z",
          "wordCount": 11093,
          "title": "The Rise of Steel – Part I",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1709bff9-569c-4553-98a5-586a1ea1bc09_768x403.png"
        },
        {
          "id": "https://soranews24.com/2017/08/18/the-secret-undo-codes-for-japanese-elevator-floor-buttons/",
          "author": null,
          "description": "Comments",
          "link": "https://soranews24.com/2017/08/18/the-secret-undo-codes-for-japanese-elevator-floor-buttons/",
          "publishedOn": "2023-01-07T12:56:03.000Z",
          "wordCount": 2643,
          "title": "Undo codes for Japanese elevator floor buttons",
          "imageUrl": "https://soranews24.com/wp-content/uploads/sites/3/2017/08/ec-1.png?w=580&h=305&crop=1"
        },
        {
          "id": "https://bruces.medium.com/the-californian-ideology-by-richard-barbrook-and-andy-cameron-1995-c50014fcdbce",
          "author": null,
          "description": "Comments",
          "link": "https://bruces.medium.com/the-californian-ideology-by-richard-barbrook-and-andy-cameron-1995-c50014fcdbce",
          "publishedOn": "2023-01-07T12:54:25.000Z",
          "wordCount": 19916,
          "title": "The Californian Ideology (1995)",
          "imageUrl": null
        },
        {
          "id": "https://www.science.org/content/blog-post/not-such-better-living-through-chemistry",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/content/blog-post/not-such-better-living-through-chemistry",
          "publishedOn": "2023-01-07T12:48:01.000Z",
          "wordCount": 2853,
          "title": "Not-such-better-living through chemistry",
          "imageUrl": "https://www.science.org/pb-assets/images/blogs/pipeline/default-image-1644619966880.png"
        },
        {
          "id": "https://floooh.github.io/2019/09/27/modern-c-for-cpp-peeps.html",
          "author": null,
          "description": "Comments",
          "link": "https://floooh.github.io/2019/09/27/modern-c-for-cpp-peeps.html",
          "publishedOn": "2023-01-07T12:47:32.000Z",
          "wordCount": 3236,
          "title": "Modern C for C++ peeps (2019)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/VBAndCs/sVB-Small-Visual-Basic",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/VBAndCs/sVB-Small-Visual-Basic",
          "publishedOn": "2023-01-07T12:23:50.000Z",
          "wordCount": 10625,
          "title": "Small Visual Basic",
          "imageUrl": "https://opengraph.githubassets.com/0c12594f15872b3dff4b4fe9f12c1ac79c9d5bff985191e139d5cae247d99e9b/VBAndCs/sVB-Small-Visual-Basic"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34287407",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34287407",
          "publishedOn": "2023-01-07T12:22:11.000Z",
          "wordCount": 10538,
          "title": "Tell HN: Vim users, `:x` is like `:wq` but writes only when changes are made",
          "imageUrl": null
        },
        {
          "id": "https://press.princeton.edu/books/paperback/9780691180984/the-new-science-of-strong-materials",
          "author": null,
          "description": "Comments",
          "link": "https://press.princeton.edu/books/paperback/9780691180984/the-new-science-of-strong-materials",
          "publishedOn": "2023-01-07T11:20:01.000Z",
          "wordCount": 1952,
          "title": "Why you don’t fall through the floor (2018)",
          "imageUrl": "https://pup-assets.imgix.net/onix/images/9780691180984.jpg?fit=fill&fill=solid&fill-color=ffffff&w=1200&h=630"
        },
        {
          "id": "https://tastecooking.com/getting-lost-in-the-worlds-largest-stack-of-menus/",
          "author": null,
          "description": "Comments",
          "link": "https://tastecooking.com/getting-lost-in-the-worlds-largest-stack-of-menus/",
          "publishedOn": "2023-01-07T07:19:00.000Z",
          "wordCount": 4450,
          "title": "Getting Lost in the World’s Largest Stack of Menus",
          "imageUrl": "https://tastecooking.com/wp-content/uploads/2022/12/MENUS_SOCIAL.jpg"
        },
        {
          "id": "https://link.springer.com/article/10.1007/s11023-022-09602-0",
          "author": null,
          "description": "Comments",
          "link": "https://link.springer.com/article/10.1007/s11023-022-09602-0",
          "publishedOn": "2023-01-07T06:19:15.000Z",
          "wordCount": 13792,
          "title": "Playing games with AIs: The limits of GPT-3 and similar large language models",
          "imageUrl": "https://media.springernature.com/w200/springer-static/cover/journal/11023.jpg"
        },
        {
          "id": "https://historiacartarum.org/eel-rents-project/english-eel-rents-10th-17th-centuries/",
          "author": null,
          "description": "Comments",
          "link": "https://historiacartarum.org/eel-rents-project/english-eel-rents-10th-17th-centuries/",
          "publishedOn": "2023-01-07T02:16:05.000Z",
          "wordCount": 8644,
          "title": "English Eel-Rents: 10th-17th Centuries",
          "imageUrl": "https://historiacartarum.org/wp-content/uploads/2019/12/Eel_Rents_and_Payments-10-17C.jpg"
        },
        {
          "id": "https://www.jeffnobbs.com/posts/death-by-vegetable-oil-what-the-studies-say",
          "author": null,
          "description": "Comments",
          "link": "https://www.jeffnobbs.com/posts/death-by-vegetable-oil-what-the-studies-say",
          "publishedOn": "2023-01-07T00:23:46.000Z",
          "wordCount": 2644,
          "title": "Death by vegetable oil: What the studies say (2020)",
          "imageUrl": "https://uploads-ssl.webflow.com/5e20f576d0e9d12be5abc763/5eb4442b5171c0dbda92fe89_Increased%20Risk%20of%20Death%20by%20Diet_Lifestyle%20Factor%20(2).png"
        },
        {
          "id": "https://github.com/artsy/README",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/artsy/README",
          "publishedOn": "2023-01-06T23:52:13.000Z",
          "wordCount": 1284,
          "title": "Artsy Engineering Handbook",
          "imageUrl": "https://opengraph.githubassets.com/c1724440d9900598d10b20d7bb8f4bf7294291ec09d4fe18f927618b44ee5a31/artsy/README"
        },
        {
          "id": "https://www.ecu.edu.au/newsroom/articles/research/less-gym-time-same-results-why-lowering-weights-is-all-you-need-to-do",
          "author": null,
          "description": "Comments",
          "link": "https://www.ecu.edu.au/newsroom/articles/research/less-gym-time-same-results-why-lowering-weights-is-all-you-need-to-do",
          "publishedOn": "2023-01-06T23:07:12.000Z",
          "wordCount": 1770,
          "title": "Less gym time, same results: Why ‘lowering’ weights is all you need to do",
          "imageUrl": "https://www.ecu.edu.au/__data/assets/image/0012/1001325/varieties/articleOpenGraphImage.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34282623",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34282623",
          "publishedOn": "2023-01-06T23:02:08.000Z",
          "wordCount": 352,
          "title": "Tell HN: Oculus will delete purchases if you don’t switch to a meta account",
          "imageUrl": null
        },
        {
          "id": "https://sashachapin.substack.com/p/five-mildly-anti-buddhist-essays",
          "author": null,
          "description": "Comments",
          "link": "https://sashachapin.substack.com/p/five-mildly-anti-buddhist-essays",
          "publishedOn": "2023-01-06T22:14:34.000Z",
          "wordCount": 8954,
          "title": "Five mildly anti-Buddhist essays",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe958c11-9262-4514-90af-6d129f47866d_1024x1024.png"
        },
        {
          "id": "https://retractionwatch.com/2022/12/22/that-paper-with-the-t-error-bars-was-just-retracted/",
          "author": null,
          "description": "Comments",
          "link": "https://retractionwatch.com/2022/12/22/that-paper-with-the-t-error-bars-was-just-retracted/",
          "publishedOn": "2023-01-06T21:56:43.000Z",
          "wordCount": 2736,
          "title": "That paper with the ‘T’ error bars was just retracted",
          "imageUrl": "https://retractionwatch.com/wp-content/uploads/2022/12/3802603.fig_.009.png"
        },
        {
          "id": "https://neal.fun/perfect-circle/",
          "author": null,
          "description": "Comments",
          "link": "https://neal.fun/perfect-circle/",
          "publishedOn": "2023-01-06T20:38:55.000Z",
          "wordCount": 302,
          "title": "Perfect Circle",
          "imageUrl": "https://neal.fun/share-cards/perfect-circle.png"
        },
        {
          "id": "https://news.mit.edu/2023/roman-concrete-durability-lime-casts-0106",
          "author": null,
          "description": "Comments",
          "link": "https://news.mit.edu/2023/roman-concrete-durability-lime-casts-0106",
          "publishedOn": "2023-01-06T20:05:50.000Z",
          "wordCount": 2915,
          "title": "Why was Roman concrete so durable?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202301/MIT-RomanConcrete-01-press.jpg"
        },
        {
          "id": "https://people.apache.org/~jim/NewArchitect/webrevu/1997/02_07/developers/02_07_97_2.html",
          "author": null,
          "description": "Comments",
          "link": "https://people.apache.org/~jim/NewArchitect/webrevu/1997/02_07/developers/02_07_97_2.html",
          "publishedOn": "2023-01-06T19:34:05.000Z",
          "wordCount": 1581,
          "title": "Netscape's Constellation (1997)",
          "imageUrl": null
        },
        {
          "id": "https://www.mt-propeller.com/en/entw/about_firsts.htm#11",
          "author": null,
          "description": "Comments",
          "link": "https://www.mt-propeller.com/en/entw/about_firsts.htm#11",
          "publishedOn": "2023-01-06T19:29:09.000Z",
          "wordCount": 984,
          "title": "MT-Propeller 11 blade propeller delivers 15% increase in static thrust",
          "imageUrl": null
        },
        {
          "id": "https://www.newscientist.com/article/2353622-weve-just-discovered-a-new-part-of-the-brains-waste-disposal-system/",
          "author": null,
          "description": "Comments",
          "link": "https://www.newscientist.com/article/2353622-weve-just-discovered-a-new-part-of-the-brains-waste-disposal-system/",
          "publishedOn": "2023-01-06T19:28:06.000Z",
          "wordCount": 3591,
          "title": "Fourth membrane is discovered in the brain",
          "imageUrl": "https://images.newscientist.com/wp-content/uploads/2023/01/05145416/SEI_139315731.jpg"
        },
        {
          "id": "https://thetinylife.com/sunken-greenhouse/",
          "author": null,
          "description": "Comments",
          "link": "https://thetinylife.com/sunken-greenhouse/",
          "publishedOn": "2023-01-06T18:59:15.000Z",
          "wordCount": 17357,
          "title": "Sunken Greenhouse",
          "imageUrl": "https://thetinylife.com/wp-content/uploads/2022/09/Sunken-Greenhouse-Garden.jpg"
        },
        {
          "id": "https://github.com/Tablane/tablane",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Tablane/tablane",
          "publishedOn": "2023-01-06T18:47:53.000Z",
          "wordCount": 816,
          "title": "Show HN: I spent 2 years building Tablane as a 17-year-old",
          "imageUrl": "https://opengraph.githubassets.com/4faaafd5980910cfac1323b0bf9e6b96b0053c6b67a770ac8683ff964130564d/Tablane/tablane"
        },
        {
          "id": "https://golem.ph.utexas.edu/category/2023/01/a_curious_integral.html",
          "author": null,
          "description": "Comments",
          "link": "https://golem.ph.utexas.edu/category/2023/01/a_curious_integral.html",
          "publishedOn": "2023-01-06T17:32:35.000Z",
          "wordCount": 1403,
          "title": "A Curious Integral",
          "imageUrl": null
        },
        {
          "id": "https://themeasureofaplan.com/us-stock-market-returns-1870s-to-present/",
          "author": null,
          "description": "Comments",
          "link": "https://themeasureofaplan.com/us-stock-market-returns-1870s-to-present/",
          "publishedOn": "2023-01-06T16:25:57.000Z",
          "wordCount": 5346,
          "title": "U.S. stock market returns – a history from the 1870s to 2022",
          "imageUrl": "https://themeasureofaplan.com/wp-content/uploads/2023/01/Annual-Returns.png"
        },
        {
          "id": "https://unchartedterritories.tomaspueyo.com/p/transportation-tech-shaped-empires",
          "author": null,
          "description": "Comments",
          "link": "https://unchartedterritories.tomaspueyo.com/p/transportation-tech-shaped-empires",
          "publishedOn": "2023-01-06T15:25:38.000Z",
          "wordCount": 9524,
          "title": "How transportation technologies shaped empires",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F800a5d1e-09bf-4663-bd32-91bc1b341f27_1600x1022.png"
        },
        {
          "id": "https://www.science.org/content/article/human-gene-linked-bigger-brains-was-born-seemingly-useless-dna",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/content/article/human-gene-linked-bigger-brains-was-born-seemingly-useless-dna",
          "publishedOn": "2023-01-06T14:51:09.000Z",
          "wordCount": 2786,
          "title": "Human gene linked to bigger brains was born from seemingly useless DNA",
          "imageUrl": "https://www.science.org/do/10.1126/science.adg5583/abs/_2023_on_de_novo_brain_lede.jpg"
        },
        {
          "id": "http://www.bay12forums.com/smf/index.php?topic=181050.0",
          "author": null,
          "description": "Comments",
          "link": "http://www.bay12forums.com/smf/index.php?topic=181050.0",
          "publishedOn": "2023-01-06T14:47:13.000Z",
          "wordCount": 875,
          "title": "Dwarf Fortress has sold half a million copies",
          "imageUrl": null
        },
        {
          "id": "https://www.nature.com/articles/d41586-018-06185-8",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/articles/d41586-018-06185-8",
          "publishedOn": "2023-01-06T13:51:58.000Z",
          "wordCount": 5086,
          "title": "Thousands of scientists publish a paper every five days (2018)",
          "imageUrl": "https://media.nature.com/lw1024/magazine-assets/d41586-018-06185-8/d41586-018-06185-8_16105424.jpg"
        },
        {
          "id": "https://www.janestreet.com/tech-talks/building-an-exchange/",
          "author": null,
          "description": "Comments",
          "link": "https://www.janestreet.com/tech-talks/building-an-exchange/",
          "publishedOn": "2023-01-06T13:50:49.000Z",
          "wordCount": 6821,
          "title": "How to Build an Exchange (2017)",
          "imageUrl": "https://www.janestreet.com/static/img/share-image.png"
        },
        {
          "id": "https://blog.scienceandindustrymuseum.org.uk/canary-resuscitator/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.scienceandindustrymuseum.org.uk/canary-resuscitator/",
          "publishedOn": "2023-01-06T13:35:38.000Z",
          "wordCount": 1649,
          "title": "Canaries in coal mines (2018)",
          "imageUrl": "https://blog.scienceandindustrymuseum.org.uk/wp-content/uploads/2018/03/cd0194_009-051216-2002_19_254_1-Canary-reviver-2-1024x681.jpeg"
        },
        {
          "id": "https://scholarlykitchen.sspnet.org/2023/01/05/github-is-sued-and-we-may-learn-something-about-creative-commons-licensing/",
          "author": null,
          "description": "Comments",
          "link": "https://scholarlykitchen.sspnet.org/2023/01/05/github-is-sued-and-we-may-learn-something-about-creative-commons-licensing/",
          "publishedOn": "2023-01-06T13:26:47.000Z",
          "wordCount": 2635,
          "title": "GitHub is sued, and we may learn something about Creative Commons licensing",
          "imageUrl": "https://scholarlykitchen.sspnet.org/wp-content/uploads/2023/01/iStock-1198893619.jpg"
        },
        {
          "id": "https://write.hamster.dance/why-cassettes",
          "author": null,
          "description": "Comments",
          "link": "https://write.hamster.dance/why-cassettes",
          "publishedOn": "2023-01-06T13:14:45.000Z",
          "wordCount": 2670,
          "title": "Why Cassettes?",
          "imageUrl": "https://hamster.dance/assets/img/2023/01/teliffusion-tape.jpg"
        },
        {
          "id": "https://p-org.github.io/P/whatisP/",
          "author": null,
          "description": "Comments",
          "link": "https://p-org.github.io/P/whatisP/",
          "publishedOn": "2023-01-06T12:35:28.000Z",
          "wordCount": 933,
          "title": "P Language: a state machine-based programming language (2021)",
          "imageUrl": null
        },
        {
          "id": "https://ivanca.tumblr.com/post/705694114475360256/making-the-ultimate-guitar-web-player-easier-to",
          "author": null,
          "description": "Comments",
          "link": "https://ivanca.tumblr.com/post/705694114475360256/making-the-ultimate-guitar-web-player-easier-to",
          "publishedOn": "2023-01-06T10:56:14.000Z",
          "wordCount": 1596,
          "title": "Making the ultimate-guitar.com web player easier to practice with",
          "imageUrl": "https://64.media.tumblr.com/e7a4c2f31877c688fd0a42b16475af06/80cb54786d9e6e89-4c/s1280x1920/9372cd10d0f627bcab7c52639562466bce32e8d6.png"
        },
        {
          "id": "https://andreisurugiu.com/blog/bad-habit/",
          "author": null,
          "description": "Comments",
          "link": "https://andreisurugiu.com/blog/bad-habit/",
          "publishedOn": "2023-01-06T09:45:32.000Z",
          "wordCount": 727,
          "title": "My bad habit of hoarding information",
          "imageUrl": "/images/og-image-1673003787383.png"
        },
        {
          "id": "https://borretti.me/article/brief-defense-of-xml",
          "author": null,
          "description": "Comments",
          "link": "https://borretti.me/article/brief-defense-of-xml",
          "publishedOn": "2023-01-06T09:16:13.000Z",
          "wordCount": 493,
          "title": "A Brief Defense of XML",
          "imageUrl": "https://borretti.me/assets/card/brief-defense-xml.jpg"
        },
        {
          "id": "https://www.cambridge.org/core/journals/cambridge-archaeological-journal/article/an-upper-palaeolithic-protowriting-system-and-phenological-calendar/6F2AD8A705888F2226FE857840B4FE19",
          "author": null,
          "description": "Comments",
          "link": "https://www.cambridge.org/core/journals/cambridge-archaeological-journal/article/an-upper-palaeolithic-protowriting-system-and-phenological-calendar/6F2AD8A705888F2226FE857840B4FE19",
          "publishedOn": "2023-01-06T06:15:44.000Z",
          "wordCount": 31026,
          "title": "An Upper Palaeolithic Proto-Writing System and Phenological Calendar",
          "imageUrl": "https://static.cambridge.org/covers/CAJ_0_0_0/cambridge_archaeological journal.jpg?send-full-size-image=true"
        },
        {
          "id": "http://who-t.blogspot.com/2023/01/x-servers-no-longer-allow-byte-swapped.html",
          "author": null,
          "description": "Comments",
          "link": "http://who-t.blogspot.com/2023/01/x-servers-no-longer-allow-byte-swapped.html",
          "publishedOn": "2023-01-06T05:24:38.000Z",
          "wordCount": 4096,
          "title": "X servers no longer allow byte-swapped clients",
          "imageUrl": null
        },
        {
          "id": "https://utcc.utoronto.ca/~cks/space/blog/unix/XIconificationManyWays",
          "author": null,
          "description": "Comments",
          "link": "https://utcc.utoronto.ca/~cks/space/blog/unix/XIconificationManyWays",
          "publishedOn": "2023-01-06T05:09:27.000Z",
          "wordCount": 886,
          "title": "The different sorts of 'iconification' of windows in X",
          "imageUrl": null
        },
        {
          "id": "https://www.newyorker.com/culture/annals-of-inquiry/a-philosophy-professors-final-class",
          "author": null,
          "description": "Comments",
          "link": "https://www.newyorker.com/culture/annals-of-inquiry/a-philosophy-professors-final-class",
          "publishedOn": "2023-01-06T03:35:02.000Z",
          "wordCount": 41114,
          "title": "A Philosophy Professor’s Final Class",
          "imageUrl": "https://media.newyorker.com/photos/63ac7732a292e0d27b31fc33/16:9/w_1280,c_limit/Graupera-Bernstein.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34269503",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34269503",
          "publishedOn": "2023-01-06T01:01:26.000Z",
          "wordCount": 168,
          "title": "Generally Intelligent (YC S17) Is Hiring Simulation Engineers",
          "imageUrl": null
        },
        {
          "id": "https://articles.roland.com/soaring-sound-meet-the-piano-of-the-future/",
          "author": null,
          "description": "Comments",
          "link": "https://articles.roland.com/soaring-sound-meet-the-piano-of-the-future/",
          "publishedOn": "2023-01-05T23:47:58.000Z",
          "wordCount": 4360,
          "title": "Roland's 50th Anniversary Concept Piano makes use of drone speakers",
          "imageUrl": "https://articles.roland.com/wp-content/uploads/2022/12/Shot_01-1-scaled.jpg"
        },
        {
          "id": "https://www.propublica.org/article/google-human-tissue-jpc-military",
          "author": null,
          "description": "Comments",
          "link": "https://www.propublica.org/article/google-human-tissue-jpc-military",
          "publishedOn": "2023-01-05T23:15:09.000Z",
          "wordCount": 6878,
          "title": "Google’s quest to digitize troops’ tissue samples",
          "imageUrl": "https://img.assets-c3.propublica.org/images/articles/20221121-DOD-OG.jpg?crop=focalpoint&fit=crop&fp-x=0.5&fp-y=0.5&h=630&imgixProfile=propublicaAssets&q=90&w=1200&s=67f8733799fed94153f768dc4380be08"
        },
        {
          "id": "https://lemire.me/blog/2023/01/05/transcoding-unicode-with-avx-512-amd-zen-4-vs-intel-ice-lake/",
          "author": null,
          "description": "Comments",
          "link": "https://lemire.me/blog/2023/01/05/transcoding-unicode-with-avx-512-amd-zen-4-vs-intel-ice-lake/",
          "publishedOn": "2023-01-05T22:38:30.000Z",
          "wordCount": 3283,
          "title": "Transcoding Unicode with AVX-512: AMD Zen 4 vs. Intel Ice Lake",
          "imageUrl": "https://lemire.me/img/portrait2018facebook.jpg"
        },
        {
          "id": "https://kentcdodds.com/blog/i-migrated-from-a-postgres-cluster-to-distributed-sqlite-with-litefs",
          "author": null,
          "description": "Comments",
          "link": "https://kentcdodds.com/blog/i-migrated-from-a-postgres-cluster-to-distributed-sqlite-with-litefs",
          "publishedOn": "2023-01-05T21:59:45.000Z",
          "wordCount": 8997,
          "title": "I Migrated from a Postgres Cluster to Distributed SQLite with LiteFS",
          "imageUrl": "https://kentcdodds.com/img/social?type=2&title=I+Migrated+from+a+Postgres+Cluster+to+Distributed+SQLite+with+LiteFS&preTitle=Check+out+this+article&img=unsplash%2Fphoto-1642134222020-cc21d2e39dd6&url=kentcdodds.com%2Fblog%2Fi-migrated-from-a-postgres-cluster-to-distributed-sqlite-with-litefs"
        },
        {
          "id": "https://www.bloomberg.com/news/features/2023-01-05/frontier-supercomputer-world-s-fastest-needs-74-miles-of-cable",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/features/2023-01-05/frontier-supercomputer-world-s-fastest-needs-74-miles-of-cable",
          "publishedOn": "2023-01-05T21:46:49.000Z",
          "wordCount": 576,
          "title": "The Frontier computer, which broke the exascale barrier in 2022",
          "imageUrl": null
        },
        {
          "id": "https://cpucycles.cr.yp.to/",
          "author": null,
          "description": "Comments",
          "link": "https://cpucycles.cr.yp.to/",
          "publishedOn": "2023-01-05T21:25:49.000Z",
          "wordCount": 330,
          "title": "Libcpucycles is a public-domain microlibrary for counting CPU cycles",
          "imageUrl": null
        },
        {
          "id": "https://alleninstitute.org/what-we-do/cell-science/news-press/articles/interior-design-our-cells",
          "author": null,
          "description": "Comments",
          "link": "https://alleninstitute.org/what-we-do/cell-science/news-press/articles/interior-design-our-cells",
          "publishedOn": "2023-01-05T21:14:28.000Z",
          "wordCount": 1352,
          "title": "Database of 200k cell images yields new mathematical framework",
          "imageUrl": "https://alleninstitute.org/media/filer_public/2f/6b/2f6b83c2-e38b-4a4a-8a0b-180f8d4dff30/variance_integratedcelltilted.jpeg"
        },
        {
          "id": "https://posts.decontextualize.com/language-models-poetry/",
          "author": null,
          "description": "Comments",
          "link": "https://posts.decontextualize.com/language-models-poetry/",
          "publishedOn": "2023-01-05T21:06:35.000Z",
          "wordCount": 6593,
          "title": "Language models and poetics (2020)",
          "imageUrl": null
        },
        {
          "id": "https://www.quantamagazine.org/the-physics-principle-that-inspired-modern-ai-art-20230105/",
          "author": null,
          "description": "Comments",
          "link": "https://www.quantamagazine.org/the-physics-principle-that-inspired-modern-ai-art-20230105/",
          "publishedOn": "2023-01-05T20:40:40.000Z",
          "wordCount": 8361,
          "title": "The physics principle of diffusion inspired modern AI art",
          "imageUrl": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2023/01/DifussionModels-bySutterstock-SamuelVelasco-Social-1.webp"
        },
        {
          "id": "https://ksltv.com/516749/why-are-antennas-popping-up-all-over-the-foothills-salt-lake-city-seeks-to-solve-mystery/",
          "author": null,
          "description": "Comments",
          "link": "https://ksltv.com/516749/why-are-antennas-popping-up-all-over-the-foothills-salt-lake-city-seeks-to-solve-mystery/",
          "publishedOn": "2023-01-05T20:35:48.000Z",
          "wordCount": 3007,
          "title": "Why are antennas popping up over the Salt Lake City foothills?",
          "imageUrl": "https://ksltv.com/wp-content/uploads/2023/01/Why-are-antennas-popping-up-all-over-the-foothills-Salt-Lake-City-seeks-to-solve-mystery-010423.jpg"
        },
        {
          "id": "https://buttondown.email/hillelwayne/archive/microfeatures-id-like-to-see-in-more-languages/",
          "author": null,
          "description": "Comments",
          "link": "https://buttondown.email/hillelwayne/archive/microfeatures-id-like-to-see-in-more-languages/",
          "publishedOn": "2023-01-05T20:29:08.000Z",
          "wordCount": 1819,
          "title": "Microfeatures I'd like to see in more languages",
          "imageUrl": null
        },
        {
          "id": "https://billychasen.medium.com/twilios-toll-fraud-problem-28b3aef39243",
          "author": null,
          "description": "Comments",
          "link": "https://billychasen.medium.com/twilios-toll-fraud-problem-28b3aef39243",
          "publishedOn": "2023-01-05T19:44:48.000Z",
          "wordCount": 1944,
          "title": "Twilio’s toll fraud problem",
          "imageUrl": "https://miro.medium.com/max/1200/1*joZpCrT36nWFohQY-Ulo-g.png"
        },
        {
          "id": "https://astronomy.stackexchange.com/questions/51501/is-it-possible-for-a-lunar-eclipse-to-occur-before-sunset",
          "author": null,
          "description": "Comments",
          "link": "https://astronomy.stackexchange.com/questions/51501/is-it-possible-for-a-lunar-eclipse-to-occur-before-sunset",
          "publishedOn": "2023-01-05T19:34:35.000Z",
          "wordCount": 2624,
          "title": "Is it possible for a lunar eclipse to occur before sunset?",
          "imageUrl": "https://cdn.sstatic.net/Sites/astronomy/Img/apple-touch-icon@2.png?v=46633b7672b0"
        },
        {
          "id": "https://litesync.io/en/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://litesync.io/en/index.html",
          "publishedOn": "2023-01-05T19:34:16.000Z",
          "wordCount": 192,
          "title": "LiteSync – Easy synchronization of SQLite databases",
          "imageUrl": null
        },
        {
          "id": "https://clickhouse.com/blog/extracting-converting-querying-local-files-with-sql-clickhouse-local",
          "author": null,
          "description": "Comments",
          "link": "https://clickhouse.com/blog/extracting-converting-querying-local-files-with-sql-clickhouse-local",
          "publishedOn": "2023-01-05T19:30:48.000Z",
          "wordCount": 11765,
          "title": "Show HN: ClickHouse-local – a small tool for serverless data analytics",
          "imageUrl": "https://clickhouse.com/uploads/clickhouse_local_754f4824bd.png"
        },
        {
          "id": "https://www.goatcounter.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.goatcounter.com/",
          "publishedOn": "2023-01-05T19:25:34.000Z",
          "wordCount": 408,
          "title": "GoatCounter: Open-source hosted/self-hosted web analytics",
          "imageUrl": null
        },
        {
          "id": "https://gizmodo.com/dnd-wizards-of-the-coast-ogl-1-1-open-gaming-license-1849950634",
          "author": null,
          "description": "Comments",
          "link": "https://gizmodo.com/dnd-wizards-of-the-coast-ogl-1-1-open-gaming-license-1849950634",
          "publishedOn": "2023-01-05T19:03:39.000Z",
          "wordCount": 9630,
          "title": "Dungeons and Dragons’ new license tightens its grip on competition",
          "imageUrl": "https://i.kinja-img.com/gawker-media/image/upload/c_fill,f_auto,fl_progressive,g_center,h_675,pg_1,q_80,w_1200/3e87b909c042c4cf64237f075185010b.png"
        },
        {
          "id": "https://github.com/Owez/yark",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Owez/yark",
          "publishedOn": "2023-01-05T18:45:19.000Z",
          "wordCount": 981,
          "title": "Yark: Advanced and easy YouTube archiver now stable",
          "imageUrl": "https://opengraph.githubassets.com/b995b642cfd568026723630f58e8383c65c9fd9e9a671c8eb39cb3dfc705ed6d/Owez/yark"
        },
        {
          "id": "https://shiftrobotics.io/",
          "author": null,
          "description": "Comments",
          "link": "https://shiftrobotics.io/",
          "publishedOn": "2023-01-05T18:40:27.000Z",
          "wordCount": 4030,
          "title": "Moonwalkers: Shoes that make you walk faster (pre-order)",
          "imageUrl": "http://cdn.shopify.com/s/files/1/0652/6238/7422/files/SHIFT_LOGO-2.png?height=628&pad_color=fff&v=1658395435&width=1200"
        },
        {
          "id": "https://www.caltech.edu/about/news/caltech-to-launch-space-solar-power-technology-demo-into-orbit-in-january",
          "author": null,
          "description": "Comments",
          "link": "https://www.caltech.edu/about/news/caltech-to-launch-space-solar-power-technology-demo-into-orbit-in-january",
          "publishedOn": "2023-01-05T17:49:18.000Z",
          "wordCount": 2295,
          "title": "Caltech to launch space solar power technology demo into orbit",
          "imageUrl": "https://caltech-prod.s3.amazonaws.com/main/images/SSPD-1440x1060pixels48.width-600.jpg"
        },
        {
          "id": "https://www.vimonlineeditor.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.vimonlineeditor.com/",
          "publishedOn": "2023-01-05T17:02:04.000Z",
          "wordCount": 1258,
          "title": "Show HN: Vim online editor using WebAssembly, storing files using IndexedDB",
          "imageUrl": null
        },
        {
          "id": "https://www.npr.org/2023/01/05/1142817339/america-needs-carpenters-and-plumbers-try-telling-that-to-gen-z",
          "author": null,
          "description": "Comments",
          "link": "https://www.npr.org/2023/01/05/1142817339/america-needs-carpenters-and-plumbers-try-telling-that-to-gen-z",
          "publishedOn": "2023-01-05T16:33:22.000Z",
          "wordCount": 1838,
          "title": "The skilled trades haven't caught as a career choice with Gen Z",
          "imageUrl": "https://media.npr.org/assets/img/2022/12/16/ap21334817875512_wide-f7e32bff22d3625a8ddcae5f0d37480aed7d1d72-s1400-c100.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34262047",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34262047",
          "publishedOn": "2023-01-05T16:18:39.000Z",
          "wordCount": 1957,
          "title": "Show HN: Ello (YC W20) – AI-reading tutor for kids that works with real books",
          "imageUrl": null
        },
        {
          "id": "https://www.ycombinator.com/blog/the-yc-founder-directory",
          "author": null,
          "description": "Comments",
          "link": "https://www.ycombinator.com/blog/the-yc-founder-directory",
          "publishedOn": "2023-01-05T16:00:52.000Z",
          "wordCount": 4962,
          "title": "The YC Founder Directory",
          "imageUrl": "https://www.ycombinator.com/blog/content/images/2023/01/BlogTwitter-Image-Template-3.jpeg"
        },
        {
          "id": "https://www.nytimes.com/2023/01/05/business/economy/ftc-noncompete.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2023/01/05/business/economy/ftc-noncompete.html",
          "publishedOn": "2023-01-05T15:07:03.000Z",
          "wordCount": 5917,
          "title": "U.S. moves to bar noncompete agreements in labor contracts",
          "imageUrl": "https://static01.nyt.com/images/2023/01/05/multimedia/05noncompete-1-1-173c/05noncompete-1-1-173c-facebookJumbo.jpg"
        },
        {
          "id": "https://www.anandtech.com/show/18709/amd-unveils-ryzen-9-7950x3d-7900x3d-and-ryzen-7-7800x3d-up-to-128-mb-of-l3-cache-and-5-7-ghz-boost",
          "author": null,
          "description": "Comments",
          "link": "https://www.anandtech.com/show/18709/amd-unveils-ryzen-9-7950x3d-7900x3d-and-ryzen-7-7800x3d-up-to-128-mb-of-l3-cache-and-5-7-ghz-boost",
          "publishedOn": "2023-01-05T14:46:31.000Z",
          "wordCount": 4986,
          "title": "AMD Announces 7950X3D, 7900X3D Upto 128MB L3 Cache",
          "imageUrl": "https://images.anandtech.com/doci/18709/7000X3D-Render-1_crop_678x452.jpg"
        },
        {
          "id": "https://scottaaronson.blog/?p=6957",
          "author": null,
          "description": "Comments",
          "link": "https://scottaaronson.blog/?p=6957",
          "publishedOn": "2023-01-05T14:38:56.000Z",
          "wordCount": 2899,
          "title": "Cargo Cult Quantum Factoring",
          "imageUrl": "https://149663533.v2.pressablecdn.com/wp-content/uploads/2021/10/cropped-Jacket.gif"
        },
        {
          "id": "https://jott.live/markdown/1.5tflop_m1",
          "author": null,
          "description": "Comments",
          "link": "https://jott.live/markdown/1.5tflop_m1",
          "publishedOn": "2023-01-05T13:22:04.000Z",
          "wordCount": 1709,
          "title": "How to get 1.5 TFlops of FP32 performance on a single M1 CPU core",
          "imageUrl": null
        },
        {
          "id": "https://blog.the.al/2023/01/01/ds4-reverse-engineering.html",
          "author": null,
          "description": "Comments",
          "link": "https://blog.the.al/2023/01/01/ds4-reverse-engineering.html",
          "publishedOn": "2023-01-05T10:09:47.000Z",
          "wordCount": 1805,
          "title": "Reverse Engineering the DualShock 4",
          "imageUrl": null
        },
        {
          "id": "https://www.rachellaudan.com/wp-content/uploads/2007/12/plea-for-culinary-modernism.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://www.rachellaudan.com/wp-content/uploads/2007/12/plea-for-culinary-modernism.pdf",
          "publishedOn": "2023-01-05T01:20:38.000Z",
          "wordCount": 4616,
          "title": "A plea for culinary modernism (2001) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://www.ftc.gov/news-events/news/press-releases/2023/01/ftc-cracks-down-companies-impose-harmful-noncompete-restrictions-thousands-workers",
          "author": null,
          "description": "Comments",
          "link": "https://www.ftc.gov/news-events/news/press-releases/2023/01/ftc-cracks-down-companies-impose-harmful-noncompete-restrictions-thousands-workers",
          "publishedOn": "2023-01-05T00:38:43.000Z",
          "wordCount": 2717,
          "title": "FTC Cracks Down on Companies That Impose Harmful Noncompete Restrictions",
          "imageUrl": "https://www.ftc.gov/themes/custom/ftc_uswds/img/ftc_social_share_default_en.jpg"
        },
        {
          "id": "https://www.nola.com/news/crime_police/jpso-used-facial-recognition-to-arrest-a-man-it-was-wrong/article_0818361a-8886-11ed-8119-93b98ecccc8d.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nola.com/news/crime_police/jpso-used-facial-recognition-to-arrest-a-man-it-was-wrong/article_0818361a-8886-11ed-8119-93b98ecccc8d.html",
          "publishedOn": "2023-01-04T23:50:03.000Z",
          "wordCount": 15555,
          "title": "JPSO used facial recognition technology to arrest a man. The tech was wrong",
          "imageUrl": "https://bloximages.newyork1.vip.townnews.com/nola.com/content/tncms/assets/v3/editorial/a/12/a12f3b8a-8888-11ed-9665-6fbfb8207a52/5cdcce4445726.image.jpg?crop=1575%2C827%2C0%2C244&resize=1200%2C630&order=crop%2Cresize"
        },
        {
          "id": "https://locusmag.com/2023/01/suzy-mckee-charnas-1939-2023/",
          "author": null,
          "description": "Comments",
          "link": "https://locusmag.com/2023/01/suzy-mckee-charnas-1939-2023/",
          "publishedOn": "2023-01-04T23:48:02.000Z",
          "wordCount": 3480,
          "title": "RIP SF/f author Suzy McKee Charnas (1939-2023)",
          "imageUrl": "https://s0.wp.com/i/blank.jpg"
        },
        {
          "id": "https://www.wsj.com/articles/amazon-to-lay-off-over-17-000-workers-more-than-first-planned-11672874304",
          "author": null,
          "description": "Comments",
          "link": "https://www.wsj.com/articles/amazon-to-lay-off-over-17-000-workers-more-than-first-planned-11672874304",
          "publishedOn": "2023-01-04T23:25:20.000Z",
          "wordCount": 7970,
          "title": "Amazon to Lay Off over 17,000 Workers, More Than First Planned",
          "imageUrl": "https://images.wsj.net/im-697169/social"
        },
        {
          "id": "https://www.dragonflybsd.org/release64/",
          "author": null,
          "description": "Comments",
          "link": "https://www.dragonflybsd.org/release64/",
          "publishedOn": "2023-01-04T23:18:56.000Z",
          "wordCount": 1553,
          "title": "DragonFly BSD 6.4",
          "imageUrl": null
        },
        {
          "id": "https://codeberg.org/grisha/newsraft",
          "author": null,
          "description": "Comments",
          "link": "https://codeberg.org/grisha/newsraft",
          "publishedOn": "2023-01-04T22:44:20.000Z",
          "wordCount": 683,
          "title": "Newsraft: feed reader with ncurses user interface",
          "imageUrl": "https://codeberg.org/avatars/0fc43f0dc9c58e826f0509fc39700bee"
        },
        {
          "id": "https://www.tubesandmore.com/tech-articles/potentiometer-taper-modifications",
          "author": null,
          "description": "Comments",
          "link": "https://www.tubesandmore.com/tech-articles/potentiometer-taper-modifications",
          "publishedOn": "2023-01-04T21:23:50.000Z",
          "wordCount": null,
          "title": "Potentiometers – Modifying Taper",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/tenable-techblog/g-3po-a-protocol-droid-for-ghidra-4b46fa72f1ff",
          "author": null,
          "description": "Comments",
          "link": "https://medium.com/tenable-techblog/g-3po-a-protocol-droid-for-ghidra-4b46fa72f1ff",
          "publishedOn": "2023-01-04T20:20:03.000Z",
          "wordCount": 13905,
          "title": "G-3PO: A protocol droid for Ghidra, or GPT-3 for reverse-engineering",
          "imageUrl": "https://miro.medium.com/max/1200/1*M6paTMFbk1CWGijweff9SQ.png"
        },
        {
          "id": "https://neugierig.org/software/blog/2023/01/browser-crashes.html",
          "author": null,
          "description": "Comments",
          "link": "https://neugierig.org/software/blog/2023/01/browser-crashes.html",
          "publishedOn": "2023-01-04T19:50:31.000Z",
          "wordCount": 374,
          "title": "Two surprises in browser crashes",
          "imageUrl": null
        },
        {
          "id": "https://hiro.codes/read/emulating-an-emulator-inside-itself.-meet-blink",
          "author": null,
          "description": "Comments",
          "link": "https://hiro.codes/read/emulating-an-emulator-inside-itself.-meet-blink",
          "publishedOn": "2023-01-04T19:42:36.000Z",
          "wordCount": 432,
          "title": "Emulating an emulator inside itself. Meet Blink",
          "imageUrl": "https://hiro.codes/images/blink-gcc.png"
        },
        {
          "id": "https://eclecticlight.co/2023/01/04/how-do-you-know-when-macos-detects-and-remediates-malware/",
          "author": null,
          "description": "Comments",
          "link": "https://eclecticlight.co/2023/01/04/how-do-you-know-when-macos-detects-and-remediates-malware/",
          "publishedOn": "2023-01-04T17:59:17.000Z",
          "wordCount": 4015,
          "title": "How do you know when macOS detects and remediates malware?",
          "imageUrl": "https://eclecticlightdotcom.files.wordpress.com/2023/01/xprxcs02.png"
        },
        {
          "id": "https://www.autohotkey.com/v2/",
          "author": null,
          "description": "Comments",
          "link": "https://www.autohotkey.com/v2/",
          "publishedOn": "2023-01-04T17:06:29.000Z",
          "wordCount": 255,
          "title": "AutoHotKey V2 (Breaking Upgrade)",
          "imageUrl": null
        },
        {
          "id": "https://www.jernesto.com/articles/learning.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.jernesto.com/articles/learning.html",
          "publishedOn": "2023-01-04T17:02:24.000Z",
          "wordCount": 1484,
          "title": "On-demand learning comes at the cost of conceptual understanding",
          "imageUrl": null
        },
        {
          "id": "https://planetscale.com/blog/faster-mysql-with-http3",
          "author": null,
          "description": "Comments",
          "link": "https://planetscale.com/blog/faster-mysql-with-http3",
          "publishedOn": "2023-01-04T16:40:26.000Z",
          "wordCount": 1898,
          "title": "Faster MySQL with HTTP/3",
          "imageUrl": "https://planetscale.com/images/blog/content/faster-mysql-with-http3/social-faster-mysql-with-http3.png"
        },
        {
          "id": "https://fly.io/blog/wal-mode-in-litefs/",
          "author": null,
          "description": "Comments",
          "link": "https://fly.io/blog/wal-mode-in-litefs/",
          "publishedOn": "2023-01-04T16:36:03.000Z",
          "wordCount": 2215,
          "title": "WAL Mode in LiteFS",
          "imageUrl": "https://fly.io/blog/2023-01-04/wal-mode-thumbnail.jpg"
        },
        {
          "id": "https://gothamist.com/news/snow-go-for-nycs-electric-garbage-trucks-that-cant-handle-winter-weather",
          "author": null,
          "description": "Comments",
          "link": "https://gothamist.com/news/snow-go-for-nycs-electric-garbage-trucks-that-cant-handle-winter-weather",
          "publishedOn": "2023-01-04T16:25:05.000Z",
          "wordCount": 2412,
          "title": "NYC officials say they can't find EV garbage trucks powerful enough to plow snow",
          "imageUrl": null
        },
        {
          "id": "https://github.com/adhocteam/pushup",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/adhocteam/pushup",
          "publishedOn": "2023-01-04T15:49:34.000Z",
          "wordCount": 3647,
          "title": "Pushup: a new compiler for making web apps in Go",
          "imageUrl": "https://opengraph.githubassets.com/8027b7549cae83c580b2aeab74ff46bd7dc44cc3cfb7bcecd94b3e6fbfb6d20e/adhocteam/pushup"
        },
        {
          "id": "https://hackaday.com/2023/01/04/all-about-usb-c-resistors-and-emarkers/",
          "author": null,
          "description": "Comments",
          "link": "https://hackaday.com/2023/01/04/all-about-usb-c-resistors-and-emarkers/",
          "publishedOn": "2023-01-04T15:36:18.000Z",
          "wordCount": 4029,
          "title": "All About USB-C: Resistors and Emarkers",
          "imageUrl": "https://hackaday.com/wp-content/uploads/2020/06/USBC.jpg"
        },
        {
          "id": "https://mattmazur.com/2023/01/04/going-full-time-on-my-saas-after-13-years/",
          "author": null,
          "description": "Comments",
          "link": "https://mattmazur.com/2023/01/04/going-full-time-on-my-saas-after-13-years/",
          "publishedOn": "2023-01-04T15:23:41.000Z",
          "wordCount": 3092,
          "title": "Going full time on my SaaS after 13 years",
          "imageUrl": "https://matthewmazur.files.wordpress.com/2023/01/climb.png"
        },
        {
          "id": "https://www.nytimes.com/2023/01/02/magazine/juan-tamariz-magic.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2023/01/02/magazine/juan-tamariz-magic.html",
          "publishedOn": "2023-01-04T14:55:08.000Z",
          "wordCount": 11739,
          "title": "Juan Tamariz, the godfather of close-up card magic",
          "imageUrl": "https://static01.nyt.com/images/2023/01/08/magazine/08mag-tamariz-copy/08mag-tamariz-copy-facebookJumbo.jpg"
        },
        {
          "id": "https://www.nature.com/articles/d41586-022-04505-7",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/articles/d41586-022-04505-7",
          "publishedOn": "2023-01-04T14:52:33.000Z",
          "wordCount": 4907,
          "title": "‘Breakthrough’ obesity drugs that have stunned researchers",
          "imageUrl": "https://media.nature.com/lw1024/magazine-assets/d41586-022-04505-7/d41586-022-04505-7_23852316.jpg"
        },
        {
          "id": "https://www.nextplatform.com/2023/01/03/supermicro-throws-its-weight-behind-arm-servers/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nextplatform.com/2023/01/03/supermicro-throws-its-weight-behind-arm-servers/",
          "publishedOn": "2023-01-04T13:26:17.000Z",
          "wordCount": 2989,
          "title": "Supermicro throws its weight behind Arm servers",
          "imageUrl": "http://www.nextplatform.com/wp-content/uploads/2023/01/supermicro-mt-hamilton-server.jpg"
        },
        {
          "id": "https://www.channable.com/tech/parallel-streaming-in-haskell-part-1-fast-efficient-fun",
          "author": null,
          "description": "Comments",
          "link": "https://www.channable.com/tech/parallel-streaming-in-haskell-part-1-fast-efficient-fun",
          "publishedOn": "2023-01-04T13:03:58.000Z",
          "wordCount": 18287,
          "title": "Parallel streaming in Haskell: Part 1 – Fast, efficient, and fun",
          "imageUrl": null
        },
        {
          "id": "https://hypertextbook.com/chaos/",
          "author": null,
          "description": "Comments",
          "link": "https://hypertextbook.com/chaos/",
          "publishedOn": "2023-01-04T12:57:11.000Z",
          "wordCount": 899,
          "title": "Chaos Hypertextbook",
          "imageUrl": "https://hypertextbook.com/chaos/og-image.jpg"
        },
        {
          "id": "https://www.countrylife.co.uk/architecture/lincoln-cathedral-the-950-year-story-of-one-of-europes-very-greatest-cathedrals-251041",
          "author": null,
          "description": "Comments",
          "link": "https://www.countrylife.co.uk/architecture/lincoln-cathedral-the-950-year-story-of-one-of-europes-very-greatest-cathedrals-251041",
          "publishedOn": "2023-01-04T06:00:18.000Z",
          "wordCount": 6757,
          "title": "Lincoln Cathedral",
          "imageUrl": "https://keyassets.timeincuk.net/inspirewp/live/wp-content/uploads/sites/8/2023/01/GettyImages-1330769318-533x400.jpg"
        },
        {
          "id": "https://whyisthisinteresting.substack.com/p/the-worlds-most-dangerous-toy-edition",
          "author": null,
          "description": "Comments",
          "link": "https://whyisthisinteresting.substack.com/p/the-worlds-most-dangerous-toy-edition",
          "publishedOn": "2023-01-04T05:59:01.000Z",
          "wordCount": 3494,
          "title": "Fun, danger, and 70s airplane toys",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1f3bf493-03db-4681-bb95-9377060f40ea_1600x765.png"
        },
        {
          "id": "https://busybox.net/",
          "author": null,
          "description": "Comments",
          "link": "https://busybox.net/",
          "publishedOn": "2023-01-04T01:02:30.000Z",
          "wordCount": null,
          "title": "BusyBox 1.36.0",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34240298",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34240298",
          "publishedOn": "2023-01-04T00:42:51.000Z",
          "wordCount": 2002,
          "title": "Tell HN: I just received my Equifax breach settlement check",
          "imageUrl": null
        },
        {
          "id": "https://kguttag.com/2023/01/03/meta-quest-pro-part-1-unbelievably-bad-ar-passthrough/",
          "author": null,
          "description": "Comments",
          "link": "https://kguttag.com/2023/01/03/meta-quest-pro-part-1-unbelievably-bad-ar-passthrough/",
          "publishedOn": "2023-01-03T23:32:27.000Z",
          "wordCount": 7111,
          "title": "Meta Quest Pro – Bad AR Passthrough",
          "imageUrl": "https://kguttag.com/wp-content/uploads/2023/01/Feature-Image-MQP-Part-1-001-copy.jpg"
        },
        {
          "id": "https://indiestack.com/2023/01/inline-applescript-documentation/",
          "author": null,
          "description": "Comments",
          "link": "https://indiestack.com/2023/01/inline-applescript-documentation/",
          "publishedOn": "2023-01-03T23:05:02.000Z",
          "wordCount": 905,
          "title": "Inline AppleScript Documentation",
          "imageUrl": "https://indiestack.com/wp-content/uploads/2018/10/wjyc3FfR_400x400.png"
        },
        {
          "id": "https://arstechnica.com/gadgets/2023/01/google-announces-official-android-support-for-risc-v/",
          "author": null,
          "description": "Comments",
          "link": "https://arstechnica.com/gadgets/2023/01/google-announces-official-android-support-for-risc-v/",
          "publishedOn": "2023-01-03T22:47:11.000Z",
          "wordCount": 1886,
          "title": "Google wants RISC-V to be a “tier-1” Android architecture",
          "imageUrl": "https://cdn.arstechnica.net/wp-content/uploads/2021/04/android-google-760x380.jpeg"
        },
        {
          "id": "https://torrentfreak.com/major-private-torrent-sites-have-a-security-disaster-to-fix-right-now-230103/",
          "author": null,
          "description": "Comments",
          "link": "https://torrentfreak.com/major-private-torrent-sites-have-a-security-disaster-to-fix-right-now-230103/",
          "publishedOn": "2023-01-03T22:18:37.000Z",
          "wordCount": 3538,
          "title": "Major torrent sites are currently exposing intimate details of their operations",
          "imageUrl": null
        },
        {
          "id": "https://www.smithsonianmag.com/history/how-unorthodox-scholar-uses-technology-expose-biblical-forgeries-180981290/",
          "author": null,
          "description": "Comments",
          "link": "https://www.smithsonianmag.com/history/how-unorthodox-scholar-uses-technology-expose-biblical-forgeries-180981290/",
          "publishedOn": "2023-01-03T22:12:22.000Z",
          "wordCount": 5819,
          "title": "An Unorthodox Scholar Uses Technology to Expose Biblical Forgeries",
          "imageUrl": "https://th-thumbnailer.cdn-si-edu.com/eIQdvXtB_D4jrLShICEoSfwkfVE=/fit-in/1600x0/filters:focal(1548x2064:1549x2065)/https%3A%2F%2Ftf-cmsv2-smithsonianmag-media.s3.amazonaws.com%2Ffiler_public%2F4a%2F47%2F4a479f84-bbc6-44de-b055-215d1ad6d710%2Fjanfeb2023_n05_deadseascrolls.jpg"
        },
        {
          "id": "https://terrateam.io/blog/flying-away-from-aws",
          "author": null,
          "description": "Comments",
          "link": "https://terrateam.io/blog/flying-away-from-aws",
          "publishedOn": "2023-01-03T21:13:45.000Z",
          "wordCount": 2306,
          "title": "Migrating from AWS to Fly.io",
          "imageUrl": "https://terrateam.io/og-image.jpg"
        },
        {
          "id": "https://pdfs.semanticscholar.org/3cb2/0df9e075056030103d73f173fa29f8f92f07.pdf?_ga=2.37017120.1076752451.1672779819-279137700.1672779819",
          "author": null,
          "description": "Comments",
          "link": "https://pdfs.semanticscholar.org/3cb2/0df9e075056030103d73f173fa29f8f92f07.pdf?_ga=2.37017120.1076752451.1672779819-279137700.1672779819",
          "publishedOn": "2023-01-03T21:04:10.000Z",
          "wordCount": 5207,
          "title": "Can self-replicating species flourish in the interior of a star? (2020) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515",
          "author": null,
          "description": "Comments",
          "link": "https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515",
          "publishedOn": "2023-01-03T20:34:37.000Z",
          "wordCount": 6880,
          "title": "To build truly intelligent machines, teach them cause and effect (2018)",
          "imageUrl": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2018/05/Pearl_520x292.jpg"
        },
        {
          "id": "https://www.macrumors.com/2023/01/03/qi2-wireless-charging-standard-gains-magsafe/",
          "author": null,
          "description": "Comments",
          "link": "https://www.macrumors.com/2023/01/03/qi2-wireless-charging-standard-gains-magsafe/",
          "publishedOn": "2023-01-03T20:04:27.000Z",
          "wordCount": 2501,
          "title": "Next-generation Qi2 wireless charging standard embraces Apple's MagSafe",
          "imageUrl": "https://images.macrumors.com/t/mpnQXzZGuaLA21axndmOPbm-Kgw=/2500x/article-new/2022/10/magsafe-charger-blue.jpg"
        },
        {
          "id": "https://twitter.com/lanewinfield/status/1610294277434933249",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/lanewinfield/status/1610294277434933249",
          "publishedOn": "2023-01-03T20:03:18.000Z",
          "wordCount": 470,
          "title": "Show HN: A device that only lets you type lol if you've truly laughed out loud",
          "imageUrl": null
        },
        {
          "id": "https://www.youtube.com/watch?v=Xm9jr0cSqZo",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=Xm9jr0cSqZo",
          "publishedOn": "2023-01-03T19:57:04.000Z",
          "wordCount": null,
          "title": "AT&T's predictions of the future (1993)",
          "imageUrl": null
        },
        {
          "id": "https://pypackaging-native.github.io/",
          "author": null,
          "description": "Comments",
          "link": "https://pypackaging-native.github.io/",
          "publishedOn": "2023-01-03T19:45:06.000Z",
          "wordCount": 701,
          "title": "Underappreciated challenges with Python packaging",
          "imageUrl": null
        },
        {
          "id": "https://www.quantamagazine.org/long-out-of-math-an-ai-programmer-cracks-a-pure-math-problem-20230103/",
          "author": null,
          "description": "Comments",
          "link": "https://www.quantamagazine.org/long-out-of-math-an-ai-programmer-cracks-a-pure-math-problem-20230103/",
          "publishedOn": "2023-01-03T19:43:21.000Z",
          "wordCount": 7397,
          "title": "Google researcher, long out of math, cracks devilish problem about sets",
          "imageUrl": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/12/ClosedUnionConjecture-byKristinaArmitage-Social.webp"
        },
        {
          "id": "https://en.wikipedia.org/wiki/Tafl_games",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/Tafl_games",
          "publishedOn": "2023-01-03T19:31:56.000Z",
          "wordCount": 7965,
          "title": "Hnefatafl",
          "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/7/7c/ZHNEFA.jpg"
        },
        {
          "id": "https://www.schneier.com/blog/archives/2023/01/breaking-rsa-with-a-quantum-computer.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.schneier.com/blog/archives/2023/01/breaking-rsa-with-a-quantum-computer.html",
          "publishedOn": "2023-01-03T18:15:49.000Z",
          "wordCount": 2138,
          "title": "Breaking RSA with a quantum computer?",
          "imageUrl": null
        },
        {
          "id": "https://www.pv-magazine.com/2023/01/02/residential-thermo-acoustic-heat-pump-produces-water-up-to-80-c/",
          "author": null,
          "description": "Comments",
          "link": "https://www.pv-magazine.com/2023/01/02/residential-thermo-acoustic-heat-pump-produces-water-up-to-80-c/",
          "publishedOn": "2023-01-03T16:36:57.000Z",
          "wordCount": 4475,
          "title": "French startup unveils new residential thermo-acoustic heat pump",
          "imageUrl": "https://www.pv-magazine.com/wp-content/uploads/2022/12/EQORE-EQUIUM-1200x1200.png"
        },
        {
          "id": "https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9",
          "author": null,
          "description": "Comments",
          "link": "https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9",
          "publishedOn": "2023-01-03T15:54:22.000Z",
          "wordCount": 4809,
          "title": "Some Remarks on Large Language Models",
          "imageUrl": "https://github.githubassets.com/images/modules/gists/gist-og-image.png"
        },
        {
          "id": "https://stevepulec.com/posts/small/",
          "author": null,
          "description": "Comments",
          "link": "https://stevepulec.com/posts/small/",
          "publishedOn": "2023-01-03T14:54:49.000Z",
          "wordCount": 815,
          "title": "Small Teams",
          "imageUrl": null
        },
        {
          "id": "https://palant.info/2023/01/02/south-koreas-online-security-dead-end/",
          "author": null,
          "description": "Comments",
          "link": "https://palant.info/2023/01/02/south-koreas-online-security-dead-end/",
          "publishedOn": "2023-01-03T14:01:45.000Z",
          "wordCount": 1854,
          "title": "South Korea’s online security dead end",
          "imageUrl": "https://palant.info/2023/01/02/south-koreas-online-security-dead-end/message.png"
        },
        {
          "id": "https://stackoverflow.com/questions/4703844/unexplainable-core-dump",
          "author": null,
          "description": "Comments",
          "link": "https://stackoverflow.com/questions/4703844/unexplainable-core-dump",
          "publishedOn": "2023-01-03T13:02:05.000Z",
          "wordCount": 2933,
          "title": "“Unexplainable” core dump (2011)",
          "imageUrl": "https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded"
        },
        {
          "id": "https://news.unl.edu/newsrooms/today/article/eating-viruses-can-power-growth-reproduction-of-microorganism/",
          "author": null,
          "description": "Comments",
          "link": "https://news.unl.edu/newsrooms/today/article/eating-viruses-can-power-growth-reproduction-of-microorganism/",
          "publishedOn": "2023-01-03T12:57:07.000Z",
          "wordCount": 1945,
          "title": "Scientists have discovered the first virovore – an organism that eats viruses",
          "imageUrl": "https://news.unl.edu/sites/default/files/media/Hero_277.jpg"
        },
        {
          "id": "http://blogs.newardassociates.com/blog/2023/you-want-modules-not-microservices.html",
          "author": null,
          "description": "Comments",
          "link": "http://blogs.newardassociates.com/blog/2023/you-want-modules-not-microservices.html",
          "publishedOn": "2023-01-03T12:35:03.000Z",
          "wordCount": 2460,
          "title": "Modules, not microservices",
          "imageUrl": null
        },
        {
          "id": "https://jmvdveer.home.xs4all.nl/en.algol-68-genie.html",
          "author": null,
          "description": "Comments",
          "link": "https://jmvdveer.home.xs4all.nl/en.algol-68-genie.html",
          "publishedOn": "2023-01-03T11:25:07.000Z",
          "wordCount": 585,
          "title": "The Algol 68 Genie project",
          "imageUrl": "images.algol-68-genie.png"
        },
        {
          "id": "https://samcurry.net/web-hackers-vs-the-auto-industry/",
          "author": null,
          "description": "Comments",
          "link": "https://samcurry.net/web-hackers-vs-the-auto-industry/",
          "publishedOn": "2023-01-03T11:07:11.000Z",
          "wordCount": 6372,
          "title": "Web hackers vs. the auto industry",
          "imageUrl": "https://i.imgur.com/o2WUB2y.png"
        },
        {
          "id": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1498&context=open_access_etds",
          "author": null,
          "description": "Comments",
          "link": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1498&context=open_access_etds",
          "publishedOn": "2023-01-03T09:10:22.000Z",
          "wordCount": 56511,
          "title": "A functional approach to memory-safe operating systems",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34225669",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34225669",
          "publishedOn": "2023-01-03T00:15:48.000Z",
          "wordCount": 846,
          "title": "Ask HN: A Better Docker Compose?",
          "imageUrl": null
        },
        {
          "id": "https://grantisom.com/2023/01/02/mustread-books-for.html",
          "author": null,
          "description": "Comments",
          "link": "https://grantisom.com/2023/01/02/mustread-books-for.html",
          "publishedOn": "2023-01-02T23:48:37.000Z",
          "wordCount": 765,
          "title": "Books for Software Engineers in 2023",
          "imageUrl": "https://grantisom.com/uploads/2023/ec18f32904.jpg"
        },
        {
          "id": "https://brickexperimentchannel.wordpress.com/2022/11/19/my-youtube-earnings/",
          "author": null,
          "description": "Comments",
          "link": "https://brickexperimentchannel.wordpress.com/2022/11/19/my-youtube-earnings/",
          "publishedOn": "2023-01-02T23:25:30.000Z",
          "wordCount": 3061,
          "title": "My YouTube earnings",
          "imageUrl": "https://brickexperimentchannel.files.wordpress.com/2022/11/revenue_analysis_ctr_vs_views.png"
        },
        {
          "id": "https://ianbicking.org/blog/2023/01/infinite-ai-array.html",
          "author": null,
          "description": "Comments",
          "link": "https://ianbicking.org/blog/2023/01/infinite-ai-array.html",
          "publishedOn": "2023-01-02T22:36:46.000Z",
          "wordCount": 1067,
          "title": "Infinite AI Array",
          "imageUrl": null
        },
        {
          "id": "https://gist.github.com/Spuffynism/446c7c2d498477491d8137e8f234d4a9",
          "author": null,
          "description": "Comments",
          "link": "https://gist.github.com/Spuffynism/446c7c2d498477491d8137e8f234d4a9",
          "publishedOn": "2023-01-02T22:16:33.000Z",
          "wordCount": 2028,
          "title": "Solving a Dungeons and Dragons riddle using Prolog",
          "imageUrl": "https://github.githubassets.com/images/modules/gists/gist-og-image.png"
        },
        {
          "id": "https://ironicsans.substack.com/p/the-strangest-computer-manual-ever",
          "author": null,
          "description": "Comments",
          "link": "https://ironicsans.substack.com/p/the-strangest-computer-manual-ever",
          "publishedOn": "2023-01-02T21:52:13.000Z",
          "wordCount": 4491,
          "title": "The strangest computer manual ever written",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F391e6f32-9dd9-4126-a0f5-03d7c7dd6970_1476x982.png"
        },
        {
          "id": "https://www.impact-solutions.co.uk/tallow-in-plastics/",
          "author": null,
          "description": "Comments",
          "link": "https://www.impact-solutions.co.uk/tallow-in-plastics/",
          "publishedOn": "2023-01-02T21:36:08.000Z",
          "wordCount": 22900,
          "title": "Tallow in plastics – why? (2016)",
          "imageUrl": "https://www.impact-solutions.co.uk/wp-content/uploads/2016/12/tallow-in-plastics-1.jpg"
        },
        {
          "id": "https://overexact.com/rust-for-professionals/",
          "author": null,
          "description": "Comments",
          "link": "https://overexact.com/rust-for-professionals/",
          "publishedOn": "2023-01-02T20:59:31.000Z",
          "wordCount": 4091,
          "title": "Rust for Professionals",
          "imageUrl": null
        },
        {
          "id": "https://www.hypchain.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.hypchain.com/",
          "publishedOn": "2023-01-02T20:55:51.000Z",
          "wordCount": 588,
          "title": "HypChain, the first completely hypothetical blockchain",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34223288",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34223288",
          "publishedOn": "2023-01-02T20:35:18.000Z",
          "wordCount": 8817,
          "title": "Ask HN: Pros and cons of thinking in public vs. in private?",
          "imageUrl": null
        },
        {
          "id": "https://www.kryogenix.org/days/2023/01/02/what-to-do-about-hotlinking/",
          "author": null,
          "description": "Comments",
          "link": "https://www.kryogenix.org/days/2023/01/02/what-to-do-about-hotlinking/",
          "publishedOn": "2023-01-02T18:49:14.000Z",
          "wordCount": 1794,
          "title": "Wondering what to do (if anything) about hotlinking",
          "imageUrl": "https://www.kryogenix.org/days/2023/01/02/what-to-do-about-hotlinking/index.html.og_image.png"
        },
        {
          "id": "https://www.exclassics.com/espoke/espkpdf.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://www.exclassics.com/espoke/espkpdf.pdf",
          "publishedOn": "2023-01-02T18:44:59.000Z",
          "wordCount": 5666,
          "title": "English as She Is Spoke (1884) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://www.tbray.org/ongoing/When/202x/2022/12/30/Mastodon-Privacy-and-Search",
          "author": null,
          "description": "Comments",
          "link": "https://www.tbray.org/ongoing/When/202x/2022/12/30/Mastodon-Privacy-and-Search",
          "publishedOn": "2023-01-02T18:43:19.000Z",
          "wordCount": 2662,
          "title": "Private and Public Mastodon",
          "imageUrl": null
        },
        {
          "id": "https://arxiv.org/abs/2203.10702",
          "author": null,
          "description": "Comments",
          "link": "https://arxiv.org/abs/2203.10702",
          "publishedOn": "2023-01-02T18:37:12.000Z",
          "wordCount": 642,
          "title": "Higher-order organization of multivariate time series",
          "imageUrl": null
        },
        {
          "id": "https://gbatemp.net/download/gba-and-ds-rom-hacking-guide.33419/",
          "author": null,
          "description": "Comments",
          "link": "https://gbatemp.net/download/gba-and-ds-rom-hacking-guide.33419/",
          "publishedOn": "2023-01-02T18:24:14.000Z",
          "wordCount": 3264,
          "title": "Nintendo GBA and DS ROM hacking guide (2016)",
          "imageUrl": null
        },
        {
          "id": "https://www.smithsonianmag.com/history/musicians-wage-war-against-evil-robots-92702721/",
          "author": null,
          "description": "Comments",
          "link": "https://www.smithsonianmag.com/history/musicians-wage-war-against-evil-robots-92702721/",
          "publishedOn": "2023-01-02T18:16:59.000Z",
          "wordCount": 1719,
          "title": "Musicians wage war against evil robots (2012)",
          "imageUrl": "https://th-thumbnailer.cdn-si-edu.com/LdwRMBTavVzyy2Excwbw5n9r2Y8=/fit-in/1600x0/https%3A%2F%2Ftf-cmsv2-smithsonianmag-media.s3.amazonaws.com%2Ffiler%2F201202100131061930-Nov-3-Syracuse-Herald-Syracuse-NY-470x251.jpg"
        },
        {
          "id": "https://www.righto.com/2023/01/inside-8086-processors-instruction.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.righto.com/2023/01/inside-8086-processors-instruction.html",
          "publishedOn": "2023-01-02T18:11:53.000Z",
          "wordCount": 8677,
          "title": "Inside the 8086 processor's instruction prefetch circuitry",
          "imageUrl": "https://lh3.googleusercontent.com/blogger_img_proxy/ANbyha1EK8XVX21S4dgm9jRSjdccXpkWQjI-VCVIRS8ndbBRrxyghuXUvFGgvRTa_ICKBAhhEHoJzbHEQiUlXMCItZ5b6vb--ZYPivPhex0RowwgDw8KVx_ZAhTEFT94rjjEw6duIwwvIsI=w1200-h630-p-k-no-nu"
        },
        {
          "id": "https://softwarescalability.com/editorial/real-time-object-detection-with-webrtc-and-yolo",
          "author": null,
          "description": "Comments",
          "link": "https://softwarescalability.com/editorial/real-time-object-detection-with-webrtc-and-yolo",
          "publishedOn": "2023-01-02T18:05:49.000Z",
          "wordCount": 11114,
          "title": "Multi-camera real-time object detection with WebRTC and YOLO",
          "imageUrl": "https://softwarescalability.com/assets/blog/real-time-object-detection-with-webrtc-and-yolo/cover.jpg"
        },
        {
          "id": "https://lethain.com/measuring-engineering-organizations/",
          "author": null,
          "description": "Comments",
          "link": "https://lethain.com/measuring-engineering-organizations/",
          "publishedOn": "2023-01-02T17:59:53.000Z",
          "wordCount": 3067,
          "title": "Measuring an engineering organization",
          "imageUrl": "https://lethain.com/static/blog/2023/EngMeasurements.png"
        },
        {
          "id": "https://secretartofscience.com/performance",
          "author": null,
          "description": "Comments",
          "link": "https://secretartofscience.com/performance",
          "publishedOn": "2023-01-02T17:46:11.000Z",
          "wordCount": 3475,
          "title": "What we talk about when we talk about performance (2021)",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34220710",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34220710",
          "publishedOn": "2023-01-02T17:28:51.000Z",
          "wordCount": 13424,
          "title": "Ask HN: What are you working on this year?",
          "imageUrl": null
        },
        {
          "id": "https://ottertune.com/blog/2022-databases-retrospective/",
          "author": null,
          "description": "Comments",
          "link": "https://ottertune.com/blog/2022-databases-retrospective/",
          "publishedOn": "2023-01-02T17:17:37.000Z",
          "wordCount": 3352,
          "title": "Databases in 2022: A Year in Review",
          "imageUrl": "https://ottertune.com/wp-content/uploads/2023/01/Databases-in-Review-2022-social-image.jpg"
        },
        {
          "id": "https://100r.co/site/weathering_software_winter.html",
          "author": null,
          "description": "Comments",
          "link": "https://100r.co/site/weathering_software_winter.html",
          "publishedOn": "2023-01-02T16:20:17.000Z",
          "wordCount": 6140,
          "title": "Weathering Software Winter",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34219335",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34219335",
          "publishedOn": "2023-01-02T16:01:16.000Z",
          "wordCount": 31883,
          "title": "Ask HN: Who is hiring? (January 2023)",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34219332",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34219332",
          "publishedOn": "2023-01-02T16:01:14.000Z",
          "wordCount": 24636,
          "title": "Ask HN: Who wants to be hired? (January 2023)",
          "imageUrl": null
        },
        {
          "id": "https://haystack.it/",
          "author": null,
          "description": "Comments",
          "link": "https://haystack.it/",
          "publishedOn": "2023-01-02T15:14:13.000Z",
          "wordCount": 143,
          "title": "Show HN: I built Haystack – your own google for scattered workplace knowledge",
          "imageUrl": "https://lh3.googleusercontent.com/mxua9jWPye0iJb--i0Ataut1XcGH3Tv1QCSqYO7nbbsvKEBS7-g6yqaGneJHixHAh_SI0l-1EPTFzeICV3tjagWHaZJEV08_9GHuxnvnHhGHpW79MYpG27uRKEPrVtrSgye3vYZ2DuLABMlqMRKGmugL0JtYZssJ_jch2a9G-7g4gwdKhGo-mKPJhHrAMYjjjL2YKTe1RK0c2ufgiS2o4a2Ei9JkNVAPq_MiXn_OhdMvaSNNbtTSr0JLCo1Ave1H1jayO3dILI_CH7nE9yXgCdGfvGBYj0OInekDKPAa9U_gxshtpusTCowgiasmn497IuzzgwHOwreeMSmGXfDxb4bX0-zwo6uzvNK7GQ6Q6PF8AaBAZWJVlJ35c1SLyNZs9lHTwOWjCCwRW1437c-sbQkoUKC4FTkb-451rVNlr9LFOl3-Wpat2VHfOeeMjW4QjTxEC7GOgQATwI5br6RObRe5jmgpghnm32DY5Rmjk2b0yZ6S7H-pD0x98POxwAVLyYBdIrQ0nMzzw0bmCphjlOfJq1MN1MpCK5D4CwHvdTxbznqFDZhCVUEtWMV2ovfiZqsKqrsSshvV2deFquWvyopmdbNNbkrLgitPz-5abL2SHUeVIsm84Qn9d37iJExDZ9-zP7ytvM3MizlDLnI34qv8rDCRQ3Xi0JWu9xeRsS4AGfYgqJbPJaCgwTcMji48NWhd7iecqc_aU1cKHeCEk1NCNuu4qLE059vQ91qdRWuU0QHzIUgXl9BpoLfgi12MhVFOgclgi2HliRJsA7vEwa0e8f5-Cx3qg1zs3tsalZxRzDos8zTQ2pqGVWjJyW5UPlPyC6qbQ2yG7-qWmTMk49iv_lN1ZnfDKdQzhH0y-KYo3vMBNKagCetvftuvWSkio9pbakBBTprhhtE_XnQXksHupyIadWPwbXkjYg=w1493-h784-no?authuser=0"
        },
        {
          "id": "https://www.youtube.com/watch?v=QrkiJZKJfpY",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=QrkiJZKJfpY",
          "publishedOn": "2023-01-02T15:08:28.000Z",
          "wordCount": null,
          "title": "Mechanical circuits: electronics without electricity [video]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/skuep/AIOC",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/skuep/AIOC",
          "publishedOn": "2023-01-02T15:06:45.000Z",
          "wordCount": 1208,
          "title": "AIOC: Ham Radio All-in-One-Cable",
          "imageUrl": "https://opengraph.githubassets.com/268e6dc33b151e264ca53f0dd9f65579ed8ca4ee2ad382ea7ad2136cdf5476b9/skuep/AIOC"
        },
        {
          "id": "https://spectrum.ieee.org/interconnect-back-side-power",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/interconnect-back-side-power",
          "publishedOn": "2023-01-02T14:19:32.000Z",
          "wordCount": 10561,
          "title": "At the edges of Moore’s Law, connecting components is increasingly the game",
          "imageUrl": "https://spectrum.ieee.org/media-library/six-short-black-pillars-with-a-tall-pillar-at-center-bridge-two-light-grey-areas.jpg?id=32417203&width=1200&height=600&coordinates=0%2C72%2C0%2C72"
        },
        {
          "id": "https://www.youtube.com/watch?v=aVwxzDHniEw",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=aVwxzDHniEw",
          "publishedOn": "2023-01-02T13:43:12.000Z",
          "wordCount": null,
          "title": "The Beauty of Bézier Curves (2021) [video]",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/badlogicgames/status/1609652290113404928",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/badlogicgames/status/1609652290113404928",
          "publishedOn": "2023-01-02T11:41:52.000Z",
          "wordCount": 470,
          "title": "Writing DOS games and demos with modern tools",
          "imageUrl": null
        },
        {
          "id": "https://www.youtube.com/watch?v=VhYEOG9LOIk",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=VhYEOG9LOIk",
          "publishedOn": "2023-01-02T10:33:27.000Z",
          "wordCount": null,
          "title": "Trash Train: I put my trash cans on rails so they move automatically [video]",
          "imageUrl": null
        },
        {
          "id": "https://www.voanews.com/a/canada-bans-most-foreigners-from-buying-homes/6899982.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.voanews.com/a/canada-bans-most-foreigners-from-buying-homes/6899982.html",
          "publishedOn": "2023-01-02T09:42:02.000Z",
          "wordCount": 1172,
          "title": "Canada bans most foreigners from buying homes",
          "imageUrl": "https://gdb.voanews.com/022a0000-0aff-0242-1edc-08daec5290ad_cx0_cy4_cw0_w1200_r1.jpg"
        },
        {
          "id": "https://mafs.dev/",
          "author": null,
          "description": "Comments",
          "link": "https://mafs.dev/",
          "publishedOn": "2023-01-02T06:09:23.000Z",
          "wordCount": 503,
          "title": "Show HN: Mafs – React components for interactive math",
          "imageUrl": null
        },
        {
          "id": "https://thesephist.com/posts/lua/",
          "author": null,
          "description": "Comments",
          "link": "https://thesephist.com/posts/lua/",
          "publishedOn": "2023-01-02T02:57:13.000Z",
          "wordCount": 3753,
          "title": "Interesting things about the Lua interpreter (2020)",
          "imageUrl": null
        },
        {
          "id": "https://www.youtube.com/watch?v=x2IQNsLuikw",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=x2IQNsLuikw",
          "publishedOn": "2023-01-02T01:11:21.000Z",
          "wordCount": null,
          "title": "Automatic snow tires throw chains at your wheels [video]",
          "imageUrl": null
        },
        {
          "id": "https://exposing.ai/megaface/",
          "author": null,
          "description": "Comments",
          "link": "https://exposing.ai/megaface/",
          "publishedOn": "2023-01-02T01:09:03.000Z",
          "wordCount": 1762,
          "title": "Megaface",
          "imageUrl": "https://exposing.ai/assets/pages/datasets/megaface/assets/background.jpg"
        },
        {
          "id": "https://www.airdeets.com/blog/diy-arduino-based-air-sensor-pt1",
          "author": null,
          "description": "Comments",
          "link": "https://www.airdeets.com/blog/diy-arduino-based-air-sensor-pt1",
          "publishedOn": "2023-01-02T00:08:38.000Z",
          "wordCount": 624,
          "title": "Blog series on building an air sensor with Arduino",
          "imageUrl": null
        },
        {
          "id": "https://statmodeling.stat.columbia.edu/2016/06/28/khkhkj/",
          "author": null,
          "description": "Comments",
          "link": "https://statmodeling.stat.columbia.edu/2016/06/28/khkhkj/",
          "publishedOn": "2023-01-02T00:05:19.000Z",
          "wordCount": 11645,
          "title": "Should this paper in Psychological Science be retracted?",
          "imageUrl": null
        },
        {
          "id": "https://www.instructables.com/Orrery-Earth-Moon-and-Sun/",
          "author": null,
          "description": "Comments",
          "link": "https://www.instructables.com/Orrery-Earth-Moon-and-Sun/",
          "publishedOn": "2023-01-02T00:00:37.000Z",
          "wordCount": 15611,
          "title": "Orrery (Earth, Moon, and Sun)",
          "imageUrl": "https://content.instructables.com/F73/4W6W/KYR9YCEJ/F734W6WKYR9YCEJ.png?auto=webp&frame=1&width=2100"
        },
        {
          "id": "https://jalammar.github.io/ai-image-generation-tools/",
          "author": null,
          "description": "Comments",
          "link": "https://jalammar.github.io/ai-image-generation-tools/",
          "publishedOn": "2023-01-01T23:59:16.000Z",
          "wordCount": 2170,
          "title": "Remaking old computer graphics with AI image generation",
          "imageUrl": null
        },
        {
          "id": "https://langoguessr.com/",
          "author": null,
          "description": "Comments",
          "link": "https://langoguessr.com/",
          "publishedOn": "2023-01-01T23:48:46.000Z",
          "wordCount": 9,
          "title": "Langoguessr",
          "imageUrl": null
        },
        {
          "id": "https://murdoch.is/projects/currency/",
          "author": null,
          "description": "Comments",
          "link": "https://murdoch.is/projects/currency/",
          "publishedOn": "2023-01-01T23:34:55.000Z",
          "wordCount": 1151,
          "title": "Software Detection of Currency (2004)",
          "imageUrl": null
        },
        {
          "id": "https://celso.io/retrocomputing/2022/12/27/c64-from-scratch",
          "author": null,
          "description": "Comments",
          "link": "https://celso.io/retrocomputing/2022/12/27/c64-from-scratch",
          "publishedOn": "2023-01-01T22:50:25.000Z",
          "wordCount": 3842,
          "title": "Building a Frankenstein 64",
          "imageUrl": "https://celso.io//assets/c64final2.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34211796",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34211796",
          "publishedOn": "2023-01-01T22:34:32.000Z",
          "wordCount": 5376,
          "title": "Ask HN: Why isn't JSON-RPC more widely adopted?",
          "imageUrl": null
        },
        {
          "id": "https://gavinray97.github.io/blog/adding-invariant-to-cpp-design-by-contract",
          "author": null,
          "description": "Comments",
          "link": "https://gavinray97.github.io/blog/adding-invariant-to-cpp-design-by-contract",
          "publishedOn": "2023-01-01T22:02:03.000Z",
          "wordCount": 8442,
          "title": "Adding design-by-contract conditions to C++ via a GCC plugin",
          "imageUrl": "https://gavinray97.github.io/static/images/design-by-contract-logo.png"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34211457",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34211457",
          "publishedOn": "2023-01-01T21:59:07.000Z",
          "wordCount": 1707,
          "title": "Ask HN: Are there any good open source text-to-speech tools?",
          "imageUrl": null
        },
        {
          "id": "https://www.jeffgeerling.com/blog/2021/modeling-my-grandpa-3d-photogrammetry",
          "author": null,
          "description": "Comments",
          "link": "https://www.jeffgeerling.com/blog/2021/modeling-my-grandpa-3d-photogrammetry",
          "publishedOn": "2023-01-01T21:06:16.000Z",
          "wordCount": 1661,
          "title": "Modeling my Grandpa with 3D Photogrammetry (2021)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/linleyh/liberation-circuit",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/linleyh/liberation-circuit",
          "publishedOn": "2023-01-01T20:41:28.000Z",
          "wordCount": 1046,
          "title": "Liberation Circuit – FOSS RTS/programming game",
          "imageUrl": "https://opengraph.githubassets.com/1fad86af89328432db8f55eb0d9cdbe653bea7ca598176e6a7cfff704d379fbe/linleyh/liberation-circuit"
        },
        {
          "id": "https://twitter.com/LukeDashjr/status/1609613748364509184",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/LukeDashjr/status/1609613748364509184",
          "publishedOn": "2023-01-01T20:35:51.000Z",
          "wordCount": 470,
          "title": "“My PGP key is compromised, and at least many of my bitcoins stolen”",
          "imageUrl": null
        },
        {
          "id": "http://elm-chan.org/fsw/ff/00index_e.html",
          "author": null,
          "description": "Comments",
          "link": "http://elm-chan.org/fsw/ff/00index_e.html",
          "publishedOn": "2023-01-01T19:48:45.000Z",
          "wordCount": 720,
          "title": "FatFs – Generic FAT Filesystem Module",
          "imageUrl": null
        },
        {
          "id": "https://zeptobars.com/en/read/Casio-F-91W-OKI-quartz-watch",
          "author": null,
          "description": "Comments",
          "link": "https://zeptobars.com/en/read/Casio-F-91W-OKI-quartz-watch",
          "publishedOn": "2023-01-01T19:41:11.000Z",
          "wordCount": 261,
          "title": "Casio-F-91W die-shot",
          "imageUrl": null
        },
        {
          "id": "https://www.bakertilly.de/en/news/detail/bundestag-beschliesst-hinweisgeberschutzgesetz-welche-neuerungen-fuer-unternehmen-nun-wichtig-sind.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.bakertilly.de/en/news/detail/bundestag-beschliesst-hinweisgeberschutzgesetz-welche-neuerungen-fuer-unternehmen-nun-wichtig-sind.html",
          "publishedOn": "2023-01-01T19:00:11.000Z",
          "wordCount": 694,
          "title": "German Bundestag Passes Whistleblower Protection Act",
          "imageUrl": null
        },
        {
          "id": "https://www.science.org/content/article/why-536-was-worst-year-be-alive",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/content/article/why-536-was-worst-year-be-alive",
          "publishedOn": "2023-01-01T18:44:55.000Z",
          "wordCount": 2935,
          "title": "Why 536 was 'the worst year to be alive' (2018)",
          "imageUrl": "https://www.science.org/do/10.1126/science.aaw0632/abs/ca_1116NID_Dome_Tent_online_CC_cropped.jpg"
        },
        {
          "id": "https://www.smithsonianmag.com/smart-news/mini-brains-grown-stem-cells-developed-eyes-can-sense-light-180978478/",
          "author": null,
          "description": "Comments",
          "link": "https://www.smithsonianmag.com/smart-news/mini-brains-grown-stem-cells-developed-eyes-can-sense-light-180978478/",
          "publishedOn": "2023-01-01T18:12:27.000Z",
          "wordCount": 1531,
          "title": "Mini brains grown from stem cells developed eye-like features (2021)",
          "imageUrl": "https://th-thumbnailer.cdn-si-edu.com/WPo1QYijZgwNpDFMfC96j9CZc7Y=/fit-in/1600x0/filters:focal(153x309:154x310)/https%3A%2F%2Ftf-cmsv2-smithsonianmag-media.s3.amazonaws.com%2Ffiler%2F19%2Fa4%2F19a45954-e4b5-400c-b148-52f493ec5688%2Flow-res_this_image_shows_a_brain_organoid_with_optic_cups_credit_elke_gabriel_2021_1jpg.png"
        },
        {
          "id": "https://github.com/michaelengel/crosstalk",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/michaelengel/crosstalk",
          "publishedOn": "2023-01-01T17:56:04.000Z",
          "wordCount": 790,
          "title": "Smalltalk-80 on Raspberry Pi: A bare metal implementation",
          "imageUrl": "https://opengraph.githubassets.com/173e8a91062e4795b65e446acc95402728fcfd221b0a328da9c12bdf2e646d6a/michaelengel/crosstalk"
        },
        {
          "id": "https://joemorrison.substack.com/p/how-internet-in-space-will-transform",
          "author": null,
          "description": "Comments",
          "link": "https://joemorrison.substack.com/p/how-internet-in-space-will-transform",
          "publishedOn": "2023-01-01T16:49:01.000Z",
          "wordCount": 7563,
          "title": "“Internet in space” will transform the satellite imagery industry",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe10ce776-534c-4724-ad55-266e16fc4070_2160x1620.jpeg"
        },
        {
          "id": "https://til.simonwillison.net/clickhouse/github-explorer",
          "author": null,
          "description": "Comments",
          "link": "https://til.simonwillison.net/clickhouse/github-explorer",
          "publishedOn": "2023-01-01T16:45:56.000Z",
          "wordCount": 874,
          "title": "Querying the GitHub archive with the ClickHouse playground",
          "imageUrl": "https://til.simonwillison.net/-/media/screenshot/clickhouse_github-explorer.md"
        },
        {
          "id": "https://tynan.com/letstalk/",
          "author": null,
          "description": "Comments",
          "link": "https://tynan.com/letstalk/",
          "publishedOn": "2023-01-01T14:19:18.000Z",
          "wordCount": 3492,
          "title": "Conversation Skills Essentials",
          "imageUrl": null
        },
        {
          "id": "https://www.youtube.com/watch?v=U9uZlEqUQw0",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=U9uZlEqUQw0",
          "publishedOn": "2023-01-01T14:01:47.000Z",
          "wordCount": null,
          "title": "Homoiconic Spreadsheets: What, How and Why [video]",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34206219",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34206219",
          "publishedOn": "2023-01-01T13:50:27.000Z",
          "wordCount": 21912,
          "title": "Ask HN: Concepts that clicked only years after you first encountered them?",
          "imageUrl": null
        },
        {
          "id": "https://sweetcocoa.github.io/pop2piano_samples/",
          "author": null,
          "description": "Comments",
          "link": "https://sweetcocoa.github.io/pop2piano_samples/",
          "publishedOn": "2023-01-01T13:08:16.000Z",
          "wordCount": 312,
          "title": "Pop2Piano: Pop audio-based piano cover generation",
          "imageUrl": null
        },
        {
          "id": "https://noahpinion.substack.com/p/the-internet-wants-to-be-fragmented",
          "author": null,
          "description": "Comments",
          "link": "https://noahpinion.substack.com/p/the-internet-wants-to-be-fragmented",
          "publishedOn": "2023-01-01T12:37:59.000Z",
          "wordCount": 6547,
          "title": "The internet wants to be fragmented",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec79951-fd6d-4552-8163-d2c069e3000b_1440x799.png"
        },
        {
          "id": "https://medium.com/@erik_68861/running-advent-of-code-on-a-2-microcontroller-fa35b596cf11",
          "author": null,
          "description": "Comments",
          "link": "https://medium.com/@erik_68861/running-advent-of-code-on-a-2-microcontroller-fa35b596cf11",
          "publishedOn": "2023-01-01T07:31:39.000Z",
          "wordCount": 6198,
          "title": "Running Advent of Code on a $2 microcontroller",
          "imageUrl": "https://miro.medium.com/max/800/0*v01_1vUuRXH9tX2Q.jpg"
        },
        {
          "id": "https://richardg867.wordpress.com/2020/02/29/usb-c-done-cheap/",
          "author": null,
          "description": "Comments",
          "link": "https://richardg867.wordpress.com/2020/02/29/usb-c-done-cheap/",
          "publishedOn": "2023-01-01T05:51:59.000Z",
          "wordCount": 4880,
          "title": "USB-C done cheap: when 2 ports become 1 (2020)",
          "imageUrl": "https://richardg867.files.wordpress.com/2020/02/regularcard.jpg"
        },
        {
          "id": "https://www.bbc.com/news/world-latin-america-63995293",
          "author": null,
          "description": "Comments",
          "link": "https://www.bbc.com/news/world-latin-america-63995293",
          "publishedOn": "2023-01-01T03:17:07.000Z",
          "wordCount": 7297,
          "title": "A secret message in a Colombian song gave hostages hope",
          "imageUrl": "https://ichef.bbci.co.uk/news/1024/branded_news/16429/production/_128077119_c0d2452d-66f9-4ad2-a176-f5b5d77eee98.jpg"
        },
        {
          "id": "https://www.softwaremaxims.com/blog/not-a-supplier",
          "author": null,
          "description": "Comments",
          "link": "https://www.softwaremaxims.com/blog/not-a-supplier",
          "publishedOn": "2022-12-31T22:22:39.000Z",
          "wordCount": 1536,
          "title": "I am not a supplier",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34201366",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34201366",
          "publishedOn": "2022-12-31T22:21:53.000Z",
          "wordCount": 2860,
          "title": "Tell HN: Happy New Year",
          "imageUrl": null
        },
        {
          "id": "https://www.hugthemonkey.com/2007/03/paul_zak_oxytoc.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.hugthemonkey.com/2007/03/paul_zak_oxytoc.html",
          "publishedOn": "2022-12-31T21:51:29.000Z",
          "wordCount": 3047,
          "title": "Oxytocin, trust, and reciprocity (2007)",
          "imageUrl": null
        },
        {
          "id": "https://www.theguardian.com/world/2022/jun/09/stowaways-oil-tanker-isle-of-wight-hijacking-strange-case-nave-andromeda",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/world/2022/jun/09/stowaways-oil-tanker-isle-of-wight-hijacking-strange-case-nave-andromeda",
          "publishedOn": "2022-12-31T21:50:27.000Z",
          "wordCount": 9924,
          "title": "Seven stowaways and a hijacked oil tanker",
          "imageUrl": "https://i.guim.co.uk/img/media/1bd12b495e32f80e87c4c223b00083a258b13fc1/0_0_5000_3000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a8c315e4fd6d62d6239d47607df7d5b8"
        },
        {
          "id": "https://blog.cloudflare.com/the-state-of-http-in-2022/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.cloudflare.com/the-state-of-http-in-2022/",
          "publishedOn": "2022-12-31T21:45:02.000Z",
          "wordCount": null,
          "title": "The State of HTTP in 2022",
          "imageUrl": null
        },
        {
          "id": "https://blog.aqnichol.com/2022/12/31/large-scale-vehicle-classification/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.aqnichol.com/2022/12/31/large-scale-vehicle-classification/",
          "publishedOn": "2022-12-31T21:20:49.000Z",
          "wordCount": 3556,
          "title": "Large-scale vehicle classification",
          "imageUrl": null
        },
        {
          "id": "https://danluu.com/branch-prediction/",
          "author": null,
          "description": "Comments",
          "link": "https://danluu.com/branch-prediction/",
          "publishedOn": "2022-12-31T20:46:07.000Z",
          "wordCount": 5508,
          "title": "CPU branch prediction evolution over years (2017)",
          "imageUrl": null
        },
        {
          "id": "https://www.palladiummag.com/2021/02/02/new-industries-come-from-crazy-people/",
          "author": null,
          "description": "Comments",
          "link": "https://www.palladiummag.com/2021/02/02/new-industries-come-from-crazy-people/",
          "publishedOn": "2022-12-31T20:33:13.000Z",
          "wordCount": 3923,
          "title": "New industries come from crazy people (2021)",
          "imageUrl": "https://pdmedia.b-cdn.net/2021/02/Edison_Burroughs_Ford.jpg"
        },
        {
          "id": "https://arnaud-carre.github.io/2022-12-30-amiga-ham/",
          "author": null,
          "description": "Comments",
          "link": "https://arnaud-carre.github.io/2022-12-30-amiga-ham/",
          "publishedOn": "2022-12-31T20:10:46.000Z",
          "wordCount": 3221,
          "title": "Brute Force Colors",
          "imageUrl": "https://arnaud-carre.github.io/assets/img/ham/ham_title.jpg"
        },
        {
          "id": "https://susam.net/blog/cal-9-1752.html",
          "author": null,
          "description": "Comments",
          "link": "https://susam.net/blog/cal-9-1752.html",
          "publishedOn": "2022-12-31T19:45:33.000Z",
          "wordCount": 396,
          "title": "Cal 9 1752 (2004)",
          "imageUrl": null
        },
        {
          "id": "https://www.aljazeera.com/news/2022/12/31/croatia-to-switch-to-euro-enter-passport-free-schengen-zone",
          "author": null,
          "description": "Comments",
          "link": "https://www.aljazeera.com/news/2022/12/31/croatia-to-switch-to-euro-enter-passport-free-schengen-zone",
          "publishedOn": "2022-12-31T19:43:57.000Z",
          "wordCount": 1239,
          "title": "Croatia to switch to euro, enter passport-free Schengen zone",
          "imageUrl": "https://www.aljazeera.com/wp-content/uploads/2022/12/2022-07-12T132356Z_1571652692_RC2BAV99DU3A_RTRMADP_3_EUROZONE-EXPANSION-CROATIA-RATE.jpg?resize=1920%2C1440"
        },
        {
          "id": "https://azeemba.com/posts/degenerate-matter.html",
          "author": null,
          "description": "Comments",
          "link": "https://azeemba.com/posts/degenerate-matter.html",
          "publishedOn": "2022-12-31T17:55:26.000Z",
          "wordCount": 4853,
          "title": "Degenerate matter: How reality deals with uncertainty",
          "imageUrl": null
        },
        {
          "id": "https://blog.jez.io/rss-after-one-week/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.jez.io/rss-after-one-week/",
          "publishedOn": "2022-12-31T17:46:41.000Z",
          "wordCount": 1507,
          "title": "Gripes with RSS after one week",
          "imageUrl": null
        },
        {
          "id": "http://www.directedplay.com/first-tv-image-of-mars",
          "author": null,
          "description": "Comments",
          "link": "http://www.directedplay.com/first-tv-image-of-mars",
          "publishedOn": "2022-12-31T17:45:07.000Z",
          "wordCount": 1214,
          "title": "First TV Image of Mars: Interplanetary color by numbers (2016)",
          "imageUrl": null
        },
        {
          "id": "https://hakaimagazine.com/videos-visuals/for-humpbacks-bubbles-can-be-tools/",
          "author": null,
          "description": "Comments",
          "link": "https://hakaimagazine.com/videos-visuals/for-humpbacks-bubbles-can-be-tools/",
          "publishedOn": "2022-12-31T16:49:00.000Z",
          "wordCount": 2243,
          "title": "For humpbacks, bubbles can be tools",
          "imageUrl": "https://hakaimagazine.com/wp-content/uploads/facebook-bubble-tools.jpg"
        },
        {
          "id": "https://twitter.com/taviso/status/1609032924015493120",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/taviso/status/1609032924015493120",
          "publishedOn": "2022-12-31T16:43:44.000Z",
          "wordCount": 470,
          "title": "Templates of Doom – A spreadsheet text adventure game (1985)",
          "imageUrl": null
        },
        {
          "id": "https://jonpauluritis.com/articles/5-percent-rule/",
          "author": null,
          "description": "Comments",
          "link": "https://jonpauluritis.com/articles/5-percent-rule/",
          "publishedOn": "2022-12-31T16:30:35.000Z",
          "wordCount": 827,
          "title": "The 5% Rule",
          "imageUrl": "https://jonpauluritis.com/img/bart.jpg"
        },
        {
          "id": "https://blog.standardnotes.com/40921/no-react-native-is-not-the-future",
          "author": null,
          "description": "Comments",
          "link": "https://blog.standardnotes.com/40921/no-react-native-is-not-the-future",
          "publishedOn": "2022-12-31T16:02:48.000Z",
          "wordCount": 3383,
          "title": "React Native is not the future",
          "imageUrl": null
        },
        {
          "id": "https://muffinman.io/blog/draw-svg-rope-using-javascript/",
          "author": null,
          "description": "Comments",
          "link": "https://muffinman.io/blog/draw-svg-rope-using-javascript/",
          "publishedOn": "2022-12-31T15:43:54.000Z",
          "wordCount": 2003,
          "title": "Draw SVG rope using JavaScript",
          "imageUrl": "https://muffinman.io/img/rope/cover.png"
        },
        {
          "id": "https://godotengine.org/article/2022-retrospective",
          "author": null,
          "description": "Comments",
          "link": "https://godotengine.org/article/2022-retrospective",
          "publishedOn": "2022-12-31T15:12:28.000Z",
          "wordCount": 1751,
          "title": "2022: A Retrospective",
          "imageUrl": "https://godotengine.org/storage/app/uploads/public/63a/ebf/03e/63aebf03e854b249543216.png"
        },
        {
          "id": "https://github.com/zakird/crux-top-lists",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/zakird/crux-top-lists",
          "publishedOn": "2022-12-31T13:49:20.000Z",
          "wordCount": 1218,
          "title": "Cached Chrome Top Million Websites",
          "imageUrl": "https://opengraph.githubassets.com/3fb5a2be93f72cd33ef1d331cd2a25e1f895fdd48a374c1b6d143731d5685833/zakird/crux-top-lists"
        },
        {
          "id": "https://userpages.umbc.edu/~vijay/mashey.on.risc.html",
          "author": null,
          "description": "Comments",
          "link": "https://userpages.umbc.edu/~vijay/mashey.on.risc.html",
          "publishedOn": "2022-12-31T13:47:05.000Z",
          "wordCount": 4596,
          "title": "John Mashey on RISC/CISC (1991)",
          "imageUrl": null
        },
        {
          "id": "https://poleclock.com/",
          "author": null,
          "description": "Comments",
          "link": "https://poleclock.com/",
          "publishedOn": "2022-12-31T13:40:51.000Z",
          "wordCount": 12,
          "title": "Show HN: Pole Clock, a single 24h clock with multiple timezones",
          "imageUrl": null
        },
        {
          "id": "https://www.forrestthewoods.com/blog/should-small-rust-structs-be-passed-by-copy-or-by-borrow/",
          "author": null,
          "description": "Comments",
          "link": "https://www.forrestthewoods.com/blog/should-small-rust-structs-be-passed-by-copy-or-by-borrow/",
          "publishedOn": "2022-12-31T13:33:30.000Z",
          "wordCount": 1690,
          "title": "Should small Rust structs be passed by-copy or by-borrow? (2019)",
          "imageUrl": "https://www.forrestthewoods.com/blog/should-small-rust-structs-be-passed-by-copy-or-by-borrow/assets/img/header.png"
        },
        {
          "id": "https://blog.ericfrisch.com/start-again/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.ericfrisch.com/start-again/",
          "publishedOn": "2022-12-31T13:24:59.000Z",
          "wordCount": 954,
          "title": "The Power of Starting Again",
          "imageUrl": "https://efresources.s3.amazonaws.com/eric.jpg"
        },
        {
          "id": "https://aeon.co/essays/the-first-americans-a-story-of-wonderful-uncertain-science",
          "author": null,
          "description": "Comments",
          "link": "https://aeon.co/essays/the-first-americans-a-story-of-wonderful-uncertain-science",
          "publishedOn": "2022-12-31T12:44:10.000Z",
          "wordCount": 13891,
          "title": "Archaeology and genetics can’t yet agree on when humans arrived in the Americas",
          "imageUrl": "https://omicron.aeon.co/images/6eae7c81-732c-42d3-9930-18289dfd950d/header_essay-final-image_8953e-white-sands-footprints.jpg"
        },
        {
          "id": "https://www.historyhit.com/culture/dinner-for-one/",
          "author": null,
          "description": "Comments",
          "link": "https://www.historyhit.com/culture/dinner-for-one/",
          "publishedOn": "2022-12-31T11:34:53.000Z",
          "wordCount": 2795,
          "title": "Dinner for one: A little-known British comedy famous in Germany",
          "imageUrl": "https://www.historyhit.com/app/uploads/2022/12/Dinner-For-One-Cover-Image.jpg"
        },
        {
          "id": "https://www.wsj.com/articles/wage-inequality-may-be-starting-to-reverse-11672339062",
          "author": null,
          "description": "Comments",
          "link": "https://www.wsj.com/articles/wage-inequality-may-be-starting-to-reverse-11672339062",
          "publishedOn": "2022-12-31T00:24:33.000Z",
          "wordCount": 7276,
          "title": "Wage inequality may be starting to reverse",
          "imageUrl": "https://images.wsj.net/im-693692/social"
        },
        {
          "id": "https://thecolumn.substack.com/p/southwest-airlines-christmas-meltdown",
          "author": null,
          "description": "Comments",
          "link": "https://thecolumn.substack.com/p/southwest-airlines-christmas-meltdown",
          "publishedOn": "2022-12-30T23:58:41.000Z",
          "wordCount": 4493,
          "title": "SouthwestAirlines' Meltdown Shows How Corporations Pit Consumers Against Workers",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F704fe5c8-8d48-4b61-92ab-19ce409f74c2_2564x1522.png"
        },
        {
          "id": "https://www.quantamagazine.org/how-claude-shannons-information-theory-invented-the-future-20201222/",
          "author": null,
          "description": "Comments",
          "link": "https://www.quantamagazine.org/how-claude-shannons-information-theory-invented-the-future-20201222/",
          "publishedOn": "2022-12-30T23:16:23.000Z",
          "wordCount": 6379,
          "title": "Claude Shannon’s research laid foundations for modern communications (2020)",
          "imageUrl": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2020/12/Claude-Shannon_1200_social.jpg"
        },
        {
          "id": "https://github.com/punnerud/rgcosm",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/punnerud/rgcosm",
          "publishedOn": "2022-12-30T22:45:50.000Z",
          "wordCount": 734,
          "title": "RGCosm – Reverse Geocode for OpenStreetmap",
          "imageUrl": "https://opengraph.githubassets.com/e9fd53e7ddf873936de35cc0a9d50c967977da5a83a67a2a77119730c21955bd/punnerud/rgcosm"
        },
        {
          "id": "https://www.kqed.org/mindshift/60624/young-adults-are-struggling-with-their-mental-health-is-more-childhood-independence-the-answer",
          "author": null,
          "description": "Comments",
          "link": "https://www.kqed.org/mindshift/60624/young-adults-are-struggling-with-their-mental-health-is-more-childhood-independence-the-answer",
          "publishedOn": "2022-12-30T22:40:10.000Z",
          "wordCount": 29339,
          "title": "Young adults are struggling with their mental health",
          "imageUrl": "https://ww2.kqed.org/app/uploads/sites/23/2022/12/iStock-Gabriel-Codarcea-1020x680.jpg"
        },
        {
          "id": "https://github.com/WinVector/data_algebra",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/WinVector/data_algebra",
          "publishedOn": "2022-12-30T21:24:53.000Z",
          "wordCount": 3069,
          "title": "Control Pandas, Polars, or SQL from One DSL",
          "imageUrl": "https://opengraph.githubassets.com/773ce7489effd15bf1a7d8d5aeecdb70d81ba35c5abf06a9e12fcbbbe114e7f6/WinVector/data_algebra"
        },
        {
          "id": "https://github.com/marsupialtail/quokka/blob/master/blog/why.md",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/marsupialtail/quokka/blob/master/blog/why.md",
          "publishedOn": "2022-12-30T20:08:29.000Z",
          "wordCount": 1747,
          "title": "I wrote a SQL engine in Python",
          "imageUrl": "https://opengraph.githubassets.com/3d7c8c8eabdfecc1a29bf5127d44dfcba92a5b0f05642c56ff6836e612f9fc0b/marsupialtail/quokka"
        },
        {
          "id": "https://boards.straightdope.com/t/what-are-those-dents-in-i-90-outside-seattle/422061/30",
          "author": null,
          "description": "Comments",
          "link": "https://boards.straightdope.com/t/what-are-those-dents-in-i-90-outside-seattle/422061/30",
          "publishedOn": "2022-12-30T19:32:03.000Z",
          "wordCount": 2209,
          "title": "What are those dents in I-90 outside Seattle?",
          "imageUrl": "https://global.discourse-cdn.com/straightdope/original/2X/e/e489c3b7d8fce19c4b355dd4fc3f88cc39c34b87.png"
        },
        {
          "id": "https://www.rssbrain.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.rssbrain.com/",
          "publishedOn": "2022-12-30T19:13:52.000Z",
          "wordCount": 219,
          "title": "Show HN: RSS Brain",
          "imageUrl": null
        },
        {
          "id": "https://www.germanvelasco.com/blog/phoenix-1-7-is-view-less",
          "author": null,
          "description": "Comments",
          "link": "https://www.germanvelasco.com/blog/phoenix-1-7-is-view-less",
          "publishedOn": "2022-12-30T18:52:32.000Z",
          "wordCount": 2462,
          "title": "Phoenix 1.7 is View-less",
          "imageUrl": "https://www.germanvelasco.com/images/gv-photo.jpeg"
        },
        {
          "id": "https://zhengdongwang.com/2022/12/28/2022-letter.html",
          "author": null,
          "description": "Comments",
          "link": "https://zhengdongwang.com/2022/12/28/2022-letter.html",
          "publishedOn": "2022-12-30T18:18:06.000Z",
          "wordCount": 12133,
          "title": "2022 Letter",
          "imageUrl": null
        },
        {
          "id": "https://blogs.uoregon.edu/dymaxionhouse/the-dymaxion-bathroom/",
          "author": null,
          "description": "Comments",
          "link": "https://blogs.uoregon.edu/dymaxionhouse/the-dymaxion-bathroom/",
          "publishedOn": "2022-12-30T17:42:07.000Z",
          "wordCount": 1124,
          "title": "The Dymaxion Bathroom",
          "imageUrl": null
        },
        {
          "id": "https://www.atlasobscura.com/articles/vostell-concrete-book-mystery",
          "author": null,
          "description": "Comments",
          "link": "https://www.atlasobscura.com/articles/vostell-concrete-book-mystery",
          "publishedOn": "2022-12-30T17:29:24.000Z",
          "wordCount": 5871,
          "title": "Can science solve the mystery of the concrete book?",
          "imageUrl": "https://img.atlasobscura.com/AvtsT3FR1EeEiC6miDWHh_MjdCNzHxucHxA0qCxPbFg/rt:fit/w:600/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy84ZTAzZDAzM2M0/ZmZiMTE3NWZfMzMx/MzJEXzI2NV9BUFNf/Q29uY3JldGUgQm9v/ayBSZXNlYXJjaC5q/cGc.jpg"
        },
        {
          "id": "https://lupyuen.github.io/articles/fb?1",
          "author": null,
          "description": "Comments",
          "link": "https://lupyuen.github.io/articles/fb?1",
          "publishedOn": "2022-12-30T16:50:34.000Z",
          "wordCount": 3236,
          "title": "NuttX RTOS for PinePhone: Framebuffer",
          "imageUrl": "https://lupyuen.github.io/images/fb-title.jpg"
        },
        {
          "id": "https://tamagui.dev/blog/version-one",
          "author": null,
          "description": "Comments",
          "link": "https://tamagui.dev/blog/version-one",
          "publishedOn": "2022-12-30T16:45:50.000Z",
          "wordCount": 24572,
          "title": "Tamagui 1.0 – Cross-platform React apps in less time, with better performance",
          "imageUrl": "https://tamagui.dev/banner-one.jpg"
        },
        {
          "id": "https://erthalion.info/2022/12/30/bpf-performance/",
          "author": null,
          "description": "Comments",
          "link": "https://erthalion.info/2022/12/30/bpf-performance/",
          "publishedOn": "2022-12-30T16:23:07.000Z",
          "wordCount": 5242,
          "title": "Running fast and slow: experiments with BPF programs' performance",
          "imageUrl": null
        },
        {
          "id": "https://mostlypython.substack.com/p/why-im-still-using-python",
          "author": null,
          "description": "Comments",
          "link": "https://mostlypython.substack.com/p/why-im-still-using-python",
          "publishedOn": "2022-12-30T16:06:02.000Z",
          "wordCount": 2871,
          "title": "Why I'm still using Python",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8f6ea1-2d0c-4abb-84db-054ff4c03bb1_1224x1632.jpeg"
        },
        {
          "id": "https://streaming.media.ccc.de/jev22/relive/49255",
          "author": null,
          "description": "Comments",
          "link": "https://streaming.media.ccc.de/jev22/relive/49255",
          "publishedOn": "2022-12-30T14:43:03.000Z",
          "wordCount": 54,
          "title": "Write a Wayland Compositor [video]",
          "imageUrl": null
        },
        {
          "id": "https://strlen.com/treesheets/",
          "author": null,
          "description": "Comments",
          "link": "https://strlen.com/treesheets/",
          "publishedOn": "2022-12-30T13:55:10.000Z",
          "wordCount": 445,
          "title": "TreeSheets: Open Source Free Form Data Organizer",
          "imageUrl": null
        },
        {
          "id": "https://oceanservice.noaa.gov/geodesy/international-foot.html",
          "author": null,
          "description": "Comments",
          "link": "https://oceanservice.noaa.gov/geodesy/international-foot.html",
          "publishedOn": "2022-12-30T13:43:10.000Z",
          "wordCount": 802,
          "title": "A Tale of Two Feet",
          "imageUrl": "https://oceanservice.noaa.gov/geodesy/two-surveyors.jpg"
        },
        {
          "id": "https://authjs.dev/",
          "author": null,
          "description": "Comments",
          "link": "https://authjs.dev/",
          "publishedOn": "2022-12-30T13:10:21.000Z",
          "wordCount": 289,
          "title": "Auth.js Authentication for the Web",
          "imageUrl": "https://authjs.dev/img/og-image.png"
        },
        {
          "id": "https://jott.live/markdown/images_as_emoji",
          "author": null,
          "description": "Comments",
          "link": "https://jott.live/markdown/images_as_emoji",
          "publishedOn": "2022-12-30T05:06:04.000Z",
          "wordCount": 1611,
          "title": "Over-engineering an emoji webcam filter with a neural network",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34180508",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34180508",
          "publishedOn": "2022-12-30T01:24:47.000Z",
          "wordCount": 236,
          "title": "Poll: What's the best laptop for Linux these days?",
          "imageUrl": null
        },
        {
          "id": "https://kagi.com/",
          "author": null,
          "description": "Comments",
          "link": "https://kagi.com/",
          "publishedOn": "2022-12-30T00:17:12.000Z",
          "wordCount": 300,
          "title": "Kagi – Paid Search Engine",
          "imageUrl": null
        },
        {
          "id": "https://blog.oup.com/2022/11/how-to-identify-a-scientific-fact/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.oup.com/2022/11/how-to-identify-a-scientific-fact/",
          "publishedOn": "2022-12-29T23:32:34.000Z",
          "wordCount": 1723,
          "title": "How to Identify a Scientific Fact",
          "imageUrl": "https://oupblog.wpenginepowered.com/wp-content/uploads/2022/11/joel-filipe-Lw7BruqPnJY-unsplash.jpg"
        },
        {
          "id": "https://withinboredom.info/blog/2022/12/29/golang-is-evil-on-shitty-networks/",
          "author": null,
          "description": "Comments",
          "link": "https://withinboredom.info/blog/2022/12/29/golang-is-evil-on-shitty-networks/",
          "publishedOn": "2022-12-29T23:17:43.000Z",
          "wordCount": 2471,
          "title": "Golang is evil on shitty networks",
          "imageUrl": "https://withinboredom.info/wp-content/uploads/2022/12/image-3.png"
        },
        {
          "id": "https://www.mikesteder.com/engineering/management/gifs/software/illustrated/2014/12/31/software-engineering-illustrated-im-just-trying-to-change-this-lightbulb.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.mikesteder.com/engineering/management/gifs/software/illustrated/2014/12/31/software-engineering-illustrated-im-just-trying-to-change-this-lightbulb.html",
          "publishedOn": "2022-12-29T22:39:02.000Z",
          "wordCount": 1665,
          "title": "Software Illustrated: I'm just trying to change this lightbulb",
          "imageUrl": null
        },
        {
          "id": "https://freenetproject.org/freenet-build-1495-new-user-experience-and-performance.html",
          "author": null,
          "description": "Comments",
          "link": "https://freenetproject.org/freenet-build-1495-new-user-experience-and-performance.html",
          "publishedOn": "2022-12-29T22:33:21.000Z",
          "wordCount": 575,
          "title": "Freenet build 1495 released: new user entrance, user experience, performance",
          "imageUrl": "https://freenetproject.org/"
        },
        {
          "id": "https://miketaylr.com/posts/2022/12/how-the-IE-11-ua-string-broke-sites-in-firefox.html",
          "author": null,
          "description": "Comments",
          "link": "https://miketaylr.com/posts/2022/12/how-the-IE-11-ua-string-broke-sites-in-firefox.html",
          "publishedOn": "2022-12-29T22:23:16.000Z",
          "wordCount": 537,
          "title": "The IE 11 user-agent forced Mozilla to freeze part of its user-agent string",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/tivadardanka/status/1608419325706391554",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/tivadardanka/status/1608419325706391554",
          "publishedOn": "2022-12-29T22:22:27.000Z",
          "wordCount": 470,
          "title": "Stone tablet shows Babylonians able to approximate √2 with 99.9999% accuracy",
          "imageUrl": null
        },
        {
          "id": "https://www.ufarooqi.com/speaker-diarization-for-whisper-transcripts/",
          "author": null,
          "description": "Comments",
          "link": "https://www.ufarooqi.com/speaker-diarization-for-whisper-transcripts/",
          "publishedOn": "2022-12-29T21:32:48.000Z",
          "wordCount": 1639,
          "title": "Speaker diarization (labels) for OpenAI Whisper generated transcripts",
          "imageUrl": "https://www.ufarooqi.com/content/images/2022/12/DALL-E-2022-12-29-03.16.07---Speech-to-text-tool.-Audio-Waves-merging-into-text.png"
        },
        {
          "id": "https://blog.cloudflare.com/consequences-of-ip-blocking/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.cloudflare.com/consequences-of-ip-blocking/",
          "publishedOn": "2022-12-29T21:23:32.000Z",
          "wordCount": null,
          "title": "Unintended consequences of blocking IP addresses",
          "imageUrl": null
        },
        {
          "id": "http://endless.horse/",
          "author": null,
          "description": "Comments",
          "link": "http://endless.horse/",
          "publishedOn": "2022-12-29T21:07:40.000Z",
          "wordCount": 103,
          "title": "Endless Horse",
          "imageUrl": null
        },
        {
          "id": "https://www.tbray.org/ongoing/When/202x/2022/12/29/Privacy-is-OK",
          "author": null,
          "description": "Comments",
          "link": "https://www.tbray.org/ongoing/When/202x/2022/12/29/Privacy-is-OK",
          "publishedOn": "2022-12-29T21:07:20.000Z",
          "wordCount": 1142,
          "title": "Privacy is ok",
          "imageUrl": null
        },
        {
          "id": "https://angel.co/l/2xRy8y",
          "author": null,
          "description": "Comments",
          "link": "https://angel.co/l/2xRy8y",
          "publishedOn": "2022-12-29T21:01:08.000Z",
          "wordCount": null,
          "title": "Hive (YC S14) is hiring devs #3-10 in 2023 (Canada remote)",
          "imageUrl": null
        },
        {
          "id": "https://www.ncei.noaa.gov/news/airport-runway-names-shift-magnetic-field",
          "author": null,
          "description": "Comments",
          "link": "https://www.ncei.noaa.gov/news/airport-runway-names-shift-magnetic-field",
          "publishedOn": "2022-12-29T20:06:52.000Z",
          "wordCount": 1320,
          "title": "Airport runway names shift with magnetic field",
          "imageUrl": null
        },
        {
          "id": "https://www.nytimes.com/2022/12/29/sports/soccer/pele-dead.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/29/sports/soccer/pele-dead.html",
          "publishedOn": "2022-12-29T19:13:18.000Z",
          "wordCount": null,
          "title": "Pelé has died",
          "imageUrl": null
        },
        {
          "id": "https://www.robinsloan.com/lab/slab/",
          "author": null,
          "description": "Comments",
          "link": "https://www.robinsloan.com/lab/slab/",
          "publishedOn": "2022-12-29T19:05:58.000Z",
          "wordCount": 5045,
          "title": "The slab and the permacomputer (2021)",
          "imageUrl": "https://www.robinsloan.com/img/obsidian-slab.jpg"
        },
        {
          "id": "https://zlib.zu1k.com/",
          "author": null,
          "description": "Comments",
          "link": "https://zlib.zu1k.com/",
          "publishedOn": "2022-12-29T19:05:23.000Z",
          "wordCount": 4,
          "title": "A search engine for searching books in the Z-Library index on the IPFS network",
          "imageUrl": null
        },
        {
          "id": "https://blog.daveallie.com/ulid-primary-keys",
          "author": null,
          "description": "Comments",
          "link": "https://blog.daveallie.com/ulid-primary-keys",
          "publishedOn": "2022-12-29T18:00:10.000Z",
          "wordCount": 2177,
          "title": "ULIDs and Primary Keys",
          "imageUrl": null
        },
        {
          "id": "https://focustaiwan.tw/business/202212290013",
          "author": null,
          "description": "Comments",
          "link": "https://focustaiwan.tw/business/202212290013",
          "publishedOn": "2022-12-29T17:06:42.000Z",
          "wordCount": 2392,
          "title": "TSMC starts volume production of 3nm chips",
          "imageUrl": "https://imgcdn.cna.com.tw/Eng/WebEngPhotos/1024/2022/20221229/1024x683_065152670836.jpg"
        },
        {
          "id": "https://www.universetoday.com/159372/power-on-the-moon-what-will-it-take-to-survive-the-lunar-night/",
          "author": null,
          "description": "Comments",
          "link": "https://www.universetoday.com/159372/power-on-the-moon-what-will-it-take-to-survive-the-lunar-night/",
          "publishedOn": "2022-12-29T17:03:52.000Z",
          "wordCount": 2534,
          "title": "Power on the moon: What will it take to survive the lunar night?",
          "imageUrl": "https://www.universetoday.com/wp-content/uploads/2021/06/sandyastrov2_16x9.jpg"
        },
        {
          "id": "https://elonman.com/page/how/",
          "author": null,
          "description": "Comments",
          "link": "https://elonman.com/page/how/",
          "publishedOn": "2022-12-29T15:45:26.000Z",
          "wordCount": 4475,
          "title": "Show HN: GUI for making animated webcomics",
          "imageUrl": "/static/elonman/meta/android-chrome-512x512.39494b973dcb.png"
        },
        {
          "id": "https://raphlinus.github.io/text/2020/10/26/text-layout.html",
          "author": null,
          "description": "Comments",
          "link": "https://raphlinus.github.io/text/2020/10/26/text-layout.html",
          "publishedOn": "2022-12-29T15:05:02.000Z",
          "wordCount": 4008,
          "title": "Text layout is a loose hierarchy of segmentation (2020)",
          "imageUrl": null
        },
        {
          "id": "https://www.bbc.com/future/article/20220322-how-sleep-training-affects-babies",
          "author": null,
          "description": "Comments",
          "link": "https://www.bbc.com/future/article/20220322-how-sleep-training-affects-babies",
          "publishedOn": "2022-12-29T14:40:17.000Z",
          "wordCount": 66159,
          "title": "What happens when babies are left to cry it out?",
          "imageUrl": "https://ychef.files.bbci.co.uk/live/624x351/p0by4jnm.jpg"
        },
        {
          "id": "https://postgrest.org/en/stable/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://postgrest.org/en/stable/index.html",
          "publishedOn": "2022-12-29T13:04:46.000Z",
          "wordCount": 911,
          "title": "PostgREST – Serve a RESTful API from any Postgres database",
          "imageUrl": null
        },
        {
          "id": "https://seumasjeltzz.github.io/LinguaeGraecaePerSeIllustrata/",
          "author": null,
          "description": "Comments",
          "link": "https://seumasjeltzz.github.io/LinguaeGraecaePerSeIllustrata/",
          "publishedOn": "2022-12-29T12:11:52.000Z",
          "wordCount": 154,
          "title": "Lingua Graeca Per Se Illustrata",
          "imageUrl": null
        },
        {
          "id": "https://github.com/ciniml/WireGuard-ESP32-Arduino",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/ciniml/WireGuard-ESP32-Arduino",
          "publishedOn": "2022-12-29T10:52:38.000Z",
          "wordCount": 818,
          "title": "WireGuard for the ESP32",
          "imageUrl": "https://opengraph.githubassets.com/11ff8352a791d50fc3d43d3cd0ef2e3e8757f5822147b22924cfbbaf55dcd7ea/ciniml/WireGuard-ESP32-Arduino"
        },
        {
          "id": "https://borretti.me/article/introducing-austral",
          "author": null,
          "description": "Comments",
          "link": "https://borretti.me/article/introducing-austral",
          "publishedOn": "2022-12-29T01:37:41.000Z",
          "wordCount": 5945,
          "title": "Austral: A systems language with linear types and capabilities",
          "imageUrl": "https://borretti.me/assets/card/introducing-austral.jpg"
        },
        {
          "id": "https://www.laphamsquarterly.org/democracy/hiding-plain-sight",
          "author": null,
          "description": "Comments",
          "link": "https://www.laphamsquarterly.org/democracy/hiding-plain-sight",
          "publishedOn": "2022-12-29T00:31:16.000Z",
          "wordCount": 5011,
          "title": "Hiding in Plain Sight",
          "imageUrl": "https://www.laphamsquarterly.org/sites/default/files/styles/thumbnail/public/images/essay/hidinginplainsight.jpg?itok=41lDogar"
        },
        {
          "id": "https://www.economist.com/christmas-specials/2022/12/20/the-new-tech-worldview",
          "author": null,
          "description": "Comments",
          "link": "https://www.economist.com/christmas-specials/2022/12/20/the-new-tech-worldview",
          "publishedOn": "2022-12-28T23:02:04.000Z",
          "wordCount": 13154,
          "title": "The new tech worldview",
          "imageUrl": "https://www.economist.com/img/b/1280/720/90/media-assets/image/20221224_XMD117.jpg"
        },
        {
          "id": "https://www.chatbcg.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.chatbcg.com/",
          "publishedOn": "2022-12-28T22:50:59.000Z",
          "wordCount": 66,
          "title": "ChatBCG: Generative AI For Slides",
          "imageUrl": "https://i.imgur.com/zoRf1rU.png"
        },
        {
          "id": "https://spindas.dreamwidth.org/4207.html",
          "author": null,
          "description": "Comments",
          "link": "https://spindas.dreamwidth.org/4207.html",
          "publishedOn": "2022-12-28T21:26:04.000Z",
          "wordCount": 230,
          "title": "Build your front end in React, then let ChatGPT be your Redux reducer",
          "imageUrl": null
        },
        {
          "id": "https://tedgioia.substack.com/p/what-can-we-learn-from-barnes-and",
          "author": null,
          "description": "Comments",
          "link": "https://tedgioia.substack.com/p/what-can-we-learn-from-barnes-and",
          "publishedOn": "2022-12-28T21:07:09.000Z",
          "wordCount": 5943,
          "title": "Barnes and Noble's surprising turnaround",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0b32e6a-0ac5-454d-8f6f-3a241a948253_770x364.jpeg"
        },
        {
          "id": "https://www.coindesk.com/consensus-magazine/2022/12/28/why-solana-was-decimated-by-bankman-frieds-downfall/",
          "author": null,
          "description": "Comments",
          "link": "https://www.coindesk.com/consensus-magazine/2022/12/28/why-solana-was-decimated-by-bankman-frieds-downfall/",
          "publishedOn": "2022-12-28T20:59:59.000Z",
          "wordCount": 23003,
          "title": "Why Solana was decimated by Bankman-Fried’s downfall",
          "imageUrl": "https://www.coindesk.com/resizer/9tdmt3M-6OWcFStwGHBWffWizbE=/1200x628/center/middle/cloudfront-us-east-1.images.arcpublishing.com/coindesk/TDVOS52CMBGZVK7CYRL5GK7NMQ.jpg"
        },
        {
          "id": "https://chipsandcheese.com/2022/12/25/golden-coves-lopsided-vector-register-file/",
          "author": null,
          "description": "Comments",
          "link": "https://chipsandcheese.com/2022/12/25/golden-coves-lopsided-vector-register-file/",
          "publishedOn": "2022-12-28T20:57:53.000Z",
          "wordCount": 3826,
          "title": "Golden Cove’s Lopsided Vector Register File",
          "imageUrl": "https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2021/12/alderlakedie.jpg?fit=1200%2C607&ssl=1"
        },
        {
          "id": "https://www.filfre.net/2017/10/the-68000-wars-part-5-the-age-of-multimedia/",
          "author": null,
          "description": "Comments",
          "link": "https://www.filfre.net/2017/10/the-68000-wars-part-5-the-age-of-multimedia/",
          "publishedOn": "2022-12-28T20:55:25.000Z",
          "wordCount": 9857,
          "title": "The 68k Wars: The Age of Multimedia (2017)",
          "imageUrl": null
        },
        {
          "id": "https://guzey.com/books/why-we-sleep/",
          "author": null,
          "description": "Comments",
          "link": "https://guzey.com/books/why-we-sleep/",
          "publishedOn": "2022-12-28T20:50:43.000Z",
          "wordCount": 13753,
          "title": "“Why We Sleep” is riddled with scientific and factual errors (2019)",
          "imageUrl": "https://guzey.com/files/books/why-we-sleep/why-we-sleep-preview.png?4"
        },
        {
          "id": "https://aljazaribook.com/en/2019/10/15/a-goblet-which-arbitrates_en/",
          "author": null,
          "description": "Comments",
          "link": "https://aljazaribook.com/en/2019/10/15/a-goblet-which-arbitrates_en/",
          "publishedOn": "2022-12-28T20:31:38.000Z",
          "wordCount": 2638,
          "title": "A goblet which arbitrates during drinking parties (2019)",
          "imageUrl": "https://aljazaribook.com/wp-content/uploads/2019/10/Category-II-Chapter-1-mechanism_en.jpg"
        },
        {
          "id": "https://lspace.swyx.io/p/reverse-prompt-eng",
          "author": null,
          "description": "Comments",
          "link": "https://lspace.swyx.io/p/reverse-prompt-eng",
          "publishedOn": "2022-12-28T20:29:02.000Z",
          "wordCount": 8144,
          "title": "Reverse-engineering the source prompts of Notion AI",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F055a7cef-7c78-49c7-8dbd-bc3f79ac04e1_601x330.png"
        },
        {
          "id": "https://paroj.github.io/gltut/",
          "author": null,
          "description": "Comments",
          "link": "https://paroj.github.io/gltut/",
          "publishedOn": "2022-12-28T20:10:05.000Z",
          "wordCount": 1180,
          "title": "Learning Modern 3D Graphics Programming (2012)",
          "imageUrl": null
        },
        {
          "id": "https://mastodon.laurenweinstein.org/@lauren/109588605178700335",
          "author": null,
          "description": "Comments",
          "link": "https://mastodon.laurenweinstein.org/@lauren/109588605178700335",
          "publishedOn": "2022-12-28T19:45:57.000Z",
          "wordCount": 115,
          "title": "Once upon a time long ago, I was sitting alone in the UCLA ARPANET site #1",
          "imageUrl": "https://mastodon.laurenweinstein.org/system/accounts/avatars/109/357/023/842/046/447/original/5c9aa641bf055d08.jpg"
        },
        {
          "id": "https://www.smithsonianmag.com/smithsonian-institution/fourteen-discoveries-made-about-human-evolution-in-2022-180981344/",
          "author": null,
          "description": "Comments",
          "link": "https://www.smithsonianmag.com/smithsonian-institution/fourteen-discoveries-made-about-human-evolution-in-2022-180981344/",
          "publishedOn": "2022-12-28T19:18:28.000Z",
          "wordCount": 3830,
          "title": "Discoveries made about human evolution in 2022",
          "imageUrl": "https://th-thumbnailer.cdn-si-edu.com/gRojI9UPny0Qj_OLml-72YwKSAI=/fit-in/1600x0/filters:focal(800x602:801x603)/https%3A%2F%2Ftf-cmsv2-smithsonianmag-media.s3.amazonaws.com%2Ffiler_public%2F35%2F79%2F357909ac-8460-4e81-a523-4d33d69c84a4%2Fneanderthal_pressrelease22_tbcrop.jpg"
        },
        {
          "id": "https://www.theverge.com/2022/12/28/23528003/sherlock-holmes-metropolis-to-the-lighthouse-public-domain-day-2023",
          "author": null,
          "description": "Comments",
          "link": "https://www.theverge.com/2022/12/28/23528003/sherlock-holmes-metropolis-to-the-lighthouse-public-domain-day-2023",
          "publishedOn": "2022-12-28T19:07:33.000Z",
          "wordCount": 8841,
          "title": "Sherlock Holmes will finally escape copyright this weekend",
          "imageUrl": "https://cdn.vox-cdn.com/thumbor/kH5bEYpuYd8sUwxDNmmW8x6GdRM=/0x0:1559x1198/1200x628/filters:focal(710x496:711x497)/cdn.vox-cdn.com/uploads/chorus_asset/file/24319392/1559px_Portrait_of_Sherlock_Holmes_by_Sidney_Paget.jpg"
        },
        {
          "id": "https://www.theverge.com/2022/12/28/23529380/waze-history-of-crashes-beta-release-traffic-crash-data",
          "author": null,
          "description": "Comments",
          "link": "https://www.theverge.com/2022/12/28/23529380/waze-history-of-crashes-beta-release-traffic-crash-data",
          "publishedOn": "2022-12-28T19:04:01.000Z",
          "wordCount": 9200,
          "title": "Waze tests new alerts warning drivers about roads with a ‘history of crashes’",
          "imageUrl": "https://cdn.vox-cdn.com/thumbor/SC3ur0HICB-_d9PszNWyhYODa0k=/0x0:1354x900/1200x628/filters:focal(677x450:678x451)/cdn.vox-cdn.com/uploads/chorus_asset/file/24321462/RED_1.jpg"
        },
        {
          "id": "https://www.themarginalian.org/2022/12/26/jeanne-villepreux-power-argonaut/",
          "author": null,
          "description": "Comments",
          "link": "https://www.themarginalian.org/2022/12/26/jeanne-villepreux-power-argonaut/",
          "publishedOn": "2022-12-28T18:51:33.000Z",
          "wordCount": 4081,
          "title": "A seamstress who solved the ancient mystery of the Argonaut",
          "imageUrl": "https://www.themarginalian.org/wp-content/uploads/2022/12/JeanneVillepreux-Power_argonaut_TheMarginalian.jpg?fit=1200%2C630&ssl=1"
        },
        {
          "id": "https://www.synthtopia.com/content/2022/12/27/jean-michel-jarres-classic-oxygene-4-recreated-with-19kb-of-javascript/",
          "author": null,
          "description": "Comments",
          "link": "https://www.synthtopia.com/content/2022/12/27/jean-michel-jarres-classic-oxygene-4-recreated-with-19kb-of-javascript/",
          "publishedOn": "2022-12-28T17:44:07.000Z",
          "wordCount": 1820,
          "title": "Jean-Michel Jarre’s ‘Oxygene 4’ Recreated with 19KB of JavaScript",
          "imageUrl": "https://www.synthtopia.com/wp-content/uploads/2004/01/oxygene-e1485276280658.jpg"
        },
        {
          "id": "https://spectrum.ieee.org/robot-gripper-extrinsic-dexterity",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/robot-gripper-extrinsic-dexterity",
          "publishedOn": "2022-12-28T17:43:28.000Z",
          "wordCount": 11853,
          "title": "Robots Grip Better When They Grip Smarter",
          "imageUrl": "https://spectrum.ieee.org/media-library/animated-gif-of-four-scenes-showing-a-robotic-gripper-pushing-a-different-box-against-a-barrier-to-angle-it-in-order-to-grasp-an.gif?id=32408738&width=1200&height=600&coordinates=270%2C0%2C270%2C0"
        },
        {
          "id": "https://sindresorhus.com/one-thing",
          "author": null,
          "description": "Comments",
          "link": "https://sindresorhus.com/one-thing",
          "publishedOn": "2022-12-28T17:18:52.000Z",
          "wordCount": 999,
          "title": "One Thing – Put a single task or goal in your menu bar",
          "imageUrl": "https://sindresorhus.com/apps/one-thing/icon.png"
        },
        {
          "id": "https://spectrum.ieee.org/rhumatoid-arthritis",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/rhumatoid-arthritis",
          "publishedOn": "2022-12-28T17:18:15.000Z",
          "wordCount": 12552,
          "title": "A new treatment for arthritis: Vagus-nerve stimulation",
          "imageUrl": "https://spectrum.ieee.org/media-library/a-tablet-computer-a-smartphone-a-grey-belt-with-white-stripes-a-grey-disc-and-a-small-silver-rectangle-with-a-wire-curled-be.jpg?id=32333913&width=1200&height=600&coordinates=0%2C356%2C0%2C356"
        },
        {
          "id": "https://research.gatech.edu/cheerful-chatbots-dont-necessarily-improve-customer-service",
          "author": null,
          "description": "Comments",
          "link": "https://research.gatech.edu/cheerful-chatbots-dont-necessarily-improve-customer-service",
          "publishedOn": "2022-12-28T16:50:14.000Z",
          "wordCount": 927,
          "title": "Cheerful chatbots don’t necessarily improve customer service",
          "imageUrl": null
        },
        {
          "id": "https://www.hollywoodreporter.com/tv/tv-news/tv-ratings-explained-where-how-viewers-watch-1235286912/",
          "author": null,
          "description": "Comments",
          "link": "https://www.hollywoodreporter.com/tv/tv-news/tv-ratings-explained-where-how-viewers-watch-1235286912/",
          "publishedOn": "2022-12-28T16:40:04.000Z",
          "wordCount": 10087,
          "title": "TV Ratings Road Map: Where, When and How Viewers Watch in the Streaming Era",
          "imageUrl": "https://www.hollywoodreporter.com/wp-content/uploads/2022/12/2022_12-TVratings_collage-01.jpg?w=1024"
        },
        {
          "id": "https://theovershoot.co/p/inequality-interest-rates-aging-and",
          "author": null,
          "description": "Comments",
          "link": "https://theovershoot.co/p/inequality-interest-rates-aging-and",
          "publishedOn": "2022-12-28T15:56:13.000Z",
          "wordCount": 7615,
          "title": "Inequality, Interest Rates, Aging, and the Role of Central Banks",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F13f5f00e-8f4e-4927-a823-65862ca230e7_3011x1709.png"
        },
        {
          "id": "http://bitsavers.org/pdf/apple/lisa/development_history/articles/IBM_RC8384_Schild_-_PICTUREWORLD_A_Concept_for_Future_Office_Systems_198007.pdf",
          "author": null,
          "description": "Comments",
          "link": "http://bitsavers.org/pdf/apple/lisa/development_history/articles/IBM_RC8384_Schild_-_PICTUREWORLD_A_Concept_for_Future_Office_Systems_198007.pdf",
          "publishedOn": "2022-12-28T15:35:57.000Z",
          "wordCount": 17447,
          "title": "Pictureworld: A Concept for Future Office Systems (1980) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://community.twistedfields.com/t/a-closer-look-at-acorn-our-open-source-precision-farming-rover/108",
          "author": null,
          "description": "Comments",
          "link": "https://community.twistedfields.com/t/a-closer-look-at-acorn-our-open-source-precision-farming-rover/108",
          "publishedOn": "2022-12-28T15:35:36.000Z",
          "wordCount": 1467,
          "title": "Acorn, our open source precision farming rover",
          "imageUrl": "https://community.twistedfields.com/uploads/default/original/1X/6fc1d04a314e1f2faa27f898e7059cd3afabb05f.jpeg"
        },
        {
          "id": "https://blog.galowicz.de/2022/12/28/book-review-algorithms-to-live-by/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.galowicz.de/2022/12/28/book-review-algorithms-to-live-by/",
          "publishedOn": "2022-12-28T15:25:03.000Z",
          "wordCount": 7078,
          "title": "Algorithms to Live By – The Computer Science of Human Decisions",
          "imageUrl": null
        },
        {
          "id": "https://www.stevenbuccini.com/8-hard-truths-on-getting-laid-off",
          "author": null,
          "description": "Comments",
          "link": "https://www.stevenbuccini.com/8-hard-truths-on-getting-laid-off",
          "publishedOn": "2022-12-28T15:21:29.000Z",
          "wordCount": 2719,
          "title": "Hard truths I learned when I got laid off from my SWE job",
          "imageUrl": null
        },
        {
          "id": "https://gist.github.com/sj26/88e1c6584397bb7c13bd11108a579746",
          "author": null,
          "description": "Comments",
          "link": "https://gist.github.com/sj26/88e1c6584397bb7c13bd11108a579746",
          "publishedOn": "2022-12-28T15:07:30.000Z",
          "wordCount": 1396,
          "title": "Bash retry function with exponential backoff",
          "imageUrl": "https://github.githubassets.com/images/modules/gists/gist-og-image.png"
        },
        {
          "id": "https://matt.might.net/articles/26-languages-part1/",
          "author": null,
          "description": "Comments",
          "link": "https://matt.might.net/articles/26-languages-part1/",
          "publishedOn": "2022-12-28T14:44:12.000Z",
          "wordCount": 1844,
          "title": "26 Programming Languages in 25 Days",
          "imageUrl": null
        },
        {
          "id": "https://www.theregister.com/2013/07/16/netware_4_anniversary/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theregister.com/2013/07/16/netware_4_anniversary/",
          "publishedOn": "2022-12-28T14:27:05.000Z",
          "wordCount": 1756,
          "title": "How Novell Netware lost the battle against Windows NT (2013)",
          "imageUrl": null
        },
        {
          "id": "https://glissblog.vercel.app/posts/how-i-found-my-new-house-thru-6-degrees",
          "author": null,
          "description": "Comments",
          "link": "https://glissblog.vercel.app/posts/how-i-found-my-new-house-thru-6-degrees",
          "publishedOn": "2022-12-28T14:08:15.000Z",
          "wordCount": 3351,
          "title": "How I found my house through 6 degrees of separation",
          "imageUrl": null
        },
        {
          "id": "https://www.scypress.com/book_download.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.scypress.com/book_download.html",
          "publishedOn": "2022-12-28T14:05:40.000Z",
          "wordCount": 79,
          "title": "TeXmacs “The Jolly Writer” book is now available as pdf download",
          "imageUrl": null
        },
        {
          "id": "https://www.calculator.net/bra-size-calculator.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.calculator.net/bra-size-calculator.html",
          "publishedOn": "2022-12-28T13:35:36.000Z",
          "wordCount": 973,
          "title": "Bra size calculator",
          "imageUrl": null
        },
        {
          "id": "https://ieeexplore.ieee.org/document/9415699",
          "author": null,
          "description": "Comments",
          "link": "https://ieeexplore.ieee.org/document/9415699",
          "publishedOn": "2022-12-28T12:30:06.000Z",
          "wordCount": 1975,
          "title": "Active ball joint mechanism with 3 DoF based on spherical gear meshings (2021)",
          "imageUrl": "https://ieeexplore.ieee.org/assets/img/ieee_logo_smedia_200X200.png"
        },
        {
          "id": "https://www.getlazarus.org/guides/intro/",
          "author": null,
          "description": "Comments",
          "link": "https://www.getlazarus.org/guides/intro/",
          "publishedOn": "2022-12-28T11:53:32.000Z",
          "wordCount": 2162,
          "title": "A guided intro to the Free Pascal language",
          "imageUrl": null
        },
        {
          "id": "https://downrightnifty.me/blog/2022/12/26/hacking-google-home.html",
          "author": null,
          "description": "Comments",
          "link": "https://downrightnifty.me/blog/2022/12/26/hacking-google-home.html",
          "publishedOn": "2022-12-28T11:19:45.000Z",
          "wordCount": 8025,
          "title": "Wiretapping Google smart speakers",
          "imageUrl": null
        },
        {
          "id": "https://cohost.org/offset---cyan/post/728975-the-zen-of-forth",
          "author": null,
          "description": "Comments",
          "link": "https://cohost.org/offset---cyan/post/728975-the-zen-of-forth",
          "publishedOn": "2022-12-28T06:52:30.000Z",
          "wordCount": 6406,
          "title": "The Zen of Forth",
          "imageUrl": "https://staging.cohostcdn.org/avatar/35784-3580bc03-1dad-4f1e-9c85-955031865239-profile.jpg"
        },
        {
          "id": "https://www.theverge.com/2022/12/27/23523281/excel-formula-suggestions-by-example-microsoft-365",
          "author": null,
          "description": "Comments",
          "link": "https://www.theverge.com/2022/12/27/23523281/excel-formula-suggestions-by-example-microsoft-365",
          "publishedOn": "2022-12-28T06:25:02.000Z",
          "wordCount": 9214,
          "title": "Microsoft is making Excel’s formulas easier",
          "imageUrl": "https://cdn.vox-cdn.com/thumbor/2LpcEUR9vxFA_n_aNZ-N_tTvOps=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24038601/acastro_STK109_microsoft_02.jpg"
        },
        {
          "id": "https://canarytokens.org/generate",
          "author": null,
          "description": "Comments",
          "link": "https://canarytokens.org/generate",
          "publishedOn": "2022-12-28T05:13:23.000Z",
          "wordCount": 3968,
          "title": "Canary Tokens",
          "imageUrl": "https://canary.tools/static/images/ico_canary.png"
        },
        {
          "id": "https://drew.shoes/posts/sup/",
          "author": null,
          "description": "Comments",
          "link": "https://drew.shoes/posts/sup/",
          "publishedOn": "2022-12-28T04:47:07.000Z",
          "wordCount": 1725,
          "title": "Saying “sup” with `net send`",
          "imageUrl": null
        },
        {
          "id": "https://lareviewofbooks.org/article/what-is-the-secret-of-chernivtsi-a-conversation-with-igor-pomerantsev/",
          "author": null,
          "description": "Comments",
          "link": "https://lareviewofbooks.org/article/what-is-the-secret-of-chernivtsi-a-conversation-with-igor-pomerantsev/",
          "publishedOn": "2022-12-28T02:37:12.000Z",
          "wordCount": 6285,
          "title": "What Is the Secret of Chernivtsi?: A Conversation with Ihor Pomerantsev",
          "imageUrl": "https://dev.lareviewofbooks.org/wp-content/uploads/2022/12/Black-and-White-scaled-e1671705830689.jpg"
        },
        {
          "id": "https://asia.nikkei.com/Business/Retail/Apple-Japan-hit-with-98m-in-back-taxes-for-missing-duty-free-abuses",
          "author": null,
          "description": "Comments",
          "link": "https://asia.nikkei.com/Business/Retail/Apple-Japan-hit-with-98m-in-back-taxes-for-missing-duty-free-abuses",
          "publishedOn": "2022-12-28T01:10:11.000Z",
          "wordCount": 2410,
          "title": "Apple Japan hit with $98M in back taxes for missing duty-free abuses",
          "imageUrl": "https://www.ft.com/__origami/service/image/v2/images/raw/https%253A%252F%252Fs3-ap-northeast-1.amazonaws.com%252Fpsh-ex-ftnikkei-3937bb4%252Fimages%252F2%252F4%252F8%252F3%252F43693842-5-eng-GB%252FGettyImages-1445281555_2048x1152.jpg?width=1260&height=630&fit=cover&gravity=faces&source=nar-cms"
        },
        {
          "id": "https://techxplore.com/news/2022-12-ethylene-carbonate-solvent-sodium-iodide.html",
          "author": null,
          "description": "Comments",
          "link": "https://techxplore.com/news/2022-12-ethylene-carbonate-solvent-sodium-iodide.html",
          "publishedOn": "2022-12-28T01:08:36.000Z",
          "wordCount": 1805,
          "title": "Ethylene carbonate solvent with a sodium iodide salt create a new refrigerator",
          "imageUrl": "https://scx2.b-cdn.net/gfx/news/2022/using-an-ethylene-carb.jpg"
        },
        {
          "id": "https://mjtsai.com/blog/2022/12/27/ventura-issues/",
          "author": null,
          "description": "Comments",
          "link": "https://mjtsai.com/blog/2022/12/27/ventura-issues/",
          "publishedOn": "2022-12-28T00:27:45.000Z",
          "wordCount": 1088,
          "title": "Ventura Issues",
          "imageUrl": null
        },
        {
          "id": "https://spectrum.ieee.org/satellite-cellphone",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/satellite-cellphone",
          "publishedOn": "2022-12-28T00:16:58.000Z",
          "wordCount": 11526,
          "title": "Your Cellphone Will Be a Satphone",
          "imageUrl": "https://spectrum.ieee.org/media-library/a-3d-rendering-of-a-large-flat-satellite-orbiting-the-earth-with-the-sun-rising-over-the-horizon-behind-it.jpg?id=32315788&width=1200&height=600&coordinates=0%2C347%2C0%2C348"
        },
        {
          "id": "https://www.theguardian.com/technology/2022/dec/27/tesla-stock-drops-lowest-close-years-elon-musk",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/technology/2022/dec/27/tesla-stock-drops-lowest-close-years-elon-musk",
          "publishedOn": "2022-12-27T23:54:44.000Z",
          "wordCount": 4611,
          "title": "Tesla stock marks lowest close in years as investors worry about Musk’s focus",
          "imageUrl": "https://i.guim.co.uk/img/media/252928c334015f4f0fd5283d886781bf217b0660/958_300_2542_1526/master/2542.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=3b83d65f7ff191bfb2662f9d150cc9f9"
        },
        {
          "id": "https://official.resource.org/@carlmalamud/109582097911957160",
          "author": null,
          "description": "Comments",
          "link": "https://official.resource.org/@carlmalamud/109582097911957160",
          "publishedOn": "2022-12-27T22:58:47.000Z",
          "wordCount": 113,
          "title": "Added 49 volumes of Arkansas, Mississippi, and Tennessee law",
          "imageUrl": "https://official.resource.org/system/accounts/avatars/109/378/860/290/523/001/original/d0d24fe3fda44dff.jpg"
        },
        {
          "id": "https://github.com/beakerbrowser/beaker/blob/master/archive-notice.md",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/beakerbrowser/beaker/blob/master/archive-notice.md",
          "publishedOn": "2022-12-27T22:47:32.000Z",
          "wordCount": 3318,
          "title": "Beaker Browser is now archived",
          "imageUrl": "https://repository-images.githubusercontent.com/59700207/36753380-8f8e-11ea-81f4-64876855abbb"
        },
        {
          "id": "https://www.smithsonianmag.com/smart-news/30000-year-old-indigenous-cave-drawings-in-australia-have-been-destroyed-180981363/",
          "author": null,
          "description": "Comments",
          "link": "https://www.smithsonianmag.com/smart-news/30000-year-old-indigenous-cave-drawings-in-australia-have-been-destroyed-180981363/",
          "publishedOn": "2022-12-27T22:33:20.000Z",
          "wordCount": 1638,
          "title": "Vandals destroy 30k-year-old indigenous cave drawings in Australia",
          "imageUrl": "https://th-thumbnailer.cdn-si-edu.com/IfQrtQK0F8tAwADSmHzUE2ZIKvM=/fit-in/1600x0/filters:focal(512x512:513x513)/https%3A%2F%2Ftf-cmsv2-smithsonianmag-media.s3.amazonaws.com%2Ffiler_public%2F84%2F2e%2F842e6054-aaa8-41d6-8445-b2075199884e%2F2160-1024x1024.jpg"
        },
        {
          "id": "https://danielmangum.com/posts/risc-v-bytes-timer-interrupts/",
          "author": null,
          "description": "Comments",
          "link": "https://danielmangum.com/posts/risc-v-bytes-timer-interrupts/",
          "publishedOn": "2022-12-27T21:56:48.000Z",
          "wordCount": 4292,
          "title": "How RISC-V Timer Interrupts Work",
          "imageUrl": null
        },
        {
          "id": "https://notepadcalculator.com/",
          "author": null,
          "description": "Comments",
          "link": "https://notepadcalculator.com/",
          "publishedOn": "2022-12-27T21:13:15.000Z",
          "wordCount": 26,
          "title": "Notepad Calculator",
          "imageUrl": null
        },
        {
          "id": "https://www.brooklynbarmenus.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.brooklynbarmenus.com/",
          "publishedOn": "2022-12-27T20:53:15.000Z",
          "wordCount": 306,
          "title": "Brooklyn Bar Menu Generator (2015)",
          "imageUrl": null
        },
        {
          "id": "https://infosec.exchange/@briankrebs/109587022002246891",
          "author": null,
          "description": "Comments",
          "link": "https://infosec.exchange/@briankrebs/109587022002246891",
          "publishedOn": "2022-12-27T19:54:03.000Z",
          "wordCount": 119,
          "title": "Experian Vulnerability Shows Any Report with just SSN, DOB, ADR",
          "imageUrl": "https://media.infosec.exchange/infosecmedia/accounts/avatars/109/292/943/884/713/975/original/aad1b6c1f00ab8ef.png"
        },
        {
          "id": "https://sloanreview.mit.edu/article/when-algorithms-rule-values-can-wither/",
          "author": null,
          "description": "Comments",
          "link": "https://sloanreview.mit.edu/article/when-algorithms-rule-values-can-wither/",
          "publishedOn": "2022-12-27T19:53:49.000Z",
          "wordCount": 2486,
          "title": "When Algorithms Rule, Values Can Wither",
          "imageUrl": "https://sloanreview.mit.edu/wp-content/uploads/2022/10/WINTER22-Lindebaum-2400x1260-1-1200x630.jpg"
        },
        {
          "id": "https://www.borgbackup.org/",
          "author": null,
          "description": "Comments",
          "link": "https://www.borgbackup.org/",
          "publishedOn": "2022-12-27T19:01:48.000Z",
          "wordCount": 2046,
          "title": "BorgBackup: Deduplicating archiver with compression and encryption",
          "imageUrl": null
        },
        {
          "id": "http://bitsavers.org/pdf/apple/lisa/development_history/articles/Daniels_-_The_Architecture_of_the_Lisa_Personal_Computer_198403.pdf",
          "author": null,
          "description": "Comments",
          "link": "http://bitsavers.org/pdf/apple/lisa/development_history/articles/Daniels_-_The_Architecture_of_the_Lisa_Personal_Computer_198403.pdf",
          "publishedOn": "2022-12-27T18:59:11.000Z",
          "wordCount": 23096,
          "title": "The Architecture of the Lisa Personal Computer (1984) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://lite-xl.com/",
          "author": null,
          "description": "Comments",
          "link": "https://lite-xl.com/",
          "publishedOn": "2022-12-27T18:46:12.000Z",
          "wordCount": 56,
          "title": "Lite XL: A lightweight text editor written in C and Lua",
          "imageUrl": null
        },
        {
          "id": "https://www.juliensobczak.com/inspect/2022/05/30/anki-srs.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.juliensobczak.com/inspect/2022/05/30/anki-srs.html",
          "publishedOn": "2022-12-27T18:43:59.000Z",
          "wordCount": 8575,
          "title": "Anki SRS Algorithm : Spaced repetition explained with code",
          "imageUrl": null
        },
        {
          "id": "https://scottaaronson.blog/?p=5359",
          "author": null,
          "description": "Comments",
          "link": "https://scottaaronson.blog/?p=5359",
          "publishedOn": "2022-12-27T18:33:33.000Z",
          "wordCount": 58118,
          "title": "The Zen anti-interpretation of quantum mechanics (2021)",
          "imageUrl": "https://149663533.v2.pressablecdn.com/wp-content/uploads/2021/10/cropped-Jacket.gif"
        },
        {
          "id": "https://www.science.org/content/blog-post/acid-personalities",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/content/blog-post/acid-personalities",
          "publishedOn": "2022-12-27T18:27:45.000Z",
          "wordCount": 1916,
          "title": "Hydrochloric acid is more complicated than you think",
          "imageUrl": "https://www.science.org/pb-assets/images/blogs/pipeline/default-image-1644619966880.png"
        },
        {
          "id": "https://hackaday.com/2022/12/27/all-about-usb-c-illegal-adapters/",
          "author": null,
          "description": "Comments",
          "link": "https://hackaday.com/2022/12/27/all-about-usb-c-illegal-adapters/",
          "publishedOn": "2022-12-27T18:14:56.000Z",
          "wordCount": 10418,
          "title": "All About USB-C: Illegal Adapters",
          "imageUrl": "https://hackaday.com/wp-content/uploads/2020/06/USBC.jpg"
        },
        {
          "id": "https://digit.so36.net/Data/20221227_HIP_EBSP_IBIS.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://digit.so36.net/Data/20221227_HIP_EBSP_IBIS.pdf",
          "publishedOn": "2022-12-27T17:51:19.000Z",
          "wordCount": 31091,
          "title": "US Government demands direct police access to European biometric data [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://en.wikipedia.org/wiki/Hogmanay",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/Hogmanay",
          "publishedOn": "2022-12-27T17:44:14.000Z",
          "wordCount": 5296,
          "title": "Hogmanay",
          "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/EdinburghNYE.jpg/1200px-EdinburghNYE.jpg"
        },
        {
          "id": "https://coroot.com/blog/minimizing-observability-tax",
          "author": null,
          "description": "Comments",
          "link": "https://coroot.com/blog/minimizing-observability-tax",
          "publishedOn": "2022-12-27T16:02:49.000Z",
          "wordCount": 1585,
          "title": "Using eBPF and predefined inspections to minimize “observability tax”",
          "imageUrl": "https://coroot.com/static/img/blog/observability-tax/teaser.png"
        },
        {
          "id": "https://www.npr.org/2022/12/26/1145536902/southwest-flight-cancellations-winter-storm",
          "author": null,
          "description": "Comments",
          "link": "https://www.npr.org/2022/12/26/1145536902/southwest-flight-cancellations-winter-storm",
          "publishedOn": "2022-12-27T15:13:13.000Z",
          "wordCount": 1511,
          "title": "Southwest cancels 5,400 flights in less than 48 hours",
          "imageUrl": "https://media.npr.org/assets/img/2022/12/27/ap22361049881597_wide-0e829d614411e16f2bb810088c1cb580a0887b39-s1400-c100.jpg"
        },
        {
          "id": "https://www.johndcook.com/blog/2022/12/27/visually-symmetric-words/",
          "author": null,
          "description": "Comments",
          "link": "https://www.johndcook.com/blog/2022/12/27/visually-symmetric-words/",
          "publishedOn": "2022-12-27T15:02:17.000Z",
          "wordCount": 1687,
          "title": "Visually symmetric words",
          "imageUrl": null
        },
        {
          "id": "https://github.com/microfeed/microfeed",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/microfeed/microfeed",
          "publishedOn": "2022-12-27T11:42:00.000Z",
          "wordCount": 2530,
          "title": "Show HN: Self-hosted CMS on serverless Cloudflare",
          "imageUrl": "https://repository-images.githubusercontent.com/266677657/b8b62eb5-5d1c-4950-82c9-cf7abc4c48a7"
        },
        {
          "id": "https://dogapi.dog/",
          "author": null,
          "description": "Comments",
          "link": "https://dogapi.dog/",
          "publishedOn": "2022-12-27T10:23:03.000Z",
          "wordCount": 290,
          "title": "Show HN: Dog API",
          "imageUrl": "https://dogapi.dog/assets/social-b1f7d983a34ffe8d424d7272e675e139184a7285f85d1163614c61d7228a38d6.jpg"
        },
        {
          "id": "https://www.nature.com/articles/d41586-021-01431-y",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/articles/d41586-021-01431-y",
          "publishedOn": "2022-12-27T08:16:45.000Z",
          "wordCount": 4161,
          "title": "Old-school computing: when your lab PC is ancient (2021)",
          "imageUrl": "https://media.nature.com/lw1024/magazine-assets/d41586-021-01431-y/d41586-021-01431-y_19198634.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34146397",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34146397",
          "publishedOn": "2022-12-27T08:04:56.000Z",
          "wordCount": 3234,
          "title": "Ask HN: Elevator Pitch for a Polymath?",
          "imageUrl": null
        },
        {
          "id": "https://partytown.builder.io/",
          "author": null,
          "description": "Comments",
          "link": "https://partytown.builder.io/",
          "publishedOn": "2022-12-27T06:29:43.000Z",
          "wordCount": 1081,
          "title": "Run Third-Party Scripts from a Web Worker",
          "imageUrl": "https://partytown.builder.io/partytown-media.png"
        },
        {
          "id": "https://coreform.com/",
          "author": null,
          "description": "Comments",
          "link": "https://coreform.com/",
          "publishedOn": "2022-12-27T06:03:28.000Z",
          "wordCount": 332,
          "title": "FEA Solver that doesn't need defeaturing",
          "imageUrl": "https://coreform.com/images/coreform-logo-transparent.png"
        },
        {
          "id": "https://www.onxmaps.com/onx-access-initiatives/corner-crossing-report",
          "author": null,
          "description": "Comments",
          "link": "https://www.onxmaps.com/onx-access-initiatives/corner-crossing-report",
          "publishedOn": "2022-12-27T00:11:58.000Z",
          "wordCount": 4722,
          "title": "6M Acres of Public Land in the US West Are Corner-Locked",
          "imageUrl": "https://www.onxmaps.com/wp-content/uploads/sites/1/2022/04/Corner-locked_Featured.jpg"
        },
        {
          "id": "https://observablehq.com/@mjbo/sydney-qms-panel-public-telephone-pairings",
          "author": null,
          "description": "Comments",
          "link": "https://observablehq.com/@mjbo/sydney-qms-panel-public-telephone-pairings",
          "publishedOn": "2022-12-26T23:57:37.000Z",
          "wordCount": 1745,
          "title": "Show HN: How many advertising panels in Sydney are near a public telephone?",
          "imageUrl": "https://static.observableusercontent.com/thumbnail/87edbb3b0bdba52d702d742dbf078f571acd6c6eb9f84edc542c5cdc53024842.jpg"
        },
        {
          "id": "https://www.nytimes.com/2022/12/20/science/archaeology-bible-geomagnetism.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/20/science/archaeology-bible-geomagnetism.html",
          "publishedOn": "2022-12-26T23:56:38.000Z",
          "wordCount": 5419,
          "title": "Archaeologists devise a better clock for Biblical times",
          "imageUrl": "https://static01.nyt.com/images/2022/11/28/science/00SCI-BIBLIOARCHAEO-04/00SCI-BIBLIOARCHAEO-04-facebookJumbo.jpg"
        },
        {
          "id": "https://www.tomshardware.com/news/windows-7-runs-at-5-mhz",
          "author": null,
          "description": "Comments",
          "link": "https://www.tomshardware.com/news/windows-7-runs-at-5-mhz",
          "publishedOn": "2022-12-26T23:43:09.000Z",
          "wordCount": 11850,
          "title": "Running Windows 7 on a 5 MHz CPU with 128MB of RAM",
          "imageUrl": "https://cdn.mos.cms.futurecdn.net/FB3eHhdvh55CDVGyH5NTDd-1200-80.png"
        },
        {
          "id": "https://www.rigsofrods.org/",
          "author": null,
          "description": "Comments",
          "link": "https://www.rigsofrods.org/",
          "publishedOn": "2022-12-26T23:32:51.000Z",
          "wordCount": 15,
          "title": "Rigs of Rods: free and open source vehicle simulator that uses soft-body physics",
          "imageUrl": "https://cdn.rigsofrods.org/data/assets/og/RoR_2021_02.png"
        },
        {
          "id": "https://memex.marginalia.nu/log/69-creepy-website-similarity.gmi",
          "author": null,
          "description": "Comments",
          "link": "https://memex.marginalia.nu/log/69-creepy-website-similarity.gmi",
          "publishedOn": "2022-12-26T23:30:41.000Z",
          "wordCount": 990,
          "title": "Creepy Website Similarity",
          "imageUrl": null
        },
        {
          "id": "https://github.com/corkami/pics/blob/master/binary/README.md",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/corkami/pics/blob/master/binary/README.md",
          "publishedOn": "2022-12-26T22:04:33.000Z",
          "wordCount": 532,
          "title": "Binary Posters",
          "imageUrl": "https://opengraph.githubassets.com/32281e1a3f8f4b05aaf659ba6954ea23dacc69787003198b6272c3f79fa92339/corkami/pics"
        },
        {
          "id": "https://jasmcole.com/2022/02/10/losing-it/",
          "author": null,
          "description": "Comments",
          "link": "https://jasmcole.com/2022/02/10/losing-it/",
          "publishedOn": "2022-12-26T21:39:53.000Z",
          "wordCount": 3298,
          "title": "Are You Really Losing Weight?",
          "imageUrl": "https://jasmcole.files.wordpress.com/2022/02/theory-2-2.png"
        },
        {
          "id": "https://alexsidorenko.com/blog/useeffect/",
          "author": null,
          "description": "Comments",
          "link": "https://alexsidorenko.com/blog/useeffect/",
          "publishedOn": "2022-12-26T21:37:47.000Z",
          "wordCount": 977,
          "title": "A Visual Guide to React's useEffect",
          "imageUrl": "https://alexsidorenko.com/og/useeffect.png"
        },
        {
          "id": "https://www.battlefields.org/learn/articles/how-france-helped-win-american-revolution",
          "author": null,
          "description": "Comments",
          "link": "https://www.battlefields.org/learn/articles/how-france-helped-win-american-revolution",
          "publishedOn": "2022-12-26T21:34:27.000Z",
          "wordCount": 3249,
          "title": "The Tipping Point: How France Changed the Tides of the American Revolution",
          "imageUrl": "https://www.battlefields.org/sites/default/files/styles/social_media/public/master-pnp-pga-01500-01591u.jpg?h=e7ec504f&itok=JU8TAMQ9"
        },
        {
          "id": "https://github.com/rui314/mold/releases/tag/v1.8.0",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/rui314/mold/releases/tag/v1.8.0",
          "publishedOn": "2022-12-26T21:09:11.000Z",
          "wordCount": 1063,
          "title": "Mold linker: targeting macOS/iOS now requires a commercial license",
          "imageUrl": "https://opengraph.githubassets.com/5c601150ca3991d722be664c3ce68bcdadaa5364c0843cfc1eefa5d02d32cc81/rui314/mold/releases/tag/v1.8.0"
        },
        {
          "id": "https://www.eseller365.com/ebay-etsy-inform-act-hidden-spending-bill/",
          "author": null,
          "description": "Comments",
          "link": "https://www.eseller365.com/ebay-etsy-inform-act-hidden-spending-bill/",
          "publishedOn": "2022-12-26T20:38:19.000Z",
          "wordCount": 5438,
          "title": "eBay, Etsy and other marketplaces on brink of having to disclose seller details",
          "imageUrl": "https://www.eseller365.com/wp-content/uploads/2022/12/stack-legislation-inform-act.jpg"
        },
        {
          "id": "https://medium.com/@AnalyticsAtMeta/notifications-why-less-is-more-how-facebook-has-been-increasing-both-user-satisfaction-and-app-9463f7325e7d",
          "author": null,
          "description": "Comments",
          "link": "https://medium.com/@AnalyticsAtMeta/notifications-why-less-is-more-how-facebook-has-been-increasing-both-user-satisfaction-and-app-9463f7325e7d",
          "publishedOn": "2022-12-26T18:54:34.000Z",
          "wordCount": 4333,
          "title": "Facebook increased satisfaction and usage by sending fewer notifications",
          "imageUrl": "https://miro.medium.com/max/960/1*VswDJMSLW4hgFz-0r0rvQg.png"
        },
        {
          "id": "https://dioxuslabs.com/",
          "author": null,
          "description": "Comments",
          "link": "https://dioxuslabs.com/",
          "publishedOn": "2022-12-26T18:16:46.000Z",
          "wordCount": 155,
          "title": "Dioxus: User interfaces that run anywhere",
          "imageUrl": "https://dioxuslabs.com/static/opengraph.png"
        },
        {
          "id": "https://www.cryptomuseum.com/spy/ddr2/index.htm",
          "author": null,
          "description": "Comments",
          "link": "https://www.cryptomuseum.com/spy/ddr2/index.htm",
          "publishedOn": "2022-12-26T18:02:04.000Z",
          "wordCount": 5746,
          "title": "DDR Type 2 – Short-wave spy transmitter",
          "imageUrl": null
        },
        {
          "id": "https://www.aneventapart.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.aneventapart.com/",
          "publishedOn": "2022-12-26T17:55:58.000Z",
          "wordCount": 335,
          "title": "An Event Apart – Farewell",
          "imageUrl": ""
        },
        {
          "id": "https://github.com/wanjohiryan/qwantify",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/wanjohiryan/qwantify",
          "publishedOn": "2022-12-26T16:45:20.000Z",
          "wordCount": 1190,
          "title": "Qwantify",
          "imageUrl": "https://opengraph.githubassets.com/4e0652eb2c84a60a11b141fac647c3176e0c2245e22747012166007fc4399320/wanjohiryan/qwantify"
        },
        {
          "id": "https://fediscience.org/@ct_bergstrom/109571409346371116",
          "author": null,
          "description": "Comments",
          "link": "https://fediscience.org/@ct_bergstrom/109571409346371116",
          "publishedOn": "2022-12-26T16:27:11.000Z",
          "wordCount": 116,
          "title": "How to Befriend Crows",
          "imageUrl": "https://fediscience.org/system/media_attachments/files/109/571/407/059/801/478/original/25ae1523bb9dba68.jpeg"
        },
        {
          "id": "https://www.aljazeera.com/news/2022/12/26/inside-the-library-where-you-can-read-in-two-countries-at-once",
          "author": null,
          "description": "Comments",
          "link": "https://www.aljazeera.com/news/2022/12/26/inside-the-library-where-you-can-read-in-two-countries-at-once",
          "publishedOn": "2022-12-26T16:12:10.000Z",
          "wordCount": 1891,
          "title": "The US-Canada border cuts through the Haskell Free Library and Opera House",
          "imageUrl": "https://www.aljazeera.com/wp-content/uploads/2022/12/PXL_20221213_154814675.jpg?resize=1920%2C1440"
        },
        {
          "id": "https://www.bath.ac.uk/announcements/social-media-may-prevent-users-from-reaping-creative-rewards-of-profound-boredom-new-research/",
          "author": null,
          "description": "Comments",
          "link": "https://www.bath.ac.uk/announcements/social-media-may-prevent-users-from-reaping-creative-rewards-of-profound-boredom-new-research/",
          "publishedOn": "2022-12-26T15:10:52.000Z",
          "wordCount": 853,
          "title": "Social media may prevent users from reaping creative rewards of profound boredom",
          "imageUrl": null
        },
        {
          "id": "https://arstechnica.com/gadgets/2022/10/windows-95-went-the-extra-mile-to-ensure-compatibility-of-simcity-other-games/",
          "author": null,
          "description": "Comments",
          "link": "https://arstechnica.com/gadgets/2022/10/windows-95-went-the-extra-mile-to-ensure-compatibility-of-simcity-other-games/",
          "publishedOn": "2022-12-26T14:53:04.000Z",
          "wordCount": 1999,
          "title": "Windows 95 went the extra mile to ensure compatibility of SimCity, other games",
          "imageUrl": "https://cdn.arstechnica.net/wp-content/uploads/2022/10/8350168815_dd3c4cb302_o-760x380.jpg"
        },
        {
          "id": "https://borretti.me/article/unbundling-tools-for-thought",
          "author": null,
          "description": "Comments",
          "link": "https://borretti.me/article/unbundling-tools-for-thought",
          "publishedOn": "2022-12-26T14:17:24.000Z",
          "wordCount": 3383,
          "title": "Unbundling Tools for Thought",
          "imageUrl": "https://borretti.me/assets/card/unbundling-tools-for-thought.png"
        },
        {
          "id": "https://hyperview.org/",
          "author": null,
          "description": "Comments",
          "link": "https://hyperview.org/",
          "publishedOn": "2022-12-26T13:17:13.000Z",
          "wordCount": 339,
          "title": "Hyperview: Native mobile apps, as easy as creating a website",
          "imageUrl": "https://hyperview.org/img/icon.png"
        },
        {
          "id": "http://web.archive.org/web/20200217014004/https://www.aaxnet.com/design/novell.html",
          "author": null,
          "description": "Comments",
          "link": "http://web.archive.org/web/20200217014004/https://www.aaxnet.com/design/novell.html",
          "publishedOn": "2022-12-26T12:25:05.000Z",
          "wordCount": 1264,
          "title": "Novell NetWare: The King Returns from the Dead (2001)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/leandromoreira/cdn-up-and-running",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/leandromoreira/cdn-up-and-running",
          "publishedOn": "2022-12-26T12:17:38.000Z",
          "wordCount": 5165,
          "title": "Writing a Mini-CDN to Learn Nginx/Prometheus/Grafana/Lua",
          "imageUrl": "https://opengraph.githubassets.com/c8f4708039c6d81917a5362e6bf8a511b137f210d684a9d742e5961de9e5d7cb/leandromoreira/cdn-up-and-running"
        },
        {
          "id": "https://arxiv.org/abs/2211.13224",
          "author": null,
          "description": "Comments",
          "link": "https://arxiv.org/abs/2211.13224",
          "publishedOn": "2022-12-26T11:45:30.000Z",
          "wordCount": 640,
          "title": "Peekaboo: Text to Image Diffusion Models Are Zero-Shot Segmentors",
          "imageUrl": null
        },
        {
          "id": "https://www.subanima.org/bees/",
          "author": null,
          "description": "Comments",
          "link": "https://www.subanima.org/bees/",
          "publishedOn": "2022-12-26T11:20:12.000Z",
          "wordCount": 3872,
          "title": "Why do bees die when they sting you?",
          "imageUrl": "https://www.subanima.org/content/images/2021/11/beedead.png"
        },
        {
          "id": "https://en.wikipedia.org/wiki/M%C3%A9nage_problem",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/M%C3%A9nage_problem",
          "publishedOn": "2022-12-26T07:47:58.000Z",
          "wordCount": 2492,
          "title": "Ménage Problem",
          "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Wedding_Banquet_setting.jpeg/1200px-Wedding_Banquet_setting.jpeg"
        },
        {
          "id": "https://twitter.com/vinciusmedeiro6/status/1607187382335324162",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/vinciusmedeiro6/status/1607187382335324162",
          "publishedOn": "2022-12-26T07:38:31.000Z",
          "wordCount": 470,
          "title": "Leak of a cancelled 1996 “Duke Nukem Forever” side-scroller",
          "imageUrl": null
        },
        {
          "id": "https://www.choctawnation.com/about/history/irish-connection/",
          "author": null,
          "description": "Comments",
          "link": "https://www.choctawnation.com/about/history/irish-connection/",
          "publishedOn": "2022-12-26T06:08:19.000Z",
          "wordCount": 1497,
          "title": "Choctaw and Irish History",
          "imageUrl": "https://www.choctawnation.com/wp-content/uploads/2022/01/011922kindred-spirits.jpg"
        },
        {
          "id": "http://amasci.com/amateur/holo1.html",
          "author": null,
          "description": "Comments",
          "link": "http://amasci.com/amateur/holo1.html",
          "publishedOn": "2022-12-25T23:58:11.000Z",
          "wordCount": 3047,
          "title": "Holography without Lasers: Hand-drawn Holograms (1999)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/LemonHaze420/DCPopulous",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/LemonHaze420/DCPopulous",
          "publishedOn": "2022-12-25T23:08:48.000Z",
          "wordCount": 574,
          "title": "Source Code for Populous for Windows CE / Dreamcast Released",
          "imageUrl": "https://opengraph.githubassets.com/be2214ccd9be15f1f8816b98cf4aecedd4cbf60310d39073bacfc61d3c7b6bf1/LemonHaze420/DCPopulous"
        },
        {
          "id": "https://spectrum.ieee.org/green-hydrogen",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/green-hydrogen",
          "publishedOn": "2022-12-25T22:56:19.000Z",
          "wordCount": 13016,
          "title": "Green hydrogen is the centerpiece of Australia’s clean-economy growth plan",
          "imageUrl": "https://spectrum.ieee.org/media-library/an-aerial-photo-shows-a-large-solar-photovoltaic-generating-plant.jpg?id=32333508&width=1200&height=600&coordinates=0%2C180%2C0%2C180"
        },
        {
          "id": "https://twitter.com/thefireorg/status/1606010943309336576",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/thefireorg/status/1606010943309336576",
          "publishedOn": "2022-12-25T22:28:18.000Z",
          "wordCount": 470,
          "title": "MIT Faculty Votes for Statement on Freedom of Expression and Academic Freedom",
          "imageUrl": null
        },
        {
          "id": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001918",
          "author": null,
          "description": "Comments",
          "link": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001918",
          "publishedOn": "2022-12-25T21:41:42.000Z",
          "wordCount": 3527,
          "title": "The antimicrobial resistance crisis needs action now",
          "imageUrl": null
        },
        {
          "id": "https://iai.tv/articles/all-knowing-machines-are-a-fantasy-auid-2334",
          "author": null,
          "description": "Comments",
          "link": "https://iai.tv/articles/all-knowing-machines-are-a-fantasy-auid-2334",
          "publishedOn": "2022-12-25T21:31:42.000Z",
          "wordCount": 1546,
          "title": "AI chatbots are not a replacement for search engines",
          "imageUrl": "https://iai.tv/assets/Uploads/_resampled/FillWyI4MDAiLCI1MDAiXQ/All-knowing-machines-are-a-fantasy.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34131436",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34131436",
          "publishedOn": "2022-12-25T21:21:54.000Z",
          "wordCount": 2244,
          "title": "Ask HN: Has anyone successfully recovered photos from a broken Android phone?",
          "imageUrl": null
        },
        {
          "id": "https://www.lockedinspace.com/posts/001.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.lockedinspace.com/posts/001.html",
          "publishedOn": "2022-12-25T21:13:51.000Z",
          "wordCount": 684,
          "title": "General guidance when working as a cloud engineer",
          "imageUrl": null
        },
        {
          "id": "https://onesignal.com/careers/4004532006",
          "author": null,
          "description": "Comments",
          "link": "https://onesignal.com/careers/4004532006",
          "publishedOn": "2022-12-25T21:02:03.000Z",
          "wordCount": 385,
          "title": "OneSignal (YC S11) Is Hiring a Head of Developer Relations",
          "imageUrl": "https://media.onesignal.com/cms/_1200x630_crop_center-center_82_none/onesignal.jpg?mtime=1666043174"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34130767",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34130767",
          "publishedOn": "2022-12-25T20:12:19.000Z",
          "wordCount": 3684,
          "title": "Ask HN: What is your favorite front end state management solution?",
          "imageUrl": null
        },
        {
          "id": "https://kk.org/thetechnium/1000-true-fans/",
          "author": null,
          "description": "Comments",
          "link": "https://kk.org/thetechnium/1000-true-fans/",
          "publishedOn": "2022-12-25T20:06:48.000Z",
          "wordCount": 4722,
          "title": "1k True Fans (2008)",
          "imageUrl": "https://kk.org/wp-content/themes/kkdotorg/inc/images/og_default_1200.png"
        },
        {
          "id": "https://shyim.me/blog/devenv-compose-developer-environment-for-php-with-nix/",
          "author": null,
          "description": "Comments",
          "link": "https://shyim.me/blog/devenv-compose-developer-environment-for-php-with-nix/",
          "publishedOn": "2022-12-25T19:53:19.000Z",
          "wordCount": 3756,
          "title": "Devenv: Compose a Developer Environment Easily for PHP with Nix",
          "imageUrl": "https://avatars.githubusercontent.com/u/6224096?v=4?s=400"
        },
        {
          "id": "https://blog.nuclearsecrecy.com/2022/12/21/oppenheimer-vacated-but-not-vindicated/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.nuclearsecrecy.com/2022/12/21/oppenheimer-vacated-but-not-vindicated/",
          "publishedOn": "2022-12-25T18:46:23.000Z",
          "wordCount": 3861,
          "title": "Oppenheimer: Vacated but Not Vindicated",
          "imageUrl": "https://blog.nuclearsecrecy.com/wp-content/uploads/2022/12/1954-Oppenheimer-TIME-large-face.jpg"
        },
        {
          "id": "https://lwn.net/Articles/917280/",
          "author": null,
          "description": "Comments",
          "link": "https://lwn.net/Articles/917280/",
          "publishedOn": "2022-12-25T17:18:41.000Z",
          "wordCount": 3172,
          "title": "The return of lazy imports for Python",
          "imageUrl": null
        },
        {
          "id": "https://github.com/below/HelloSilicon",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/below/HelloSilicon",
          "publishedOn": "2022-12-25T17:01:10.000Z",
          "wordCount": 4366,
          "title": "HelloSilicon – An introduction to assembly on Apple Silicon Macs",
          "imageUrl": "https://repository-images.githubusercontent.com/276852180/16c87c7a-acc1-4426-8b29-365e4c8f6d6d"
        },
        {
          "id": "https://8bitworkshop.com/docs/posts/2022/happy-holidays-2022.html",
          "author": null,
          "description": "Comments",
          "link": "https://8bitworkshop.com/docs/posts/2022/happy-holidays-2022.html",
          "publishedOn": "2022-12-25T15:42:05.000Z",
          "wordCount": 986,
          "title": "Atari 800 Winter Solstice Celebration Demo 2022",
          "imageUrl": "https://8bitworkshop.com/docs/_static/icon.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=TYJl1EzBs_4",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=TYJl1EzBs_4",
          "publishedOn": "2022-12-25T15:28:36.000Z",
          "wordCount": null,
          "title": "Commodore Christmas Demo (1982) [video]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/apitable/apitable",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/apitable/apitable",
          "publishedOn": "2022-12-25T15:06:22.000Z",
          "wordCount": 1606,
          "title": "APITable: open-source Airtable alternative",
          "imageUrl": "https://opengraph.githubassets.com/1479b72d5134b4f26710c6e2aa5006a8dad619b989c8e82357f378b523045535/apitable/apitable"
        },
        {
          "id": "https://theconversation.com/cats-in-the-middle-ages-what-medieval-manuscripts-teach-us-about-our-ancestors-pets-195389",
          "author": null,
          "description": "Comments",
          "link": "https://theconversation.com/cats-in-the-middle-ages-what-medieval-manuscripts-teach-us-about-our-ancestors-pets-195389",
          "publishedOn": "2022-12-25T14:34:39.000Z",
          "wordCount": 4324,
          "title": "What medieval manuscripts teach us about our ancestors’ pets",
          "imageUrl": "https://images.theconversation.com/files/497695/original/file-20221128-12-umimlg.png?ixlib=rb-1.1.0&rect=4%2C12%2C945%2C471&q=45&auto=format&w=1356&h=668&fit=crop"
        },
        {
          "id": "https://worldsensorium.com/monets-garden-in-giverny/",
          "author": null,
          "description": "Comments",
          "link": "https://worldsensorium.com/monets-garden-in-giverny/",
          "publishedOn": "2022-12-25T13:56:19.000Z",
          "wordCount": 2942,
          "title": "Monet’s Garden in Giverny",
          "imageUrl": "https://worldsensorium.com/wp-content/uploads/2022/11/Nalls-1222-01.jpg"
        },
        {
          "id": "https://danielbmarkham.com/the-overlords-finally-showed-up/",
          "author": null,
          "description": "Comments",
          "link": "https://danielbmarkham.com/the-overlords-finally-showed-up/",
          "publishedOn": "2022-12-25T11:56:18.000Z",
          "wordCount": 2161,
          "title": "The Overlords Finally Showed Up",
          "imageUrl": "https://danielbmarkham.com/content/images/2022/12/dark-ages.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=0itrM7t4l34",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=0itrM7t4l34",
          "publishedOn": "2022-12-25T11:17:17.000Z",
          "wordCount": null,
          "title": "Non-ECC memory corrupted my hard drive image [video]",
          "imageUrl": null
        },
        {
          "id": "https://www.emacswiki.org/emacs/MovingTheCtrlKey",
          "author": null,
          "description": "Comments",
          "link": "https://www.emacswiki.org/emacs/MovingTheCtrlKey",
          "publishedOn": "2022-12-25T10:50:27.000Z",
          "wordCount": 3078,
          "title": "Moving the Ctrl Key",
          "imageUrl": null
        },
        {
          "id": "https://mijailovic.net/2022/12/25/hkpropel/",
          "author": null,
          "description": "Comments",
          "link": "https://mijailovic.net/2022/12/25/hkpropel/",
          "publishedOn": "2022-12-25T10:32:00.000Z",
          "wordCount": 1264,
          "title": "Reverse engineering yet another eBook format",
          "imageUrl": null
        },
        {
          "id": "https://smp.uq.edu.au/pitch-drop-experiment",
          "author": null,
          "description": "Comments",
          "link": "https://smp.uq.edu.au/pitch-drop-experiment",
          "publishedOn": "2022-12-25T09:34:14.000Z",
          "wordCount": 906,
          "title": "Pitch Drop Experiment",
          "imageUrl": "https://smp.uq.edu.au/"
        },
        {
          "id": "https://www.wsj.com/articles/vint-cerf-helped-create-the-internet-on-the-back-of-an-envelope-11671210858",
          "author": null,
          "description": "Comments",
          "link": "https://www.wsj.com/articles/vint-cerf-helped-create-the-internet-on-the-back-of-an-envelope-11671210858",
          "publishedOn": "2022-12-25T05:12:37.000Z",
          "wordCount": 7508,
          "title": "Vint Cerf Helped Create the Internet on the Back of an Envelope",
          "imageUrl": "https://images.wsj.net/im-683799/social"
        },
        {
          "id": "https://www.sainsburywellcome.org/web/research-news/brain-circuit-converts-spatial-goals-escape-actions-discovered",
          "author": null,
          "description": "Comments",
          "link": "https://www.sainsburywellcome.org/web/research-news/brain-circuit-converts-spatial-goals-escape-actions-discovered",
          "publishedOn": "2022-12-25T05:11:55.000Z",
          "wordCount": 1702,
          "title": "Brain circuit that converts spatial goals to escape actions discovered in mice",
          "imageUrl": null
        },
        {
          "id": "https://mastodon.social/@acb/109567809376185861",
          "author": null,
          "description": "Comments",
          "link": "https://mastodon.social/@acb/109567809376185861",
          "publishedOn": "2022-12-25T04:19:03.000Z",
          "wordCount": 111,
          "title": "Interpreting a Sierpinski Triangle Fractal as musical notes sounds good",
          "imageUrl": "https://files.mastodon.social/media_attachments/files/109/567/808/614/600/092/small/e453ebe6673dbc20.png"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34122578",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34122578",
          "publishedOn": "2022-12-25T00:07:19.000Z",
          "wordCount": 1252,
          "title": "Ask HN: Who else is working/on call over Christmas?",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34122118",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34122118",
          "publishedOn": "2022-12-24T23:09:29.000Z",
          "wordCount": 880,
          "title": "Tell HN: Everyone should have a holiday dinner this year",
          "imageUrl": null
        },
        {
          "id": "https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/",
          "author": null,
          "description": "Comments",
          "link": "https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/",
          "publishedOn": "2022-12-24T23:05:12.000Z",
          "wordCount": 2141,
          "title": "The Psychedelic Inspiration for Hypercard (2018)",
          "imageUrl": "https://www.mondo2000.com/wp-content/uploads/2018/06/images-1.jpeg"
        },
        {
          "id": "https://github.com/Droogans/unmaintainable-code",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Droogans/unmaintainable-code",
          "publishedOn": "2022-12-24T22:11:24.000Z",
          "wordCount": 17213,
          "title": "How to write unmantainable code (2015)",
          "imageUrl": "https://opengraph.githubassets.com/d96a518f8def117eab3c75dacebe1207500596d336f20a6037aa61a562d1dd8b/Droogans/unmaintainable-code"
        },
        {
          "id": "https://auerstack.substack.com/p/what-chatgpt-cant-do",
          "author": null,
          "description": "Comments",
          "link": "https://auerstack.substack.com/p/what-chatgpt-cant-do",
          "publishedOn": "2022-12-24T21:46:58.000Z",
          "wordCount": 2825,
          "title": "What ChatGPT can't do",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd539c725-7783-4644-aa25-b785a9bca0e7_795x1014.jpeg"
        },
        {
          "id": "https://www.pagetable.com/?p=1721",
          "author": null,
          "description": "Comments",
          "link": "https://www.pagetable.com/?p=1721",
          "publishedOn": "2022-12-24T21:46:01.000Z",
          "wordCount": 1170,
          "title": "PostScript Cartridge for HP LaserJet",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34121082",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34121082",
          "publishedOn": "2022-12-24T21:06:38.000Z",
          "wordCount": 7738,
          "title": "Merry Christmas, HN",
          "imageUrl": null
        },
        {
          "id": "https://johnhcochrane.blogspot.com/2022/12/stanford-hates-fun.html",
          "author": null,
          "description": "Comments",
          "link": "https://johnhcochrane.blogspot.com/2022/12/stanford-hates-fun.html",
          "publishedOn": "2022-12-24T19:59:05.000Z",
          "wordCount": 6877,
          "title": "Stanford hates fun",
          "imageUrl": "https://lh3.googleusercontent.com/blogger_img_proxy/ANbyha2ZuBmkk5-h515qsZ_69mIBU6Ov5FfbEFTBZ4i2z086ITJ5g7uiiQinaizAeSLcEzQz204neL0GEX-zOc6utBWXO2eeRKmR1LuVYdiTZxZybYDgOk-Tt22gdAtH-4yBFh_TER-OyrWjnMfI=w1200-h630-p-k-no-nu"
        },
        {
          "id": "https://www.axios.com/2022/03/04/the-cold-hard-truth-about-electric-vehicles-in-winter",
          "author": null,
          "description": "Comments",
          "link": "https://www.axios.com/2022/03/04/the-cold-hard-truth-about-electric-vehicles-in-winter",
          "publishedOn": "2022-12-24T19:27:53.000Z",
          "wordCount": 2206,
          "title": "The cold hard truth about electric vehicles in winter",
          "imageUrl": "https://images.axios.com/dlirObIllA2rhztW6nGVX9v1HCw=/0x522:2825x2111/1366x768/2022/03/04/1646391658299.jpg"
        },
        {
          "id": "https://bmcgee.ie/posts/2022/12/setting-up-my-new-laptop-nix-style/",
          "author": null,
          "description": "Comments",
          "link": "https://bmcgee.ie/posts/2022/12/setting-up-my-new-laptop-nix-style/",
          "publishedOn": "2022-12-24T18:53:16.000Z",
          "wordCount": 1710,
          "title": "Setting up my new laptop: Nix style",
          "imageUrl": "https://bmcgee.ie"
        },
        {
          "id": "https://www.os2museum.com/wp/win16-retro-development/",
          "author": null,
          "description": "Comments",
          "link": "https://www.os2museum.com/wp/win16-retro-development/",
          "publishedOn": "2022-12-24T18:37:15.000Z",
          "wordCount": 3623,
          "title": "Win16 Retro Development",
          "imageUrl": null
        },
        {
          "id": "https://github.com/ethereum/pos-evolution/blob/master/pos-evolution.md",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/ethereum/pos-evolution/blob/master/pos-evolution.md",
          "publishedOn": "2022-12-24T17:39:34.000Z",
          "wordCount": 14975,
          "title": "Evolution of the Ethereum proof-of-stake consensus protocol",
          "imageUrl": "https://opengraph.githubassets.com/b026dc7800f313e83e8c87986c8bab860244e43fc9c40c9863fc023543223377/ethereum/pos-evolution"
        },
        {
          "id": "https://www.sacbee.com/news/politics-government/capitol-alert/article270354472.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.sacbee.com/news/politics-government/capitol-alert/article270354472.html",
          "publishedOn": "2022-12-24T16:54:31.000Z",
          "wordCount": 1217,
          "title": "California’s population shrinks for third straight year",
          "imageUrl": "https://www.sacbee.com/latest-news/lnfcmc/picture251009279/alternates/LANDSCAPE_1140/AP21116712044302%20(1).jpg"
        },
        {
          "id": "https://community.secondlife.com/blogs/entry/12081-second-life-on-github/",
          "author": null,
          "description": "Comments",
          "link": "https://community.secondlife.com/blogs/entry/12081-second-life-on-github/",
          "publishedOn": "2022-12-24T16:51:37.000Z",
          "wordCount": 1581,
          "title": "Second Life on GitHub",
          "imageUrl": "https://content.invisioncic.com/Mseclife/monthly_2022_11/image2.jpg.725a20371f8f0350e6007371ae8f89da.jpg"
        },
        {
          "id": "https://austinhenley.com/blog/challengingalgorithms.html",
          "author": null,
          "description": "Comments",
          "link": "https://austinhenley.com/blog/challengingalgorithms.html",
          "publishedOn": "2022-12-24T16:41:19.000Z",
          "wordCount": 883,
          "title": "Challenging algorithms and data structures every programmer should try",
          "imageUrl": "https://austinhenley.com/blog/images/algorithmsbook.jpg"
        },
        {
          "id": "http://theoryofconstraints.blogspot.com/2007/06/toc-stories-2-blue-light-creating.html",
          "author": null,
          "description": "Comments",
          "link": "http://theoryofconstraints.blogspot.com/2007/06/toc-stories-2-blue-light-creating.html",
          "publishedOn": "2022-12-24T15:06:19.000Z",
          "wordCount": 3622,
          "title": "“Blue Light” creating capacity for nothing (2007)",
          "imageUrl": null
        },
        {
          "id": "https://www.theguardian.com/books/2022/dec/23/philip-pullman-i-had-to-grow-up-before-i-could-cope-with-middlemarch",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/books/2022/dec/23/philip-pullman-i-had-to-grow-up-before-i-could-cope-with-middlemarch",
          "publishedOn": "2022-12-24T13:13:42.000Z",
          "wordCount": 4866,
          "title": "‘I had to grow up before I could cope with Middlemarch’",
          "imageUrl": "https://i.guim.co.uk/img/media/47a090e17e763e91dca764b995525b10e176ec7f/0_111_683_410/master/683.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=6725bc54a08a4ce601f6b444f32f3eb9"
        },
        {
          "id": "https://www.teslarati.com/califonia-banning-tesla-fsd/",
          "author": null,
          "description": "Comments",
          "link": "https://www.teslarati.com/califonia-banning-tesla-fsd/",
          "publishedOn": "2022-12-24T13:09:54.000Z",
          "wordCount": 2519,
          "title": "California passes law banning Tesla from calling software FSD",
          "imageUrl": "https://www.teslarati.com/wp-content/uploads/2022/12/California-passes-law-banning-Tesla-from-calling-software-FSD.jpeg"
        },
        {
          "id": "https://nautil.us/the-great-forgetting-253223/",
          "author": null,
          "description": "Comments",
          "link": "https://nautil.us/the-great-forgetting-253223/",
          "publishedOn": "2022-12-24T11:55:51.000Z",
          "wordCount": 10137,
          "title": "The Great Forgetting",
          "imageUrl": "https://assets.nautil.us/sites/3/nautilus/Praetorius_HERO.png?auto=compress&fm=png&ixlib=php-3.3.1"
        },
        {
          "id": "https://www.economist.com/christmas-specials/2022/12/20/deadly-dirty-indispensable-the-nitrogen-industry-has-changed-the-world",
          "author": null,
          "description": "Comments",
          "link": "https://www.economist.com/christmas-specials/2022/12/20/deadly-dirty-indispensable-the-nitrogen-industry-has-changed-the-world",
          "publishedOn": "2022-12-24T11:31:49.000Z",
          "wordCount": 36182,
          "title": "Deadly, dirty, indispensable: the nitrogen industry has changed the world",
          "imageUrl": "https://www.economist.com/img/b/1280/720/90/media-assets/image/20221224_XMD114.jpg"
        },
        {
          "id": "https://charperbonaroo.github.io/bls/#0",
          "author": null,
          "description": "Comments",
          "link": "https://charperbonaroo.github.io/bls/#0",
          "publishedOn": "2022-12-24T10:59:06.000Z",
          "wordCount": 33,
          "title": "Bitmap Logic Simulator – Game",
          "imageUrl": null
        },
        {
          "id": "https://squidgeefish.com/projects/rotary-keyboard/",
          "author": null,
          "description": "Comments",
          "link": "https://squidgeefish.com/projects/rotary-keyboard/",
          "publishedOn": "2022-12-24T10:56:32.000Z",
          "wordCount": 1918,
          "title": "Rotary Keyboard",
          "imageUrl": "http://squidgeefish.com/assets/rotary-keyboard/banner.jpg"
        },
        {
          "id": "https://www.vice.com/en/article/3admdv/archaeologists-discover-huge-lost-civilization-in-guatemala",
          "author": null,
          "description": "Comments",
          "link": "https://www.vice.com/en/article/3admdv/archaeologists-discover-huge-lost-civilization-in-guatemala",
          "publishedOn": "2022-12-24T08:38:51.000Z",
          "wordCount": 4426,
          "title": "Archaeologists Discover Lost Civilization in Guatemala",
          "imageUrl": "https://video-images.vice.com/articles/63a212f14af82d9c42dfc974/lede/1671566301999-22.jpeg?image-resize-opts=Y3JvcD0xeHc6MC43ODkzeGg7MHh3LDB4aCZyZXNpemU9MTIwMDoqJnJlc2l6ZT0xMjAwOio"
        },
        {
          "id": "https://www.hcn.org/articles/wildlife-bringing-back-californias-wild-bees",
          "author": null,
          "description": "Comments",
          "link": "https://www.hcn.org/articles/wildlife-bringing-back-californias-wild-bees",
          "publishedOn": "2022-12-24T05:52:40.000Z",
          "wordCount": 4444,
          "title": "Bringing back California’s wild bees",
          "imageUrl": "https://www.hcn.org/articles/wildlife-bringing-back-californias-wild-bees/bigimage_large"
        },
        {
          "id": "https://www.taptab.dev/",
          "author": null,
          "description": "Comments",
          "link": "https://www.taptab.dev/",
          "publishedOn": "2022-12-24T01:05:20.000Z",
          "wordCount": 529,
          "title": "Show HN: TapTab – Tab switching web extension for Safari",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/cryptopathic/status/1606416137771782151",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/cryptopathic/status/1606416137771782151",
          "publishedOn": "2022-12-23T23:27:39.000Z",
          "wordCount": 470,
          "title": "The situation at LastPass may be worse than they are letting on",
          "imageUrl": null
        },
        {
          "id": "http://blogs.intellique.com/cgi-bin/tech/2022/01/27",
          "author": null,
          "description": "Comments",
          "link": "http://blogs.intellique.com/cgi-bin/tech/2022/01/27",
          "publishedOn": "2022-12-23T22:29:35.000Z",
          "wordCount": 2632,
          "title": "Managing tape drives and libraries with the Unix/Linux CLI",
          "imageUrl": null
        },
        {
          "id": "https://www.science.org/doi/10.1126/sciadv.ade1248",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/doi/10.1126/sciadv.ade1248",
          "publishedOn": "2022-12-23T22:12:06.000Z",
          "wordCount": null,
          "title": "Dating of a large tool assemblage at the Cooper’s Ferry site (Idaho, USA)",
          "imageUrl": null
        },
        {
          "id": "http://whatcolorisit.sumbioun.com/",
          "author": null,
          "description": "Comments",
          "link": "http://whatcolorisit.sumbioun.com/",
          "publishedOn": "2022-12-23T21:57:42.000Z",
          "wordCount": 350,
          "title": "What color is it?",
          "imageUrl": "http://whatcolorisit.sumbioun.com/what-color.jpg"
        },
        {
          "id": "https://pioneerworks.org/broadcast/picture-this-periodic-table",
          "author": null,
          "description": "Comments",
          "link": "https://pioneerworks.org/broadcast/picture-this-periodic-table",
          "publishedOn": "2022-12-23T21:50:07.000Z",
          "wordCount": 15266,
          "title": "Picture This: The Periodic Table",
          "imageUrl": "https://cdn.sanity.io/images/vgvol637/production/1799b148edd4666995b3dfea168dad5ea51ed620-2592x1944.svg?w=800"
        },
        {
          "id": "https://www.science.org/content/article/deadly-sharp-points-found-idaho-could-be-first-american-made-tools",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/content/article/deadly-sharp-points-found-idaho-could-be-first-american-made-tools",
          "publishedOn": "2022-12-23T21:46:37.000Z",
          "wordCount": 3027,
          "title": "Sharp points found in Idaho could be first American-made tools",
          "imageUrl": "https://www.science.org/do/10.1126/science.adg4404/abs/_20221223_on_stemmed_points.jpg"
        },
        {
          "id": "https://www.theguardian.com/business/2022/dec/23/chief-executive-of-ftx-sister-company-pleads-guilty-to-seven-offences",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/business/2022/dec/23/chief-executive-of-ftx-sister-company-pleads-guilty-to-seven-offences",
          "publishedOn": "2022-12-23T21:45:04.000Z",
          "wordCount": 4962,
          "title": "Caroline Ellison, CEO of Alameda Research, pleads guilty to seven offences",
          "imageUrl": "https://i.guim.co.uk/img/media/1be2f27880aeeea8a423433e8bd73f36deb6cd32/0_104_4902_2941/master/4902.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f69e20086dbf622b30d84ce12d7ff014"
        },
        {
          "id": "https://you.com/search?q=what+was+the+recent+breakthrough+in+fusion+research%3F&fromSearchBar=true&tbm=youchat",
          "author": null,
          "description": "Comments",
          "link": "https://you.com/search?q=what+was+the+recent+breakthrough+in+fusion+research%3F&fromSearchBar=true&tbm=youchat",
          "publishedOn": "2022-12-23T21:19:04.000Z",
          "wordCount": null,
          "title": "A new chat feature has been released by You Search",
          "imageUrl": null
        },
        {
          "id": "https://github.com/gabrielsroka/gabrielsroka.github.io/blob/master/getHNFavorites.js",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/gabrielsroka/gabrielsroka.github.io/blob/master/getHNFavorites.js",
          "publishedOn": "2022-12-23T21:07:23.000Z",
          "wordCount": 951,
          "title": "Show HN: Search HN Favorites or Export to CSV/HTML",
          "imageUrl": "https://opengraph.githubassets.com/caa0c293d298022e1a5c47700d6da3a76225808317683d0d0b1a0b0634a9f440/gabrielsroka/gabrielsroka.github.io"
        },
        {
          "id": "https://ossinsight.io/",
          "author": null,
          "description": "Comments",
          "link": "https://ossinsight.io/",
          "publishedOn": "2022-12-23T21:04:34.000Z",
          "wordCount": 1522,
          "title": "GitHub Statistics",
          "imageUrl": "https://ossinsight.io/img/screenshots/homepage.png"
        },
        {
          "id": "https://theprintshop.club/",
          "author": null,
          "description": "Comments",
          "link": "https://theprintshop.club/",
          "publishedOn": "2022-12-23T21:00:05.000Z",
          "wordCount": 440,
          "title": "The Print Shop Club – Create Apple II Print Shop printouts on-line",
          "imageUrl": null
        },
        {
          "id": "https://docs.ruby-lang.org/en/master/NEWS_md.html#label-NEWS+for+Ruby+3.2.0",
          "author": null,
          "description": "Comments",
          "link": "https://docs.ruby-lang.org/en/master/NEWS_md.html#label-NEWS+for+Ruby+3.2.0",
          "publishedOn": "2022-12-23T20:20:23.000Z",
          "wordCount": 2922,
          "title": "News for Ruby 3.2.0",
          "imageUrl": null
        },
        {
          "id": "https://www.lrb.co.uk/the-paper/v45/n01/anne-enright/eyes-that-bite",
          "author": null,
          "description": "Comments",
          "link": "https://www.lrb.co.uk/the-paper/v45/n01/anne-enright/eyes-that-bite",
          "publishedOn": "2022-12-23T20:06:29.000Z",
          "wordCount": 8921,
          "title": "Eyes That Bite",
          "imageUrl": "https://www.lrb.co.uk/storage/social_image/images/3/1/8/0/29050813-1-eng-GB/e780c4508f13-enright_website2.jpg"
        },
        {
          "id": "https://docs.google.com/presentation/d/1sowJrQQfgxnLCErb-CvUV8VGXdtca6SWYWWLRPZgaHI/edit?usp=sharing",
          "author": null,
          "description": "Comments",
          "link": "https://docs.google.com/presentation/d/1sowJrQQfgxnLCErb-CvUV8VGXdtca6SWYWWLRPZgaHI/edit?usp=sharing",
          "publishedOn": "2022-12-23T19:10:07.000Z",
          "wordCount": 6415,
          "title": "I found a secret US Government surveillance program (2019)",
          "imageUrl": "https://lh4.googleusercontent.com/oV3a2QuB7XsN4CSpzbv4bFWL4_BbpNJbExDh5af_20DFwJEzN0m4JKLqPmUN9PWVo99LAnNL9lhRDg=w1200-h630-p"
        },
        {
          "id": "https://www.haiku-os.org/get-haiku/r1beta4/release-notes/",
          "author": null,
          "description": "Comments",
          "link": "https://www.haiku-os.org/get-haiku/r1beta4/release-notes/",
          "publishedOn": "2022-12-23T18:54:10.000Z",
          "wordCount": 2151,
          "title": "Haiku R1/beta4",
          "imageUrl": "https://www.haiku-os.org/images/haiku_600x315.png"
        },
        {
          "id": "https://mesonbuild.com/Release-notes-for-1-0-0.html",
          "author": null,
          "description": "Comments",
          "link": "https://mesonbuild.com/Release-notes-for-1-0-0.html",
          "publishedOn": "2022-12-23T18:41:35.000Z",
          "wordCount": 463,
          "title": "Meson Build System 1.0",
          "imageUrl": null
        },
        {
          "id": "https://bt.ht/suckless/",
          "author": null,
          "description": "Comments",
          "link": "https://bt.ht/suckless/",
          "publishedOn": "2022-12-23T18:26:18.000Z",
          "wordCount": 1227,
          "title": "I want to suckless and you can too",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/zzznah/status/1606294595330940928",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/zzznah/status/1606294595330940928",
          "publishedOn": "2022-12-23T17:58:47.000Z",
          "wordCount": 470,
          "title": "Particle Lenia: Self Organising Particles",
          "imageUrl": null
        },
        {
          "id": "https://www.evanmiller.org/mathematical-hacker.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.evanmiller.org/mathematical-hacker.html",
          "publishedOn": "2022-12-23T17:33:11.000Z",
          "wordCount": 2182,
          "title": "The Mathematical Hacker (2012)",
          "imageUrl": null
        },
        {
          "id": "https://www.macrumors.com/2022/12/23/iphone-14-pro-setback-removed-graphics-processor/",
          "author": null,
          "description": "Comments",
          "link": "https://www.macrumors.com/2022/12/23/iphone-14-pro-setback-removed-graphics-processor/",
          "publishedOn": "2022-12-23T16:11:16.000Z",
          "wordCount": 2911,
          "title": "iPhone 14 Pro faced 'unprecedented' setback leading to removal of new GPU",
          "imageUrl": "https://images.macrumors.com/t/WVnXQ13cuwrE9ZUl4NdNBfTOXr0=/1600x/article-new/2022/10/A16-iPhone-14-Pro.jpeg"
        },
        {
          "id": "https://github.com/vasanthv/talk",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/vasanthv/talk",
          "publishedOn": "2022-12-23T16:04:09.000Z",
          "wordCount": 743,
          "title": "Free, P2P, disposable group video calling app for the web",
          "imageUrl": "https://opengraph.githubassets.com/78545e35550ca5ac66ead96589786f57df8dd1267b564cc2b1ae8095f92f74a5/vasanthv/talk"
        },
        {
          "id": "https://github.com/Immediate-Mode-UI/Nuklear",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Immediate-Mode-UI/Nuklear",
          "publishedOn": "2022-12-23T15:23:33.000Z",
          "wordCount": 1855,
          "title": "Nuklear – A single-header ANSI C immediate mode cross-platform GUI library",
          "imageUrl": "https://opengraph.githubassets.com/54e9c2c98bc187a1ec9c7e381238d92eee3b0e4808e3124dd92e6eff68829802/Immediate-Mode-UI/Nuklear"
        },
        {
          "id": "https://kno.wled.ge/",
          "author": null,
          "description": "Comments",
          "link": "https://kno.wled.ge/",
          "publishedOn": "2022-12-23T13:56:13.000Z",
          "wordCount": 660,
          "title": "WLED Project",
          "imageUrl": null
        },
        {
          "id": "https://craigmod.com/ridgeline/115/",
          "author": null,
          "description": "Comments",
          "link": "https://craigmod.com/ridgeline/115/",
          "publishedOn": "2022-12-23T13:29:56.000Z",
          "wordCount": 753,
          "title": "Walk as Spreadsheet (2021)",
          "imageUrl": "https://craigmod.com/ridgeline/images/115/115.jpg"
        },
        {
          "id": "https://semiengineering.com/risc-v-pushes-into-the-mainstream/",
          "author": null,
          "description": "Comments",
          "link": "https://semiengineering.com/risc-v-pushes-into-the-mainstream/",
          "publishedOn": "2022-12-23T13:27:33.000Z",
          "wordCount": null,
          "title": "RISC-V Pushes into the Mainstream",
          "imageUrl": null
        },
        {
          "id": "https://pcalc.com/mac/thirty.html",
          "author": null,
          "description": "Comments",
          "link": "https://pcalc.com/mac/thirty.html",
          "publishedOn": "2022-12-23T12:42:30.000Z",
          "wordCount": 3112,
          "title": "PCalc, an Origin Story",
          "imageUrl": null
        },
        {
          "id": "https://www.bbc.co.uk/accessibility/forproducts/guides/subtitles/",
          "author": null,
          "description": "Comments",
          "link": "https://www.bbc.co.uk/accessibility/forproducts/guides/subtitles/",
          "publishedOn": "2022-12-23T12:28:10.000Z",
          "wordCount": 31275,
          "title": "BBC Subtitle Guidelines",
          "imageUrl": "https://www.bbc.co.uk/accessibility/forproducts/guides/subtitles/img/EBU-TT-D_illustration1.png"
        },
        {
          "id": "https://www.ringgame.net/riddles.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.ringgame.net/riddles.html",
          "publishedOn": "2022-12-23T12:25:55.000Z",
          "wordCount": 12490,
          "title": "The Hobbit: Riddles in the Dark – The Lost Version (2001)",
          "imageUrl": null
        },
        {
          "id": "https://www.brandonsanderson.com/state-of-the-sanderson-2022/",
          "author": null,
          "description": "Comments",
          "link": "https://www.brandonsanderson.com/state-of-the-sanderson-2022/",
          "publishedOn": "2022-12-23T10:23:16.000Z",
          "wordCount": 11730,
          "title": "State of the Sanderson 2022",
          "imageUrl": "https://www.brandonsanderson.com/wp-content/uploads/2022/12/BS_State-of-Sanderson_BLOG-HEADER_V7-copy.png"
        },
        {
          "id": "https://philip.greenspun.com/materialism/money",
          "author": null,
          "description": "Comments",
          "link": "https://philip.greenspun.com/materialism/money",
          "publishedOn": "2022-12-23T07:16:09.000Z",
          "wordCount": 6249,
          "title": "Money, money, money (and investing) (2015)",
          "imageUrl": null
        },
        {
          "id": "https://tylerneylon.com/a/lsh1/",
          "author": null,
          "description": "Comments",
          "link": "https://tylerneylon.com/a/lsh1/",
          "publishedOn": "2022-12-23T06:30:42.000Z",
          "wordCount": 4689,
          "title": "Introduction to Locality-Sensitive Hashing (2018)",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34101086",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34101086",
          "publishedOn": "2022-12-23T01:00:14.000Z",
          "wordCount": 168,
          "title": "Generally Intelligent (YC S17) Is Hiring Systems Engineers",
          "imageUrl": null
        },
        {
          "id": "https://oscargws.substack.com/p/why-i-gave-up-drinking-in-my-twenties",
          "author": null,
          "description": "Comments",
          "link": "https://oscargws.substack.com/p/why-i-gave-up-drinking-in-my-twenties",
          "publishedOn": "2022-12-23T00:32:04.000Z",
          "wordCount": 3748,
          "title": "On why I gave up drinking in my early twenties",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53dbd9ab-af84-4435-9dcd-9a5b2c62256a_1280x720.png"
        },
        {
          "id": "https://lupyuen.github.io/articles/de3",
          "author": null,
          "description": "Comments",
          "link": "https://lupyuen.github.io/articles/de3",
          "publishedOn": "2022-12-22T23:55:35.000Z",
          "wordCount": 3530,
          "title": "NuttX RTOS for PinePhone: Display Engine",
          "imageUrl": "https://lupyuen.github.io/images/de3-title.jpg"
        },
        {
          "id": "https://interlisp.org/news/2022medleyannualreport/",
          "author": null,
          "description": "Comments",
          "link": "https://interlisp.org/news/2022medleyannualreport/",
          "publishedOn": "2022-12-22T23:53:40.000Z",
          "wordCount": 489,
          "title": "2022 Medley Interlisp Annual Report",
          "imageUrl": null
        },
        {
          "id": "https://handlr.sapico.me/?domain=https%3A%2F%2Fnews.ycombinator.com",
          "author": null,
          "description": "Comments",
          "link": "https://handlr.sapico.me/?domain=https%3A%2F%2Fnews.ycombinator.com",
          "publishedOn": "2022-12-22T23:10:44.000Z",
          "wordCount": 1117,
          "title": "Show HN: My bookmarks of HN and who I'm following",
          "imageUrl": null
        },
        {
          "id": "http://www.acad.bg/ebook/ml/Society%20of%20Mind.pdf",
          "author": null,
          "description": "Comments",
          "link": "http://www.acad.bg/ebook/ml/Society%20of%20Mind.pdf",
          "publishedOn": "2022-12-22T23:01:26.000Z",
          "wordCount": 634532,
          "title": "The Society of Mind (1986) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/elanmart/cbp-translate",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/elanmart/cbp-translate",
          "publishedOn": "2022-12-22T22:20:18.000Z",
          "wordCount": 2760,
          "title": "Serverless Video Transcription inspired by Cyberpunk 2077",
          "imageUrl": "https://opengraph.githubassets.com/8834529f4321ee12a5b0e7112e52bb0b4ebb7af0f9391fa8ace824db0119dd13/elanmart/cbp-translate"
        },
        {
          "id": "https://www.pcmag.com/news/40-years-of-pcmag-an-illustrated-guide",
          "author": null,
          "description": "Comments",
          "link": "https://www.pcmag.com/news/40-years-of-pcmag-an-illustrated-guide",
          "publishedOn": "2022-12-22T22:03:57.000Z",
          "wordCount": 5011,
          "title": "40 Years of PCMag: An Illustrated Guide",
          "imageUrl": "https://i.pcmag.com/imagery/articles/05ItT3UlIrFDJEPH8tt88ii-25.fit_lim.size_1200x630.v1654019873.jpg"
        },
        {
          "id": "https://www.wsj.com/articles/airlines-frequent-flier-status-mileage-run-11671562815",
          "author": null,
          "description": "Comments",
          "link": "https://www.wsj.com/articles/airlines-frequent-flier-status-mileage-run-11671562815",
          "publishedOn": "2022-12-22T22:02:48.000Z",
          "wordCount": 7182,
          "title": "What frequent fliers do for status",
          "imageUrl": "https://images.wsj.net/im-684890/social"
        },
        {
          "id": "https://www.zerodayinitiative.com/advisories/ZDI-22-1690/",
          "author": null,
          "description": "Comments",
          "link": "https://www.zerodayinitiative.com/advisories/ZDI-22-1690/",
          "publishedOn": "2022-12-22T21:15:39.000Z",
          "wordCount": 247,
          "title": "Linux Kernel Ksmbd Use-After-Free Remote Code Execution Vulnerability",
          "imageUrl": "https://zerodayinitiative.com/images/logo-footer.svg"
        },
        {
          "id": "https://www.franzoni.eu/password-requirements-myths-madness/",
          "author": null,
          "description": "Comments",
          "link": "https://www.franzoni.eu/password-requirements-myths-madness/",
          "publishedOn": "2022-12-22T20:42:24.000Z",
          "wordCount": 1624,
          "title": "Password Requirements: Myths and Madness",
          "imageUrl": "https://www.franzoni.eu/content/images/2017/03/cosmic-timetraveler-39766--1-.jpg"
        },
        {
          "id": "https://www.paolomainardi.com/posts/docker-performance-macos/",
          "author": null,
          "description": "Comments",
          "link": "https://www.paolomainardi.com/posts/docker-performance-macos/",
          "publishedOn": "2022-12-22T20:42:12.000Z",
          "wordCount": 3769,
          "title": "Docker on MacOS is slow and how to fix it",
          "imageUrl": "https://www.paolomainardi.com/images/posts/3-docker/docker-dalle-container-macbook.webp"
        },
        {
          "id": "https://www.nngroup.com/articles/optional-registration/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nngroup.com/articles/optional-registration/",
          "publishedOn": "2022-12-22T20:35:10.000Z",
          "wordCount": 2003,
          "title": "Don't force users to register before they can buy (2015)",
          "imageUrl": "https://media.nngroup.com/media/articles/opengraph_images/Slide23articlesoptional-registration.png"
        },
        {
          "id": "https://www.forbes.com/sites/emilybaker-white/2022/12/22/tiktok-tracks-forbes-journalists-bytedance/",
          "author": null,
          "description": "Comments",
          "link": "https://www.forbes.com/sites/emilybaker-white/2022/12/22/tiktok-tracks-forbes-journalists-bytedance/",
          "publishedOn": "2022-12-22T20:22:08.000Z",
          "wordCount": 11646,
          "title": "ByteDance confirmed it used TikTok to monitor journalists’ physical location",
          "imageUrl": "https://imageio.forbes.com/specials-images/imageserve/63a4af573d1eb6def1c8a814/0x0.jpg?format=jpg&width=1200"
        },
        {
          "id": "https://johanpeitz.itch.io/picosynth",
          "author": null,
          "description": "Comments",
          "link": "https://johanpeitz.itch.io/picosynth",
          "publishedOn": "2022-12-22T20:06:52.000Z",
          "wordCount": 515,
          "title": "Pico8 Music Synthesizer",
          "imageUrl": "https://img.itch.zone/aW1nLzEwNzM1ODQ1LnBuZw==/original/1CJm%2Fa.png"
        },
        {
          "id": "http://www.lispworks.com/products/myths_and_legends.html",
          "author": null,
          "description": "Comments",
          "link": "http://www.lispworks.com/products/myths_and_legends.html",
          "publishedOn": "2022-12-22T19:48:24.000Z",
          "wordCount": 5418,
          "title": "Common Lisp – Myths and Legends (2002)",
          "imageUrl": null
        },
        {
          "id": "https://huggingface.co/spaces/bigcode/santacoder-demo",
          "author": null,
          "description": "Comments",
          "link": "https://huggingface.co/spaces/bigcode/santacoder-demo",
          "publishedOn": "2022-12-22T19:45:44.000Z",
          "wordCount": 117,
          "title": "SantaCoder: A new 1.1B code model for generation and infilling",
          "imageUrl": "https://thumbnails.huggingface.co/social-thumbnails/spaces/bigcode/santacoder-demo.png"
        },
        {
          "id": "https://bunny.net/blog/introducing-bunny-optimizer-ai-a-new-way-of-creating-content/",
          "author": null,
          "description": "Comments",
          "link": "https://bunny.net/blog/introducing-bunny-optimizer-ai-a-new-way-of-creating-content/",
          "publishedOn": "2022-12-22T19:22:35.000Z",
          "wordCount": 1381,
          "title": "Bunny AI",
          "imageUrl": "https://bunny.net/blog/content/images/2022/12/bunnynet-introducing-bunny-ai-generate-images-dynamicaly.jpg"
        },
        {
          "id": "https://adamfallon.com/databreach/csv/elasticsearch/2022/12/22/elasticsearch-facebook-data-leak.html",
          "author": null,
          "description": "Comments",
          "link": "https://adamfallon.com/databreach/csv/elasticsearch/2022/12/22/elasticsearch-facebook-data-leak.html",
          "publishedOn": "2022-12-22T19:09:30.000Z",
          "wordCount": 1449,
          "title": "Searching a data breach with ElasticSearch",
          "imageUrl": null
        },
        {
          "id": "https://blog.lastpass.com/2022/12/notice-of-recent-security-incident/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.lastpass.com/2022/12/notice-of-recent-security-incident/",
          "publishedOn": "2022-12-22T19:07:27.000Z",
          "wordCount": 3217,
          "title": "Notice of Recent Security Incident [updated]",
          "imageUrl": "https://blog.lastpass.com/wp-content/uploads/sites/20/2022/08/iStock-621574390-1-scaled.jpg"
        },
        {
          "id": "https://greydanus.github.io/2020/12/01/scaling-down/",
          "author": null,
          "description": "Comments",
          "link": "https://greydanus.github.io/2020/12/01/scaling-down/",
          "publishedOn": "2022-12-22T19:04:39.000Z",
          "wordCount": 3435,
          "title": "Scaling Down Deep Learning",
          "imageUrl": null
        },
        {
          "id": "https://statmodeling.stat.columbia.edu/2022/12/22/do-simpler-machine-learning-models-exist-and-how-can-we-find-them/",
          "author": null,
          "description": "Comments",
          "link": "https://statmodeling.stat.columbia.edu/2022/12/22/do-simpler-machine-learning-models-exist-and-how-can-we-find-them/",
          "publishedOn": "2022-12-22T18:56:34.000Z",
          "wordCount": 3782,
          "title": "Do simpler machine learning models exist and how can we find them?",
          "imageUrl": null
        },
        {
          "id": "https://www.cnbc.com/2022/12/22/ftx-founder-sam-bankman-fried-to-be-released-on-250-million-bail.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.cnbc.com/2022/12/22/ftx-founder-sam-bankman-fried-to-be-released-on-250-million-bail.html",
          "publishedOn": "2022-12-22T18:50:20.000Z",
          "wordCount": 17389,
          "title": "FTX founder Sam Bankman-Fried to be released on $250M bail",
          "imageUrl": "https://image.cnbcfm.com/api/v1/image/107169989-1671666602093-gettyimages-1451152696-029a6648_9afdcfb2-7d82-4df2-ab6f-d8cd93d45c54.jpeg?v=1671734197&w=1920&h=1080"
        },
        {
          "id": "https://evoniuk.github.io/posts/pitfall.html",
          "author": null,
          "description": "Comments",
          "link": "https://evoniuk.github.io/posts/pitfall.html",
          "publishedOn": "2022-12-22T17:30:42.000Z",
          "wordCount": 2989,
          "title": "How Pitfall builds its world (2021)",
          "imageUrl": null
        },
        {
          "id": "https://devos50.github.io/blog/2022/ipod-touch-qemu/",
          "author": null,
          "description": "Comments",
          "link": "https://devos50.github.io/blog/2022/ipod-touch-qemu/",
          "publishedOn": "2022-12-22T17:22:01.000Z",
          "wordCount": 4214,
          "title": "Emulating an iPod Touch 1G and iPhoneOS 1.0 using QEMU (Part I)",
          "imageUrl": null
        },
        {
          "id": "https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/",
          "author": null,
          "description": "Comments",
          "link": "https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/",
          "publishedOn": "2022-12-22T17:17:46.000Z",
          "wordCount": 5759,
          "title": "Don't call yourself a programmer, and other career advice (2011)",
          "imageUrl": null
        },
        {
          "id": "https://randomascii.wordpress.com/2017/07/09/24-core-cpu-and-i-cant-move-my-mouse/",
          "author": null,
          "description": "Comments",
          "link": "https://randomascii.wordpress.com/2017/07/09/24-core-cpu-and-i-cant-move-my-mouse/",
          "publishedOn": "2022-12-22T16:23:49.000Z",
          "wordCount": 14811,
          "title": "24-core CPU and I can’t move my mouse (2017)",
          "imageUrl": "https://randomascii.files.wordpress.com/2017/07/gdi-serialization-fixed.png"
        },
        {
          "id": "https://www.benkuhn.net/abyss/",
          "author": null,
          "description": "Comments",
          "link": "https://www.benkuhn.net/abyss/",
          "publishedOn": "2022-12-22T15:54:24.000Z",
          "wordCount": 3727,
          "title": "Staring into the abyss as a core life skill",
          "imageUrl": null
        },
        {
          "id": "https://f-droid.org/2022/12/18/unifiedpush.html",
          "author": null,
          "description": "Comments",
          "link": "https://f-droid.org/2022/12/18/unifiedpush.html",
          "publishedOn": "2022-12-22T15:45:57.000Z",
          "wordCount": 1730,
          "title": "UnifiedPush: A decentralized, open-source push notification protocol",
          "imageUrl": "https://f-droid.org/assets/fdroid-logo_bfHl7nsLHOUQxzdU8-rGIhn4bAgl6z7k2mA3fWoCyT4=.png"
        },
        {
          "id": "https://spectrum.ieee.org/thin-film-solar-panels",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/thin-film-solar-panels",
          "publishedOn": "2022-12-22T14:08:00.000Z",
          "wordCount": 11502,
          "title": "Paper-Thin Solar Makes Any Surface Photovoltaic",
          "imageUrl": "https://spectrum.ieee.org/media-library/white-glvoed-hands-hold-up-a-green-and-gold-rectangle-of-material.jpg?id=32372942&width=1200&height=600&coordinates=0%2C173%2C0%2C173"
        },
        {
          "id": "https://eandt.theiet.org/content/articles/2022/12/japan-to-invest-on-nuclear-energy-in-major-policy-shift/",
          "author": null,
          "description": "Comments",
          "link": "https://eandt.theiet.org/content/articles/2022/12/japan-to-invest-on-nuclear-energy-in-major-policy-shift/",
          "publishedOn": "2022-12-22T13:18:03.000Z",
          "wordCount": 6968,
          "title": "Japan to invest on nuclear energy in major policy shift",
          "imageUrl": "https://eandt.theiet.org/media/20272/untitled-design-1.jpg?crop=0,0.27416666666666667,0,0.23364583333333328&cropmode=percentage&width=1200&height=450&rnd=133161801130000000"
        },
        {
          "id": "https://www.theguardian.com/artanddesign/2017/may/11/design-museum-california-designing-freedom-tech-design",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/artanddesign/2017/may/11/design-museum-california-designing-freedom-tech-design",
          "publishedOn": "2022-12-22T13:11:30.000Z",
          "wordCount": 5717,
          "title": "Tripping Californians who paved the way to our touchscreen world",
          "imageUrl": "https://i.guim.co.uk/img/media/ff05be3cc9c2cdb92a50ba1910320403fef787bc/14_43_2789_1673/master/2789.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2818de6d5efb50a18eacd9055961b847"
        },
        {
          "id": "https://dalton.substack.com/p/startup-childhood",
          "author": null,
          "description": "Comments",
          "link": "https://dalton.substack.com/p/startup-childhood",
          "publishedOn": "2022-12-22T13:11:24.000Z",
          "wordCount": 2252,
          "title": "Startup childhood – Tiny startups are not Google-in-miniature-form",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F11960689-a421-4f2b-b0c5-3720b4fea9a0_1500x1000.webp"
        },
        {
          "id": "https://www.theguardian.com/global-development/2022/dec/20/africas-biggest-photography-library-opens-in-ghana-accra-dikan-center",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/global-development/2022/dec/20/africas-biggest-photography-library-opens-in-ghana-accra-dikan-center",
          "publishedOn": "2022-12-22T11:02:26.000Z",
          "wordCount": 4918,
          "title": "Africa’s biggest photography library opens in Ghana",
          "imageUrl": "https://i.guim.co.uk/img/media/bf050f7d565f2973e32b7f41f52478f8305cd66e/0_483_7229_4338/master/7229.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=09c5b85fd666856af8160d0b4bfb0f1f"
        },
        {
          "id": "https://lemire.me/blog/2022/05/13/avoid-exception-throwing-in-performance-sensitive-code/",
          "author": null,
          "description": "Comments",
          "link": "https://lemire.me/blog/2022/05/13/avoid-exception-throwing-in-performance-sensitive-code/",
          "publishedOn": "2022-12-22T00:53:51.000Z",
          "wordCount": 4442,
          "title": "Avoid exception throwing in performance-sensitive code",
          "imageUrl": "https://lemire.me/img/portrait2018facebook.jpg"
        },
        {
          "id": "https://peter.sh/experiments/chromium-command-line-switches/",
          "author": null,
          "description": "Comments",
          "link": "https://peter.sh/experiments/chromium-command-line-switches/",
          "publishedOn": "2022-12-21T23:32:05.000Z",
          "wordCount": 29973,
          "title": "All 1,400 Google Chrome CLI flags",
          "imageUrl": null
        },
        {
          "id": "https://www.pixelmator.com/blog/2022/12/21/pixelmator-pro-gets-a-magical-ai-powered-deband-feature/",
          "author": null,
          "description": "Comments",
          "link": "https://www.pixelmator.com/blog/2022/12/21/pixelmator-pro-gets-a-magical-ai-powered-deband-feature/",
          "publishedOn": "2022-12-21T22:08:56.000Z",
          "wordCount": 1216,
          "title": "Pixelmator Pro gets a magical, AI‑powered Deband feature",
          "imageUrl": "https://pixelmator-blog.s3.amazonaws.com/2022-12-21-pixelmator-pro-introduces-a-magical-deband-feature/img_social.png"
        },
        {
          "id": "https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext",
          "author": null,
          "description": "Comments",
          "link": "https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext",
          "publishedOn": "2022-12-21T22:06:01.000Z",
          "wordCount": 2118,
          "title": "The End of Programming",
          "imageUrl": "https://cacm.acm.org/system/assets/0004/4466/121922_CACMpg34_The-End-of2.large.jpg?1671322023&1671322023"
        },
        {
          "id": "https://nim-lang.org/blog/2022/12/21/version-20-rc.html",
          "author": null,
          "description": "Comments",
          "link": "https://nim-lang.org/blog/2022/12/21/version-20-rc.html",
          "publishedOn": "2022-12-21T21:38:38.000Z",
          "wordCount": 4210,
          "title": "Nim version 2.0.0 release candidate",
          "imageUrl": "https://nim-lang.org/assets/img/twitter_banner.png"
        },
        {
          "id": "https://www.pypy.org/posts/2022/07/toy-optimizer.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.pypy.org/posts/2022/07/toy-optimizer.html",
          "publishedOn": "2022-12-21T21:26:59.000Z",
          "wordCount": 4229,
          "title": "Implementing a Toy Optimizer",
          "imageUrl": null
        },
        {
          "id": "https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html",
          "publishedOn": "2022-12-21T21:12:31.000Z",
          "wordCount": 6044,
          "title": "ChatGPT is a ‘code red’ for Google’s search business",
          "imageUrl": "https://static01.nyt.com/images/2022/12/20/business/00google-killer/00google-killer-facebookJumbo.jpg"
        },
        {
          "id": "https://en.wikipedia.org/wiki/All_American_Five",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/All_American_Five",
          "publishedOn": "2022-12-21T21:10:43.000Z",
          "wordCount": 3554,
          "title": "All American Five radio receivers",
          "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Philco_radio_model_PT44_front.jpg/1200px-Philco_radio_model_PT44_front.jpg"
        },
        {
          "id": "https://james.darpinian.com/blog/how-see-a-satellite-tonight-works",
          "author": null,
          "description": "Comments",
          "link": "https://james.darpinian.com/blog/how-see-a-satellite-tonight-works",
          "publishedOn": "2022-12-21T21:08:49.000Z",
          "wordCount": 4015,
          "title": "How “See a Satellite Tonight” Works",
          "imageUrl": "https://james.darpinian.com/blog/headshot.jpg"
        },
        {
          "id": "https://nld-intern.ds.mpg.de/swingratio/",
          "author": null,
          "description": "Comments",
          "link": "https://nld-intern.ds.mpg.de/swingratio/",
          "publishedOn": "2022-12-21T21:03:51.000Z",
          "wordCount": 997,
          "title": "Swing Ratio",
          "imageUrl": null
        },
        {
          "id": "https://www.fivehundredwordsaday.com/beta",
          "author": null,
          "description": "Comments",
          "link": "https://www.fivehundredwordsaday.com/beta",
          "publishedOn": "2022-12-21T20:29:30.000Z",
          "wordCount": 786,
          "title": "Show HN: Write 500 Words a Day",
          "imageUrl": null
        },
        {
          "id": "https://github.com/LMP88959/NTSC-CRT",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/LMP88959/NTSC-CRT",
          "publishedOn": "2022-12-21T20:22:49.000Z",
          "wordCount": 999,
          "title": "NTSC encoding/decoding in C89 using only integers and fixed point math",
          "imageUrl": "https://opengraph.githubassets.com/0dbb8ffb49ee587315f54c1f46ebe27b2c6e440537aa43db601d2d253604142f/LMP88959/NTSC-CRT"
        },
        {
          "id": "https://brev.dev/blog/ai-wont-replace-you-write-bash",
          "author": null,
          "description": "Comments",
          "link": "https://brev.dev/blog/ai-wont-replace-you-write-bash",
          "publishedOn": "2022-12-21T20:22:16.000Z",
          "wordCount": 1415,
          "title": "Using ChatGPT to make Bash palatable",
          "imageUrl": "https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/thumbnail-main.png"
        },
        {
          "id": "https://www.infoq.com/news/2022/12/openjdk-galahad-Dec22/",
          "author": null,
          "description": "Comments",
          "link": "https://www.infoq.com/news/2022/12/openjdk-galahad-Dec22/",
          "publishedOn": "2022-12-21T19:56:22.000Z",
          "wordCount": 7544,
          "title": "OpenJDK Proposes Project Galahad to Merge GraalVM Native Compilation",
          "imageUrl": "https://cdn.infoq.com/statics_s1_20221220065205/styles/static/images/logo/logo-big.jpg"
        },
        {
          "id": "https://www.philipithomas.com/posts/why-i-built-postcard-a-calmer-alternative-to-social-networks",
          "author": null,
          "description": "Comments",
          "link": "https://www.philipithomas.com/posts/why-i-built-postcard-a-calmer-alternative-to-social-networks",
          "publishedOn": "2022-12-21T19:20:16.000Z",
          "wordCount": 594,
          "title": "Personal newsletters as a calmer alternative to social networks",
          "imageUrl": "https://www.philipithomas.com/posts/why-i-built-postcard-a-calmer-alternative-to-social-networks/og/1671725138"
        },
        {
          "id": "https://github.com/microsoft/checkedc",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/microsoft/checkedc",
          "publishedOn": "2022-12-21T18:29:49.000Z",
          "wordCount": 1378,
          "title": "Checked C",
          "imageUrl": "https://opengraph.githubassets.com/4074f767e37b1fc28d0f9770a1f9bffb913740eb8d2862f44780b5bb2583bcc9/microsoft/checkedc"
        },
        {
          "id": "https://github.com/jnsmalm/pixi3d",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/jnsmalm/pixi3d",
          "publishedOn": "2022-12-21T17:49:36.000Z",
          "wordCount": 2430,
          "title": "Pixi3D – 3D rendering library for the web",
          "imageUrl": "https://opengraph.githubassets.com/a29b7ed8bb4c12ed2b6779e755e8ab6105eb889cce2164e3495ea195722c38a2/jnsmalm/pixi3d"
        },
        {
          "id": "https://mprimi.github.io/portable-secret/",
          "author": null,
          "description": "Comments",
          "link": "https://mprimi.github.io/portable-secret/",
          "publishedOn": "2022-12-21T17:10:28.000Z",
          "wordCount": 819,
          "title": "Show HN: Portable Secret – How I store my secrets and communicate privately",
          "imageUrl": null
        },
        {
          "id": "https://www.ycombinator.com/companies/ciro/jobs",
          "author": null,
          "description": "Comments",
          "link": "https://www.ycombinator.com/companies/ciro/jobs",
          "publishedOn": "2022-12-21T17:00:42.000Z",
          "wordCount": 1959,
          "title": "Ciro (YC S22) hiring a founding back end engineer to build an SMB search engine",
          "imageUrl": "https://bookface-images.s3.amazonaws.com/logos/765d253c1131dca038a6ffed081c22c1ad1c92c5.png?1650821484"
        },
        {
          "id": "https://www.economist.com/interactive/christmas-specials/2022/12/20/the-decline-of-the-city-grid",
          "author": null,
          "description": "Comments",
          "link": "https://www.economist.com/interactive/christmas-specials/2022/12/20/the-decline-of-the-city-grid",
          "publishedOn": "2022-12-21T16:30:46.000Z",
          "wordCount": 2292,
          "title": "The Decline of the City Grid",
          "imageUrl": "https://www.economist.com/interactive/christmas-specials/2022/12/20/the-decline-of-the-city-grid/promo.jpg"
        },
        {
          "id": "https://jami.net/",
          "author": null,
          "description": "Comments",
          "link": "https://jami.net/",
          "publishedOn": "2022-12-21T16:24:30.000Z",
          "wordCount": 577,
          "title": "Jami: Share, Message, Call freely and privately",
          "imageUrl": "https://jami.net/assets/images/logo-jami.jpg"
        },
        {
          "id": "https://arxiv.org/abs/2212.09835",
          "author": null,
          "description": "Comments",
          "link": "https://arxiv.org/abs/2212.09835",
          "publishedOn": "2022-12-21T15:36:07.000Z",
          "wordCount": 458,
          "title": "A non-constructive proof of the Four Colour Theorem",
          "imageUrl": null
        },
        {
          "id": "https://www.nbcphiladelphia.com/news/tech/pay-phone-philadelphia/3452775/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nbcphiladelphia.com/news/tech/pay-phone-philadelphia/3452775/",
          "publishedOn": "2022-12-21T15:26:05.000Z",
          "wordCount": 7714,
          "title": "Philadelphia Phreakers installing free payphone",
          "imageUrl": "https://media.nbcphiladelphia.com/2022/12/This-Philly-Guy-Is-Trying-to-Bring-Back-the-Pay-Phone-Without-the-Pay-Part.jpg?quality=85&strip=all&resize=1200%2C675"
        },
        {
          "id": "https://www.scientificamerican.com/article/scientists-created-male-and-female-cells-from-a-single-person/",
          "author": null,
          "description": "Comments",
          "link": "https://www.scientificamerican.com/article/scientists-created-male-and-female-cells-from-a-single-person/",
          "publishedOn": "2022-12-21T13:30:45.000Z",
          "wordCount": 4500,
          "title": "Scientists generate XX and XY cells from a single person",
          "imageUrl": "https://static.scientificamerican.com/sciam/cache/file/B6487D36-289D-4A0C-9FB6802485113611.jpg"
        },
        {
          "id": "https://realizeengineering.blog/2021/01/20/we-are-drowning-in-information-while-starving-for-wisdom/",
          "author": null,
          "description": "Comments",
          "link": "https://realizeengineering.blog/2021/01/20/we-are-drowning-in-information-while-starving-for-wisdom/",
          "publishedOn": "2022-12-21T13:26:46.000Z",
          "wordCount": 3806,
          "title": "We are drowning in information while starving for wisdom (2021)",
          "imageUrl": "https://realizeengineering.files.wordpress.com/2021/01/lake-maggiore.jpg"
        },
        {
          "id": "https://foon.uk/how-flash-2022/",
          "author": null,
          "description": "Comments",
          "link": "https://foon.uk/how-flash-2022/",
          "publishedOn": "2022-12-21T12:01:57.000Z",
          "wordCount": 4232,
          "title": "I still use Flash",
          "imageUrl": "https://foon.uk/how-flash-2022/thumbs/action.png"
        },
        {
          "id": "https://www.cyclist.co.uk/in-depth/11046/bike-frame-stiffness",
          "author": null,
          "description": "Comments",
          "link": "https://www.cyclist.co.uk/in-depth/11046/bike-frame-stiffness",
          "publishedOn": "2022-12-21T11:59:07.000Z",
          "wordCount": 2765,
          "title": "Bike Frame Stiffness",
          "imageUrl": "https://cyclist.b-cdn.net/sites/cyclist/files/2022/12/stiffness_01.jpg"
        },
        {
          "id": "https://www.apple.com/newsroom/2022/12/apple-launches-freeform-a-powerful-new-app-designed-for-creative-collaboration/",
          "author": null,
          "description": "Comments",
          "link": "https://www.apple.com/newsroom/2022/12/apple-launches-freeform-a-powerful-new-app-designed-for-creative-collaboration/",
          "publishedOn": "2022-12-21T10:37:37.000Z",
          "wordCount": 2627,
          "title": "Freeform: a new app designed for creative collaboration",
          "imageUrl": "https://www.apple.com/newsroom/images/product/apps/standard/Apple-Freeform-hero.jpg.og.jpg?202212211312"
        },
        {
          "id": "https://www.youtube.com/watch?v=bfJY0syocfU",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=bfJY0syocfU",
          "publishedOn": "2022-12-21T10:33:57.000Z",
          "wordCount": null,
          "title": "A swarm of robots built this tunnel [video]",
          "imageUrl": null
        },
        {
          "id": "https://but-her-flies.bearblog.dev/mastodon-is-not-a-good-social-network/",
          "author": null,
          "description": "Comments",
          "link": "https://but-her-flies.bearblog.dev/mastodon-is-not-a-good-social-network/",
          "publishedOn": "2022-12-21T09:15:14.000Z",
          "wordCount": 996,
          "title": "Mastodon's federation model encourages specific instances with peculiar rules",
          "imageUrl": null
        },
        {
          "id": "https://www.alexbond.com.au/understanding-large-format-camera-movements/",
          "author": null,
          "description": "Comments",
          "link": "https://www.alexbond.com.au/understanding-large-format-camera-movements/",
          "publishedOn": "2022-12-21T09:04:50.000Z",
          "wordCount": 11164,
          "title": "Large-format camera movements (2020)",
          "imageUrl": "https://www.alexbond.com.au/wp-content/uploads/2020/04/front-tilt_7772.jpg"
        },
        {
          "id": "https://emilymstark.com/2022/12/18/death-to-the-line-of-death.html",
          "author": null,
          "description": "Comments",
          "link": "https://emilymstark.com/2022/12/18/death-to-the-line-of-death.html",
          "publishedOn": "2022-12-21T00:21:34.000Z",
          "wordCount": 1789,
          "title": "The death of the line of death",
          "imageUrl": null
        },
        {
          "id": "https://themacrocompass.substack.com/p/bank-of-japan-surprise",
          "author": null,
          "description": "Comments",
          "link": "https://themacrocompass.substack.com/p/bank-of-japan-surprise",
          "publishedOn": "2022-12-21T00:09:58.000Z",
          "wordCount": 4612,
          "title": "The recent Bank of Japan meeting and its implications for markets",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1ab2c16d-18c1-43cd-8d1c-7ba570893771_1465x1048.jpeg"
        },
        {
          "id": "https://noidea.dog/glue",
          "author": null,
          "description": "Comments",
          "link": "https://noidea.dog/glue",
          "publishedOn": "2022-12-21T00:00:03.000Z",
          "wordCount": 7559,
          "title": "Being Glue (2019)",
          "imageUrl": "http://static1.squarespace.com/static/5a05ececd55b4165f250f032/t/5cc9ed1ec830253749518ae4/1556737311165/boat-1297042_1280+%281%29.png?format=1500w"
        },
        {
          "id": "https://www.nytimes.com/2022/12/19/books/cormac-mccarthy-food-passenger.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/19/books/cormac-mccarthy-food-passenger.html",
          "publishedOn": "2022-12-20T23:01:44.000Z",
          "wordCount": null,
          "title": "Cormac McCarthy loves a good diner",
          "imageUrl": null
        },
        {
          "id": "https://www.jetpack.io/blog/devbox-0-2-0/",
          "author": null,
          "description": "Comments",
          "link": "https://www.jetpack.io/blog/devbox-0-2-0/",
          "publishedOn": "2022-12-20T22:50:34.000Z",
          "wordCount": 1241,
          "title": "Devbox 0.2.0: Automatic Nix installer, plugins, and background services",
          "imageUrl": "https://res-5.cloudinary.com/jetpack-io/image/upload/q_auto/v1/blog/Devbox-0.2.0.png"
        },
        {
          "id": "https://blog.mozilla.org/en/mozilla/mozilla-launch-fediverse-instance-social-media-alternative/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.mozilla.org/en/mozilla/mozilla-launch-fediverse-instance-social-media-alternative/",
          "publishedOn": "2022-12-20T22:45:36.000Z",
          "wordCount": 1497,
          "title": "Mozilla to explore healthy social media alternative",
          "imageUrl": "https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/11/pocket_best_of_special_collections_stories_1200x800-1200x800.jpg"
        },
        {
          "id": "https://www.sparkfun.com/news/5497",
          "author": null,
          "description": "Comments",
          "link": "https://www.sparkfun.com/news/5497",
          "publishedOn": "2022-12-20T22:42:56.000Z",
          "wordCount": null,
          "title": "LoRa: Field Testing Antennas",
          "imageUrl": null
        },
        {
          "id": "https://cacm.acm.org/blogs/blog-cacm/267674-ais-jurassic-park-moment/fulltext",
          "author": null,
          "description": "Comments",
          "link": "https://cacm.acm.org/blogs/blog-cacm/267674-ais-jurassic-park-moment/fulltext",
          "publishedOn": "2022-12-20T22:32:08.000Z",
          "wordCount": 1791,
          "title": "AI's Jurassic Park Moment",
          "imageUrl": "https://cacm.acm.org/system/assets/0004/4410/121222_Gary_Marcus_Marcus.large.jpg?1670874682&1670874682"
        },
        {
          "id": "https://vgel.me/posts/donut/",
          "author": null,
          "description": "Comments",
          "link": "https://vgel.me/posts/donut/",
          "publishedOn": "2022-12-20T22:00:30.000Z",
          "wordCount": 3879,
          "title": "Signed distance functions in 46 lines of Python",
          "imageUrl": null
        },
        {
          "id": "https://slimemoldtimemold.com/2022/12/20/people-took-some-potassium-and-lost-some-weight/",
          "author": null,
          "description": "Comments",
          "link": "https://slimemoldtimemold.com/2022/12/20/people-took-some-potassium-and-lost-some-weight/",
          "publishedOn": "2022-12-20T21:25:02.000Z",
          "wordCount": 17707,
          "title": "People took some potassium and lost some weight",
          "imageUrl": "https://slimemoldtimemold.files.wordpress.com/2022/12/sirkaysturkeylegss_01-copy.jpg"
        },
        {
          "id": "https://www.newstatesman.com/culture/music/2022/11/well-tempered-clavier-bach-300-years-accidental-masterpiece",
          "author": null,
          "description": "Comments",
          "link": "https://www.newstatesman.com/culture/music/2022/11/well-tempered-clavier-bach-300-years-accidental-masterpiece",
          "publishedOn": "2022-12-20T20:54:41.000Z",
          "wordCount": 4730,
          "title": "Bach’s Accidental Masterpiece",
          "imageUrl": "https://www.newstatesman.com/wp-content/uploads/sites/2/2022/11/202249-Bach.jpg"
        },
        {
          "id": "https://technology.doximity.com/articles/ruby-delights-built-into-the-language",
          "author": null,
          "description": "Comments",
          "link": "https://technology.doximity.com/articles/ruby-delights-built-into-the-language",
          "publishedOn": "2022-12-20T20:51:07.000Z",
          "wordCount": 7338,
          "title": "Ruby delights built into the language",
          "imageUrl": "https://res.cloudinary.com/dhttas9u5/image/upload/c_fill,dpr_2,fl_progressive,h_800,q_auto,w_1600/dsfstuyoarbamkbuls2z.jpg"
        },
        {
          "id": "https://web.law.duke.edu/cspd/publicdomainday/2023/",
          "author": null,
          "description": "Comments",
          "link": "https://web.law.duke.edu/cspd/publicdomainday/2023/",
          "publishedOn": "2022-12-20T20:50:50.000Z",
          "wordCount": 9533,
          "title": "January 1, 2023 is Public Domain Day: Works from 1927 are open to all",
          "imageUrl": "https://web.law.duke.edu/sites/default/files/images/centers/cspd/pdd2023/2023-montage.jpg"
        },
        {
          "id": "https://jorzel.github.io/deep-work-essentialism-in-asynchronous-culture/",
          "author": null,
          "description": "Comments",
          "link": "https://jorzel.github.io/deep-work-essentialism-in-asynchronous-culture/",
          "publishedOn": "2022-12-20T20:12:53.000Z",
          "wordCount": 1375,
          "title": "Deep work. Essentialism in asynchronous culture",
          "imageUrl": null
        },
        {
          "id": "https://potassco.org/",
          "author": null,
          "description": "Comments",
          "link": "https://potassco.org/",
          "publishedOn": "2022-12-20T19:40:28.000Z",
          "wordCount": 240,
          "title": "Potassco: The Answer Set Solving Collection",
          "imageUrl": null
        },
        {
          "id": "https://there.oughta.be/a/game-boy-capture-cartridge",
          "author": null,
          "description": "Comments",
          "link": "https://there.oughta.be/a/game-boy-capture-cartridge",
          "publishedOn": "2022-12-20T17:40:21.000Z",
          "wordCount": 4859,
          "title": "There oughta be a Game Boy capture cartridge",
          "imageUrl": "https://there.oughta.be/assets/images/2022-12-20/youtube.jpg"
        },
        {
          "id": "http://blog.presentandcorrect.com/27986-2",
          "author": null,
          "description": "Comments",
          "link": "http://blog.presentandcorrect.com/27986-2",
          "publishedOn": "2022-12-20T17:34:31.000Z",
          "wordCount": 525,
          "title": "A collection of Soviet control rooms",
          "imageUrl": null
        },
        {
          "id": "https://ourworldindata.org/europe-mammal-comeback",
          "author": null,
          "description": "Comments",
          "link": "https://ourworldindata.org/europe-mammal-comeback",
          "publishedOn": "2022-12-20T17:28:17.000Z",
          "wordCount": 2361,
          "title": "Wild mammals are making a comeback in Europe",
          "imageUrl": "https://ourworldindata.org/uploads/2022/05/European-mammals-thumbnail-768x402.png"
        },
        {
          "id": "https://www.ribbonhealth.com/blog/arik-gaisler-ribbons-new-vp-of-engineering-knows-what-makes-a-successful-tech-team",
          "author": null,
          "description": "Comments",
          "link": "https://www.ribbonhealth.com/blog/arik-gaisler-ribbons-new-vp-of-engineering-knows-what-makes-a-successful-tech-team",
          "publishedOn": "2022-12-20T17:00:01.000Z",
          "wordCount": 1604,
          "title": "Ribbon (YC S17) is hiring engineers who want to simplify healthcare",
          "imageUrl": "https://assets.website-files.com/633f1ce35b02f44cbe97afba/639c8ee075bcb403672cb02f_Screen%20Shot%202022-12-16%20at%2010.29.07%20AM.png"
        },
        {
          "id": "https://finance.yahoo.com/news/wells-fargo-reaches-record-3-135449093.html",
          "author": null,
          "description": "Comments",
          "link": "https://finance.yahoo.com/news/wells-fargo-reaches-record-3-135449093.html",
          "publishedOn": "2022-12-20T16:03:54.000Z",
          "wordCount": 14412,
          "title": "Wells Fargo to pay $3.7B for mistreating customers",
          "imageUrl": "https://s.yimg.com/ny/api/res/1.2/coCTgtsJ5spowFFQVs.cRA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/bloomberg_markets_842/821865e0f63580debe413b0776268422"
        },
        {
          "id": "https://grack.com/blog/2022/12/20/deriving-a-bit-twiddling-hack/",
          "author": null,
          "description": "Comments",
          "link": "https://grack.com/blog/2022/12/20/deriving-a-bit-twiddling-hack/",
          "publishedOn": "2022-12-20T15:26:42.000Z",
          "wordCount": 1720,
          "title": "Deriving a Bit-Twiddling Hack: Signed Integer Overflow",
          "imageUrl": null
        },
        {
          "id": "https://paidlink.to/",
          "author": null,
          "description": "Comments",
          "link": "https://paidlink.to/",
          "publishedOn": "2022-12-20T15:23:07.000Z",
          "wordCount": 297,
          "title": "Show HN: Create a paid link to anything",
          "imageUrl": null
        },
        {
          "id": "https://www.nbcnewyork.com/investigations/face-recognition-tech-gets-girl-scout-mom-booted-from-rockettes-show-due-to-her-employer/4004677/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nbcnewyork.com/investigations/face-recognition-tech-gets-girl-scout-mom-booted-from-rockettes-show-due-to-her-employer/4004677/",
          "publishedOn": "2022-12-20T15:13:47.000Z",
          "wordCount": 10702,
          "title": "Facial recognition tech gets woman booted from Rockettes show due to employer",
          "imageUrl": "https://media.nbcnewyork.com/2022/12/Radio-City-music-Hall-w-insets.jpg?quality=85&strip=all&resize=1200%2C675"
        },
        {
          "id": "https://obsidian.md/canvas",
          "author": null,
          "description": "Comments",
          "link": "https://obsidian.md/canvas",
          "publishedOn": "2022-12-20T15:04:48.000Z",
          "wordCount": 841,
          "title": "Show HN: Obsidian Canvas – An infinite space for your ideas",
          "imageUrl": "https://obsidian.md/images/banner.png"
        },
        {
          "id": "https://maskray.me/blog/2022-12-18-control-flow-integrity",
          "author": null,
          "description": "Comments",
          "link": "https://maskray.me/blog/2022-12-18-control-flow-integrity",
          "publishedOn": "2022-12-20T13:43:10.000Z",
          "wordCount": 3114,
          "title": "Control-flow integrity",
          "imageUrl": null
        },
        {
          "id": "https://tafc.space/qna/the-topologists-world-map/",
          "author": null,
          "description": "Comments",
          "link": "https://tafc.space/qna/the-topologists-world-map/",
          "publishedOn": "2022-12-20T12:05:53.000Z",
          "wordCount": 2163,
          "title": "The topologist’s world map (2020)",
          "imageUrl": null
        },
        {
          "id": "https://robertheaton.com/2018/12/17/wavefunction-collapse-algorithm/",
          "author": null,
          "description": "Comments",
          "link": "https://robertheaton.com/2018/12/17/wavefunction-collapse-algorithm/",
          "publishedOn": "2022-12-20T11:54:23.000Z",
          "wordCount": 2869,
          "title": "The “Wavefunction Collapse” generation algorithm explained clearly (2018)",
          "imageUrl": "https://robertheaton.com/images/wfc-terminal.png"
        },
        {
          "id": "https://github.com/openai/point-e",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/openai/point-e",
          "publishedOn": "2022-12-20T11:15:49.000Z",
          "wordCount": 707,
          "title": "Point-E: Point cloud diffusion for 3D model synthesis",
          "imageUrl": "https://opengraph.githubassets.com/39dcd9b5e33bcf9a49b5d302724e7664ba2d92be531be8df4de94e2ab4b67c11/openai/point-e"
        },
        {
          "id": "https://raw.githubusercontent.com/websnarf/bstrlib/master/bstrlib.txt",
          "author": null,
          "description": "Comments",
          "link": "https://raw.githubusercontent.com/websnarf/bstrlib/master/bstrlib.txt",
          "publishedOn": "2022-12-20T10:39:51.000Z",
          "wordCount": 24293,
          "title": "Better String Library (2015)",
          "imageUrl": null
        },
        {
          "id": "https://www.downtowndougbrown.com/2022/12/upgrading-my-old-chumby-8-linux-kernel-part-1-u-boot/",
          "author": null,
          "description": "Comments",
          "link": "https://www.downtowndougbrown.com/2022/12/upgrading-my-old-chumby-8-linux-kernel-part-1-u-boot/",
          "publishedOn": "2022-12-20T10:18:11.000Z",
          "wordCount": 4803,
          "title": "Upgrading my old Chumby 8 Linux kernel",
          "imageUrl": null
        },
        {
          "id": "https://wiki.c2.com/?ExceptionPatterns",
          "author": null,
          "description": "Comments",
          "link": "https://wiki.c2.com/?ExceptionPatterns",
          "publishedOn": "2022-12-20T08:16:23.000Z",
          "wordCount": 780,
          "title": "Exception Patterns (2013)",
          "imageUrl": null
        },
        {
          "id": "https://www.theregister.com/2022/12/19/in_praise_of_midi_techs/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theregister.com/2022/12/19/in_praise_of_midi_techs/",
          "publishedOn": "2022-12-20T08:11:39.000Z",
          "wordCount": 1749,
          "title": "In praise of MIDI",
          "imageUrl": "https://regmedia.co.uk/2022/12/16/shutterstock_midi.jpg"
        },
        {
          "id": "https://www.theguardian.com/world/2022/dec/19/peru-nazca-plain-ancient-art-new-designs-discovered",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/world/2022/dec/19/peru-nazca-plain-ancient-art-new-designs-discovered",
          "publishedOn": "2022-12-20T07:23:43.000Z",
          "wordCount": 4413,
          "title": "More than 100 new designs discovered in Peru’s ancient Nazca plain",
          "imageUrl": "https://i.guim.co.uk/img/media/d76c9a7f98332ea93a6a146c3286e13f9d6d0b46/0_259_3500_2100/master/3500.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=cce953a9c396da79e0183e1e746e63ef"
        },
        {
          "id": "https://github.com/microsoft/WSA/discussions/167",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/microsoft/WSA/discussions/167",
          "publishedOn": "2022-12-20T01:08:02.000Z",
          "wordCount": 1693,
          "title": "The Windows Subsystem for Android now runs Android 13 in beta",
          "imageUrl": "https://opengraph.githubassets.com/5939b20d240d541c07cc6d48f2f18be4115d040db00197f135c89f2a1d788c8a/microsoft/WSA/discussions/167"
        },
        {
          "id": "https://github.com/google-research/frame-interpolation",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/google-research/frame-interpolation",
          "publishedOn": "2022-12-20T00:11:30.000Z",
          "wordCount": 1772,
          "title": "FILM: Frame Interpolation for Large Motion",
          "imageUrl": "https://opengraph.githubassets.com/7469e768e44052f8e7bcacd1b3278324cff437afc72572d1ff8dd0fd1ad8d357/google-research/frame-interpolation"
        },
        {
          "id": "https://www.bloomberg.com/news/articles/2022-12-19/two-charged-with-using-amazon-ring-cameras-in-nationwide-swatting-spree",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/articles/2022-12-19/two-charged-with-using-amazon-ring-cameras-in-nationwide-swatting-spree",
          "publishedOn": "2022-12-19T23:59:22.000Z",
          "wordCount": 576,
          "title": "Amazon Ring cameras used in nationwide ‘swatting’ spree, US Justice Dept. says",
          "imageUrl": null
        },
        {
          "id": "https://theforceengine.github.io/",
          "author": null,
          "description": "Comments",
          "link": "https://theforceengine.github.io/",
          "publishedOn": "2022-12-19T23:54:21.000Z",
          "wordCount": 789,
          "title": "The Force Engine v1.0 Released",
          "imageUrl": null
        },
        {
          "id": "https://lemire.me/blog/2022/12/19/implementing-strlen-using-sve/",
          "author": null,
          "description": "Comments",
          "link": "https://lemire.me/blog/2022/12/19/implementing-strlen-using-sve/",
          "publishedOn": "2022-12-19T22:44:36.000Z",
          "wordCount": 3447,
          "title": "Implementing ‘strlen’ using SVE",
          "imageUrl": "https://lemire.me/img/portrait2018facebook.jpg"
        },
        {
          "id": "https://github.com/facebook/zstd",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/facebook/zstd",
          "publishedOn": "2022-12-19T22:31:47.000Z",
          "wordCount": 2005,
          "title": "Zstandard – Fast real-time compression algorithm",
          "imageUrl": "https://opengraph.githubassets.com/5c85202b23def8995514f646edab958cc264c26fdcfae3e8cfa8cefb4a6604a1/facebook/zstd"
        },
        {
          "id": "https://phys.org/news/2022-12-isotopic-signatures-ryugu-comets-unique.html",
          "author": null,
          "description": "Comments",
          "link": "https://phys.org/news/2022-12-isotopic-signatures-ryugu-comets-unique.html",
          "publishedOn": "2022-12-19T22:30:12.000Z",
          "wordCount": 1880,
          "title": "Ryugu isotopes suggest it formed close to comets along with some unique minerals",
          "imageUrl": "https://scx2.b-cdn.net/gfx/news/hires/2022/isotopic-signatures-in.jpg"
        },
        {
          "id": "https://borretti.me/article/astronomical-calculations-for-hard-sf-common-lisp",
          "author": null,
          "description": "Comments",
          "link": "https://borretti.me/article/astronomical-calculations-for-hard-sf-common-lisp",
          "publishedOn": "2022-12-19T22:27:53.000Z",
          "wordCount": 4941,
          "title": "Astronomical Calculations for Hard SF in Common Lisp",
          "imageUrl": "https://borretti.me/assets/card/astronomical-calculations-hard-sf-common-lisp.jpg"
        },
        {
          "id": "https://www.sigarch.org/fast-memcpy-a-system-design/",
          "author": null,
          "description": "Comments",
          "link": "https://www.sigarch.org/fast-memcpy-a-system-design/",
          "publishedOn": "2022-12-19T22:07:45.000Z",
          "wordCount": 3677,
          "title": "Fast memcpy, A System Design",
          "imageUrl": "https://www.sigarch.org/wp-content/uploads/2022/12/monk_copying_rounded.png"
        },
        {
          "id": "https://jakecoppinger.com/2022/12/sydney-cbd-is-bringing-back-pedestrian-beg-buttons/",
          "author": null,
          "description": "Comments",
          "link": "https://jakecoppinger.com/2022/12/sydney-cbd-is-bringing-back-pedestrian-beg-buttons/",
          "publishedOn": "2022-12-19T21:29:55.000Z",
          "wordCount": 2899,
          "title": "Sydney CBD is bringing back pedestrian “beg buttons”",
          "imageUrl": "https://jakecoppinger.com/wp-content/uploads/2022/12/IMG_0739-1.jpg"
        },
        {
          "id": "https://www.technologyreview.com/2022/12/19/1065306/roomba-irobot-robot-vacuums-artificial-intelligence-training-data-privacy/",
          "author": null,
          "description": "Comments",
          "link": "https://www.technologyreview.com/2022/12/19/1065306/roomba-irobot-robot-vacuums-artificial-intelligence-training-data-privacy/",
          "publishedOn": "2022-12-19T21:04:59.000Z",
          "wordCount": 15549,
          "title": "How did Roomba-recorded photos end up on Facebook?",
          "imageUrl": "https://wp.technologyreview.com/wp-content/uploads/2022/12/A_3-crop.jpg?resize=1200,600"
        },
        {
          "id": "https://bigthink.com/the-future/cryonics-horror-stories/",
          "author": null,
          "description": "Comments",
          "link": "https://bigthink.com/the-future/cryonics-horror-stories/",
          "publishedOn": "2022-12-19T21:02:55.000Z",
          "wordCount": 4345,
          "title": "What happened to the first cryogenically frozen humans?",
          "imageUrl": "https://bigthink.com/wp-content/uploads/2022/08/headfinal2.jpg?resize=1200,630"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34056812",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34056812",
          "publishedOn": "2022-12-19T19:56:52.000Z",
          "wordCount": 7663,
          "title": "Ask HN: What is the cheapest, easiest way to host a cronjob in 2022?",
          "imageUrl": null
        },
        {
          "id": "https://github.com/dariusk/twitter-archiver",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/dariusk/twitter-archiver",
          "publishedOn": "2022-12-19T19:21:55.000Z",
          "wordCount": 681,
          "title": "Twitter archiver: Make your own simple, public, searchable Twitter archive",
          "imageUrl": "https://opengraph.githubassets.com/f62f86b69a7b3bcef86f5613bb85be4fa49697a570087c91d0f76eb1df317541/dariusk/twitter-archiver"
        },
        {
          "id": "https://www.nature.com/articles/s41578-022-00483-4",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/articles/s41578-022-00483-4",
          "publishedOn": "2022-12-19T19:21:26.000Z",
          "wordCount": 17729,
          "title": "Hydrogel interfaces for merging humans and machines",
          "imageUrl": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41578-022-00483-4/MediaObjects/41578_2022_483_Fig1_HTML.png"
        },
        {
          "id": "https://github.com/Spotifyd/spotifyd",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Spotifyd/spotifyd",
          "publishedOn": "2022-12-19T18:56:38.000Z",
          "wordCount": 862,
          "title": "Spotifyd",
          "imageUrl": "https://opengraph.githubassets.com/ef6e6a882febb41bf1340e499969a621665f7a71dc98076b327b78cddbab3fd2/Spotifyd/spotifyd"
        },
        {
          "id": "https://www.helmholtz-berlin.de/pubbin/news_seite?nid=24348&sprache=en&seitenid=1",
          "author": null,
          "description": "Comments",
          "link": "https://www.helmholtz-berlin.de/pubbin/news_seite?nid=24348&sprache=en&seitenid=1",
          "publishedOn": "2022-12-19T18:51:04.000Z",
          "wordCount": 2027,
          "title": "Tandem solar cell achieves 32.5 percent efficiency",
          "imageUrl": "https://www.helmholtz-berlin.de/pubbin/news_datei?modus=DETAIL&did=15063"
        },
        {
          "id": "https://briancallahan.net/blog/20221219.html",
          "author": null,
          "description": "Comments",
          "link": "https://briancallahan.net/blog/20221219.html",
          "publishedOn": "2022-12-19T18:19:08.000Z",
          "wordCount": 1189,
          "title": "GCC now includes Modula-2 and Rust. Do they work on OpenBSD?",
          "imageUrl": null
        },
        {
          "id": "https://github.com/Infisical/infisical",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Infisical/infisical",
          "publishedOn": "2022-12-19T17:52:20.000Z",
          "wordCount": 1440,
          "title": "Show HN: Infisical – open-source secrets manager",
          "imageUrl": "https://repository-images.githubusercontent.com/521655652/7d1fa6af-1799-411b-a127-ae342e934685"
        },
        {
          "id": "https://blog.tempus-ex.com/hello-video-codec/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.tempus-ex.com/hello-video-codec/",
          "publishedOn": "2022-12-19T17:50:34.000Z",
          "wordCount": 2151,
          "title": "Video codec in 100 lines of Rust",
          "imageUrl": "https://blog.tempus-ex.com/content/images/2021/07/tears_of_steel_12130_vis.jpg"
        },
        {
          "id": "https://www.reuters.com/technology/binances-books-are-black-box-filings-show-crypto-giant-tries-rally-confidence-2022-12-19/",
          "author": null,
          "description": "Comments",
          "link": "https://www.reuters.com/technology/binances-books-are-black-box-filings-show-crypto-giant-tries-rally-confidence-2022-12-19/",
          "publishedOn": "2022-12-19T17:48:02.000Z",
          "wordCount": 10508,
          "title": "Binance's books are a black box, filings show, as it tries to rally confidence",
          "imageUrl": "https://www.reuters.com/resizer/-hT9_WQK-v6DeN7BZhcp16_kjb0=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/GDB4YV3UQFNHJMGZVA7FACCKJ4.jpg"
        },
        {
          "id": "https://www.treehugger.com/how-cook-any-whole-grain-popcorn-4858738",
          "author": null,
          "description": "Comments",
          "link": "https://www.treehugger.com/how-cook-any-whole-grain-popcorn-4858738",
          "publishedOn": "2022-12-19T17:22:07.000Z",
          "wordCount": 3519,
          "title": "Cook whole grains like popcorn (2018)",
          "imageUrl": "https://www.treehugger.com/thmb/gumtqbzn5Tdl_vrT7-4X0cLPXfw=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/__opt__aboutcom__coeus__resources__content_migration__treehugger__images__2017__02__popped-buckwheat-fa9e68517fb4462a863437ac17157609.jpg"
        },
        {
          "id": "https://biosrhythm.com/?p=2224",
          "author": null,
          "description": "Comments",
          "link": "https://biosrhythm.com/?p=2224",
          "publishedOn": "2022-12-19T17:10:59.000Z",
          "wordCount": 1568,
          "title": "Commodore PET 2001 repair",
          "imageUrl": null
        },
        {
          "id": "https://www.tomscott.com/corrections/firemarks/",
          "author": null,
          "description": "Comments",
          "link": "https://www.tomscott.com/corrections/firemarks/",
          "publishedOn": "2022-12-19T16:09:33.000Z",
          "wordCount": 6267,
          "title": "Did insurance fire brigades let uninsured buildings burn?",
          "imageUrl": null
        },
        {
          "id": "https://yogthos.net/posts/2022-12-18-StructuringClojureApplications.html",
          "author": null,
          "description": "Comments",
          "link": "https://yogthos.net/posts/2022-12-18-StructuringClojureApplications.html",
          "publishedOn": "2022-12-19T14:16:51.000Z",
          "wordCount": 1714,
          "title": "Structuring Clojure applications",
          "imageUrl": null
        },
        {
          "id": "https://www.australiangeographic.com.au/news/2022/12/discovery-identifies-australia-as-birthplace-of-all-modern-mammals/",
          "author": null,
          "description": "Comments",
          "link": "https://www.australiangeographic.com.au/news/2022/12/discovery-identifies-australia-as-birthplace-of-all-modern-mammals/",
          "publishedOn": "2022-12-19T13:39:34.000Z",
          "wordCount": 2927,
          "title": "Evidence that the evolution of mammals began in the Southern Hemisphere",
          "imageUrl": "https://www.australiangeographic.com.au/wp-content/uploads/2022/12/thumbnail_image001-1.jpg"
        },
        {
          "id": "https://github.com/open-pdf-sign/open-pdf-sign",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/open-pdf-sign/open-pdf-sign",
          "publishedOn": "2022-12-19T13:15:40.000Z",
          "wordCount": 1138,
          "title": "Digitally sign PDF files from your commandline – open-pdf-sign",
          "imageUrl": "https://opengraph.githubassets.com/d8c566214a21fe84ef60ad9f2c7c171f3dd318fcfcafa95171a0a7ee7b27d3cc/open-pdf-sign/open-pdf-sign"
        },
        {
          "id": "https://www.cnbc.com/2022/12/19/dont-want-to-travel-many-in-japan-say-theyll-never-travel-again.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.cnbc.com/2022/12/19/dont-want-to-travel-many-in-japan-say-theyll-never-travel-again.html",
          "publishedOn": "2022-12-19T00:58:22.000Z",
          "wordCount": 22154,
          "title": "35% of Japanese people say they’ll ‘never travel’ again",
          "imageUrl": "https://image.cnbcfm.com/api/v1/image/107166649-1671083587492-gettyimages-1220908117-2404familyeps.jpeg?v=1671404521&w=1920&h=1080"
        },
        {
          "id": "https://github.com/numpy/numpy/releases/tag/v1.24.0",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/numpy/numpy/releases/tag/v1.24.0",
          "publishedOn": "2022-12-19T00:31:09.000Z",
          "wordCount": 2757,
          "title": "NumPy 1.24 Release Notes",
          "imageUrl": "https://opengraph.githubassets.com/629abf17c6c3c961d791b127e7342580c2ce285ac2c5bf5dfcafb17181f18077/numpy/numpy/releases/tag/v1.24.0"
        },
        {
          "id": "https://www.nytimes.com/2022/12/16/us/marion-smith-dead.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/16/us/marion-smith-dead.html",
          "publishedOn": "2022-12-18T23:32:53.000Z",
          "wordCount": null,
          "title": "Marion Smith, the world’s most prolific cave explorer, dies at 80",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/elonmusk/status/1604617643973124097",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/elonmusk/status/1604617643973124097",
          "publishedOn": "2022-12-18T23:21:52.000Z",
          "wordCount": 470,
          "title": "Should I step down as head of Twitter? I will abide by the results of this poll",
          "imageUrl": null
        },
        {
          "id": "https://www.nytimes.com/2022/12/18/business/media/amc-networks-streaming-cable.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/18/business/media/amc-networks-streaming-cable.html",
          "publishedOn": "2022-12-18T22:46:07.000Z",
          "wordCount": null,
          "title": "What AMC’s streaming troubles say about the greater TV industry",
          "imageUrl": null
        },
        {
          "id": "https://www.uber.com/blog/devpod-improving-developer-productivity-at-uber/",
          "author": null,
          "description": "Comments",
          "link": "https://www.uber.com/blog/devpod-improving-developer-productivity-at-uber/",
          "publishedOn": "2022-12-18T22:44:26.000Z",
          "wordCount": 4051,
          "title": "Devpod: Remote development environment at Uber",
          "imageUrl": "https://blogapi.uber.com/wp-content/uploads/2022/12/My-project-1.png"
        },
        {
          "id": "https://twitter.com/paulg/",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/paulg/",
          "publishedOn": "2022-12-18T22:01:58.000Z",
          "wordCount": 470,
          "title": "Twitter suspends pg's account [fixed]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/electronicarts/EAStdC/blob/master/include/EAStdC/EABitTricks.h",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/electronicarts/EAStdC/blob/master/include/EAStdC/EABitTricks.h",
          "publishedOn": "2022-12-18T21:01:53.000Z",
          "wordCount": 8141,
          "title": "EABitTricks.h",
          "imageUrl": "https://opengraph.githubassets.com/3ddb3f8c0a914b02747903ca596eb8a67e3f59545456691120e9f78423d8c90c/electronicarts/EAStdC"
        },
        {
          "id": "https://www.atlasobscura.com/articles/perpetual-broth",
          "author": null,
          "description": "Comments",
          "link": "https://www.atlasobscura.com/articles/perpetual-broth",
          "publishedOn": "2022-12-18T20:47:15.000Z",
          "wordCount": 6587,
          "title": "‘Perpetual broths’ that simmer for decades",
          "imageUrl": "https://img.atlasobscura.com/VK5gLZf7_G890o26kDAi0IfsF8mXcY0qXyUOUZM9wvA/rt:fit/w:600/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy8zMjg4NDcyMy0y/YTE0LTRmMDItODhl/MS1jNGI0ZWU5MmVi/YjMwYWNjYTNiZTJl/NWRhYjgwZjZfYnJv/dGguanBn.jpg"
        },
        {
          "id": "https://news.bloombergtax.com/daily-tax-report/irs-accidentally-releases-112-000-taxpayers-private-data-again",
          "author": null,
          "description": "Comments",
          "link": "https://news.bloombergtax.com/daily-tax-report/irs-accidentally-releases-112-000-taxpayers-private-data-again",
          "publishedOn": "2022-12-18T20:45:57.000Z",
          "wordCount": 10665,
          "title": "IRS accidentally releases taxpayers’ private data again",
          "imageUrl": "https://db0ip7zd23b50.cloudfront.net/dims4/default/8a0cc58/2147483647/legacy_thumbnail/960x369%3E/quality/90/?url=http%3A%2F%2Fbloomberg-bna-brightspot.s3.amazonaws.com%2F6a%2Fdf%2Ff833e8244c958961a11fd6edb99a%2Fbli-irs-abstract-form.png"
        },
        {
          "id": "http://oldvcr.blogspot.com/2022/12/a-minor-memorial-for-leo-laporte-on.html",
          "author": null,
          "description": "Comments",
          "link": "http://oldvcr.blogspot.com/2022/12/a-minor-memorial-for-leo-laporte-on.html",
          "publishedOn": "2022-12-18T20:34:51.000Z",
          "wordCount": 3894,
          "title": "A minor memorial for Leo Laporte on terrestrial AM radio",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXgLPH-lXdjevTnmXNk7P2QQTytZ-4hjgE2BR7lFmxoiXGItZRJgkj9o29JdN7DEGqb7gEgFQuPEGT332sSxDRTif_Wbhjw88K33FPSnag8dxdEgI1-v27yEr3qHemR5HXIPRt6H8QyoKvBnCNISJT0lZE_MME1LdOBUxmbm-NzNO9vxSqIkdIU9sj/w1200-h630-p-k-no-nu/IMG_20110430_100602.jpg"
        },
        {
          "id": "https://github.com/Lartsch/FediAct",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Lartsch/FediAct",
          "publishedOn": "2022-12-18T20:19:20.000Z",
          "wordCount": 1792,
          "title": "Browser extension that lets you follow accounts on foreign Mastodon instances",
          "imageUrl": "https://opengraph.githubassets.com/2bfaca638e36d9a98e9fe1db7bfc136975e32ce30fa4c3f902132aeee1f4cebf/Lartsch/FediAct"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34041962",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34041962",
          "publishedOn": "2022-12-18T19:38:56.000Z",
          "wordCount": 19917,
          "title": "Ask HN: Anyone tired of everything being a subscription now?",
          "imageUrl": null
        },
        {
          "id": "https://dan.bulwinkle.net/blog/government-should-incentivize-green-builders/",
          "author": null,
          "description": "Comments",
          "link": "https://dan.bulwinkle.net/blog/government-should-incentivize-green-builders/",
          "publishedOn": "2022-12-18T19:34:22.000Z",
          "wordCount": 1010,
          "title": "Government should incentivize high performance home builders",
          "imageUrl": null
        },
        {
          "id": "https://www.hillelwayne.com/post/influential-dead-languages/",
          "author": null,
          "description": "Comments",
          "link": "https://www.hillelwayne.com/post/influential-dead-languages/",
          "publishedOn": "2022-12-18T18:04:52.000Z",
          "wordCount": 3727,
          "title": "Ten influential programming languages (2020)",
          "imageUrl": null
        },
        {
          "id": "https://www.theregister.com/2022/12/16/apple_decoy_labor_group/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theregister.com/2022/12/16/apple_decoy_labor_group/",
          "publishedOn": "2022-12-18T18:02:54.000Z",
          "wordCount": 1436,
          "title": "Apple 'created decoy labor group' to derail unionization",
          "imageUrl": "https://regmedia.co.uk/2022/12/16/shutterstock_apple_store.jpg"
        },
        {
          "id": "https://jobs.ashbyhq.com/motion?utm_source=hn",
          "author": null,
          "description": "Comments",
          "link": "https://jobs.ashbyhq.com/motion?utm_source=hn",
          "publishedOn": "2022-12-18T17:03:12.000Z",
          "wordCount": 293,
          "title": "Motion (YC W20) Is Hiring Senior Fullstack Engineers",
          "imageUrl": "https://app.ashbyhq.com/api/images/org-theme-social/fd4042c5-a696-4b26-9058-2ac8131c2d75/fab07bab-a363-44f7-8435-32f76868d3d3.png"
        },
        {
          "id": "https://youtubetranscript.com/",
          "author": null,
          "description": "Comments",
          "link": "https://youtubetranscript.com/",
          "publishedOn": "2022-12-18T16:38:03.000Z",
          "wordCount": 1489,
          "title": "YouTube Transcript – read YouTube videos",
          "imageUrl": null
        },
        {
          "id": "https://www.vulture.com/article/hbo-max-warner-cancelations-disappearing-tv-streaming-future.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.vulture.com/article/hbo-max-warner-cancelations-disappearing-tv-streaming-future.html",
          "publishedOn": "2022-12-18T16:31:33.000Z",
          "wordCount": 28654,
          "title": "TV disappears, but HBO Max removing shows feels different",
          "imageUrl": "https://pyxis.nymag.com/v1/imgs/fac/c79/12120b9eece74f545a774051fd71075f0b-erased.1x.rsocial.w1200.jpg"
        },
        {
          "id": "https://curiositysink.substack.com/p/everything-as-a-service",
          "author": null,
          "description": "Comments",
          "link": "https://curiositysink.substack.com/p/everything-as-a-service",
          "publishedOn": "2022-12-18T16:10:44.000Z",
          "wordCount": 6153,
          "title": "Everything as a Service",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4a032bf0-f180-4cdd-a021-6439f1c6a932_1224x916.png"
        },
        {
          "id": "https://www.retrotechnology.com/dri/howto_cpm.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.retrotechnology.com/dri/howto_cpm.html",
          "publishedOn": "2022-12-18T16:08:44.000Z",
          "wordCount": 7794,
          "title": "How to Start with CP/M",
          "imageUrl": null
        },
        {
          "id": "https://www.youtube.com/watch?v=386p68_lDHA",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=386p68_lDHA",
          "publishedOn": "2022-12-18T16:05:20.000Z",
          "wordCount": null,
          "title": "Investigating Logan Paul's biggest scam [video]",
          "imageUrl": null
        },
        {
          "id": "https://cassandradispatch.org/richard-feynman-on-looking-at-the-world-from-another-point-of-view/",
          "author": null,
          "description": "Comments",
          "link": "https://cassandradispatch.org/richard-feynman-on-looking-at-the-world-from-another-point-of-view/",
          "publishedOn": "2022-12-18T15:51:45.000Z",
          "wordCount": 261,
          "title": "Richard Feynman on looking at the world from another point of view (1973)",
          "imageUrl": null
        },
        {
          "id": "https://fivethirtyeight.com/features/lionel-messi-is-impossible/",
          "author": null,
          "description": "Comments",
          "link": "https://fivethirtyeight.com/features/lionel-messi-is-impossible/",
          "publishedOn": "2022-12-18T15:07:43.000Z",
          "wordCount": 5713,
          "title": "Lionel Messi Is Impossible (2014)",
          "imageUrl": "https://fivethirtyeight.com/wp-content/uploads/2014/06/messi_lede.jpg?w=596"
        },
        {
          "id": "https://www.youtube.com/watch?v=iKmXQAupWzM",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=iKmXQAupWzM",
          "publishedOn": "2022-12-18T14:55:33.000Z",
          "wordCount": null,
          "title": "Zilog Z8000 Coprocessor for the IBM PC by Sweet Micro Systems [video]",
          "imageUrl": null
        },
        {
          "id": "https://slate.com/news-and-politics/2000/06/the-unluckiest-man-in-movie-history.html",
          "author": null,
          "description": "Comments",
          "link": "https://slate.com/news-and-politics/2000/06/the-unluckiest-man-in-movie-history.html",
          "publishedOn": "2022-12-18T08:51:38.000Z",
          "wordCount": 20439,
          "title": "The Unluckiest Man in Movie History (2000)",
          "imageUrl": "https://slate.com/media/sites/slate-com/icon.400x400.png"
        },
        {
          "id": "https://queue.acm.org/detail.cfm?id=3570937",
          "author": null,
          "description": "Comments",
          "link": "https://queue.acm.org/detail.cfm?id=3570937",
          "publishedOn": "2022-12-18T07:45:04.000Z",
          "wordCount": 5755,
          "title": "Reinventing backend subsetting at Google",
          "imageUrl": null
        },
        {
          "id": "https://devblogs.microsoft.com/oldnewthing/20221216-00/?p=107598",
          "author": null,
          "description": "Comments",
          "link": "https://devblogs.microsoft.com/oldnewthing/20221216-00/?p=107598",
          "publishedOn": "2022-12-18T06:28:16.000Z",
          "wordCount": 5574,
          "title": "Why doesn’t Windows use 64-bit virtual address space below 0x00000000`7ffe0000?",
          "imageUrl": "https://devblogs.microsoft.com/oldnewthing/wp-content/uploads/sites/38/2019/02/ShowCover.jpg"
        },
        {
          "id": "https://bolinlang.com/does-it-inline",
          "author": null,
          "description": "Comments",
          "link": "https://bolinlang.com/does-it-inline",
          "publishedOn": "2022-12-17T23:56:51.000Z",
          "wordCount": 980,
          "title": "Does It Inline?",
          "imageUrl": null
        },
        {
          "id": "https://www.nature.com/immersive/d41586-022-03810-5/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/immersive/d41586-022-03810-5/index.html",
          "publishedOn": "2022-12-17T23:33:43.000Z",
          "wordCount": 17704,
          "title": "The human cost of neurotechnology failure",
          "imageUrl": "https://www.nature.com/immersive/d41586-022-03810-5/assets/uTphz5EWeS/2022-12-06_outlook_neurotech_1_bohle-lede_sm-1066x600.jpg"
        },
        {
          "id": "https://www.pointsdevue.com/article/record-high-myopia-solved-alliance-experts-10800-d",
          "author": null,
          "description": "Comments",
          "link": "https://www.pointsdevue.com/article/record-high-myopia-solved-alliance-experts-10800-d",
          "publishedOn": "2022-12-17T23:13:10.000Z",
          "wordCount": 3177,
          "title": "The record-breaking -108.00 diopter myopia lenses (2016)",
          "imageUrl": "https://www.pointsdevue.com/sites/default/files/content-images/article/201606/fig7-lens-mounting-copie.jpg"
        },
        {
          "id": "https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html",
          "author": null,
          "description": "Comments",
          "link": "https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html",
          "publishedOn": "2022-12-17T22:18:36.000Z",
          "wordCount": 2852,
          "title": "Copilot Internals",
          "imageUrl": null
        },
        {
          "id": "https://spectrum.ieee.org/the-golden-age-of-basic",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/the-golden-age-of-basic",
          "publishedOn": "2022-12-17T22:17:26.000Z",
          "wordCount": 13452,
          "title": "The Golden Age of Basic (2014)",
          "imageUrl": "https://spectrum.ieee.org/media-library/kids-try-out-a-commodore-64-in-nuremberg-in-may-1985.jpg?id=25575163&width=1200&height=600&coordinates=0%2C77%2C0%2C78"
        },
        {
          "id": "https://www.youtube.com/watch?v=oeqPrUmVz-o",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=oeqPrUmVz-o",
          "publishedOn": "2022-12-17T21:58:47.000Z",
          "wordCount": null,
          "title": "Steve Jobs Insult Response (1997) [video]",
          "imageUrl": null
        },
        {
          "id": "https://www.useragents.me/",
          "author": null,
          "description": "Comments",
          "link": "https://www.useragents.me/",
          "publishedOn": "2022-12-17T21:50:08.000Z",
          "wordCount": 2673,
          "title": "A self-updating list of the most current useragents",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34032484",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34032484",
          "publishedOn": "2022-12-17T21:35:21.000Z",
          "wordCount": 5299,
          "title": "Tell HN: Google is correlating location data to your IP",
          "imageUrl": null
        },
        {
          "id": "https://worthdoingbadly.com/macdirtycow/",
          "author": null,
          "description": "Comments",
          "link": "https://worthdoingbadly.com/macdirtycow/",
          "publishedOn": "2022-12-17T21:25:35.000Z",
          "wordCount": 813,
          "title": "Get root on macOS 13.0.1 the macOS Dirty Cow bug",
          "imageUrl": null
        },
        {
          "id": "https://www.netwatchglobal.com/solutions/capture-the-flag-using-osint-techniques/",
          "author": null,
          "description": "Comments",
          "link": "https://www.netwatchglobal.com/solutions/capture-the-flag-using-osint-techniques/",
          "publishedOn": "2022-12-17T20:30:32.000Z",
          "wordCount": 482,
          "title": "Capture the flag using OSINT techniques (2019)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/BishopFox/unredacter",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/BishopFox/unredacter",
          "publishedOn": "2022-12-17T19:58:37.000Z",
          "wordCount": 901,
          "title": "Unredacter: Never use pixelation as a redaction technique",
          "imageUrl": "https://opengraph.githubassets.com/2adb8262fbd999e907ed45eb3ebbac3d5dce3a6a89a0257e024e53baa35d79be/BishopFox/unredacter"
        },
        {
          "id": "https://twitter.com/robinberjon/status/1603834995830816769",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/robinberjon/status/1603834995830816769",
          "publishedOn": "2022-12-17T19:33:17.000Z",
          "wordCount": 470,
          "title": "W3C’s transfer from MIT to non-profit going poorly",
          "imageUrl": null
        },
        {
          "id": "https://spritely.institute/news/growing-a-networked-garden-with-spritely-goblins.html",
          "author": null,
          "description": "Comments",
          "link": "https://spritely.institute/news/growing-a-networked-garden-with-spritely-goblins.html",
          "publishedOn": "2022-12-17T19:17:39.000Z",
          "wordCount": 1887,
          "title": "Growing a Networked Garden with Spritely Goblins",
          "imageUrl": "https://spritely.institute/static/images/spritely-institute-logo-300px.png"
        },
        {
          "id": "https://huberman.rile.yt/",
          "author": null,
          "description": "Comments",
          "link": "https://huberman.rile.yt/",
          "publishedOn": "2022-12-17T18:05:04.000Z",
          "wordCount": 144,
          "title": "Show HN: Factual AI Q&A – Answers based on Huberman Lab transcripts",
          "imageUrl": "https://huberman.rile.yt/img/og.png"
        },
        {
          "id": "https://www.theverge.com/2022/11/21/23471306/apple-books-ios-16-page-flip-animation-sucks",
          "author": null,
          "description": "Comments",
          "link": "https://www.theverge.com/2022/11/21/23471306/apple-books-ios-16-page-flip-animation-sucks",
          "publishedOn": "2022-12-17T17:25:16.000Z",
          "wordCount": 8883,
          "title": "Apple changed how reading books works in iOS 16",
          "imageUrl": "https://cdn.vox-cdn.com/thumbor/s1cejsajVEIJSFOH6DjdVSw9KtU=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24020007/226270_iPHONE_14_PHO_akrales_0030.jpg"
        },
        {
          "id": "https://www.archdaily.com/956906/corviale-a-one-kilometer-residential-complex-in-rome",
          "author": null,
          "description": "Comments",
          "link": "https://www.archdaily.com/956906/corviale-a-one-kilometer-residential-complex-in-rome",
          "publishedOn": "2022-12-17T17:15:44.000Z",
          "wordCount": 10975,
          "title": "Corviale, a one-kilometer residential complex in Rome",
          "imageUrl": "https://images.adsttc.com/media/images/601a/9e9e/f91c/8198/f400/030a/large_jpg/40544632165_391d7a9ac4_o.jpg?1612357266"
        },
        {
          "id": "https://www.bigmessowires.com/2022/12/16/avr-gcc-compiler-makes-questionable-code/",
          "author": null,
          "description": "Comments",
          "link": "https://www.bigmessowires.com/2022/12/16/avr-gcc-compiler-makes-questionable-code/",
          "publishedOn": "2022-12-17T17:12:02.000Z",
          "wordCount": 2948,
          "title": "AVR-GCC Compiler Makes Questionable Code",
          "imageUrl": null
        },
        {
          "id": "https://tweedegolf.nl/en/blog/79/sorting-with-simd",
          "author": null,
          "description": "Comments",
          "link": "https://tweedegolf.nl/en/blog/79/sorting-with-simd",
          "publishedOn": "2022-12-17T16:59:07.000Z",
          "wordCount": 8446,
          "title": "Sorting with SIMD",
          "imageUrl": "https://tweedegolf.nl/images/sortingwithsimd3.png"
        },
        {
          "id": "https://github.com/willmcgugan/textual-markdown",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/willmcgugan/textual-markdown",
          "publishedOn": "2022-12-17T15:50:20.000Z",
          "wordCount": 768,
          "title": "Show HN: Textual Markdown – a Markdown “browser” in the terminal",
          "imageUrl": "https://opengraph.githubassets.com/43cd77ad33d495416f7b2894b6e986c31403c9098e80a3fcbbcdfe8e6cc97ecb/willmcgugan/textual-markdown"
        },
        {
          "id": "https://github.com/ax/apk.sh",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/ax/apk.sh",
          "publishedOn": "2022-12-17T15:38:19.000Z",
          "wordCount": 1121,
          "title": "Apk.sh is a Bash script that makes reverse engineering Android apps easier",
          "imageUrl": "https://opengraph.githubassets.com/95854ef892a1abe041d3cacdf518a36d251cd6a2b0b2e53cac0cdb71fd85e1a2/ax/apk.sh"
        },
        {
          "id": "https://www.tfeb.org/fragments/2022/12/16/the-empty-list/",
          "author": null,
          "description": "Comments",
          "link": "https://www.tfeb.org/fragments/2022/12/16/the-empty-list/",
          "publishedOn": "2022-12-17T15:05:28.000Z",
          "wordCount": 892,
          "title": "The empty list",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/tessalau/status/1604018884662951938",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/tessalau/status/1604018884662951938",
          "publishedOn": "2022-12-17T14:28:10.000Z",
          "wordCount": 470,
          "title": "As winter approaches, here's a story about why hardware is hard",
          "imageUrl": null
        },
        {
          "id": "https://www.economist.com/britain/2022/12/12/the-strange-case-of-britains-demise",
          "author": null,
          "description": "Comments",
          "link": "https://www.economist.com/britain/2022/12/12/the-strange-case-of-britains-demise",
          "publishedOn": "2022-12-17T14:17:58.000Z",
          "wordCount": 22137,
          "title": "The strange case of Britain’s demise",
          "imageUrl": "https://www.economist.com/img/b/1280/720/90/media-assets/image/20221217_BRD001.jpg"
        },
        {
          "id": "https://ittavern.com/getting-started-with-nmap/",
          "author": null,
          "description": "Comments",
          "link": "https://ittavern.com/getting-started-with-nmap/",
          "publishedOn": "2022-12-17T10:15:29.000Z",
          "wordCount": 1714,
          "title": "Getting started with nmap",
          "imageUrl": "https://ittavern.com/images/previewimages/nmap.png"
        },
        {
          "id": "https://hackaday.com/2022/12/16/foot-pedal-ups-vim-productivity-brings-ergonomic-benefits/",
          "author": null,
          "description": "Comments",
          "link": "https://hackaday.com/2022/12/16/foot-pedal-ups-vim-productivity-brings-ergonomic-benefits/",
          "publishedOn": "2022-12-17T08:25:08.000Z",
          "wordCount": 4520,
          "title": "Vim Foot Pedal",
          "imageUrl": "https://hackaday.com/wp-content/uploads/2022/12/finished-outside-e1670992799294.jpeg"
        },
        {
          "id": "https://oldvcr.blogspot.com/2022/12/the-strange-case-of-beos-srs-and-silent.html",
          "author": null,
          "description": "Comments",
          "link": "https://oldvcr.blogspot.com/2022/12/the-strange-case-of-beos-srs-and-silent.html",
          "publishedOn": "2022-12-17T04:41:40.000Z",
          "wordCount": 6740,
          "title": "The strange case of BeOS, SRS and the silent Power Mac 6500",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwHBMB16mdbIEk3ztO_P7egsVoTZ8mEBmK7J3NHhGVokIlK6q1C2xhrV_E2XB_wzY2JCXE7eXom6nk-oqEmXbKakh82xQ1jli4gXZ8GX7RjXH_iVemeKNs1C08ujftw55r1kcUz_4SVizTAtMYOVNaBh4uloClrUPPsNjNI5xE2HGoSEWMWHGYTek2/w1200-h630-p-k-no-nu/IMG_20221210_131321.jpg"
        },
        {
          "id": "https://www.newyorker.com/books/under-review/the-man-who-mastered-minor-writing",
          "author": null,
          "description": "Comments",
          "link": "https://www.newyorker.com/books/under-review/the-man-who-mastered-minor-writing",
          "publishedOn": "2022-12-17T03:18:37.000Z",
          "wordCount": 37337,
          "title": "Evan S. Connell mastered minor writing",
          "imageUrl": "https://media.newyorker.com/photos/63974a33c15e2521bb42b8c1/16:9/w_1280,c_limit/Norman_final.jpeg"
        },
        {
          "id": "https://www.circuitvalley.com/2022/06/pensource-usb-c-industrial-camera-c-mount-fpga-imx-mipi-usb-3-crosslinknx.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.circuitvalley.com/2022/06/pensource-usb-c-industrial-camera-c-mount-fpga-imx-mipi-usb-3-crosslinknx.html",
          "publishedOn": "2022-12-17T00:44:00.000Z",
          "wordCount": 9399,
          "title": "Open source USB C camera with C mount lens, MIPI Sensor, Lattice FPGA, USB 3.0",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEineztmEmFegMzFaCr1kmNTqpchNTbrV33iBmQpCceFYxqTpvLPidS6LwYimjdjWfg6ceKlAuNYfntEAkg8j_eB8Th3NTxK_OSKwJvyfmNBU01pzxuJ2HVqMqrk7hXKlHb-7HuoyImV4HrGPNdtk6m6E9Xxt_LXmgnudy48eZPGi56LiLqx_H0bnFxkew/w1200-h630-p-k-no-nu/usb_c_fpga_mipi_camera_c_mount_industrial_lattice_crosslink_fpga_xilinx_zynq%20(4)2.JPG"
        },
        {
          "id": "https://www.facebook.com/100006735798590/posts/i-resigned-from-my-position-as-an-executive-consultant-for-vr-with-meta-my-inter/3467566940144465/",
          "author": null,
          "description": "Comments",
          "link": "https://www.facebook.com/100006735798590/posts/i-resigned-from-my-position-as-an-executive-consultant-for-vr-with-meta-my-inter/3467566940144465/",
          "publishedOn": "2022-12-17T00:10:36.000Z",
          "wordCount": 154,
          "title": "John Carmack Leaves Meta",
          "imageUrl": null
        },
        {
          "id": "https://www.businessinsider.com/john-carmack-meta-consulting-cto-virtual-reality-leaving-2022-12",
          "author": null,
          "description": "Comments",
          "link": "https://www.businessinsider.com/john-carmack-meta-consulting-cto-virtual-reality-leaving-2022-12",
          "publishedOn": "2022-12-17T00:10:36.000Z",
          "wordCount": 3652,
          "title": "John Carmack Leaves Meta",
          "imageUrl": "https://i.insider.com/639cf7e6b5600000185b2e51?width=1200&format=jpeg"
        },
        {
          "id": "https://www.sciencedirect.com/science/article/pii/S0149763422003839",
          "author": null,
          "description": "Comments",
          "link": "https://www.sciencedirect.com/science/article/pii/S0149763422003839",
          "publishedOn": "2022-12-16T23:00:15.000Z",
          "wordCount": 7688,
          "title": "Schizophrenia: The new etiological synthesis",
          "imageUrl": "https://ars.els-cdn.com/content/image/1-s2.0-S0149763422003839-ga1.jpg"
        },
        {
          "id": "https://www.humanesociety.org/news/congress-passes-legislation-end-us-participation-global-shark-fin-trade",
          "author": null,
          "description": "Comments",
          "link": "https://www.humanesociety.org/news/congress-passes-legislation-end-us-participation-global-shark-fin-trade",
          "publishedOn": "2022-12-16T22:25:10.000Z",
          "wordCount": 2027,
          "title": "Congress passes legislation to end US participation in global shark fin trade",
          "imageUrl": "https://www.humanesociety.org/sites/default/files/2018/11/HSUS-logo-share-image.jpg"
        },
        {
          "id": "https://www.monkeon.co.uk/90s-web-humor-button/",
          "author": null,
          "description": "Comments",
          "link": "https://www.monkeon.co.uk/90s-web-humor-button/",
          "publishedOn": "2022-12-16T22:16:38.000Z",
          "wordCount": 839,
          "title": "90s Web \"Humor\" Button",
          "imageUrl": "https://www.monkeon.co.uk/90s-web-humor-button/fb.jpg"
        },
        {
          "id": "https://www.nytimes.com/2022/12/14/arts/thomas-pynchon-huntington-archive.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/14/arts/thomas-pynchon-huntington-archive.html",
          "publishedOn": "2022-12-16T22:15:05.000Z",
          "wordCount": null,
          "title": "Thomas Pynchon, famously private, sells his archive",
          "imageUrl": null
        },
        {
          "id": "https://www.latimes.com/environment/story/2022-12-16/risk-of-dead-pool-looms-at-colorado-river-meeting",
          "author": null,
          "description": "Comments",
          "link": "https://www.latimes.com/environment/story/2022-12-16/risk-of-dead-pool-looms-at-colorado-river-meeting",
          "publishedOn": "2022-12-16T22:13:55.000Z",
          "wordCount": 6281,
          "title": "Fears of ‘dead pool’ on Colorado River as drought threatens Hoover Dam water",
          "imageUrl": "https://ca-times.brightspotcdn.com/dims4/default/8a23f3c/2147483647/strip/true/crop/5472x2873+0+388/resize/1200x630!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Feb%2F1b%2F077149ae4618abfed8c14ac3bfa6%2F1171603-la-na-vegas-drought-lake-mead-28-gmf.jpg"
        },
        {
          "id": "https://hashman.ca/tunnels/",
          "author": null,
          "description": "Comments",
          "link": "https://hashman.ca/tunnels/",
          "publishedOn": "2022-12-16T21:58:38.000Z",
          "wordCount": 161,
          "title": "UWaterloo Steam Tunnels (2016)",
          "imageUrl": "https://hashman.ca/images/tunnels/tunnels_00.jpg"
        },
        {
          "id": "https://github.com/WordPress/performance/pull/547",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/WordPress/performance/pull/547",
          "publishedOn": "2022-12-16T21:36:45.000Z",
          "wordCount": 3676,
          "title": "WordPress testing official SQLite Support",
          "imageUrl": "https://opengraph.githubassets.com/c33f11d7743ecc499235183e20fc3aa4c36ea2c679bf14307c3054c0b2cd8b3f/WordPress/performance/pull/547"
        },
        {
          "id": "https://death.andgravity.com/pwned",
          "author": null,
          "description": "Comments",
          "link": "https://death.andgravity.com/pwned",
          "publishedOn": "2022-12-16T20:42:40.000Z",
          "wordCount": 4579,
          "title": "I almost failed to search a 37 GB text file in under 1 millisecond",
          "imageUrl": null
        },
        {
          "id": "https://github.com/norvig/pytudes/blob/main/ipynb/AlphaCode.ipynb",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/norvig/pytudes/blob/main/ipynb/AlphaCode.ipynb",
          "publishedOn": "2022-12-16T20:38:57.000Z",
          "wordCount": 411,
          "title": "Peter Norvig critically reviews AlphaCode's code quality",
          "imageUrl": "https://opengraph.githubassets.com/d1373329877b78ac968c856e72bb3cd80df80b0b02c724c81f7faabf66aca225/norvig/pytudes"
        },
        {
          "id": "https://legacyupdate.net/",
          "author": null,
          "description": "Comments",
          "link": "https://legacyupdate.net/",
          "publishedOn": "2022-12-16T20:30:42.000Z",
          "wordCount": 690,
          "title": "Legacy Update: Fix Windows Update on Windows XP, Vista, Server 2008, 2003, 2000",
          "imageUrl": "https://legacyupdate.net/banner.png"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34019486",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34019486",
          "publishedOn": "2022-12-16T20:01:08.000Z",
          "wordCount": 11768,
          "title": "Ask HN: How do you protect your children from internet addiction?",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34017934",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34017934",
          "publishedOn": "2022-12-16T18:07:26.000Z",
          "wordCount": 4128,
          "title": "Ask HN: Anyone using proprietary Unix at work?",
          "imageUrl": null
        },
        {
          "id": "https://retractionwatch.com/2022/12/12/mathematician-withdraws-preprint-24-years-after-initial-submission/",
          "author": null,
          "description": "Comments",
          "link": "https://retractionwatch.com/2022/12/12/mathematician-withdraws-preprint-24-years-after-initial-submission/",
          "publishedOn": "2022-12-16T17:23:42.000Z",
          "wordCount": 2731,
          "title": "Mathematician withdraws preprint 24 years after initial submission",
          "imageUrl": "https://retractionwatch.com/wp-content/uploads/2022/12/arxiv-logo-1-1024x461-1.png"
        },
        {
          "id": "https://www.ycombinator.com/companies/emerge-tools/jobs/5Y3MCJi-senior-mobile-engineer-remote",
          "author": null,
          "description": "Comments",
          "link": "https://www.ycombinator.com/companies/emerge-tools/jobs/5Y3MCJi-senior-mobile-engineer-remote",
          "publishedOn": "2022-12-16T17:00:44.000Z",
          "wordCount": 2841,
          "title": "Emerge (YC W21) is hiring engineers to build the future of mobile development",
          "imageUrl": "https://bookface-images.s3.amazonaws.com/logos/951c5580d5432093d2a1f23a2ba9c548dceb5fe1.png?1633041436"
        },
        {
          "id": "https://github.com/google/osv-scanner",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/google/osv-scanner",
          "publishedOn": "2022-12-16T16:10:24.000Z",
          "wordCount": 1646,
          "title": "Vulnerability scanner written in Go that uses osv.dev data",
          "imageUrl": "https://opengraph.githubassets.com/bc85806b365e0e4ae5e5661926ccbad0d1e4933414e79dab9c4ac0bdcf6f8dc8/google/osv-scanner"
        },
        {
          "id": "https://github.com/google/forma",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/google/forma",
          "publishedOn": "2022-12-16T15:53:49.000Z",
          "wordCount": 1132,
          "title": "Show HN: Forma – An efficient vector-graphics renderer",
          "imageUrl": "https://opengraph.githubassets.com/ec18447e929ea1a88d712c19c3faf78f90563ff1978ca665ff6e764aa5b27bcd/google/forma"
        },
        {
          "id": "https://pv-magazine-usa.com/2022/12/15/california-pulls-the-plug-on-rooftop-solar/",
          "author": null,
          "description": "Comments",
          "link": "https://pv-magazine-usa.com/2022/12/15/california-pulls-the-plug-on-rooftop-solar/",
          "publishedOn": "2022-12-16T15:18:56.000Z",
          "wordCount": 5576,
          "title": "California pulls the plug on rooftop solar",
          "imageUrl": "https://pv-magazine-usa.com/wp-content/uploads/sites/2/2022/01/Solar_installation_technician_on_rooftop_5392894792-1200x675.jpg"
        },
        {
          "id": "https://jackdevanney.substack.com/p/nuclear-power-is-too-slow",
          "author": null,
          "description": "Comments",
          "link": "https://jackdevanney.substack.com/p/nuclear-power-is-too-slow",
          "publishedOn": "2022-12-16T15:07:27.000Z",
          "wordCount": 4047,
          "title": "Nuclear power is too slow",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5e9d80a9-0b15-412d-bed5-d214913a57ac_1000x600.jpeg"
        },
        {
          "id": "https://www.bloomberg.com/news/articles/2022-12-15/focus-on-employees-not-tech-to-build-high-performing-team",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/articles/2022-12-15/focus-on-employees-not-tech-to-build-high-performing-team",
          "publishedOn": "2022-12-16T14:36:00.000Z",
          "wordCount": 576,
          "title": "Humans hold the key to collaboration no matter how good the software tools",
          "imageUrl": null
        },
        {
          "id": "https://arstechnica.com/science/2022/12/scientists-revisit-kepler-findings-learn-two-planets-are-water-worlds/",
          "author": null,
          "description": "Comments",
          "link": "https://arstechnica.com/science/2022/12/scientists-revisit-kepler-findings-learn-two-planets-are-water-worlds/",
          "publishedOn": "2022-12-16T14:30:16.000Z",
          "wordCount": 1685,
          "title": "Scientists may have found the first water worlds",
          "imageUrl": "https://cdn.arstechnica.net/wp-content/uploads/2022/12/STScI-01GGTAPWRG7MWT5D0CZ48FFW3J-760x380.png"
        },
        {
          "id": "https://www.gwern.net/Turing-complete",
          "author": null,
          "description": "Comments",
          "link": "https://www.gwern.net/Turing-complete",
          "publishedOn": "2022-12-16T14:29:31.000Z",
          "wordCount": 16884,
          "title": "Surprisingly Turing-Complete (2021)",
          "imageUrl": "https://www.gwern.net/static/img/logo/logo-whitebg-large-border.png-530px.jpg"
        },
        {
          "id": "https://element.io/blog/bundesmessenger-is-a-milestone-in-germanys-ground-breaking-vision/",
          "author": null,
          "description": "Comments",
          "link": "https://element.io/blog/bundesmessenger-is-a-milestone-in-germanys-ground-breaking-vision/",
          "publishedOn": "2022-12-16T14:01:38.000Z",
          "wordCount": 1834,
          "title": "BundesMessenger, a secure messenger for Germany’s public administration",
          "imageUrl": "https://element.io/blog/content/images/2022/12/BundesMessenger__blog-1.jpg"
        },
        {
          "id": "https://buildwithhubs.co.uk/",
          "author": null,
          "description": "Comments",
          "link": "https://buildwithhubs.co.uk/",
          "publishedOn": "2022-12-16T13:08:39.000Z",
          "wordCount": 248,
          "title": "Geodesic domes made simple",
          "imageUrl": "https://buildwithhubs.co.uk/img/fb/hubs_den.jpg"
        },
        {
          "id": "https://discuss.ocaml.org/t/ocaml-5-0-0-is-out/10974",
          "author": null,
          "description": "Comments",
          "link": "https://discuss.ocaml.org/t/ocaml-5-0-0-is-out/10974",
          "publishedOn": "2022-12-16T12:21:08.000Z",
          "wordCount": 4022,
          "title": "OCaml 5.0 Multicore is out",
          "imageUrl": "https://global.discourse-cdn.com/business7/uploads/ocaml/original/2X/d/d4dc9fe40b17e2bcced034f9fe103917b7999275.svg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34013643",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34013643",
          "publishedOn": "2022-12-16T12:04:48.000Z",
          "wordCount": 14415,
          "title": "Ask HN: I have diagnosed ADHD and cannot work with Slack anymore – advice?",
          "imageUrl": null
        },
        {
          "id": "https://fabiensanglard.net/a_linux_evening/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://fabiensanglard.net/a_linux_evening/index.html",
          "publishedOn": "2022-12-16T11:09:24.000Z",
          "wordCount": 1392,
          "title": "A Linux Evening",
          "imageUrl": null
        },
        {
          "id": "https://gmt4.github.io/mpvc/",
          "author": null,
          "description": "Comments",
          "link": "https://gmt4.github.io/mpvc/",
          "publishedOn": "2022-12-16T11:03:17.000Z",
          "wordCount": 998,
          "title": "Show HN: mpvc-tui – A minimal mpc-like CLI and TUI for controlling mpv",
          "imageUrl": "https://github.com/gmt4/mpvc/raw/master/assets/mpvc-tui.png"
        },
        {
          "id": "https://newatlas.com/electronics/water-circuit-switches-thz-faster-semiconductors/",
          "author": null,
          "description": "Comments",
          "link": "https://newatlas.com/electronics/water-circuit-switches-thz-faster-semiconductors/",
          "publishedOn": "2022-12-16T10:56:04.000Z",
          "wordCount": 4740,
          "title": "Water-based circuit concept switches much faster than semiconductors",
          "imageUrl": "https://assets.newatlas.com/dims4/default/bff5caa/2147483647/strip/true/crop/2528x1327+0+179/resize/1200x630!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6b%2F6b%2Fe63c316f4af383e98dcb283b75fb%2Flaser-wasser-adrian-buchmann-beschnitten.jpg&na.image_optimisation=0"
        },
        {
          "id": "https://arstechnica.com/information-technology/2022/12/meet-ghostwriter-a-haunted-ai-powered-typewriter-that-talks-to-you/",
          "author": null,
          "description": "Comments",
          "link": "https://arstechnica.com/information-technology/2022/12/meet-ghostwriter-a-haunted-ai-powered-typewriter-that-talks-to-you/",
          "publishedOn": "2022-12-16T10:54:38.000Z",
          "wordCount": 1720,
          "title": "Ghostwriter, a haunted AI-powered typewriter that talks to you",
          "imageUrl": "https://cdn.arstechnica.net/wp-content/uploads/2022/12/ghostwriter_hero_2-760x380.jpg"
        },
        {
          "id": "https://www.theguardian.com/world/2022/dec/16/huge-cylindrical-aquarium-housing-1500-exotic-fish-bursts-in-berlin",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/world/2022/dec/16/huge-cylindrical-aquarium-housing-1500-exotic-fish-bursts-in-berlin",
          "publishedOn": "2022-12-16T10:43:14.000Z",
          "wordCount": 4898,
          "title": "Cylindrical aquarium housing 1,500 exotic fish bursts in Berlin",
          "imageUrl": "https://i.guim.co.uk/img/media/31cd90d59ab05fbe4adb641d2cceae1b9f1d9ef3/0_208_3500_2100/master/3500.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=7b01d76515731ac381c97cc208cf917e"
        },
        {
          "id": "https://beautiful.software/",
          "author": null,
          "description": "Comments",
          "link": "https://beautiful.software/",
          "publishedOn": "2022-12-16T06:53:20.000Z",
          "wordCount": 1779,
          "title": "Beautiful Software: Christopher Alexander's research initiative on computing",
          "imageUrl": null
        },
        {
          "id": "https://www.printmag.com/advertising/making-the-mac-20-vintage-apple-ads/",
          "author": null,
          "description": "Comments",
          "link": "https://www.printmag.com/advertising/making-the-mac-20-vintage-apple-ads/",
          "publishedOn": "2022-12-16T00:04:53.000Z",
          "wordCount": 2209,
          "title": "Vintage Apple Advertisements",
          "imageUrl": "https://149522020.v2.pressablecdn.com/wp-content/uploads/2020/02/2a34d8_419100b4e44a4b60a3e768e0f4d0f151mv2.jpg"
        },
        {
          "id": "https://github.blog/changelog/2022-12-15-secret-scanning-is-now-available-for-free-on-public-repositories/",
          "author": null,
          "description": "Comments",
          "link": "https://github.blog/changelog/2022-12-15-secret-scanning-is-now-available-for-free-on-public-repositories/",
          "publishedOn": "2022-12-16T00:03:02.000Z",
          "wordCount": 718,
          "title": "Secret scanning is now available for free on public repositories",
          "imageUrl": "https://github.blog/wp-content/uploads/2022/04/Engineering-Security.png?fit=1200%2C630"
        },
        {
          "id": "https://www.atlasobscura.com/articles/what-is-cervois",
          "author": null,
          "description": "Comments",
          "link": "https://www.atlasobscura.com/articles/what-is-cervois",
          "publishedOn": "2022-12-15T23:52:31.000Z",
          "wordCount": 7140,
          "title": "A brewer updating an ancient French beer for modern drinkers",
          "imageUrl": "https://img.atlasobscura.com/7VH2Z4XMcmQc4VzWT2Ei8isEXGkB8n1guP0QZHur62s/rt:fit/w:600/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy9mNjljZWM4Zjhj/MDdiMGM3M2FfSU1H/XzMzODAuSlBH.jpg"
        },
        {
          "id": "https://billwadge.com/2022/12/15/just-how-smart-are-you-chatgpt-i-quiz-chatgpt-about-math/",
          "author": null,
          "description": "Comments",
          "link": "https://billwadge.com/2022/12/15/just-how-smart-are-you-chatgpt-i-quiz-chatgpt-about-math/",
          "publishedOn": "2022-12-15T23:51:59.000Z",
          "wordCount": 4299,
          "title": "I quiz ChatGPT about math",
          "imageUrl": "https://billwadge.files.wordpress.com/2022/12/screenshot-2022-12-16-at-12.41.06-pm.png"
        },
        {
          "id": "https://github.com/IvorySQL/IvorySQL",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/IvorySQL/IvorySQL",
          "publishedOn": "2022-12-15T23:37:42.000Z",
          "wordCount": 1554,
          "title": "IvorySQL: Open-source Oracle-compatible PostgreSQL",
          "imageUrl": "https://repository-images.githubusercontent.com/423810080/a080589b-b9e3-46b4-bb0b-70ba87c815a9"
        },
        {
          "id": "https://webkit.org/blog/13607/help-choose-from-options-for-css-nesting-syntax/",
          "author": null,
          "description": "Comments",
          "link": "https://webkit.org/blog/13607/help-choose-from-options-for-css-nesting-syntax/",
          "publishedOn": "2022-12-15T22:19:18.000Z",
          "wordCount": 2637,
          "title": "Help choose the syntax for CSS Nesting",
          "imageUrl": null
        },
        {
          "id": "https://oschvr.com/posts/what-id-like-as-sre/",
          "author": null,
          "description": "Comments",
          "link": "https://oschvr.com/posts/what-id-like-as-sre/",
          "publishedOn": "2022-12-15T22:04:20.000Z",
          "wordCount": 519,
          "title": "Things I want from Devs as SRE/DevOps",
          "imageUrl": "https://oschvr.s3.us-west-2.amazonaws.com/oldstreet.jpeg"
        },
        {
          "id": "http://incompleteideas.net/IncIdeas/BitterLesson.html",
          "author": null,
          "description": "Comments",
          "link": "http://incompleteideas.net/IncIdeas/BitterLesson.html",
          "publishedOn": "2022-12-15T21:57:34.000Z",
          "wordCount": 1131,
          "title": "The Bitter Lesson (2019)",
          "imageUrl": null
        },
        {
          "id": "https://readwise.io/read",
          "author": null,
          "description": "Comments",
          "link": "https://readwise.io/read",
          "publishedOn": "2022-12-15T21:44:03.000Z",
          "wordCount": 3638,
          "title": "Show HN: Readwise Reader, an all-in-one reading app",
          "imageUrl": "https://readwise-assets.s3.amazonaws.com/static/images/reader/OG-Reader.9fe9ca92418f.jpg"
        },
        {
          "id": "https://groups.google.com/g/net.lang.lisp/c/P7W_1ISJ-sU/m/GAo6w-0B7oQJ",
          "author": null,
          "description": "Comments",
          "link": "https://groups.google.com/g/net.lang.lisp/c/P7W_1ISJ-sU/m/GAo6w-0B7oQJ",
          "publishedOn": "2022-12-15T21:19:18.000Z",
          "wordCount": 15581,
          "title": "Common Lisp (1986)",
          "imageUrl": null
        },
        {
          "id": "https://www.apollographql.com/blog/announcement/ceo-geoff-schmidts-message-to-apollo-employees/",
          "author": null,
          "description": "Comments",
          "link": "https://www.apollographql.com/blog/announcement/ceo-geoff-schmidts-message-to-apollo-employees/",
          "publishedOn": "2022-12-15T21:16:54.000Z",
          "wordCount": 1773,
          "title": "Apollo Layoffs",
          "imageUrl": "/blog/static/Skylark-R-1-d25f1398adc12d53b5404742a0247152.png"
        },
        {
          "id": "https://www.pypy.org/posts/2022/12/jit-bug-finding-smt-fuzzing.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.pypy.org/posts/2022/12/jit-bug-finding-smt-fuzzing.html",
          "publishedOn": "2022-12-15T21:07:30.000Z",
          "wordCount": 4680,
          "title": "Finding JIT Optimizer Bugs Using SMT Solvers and Fuzzing – PyPy",
          "imageUrl": null
        },
        {
          "id": "https://kottke.org/22/12/vintage-map-mandelbrot-set",
          "author": null,
          "description": "Comments",
          "link": "https://kottke.org/22/12/vintage-map-mandelbrot-set",
          "publishedOn": "2022-12-15T20:06:58.000Z",
          "wordCount": 291,
          "title": "Vintage-Style Map of the Mandelbrot Set",
          "imageUrl": "https://kottke.org/plus/misc/images/mandelbrot-map-01.jpg"
        },
        {
          "id": "https://openai.com/blog/new-and-improved-embedding-model/",
          "author": null,
          "description": "Comments",
          "link": "https://openai.com/blog/new-and-improved-embedding-model/",
          "publishedOn": "2022-12-15T18:13:06.000Z",
          "wordCount": 1238,
          "title": "New and Improved Embedding Model for OpenAI",
          "imageUrl": "https://openai.com/content/images/2022/12/new-and-improved-embedding-model-og-1.jpg"
        },
        {
          "id": "https://www.nytimes.com/2022/12/15/books/review/tudors-in-love-sarah-gristwood.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/15/books/review/tudors-in-love-sarah-gristwood.html",
          "publishedOn": "2022-12-15T18:07:33.000Z",
          "wordCount": null,
          "title": "Courtly Love Can Be Deadly",
          "imageUrl": null
        },
        {
          "id": "https://lichess.org/@/thibault/blog/lichess--scala-3/y1sbYzJX",
          "author": null,
          "description": "Comments",
          "link": "https://lichess.org/@/thibault/blog/lichess--scala-3/y1sbYzJX",
          "publishedOn": "2022-12-15T17:07:58.000Z",
          "wordCount": 1475,
          "title": "Lichess gets a big upgrade. It doesn't go as planned",
          "imageUrl": "https://image.lichess1.org/display?h=550&op=thumbnail&path=thibault:ublog:y1sbYzJX:lzBKpBVG.png&w=880&sig=ff30fed332961a1d4d2f3d7581bfa1bddfe89406"
        },
        {
          "id": "https://www.ycombinator.com/blog/rfs-climatetech",
          "author": null,
          "description": "Comments",
          "link": "https://www.ycombinator.com/blog/rfs-climatetech",
          "publishedOn": "2022-12-15T17:07:32.000Z",
          "wordCount": 15296,
          "title": "Request for Startups: Climate Tech",
          "imageUrl": "https://www.ycombinator.com/blog/content/images/2022/12/BlogTwitter-Image-Template1.jpeg"
        },
        {
          "id": "https://brr.fyi/posts/doors-of-mcmurdo",
          "author": null,
          "description": "Comments",
          "link": "https://brr.fyi/posts/doors-of-mcmurdo",
          "publishedOn": "2022-12-15T17:00:15.000Z",
          "wordCount": 1290,
          "title": "Doors of McMurdo",
          "imageUrl": null
        },
        {
          "id": "https://jack.wrenn.fyi/blog/deflect/",
          "author": null,
          "description": "Comments",
          "link": "https://jack.wrenn.fyi/blog/deflect/",
          "publishedOn": "2022-12-15T15:54:48.000Z",
          "wordCount": 1254,
          "title": "Native Reflection in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.nist.gov/news-events/news/2022/12/nist-retires-sha-1-cryptographic-algorithm",
          "author": null,
          "description": "Comments",
          "link": "https://www.nist.gov/news-events/news/2022/12/nist-retires-sha-1-cryptographic-algorithm",
          "publishedOn": "2022-12-15T15:49:12.000Z",
          "wordCount": 2051,
          "title": "NIST is announcing that SHA-1 should be phased out by Dec. 31, 2030",
          "imageUrl": "https://www.nist.gov/sites/default/files/images/2022/12/14/SecureHashAltogirthm23_Released_960x600_v4_A.png"
        },
        {
          "id": "https://medusajs.com/blog/9-best-ecommerce-ux-practices-with-examples",
          "author": null,
          "description": "Comments",
          "link": "https://medusajs.com/blog/9-best-ecommerce-ux-practices-with-examples",
          "publishedOn": "2022-12-15T14:59:37.000Z",
          "wordCount": 18774,
          "title": "Best ecommerce UX practices from mcmaster.com",
          "imageUrl": "https://medusajs.com/images/ux-practices.jpg"
        },
        {
          "id": "https://github.com/obsproject/obs-studio/pull/7926",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/obsproject/obs-studio/pull/7926",
          "publishedOn": "2022-12-15T14:49:52.000Z",
          "wordCount": 2803,
          "title": "Adding WebRTC support to OBS using Rust",
          "imageUrl": "https://opengraph.githubassets.com/90fa3ff622885e846856e91355f0d5891a2c43f4ba4613c160f2f0058e6b4936/obsproject/obs-studio/pull/7926"
        },
        {
          "id": "https://singularityhub.com/2022/12/13/deepminds-alphacode-conquers-coding-performing-as-well-as-humans/",
          "author": null,
          "description": "Comments",
          "link": "https://singularityhub.com/2022/12/13/deepminds-alphacode-conquers-coding-performing-as-well-as-humans/",
          "publishedOn": "2022-12-15T14:43:12.000Z",
          "wordCount": 17519,
          "title": "Deepmind’s alphacode conquers coding, performing as well as humans",
          "imageUrl": "https://singularityhub.com/wp-content/uploads/2022/12/deepmind-alphacode-lines-of-code-purple-blue-pink-1.jpeg"
        },
        {
          "id": "https://link.springer.com/article/10.1007/s00392-022-02129-5",
          "author": null,
          "description": "Comments",
          "link": "https://link.springer.com/article/10.1007/s00392-022-02129-5",
          "publishedOn": "2022-12-15T14:38:52.000Z",
          "wordCount": 6688,
          "title": "Autopsy-based characterization of myocarditis after anti-SARS-CoV-2-vaccination",
          "imageUrl": "https://media.springernature.com/w200/springer-static/cover/journal/392.jpg"
        },
        {
          "id": "https://21sci-tech.com/articles/spring01/Electrodynamics.html",
          "author": null,
          "description": "Comments",
          "link": "https://21sci-tech.com/articles/spring01/Electrodynamics.html",
          "publishedOn": "2022-12-15T14:29:30.000Z",
          "wordCount": 4665,
          "title": "The Suppressed Electrodynamics of Ampère-Gauss-Weber (2001)",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33999296",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33999296",
          "publishedOn": "2022-12-15T13:37:47.000Z",
          "wordCount": 17263,
          "title": "Ask HN: How might HN build a social network together?",
          "imageUrl": null
        },
        {
          "id": "https://www.riffusion.com/about",
          "author": null,
          "description": "Comments",
          "link": "https://www.riffusion.com/about",
          "publishedOn": "2022-12-15T13:26:04.000Z",
          "wordCount": 1489,
          "title": "Riffusion – Stable Diffusion fine-tuned to generate Music",
          "imageUrl": "https://i.imgur.com/fywZpQ7.jpeg"
        },
        {
          "id": "https://www.sydney.edu.au/news-opinion/news/2022/12/07/low-cost-battery-built-with-four-times-the-capacity-of-lithium.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.sydney.edu.au/news-opinion/news/2022/12/07/low-cost-battery-built-with-four-times-the-capacity-of-lithium.html",
          "publishedOn": "2022-12-15T12:07:57.000Z",
          "wordCount": 1173,
          "title": "Na-S Battery: Low-cost with four times the capacity of lithium",
          "imageUrl": "https://www.sydney.edu.au/content/dam/corporate/images/news-and-opinion/news/2022/november/battery.jpg"
        },
        {
          "id": "https://vmst.io/@selzero/109512557990367884",
          "author": null,
          "description": "Comments",
          "link": "https://vmst.io/@selzero/109512557990367884",
          "publishedOn": "2022-12-15T11:49:31.000Z",
          "wordCount": 116,
          "title": "Who knew the first AI battles would be fought by artists?",
          "imageUrl": "https://cdn.vmst.io/media_attachments/files/109/512/541/971/089/323/original/c6caeee2cab72099.png"
        },
        {
          "id": "https://www.oreilly.com/radar/what-does-copyright-say-about-generative-models/",
          "author": null,
          "description": "Comments",
          "link": "https://www.oreilly.com/radar/what-does-copyright-say-about-generative-models/",
          "publishedOn": "2022-12-15T09:00:19.000Z",
          "wordCount": 2807,
          "title": "What does copyright say about generative models?",
          "imageUrl": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/pbthey.lawyer.750pix_crop-5e9abc2396314ea45f97b258fc440487-1.jpg"
        },
        {
          "id": "https://www.quantamagazine.org/how-the-brain-distinguishes-memories-from-perceptions-20221214/",
          "author": null,
          "description": "Comments",
          "link": "https://www.quantamagazine.org/how-the-brain-distinguishes-memories-from-perceptions-20221214/",
          "publishedOn": "2022-12-15T01:32:00.000Z",
          "wordCount": 5745,
          "title": "How the brain distinguishes memories from perceptions",
          "imageUrl": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/12/PerceptionOrMemory-byKristinaArmitage-Social.webp"
        },
        {
          "id": "https://www.coindesk.com/policy/2022/12/13/ftxs-bahamas-liquidators-seek-to-exclude-over-200m-worth-of-luxury-properties-from-liquidation/",
          "author": null,
          "description": "Comments",
          "link": "https://www.coindesk.com/policy/2022/12/13/ftxs-bahamas-liquidators-seek-to-exclude-over-200m-worth-of-luxury-properties-from-liquidation/",
          "publishedOn": "2022-12-15T00:56:30.000Z",
          "wordCount": 21980,
          "title": "FTX's Bahamas Liquidators Seek to Exclude Luxury Properties from Liquidation",
          "imageUrl": "https://www.coindesk.com/resizer/PXigqToo2gdyyUOgvUX9CLRYHiM=/1200x628/center/middle/cloudfront-us-east-1.images.arcpublishing.com/coindesk/CYIY5TNUPRB2VHL2OLGC2IUWHM.jpg"
        },
        {
          "id": "https://www.nytimes.com/2022/12/14/climate/native-plants-lawns-homeowners.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/14/climate/native-plants-lawns-homeowners.html",
          "publishedOn": "2022-12-15T00:16:21.000Z",
          "wordCount": null,
          "title": "Maryland couple fights home owners assoc. and wins ushering in new state law",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/elonjet/status/1603166460746104833",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/elonjet/status/1603166460746104833",
          "publishedOn": "2022-12-14T23:29:41.000Z",
          "wordCount": 470,
          "title": "Twitter restored ElonJet account",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/twittersafety/status/1603165959669354496",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/twittersafety/status/1603165959669354496",
          "publishedOn": "2022-12-14T23:26:43.000Z",
          "wordCount": 470,
          "title": "“We’ve updated our policy to prohibit sharing someone else’s live location.”",
          "imageUrl": null
        },
        {
          "id": "https://www.withdiode.com/projects/62716731-5e1e-4622-86af-90d8e6b5123b",
          "author": null,
          "description": "Comments",
          "link": "https://www.withdiode.com/projects/62716731-5e1e-4622-86af-90d8e6b5123b",
          "publishedOn": "2022-12-14T21:42:28.000Z",
          "wordCount": 324,
          "title": "A circuit simulator that doesn't look like it was made in 2003",
          "imageUrl": "https://withdiode.com/api/og?project=62716731-5e1e-4622-86af-90d8e6b5123b"
        },
        {
          "id": "https://matthewfelgate.wordpress.com/2022/12/14/turn-the-radio-volume-down-for-adverts-and-djs-talking/",
          "author": null,
          "description": "Comments",
          "link": "https://matthewfelgate.wordpress.com/2022/12/14/turn-the-radio-volume-down-for-adverts-and-djs-talking/",
          "publishedOn": "2022-12-14T21:10:25.000Z",
          "wordCount": 3752,
          "title": "Turn the radio volume down for adverts and DJs talking",
          "imageUrl": "https://s0.wp.com/i/blank.jpg"
        },
        {
          "id": "https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1",
          "author": null,
          "description": "Comments",
          "link": "https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1",
          "publishedOn": "2022-12-14T21:07:52.000Z",
          "wordCount": 73,
          "title": "How does GPT obtain its ability? Tracing emergent abilities of language models",
          "imageUrl": "https://www.notion.so/images/meta/default.png"
        },
        {
          "id": "https://musescore.org/en/4.0",
          "author": null,
          "description": "Comments",
          "link": "https://musescore.org/en/4.0",
          "publishedOn": "2022-12-14T21:05:36.000Z",
          "wordCount": 1737,
          "title": "MuseScore 4",
          "imageUrl": "https://musescore.org/sites/musescore.org/files/2022-12/laptop_desktop_2x.png"
        },
        {
          "id": "https://www.easypost.com/careers",
          "author": null,
          "description": "Comments",
          "link": "https://www.easypost.com/careers",
          "publishedOn": "2022-12-14T21:00:16.000Z",
          "wordCount": 510,
          "title": "EasyPost (YC S13) Is Hiring",
          "imageUrl": "https://assets.easypost.com/assets/images/branding/easypost-primary-icon-padded.dc7ae4617154a87e131844bbe208c350.png"
        },
        {
          "id": "https://fuse.wikichip.org/news/7343/iedm-2022-did-we-just-witness-the-death-of-sram/",
          "author": null,
          "description": "Comments",
          "link": "https://fuse.wikichip.org/news/7343/iedm-2022-did-we-just-witness-the-death-of-sram/",
          "publishedOn": "2022-12-14T20:55:17.000Z",
          "wordCount": 4305,
          "title": "The Death of SRAM?",
          "imageUrl": "https://fuse.wikichip.org/wp-content/uploads/2022/09/tsmc-n3e-thumb.png"
        },
        {
          "id": "https://www.theregister.com/2022/12/14/firefox_108/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theregister.com/2022/12/14/firefox_108/",
          "publishedOn": "2022-12-14T20:31:21.000Z",
          "wordCount": 1491,
          "title": "You can hook your MIDI keyboard up to a website with Firefox 108",
          "imageUrl": "https://regmedia.co.uk/2016/03/01/burning_keyboard_teaser.jpg"
        },
        {
          "id": "https://krebsonsecurity.com/2022/12/six-charged-in-mass-takedown-of-ddos-for-hire-sites/",
          "author": null,
          "description": "Comments",
          "link": "https://krebsonsecurity.com/2022/12/six-charged-in-mass-takedown-of-ddos-for-hire-sites/",
          "publishedOn": "2022-12-14T20:01:43.000Z",
          "wordCount": 2221,
          "title": "Six charged in mass takedown of DDoS-for-hire sites",
          "imageUrl": null
        },
        {
          "id": "https://investors.metals.co/news-releases/news-release-details/nori-and-allseas-lift-over-3000-tonnes-polymetallic-nodules/",
          "author": null,
          "description": "Comments",
          "link": "https://investors.metals.co/news-releases/news-release-details/nori-and-allseas-lift-over-3000-tonnes-polymetallic-nodules/",
          "publishedOn": "2022-12-14T19:40:02.000Z",
          "wordCount": 2869,
          "title": "The Metals Company subsidiary lifts over 3000T of nodules to sea surface",
          "imageUrl": null
        },
        {
          "id": "https://www.scanofthemonth.com/scans/nest-thermostat-evolution",
          "author": null,
          "description": "Comments",
          "link": "https://www.scanofthemonth.com/scans/nest-thermostat-evolution",
          "publishedOn": "2022-12-14T18:43:00.000Z",
          "wordCount": 3353,
          "title": "Hidden tech of the Nest Thermostat",
          "imageUrl": "https://assets.website-files.com/6202f89a2c14fae9e9222dc3/6398ee5b5b192d5171c7eece_og-image-nest.png"
        },
        {
          "id": "https://htmx.org/docs/",
          "author": null,
          "description": "Comments",
          "link": "https://htmx.org/docs/",
          "publishedOn": "2022-12-14T18:25:38.000Z",
          "wordCount": 7523,
          "title": "Htmx in a Nutshell",
          "imageUrl": null
        },
        {
          "id": "https://blog.jquery.com/2022/12/13/jquery-3-6-2-released/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.jquery.com/2022/12/13/jquery-3-6-2-released/",
          "publishedOn": "2022-12-14T18:14:16.000Z",
          "wordCount": 1623,
          "title": "jQuery 3.6.2",
          "imageUrl": null
        },
        {
          "id": "https://blog.waymo.com/2022/12/waymos-collision-avoidance-testing.html",
          "author": null,
          "description": "Comments",
          "link": "https://blog.waymo.com/2022/12/waymos-collision-avoidance-testing.html",
          "publishedOn": "2022-12-14T17:56:48.000Z",
          "wordCount": 2507,
          "title": "Waymo's collision avoidance testing",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiloNh_iPC9dOPaXNe1mWtX3yrt11SqMck9RJhNXJ-L1ky4KKKz3UwkT3XyOIowlD7-8FqSVQolTI9MdQVtv4dIPCVx4FtWTUtNnWw7XpP_MNEqtU4uzFMRwGx5jkuqGmh1elLLWlEfKwMarlWP3LK-tHANjBqOcO5SBcs4TL_kEKTMTe5PAMUeglwY/w1200-h630-p-k-no-nu/CAT.gif"
        },
        {
          "id": "https://svelte.dev/blog/announcing-sveltekit-1.0",
          "author": null,
          "description": "Comments",
          "link": "https://svelte.dev/blog/announcing-sveltekit-1.0",
          "publishedOn": "2022-12-14T17:15:27.000Z",
          "wordCount": 2828,
          "title": "SvelteKit 1.0",
          "imageUrl": null
        },
        {
          "id": "https://tailscale.com/blog/tailnet-lock/",
          "author": null,
          "description": "Comments",
          "link": "https://tailscale.com/blog/tailnet-lock/",
          "publishedOn": "2022-12-14T17:07:07.000Z",
          "wordCount": 1406,
          "title": "Tailnet Lock",
          "imageUrl": "https://tailscale.com/blog/tailnet-lock/social.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=TAO1i9Z9GpQ",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=TAO1i9Z9GpQ",
          "publishedOn": "2022-12-14T16:44:16.000Z",
          "wordCount": null,
          "title": "Does glass break faster than a bullet? [video]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/Juice-Labs/Juice-Labs/wiki",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Juice-Labs/Juice-Labs/wiki",
          "publishedOn": "2022-12-14T16:10:49.000Z",
          "wordCount": 898,
          "title": "Show HN: Software for Remote GPU-over-IP",
          "imageUrl": "https://opengraph.githubassets.com/81967fb6bf88cb547469f5f7be34ccdc817b1fc1dd7a7c59bb1cd0c6da407612/Juice-Labs/Juice-Labs"
        },
        {
          "id": "https://www.ft.com/content/741772c0-ee76-4d3d-bfcd-4fabc1fb405d",
          "author": null,
          "description": "Comments",
          "link": "https://www.ft.com/content/741772c0-ee76-4d3d-bfcd-4fabc1fb405d",
          "publishedOn": "2022-12-14T13:06:25.000Z",
          "wordCount": 15256,
          "title": "Female spies of MI6",
          "imageUrl": "https://www.ft.com/__origami/service/image/v2/images/raw/https%3A%2F%2Fd1e00ek4ebabms.cloudfront.net%2Fproduction%2F4725bafd-9c9e-4407-a0c1-ea71bfd27ac3.jpg?source=next-opengraph&fit=scale-down&width=900"
        },
        {
          "id": "https://twitter.com/davisblalock/status/1602600453555961856",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/davisblalock/status/1602600453555961856",
          "publishedOn": "2022-12-14T12:40:24.000Z",
          "wordCount": 470,
          "title": "Ways to get around ChatGPT's safeguards",
          "imageUrl": null
        },
        {
          "id": "https://www.totaltypescript.com/rewriting-typescript-in-rust",
          "author": null,
          "description": "Comments",
          "link": "https://www.totaltypescript.com/rewriting-typescript-in-rust",
          "publishedOn": "2022-12-14T11:56:42.000Z",
          "wordCount": 4519,
          "title": "Rewriting TypeScript in Rust?",
          "imageUrl": "https://www.totaltypescript.com/api/og?title=Rewriting%20TypeScript%20in%20Rust?%20You'd%20have%20to%20be..."
        },
        {
          "id": "https://english.elpais.com/culture/2022-12-12/wendy-carlos-the-brilliant-but-lonely-life-of-an-electronic-music-pioneer.html",
          "author": null,
          "description": "Comments",
          "link": "https://english.elpais.com/culture/2022-12-12/wendy-carlos-the-brilliant-but-lonely-life-of-an-electronic-music-pioneer.html",
          "publishedOn": "2022-12-14T10:20:07.000Z",
          "wordCount": 5942,
          "title": "Wendy Carlos: The brilliant but lonely life of an electronic music pioneer",
          "imageUrl": "https://images.english.elpais.com/resizer/_jDxXwbltG15yrrG-Q3Sp7Br1cU=/1200x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/ZIYYEWM7CNAXLLAYAWFNEHJT7Y.jpg"
        },
        {
          "id": "https://designnotes.blog.gov.uk/2022/12/12/making-the-gov-uk-frontend-typography-scale-more-accessible/",
          "author": null,
          "description": "Comments",
          "link": "https://designnotes.blog.gov.uk/2022/12/12/making-the-gov-uk-frontend-typography-scale-more-accessible/",
          "publishedOn": "2022-12-14T08:04:50.000Z",
          "wordCount": 1660,
          "title": "Making the Gov.uk front end typography scale more accessible",
          "imageUrl": "https://designnotes.blog.gov.uk/wp-content/uploads/sites/53/2022/12/User-looking-at-GOV.UK-on-a-mobile-device.jpg"
        },
        {
          "id": "https://en.wikipedia.org/wiki/Windy_City_Heat",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/Windy_City_Heat",
          "publishedOn": "2022-12-14T06:35:45.000Z",
          "wordCount": 2661,
          "title": "Windy City Heat",
          "imageUrl": "https://upload.wikimedia.org/wikipedia/en/3/31/Windycityheat.jpg"
        },
        {
          "id": "https://skamille.medium.com/okrs-are-hard-b4a6a8491af0",
          "author": null,
          "description": "Comments",
          "link": "https://skamille.medium.com/okrs-are-hard-b4a6a8491af0",
          "publishedOn": "2022-12-14T00:59:26.000Z",
          "wordCount": 3487,
          "title": "OKRs Are Hard",
          "imageUrl": null
        },
        {
          "id": "https://www.getrevue.co/profile/jackjack/issues/a-native-internet-protocol-for-social-media-1503112",
          "author": null,
          "description": "Comments",
          "link": "https://www.getrevue.co/profile/jackjack/issues/a-native-internet-protocol-for-social-media-1503112",
          "publishedOn": "2022-12-13T23:03:29.000Z",
          "wordCount": 2513,
          "title": "A native internet protocol for social media",
          "imageUrl": "https://s3.amazonaws.com/revue/issue_images/images/000/668/283/original/issue_image_1503112.jpg?1670939808"
        },
        {
          "id": "https://old.reddit.com/r/shittychangelog/comments/zl5gaz/here_at_reddit_we_believe_everything_is_better_in/",
          "author": null,
          "description": "Comments",
          "link": "https://old.reddit.com/r/shittychangelog/comments/zl5gaz/here_at_reddit_we_believe_everything_is_better_in/",
          "publishedOn": "2022-12-13T21:45:56.000Z",
          "wordCount": 2611,
          "title": "Reddit's photo albums broke due to Integer overflow of Signed Int32",
          "imageUrl": "https://www.redditstatic.com/new-icon.png"
        },
        {
          "id": "https://www.pcgamer.com/after-spending-20-years-simulating-reality-the-dwarf-fortress-devs-have-to-get-used-to-a-new-one-being-millionaires/",
          "author": null,
          "description": "Comments",
          "link": "https://www.pcgamer.com/after-spending-20-years-simulating-reality-the-dwarf-fortress-devs-have-to-get-used-to-a-new-one-being-millionaires/",
          "publishedOn": "2022-12-13T21:32:57.000Z",
          "wordCount": 12622,
          "title": "After 20 years the Dwarf Fortress devs have to get used to being millionaires",
          "imageUrl": "https://cdn.mos.cms.futurecdn.net/5i5EaBh4eSGR8AJYhpqPUR-1200-80.jpg"
        },
        {
          "id": "https://www.agwa.name/blog/post/domain_pricing_is_very_confusing",
          "author": null,
          "description": "Comments",
          "link": "https://www.agwa.name/blog/post/domain_pricing_is_very_confusing",
          "publishedOn": "2022-12-13T21:27:19.000Z",
          "wordCount": 1917,
          "title": "No, Google did not hike the price of a .dev domain from $12 to $850",
          "imageUrl": null
        },
        {
          "id": "https://www.reuters.com/technology/how-secret-software-change-allowed-ftx-use-client-money-2022-12-13/",
          "author": null,
          "description": "Comments",
          "link": "https://www.reuters.com/technology/how-secret-software-change-allowed-ftx-use-client-money-2022-12-13/",
          "publishedOn": "2022-12-13T21:16:57.000Z",
          "wordCount": 6399,
          "title": "A software change allowed FTX to use client money",
          "imageUrl": "https://www.reuters.com/resizer/8gBJEoCC1GaxZoMG3GaQ4KhbQz4=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/HQEXMEIJYNM3JBMME5F3VPBWVU.jpg"
        },
        {
          "id": "https://www.flickr.org/announcing-the-flickr-foundation/",
          "author": null,
          "description": "Comments",
          "link": "https://www.flickr.org/announcing-the-flickr-foundation/",
          "publishedOn": "2022-12-13T21:02:38.000Z",
          "wordCount": 2518,
          "title": "The Flickr Foundation",
          "imageUrl": "https://www.flickr.org/wp-content/uploads/sites/4/2022/10/flickr_og.jpg"
        },
        {
          "id": "https://jobs.lever.co/mindsdb/5ef21d35-8386-4b1c-941d-77aed16b2c18",
          "author": null,
          "description": "Comments",
          "link": "https://jobs.lever.co/mindsdb/5ef21d35-8386-4b1c-941d-77aed16b2c18",
          "publishedOn": "2022-12-13T21:01:10.000Z",
          "wordCount": 16281,
          "title": "MindsDB (YC W20) Is Hiring a Senior PM",
          "imageUrl": "https://lever-client-logos.s3.us-west-2.amazonaws.com/df2cb049-f236-48be-863e-1c03abaec2e5-1634589438039.png"
        },
        {
          "id": "https://support.apple.com/en-gb/HT213530",
          "author": null,
          "description": "Comments",
          "link": "https://support.apple.com/en-gb/HT213530",
          "publishedOn": "2022-12-13T20:57:04.000Z",
          "wordCount": 2419,
          "title": "About the security content of iOS 16.2 and iPadOS 16.2",
          "imageUrl": null
        },
        {
          "id": "https://tfos.co/p/rebuild-social-media/",
          "author": null,
          "description": "Comments",
          "link": "https://tfos.co/p/rebuild-social-media/",
          "publishedOn": "2022-12-13T20:15:32.000Z",
          "wordCount": 1481,
          "title": "How to rebuild social media on top of RSS",
          "imageUrl": "https://platypub.sfo3.cdn.digitaloceanspaces.com/93206301-493d-43d0-847e-d67a0c70cb7b"
        },
        {
          "id": "https://constructionphysics.substack.com/p/balloon-framing-is-worse-is-better",
          "author": null,
          "description": "Comments",
          "link": "https://constructionphysics.substack.com/p/balloon-framing-is-worse-is-better",
          "publishedOn": "2022-12-13T19:51:21.000Z",
          "wordCount": 5453,
          "title": "Balloon framing is worse-is-better (2021)",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4a7c5b0-3965-4fa1-b4eb-9b71a0480285_548x352.png"
        },
        {
          "id": "https://www.bloomberg.com/news/articles/2022-12-13/will-apple-allow-users-to-install-third-party-app-stores-sideload-in-europe",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/articles/2022-12-13/will-apple-allow-users-to-install-third-party-app-stores-sideload-in-europe",
          "publishedOn": "2022-12-13T19:19:14.000Z",
          "wordCount": 576,
          "title": "Apple to allow outside app stores in overhaul spurred by EU laws",
          "imageUrl": null
        },
        {
          "id": "https://www.newyorker.com/culture/cultural-comment/the-delight-of-edward-hoppers-solitude",
          "author": null,
          "description": "Comments",
          "link": "https://www.newyorker.com/culture/cultural-comment/the-delight-of-edward-hoppers-solitude",
          "publishedOn": "2022-12-13T19:00:31.000Z",
          "wordCount": 37722,
          "title": "The Delight of Edward Hopper’s Solitude",
          "imageUrl": "https://media.newyorker.com/photos/638e75002276ab205c011c87/16:9/w_1280,c_limit/Gopnik-Hopper-1.jpg"
        },
        {
          "id": "https://observablehq.com/@asg017/introducing-sqlite-loadable-rs",
          "author": null,
          "description": "Comments",
          "link": "https://observablehq.com/@asg017/introducing-sqlite-loadable-rs",
          "publishedOn": "2022-12-13T18:54:22.000Z",
          "wordCount": 1826,
          "title": "SQLite-loadable-rs: A framework for building SQLite Extensions in Rust",
          "imageUrl": "https://static.observableusercontent.com/thumbnail/bfc35020b7a962ea51d05982415e9c4fcd4284b6240f7e9bfa64e1e11aa22866.jpg"
        },
        {
          "id": "https://ai.facebook.com/blog/ai-self-supervised-learning-data2vec/",
          "author": null,
          "description": "Comments",
          "link": "https://ai.facebook.com/blog/ai-self-supervised-learning-data2vec/",
          "publishedOn": "2022-12-13T18:03:03.000Z",
          "wordCount": 1191,
          "title": "Data2vec 2.0: Highly efficient self-supervised learning for vision, speech, text",
          "imageUrl": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/318451836_1178090343105940_5457223586182092425_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=ffMH8bGXcV0AX9KtBSg&_nc_oc=AQmXPHZM20ouBRwzgubKz_Fm4_1XFVewy2vIgCdxjJZ2kxWEaz94yziIQh2g8bspnQ8&_nc_ht=scontent-iad3-1.xx&oh=00_AfBEbUaNxxhKpStDW9UjdqKb8KbpBAzmUZePh9gBwMzhQw&oe=639E5F39"
        },
        {
          "id": "https://mars.nasa.gov/explore/mars-now/",
          "author": null,
          "description": "Comments",
          "link": "https://mars.nasa.gov/explore/mars-now/",
          "publishedOn": "2022-12-13T17:35:21.000Z",
          "wordCount": 127,
          "title": "Mars Now",
          "imageUrl": "https://mars.nasa.gov/system/site_config_values/meta_share_images/1_mars-nasa-gov.jpg"
        },
        {
          "id": "https://tailscale.com/blog/throughput-improvements/",
          "author": null,
          "description": "Comments",
          "link": "https://tailscale.com/blog/throughput-improvements/",
          "publishedOn": "2022-12-13T17:25:30.000Z",
          "wordCount": 2926,
          "title": "Userspace isn't slow, some kernel interfaces are",
          "imageUrl": "https://tailscale.com/blog/throughput-improvements/social.png"
        },
        {
          "id": "https://jvns.ca/blog/2022/12/07/tips-for-analyzing-logs/",
          "author": null,
          "description": "Comments",
          "link": "https://jvns.ca/blog/2022/12/07/tips-for-analyzing-logs/",
          "publishedOn": "2022-12-13T16:47:16.000Z",
          "wordCount": 1323,
          "title": "Tips for analyzing logs",
          "imageUrl": null
        },
        {
          "id": "https://www.energy.gov/articles/doe-national-laboratory-makes-history-achieving-fusion-ignition",
          "author": null,
          "description": "Comments",
          "link": "https://www.energy.gov/articles/doe-national-laboratory-makes-history-achieving-fusion-ignition",
          "publishedOn": "2022-12-13T16:44:40.000Z",
          "wordCount": 1792,
          "title": "US Department of Energy: Fusion Ignition Achieved",
          "imageUrl": "https://www.energy.gov/sites/default/files/styles/photo_gallery_509_x_678_/public/2022-06/DOE%20Press%20Release%20Preview%20image.png?itok=tlJni6eS"
        },
        {
          "id": "https://github.com/ponylang/ponyc",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/ponylang/ponyc",
          "publishedOn": "2022-12-13T15:56:04.000Z",
          "wordCount": 1107,
          "title": "Pony Programming Language",
          "imageUrl": "https://repository-images.githubusercontent.com/6667084/a832d300-6128-11e9-8d1a-0773bba1d4c8"
        },
        {
          "id": "https://xethub.com/user/login",
          "author": null,
          "description": "Comments",
          "link": "https://xethub.com/user/login",
          "publishedOn": "2022-12-13T15:14:54.000Z",
          "wordCount": 483,
          "title": "Show HN: We scaled Git to support 1 TB repos",
          "imageUrl": "/assets/img/logo.png"
        },
        {
          "id": "https://www.justice.gov/usao-sdny/press-release/file/1557571/download",
          "author": null,
          "description": "Comments",
          "link": "https://www.justice.gov/usao-sdny/press-release/file/1557571/download",
          "publishedOn": "2022-12-13T15:14:07.000Z",
          "wordCount": 74244,
          "title": "The United States of America vs. Samuel Bankman-Fried Indictment [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/readme/featured/vintage-computing",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/readme/featured/vintage-computing",
          "publishedOn": "2022-12-13T15:12:01.000Z",
          "wordCount": 3141,
          "title": "What we can learn from vintage computing",
          "imageUrl": "https://images.ctfassets.net/s5uo95nf6njh/5VvjzsD4mgUXrfHkk2zXli/7c874faacb9858fe851135a315f8040a/1200x630-ReadMe-Twitter_LI_Post-ImageOnly-Old_Teach_Featured_Article.jpg"
        },
        {
          "id": "https://mifi.no/losslesscut/",
          "author": null,
          "description": "Comments",
          "link": "https://mifi.no/losslesscut/",
          "publishedOn": "2022-12-13T14:44:56.000Z",
          "wordCount": 909,
          "title": "LosslessCut: lossless video/audio editing",
          "imageUrl": null
        },
        {
          "id": "https://mullvad.net/en/blog/2022/12/13/shutting-down-our-unencrypted-public-dns-service/",
          "author": null,
          "description": "Comments",
          "link": "https://mullvad.net/en/blog/2022/12/13/shutting-down-our-unencrypted-public-dns-service/",
          "publishedOn": "2022-12-13T14:41:30.000Z",
          "wordCount": 296,
          "title": "Shutting down our unencrypted public DNS service",
          "imageUrl": "https://mullvad.net/static/press/MullvadVPN_logo_Round_RGB_Color_positive.png"
        },
        {
          "id": "http://blog.fogus.me/2022/12/13/the-best-things-and-stuff-of-2022/",
          "author": null,
          "description": "Comments",
          "link": "http://blog.fogus.me/2022/12/13/the-best-things-and-stuff-of-2022/",
          "publishedOn": "2022-12-13T14:27:28.000Z",
          "wordCount": 3281,
          "title": "The best things and stuff of 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8622869/",
          "author": null,
          "description": "Comments",
          "link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8622869/",
          "publishedOn": "2022-12-13T11:18:59.000Z",
          "wordCount": 12902,
          "title": "Yerba Mate – A Long but Current History (2021)",
          "imageUrl": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-logo-share.png?_=0"
        },
        {
          "id": "https://stratechery.com/2022/consoles-and-competition/",
          "author": null,
          "description": "Comments",
          "link": "https://stratechery.com/2022/consoles-and-competition/",
          "publishedOn": "2022-12-13T09:35:25.000Z",
          "wordCount": 6506,
          "title": "Consoles and competition",
          "imageUrl": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/activision-9.png?fit=1200%2C653&ssl=1"
        },
        {
          "id": "https://github.com/observablehq/plot/blob/main/CHANGELOG.md",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/observablehq/plot/blob/main/CHANGELOG.md",
          "publishedOn": "2022-12-13T08:04:48.000Z",
          "wordCount": 8786,
          "title": "Observable Plot 0.6.1",
          "imageUrl": "https://opengraph.githubassets.com/dee4c7fa8ac767ccaf53457d03275f82b2df180592025b0e77933cfa15425eaa/observablehq/plot"
        },
        {
          "id": "https://www.smashingmagazine.com/2022/09/javascript-api-guide/",
          "author": null,
          "description": "Comments",
          "link": "https://www.smashingmagazine.com/2022/09/javascript-api-guide/",
          "publishedOn": "2022-12-13T06:55:49.000Z",
          "wordCount": 5772,
          "title": "Lesser-known JavaScript APIs",
          "imageUrl": "https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b583db40-b8c0-46c4-9893-5a7ae3d00453/api-page-visibility-web-sharing-broadcast-channel-internationalization.jpg"
        },
        {
          "id": "https://www.historytoday.com/archive/feature/violent-ends",
          "author": null,
          "description": "Comments",
          "link": "https://www.historytoday.com/archive/feature/violent-ends",
          "publishedOn": "2022-12-13T05:04:15.000Z",
          "wordCount": 2569,
          "title": "Violent Ends: Early modern methods of execution",
          "imageUrl": null
        },
        {
          "id": "https://github.com/odnoletkov/advent-of-code-jq",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/odnoletkov/advent-of-code-jq",
          "publishedOn": "2022-12-13T01:29:54.000Z",
          "wordCount": 614,
          "title": "Solving Advent of Code with jq",
          "imageUrl": "https://opengraph.githubassets.com/1f138e621e20f91d4c49c5dae49c822c845445eaa76c84afdcc02562530b761e/odnoletkov/advent-of-code-jq"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33963269",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33963269",
          "publishedOn": "2022-12-13T01:17:50.000Z",
          "wordCount": 933,
          "title": "Ask HN: If I get locked out of everything, please try to help me",
          "imageUrl": null
        },
        {
          "id": "https://www.datocms-assets.com/65181/1667327773-iconiq-analytics-insights-engineering-in-a-hybrid-world.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://www.datocms-assets.com/65181/1667327773-iconiq-analytics-insights-engineering-in-a-hybrid-world.pdf",
          "publishedOn": "2022-12-13T00:08:56.000Z",
          "wordCount": 58290,
          "title": "Data behind high-functioning engineering organizations [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://blog.jakubholy.net/2022/trinity-of-clojure/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.jakubholy.net/2022/trinity-of-clojure/",
          "publishedOn": "2022-12-12T23:39:21.000Z",
          "wordCount": 788,
          "title": "Clojure is a trinity of language, REPL, and structural editor",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/tier10k/status/1602446984090107905",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/tier10k/status/1602446984090107905",
          "publishedOn": "2022-12-12T23:38:53.000Z",
          "wordCount": 470,
          "title": "SBF Arrested by Bahamian Authorities",
          "imageUrl": null
        },
        {
          "id": "https://book.dragonriders.community/",
          "author": null,
          "description": "Comments",
          "link": "https://book.dragonriders.community/",
          "publishedOn": "2022-12-12T23:34:58.000Z",
          "wordCount": 1956,
          "title": "Building Games with DragonRuby – A free book on Ruby game dev",
          "imageUrl": "https://book.dragonriders.community/img/cover.jpg"
        },
        {
          "id": "https://www.slowboring.com/p/why-hasnt-technology-disrupted-higher",
          "author": null,
          "description": "Comments",
          "link": "https://www.slowboring.com/p/why-hasnt-technology-disrupted-higher",
          "publishedOn": "2022-12-12T23:13:51.000Z",
          "wordCount": 3894,
          "title": "Why hasn’t technology disrupted higher education already?",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8ef74a63-a936-4cc2-8a58-563d2f657594_3496x2469.jpeg"
        },
        {
          "id": "https://astralcodexten.substack.com/p/perhaps-it-is-a-bad-thing-that-the",
          "author": null,
          "description": "Comments",
          "link": "https://astralcodexten.substack.com/p/perhaps-it-is-a-bad-thing-that-the",
          "publishedOn": "2022-12-12T22:30:52.000Z",
          "wordCount": 5509,
          "title": "Perhaps it is a bad thing that the leading AI companies cannot control their AIs",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0484a62e-4fb0-4bff-afae-9818b71a58fc_448x271.png"
        },
        {
          "id": "https://jjar.huji.ac.il/sites/default/files/jjar/files/jjar2_art4_lachish_p76-119_2022-10-12_01.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://jjar.huji.ac.il/sites/default/files/jjar/files/jjar2_art4_lachish_p76-119_2022-10-12_01.pdf",
          "publishedOn": "2022-12-12T22:12:08.000Z",
          "wordCount": 149763,
          "title": "A Canaanite’s wish to eradicate lice on an inscribed ivory comb from Lachish [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://www.phoronix.com/news/Linux-6.2-Btrfs-EXT4",
          "author": null,
          "description": "Comments",
          "link": "https://www.phoronix.com/news/Linux-6.2-Btrfs-EXT4",
          "publishedOn": "2022-12-12T22:06:25.000Z",
          "wordCount": 1530,
          "title": "Btrfs in Linux 6.2 brings performance improvements, better RAID 5/6 reliability",
          "imageUrl": null
        },
        {
          "id": "https://unovis.dev/",
          "author": null,
          "description": "Comments",
          "link": "https://unovis.dev/",
          "publishedOn": "2022-12-12T20:13:27.000Z",
          "wordCount": 1436,
          "title": "Unovis: Data visualization for React, Angular, Svelte, TypeScript, JavaScript",
          "imageUrl": "https://unovis.dev/img/unovis-social.png"
        },
        {
          "id": "https://yalereview.org/article/surowiecki-geoff-dyer",
          "author": null,
          "description": "Comments",
          "link": "https://yalereview.org/article/surowiecki-geoff-dyer",
          "publishedOn": "2022-12-12T19:28:32.000Z",
          "wordCount": 3795,
          "title": "Geoff Dyer: The essayist on not having a career James Surowiecki",
          "imageUrl": "https://d181q449nqu6en.cloudfront.net/content/craft/articles/_1200x630_crop_center-center_82_none/Dyer_InterviewAsset-1@2x.png?mtime=20221130105717&focal=none&tmtime=20221130111559"
        },
        {
          "id": "https://www.curbsideclassic.com/trackside-classic/trackside-classic-1955-union-pacific-emd-e9-the-last-of-the-classic-diesel-streamliners/",
          "author": null,
          "description": "Comments",
          "link": "https://www.curbsideclassic.com/trackside-classic/trackside-classic-1955-union-pacific-emd-e9-the-last-of-the-classic-diesel-streamliners/",
          "publishedOn": "2022-12-12T19:02:19.000Z",
          "wordCount": 17240,
          "title": "1955 Union Pacific EMD E9 – The Last of the Classic Diesel Streamliners (2012)",
          "imageUrl": "https://i0.wp.com/www.curbsideclassic.com/wp-content/uploads/2022/07/e9.jpg?fit=112%2C96&ssl=1"
        },
        {
          "id": "https://www.prequel.co/blog/database-drivers-naughty-or-nice",
          "author": null,
          "description": "Comments",
          "link": "https://www.prequel.co/blog/database-drivers-naughty-or-nice",
          "publishedOn": "2022-12-12T15:51:57.000Z",
          "wordCount": 1640,
          "title": "Database drivers: Naughty or nice?",
          "imageUrl": "https://uploads-ssl.webflow.com/632e1440a7cdd10ccb606ffd/639746c0b98a9ad7d61dcbd2_NaughtyOrNice_v2.png"
        },
        {
          "id": "https://thewalrus.ca/bring-back-dinosaurs/",
          "author": null,
          "description": "Comments",
          "link": "https://thewalrus.ca/bring-back-dinosaurs/",
          "publishedOn": "2022-12-12T14:40:00.000Z",
          "wordCount": 4275,
          "title": "What would it take to bring back the dinosaurs?",
          "imageUrl": "https://walrus-assets.s3.amazonaws.com/img/Expert_Jurassic-Park_735.jpg"
        },
        {
          "id": "https://sciencenorway.no/archaeoloy-medieval-history-ships/shipwreck-discovered-at-the-bottom-of-norways-largest-lake-possibly-700-years-old/2110769",
          "author": null,
          "description": "Comments",
          "link": "https://sciencenorway.no/archaeoloy-medieval-history-ships/shipwreck-discovered-at-the-bottom-of-norways-largest-lake-possibly-700-years-old/2110769",
          "publishedOn": "2022-12-12T14:36:10.000Z",
          "wordCount": 9830,
          "title": "Medieval ship found in Norway's biggest lake",
          "imageUrl": "https://image.sciencenorway.no/2110998.jpg?imageId=2110998&panow=100&panoh=100&panox=0&panoy=0&heightw=100&heighth=100&heightx=0&heighty=0&width=1200&height=630"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33954778",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33954778",
          "publishedOn": "2022-12-12T14:13:45.000Z",
          "wordCount": 14498,
          "title": "Ask HN: What's your proudest hack?",
          "imageUrl": null
        },
        {
          "id": "https://www.bloomberg.com/news/articles/2022-12-08/the-hype-around-esports-is-fading-as-investors-and-sponsors-flee",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/articles/2022-12-08/the-hype-around-esports-is-fading-as-investors-and-sponsors-flee",
          "publishedOn": "2022-12-12T14:00:18.000Z",
          "wordCount": 576,
          "title": "The hype around esports is fading as investors and sponsors dry up",
          "imageUrl": null
        },
        {
          "id": "https://www.thediff.co/p/a-solution-in-search-of-a-problem",
          "author": null,
          "description": "Comments",
          "link": "https://www.thediff.co/p/a-solution-in-search-of-a-problem",
          "publishedOn": "2022-12-12T13:57:04.000Z",
          "wordCount": 7775,
          "title": "“A solution in search of a problem” is a low-rates phenomenon",
          "imageUrl": "https://substackcdn.com/image/fetch/w_256,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5b730ae4-aa35-496e-8198-965a187e2e43_600x600.png"
        },
        {
          "id": "https://animationobsessive.substack.com/p/the-complicated-man-who-made-rudolph",
          "author": null,
          "description": "Comments",
          "link": "https://animationobsessive.substack.com/p/the-complicated-man-who-made-rudolph",
          "publishedOn": "2022-12-12T13:52:52.000Z",
          "wordCount": 7296,
          "title": "The complicated man who made 'Rudolph'",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad1343d6-91f8-4d63-9080-92e3065707ac_1454x882.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=BVIN_PJu2rs",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=BVIN_PJu2rs",
          "publishedOn": "2022-12-12T12:58:12.000Z",
          "wordCount": null,
          "title": "What if you delete the “Program Files” folder in Windows? [video]",
          "imageUrl": null
        },
        {
          "id": "https://laion.ai/blog/laion-5b/",
          "author": null,
          "description": "Comments",
          "link": "https://laion.ai/blog/laion-5b/",
          "publishedOn": "2022-12-12T12:18:46.000Z",
          "wordCount": 8178,
          "title": "Laion-5B: A new era of open large-scale multi-modal datasets",
          "imageUrl": "https://laion.ai/images/blog/5b.png"
        },
        {
          "id": "https://www.bloomberg.com/features/2022-carlos-ghosn-escape-japan-freedom/",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/features/2022-carlos-ghosn-escape-japan-freedom/",
          "publishedOn": "2022-12-12T10:23:14.000Z",
          "wordCount": 576,
          "title": "Ghosn’s daring escape cost his extraction crew their freedom",
          "imageUrl": null
        },
        {
          "id": "https://www.youtube.com/watch?v=4LvaX748pVI",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=4LvaX748pVI",
          "publishedOn": "2022-12-12T08:51:56.000Z",
          "wordCount": null,
          "title": "I built a wildlife pond [video]",
          "imageUrl": null
        },
        {
          "id": "https://shkspr.mobi/blog/2022/12/how-much-decentralisation-is-too-much/",
          "author": null,
          "description": "Comments",
          "link": "https://shkspr.mobi/blog/2022/12/how-much-decentralisation-is-too-much/",
          "publishedOn": "2022-12-12T07:30:18.000Z",
          "wordCount": 3452,
          "title": "How much decentralisation is too much?",
          "imageUrl": "https://shkspr.mobi/blog/wp-content/uploads/2022/11/b4ceb19c9c54ec7e.png"
        },
        {
          "id": "https://en.wikipedia.org/wiki/Overlapping_markup",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/Overlapping_markup",
          "publishedOn": "2022-12-12T06:33:36.000Z",
          "wordCount": 4444,
          "title": "Overlapping markup",
          "imageUrl": null
        },
        {
          "id": "https://www.wired.com/story/the-extraordinary-shelf-life-of-the-deep-sea-sandwiches/",
          "author": null,
          "description": "Comments",
          "link": "https://www.wired.com/story/the-extraordinary-shelf-life-of-the-deep-sea-sandwiches/",
          "publishedOn": "2022-12-12T03:11:34.000Z",
          "wordCount": 21892,
          "title": "The extraordinary shelf life of the deep sea sandwiches",
          "imageUrl": "https://media.wired.com/photos/6392312c41224999a9db8bea/191:100/w_1280,c_limit/bologna_sandwich_science_GettyImages-176066417.jpg"
        },
        {
          "id": "https://www.washingtonpost.com/politics/2022/01/13/no-one-reads-terms-service-lawmakers-want-fix-that-with-new-tldr-bill/",
          "author": null,
          "description": "Comments",
          "link": "https://www.washingtonpost.com/politics/2022/01/13/no-one-reads-terms-service-lawmakers-want-fix-that-with-new-tldr-bill/",
          "publishedOn": "2022-12-12T01:17:27.000Z",
          "wordCount": 9662,
          "title": "No one reads the terms of service. Lawmakers want to fix that with 'TLDR' bill",
          "imageUrl": "https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/JVQYRUDT74I6ZITNDQQ4C2Y4SM.jpg&w=1440"
        },
        {
          "id": "https://lwn.net/Articles/917504/",
          "author": null,
          "description": "Comments",
          "link": "https://lwn.net/Articles/917504/",
          "publishedOn": "2022-12-12T01:09:26.000Z",
          "wordCount": 297,
          "title": "The 6.1 kernel is out",
          "imageUrl": null
        },
        {
          "id": "https://www.yannickoswald.com/post/are-you-a-nice-to-have-or-must-have",
          "author": null,
          "description": "Comments",
          "link": "https://www.yannickoswald.com/post/are-you-a-nice-to-have-or-must-have",
          "publishedOn": "2022-12-12T01:03:14.000Z",
          "wordCount": 16120,
          "title": "Are you a nice to have or a must have?",
          "imageUrl": "https://static.wixstatic.com/media/7926ce_e488269507dd403998eb52610bb4b9b2~mv2.png/v1/fit/w_1000%2Ch_987%2Cal_c/file.png"
        },
        {
          "id": "https://onformative.com/work/ai-sculpting/",
          "author": null,
          "description": "Comments",
          "link": "https://onformative.com/work/ai-sculpting/",
          "publishedOn": "2022-12-12T00:24:30.000Z",
          "wordCount": 3533,
          "title": "AI Sculpting",
          "imageUrl": "https://backend.onformative.com/assets/work/ai_sculpting_header.jpg"
        },
        {
          "id": "https://singularityhub.com/2022/12/11/astronomers-just-confirmed-the-most-ancient-galaxies-ever-observed/",
          "author": null,
          "description": "Comments",
          "link": "https://singularityhub.com/2022/12/11/astronomers-just-confirmed-the-most-ancient-galaxies-ever-observed/",
          "publishedOn": "2022-12-12T00:11:21.000Z",
          "wordCount": 16967,
          "title": "Astronomers Just Confirmed the Most Ancient Galaxies Ever Observed",
          "imageUrl": "https://singularityhub.com/wp-content/uploads/2022/12/james_webb_image_deep_field-1.jpeg"
        },
        {
          "id": "https://hackaday.com/2021/10/25/the-longest-ever-flight-was-over-64-days-in-a-cessna-172/",
          "author": null,
          "description": "Comments",
          "link": "https://hackaday.com/2021/10/25/the-longest-ever-flight-was-over-64-days-in-a-cessna-172/",
          "publishedOn": "2022-12-11T23:11:59.000Z",
          "wordCount": 5899,
          "title": "The longest ever flight was 64 days in a Cessna 172 (2021)",
          "imageUrl": "https://hackaday.com/wp-content/uploads/2021/10/LongestFlight.jpg"
        },
        {
          "id": "https://www.businessinsider.com/used-vehicle-retailer-carvana-bankruptcy-car-buyers-inventory-2022-12",
          "author": null,
          "description": "Comments",
          "link": "https://www.businessinsider.com/used-vehicle-retailer-carvana-bankruptcy-car-buyers-inventory-2022-12",
          "publishedOn": "2022-12-11T22:56:56.000Z",
          "wordCount": 3307,
          "title": "Carvana sees 98% of its market value evaporate",
          "imageUrl": "https://i.insider.com/6393589f8580f70019f82ebc?width=1200&format=jpeg"
        },
        {
          "id": "https://www.economist.com/asia/2022/12/08/japanese-manga-are-being-eclipsed-by-korean-webtoons",
          "author": null,
          "description": "Comments",
          "link": "https://www.economist.com/asia/2022/12/08/japanese-manga-are-being-eclipsed-by-korean-webtoons",
          "publishedOn": "2022-12-11T22:24:22.000Z",
          "wordCount": 8087,
          "title": "Japanese Manga are being eclipsed by Korean webtoons",
          "imageUrl": "https://www.economist.com/img/b/1280/720/90/media-assets/image/20221210_ASP003.jpg"
        },
        {
          "id": "https://github.com/RobinKa/jaxga",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/RobinKa/jaxga",
          "publishedOn": "2022-12-11T21:58:07.000Z",
          "wordCount": 1192,
          "title": "Jaxga: Geometric Algebra Library for Jax",
          "imageUrl": "https://opengraph.githubassets.com/3e7700ec55c4c9ee31426e55c6d7c4b7dec39f0cf1dc6dd6aa55a23cd0f0adb3/RobinKa/jaxga"
        },
        {
          "id": "https://kevquirk.com/is-dark-mode-such-a-good-idea/",
          "author": null,
          "description": "Comments",
          "link": "https://kevquirk.com/is-dark-mode-such-a-good-idea/",
          "publishedOn": "2022-12-11T21:36:24.000Z",
          "wordCount": 1559,
          "title": "Is Dark Mode Good for Your Eyes? (2020)",
          "imageUrl": "https://cdn.kevquirk.com/wp-content/uploads/2020/04/night-light-gnome-1024x613.png"
        },
        {
          "id": "https://www.washingtonpost.com/video-games/2022/12/08/diablo-iv-release-date-crunch/",
          "author": null,
          "description": "Comments",
          "link": "https://www.washingtonpost.com/video-games/2022/12/08/diablo-iv-release-date-crunch/",
          "publishedOn": "2022-12-11T21:30:44.000Z",
          "wordCount": 12472,
          "title": "‘Diablo IV’ developers work long hours, bracing for impending release",
          "imageUrl": "https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/NYODU5RN25ADHCHDX5TTTD2NFU.jpeg&w=1440"
        },
        {
          "id": "https://wingolog.org/archives/2022/12/11/we-iterate-so-that-you-can-recurse",
          "author": null,
          "description": "Comments",
          "link": "https://wingolog.org/archives/2022/12/11/we-iterate-so-that-you-can-recurse",
          "publishedOn": "2022-12-11T21:25:34.000Z",
          "wordCount": 1069,
          "title": "We iterate so that you can recurse",
          "imageUrl": null
        },
        {
          "id": "https://jakecoppinger.com/2022/12/creating-aerial-imagery-with-a-bike-helmet-camera-and-opendronemap/",
          "author": null,
          "description": "Comments",
          "link": "https://jakecoppinger.com/2022/12/creating-aerial-imagery-with-a-bike-helmet-camera-and-opendronemap/",
          "publishedOn": "2022-12-11T21:16:45.000Z",
          "wordCount": 3823,
          "title": "Creating aerial imagery with a bike helmet camera (GoPro) and OpenDroneMap",
          "imageUrl": "https://jakecoppinger.com/wp-content/uploads/2022/12/blender-perspective-scaled.jpg"
        },
        {
          "id": "https://onesignal.com/careers/4004540006",
          "author": null,
          "description": "Comments",
          "link": "https://onesignal.com/careers/4004540006",
          "publishedOn": "2022-12-11T21:01:59.000Z",
          "wordCount": 382,
          "title": "OneSignal (YC S11) Is Hiring a Product Engineer",
          "imageUrl": "https://media.onesignal.com/cms/_1200x630_crop_center-center_82_none/onesignal.jpg?mtime=1666043174"
        },
        {
          "id": "https://www.nightcap.guru/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nightcap.guru/",
          "publishedOn": "2022-12-11T20:46:50.000Z",
          "wordCount": 10,
          "title": "Using GPT3 to Interpret Dreams",
          "imageUrl": null
        },
        {
          "id": "https://github.com/KanHarI/gpt-commit-summarizer",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/KanHarI/gpt-commit-summarizer",
          "publishedOn": "2022-12-11T20:24:41.000Z",
          "wordCount": 1352,
          "title": "GPT based tool that writes the commit message for you",
          "imageUrl": "https://opengraph.githubassets.com/8e8d2a8762f881bb137b5591e0df27525e3006a49f2fa8f766eedccb10c0b552/KanHarI/gpt-commit-summarizer"
        },
        {
          "id": "https://simon.peytonjones.org/assets/pdfs/haskell-exchange-22.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://simon.peytonjones.org/assets/pdfs/haskell-exchange-22.pdf",
          "publishedOn": "2022-12-11T20:08:40.000Z",
          "wordCount": 79824,
          "title": "Beyond Functional Programming: The Verse Programming Language [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://www.kianryan.co.uk/2022-11-28-psion-sidecar-ppp-modem-and-terminal/",
          "author": null,
          "description": "Comments",
          "link": "https://www.kianryan.co.uk/2022-11-28-psion-sidecar-ppp-modem-and-terminal/",
          "publishedOn": "2022-12-11T19:54:09.000Z",
          "wordCount": 1891,
          "title": "Getting a Psion 5 palmtop from 1997 online via PPP (and a Raspberry Pi)",
          "imageUrl": "https://www.kianryan.co.uk/assets/images/2022/12/02/sidecar_hamsterdance.png"
        },
        {
          "id": "https://www.rbth.com/lifestyle/332384-video-games-soviet-russian-tetris",
          "author": null,
          "description": "Comments",
          "link": "https://www.rbth.com/lifestyle/332384-video-games-soviet-russian-tetris",
          "publishedOn": "2022-12-11T19:16:39.000Z",
          "wordCount": 2183,
          "title": "Video games made in the USSR",
          "imageUrl": "https://mf.b37mrtl.ru/rbthmedia/images/2020.07/article/5efcf4eb85600a6ece556cdf.jpg"
        },
        {
          "id": "https://dcic-world.org/2022-08-28/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://dcic-world.org/2022-08-28/index.html",
          "publishedOn": "2022-12-11T18:42:40.000Z",
          "wordCount": 1743,
          "title": "A data-centric introduction to computing",
          "imageUrl": null
        },
        {
          "id": "https://www.ft.com/content/4b6f0fab-66ef-4e33-adec-cfc345589dc7",
          "author": null,
          "description": "Comments",
          "link": "https://www.ft.com/content/4b6f0fab-66ef-4e33-adec-cfc345589dc7",
          "publishedOn": "2022-12-11T18:29:26.000Z",
          "wordCount": 1609,
          "title": "Fusion energy breakthrough by Livermore Lab",
          "imageUrl": null
        },
        {
          "id": "https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/",
          "author": null,
          "description": "Comments",
          "link": "https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/",
          "publishedOn": "2022-12-11T18:12:34.000Z",
          "wordCount": 7944,
          "title": "What's wrong with social science and how to fix it (2020)",
          "imageUrl": "https://fantasticanachronism.com/images/skimmed_twitter_card.png"
        },
        {
          "id": "https://elastic.github.io/eui/#/",
          "author": null,
          "description": "Comments",
          "link": "https://elastic.github.io/eui/#/",
          "publishedOn": "2022-12-11T17:28:04.000Z",
          "wordCount": 2,
          "title": "Elastic UI – Component library for data-driven web apps",
          "imageUrl": "https://repository-images.githubusercontent.com/107422373/b6180480-a1d7-11eb-8a3c-902086232aa7"
        },
        {
          "id": "https://www.philipotoole.com/how-i-found-a-bug-in-sqlite/",
          "author": null,
          "description": "Comments",
          "link": "https://www.philipotoole.com/how-i-found-a-bug-in-sqlite/",
          "publishedOn": "2022-12-11T17:18:27.000Z",
          "wordCount": 1977,
          "title": "I found a bug in SQLite",
          "imageUrl": "https://www.philipotoole.com/wp-content/uploads/2022/12/bug.png"
        },
        {
          "id": "https://research.nccgroup.com/2022/12/09/public-report-vpn-by-google-one-security-assessment/",
          "author": null,
          "description": "Comments",
          "link": "https://research.nccgroup.com/2022/12/09/public-report-vpn-by-google-one-security-assessment/",
          "publishedOn": "2022-12-11T16:46:53.000Z",
          "wordCount": 1577,
          "title": "VPN by Google One security assessment",
          "imageUrl": "https://i0.wp.com/research.nccgroup.com/wp-content/uploads/2020/07/cropped-Gwl5Lrim_400x400-1.jpg?fit=512%2C512&ssl=1"
        },
        {
          "id": "https://spectrum.ieee.org/airship",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/airship",
          "publishedOn": "2022-12-11T16:46:22.000Z",
          "wordCount": 10269,
          "title": "LTA Research’s Pathfinder 1",
          "imageUrl": "https://spectrum.ieee.org/media-library/people-are-arranged-around-the-rear-end-of-a-white-cylindrical-airship-above-a-white-floor-and-inside-of-a-large-aircraft-hange.jpg?id=32252504&width=1200&height=600&coordinates=0%2C183%2C0%2C184"
        },
        {
          "id": "https://sigmodrecord.org/publications/sigmodRecord/1906/pdfs/06_Profiles_Hipp.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://sigmodrecord.org/publications/sigmodRecord/1906/pdfs/06_Profiles_Hipp.pdf",
          "publishedOn": "2022-12-11T16:00:00.000Z",
          "wordCount": 84174,
          "title": "Richard Hipp Speaks Out on SQLite (2019) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://dugas.ch/artificial_curiosity/GPT_architecture.html",
          "author": null,
          "description": "Comments",
          "link": "https://dugas.ch/artificial_curiosity/GPT_architecture.html",
          "publishedOn": "2022-12-11T12:29:41.000Z",
          "wordCount": 1992,
          "title": "The GPT Architecture, on a Napkin",
          "imageUrl": null
        },
        {
          "id": "https://www.science.org/content/article/ai-unmasks-anonymous-chess-players-posing-privacy-risks",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/content/article/ai-unmasks-anonymous-chess-players-posing-privacy-risks",
          "publishedOn": "2022-12-11T12:09:46.000Z",
          "wordCount": 2329,
          "title": "AI unmasks anonymous chess players, posing privacy risks",
          "imageUrl": "https://www.science.org/do/10.1126/science.ada0080/abs/_20210114_nid_chess.jpg"
        },
        {
          "id": "https://github.com/oyvindln/vhs-decode",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/oyvindln/vhs-decode",
          "publishedOn": "2022-12-11T12:07:50.000Z",
          "wordCount": 3748,
          "title": "VHS-Decode – Software defined VHS decoder",
          "imageUrl": "https://opengraph.githubassets.com/473589da42d7b239f499790e1b2d55748591d17f1929232e53e5b196f4051d17/oyvindln/vhs-decode"
        },
        {
          "id": "https://crypto.junod.info/posts/recursive-hash/",
          "author": null,
          "description": "Comments",
          "link": "https://crypto.junod.info/posts/recursive-hash/",
          "publishedOn": "2022-12-11T11:32:20.000Z",
          "wordCount": 6659,
          "title": "Hashing Apples, Bananas and Cherries",
          "imageUrl": null
        },
        {
          "id": "https://www.atlasobscura.com/articles/white-olives",
          "author": null,
          "description": "Comments",
          "link": "https://www.atlasobscura.com/articles/white-olives",
          "publishedOn": "2022-12-11T05:10:35.000Z",
          "wordCount": 5616,
          "title": "Rediscovering Calabria’s Mystical White Olives",
          "imageUrl": "https://img.atlasobscura.com/2tDJaHnTs7nFlufv2--P-RkQBqgW0yEGGxbLvqmnqOQ/rt:fit/w:600/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy9iZjQ4ODIxMC02/MzA3LTRmN2ItYWM4/YS1hZDU1MjNhN2Iw/ODM3OGU5MmZiMDc3/ZjczZTU2ZDdfd2hp/dGVfb2xpdmVzLmpw/Zw.jpg"
        },
        {
          "id": "https://www.nytimes.com/2022/12/09/science/puzzles-jigsaw-math.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/09/science/puzzles-jigsaw-math.html",
          "publishedOn": "2022-12-11T04:45:43.000Z",
          "wordCount": null,
          "title": "Taking jigsaw puzzles to infinity and beyond",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/zemotion/status/1600529480099196928",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/zemotion/status/1600529480099196928",
          "publishedOn": "2022-12-11T00:43:21.000Z",
          "wordCount": 470,
          "title": "Copyright denied as pose lacks originality",
          "imageUrl": null
        },
        {
          "id": "https://www.cbsnews.com/news/one-pilot-in-cockpit-staffing-shortage-faa-part-121/",
          "author": null,
          "description": "Comments",
          "link": "https://www.cbsnews.com/news/one-pilot-in-cockpit-staffing-shortage-faa-part-121/",
          "publishedOn": "2022-12-10T23:01:02.000Z",
          "wordCount": 1837,
          "title": "Airlines lobbying FAA to have only one pilot in the cockpit",
          "imageUrl": "https://assets2.cbsnewsstatic.com/hub/i/r/2015/11/23/39a3fb9f-cf91-4ad6-86e0-ef7afb500020/thumbnail/1200x630/dbbee551aa6765a80b66fdd40a1b08a9/miracle-on-the-hudson.jpg"
        },
        {
          "id": "https://notesbylex.com/disputing-a-parking-fine-with-chatgpt.html",
          "author": null,
          "description": "Comments",
          "link": "https://notesbylex.com/disputing-a-parking-fine-with-chatgpt.html",
          "publishedOn": "2022-12-10T22:40:10.000Z",
          "wordCount": 343,
          "title": "Disputing a Parking Fine with ChatGPT",
          "imageUrl": "https://notesbylex.com/_media/cover-parking-fine.png"
        },
        {
          "id": "https://www.trains.com/trn/news-reviews/news-wire/amtrak-asks-federal-regulators-to-investigate-union-pacific-handling-of-sunset-limited/",
          "author": null,
          "description": "Comments",
          "link": "https://www.trains.com/trn/news-reviews/news-wire/amtrak-asks-federal-regulators-to-investigate-union-pacific-handling-of-sunset-limited/",
          "publishedOn": "2022-12-10T22:29:59.000Z",
          "wordCount": 31333,
          "title": "Amtrak asks fed regulators to investigate Union Pacific handling of Sunset Ltd",
          "imageUrl": "https://www.trains.com/wp-content/uploads/2022/10/TRN_Sunset_Limited_Johnston.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33936862",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33936862",
          "publishedOn": "2022-12-10T21:13:54.000Z",
          "wordCount": 8730,
          "title": "Tell HN: HP printers force you into agreement",
          "imageUrl": null
        },
        {
          "id": "https://www.cs.yale.edu/publications/techreports/tr1049.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://www.cs.yale.edu/publications/techreports/tr1049.pdf",
          "publishedOn": "2022-12-10T20:14:21.000Z",
          "wordCount": 78053,
          "title": "Haskell, Ada, C++, Awk: An Experiment in Prototyping Productivity (1994) [pdf]",
          "imageUrl": null
        },
        {
          "id": "http://people.uncw.edu/ricanekk/teaching/spring09/csc100/lectures/pattersone/TheMakingOfToyStory.pdf",
          "author": null,
          "description": "Comments",
          "link": "http://people.uncw.edu/ricanekk/teaching/spring09/csc100/lectures/pattersone/TheMakingOfToyStory.pdf",
          "publishedOn": "2022-12-10T20:08:21.000Z",
          "wordCount": 34137,
          "title": "The Making of Toy Story (1996) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://4gravitons.com/2022/12/09/simulated-wormholes-for-my-real-friends-real-wormholes-for-my-simulated-friends/",
          "author": null,
          "description": "Comments",
          "link": "https://4gravitons.com/2022/12/09/simulated-wormholes-for-my-real-friends-real-wormholes-for-my-simulated-friends/",
          "publishedOn": "2022-12-10T20:07:31.000Z",
          "wordCount": 5225,
          "title": "Simulated wormholes for my real friends, real wormholes for my simulated friends",
          "imageUrl": "https://4gravitons.files.wordpress.com/2022/12/quantapreviousheadline.jpg"
        },
        {
          "id": "https://slimvoice.co/login",
          "author": null,
          "description": "Comments",
          "link": "https://slimvoice.co/login",
          "publishedOn": "2022-12-10T19:13:49.000Z",
          "wordCount": 108,
          "title": "Sign in with Google has been removed for your privacy",
          "imageUrl": "https://slimvoice.co/static/img/social_og.png"
        },
        {
          "id": "https://news.yale.edu/2015/09/22/living-artifact-dutch-golden-age-yale-s-367-year-old-water-bond-still-pays-interest",
          "author": null,
          "description": "Comments",
          "link": "https://news.yale.edu/2015/09/22/living-artifact-dutch-golden-age-yale-s-367-year-old-water-bond-still-pays-interest",
          "publishedOn": "2022-12-10T18:56:51.000Z",
          "wordCount": 2169,
          "title": "Yale’s 367-year-old water bond still pays interest (2015)",
          "imageUrl": "https://news.yale.edu/sites/default/files/styles/opengraph_image/public/thumbnail/yale-dutch-water-bond.jpg?itok=FtcU7VR5"
        },
        {
          "id": "https://www.trains.com/trn/news-reviews/news-wire/groundbreaking-marks-start-of-work-on-penn-station-access/",
          "author": null,
          "description": "Comments",
          "link": "https://www.trains.com/trn/news-reviews/news-wire/groundbreaking-marks-start-of-work-on-penn-station-access/",
          "publishedOn": "2022-12-10T18:51:38.000Z",
          "wordCount": 30089,
          "title": "Groundbreaking marks start of work on Penn Station Access",
          "imageUrl": "https://www.trains.com/wp-content/uploads/2022/12/TRN_Penn_Access_groundbreaking.jpg"
        },
        {
          "id": "https://research.american.edu/carbonremoval/2020/09/29/fuel-out-of-thin-air-co2-capture-from-air-and-conversion-to-methanol/",
          "author": null,
          "description": "Comments",
          "link": "https://research.american.edu/carbonremoval/2020/09/29/fuel-out-of-thin-air-co2-capture-from-air-and-conversion-to-methanol/",
          "publishedOn": "2022-12-10T18:34:48.000Z",
          "wordCount": 1984,
          "title": "Fuel out of thin air: CO2 capture from air and conversion to methanol (2020)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/albfan/miraclecast",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/albfan/miraclecast",
          "publishedOn": "2022-12-10T18:23:28.000Z",
          "wordCount": 1560,
          "title": "MiracleCast",
          "imageUrl": "https://opengraph.githubassets.com/fb4b08068c005954b7a2978ba1a3ce2b9a4c6f25af96d43310aadaa8bb768a3f/albfan/miraclecast"
        },
        {
          "id": "https://www.alma.sh/",
          "author": null,
          "description": "Comments",
          "link": "https://www.alma.sh/",
          "publishedOn": "2022-12-10T17:48:38.000Z",
          "wordCount": 9,
          "title": "Alma – Generative Graphics Creator",
          "imageUrl": null
        },
        {
          "id": "https://lab.whitequark.org/notes/2020-04-06/synthesizing-optimal-8051-code/",
          "author": null,
          "description": "Comments",
          "link": "https://lab.whitequark.org/notes/2020-04-06/synthesizing-optimal-8051-code/",
          "publishedOn": "2022-12-10T17:39:06.000Z",
          "wordCount": 2883,
          "title": "Synthesizing optimal 8051 code with an SMT solver (2020)",
          "imageUrl": null
        },
        {
          "id": "http://triskweline.de/unpoly-rugb/#/",
          "author": null,
          "description": "Comments",
          "link": "http://triskweline.de/unpoly-rugb/#/",
          "publishedOn": "2022-12-10T17:35:12.000Z",
          "wordCount": 4098,
          "title": "Breaking up with JavaScript front ends",
          "imageUrl": null
        },
        {
          "id": "https://thebaffler.com/salvos/the-father-of-all-secrets-adler-bell",
          "author": null,
          "description": "Comments",
          "link": "https://thebaffler.com/salvos/the-father-of-all-secrets-adler-bell",
          "publishedOn": "2022-12-10T17:15:12.000Z",
          "wordCount": 6415,
          "title": "The father of all secrets: John le Carré’s daddy issues",
          "imageUrl": "https://thebaffler.com/wp-content/uploads/2022/12/b66-adler-bell-scaled.jpg"
        },
        {
          "id": "https://www.quantamagazine.org/what-causes-alzheimers-scientists-are-rethinking-the-answer-20221208/",
          "author": null,
          "description": "Comments",
          "link": "https://www.quantamagazine.org/what-causes-alzheimers-scientists-are-rethinking-the-answer-20221208/",
          "publishedOn": "2022-12-10T17:02:00.000Z",
          "wordCount": 22140,
          "title": "What causes Alzheimer's? Scientists are rethinking the answer",
          "imageUrl": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/12/Alzheimer-byHarolBustos-Social.webp"
        },
        {
          "id": "https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/",
          "author": null,
          "description": "Comments",
          "link": "https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/",
          "publishedOn": "2022-12-10T16:55:33.000Z",
          "wordCount": 9198,
          "title": "DDD, Hexagonal, Onion, Clean, CQRS, How I put it all together (2017)",
          "imageUrl": "https://herbertograca.files.wordpress.com/2018/11/100-explicit-architecture-svg.png?w=1200"
        },
        {
          "id": "https://www.amazingcto.com/postgres-for-everything/",
          "author": null,
          "description": "Comments",
          "link": "https://www.amazingcto.com/postgres-for-everything/",
          "publishedOn": "2022-12-10T16:52:58.000Z",
          "wordCount": 1321,
          "title": "Just use Postgres for everything",
          "imageUrl": "/Amazing_CTO_Banner.png"
        },
        {
          "id": "https://arxiv.org/abs/2212.03551",
          "author": null,
          "description": "Comments",
          "link": "https://arxiv.org/abs/2212.03551",
          "publishedOn": "2022-12-10T16:12:02.000Z",
          "wordCount": 573,
          "title": "Talking About Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33932594",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33932594",
          "publishedOn": "2022-12-10T13:51:32.000Z",
          "wordCount": 8298,
          "title": "Ask HN: How to get back into AI?",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}