{
  "sources": [
    {
      "title": "Release notes from osmosfeed",
      "feedUrl": "https://github.com/osmoscraft/osmosfeed/releases.atom",
      "siteUrl": "https://github.com/osmoscraft/osmosfeed/releases",
      "articles": []
    },
    {
      "title": "CSS-Tricks",
      "feedUrl": "https://css-tricks.com/feed/",
      "siteUrl": "https://css-tricks.com",
      "articles": [
        {
          "id": "https://css-tricks.com/?p=375869",
          "author": "Geoff Graham",
          "description": "We’ve started making a tradition of rounding up the latest front-end research at the end of each year. We did it in 2020 and again in 2021. Reports are released throughout the year by a bunch of different companies …\n2022 Roundup of Web Research originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/2022-roundup-of-web-research/",
          "publishedOn": "2022-12-21T15:03:50.000Z",
          "wordCount": 6054,
          "title": "2022 Roundup of Web Research",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375869"
        },
        {
          "id": "https://css-tricks.com/?p=376319",
          "author": "Geoff Graham",
          "description": "CSS Nesting is making the rounds yet again. Remember earlier this year when Adam and Mia put three syntax options up for a vote? Those results were tallied and it wasn’t even even close.\nNow there’s another chance …\nHelp choose the syntax for CSS Nesting originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/help-choose-the-syntax-for-css-nesting/",
          "publishedOn": "2022-12-20T16:04:54.000Z",
          "wordCount": 835,
          "title": "Help choose the syntax for CSS Nesting",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/376319"
        },
        {
          "id": "https://css-tricks.com/?p=376297",
          "author": "Geoff Graham",
          "description": "Being able to quickly spin up a WordPress instance has been the strength of WordPress ever since its famous “five-minute install”. Upload a few files, configure a few settings, and you’re off.\nThe friction of uploading files has gotten …\nWordPress Playground: Running WordPress in the Browser originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/wordpress-playground-run-in-browser/",
          "publishedOn": "2022-12-19T16:52:45.000Z",
          "wordCount": 1012,
          "title": "WordPress Playground: Running WordPress in the Browser",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/376297"
        },
        {
          "id": "https://css-tricks.com/?p=375621",
          "author": "Temani Afif",
          "description": "In this series, we’ve been making image sliders with nothing but HTML and CSS. The idea is that we can use the same markup but different CSS to get wildly different results, no matter how many images we toss …\nCSS Infinite 3D Sliders originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/css-infinite-3d-sliders/",
          "publishedOn": "2022-12-16T14:58:08.000Z",
          "wordCount": 2796,
          "title": "CSS Infinite 3D Sliders",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375621"
        },
        {
          "id": "https://css-tricks.com/?p=375714",
          "author": "Geoff Graham",
          "description": "The CSS Working Group gave that a thumbs-up a couple weeks ago. The super-duper conceptual proposal being that we can animate or transition from, say, display: block to display: none.\nIt’s a bit of a brain-twister to reason …\nSo, you’d like to animate the display property originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/so-youd-like-to-animate-the-display-property/",
          "publishedOn": "2022-12-15T15:41:06.000Z",
          "wordCount": 1269,
          "title": "So, you’d like to animate the display property",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375714"
        },
        {
          "id": "https://css-tricks.com/?p=376201",
          "author": "Geoff Graham",
          "description": "Every so often, I find that the links I save to read later fall into natural groups or patterns that reveal common threads of interest. The past couple of weeks have produced a lot of thoughts about ChatGPT, an …\nSome Links on AI-Related Stuff originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/some-links-on-ai-related-stuff/",
          "publishedOn": "2022-12-14T21:34:06.000Z",
          "wordCount": 1292,
          "title": "Some Links on AI-Related Stuff",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/376201"
        },
        {
          "id": "https://css-tricks.com/?p=375952",
          "author": "Geoff Graham",
          "description": "Suzy Naschansky from the HTMHell Advent Calendar:\n<h2 id=\"article1-heading\"All About Dragons</h2<pI like dragons. Blah blah blah blah blah.</p<p<a id=\"article1-read-more\" aria-labelledby=\"article1-read-more article1-heading\"Read more</a</p\nSee that aria-labelledby attribute? It chains two IDs from the …\nUnchain My Inaccessibly-Labelled Heart originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/unchain-my-inaccessibly-labelled-heart/",
          "publishedOn": "2022-12-14T14:08:20.000Z",
          "wordCount": 1173,
          "title": "Unchain My Inaccessibly-Labelled Heart",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375952"
        },
        {
          "id": "https://css-tricks.com/?p=376229",
          "author": "Geoff Graham",
          "description": "We’ve got ourselves a real holiday treat! Join host Alex Trost from the Frontend Horse community for the Holiday Snowtacular 2022 this Friday, December 16.\nThere’s a lineup of 12 awesome speakers — including Chris Coyier, Cassidy Williams, Kevin …\nHoliday Snowtacular 2022 originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/holiday-snowtacular-2022/",
          "publishedOn": "2022-12-13T23:03:49.000Z",
          "wordCount": 796,
          "title": "Holiday Snowtacular 2022",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/376229"
        },
        {
          "id": "https://css-tricks.com/?p=375728",
          "author": "Dan Christofi",
          "description": "CSS Container Queries are still gaining traction and many of us are getting our hands wet with them, even if it’s for little experiments or whatnot. They’ve got great, but not quite full, browser support — enough to justify using …\nA Few Times Container Size Queries Would Have Helped Me Out originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/a-few-times-container-size-queries-would-have-helped-me-out/",
          "publishedOn": "2022-12-13T13:53:56.000Z",
          "wordCount": 2299,
          "title": "A Few Times Container Size Queries Would Have Helped Me Out",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375728"
        },
        {
          "id": "https://css-tricks.com/?p=375722",
          "author": "Geoff Graham",
          "description": "Sara Soueidan with everything you need, from what screen reading options are out there all the way to setting up virtual machines for them, installing them, and confguring keyboard options. It’s truly a one-stop reference that pulls together disparate …\nSetting up a screen reader testing environment on your computer originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/setting-up-a-screen-reader-testing-environment-on-your-computer/",
          "publishedOn": "2022-12-12T20:56:58.000Z",
          "wordCount": 807,
          "title": "Setting up a screen reader testing environment on your computer",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375722"
        },
        {
          "id": "https://css-tricks.com/?p=375577",
          "author": "Manoj Kumar",
          "description": "We’ve accomplished a bunch of stuff in this series! We created a custom WordPress block that fetches data from an external API and renders it on the front end. Then we took that work and extended it so the data …\nSaving Settings for a Custom WordPress Block in the Block Editor originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/saving-settings-for-a-custom-wordpress-block-in-the-block-editor/",
          "publishedOn": "2022-12-12T14:06:39.000Z",
          "wordCount": 1565,
          "title": "Saving Settings for a Custom WordPress Block in the Block Editor",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375577"
        },
        {
          "id": "https://css-tricks.com/?p=375537",
          "author": "Temani Afif",
          "description": "In the last article, we made a pretty cool little slider (or “carousel” if that’s what you prefer) that rotates in a circular direction. This time we are going to make one that flips through a stack of Polaroid …\nCSS Infinite Slider Flipping Through Polaroid Images originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/css-infinite-slider-flipping-through-polaroid-images/",
          "publishedOn": "2022-12-09T14:26:39.000Z",
          "wordCount": 3542,
          "title": "CSS Infinite Slider Flipping Through Polaroid Images",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375537"
        },
        {
          "id": "https://css-tricks.com/?p=375697",
          "author": "Preethi",
          "description": "How often to do you reach for the CSS background-size property? If you’re like me — and probably lots of other front-end folks — then it’s usually when you background-size: cover an image to fill the space of an entire …\nAnimated Background Stripes That Transition on Hover originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/animated-background-stripes-transition-hover/",
          "publishedOn": "2022-12-08T15:36:21.000Z",
          "wordCount": 2431,
          "title": "Animated Background Stripes That Transition on Hover",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375697"
        },
        {
          "id": "https://css-tricks.com/?p=375412",
          "author": "Ganesh Dahal",
          "description": "The CSS box-shadow and outline properties gained theme.json support in WordPress 6.1. Let's look at a few examples of how it works in real themes, and what options we have to apply these styles to WordPress blocks and elements.\nAdding Box Shadows to WordPress Blocks and Elements originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/adding-box-shadows-to-wordpress-blocks-and-elements/",
          "publishedOn": "2022-12-07T13:59:50.000Z",
          "wordCount": 1929,
          "title": "Adding Box Shadows to WordPress Blocks and Elements",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375412"
        },
        {
          "id": "https://css-tricks.com/?p=375747",
          "author": "Geoff Graham",
          "description": "Nothing but ear-to-ear smiles as I was watching this video from @quayjn on YouTube. (No actual name in the byline, though I think it’s Brian Katz if my paper trail is correct).\nThe best is this Pen you can …\nCSS is OK, I guess. originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/css-is-ok-i-guess/",
          "publishedOn": "2022-12-06T15:37:50.000Z",
          "wordCount": 845,
          "title": "CSS is OK, I guess.",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375747"
        },
        {
          "id": "https://css-tricks.com/?p=375184",
          "author": "Pieter De Decker",
          "description": "For years, a small pedantry war has been raging in our address bars. In one corner are brands like Google, Instagram, and Facebook. This group has chosen to redirect example.com to www.example.com. In the opposite corner: …\nDoes WWW still belong in URLs? originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/does-www-still-belong-in-urls/",
          "publishedOn": "2022-12-05T15:20:22.000Z",
          "wordCount": 1667,
          "title": "Does WWW still belong in URLs?",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375184"
        },
        {
          "id": "https://css-tricks.com/?p=375308",
          "author": "Temani Afif",
          "description": "Image sliders (also called carousels) are everywhere. There are a lot of CSS tricks to create the common slider where the images slide from left to right (or the opposite). It’s the same deal with the many JavaScript libraries out …\nCSS Infinite and Circular Rotating Image Slider originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/css-only-infinite-and-circular-image-slider/",
          "publishedOn": "2022-12-02T14:12:57.000Z",
          "wordCount": 2394,
          "title": "CSS Infinite and Circular Rotating Image Slider",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375308"
        },
        {
          "id": "https://css-tricks.com/?p=375607",
          "author": "Geoff Graham",
          "description": "I wrote up some early thoughts on container style queries a little while back. It’s still early days. They’re already defined in the CSS Containment Module Level 1 specification (currently in Editor’s Draft status) but there’s still a couple of …\nDigging Deeper Into Container Style Queries originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/digging-deeper-into-container-style-queries/",
          "publishedOn": "2022-12-01T13:59:06.000Z",
          "wordCount": 2245,
          "title": "Digging Deeper Into Container Style Queries",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375607"
        },
        {
          "id": "https://css-tricks.com/?p=375278",
          "author": "Ganesh Dahal",
          "description": "One of the main goals of the WordPress Site Editor (and, yes, that is now the “official” name) is to move basic block styling from CSS to structured JSON. JSON files are machine-readable, which makes it consumable by …\nUsing The New Constrained Layout In WordPress Block Themes originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/using-the-new-constrained-layout-in-wordpress-block-themes/",
          "publishedOn": "2022-11-30T14:11:10.000Z",
          "wordCount": 2774,
          "title": "Using The New Constrained Layout In WordPress Block Themes",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375278"
        },
        {
          "id": "https://css-tricks.com/?p=375190",
          "author": "Geoff Graham",
          "description": "I’m a sucker for anything about front-end job titles.\nAnselm Hannemann:\nCSS evolved and we’re beyond the point where everyone can just do it as a side interest. We all can learn it and build amazing stuff with it, \n…\nMore Than “Slapping Paint on a Website” originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/more-than-slapping-paint-on-a-website/",
          "publishedOn": "2022-11-29T15:03:20.000Z",
          "wordCount": 1078,
          "title": "More Than “Slapping Paint on a Website”",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375190"
        },
        {
          "id": "https://css-tricks.com/?p=375273",
          "author": "Daniel Schwarz",
          "description": "HTML lists are boring. They don’t do much, so we don’t really think about them despite how widely used they are. And we’re still able to do the same things we’ve always done to customize them, like removing markers, reversing …\nNewer Things to Know About Good Ol’ HTML Lists originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
          "link": "https://css-tricks.com/newer-things-to-know-about-good-ol-html-lists/",
          "publishedOn": "2022-11-28T14:05:11.000Z",
          "wordCount": 2148,
          "title": "Newer Things to Know About Good Ol’ HTML Lists",
          "imageUrl": "https://css-tricks.com/wp-json/social-image-generator/v1/image/375273"
        }
      ]
    },
    {
      "title": "Articles on Smashing Magazine — For Web Designers And Developers",
      "feedUrl": "https://www.smashingmagazine.com/feed/",
      "siteUrl": "https://www.smashingmagazine.com/",
      "articles": [
        {
          "id": "https://smashingmagazine.com/2022/12/deploying-css-logical-properties-on-web-apps/",
          "author": "hello@smashingmagazine.com (Nicolas Hoffmann)",
          "description": "You may have already heard of CSS logical properties or RTL adaptations but are still deciding whether to deploy them widely. To help raise your awareness of their possibilities, Nicolas Hoffmann shares his experience of how he and his team at Proton carried out a massive move from CSS logical props to production and how you can consider them from a different perspective in your very own projects.",
          "link": "https://smashingmagazine.com/2022/12/deploying-css-logical-properties-on-web-apps/",
          "publishedOn": "2022-12-23T13:00:00.000Z",
          "wordCount": 4365,
          "title": "Deploying CSS Logical Properties On Web Apps",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/dd6913e4-e4eb-4bc9-8b51-0f8d596ee839/deploying-css-logical-properties-on-web-apps.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/dd6913e4-e4eb-4bc9-8b51-0f8d596ee839/deploying-css-logical-properties-on-web-apps.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/useful-accessibility-usability-examples-help-improve-your-designs/",
          "author": "hello@smashingmagazine.com (Thomas Bohm)",
          "description": "In this article, Thomas Bohm shares strategies and methods to tackle some common graphic communication problems and gives you insights into how to improve accessibility and usability and make your designs much better.",
          "link": "https://smashingmagazine.com/2022/12/useful-accessibility-usability-examples-help-improve-your-designs/",
          "publishedOn": "2022-12-20T12:00:00.000Z",
          "wordCount": 8297,
          "title": "Useful Accessibility And Usability Examples To Help Improve Your Designs",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6d616de6-54bc-44cd-b63b-271cc7d5f3be/useful-accessibility-usability-examples-help-improve-your-designs.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6d616de6-54bc-44cd-b63b-271cc7d5f3be/useful-accessibility-usability-examples-help-improve-your-designs.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/taking-stress-out-design-system-management/",
          "author": "hello@smashingmagazine.com (Masha Shaposhnikova)",
          "description": "In this article, Masha goes over five tips that make it easier to manage a design system while increasing its effectiveness. This short guide is aimed at smaller teams.",
          "link": "https://smashingmagazine.com/2022/12/taking-stress-out-design-system-management/",
          "publishedOn": "2022-12-19T13:00:00.000Z",
          "wordCount": 5486,
          "title": "Taking The Stress Out Of Design System Management",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/bd9f560b-bc0f-49d0-8b82-c9fbaf8d3915/taking-stress-out-design-system-management.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/bd9f560b-bc0f-49d0-8b82-c9fbaf8d3915/taking-stress-out-design-system-management.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/optimizing-design-workflow-tools/",
          "author": "hello@smashingmagazine.com (Ashish Bogawat)",
          "description": "In this article, Ashish Bogawat shares some of his favorite ways how to boost productivity and do things faster, better, and probably more fun by using efficient tools and workflows.",
          "link": "https://smashingmagazine.com/2022/12/optimizing-design-workflow-tools/",
          "publishedOn": "2022-12-16T10:00:00.000Z",
          "wordCount": 5651,
          "title": "Optimizing Your Design Workflow With Tools",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fea883cf-c97a-43dc-b537-bc2147183cde/optimizing-design-workflow-tools.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fea883cf-c97a-43dc-b537-bc2147183cde/optimizing-design-workflow-tools.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/prioritize-user-security-collecting-offline-data/",
          "author": "hello@smashingmagazine.com (Suzanne Scacca)",
          "description": "Concerns over online privacy and security are nothing new. In this article, Suzanne Scacca explores how the right CSV importer can help businesses better prioritize user security.",
          "link": "https://smashingmagazine.com/2022/12/prioritize-user-security-collecting-offline-data/",
          "publishedOn": "2022-12-15T13:30:00.000Z",
          "wordCount": 4234,
          "title": "How To Prioritize User Security When Collecting Offline Data",
          "enclosure": {
            "url": "http://res.cloudinary.com/indysigner/image/upload/v1670867131/prioritize-user-security-collecting-offline-data_nozcsc.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://res.cloudinary.com/indysigner/image/upload/v1670867131/prioritize-user-security-collecting-offline-data_nozcsc.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/understanding-privacy-protect-your-users-protect-yourself/",
          "author": "hello@smashingmagazine.com (Heather Burns)",
          "description": "All of us want to create inclusive, safe, and privacy-aware digital experiences, but where to begin? Our brand new Smashing Book, “Understanding Privacy,” written by Heather Burns, can help you lay the ground for future developers, designers, and project managers to build a better web for tomorrow. [Jump to the details](https://www.smashingmagazine.com/2022/12/understanding-privacy-new-smashing-book/#about-the-book) or [get the book right away](https://www.smashingmagazine.com/printed-books/understanding-privacy/).",
          "link": "https://smashingmagazine.com/2022/12/understanding-privacy-protect-your-users-protect-yourself/",
          "publishedOn": "2022-12-13T17:30:00.000Z",
          "wordCount": 4423,
          "title": "Understanding Privacy: Protect Your Users, Protect Yourself",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d490bcc4-aa79-4b19-a39c-6ed3a8ae815c/understanding-privacy-protect-your-users-protect-yourself.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d490bcc4-aa79-4b19-a39c-6ed3a8ae815c/understanding-privacy-protect-your-users-protect-yourself.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/accessible-front-end-patterns-responsive-tables-part2/",
          "author": "hello@smashingmagazine.com (Adrian Bece)",
          "description": "There is no universal solution for making every kind of table responsive and usable on smaller screens, so we have to rely on various patterns, which Adrian explains in this two-part series.",
          "link": "https://smashingmagazine.com/2022/12/accessible-front-end-patterns-responsive-tables-part2/",
          "publishedOn": "2022-12-13T15:00:00.000Z",
          "wordCount": 5614,
          "title": "Accessible Front-End Patterns For Responsive Tables (Part 2)",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ef4ceadc-3a08-4ff7-ae9e-4e44b1054feb/accessible-front-end-patterns-responsive-tables-part2.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ef4ceadc-3a08-4ff7-ae9e-4e44b1054feb/accessible-front-end-patterns-responsive-tables-part2.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/future-design-human-powered-ai-driven/",
          "author": "hello@smashingmagazine.com (Keima Kai)",
          "description": "In this article, Keima Kai provides a brief history of AI in web design, explores its current implications for creativity, and offers suggestions for how web designers can stay ahead of the curve.",
          "link": "https://smashingmagazine.com/2022/12/future-design-human-powered-ai-driven/",
          "publishedOn": "2022-12-12T13:00:00.000Z",
          "wordCount": 5849,
          "title": "The Future Of Design: Human-Powered Or AI-Driven?",
          "enclosure": {
            "url": "http://res.cloudinary.com/indysigner/image/upload/v1670850655/future-design-human-powered-ai-driven_jn1p6k.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://res.cloudinary.com/indysigner/image/upload/v1670850655/future-design-human-powered-ai-driven_jn1p6k.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/understanding-privacy-new-smashing-book/",
          "author": "hello@smashingmagazine.com (Vitaly Friedman)",
          "description": "“Understanding Privacy,” the new Smashing Book by Heather Burns, will help you create inclusive, safe and privacy-aware digital experiences. Print books are now shipping! [Jump to details](https://www.smashingmagazine.com/2022/12/understanding-privacy-new-smashing-book/#about-the-book) and [get the book right away](https://www.smashingmagazine.com/printed-books/understanding-privacy/).",
          "link": "https://smashingmagazine.com/2022/12/understanding-privacy-new-smashing-book/",
          "publishedOn": "2022-12-08T13:00:00.000Z",
          "wordCount": 3882,
          "title": "It’s Here! “Understanding Privacy,” A New Smashing Book Is Shipping Now",
          "enclosure": {
            "url": "http://res.cloudinary.com/indysigner/image/upload/v1670507147/understanding-privacy-2048-marcthiele-55_weoj8z.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://res.cloudinary.com/indysigner/image/upload/v1670507147/understanding-privacy-2048-marcthiele-55_weoj8z.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/tech-advent-calendars-web-developers-web-designers-2022/",
          "author": "hello@smashingmagazine.com (Cosima Mielke)",
          "description": "Are you ready for the countdown to Christmas? This year, the web community was once again busy creating tech advent calendars jam-packed with fantastic content to sweeten your days. But which ones to follow? We help you find the right one, whether you’re a front-end dev, UX designer, or content strategist.",
          "link": "https://smashingmagazine.com/2022/12/tech-advent-calendars-web-developers-web-designers-2022/",
          "publishedOn": "2022-12-07T11:00:00.000Z",
          "wordCount": 5393,
          "title": "Advent Calendars For Web Designers And Developers (2022 Edition)",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/36b5e738-ea60-4f9a-91bc-9d66803d8dc1/advent-topple-22.png",
            "length": "0",
            "type": "image/png"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/36b5e738-ea60-4f9a-91bc-9d66803d8dc1/advent-topple-22.png"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/accessible-front-end-patterns-responsive-tables-part1/",
          "author": "hello@smashingmagazine.com (Adrian Bece)",
          "description": "There is no universal solution for making every kind of table responsive and usable on smaller screens, so we have to rely on various patterns, which Adrian explains in this two-part series.",
          "link": "https://smashingmagazine.com/2022/12/accessible-front-end-patterns-responsive-tables-part1/",
          "publishedOn": "2022-12-06T12:00:00.000Z",
          "wordCount": 6056,
          "title": "Accessible Front-End Patterns For Responsive Tables (Part 1)",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1a082e68-4b7b-47df-ab6a-f1b9105b491e/accessible-front-end-patterns-responsive-tables-part1.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1a082e68-4b7b-47df-ab6a-f1b9105b491e/accessible-front-end-patterns-responsive-tables-part1.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/anatomy-themed-design-system-components/",
          "author": "hello@smashingmagazine.com (Dan Donald)",
          "description": "The world of design systems can be overwhelming sometimes. There’s a lot to take in when you get into that space! In this article, Dan Donald dives into a simple component and explores some issues, complexity, and power we can encounter.",
          "link": "https://smashingmagazine.com/2022/12/anatomy-themed-design-system-components/",
          "publishedOn": "2022-12-02T09:00:00.000Z",
          "wordCount": 6511,
          "title": "The Anatomy Of Themed Design System Components",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/56513693-7577-4bc5-9baf-ed8f489f24ca/anatomy-themed-design-system-components.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/56513693-7577-4bc5-9baf-ed8f489f24ca/anatomy-themed-design-system-components.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/12/fabunit-smart-way-control-synchronize-typo-space/",
          "author": "hello@smashingmagazine.com (Fabienne Bielmann)",
          "description": "Today, we’ll take a look at the Sass function that does all the work for you — with no media queries, no breakpoints, and no design jumps. In this article, Fabienne Bielmann explains what FabUnit stands for and why she decided to create her very own responsive magic formula.",
          "link": "https://smashingmagazine.com/2022/12/fabunit-smart-way-control-synchronize-typo-space/",
          "publishedOn": "2022-12-01T09:00:00.000Z",
          "wordCount": 4979,
          "title": "FabUnit: A Smart Way To Control And Synchronize Typo And Space",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3b3ae408-a861-423b-a18c-bbe6151bbe83/fabunit-smart-way-control-synchronize-typo-space.jpg",
            "length": "0",
            "type": "image/jpg"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3b3ae408-a861-423b-a18c-bbe6151bbe83/fabunit-smart-way-control-synchronize-typo-space.jpg"
        },
        {
          "id": "https://smashingmagazine.com/2022/11/desktop-wallpaper-calendars-december-2022/",
          "author": "hello@smashingmagazine.com (Cosima Mielke)",
          "description": "December is almost here, so why not spread some holiday love across your devices? We’ve got some beautiful wallpapers to sweeten up the last days of the year.",
          "link": "https://smashingmagazine.com/2022/11/desktop-wallpaper-calendars-december-2022/",
          "publishedOn": "2022-11-30T11:15:00.000Z",
          "wordCount": 5138,
          "title": "Endings And New Beginnings (December 2022 Desktop Wallpapers Edition)",
          "enclosure": {
            "url": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a6b9bd64-491c-4be4-bb3e-0295fea6f0c6/dec-19-dear-moon-merry-christmas-preview-opt.png",
            "length": "0",
            "type": "image/png"
          },
          "imageUrl": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a6b9bd64-491c-4be4-bb3e-0295fea6f0c6/dec-19-dear-moon-merry-christmas-preview-opt.png"
        }
      ]
    },
    {
      "title": "freeCodeCamp.org",
      "feedUrl": "https://www.freecodecamp.org/news/rss/",
      "siteUrl": "https://www.freecodecamp.org/news/",
      "articles": [
        {
          "id": "https://www.freecodecamp.org/news/learn-to-code-rpg-1-5-update/",
          "author": "Lynn Zheng",
          "description": "Hello from the Learn to Code RPG dev team! We are Lynn, KayLa, and Nielda. And we've been hard at work building out new adventures for our characters. I'm excited to announce the launch of Learn to Code RPG v1.5, a year after the launch of Learn to Code RPG",
          "link": "https://www.freecodecamp.org/news/learn-to-code-rpg-1-5-update/",
          "publishedOn": "2022-12-23T02:43:43.000Z",
          "wordCount": 2134,
          "title": "Learn to Code RPG Version 1.5 is Now Playable with Hours of New Gameplay",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/splash-2-lowres-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/serverless-caching-for-your-web-applications/",
          "author": "Andrew Brown",
          "description": "When to Use a Cache When you are building a web-application, you'll need to fetch data from a database. As your traffic and the size of your database grows, you will find that querying your database gets slower and slower. In order to return requests to users quickly, a cache",
          "link": "https://www.freecodecamp.org/news/serverless-caching-for-your-web-applications/",
          "publishedOn": "2022-12-22T20:45:05.000Z",
          "wordCount": 1830,
          "title": "How to Cache Expensive Database Queries Using the Momento Serverless Cache",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-tiger-lily-4483610.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/string-equality-in-javascript-how-to-compare-strings-in-js/",
          "author": "Joel Olawanle",
          "description": "When writing code or building a solution, you might need to compare two strings to see if they are the same before proceeding with an operation. For example, when a user signs in, you'll want to compare the username the provide to the one in your database to see if",
          "link": "https://www.freecodecamp.org/news/string-equality-in-javascript-how-to-compare-strings-in-js/",
          "publishedOn": "2022-12-22T18:57:16.000Z",
          "wordCount": 1396,
          "title": "String Equality in JavaScript – How to Compare Strings in JS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-template--3-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/adding-to-a-dict-in-python-how-to-add-to-a-dictionary/",
          "author": "Kolade Chris",
          "description": "A Python dictionary is like a JavaScript object – it’s a sequence of key:value  pairs. So, you can create them like this: stack_dict = {     \"frontend\": \"JavaScript\",     \"backend\": \"Node JS\",     \"markup\": \"HTML and JSX\", } To access",
          "link": "https://www.freecodecamp.org/news/adding-to-a-dict-in-python-how-to-add-to-a-dictionary/",
          "publishedOn": "2022-12-22T18:04:49.000Z",
          "wordCount": 1315,
          "title": "Adding to a Dict in Python – How to Add to a Dictionary",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/addToDict.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-javascript-works-behind-the-scene-javascript-execution-context/",
          "author": "Rwitesh Bera",
          "description": "Have you ever wondered how JavaScript works behind the scenes? It's actually quite fascinating! And that's what you'll learn about here. JavaScript is a single-threaded interpreted language. Every browser has its own JavaScript engine. Google Chrome has the V8 engine, Mozilla Firefox has SpiderMonkey, and so on. They all are",
          "link": "https://www.freecodecamp.org/news/how-javascript-works-behind-the-scene-javascript-execution-context/",
          "publishedOn": "2022-12-22T17:50:05.000Z",
          "wordCount": 1733,
          "title": "JavaScript Execution Context – How JS Works Behind the Scenes",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Dark-Blue-Illustrated-Techno-Daily-Smore-Header--1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-enumerate-in-python/",
          "author": "Suchandra Datta",
          "description": "The enumerate() function is one of the built-in functions in Python. It provides a handy way to access each item in an iterable, along with a count value that specifies the order in which the item was accessed.  In this article you will learn all that you need to",
          "link": "https://www.freecodecamp.org/news/what-is-enumerate-in-python/",
          "publishedOn": "2022-12-22T15:56:07.000Z",
          "wordCount": 2336,
          "title": "What is enumerate() in Python? Enumeration Example",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-yan-krukov-8612931.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/filtering-in-csharp-how-to-filter-a-list-with-code-examples/",
          "author": "Edeh Israel Chidera",
          "description": "Filtering through a data set is one of the most basic operations a developer should know how to perform.  Filtering [https://learn.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/filtering-data]  refers to the process of restricting the result set to contain only those elements that satisfy a specified condition. It is also known as selection.  To",
          "link": "https://www.freecodecamp.org/news/filtering-in-csharp-how-to-filter-a-list-with-code-examples/",
          "publishedOn": "2022-12-21T21:45:12.000Z",
          "wordCount": 1636,
          "title": "Filtering in C# – How to Filter a List with Code Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/ferenc-almasi-tvHtIGbbjMo-unsplash.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/typeerror-cant-multiply-sequence-by-non-int-of-type-float-solved-python-error-3/",
          "author": "Kolade Chris",
          "description": "Most times when you encounter errors while coding, you can discover the reason why the error is occurring and how you can fix it in the error message. The Python error, \"TypeError: can't multiply sequence by non-int of type float\" is no exception to that. I have prepared this article",
          "link": "https://www.freecodecamp.org/news/typeerror-cant-multiply-sequence-by-non-int-of-type-float-solved-python-error-3/",
          "publishedOn": "2022-12-21T21:13:46.000Z",
          "wordCount": 1312,
          "title": "TypeError: can't multiply sequence by non-int of type float [Solved Python Error]",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-polina-zimmerman-3747132.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-use-scapy-python-networking/",
          "author": "Omer Rosenbaum",
          "description": "In this post you will learn about an amazing tool named Scapy. Scapy is a Python library that enables us to send, sniff, and dissect network frames.  It is useful in a variety of use cases, one of which is to actually get some hands-on experience when you learn",
          "link": "https://www.freecodecamp.org/news/how-to-use-scapy-python-networking/",
          "publishedOn": "2022-12-21T21:02:17.000Z",
          "wordCount": 2004,
          "title": "How to Use Scapy – Python Networking Tool Explained",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Computer-Networks-Hub-Switch--1-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/concurrent-programming-in-go/",
          "author": "Rwitesh Bera",
          "description": "Concurrency refers to a programming language's ability to deal with lots of things at once. A good way to understand concurrency is by imagining multiple cars traveling on two lanes. Sometimes the cars overtake each other, and sometimes they stop and let others pass by. Another good example is when",
          "link": "https://www.freecodecamp.org/news/concurrent-programming-in-go/",
          "publishedOn": "2022-12-21T19:02:59.000Z",
          "wordCount": 2014,
          "title": "Concurrent Programming in Go – Goroutines, Channels, and More Explained with Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/2-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/download-trim-mp3-from-youtube-with-python/",
          "author": "Otavio Ehrenberger",
          "description": "Everybody's different, but I believe that nearly all of us enjoy listening to music. If you want to keep a local version of audio streams you often listen to, you'll need to download these files. Sometimes you'll also want to clip a portion of this audio file instead of having",
          "link": "https://www.freecodecamp.org/news/download-trim-mp3-from-youtube-with-python/",
          "publishedOn": "2022-12-21T18:57:27.000Z",
          "wordCount": 2932,
          "title": "How to Download and Trim MP3s from YouTube with Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-pixabay-164821.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-abstraction-in-programming-for-beginners/",
          "author": "Ryan Michael Kay",
          "description": "This article will not be a dry and boring explanation of abstract classes, interfaces, protocols, or similar software entities. I will explain what they are in simple terms, but my main goal is to change how you think about abstractions in general. All of this is in service of helping",
          "link": "https://www.freecodecamp.org/news/what-is-abstraction-in-programming-for-beginners/",
          "publishedOn": "2022-12-21T18:08:21.000Z",
          "wordCount": 3678,
          "title": "What is Abstraction in Programming? Explained for Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/smartphone-g7993a9917_1280-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-build-a-santa-tracker-app-with-next-js-react-leaflet/",
          "author": "Colby Fayock",
          "description": "It's the holiday season and Santa's coming! But just like he watches all of us, we can build a map-based tracking app to keep an eye on him and find out when he'll come on Christmas night with Next.js and React Leaflet.  *  How can we track Santa?",
          "link": "https://www.freecodecamp.org/news/how-to-build-a-santa-tracker-app-with-next-js-react-leaflet/",
          "publishedOn": "2022-12-21T16:42:06.000Z",
          "wordCount": 3480,
          "title": "How to Build a Santa Tracker App with Next.js and React Leaflet",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/santa-tracking-map-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/database-normalization-1nf-2nf-3nf-table-examples/",
          "author": "Kolade Chris",
          "description": "In relational databases, especially large ones, you need to arrange entries so that other maintainers and administrators can read them and work on them. This is why database normalization is important. In simple words, database normalization entails organizing a database into several tables in order to reduce redundancy. You can",
          "link": "https://www.freecodecamp.org/news/database-normalization-1nf-2nf-3nf-table-examples/",
          "publishedOn": "2022-12-21T16:40:26.000Z",
          "wordCount": 1653,
          "title": "Database Normalization – Normal Forms 1nf 2nf 3nf Table Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/normalization.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-create-stunning-qr-codes-with-python/",
          "author": "Shittu Olumide",
          "description": "A quick response (QR) code is a barcode that a digital device can easily scan. It encodes data as a series of pixels in a square grid.  Tracking information about supply chains using QR codes is very useful in marketing and advertising campaigns. The International Organization for Standardization certified",
          "link": "https://www.freecodecamp.org/news/how-to-create-stunning-qr-codes-with-python/",
          "publishedOn": "2022-12-21T15:40:05.000Z",
          "wordCount": 1751,
          "title": "How to Create Stunning QR Codes with Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/How-to-create-stunning-QR-codes-with-python-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-build-your-own-saas-pagerduty-clone/",
          "author": "Beau Carnes",
          "description": "One of the best ways to learn software development is to create a slimmed-down version of software you use every day to get a better understanding of how it might work. This process helps you understand the problem space constraints and techniques required to build a real-world use-case. We just",
          "link": "https://www.freecodecamp.org/news/how-to-build-your-own-saas-pagerduty-clone/",
          "publishedOn": "2022-12-20T13:47:49.000Z",
          "wordCount": 11135,
          "title": "How to Build Your Own SaaS – PagerDuty Clone",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/maxresdefault.jpeg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-get-your-first-job-in-infosec/",
          "author": "Megan Kaczanowski",
          "description": "Getting your first job in information security (infosec, or cybersecurity) can be tough.  It's (still) a relatively new industry, and job roles and descriptions aren't always consistent. Plus, it can be hard to figure out where to get started, what skills you need, and how you can acquire them.",
          "link": "https://www.freecodecamp.org/news/how-to-get-your-first-job-in-infosec/",
          "publishedOn": "2022-12-19T23:32:44.000Z",
          "wordCount": 3410,
          "title": "How to Get Your First Job in InfoSec",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-tima-miroshnichenko-5380665.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/have-fun-building-react-apps/",
          "author": "Reed Barger",
          "description": "Building React apps can either be a very fun experience or a very difficult and tedious one, based off of the tools you choose. React is a JavaScript library that, unlike frameworks like Angular, leave us to making a lot of decisions on our own. You have to choose which",
          "link": "https://www.freecodecamp.org/news/have-fun-building-react-apps/",
          "publishedOn": "2022-12-19T21:41:26.000Z",
          "wordCount": 2389,
          "title": "How to Have Fun Building React Apps",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/mugshotbot.com_customize_color-teal-discounted_price--image-fa229fca-mode-light-pattern-charlie_brown-price--theme-e_commerce-url-https___gifcoins.io.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/build-your-own-wireguard-vpn-in-five-minutes/",
          "author": "David Clinton",
          "description": "You may already understand how important a good VPN can be for maintaining the security and privacy of your mobile communications.  Whether you need to use your phone for banking over a public airport or coffee shop WiFi connection, or you're worried about the wrong people listening in on",
          "link": "https://www.freecodecamp.org/news/build-your-own-wireguard-vpn-in-five-minutes/",
          "publishedOn": "2022-12-19T20:46:15.000Z",
          "wordCount": 2246,
          "title": "How to Build Your Own Wireguard VPN in Five Minutes",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-ibrahim-boran-339814.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-speed-up-your-software-development-pipeline/",
          "author": "Andrej Kovacevic",
          "description": "If you've ever managed a software development pipeline—or have plans to do so—there's one thing you'll need to prioritize above almost all else: speed.  No matter the type of software you're working on, you'll always be under pressure to speed up your team's deliverables. Some of that pressure might",
          "link": "https://www.freecodecamp.org/news/how-to-speed-up-your-software-development-pipeline/",
          "publishedOn": "2022-12-19T17:51:06.000Z",
          "wordCount": 2086,
          "title": "How to Speed up Your Software Development Pipeline",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/software-development-team.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/rules-of-api-testing-for-beginners/",
          "author": "Hillary Nyakundi",
          "description": "In this digital age, APIs have become the cornerstone of how data is shared and processed. But many users are often unaware of the fact that they are putting their trust in an API and not a person. This is why it's important to leverage API testing techniques to ensure",
          "link": "https://www.freecodecamp.org/news/rules-of-api-testing-for-beginners/",
          "publishedOn": "2022-12-16T21:25:46.000Z",
          "wordCount": 1908,
          "title": "API Testing Best Practices – How to Test APIs for Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/OOP--2-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/accessibility-best-practices-to-make-web-apps-accessible/",
          "author": "Shruti Kapoor",
          "description": "Anyone should be able to use your websites and apps - both people with disabilities and those without. This will make your website accessible. Think about the last site you built, or your favorite site. Are you confident that anyone can use your site and perform the critical actions it",
          "link": "https://www.freecodecamp.org/news/accessibility-best-practices-to-make-web-apps-accessible/",
          "publishedOn": "2022-12-16T21:01:26.000Z",
          "wordCount": 1765,
          "title": "Accessibility Best Practices – What to Remember When Building Accessible Web Apps",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/ben-kolde-bs2Ba7t69mM-unsplash-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/pair-programming-with-the-chatgpt-ai-how-well-does-gpt-3-5-understand-bash/",
          "author": "David Clinton",
          "description": "We've been hearing a lot about artificial intelligence and natural language processing – and in particular about the latest version of OpenAI's GPT – for weeks.  The recent release of GPT 3.5, and specifically the very new ChatGPT tool, is definitely a huge leap forward. You may have read",
          "link": "https://www.freecodecamp.org/news/pair-programming-with-the-chatgpt-ai-how-well-does-gpt-3-5-understand-bash/",
          "publishedOn": "2022-12-16T17:51:07.000Z",
          "wordCount": 1896,
          "title": "Pair Programming with the ChatGPT AI – Does GPT-3.5 Understand Bash?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-pavel-danilyuk-8438951.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-create-a-telegram-bot-using-python/",
          "author": "Ashutosh Krishna",
          "description": "Automated chatbots are quite useful for stimulating interactions. We can create chatbots for Slack, Discord, and other platforms.  In this article, I'll teach you how to build a Telegram chatbot that will tell you your horoscope. So, let’s get started! How to Get Your Bot Token To set up",
          "link": "https://www.freecodecamp.org/news/how-to-create-a-telegram-bot-using-python/",
          "publishedOn": "2022-12-16T17:42:10.000Z",
          "wordCount": 1988,
          "title": "How to Create a Telegram Bot using Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Telegram-Bot.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-a-rom-price-and-cost-estimate-2/",
          "author": "Eamonn Cottrell",
          "description": "ROM stands for Rough Order of Magnitude. It is a project management guideline to determine the estimated range of costs for a project. This article will explain:  1. Who should use a ROM  2. When to use a ROM  3. How to calculate a ROM  4.",
          "link": "https://www.freecodecamp.org/news/what-is-a-rom-price-and-cost-estimate-2/",
          "publishedOn": "2022-12-16T17:27:32.000Z",
          "wordCount": 1151,
          "title": "What is a ROM? ROM Price and Cost Estimate",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/12.15.22-What-is-a-ROM.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/css-display-none-and-visibility-hidden-the-difference/",
          "author": "Dillion Megida",
          "description": "display:none and visibility:hidden are two style declarations you can use to hide elements on the screen with CSS. But what are the differences between them? When building applications, there are times that you want to hide elements visually (not deleting them from the DOM, just the screen). You can do",
          "link": "https://www.freecodecamp.org/news/css-display-none-and-visibility-hidden-the-difference/",
          "publishedOn": "2022-12-15T23:13:53.000Z",
          "wordCount": 1707,
          "title": "CSS display:none and visibility:hidden – What's the Difference?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/11.-display-visibility-2.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-select-the-right-ec2-instance/",
          "author": "Daniel Adetunji",
          "description": "EC2 (Elastic Compute Cloud) is the most widely-used compute service from AWS. It's also one of the oldest services launched by AWS, as it was started in 2006.  In this article, I will go through some things you should consider when selecting an EC2 instance.  You can think",
          "link": "https://www.freecodecamp.org/news/how-to-select-the-right-ec2-instance/",
          "publishedOn": "2022-12-15T19:08:27.000Z",
          "wordCount": 2720,
          "title": "How to Select the Right EC2 Instance – A Guide to EC2 Instances and Their Capabilities",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-photo.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/javascript-get-request-tutorial/",
          "author": "Joel Olawanle",
          "description": "When building applications, you will have to interact between the backend and frontend to get, store, and manipulate data. This interaction between your frontend application and the backend server is possible through HTTP requests. There are five popular HTTP methods you can use to make requests and interact with your",
          "link": "https://www.freecodecamp.org/news/javascript-get-request-tutorial/",
          "publishedOn": "2022-12-15T19:05:24.000Z",
          "wordCount": 1593,
          "title": "JavaScript Get Request – How to Make an HTTP Request in JS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-template--2-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/build-an-ai-for-two-player-turn-based-games/",
          "author": "Houssein Badra",
          "description": "Two-player turn-based games are games where two players play against each other, turn after turn, until one of them wins. Examples of these types of games are Tic-Tac-Toe, Backgammon, Mancala, Chess, and Connect 4. In this tutorial we will learn about the Minimax algorithm. It is a backtracking algorithm that",
          "link": "https://www.freecodecamp.org/news/build-an-ai-for-two-player-turn-based-games/",
          "publishedOn": "2022-12-15T18:24:15.000Z",
          "wordCount": 2369,
          "title": "How to Build an AI for Two-Player Turn-based Games",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/2825132-637490944552534550-16x9-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/solve-your-math-equation-on-terminal/",
          "author": "Arunachalam B",
          "description": "Can you solve the below math expression on your own without using any device? Take as much time as you need – but no tools allowed: ( ( 11 + 97 ) + ( 2 * 63 ) - ( 7 / 93 ) * ( 8 - 25 )",
          "link": "https://www.freecodecamp.org/news/solve-your-math-equation-on-terminal/",
          "publishedOn": "2022-12-15T17:40:54.000Z",
          "wordCount": 2273,
          "title": "How to Solve Math Equations in the Linux Terminal",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/FreeCodeCamp---Evaluate-expression-on-Terminal.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/independent-variable-vs-dependent-variable/",
          "author": "Kolade Chris",
          "description": "The meaning of the word \"variable\" depends on the field where it's being used. In programming, a variable is a particular piece of data that holds a value. Depending on the configuration, that value can change or remain fixed. For instance, in JavaScript, you can implement a variable to change",
          "link": "https://www.freecodecamp.org/news/independent-variable-vs-dependent-variable/",
          "publishedOn": "2022-12-15T17:32:36.000Z",
          "wordCount": 1461,
          "title": "What is the Difference Between an Independent Variable and a Dependent Variable?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/snowy-4689675_1280.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/javascript-range-create-an-array-of-numbers-with-the-from-method/",
          "author": "Joel Olawanle",
          "description": "The .from() method is a static method of the Array object in JavaScript ES6. It creates a new, shallow-copied Array instance from an array-like or iterable object like map and set. This method returns an array from any object with a length property. You can use it to create an",
          "link": "https://www.freecodecamp.org/news/javascript-range-create-an-array-of-numbers-with-the-from-method/",
          "publishedOn": "2022-12-14T21:15:06.000Z",
          "wordCount": 1466,
          "title": "JavaScript Range – How to Create an Array of Numbers with .from() in JS ES6",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-template--1-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/improve-your-javascript-skills-by-coding-a-card-game/",
          "author": "Beau Carnes",
          "description": "Building projects is a great way to improve your programming skills. We just published a course on the freeCodeCamp.org YouTube channel that will teach you how to create a digital card game with JavaScirpt, HTML, and CSS. This tutorial not only covers creating a basic card game using JavaScript but",
          "link": "https://www.freecodecamp.org/news/improve-your-javascript-skills-by-coding-a-card-game/",
          "publishedOn": "2022-12-14T18:56:08.000Z",
          "wordCount": 759,
          "title": "Improve Your JavaScript Skills by Coding a Card Game",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/jsgavin.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-next-js-tutorial/",
          "author": "Beau Carnes",
          "description": "Next.js is a popular framework for building server-rendered JavaScript applications. We just published a full course on the freeCodeCamp.org YouTube channel that will help you learn how to use Next.js. Next.js is built on top of React, which is a popular JavaScript library for building user interfaces. Next.js makes it",
          "link": "https://www.freecodecamp.org/news/learn-next-js-tutorial/",
          "publishedOn": "2022-12-14T18:35:12.000Z",
          "wordCount": 811,
          "title": "Learn Next.js for Scalable Web Apps",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Next.js-Course.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-read-a-file-line-by-line-in-python/",
          "author": "Dionysia Lemonaki",
          "description": "When coding in Python, there may be times when you need to open and read the contents of a text file. Luckily enough, there are several ways to do this in Python. The language has many built-in functions, methods, and keywords that you can use to create, write, read and",
          "link": "https://www.freecodecamp.org/news/how-to-read-a-file-line-by-line-in-python/",
          "publishedOn": "2022-12-14T17:58:48.000Z",
          "wordCount": 1795,
          "title": "How to Read a File Line by Line in Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-mateusz-dach-450035.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-solidity-handbook/",
          "author": "Zubin Pratap",
          "description": "When I changed careers from lawyer to software engineer [/news/from-lawyer-to-google-engineer/] in 2018, I never imagined that I’d enjoy being a developer as much as I do. I also never thought I'd end up working for amazing organizations like Google [/news/coding-interview-prep-for-big-tech/]  and Chainlink labs.  After 15 years in law",
          "link": "https://www.freecodecamp.org/news/learn-solidity-handbook/",
          "publishedOn": "2022-12-14T15:45:30.000Z",
          "wordCount": 19072,
          "title": "Learn Solidity – A Handbook for Smart Contract Development",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-pixabay-417173--2-.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/linux-shells-explained/",
          "author": "Anthony Behery",
          "description": "When you open up your terminal, chances are that it uses Bash as its UNIX shell environment. But other \"shell\" environments exist. There are other environments such as the C Shell, Korn Shell, Z Shell, and even the Fish Shell. All of these different shell environments have their own pros",
          "link": "https://www.freecodecamp.org/news/linux-shells-explained/",
          "publishedOn": "2022-12-13T21:55:05.000Z",
          "wordCount": 1526,
          "title": "Linux Shells for Beginners – Bash, Zsh, and Fish Explained",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-oleksandr-pidvalnyi-320260.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-calculate-percentage-differences-between-two-numbers-in-excel-cell-percentage-change-tutorial/",
          "author": "Eamonn Cottrell",
          "description": "Spreadsheets are powerful and awesome. 💪  In this tutorial I will show you four ways to find the percentage difference between two numbers in Excel. I'll also show you how to use custom functions in Google Sheets. 👍 The four techniques (and one bonus) we'll use are:  1.",
          "link": "https://www.freecodecamp.org/news/how-to-calculate-percentage-differences-between-two-numbers-in-excel-cell-percentage-change-tutorial/",
          "publishedOn": "2022-12-13T21:49:00.000Z",
          "wordCount": 2081,
          "title": "How to Calculate Percentage Differences Between Two Numbers in Excel - Cell Percentage Change Tutorial",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/12.13.22-Percent-Change2.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-protect-against-sql-injection-attacks/",
          "author": "Manish Shivanandhan",
          "description": "Databases are the backbone of any application. They give us a way to store and organize large amounts of data in a way that we can easily access, manage, and update it. From small businesses to large-scale enterprises, databases play a critical role in keeping the systems up and running.",
          "link": "https://www.freecodecamp.org/news/how-to-protect-against-sql-injection-attacks/",
          "publishedOn": "2022-12-13T00:40:15.000Z",
          "wordCount": 1884,
          "title": "SQL Injection Attacks – How to Use SQLMap to Find Database Vulnerabilities",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Stealth-Security---Blog-Banner--27-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-an-algorithm-definition-for-beginners/",
          "author": "Kolade Chris",
          "description": "If you’re a student and want to study computer science, or you’re learning to code, then there’s a chance you’ve heard of algorithms. Simply put, an algorithm is a set of instructions that performs a particular action. Contrary to popular belief, an algorithm is not some piece of code that",
          "link": "https://www.freecodecamp.org/news/what-is-an-algorithm-definition-for-beginners/",
          "publishedOn": "2022-12-13T00:38:26.000Z",
          "wordCount": 1577,
          "title": "What is an Algorithm? Algorithm Definition for Computer Science Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/laptop-gfe4d4bfc0_1280.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-remove-an-item-from-a-list-in-c/",
          "author": "Edeh Israel Chidera",
          "description": "While building your application in C#, you might need to store and manipulate sets of data. The List class is a member of the System.Collections.Generic  namespace and you use it to store multiple objects of the same datatype. The List class represents a collection of strongly typed lists of",
          "link": "https://www.freecodecamp.org/news/how-to-remove-an-item-from-a-list-in-c/",
          "publishedOn": "2022-12-13T00:28:02.000Z",
          "wordCount": 1137,
          "title": "How to Remove an Item from a List in C#",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/bernd-dittrich-d_3EKbSg1tg-unsplash.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/overview-of-cyber-security-certifications/",
          "author": "Megan Kaczanowski",
          "description": "Certifications aren't strictly necessary in order to get hired as a cybersecurity analyst (with the notable exception of many government jobs). But they can help you demonstrate to an HR recruiter or hiring manager that you have a specific skillset via a third party's assessment of your skills. The process",
          "link": "https://www.freecodecamp.org/news/overview-of-cyber-security-certifications/",
          "publishedOn": "2022-12-13T00:22:54.000Z",
          "wordCount": 2299,
          "title": "Cyber Security Certifications – What Certs to Get for a Career in Infosec",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-martijn-adegeest-633565.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-programming-tutorial-for-beginners/",
          "author": "Estefania Cassingena Navone",
          "description": "Welcome to the amazing world of programming. This is one of the most useful and powerful skills that you can learn and use to make your visions come true.  In this handbook, we will dive into why programming is important, its applications, its basic concepts, and the skills you",
          "link": "https://www.freecodecamp.org/news/what-is-programming-tutorial-for-beginners/",
          "publishedOn": "2022-12-12T17:10:03.000Z",
          "wordCount": 8117,
          "title": "What is Programming? A Handbook for Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/what-is-programming.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/javascript-type-checking-how-to-check-type-in-js-with-typeof/",
          "author": "Joel Olawanle",
          "description": "JavaScript is a dynamically typed (or loosely typed) programming language. It allows you to declare variables without specifying or defining the variable type. You can create a variable in JavaScript without defining the type of value you can store in the variable. This can affect your program and cause bugs",
          "link": "https://www.freecodecamp.org/news/javascript-type-checking-how-to-check-type-in-js-with-typeof/",
          "publishedOn": "2022-12-09T22:16:19.000Z",
          "wordCount": 2178,
          "title": "JavaScript Type Checking – How to Check Type in JS with typeof()",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-template.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/linux-networking-commands-for-beginners/",
          "author": "Arunachalam B",
          "description": "Can you imagine what it would be like to have a laptop but not to be able to access the internet? If you're a developer (or an aspiring one), you'll likely use the internet every day. So you should learn a few useful networking commands.  To learn networking in",
          "link": "https://www.freecodecamp.org/news/linux-networking-commands-for-beginners/",
          "publishedOn": "2022-12-09T18:54:20.000Z",
          "wordCount": 2391,
          "title": "Linux Networking Commands You Should Know as a Beginner",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/FreeCodeCamp---Networking-in-Linux.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/a-personal-guide-to-data-privacy/",
          "author": "Megan Kaczanowski",
          "description": "What's the difference between data privacy and data security? Data security is about protecting your data from unauthorized access (basically ensuring that hackers can't access your data). Data privacy, on the other hand, is about giving you more granular control over how (and by whom) your data is accessed, used,",
          "link": "https://www.freecodecamp.org/news/a-personal-guide-to-data-privacy/",
          "publishedOn": "2022-12-09T18:51:30.000Z",
          "wordCount": 2016,
          "title": "How to Improve Your Data Privacy – A Personal Guide to Protecting Your Online Information",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-antoni-shkraba-5475793.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-build-a-dropdown-menu-with-javascript/",
          "author": "Victor Eke",
          "description": "If you use the internet, you've likely used a dropdown menu before. They primarily serve two purposes: collecting user input in web forms, and implementing action/navigation menus in web applications. Dropdowns are one of the best ways to offer numerous options for a similar collection of elements without needing to",
          "link": "https://www.freecodecamp.org/news/how-to-build-a-dropdown-menu-with-javascript/",
          "publishedOn": "2022-12-09T18:27:56.000Z",
          "wordCount": 1906,
          "title": "How to Build a Dropdown Menu with JavaScript",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/how-to-build-a-dropdown-menu-with-javascript.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/statement-vs-expression-whats-the-difference-in-programming/",
          "author": "Ogundiran Ayobami",
          "description": "Learning the syntax of a programming language is key if you want to use that language effectively. This is true for both new and experienced developers. And one of the most important things to pay attention to while learning a programming language is whether the code you're dealing with is",
          "link": "https://www.freecodecamp.org/news/statement-vs-expression-whats-the-difference-in-programming/",
          "publishedOn": "2022-12-08T23:44:58.000Z",
          "wordCount": 2128,
          "title": "Statement vs Expression – What's the Difference in Programming?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/kaleidico-7lryofJ0H9s-unsplash.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/python-slicing-how-to-slice-an-array/",
          "author": "Dillion Megida",
          "description": "Slicing an array is the concept of cutting out – or slicing out – a part of the array. How do you do this in Python? I'll show you how in this article. What is an Array? An array is a data structure that allows you to store multiple items",
          "link": "https://www.freecodecamp.org/news/python-slicing-how-to-slice-an-array/",
          "publishedOn": "2022-12-08T19:13:33.000Z",
          "wordCount": 2252,
          "title": "Python Slicing – How to Slice an Array and What Does [::-1] Mean?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/10.-slide-array.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/hacking-with-hashcat-a-practical-guide/",
          "author": "Manish Shivanandhan",
          "description": "Hashing is one of the pillars of cybersecurity. From securing passwords to sensitive data, there are a variety of use cases for hashing. Hashing is often confused with encryption. A simple difference is that hashed data is not reversible. Encrypted data can be reversed using a key. This is why",
          "link": "https://www.freecodecamp.org/news/hacking-with-hashcat-a-practical-guide/",
          "publishedOn": "2022-12-08T15:55:26.000Z",
          "wordCount": 2256,
          "title": "How to Crack Hashes with Hashcat — a Practical Pentesting Guide",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/hashcat-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/aws-lambda-interview-questions/",
          "author": "Mugilan Ragupathi",
          "description": "In this article, I'll go over some of the most commonly asked questions that come up in interviews about AWS Lambda.  Note that this is not an exhaustive list – but you can use this guide as a reference to refresh your knowledge and get pointers for further study.",
          "link": "https://www.freecodecamp.org/news/aws-lambda-interview-questions/",
          "publishedOn": "2022-12-07T20:54:49.000Z",
          "wordCount": 3161,
          "title": "AWS Lambda Interview Questions and Answers",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/AWS-Lambda-Interview-Questions.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-remove-a-specific-character-from-a-string-in-python/",
          "author": "Dionysia Lemonaki",
          "description": "When coding in Python, there may be times when you need to remove a character from a string. Removing characters from strings is handy if you are working with user-generated inputs and need to clean your data and remove unwanted characters. Specifically, you may need to remove only one instance",
          "link": "https://www.freecodecamp.org/news/how-to-remove-a-specific-character-from-a-string-in-python/",
          "publishedOn": "2022-12-07T18:43:30.000Z",
          "wordCount": 2065,
          "title": "How to Remove a Specific Character from a String in Python",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pexels-josh-sorenson-1714208.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-the-swift-programming-language/",
          "author": "Beau Carnes",
          "description": "Swift is popular programming language that is often used for creating iOS apps.  We just released a full course on the freeCodeCamp.org YouTube channel that will teach you the Swift programming language. Vandad Nahavandipoor teaches this course. He currently works as a lead iOS developer and he has created",
          "link": "https://www.freecodecamp.org/news/learn-the-swift-programming-language/",
          "publishedOn": "2022-12-07T16:51:51.000Z",
          "wordCount": 716,
          "title": "Learn the Swift Programming Language",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/swift.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/python-gui-development-using-pyside6-and-qt/",
          "author": "Beau Carnes",
          "description": "Learn how to build cross platform desktop apps for Windows, Mac and Linux. PySide6 is a Python binding for the Qt6 application framework. PySide6 allows you to use the Qt6 framework to create graphical user interfaces (GUIs) and other cross-platform applications in Python. It provides a convenient way to access",
          "link": "https://www.freecodecamp.org/news/python-gui-development-using-pyside6-and-qt/",
          "publishedOn": "2022-12-07T16:45:01.000Z",
          "wordCount": 825,
          "title": "Python GUI Development Using PySide6 and Qt",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/pyside6.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/separation-of-concerns-react-container-and-presentational-components/",
          "author": "Keyur Paralkar",
          "description": "Many new React developers combine logic and presentation inside the same React component. And they may not know why it's important to separate these two – they just want to make it work. But later, they'll find that they need to make changes to the file and doing so becomes",
          "link": "https://www.freecodecamp.org/news/separation-of-concerns-react-container-and-presentational-components/",
          "publishedOn": "2022-12-06T21:43:19.000Z",
          "wordCount": 2388,
          "title": "Separation of Concerns in React –How to Use Container and Presentational Components",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/container-and-presentational-component-pattern-image.jpeg"
        },
        {
          "id": "https://www.freecodecamp.org/news/linux-top/",
          "author": "Anthony Behery",
          "description": "You may be used to using the Activity Monitor in MacOS or the Task Manager for Windows to see the current processes running on your system.  But for those running Linux, if that includes a dual boot, virtual box, or even WSL2, you could use a useful Linux command",
          "link": "https://www.freecodecamp.org/news/linux-top/",
          "publishedOn": "2022-12-06T21:09:33.000Z",
          "wordCount": 1367,
          "title": "How to View Your Linux Processes",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Screenshot-2022-12-05-235534.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-automate-e-commerce-operations-with-python/",
          "author": "Marco Venturi",
          "description": "When you work in e-commerce operations, you'll have to perform many tasks daily to implement your company's business strategies.  But these often repetitive tasks can be time-consuming and leave room for errors. Some of these errors can cost your company money, reputation, and time.  Luckily, Python and APIs",
          "link": "https://www.freecodecamp.org/news/how-to-automate-e-commerce-operations-with-python/",
          "publishedOn": "2022-12-06T18:11:07.000Z",
          "wordCount": 1896,
          "title": "How to Automate Your Business Strategy with Python and APIs",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/cover-1.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-are-node-modules/",
          "author": "Benjamin Semah",
          "description": "Every Node.js application has modules. These modules form part of the building blocks of the application. They help developers work faster and write more structured code. In this tutorial, you will learn what node modules are. You will also learn about the three types of node modules. And we'll go",
          "link": "https://www.freecodecamp.org/news/what-are-node-modules/",
          "publishedOn": "2022-12-06T17:54:33.000Z",
          "wordCount": 1383,
          "title": "What Are Node Modules and How Do You Use Them?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/stock.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/generate-random-number-within-a-range-in-javascript/",
          "author": "Dillion Megida",
          "description": "Let's say you want to generate a random number between 10 and 15 – how do you do that in JavaScript? I'll show you how with examples in this article. In JavaScript, there's the random method of the Math object which returns random numbers. But this has a range limitation.",
          "link": "https://www.freecodecamp.org/news/generate-random-number-within-a-range-in-javascript/",
          "publishedOn": "2022-12-06T16:21:25.000Z",
          "wordCount": 1269,
          "title": "How to Generate a Random Number within Certain a Range in JavaScript",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/9.-random-number.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/gobuster-tutorial-find-hidden-directories-sub-domains-and-s3-buckets/",
          "author": "Manish Shivanandhan",
          "description": "There’s much more to web servers and websites than what appears on the surface. The first step an attacker uses when attacking a website is to find the list of URLs and sub-domains. Web developers often expose sensitive files, URL paths, or even sub-domains while building or maintaining a site.",
          "link": "https://www.freecodecamp.org/news/gobuster-tutorial-find-hidden-directories-sub-domains-and-s3-buckets/",
          "publishedOn": "2022-12-05T23:40:58.000Z",
          "wordCount": 1845,
          "title": "Gobuster Tutorial – How to Find Hidden Directories, Sub-Domains, and S3 Buckets",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/Stealth-Security---Blog-Banner--24-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-apis-work/",
          "author": "Tooba Jamal",
          "description": "When I started learning to code, the term API would always haunt me. I couldn't make sense of what it actually meant because I would hear people talking about APIs in different contexts.  The biggest challenge was that I couldn't find resources to learn about APIs in simple terms.",
          "link": "https://www.freecodecamp.org/news/how-apis-work/",
          "publishedOn": "2022-12-05T22:56:35.000Z",
          "wordCount": 1923,
          "title": "What is an API and How Does it Work? APIs for Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/api-article.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/better-react-performance-usecallback-vs-usememo/",
          "author": "Daniel Asta",
          "description": "We all want to build powerful applications and avoid unnecessary renders. There are some hooks available to help with this, but you might not be sure about which one to use and when. In this article you will learn the differences between useCallback and useMemo  as well as how",
          "link": "https://www.freecodecamp.org/news/better-react-performance-usecallback-vs-usememo/",
          "publishedOn": "2022-12-05T18:47:25.000Z",
          "wordCount": 2705,
          "title": "Better React Performance – When to Use the useCallback vs useMemo Hook",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/useCallback-vs-useMemo.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-is-node-js/",
          "author": "Benjamin Semah",
          "description": "Node.js allows developers to create both front-end and back-end applications using JavaScript. It was released in 2009 by Ryan Dahl. In this article, you will learn about Node.js. You will learn the following:  * What is Node.js?  * How the Node.js environment differs from the browser.  *",
          "link": "https://www.freecodecamp.org/news/what-is-node-js/",
          "publishedOn": "2022-12-05T15:18:12.000Z",
          "wordCount": 1907,
          "title": "What Exactly is Node.js? Explained for Beginners",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/What-is.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-find-the-size-of-an-array-in-c-with-the-sizeof-operator/",
          "author": "Dionysia Lemonaki",
          "description": "When coding in the C programming language, there may be times when you need to know the size of an array. For example, when you want to loop through all the elements stored in the array to determine whether a specific value is present. In this article, you will learn",
          "link": "https://www.freecodecamp.org/news/how-to-find-the-size-of-an-array-in-c-with-the-sizeof-operator/",
          "publishedOn": "2022-12-05T14:53:05.000Z",
          "wordCount": 1368,
          "title": "How to Find the Size of an Array in C with the sizeof Operator",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/pexels-eduardo-dutra-2115217-1.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/css-is-pseudo-class-explained/",
          "author": "Dillion Megida",
          "description": "Pseudo-classes allow you to style an element in a specific state. There are many supported classes for states in CSS. In this article, I'll explain how the :is  pseudo-class works. This article is the first in a new series I'll be working on over the coming weeks and months:",
          "link": "https://www.freecodecamp.org/news/css-is-pseudo-class-explained/",
          "publishedOn": "2022-12-02T22:04:37.000Z",
          "wordCount": 1587,
          "title": "CSS Pseudo-Classes – How the :is Pseudo-Class Works with Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/1.-is.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/freecodecamp-2022-usage-statistics/",
          "author": "Quincy Larson",
          "description": "That's 8,000 years. That's a lot of learning. 2022 has been a massive year for the freeCodeCamp community. People around the world are using freeCodeCamp to expand their skills and advance their careers. Here's a breakdown of site usage across the four main pillars of the freeCodeCamp community: /learn (the",
          "link": "https://www.freecodecamp.org/news/freecodecamp-2022-usage-statistics/",
          "publishedOn": "2022-12-02T00:22:33.000Z",
          "wordCount": 1117,
          "title": "People Spent 4 Billion Minutes Learning on freeCodeCamp in 2022",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/freeCodeCamp_historic_usage_-_Google_Sheets.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/freecodecamp-2022-top-contributors/",
          "author": "Quincy Larson",
          "description": "2022 was a massive year for the freeCodeCamp community:  * The community helped millions of people around the world learn math,    programming, and computer science. We also helped them stay motivated and    moving forward toward their goals.  * We published thousands of",
          "link": "https://www.freecodecamp.org/news/freecodecamp-2022-top-contributors/",
          "publishedOn": "2022-12-02T00:21:15.000Z",
          "wordCount": 2266,
          "title": "Announcing freeCodeCamp's 2022 Top Contributors",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/thomas-habr-wprOCzLIEYI-unsplash--1-.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/dijkstras-algorithm-explained-with-a-pseudocode-example/",
          "author": "Ihechikara Vincent Abba",
          "description": "You can use algorithms in programming to solve specific problems through a set of precise instructions or procedures. Dijkstra's algorithm is one of many graph algorithms you'll come across. It is used to find the shortest path from a fixed node to all other nodes in a graph. There are",
          "link": "https://www.freecodecamp.org/news/dijkstras-algorithm-explained-with-a-pseudocode-example/",
          "publishedOn": "2022-12-01T20:57:53.000Z",
          "wordCount": 2352,
          "title": "Dijkstra's Algorithm – Explained with a Pseudocode Example",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/michael-dziedzic-vLmo8kAVVt4-unsplash--2-.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/sql-insert-statement/",
          "author": "Annoh Karlgusta",
          "description": "In this tutorial, you'll learn how to use the SQL INSERT statement. We'll discuss the syntax of INSERT, and then we'll use an example to show all the different ways you can use INSERT. We'll also combine it with other helpful clauses to perform more complex operations. Prerequisites  *",
          "link": "https://www.freecodecamp.org/news/sql-insert-statement/",
          "publishedOn": "2022-12-01T18:54:21.000Z",
          "wordCount": 2312,
          "title": "SQL INSERT Statement – How to Insert Data into a Table in SQL",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/12/SQL-Insert-Statement.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/schedule-email-in-gmail/",
          "author": "Benjamin Semah",
          "description": "Sometimes you might want to compose an email but send it later. Well, did you know that Gmail allows you to schedule up to 100 emails? In this article, you will learn how to schedule your emails using Gmail. There's no need to install any software or plugins. What you",
          "link": "https://www.freecodecamp.org/news/schedule-email-in-gmail/",
          "publishedOn": "2022-11-30T22:23:40.000Z",
          "wordCount": 1108,
          "title": "How to Schedule an Email in Gmail – a Step-by-Step Guide",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/email-gd2563c0fc_1280.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/javascript-string-to-boolean/",
          "author": "Joel Olawanle",
          "description": "When you're manipulating data, receiving values from forms, and dealing with data in other ways, these values may take the incorrect datatype. Assume you want your value to be a boolean with either true or false, but it is stored as a string – \"true\" or \"false.\" It becomes challenging",
          "link": "https://www.freecodecamp.org/news/javascript-string-to-boolean/",
          "publishedOn": "2022-11-30T22:14:10.000Z",
          "wordCount": 1479,
          "title": "JavaScript String to Boolean – How to Parse a Boolean in JS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/pexels-boris-sopko-2376033.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/web-accessibility-best-practices-and-checklist/",
          "author": "Ophy Boamah",
          "description": "The World Health Organization reports [https://www.who.int/teams/noncommunicable-diseases/sensory-functions-disability-and-rehabilitation/world-report-on-disability]  that about 15% (1.2 billion) of the world's population lives with some form of disability.  This means that as developers, our focus on making websites and applications accessible helps more people use these resources.  In this article, I'll point out barriers",
          "link": "https://www.freecodecamp.org/news/web-accessibility-best-practices-and-checklist/",
          "publishedOn": "2022-11-30T18:40:47.000Z",
          "wordCount": 1966,
          "title": "Web Accessibility – Best Practices and a Checklist for Developers",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/WebAccessibility.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/principle-of-lease-privilege-meaning-cybersecurity/",
          "author": "Manish Shivanandhan",
          "description": "Information technology has made a profound impact on our lives over the last three decades. It has helped us create global businesses, transform industries, and build powerful connections. But it has also led to increased risks in security and privacy. Individuals and businesses are vulnerable to cyber attacks now more",
          "link": "https://www.freecodecamp.org/news/principle-of-lease-privilege-meaning-cybersecurity/",
          "publishedOn": "2022-11-30T18:23:15.000Z",
          "wordCount": 1952,
          "title": "Principle of Least Privilege – Definition and Meaning in Cybersecurity",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/cover.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-install-wifi-adapter-driver-on-aml-s905x-cc-le-potato/",
          "author": "Arunachalam B",
          "description": "If you're a developer, you might be familiar with Raspberry Pi. But you might not know about the Libre Computer AML-S905X-CC – also called Le Potato.  There was a chip shortage during the pandemic that has resulted in increased Raspberry Pi prices. Other world events have also skyrocketed the",
          "link": "https://www.freecodecamp.org/news/how-to-install-wifi-adapter-driver-on-aml-s905x-cc-le-potato/",
          "publishedOn": "2022-11-30T17:27:33.000Z",
          "wordCount": 1780,
          "title": "How to Install a Wifi Adapter Driver on AML-S905X-CC (Le Potato)",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/How-to-install-driver-for-external-wifi-adapter-in-Le-Potato-3.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/write-unit-tests-using-react-testing-library/",
          "author": "Yogesh Chavan",
          "description": "In this tutorial, you will learn how to confidently write unit tests using the  Testing Library [https://testing-library.com/]. It is a very popular React testing library for writing unit tests. So let's get started. What We'll Cover:  1. Why Do You Need to Write Unit Tests?  2. What",
          "link": "https://www.freecodecamp.org/news/write-unit-tests-using-react-testing-library/",
          "publishedOn": "2022-11-30T16:53:39.000Z",
          "wordCount": 4560,
          "title": "React Testing Library Tutorial – How to Write Unit Tests for React Apps",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/cover_testing.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-searching-works-under-the-hood/",
          "author": "Houssein Badra",
          "description": "Searching is something is something many people do every day. Whether they're word searching in documents and databases, or pattern matching in bioinformatics to detect anomalies in DNA, the applications for search are pretty much endless. And these applications require a lot of computation. Imagine searching for a particular DNA",
          "link": "https://www.freecodecamp.org/news/how-searching-works-under-the-hood/",
          "publishedOn": "2022-11-30T16:33:48.000Z",
          "wordCount": 2686,
          "title": "How Search Works Under the Hood – Data Structures and Search Algorithms Explained",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/182786404-56a9f6725f9b58b7d00038e0.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/learn-matlab-with-this-crash-course/",
          "author": "Beau Carnes",
          "description": "MATLAB is a programming language and software suite used for data analysis, scientific computing, and visualization that is widely used in academia and industry.  We just published a MATLAB crash course on the freeCodeCamp.org YouTube channel that will teach you the fundamentals of MATLAB. Phillip Parisi developed this course.",
          "link": "https://www.freecodecamp.org/news/learn-matlab-with-this-crash-course/",
          "publishedOn": "2022-11-30T14:46:10.000Z",
          "wordCount": 743,
          "title": "Learn MATLAB With This Crash Course",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/matlab.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/use-django-rest-framework-to-create-web-apis/",
          "author": "Beau Carnes",
          "description": "Django REST Framework is a powerful and flexible toolkit for building Web APIs. We just released a course on the freeCodeCamp.org YouTube channel that will teach you how to use Python and the Django REST Framework (DRF) to build a web API. Bobby Stearman developed this course. Bobby has created",
          "link": "https://www.freecodecamp.org/news/use-django-rest-framework-to-create-web-apis/",
          "publishedOn": "2022-11-30T14:42:28.000Z",
          "wordCount": 766,
          "title": "Use Django REST Framework to Create Web APIs",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/djangorest.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/best-backend-service-react/",
          "author": "Reed Barger",
          "description": "If you're building an app on your own or on a budget, you may want to consider using a backend-as-a-service (BaaS). Doing so allows you to focus on the frontend of your application, but still have a full-stack app with a database, authentication, and more.  In this guide, we",
          "link": "https://www.freecodecamp.org/news/best-backend-service-react/",
          "publishedOn": "2022-11-29T22:56:39.000Z",
          "wordCount": 2180,
          "title": "The Best Backend as a Service for your React App",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/mugshotbot.com_customize_color-pink-description-Create-a-culture-people-want-to-be-part-of-with-Gifcoins-3A-the-easy-to-use-peer-recognition-platform.-hide_watermark-0-image-2683d973-mode-light-pattern-bank_note-theme-two_up-title-Peer-to-p.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/efficient-string-building-in-javascript/",
          "author": "Andrey Germanov",
          "description": "Everything you see in browser – except images and videos – is a string.  That's why you should learn how to work with them properly. This will dramatically increase the performance of your web applications, both on the frontend and backend. How Default String Concatenation Works – and Its",
          "link": "https://www.freecodecamp.org/news/efficient-string-building-in-javascript/",
          "publishedOn": "2022-11-29T20:39:11.000Z",
          "wordCount": 2207,
          "title": "How to Work with Strings in JavaScript – Tips for Efficient String Concatenation",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/JavaScript-Strings.png_copy.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/build-a-restful-api-with-adonisjs/",
          "author": "Solomon Eseme",
          "description": "As a developer, it's important to understand how APIs work. APIs have helped bridged the gap between the frontend and backend. They also let you separate parts of large codebases and take advantage of a microservices architecture. This separation of concerns makes learning and building RESTful APIs an in-demand skill",
          "link": "https://www.freecodecamp.org/news/build-a-restful-api-with-adonisjs/",
          "publishedOn": "2022-11-29T20:37:35.000Z",
          "wordCount": 3331,
          "title": "How to Build a RESTful API with AdonisJS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/pexels-sevenstorm-juhaszimrus-443383.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-check-for-null-in-javascript/",
          "author": "Joel Olawanle",
          "description": "Null is a primitive type in JavaScript. This means you are supposed to be able to check if a variable is null with the typeof() method. But unfortunately, this returns “object” because of an historical bug [https://www.turbinelabs.com/blog/the-odd-history-of-javascripts-null] that cannot be fixed. let userName = null; console.log(typeof(userName)); // object So how",
          "link": "https://www.freecodecamp.org/news/how-to-check-for-null-in-javascript/",
          "publishedOn": "2022-11-29T20:16:54.000Z",
          "wordCount": 1227,
          "title": "JS Check for Null – Null Checking in JavaScript Explained",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/cover-template--22-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-reverse-an-array-in-javascript-js-reverse-function/",
          "author": "Dillion Megida",
          "description": "In this article, I'll show you two ways to reverse arrays in JavaScript. The reverse method of arrays reverses an array by making the last item the first, and making the first item the last. The other items in between also get reversed, respectively. Before showing you examples of the",
          "link": "https://www.freecodecamp.org/news/how-to-reverse-an-array-in-javascript-js-reverse-function/",
          "publishedOn": "2022-11-29T20:12:22.000Z",
          "wordCount": 1076,
          "title": "How to Reverse an Array in JavaScript – JS .reverse() Function",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/8.-reverse-array.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/inheritance-in-c-sharp/",
          "author": "Edeh Israel Chidera",
          "description": "Inheritance is a branch of object-oriented programming that helps you write reusable code. It allows you to extend the content of a class to another class.  Other pillars of object-oriented programming [/news/four-pillars-of-object-oriented-programming/] include encapsulation, polymorphism, and abstraction.  In this article, we will learn about inheritance in C# and",
          "link": "https://www.freecodecamp.org/news/inheritance-in-c-sharp/",
          "publishedOn": "2022-11-29T20:04:11.000Z",
          "wordCount": 1426,
          "title": "How Inheritance Works in C# – with Code Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/caspar-camille-rubin-fPkvU7RDmCo-unsplash.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/snake-case-vs-camel-case-vs-pascal-case-vs-kebab-case-whats-the-difference/",
          "author": "Dionysia Lemonaki",
          "description": "As a software engineer, you may be familiar with the following quote by Leon Bambrick [https://twitter.com/secretGeek/status/7269997868?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E7269997868%7Ctwgr%5Eb9b41e252e8f8e5c2863c7a50642e9ec2ff0fe18%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fmartinfowler.com%2Fbliki%2FTwoHardThings.html] : > “There are 2 hard problems in computer science: cache invalidation, naming things, and off-by-1 errors.” Indeed, naming things when programming can be challengi",
          "link": "https://www.freecodecamp.org/news/snake-case-vs-camel-case-vs-pascal-case-vs-kebab-case-whats-the-difference/",
          "publishedOn": "2022-11-29T16:33:11.000Z",
          "wordCount": 1480,
          "title": "Snake Case VS Camel Case VS Pascal Case VS Kebab Case – What's the Difference Between Casings?",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/pexels-olia-danilevich-4974912.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/what-are-threads-in-java-how-to-create-one/",
          "author": "Bikash Daga (Jain)",
          "description": "Threads in Java are pre-defined classes that are available in the java.package when you write your programs. Generally, every program has one thread which is provided from the java.package.  All of these threads use the same memory, but they are independent. This means that any exception in a thread",
          "link": "https://www.freecodecamp.org/news/what-are-threads-in-java-how-to-create-one/",
          "publishedOn": "2022-11-28T22:23:36.000Z",
          "wordCount": 2344,
          "title": "What are Threads in Java? How to Create a Thread with Examples",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/Copy-of-Copy-of-How-Encapsulation-is-Achieved-in-Python--1-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/deploy-react-app/",
          "author": "Reed Barger",
          "description": "You have been working on a React application and now you're ready to actually push it to the web. What services do you use to publish your site and make it live to the world?  Whether you're ready to release your website as a finished product or you are",
          "link": "https://www.freecodecamp.org/news/deploy-react-app/",
          "publishedOn": "2022-11-28T21:30:24.000Z",
          "wordCount": 1572,
          "title": "How to Deploy Your React App Using Cloudflare Pages, Vercel, and Netlify",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/mugshotbot.com_customize_color-pink-image-9129875b-mode-dark-pattern-none-theme-two_up-url-https___gifcoins.io.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-enter-safe-boot-on-windows-operating-systems/",
          "author": "Md. Fahim Bin Amin",
          "description": "If you're using the Windows operating system, you might have heard the phrase \"Rebooting to the safe boot\" or something like that. In this tutorial, I'll explain what that means and how you can do it on your Windows machine. What is Safe Boot or Safe Mode for Windows? Safe",
          "link": "https://www.freecodecamp.org/news/how-to-enter-safe-boot-on-windows-operating-systems/",
          "publishedOn": "2022-11-28T18:55:40.000Z",
          "wordCount": 1089,
          "title": "How to Enter \"Safe Boot\" On Windows Operating Systems",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/pexels-eduardo-dutra-2115217.jpg"
        },
        {
          "id": "https://www.freecodecamp.org/news/how-to-merge-arrays-in-javascript-array-concatenation-in-js/",
          "author": "Dillion Megida",
          "description": "There are multiple ways to merge arrays in JavaScript. You can use long or short approaches. I'll be showing 3 of them in this article. When working with arrays in JavaScript, there are cases where you want to combine multiple arrays together. For example, arrays with related data coming from",
          "link": "https://www.freecodecamp.org/news/how-to-merge-arrays-in-javascript-array-concatenation-in-js/",
          "publishedOn": "2022-11-28T15:37:11.000Z",
          "wordCount": 1466,
          "title": "How to Merge Arrays in JavaScript – Array Concatenation in JS",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/7.-merge-arrays.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/check-if-an-object-is-empty-in-javascript/",
          "author": "Joel Olawanle",
          "description": "An object is one of the most commonly used data types in programming. An object is a collection of related data stored as key-value pairs. For example: let userDetails = {   name: \"John Doe\",   username: \"jonnydoe\",   age: 14, } When working with objects, you",
          "link": "https://www.freecodecamp.org/news/check-if-an-object-is-empty-in-javascript/",
          "publishedOn": "2022-11-28T15:29:23.000Z",
          "wordCount": 1695,
          "title": "How to Check if an Object is Empty in JavaScript – JS Java isEmpty Equivalent",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/cover-template--21-.png"
        },
        {
          "id": "https://www.freecodecamp.org/news/clear-code-how-to-write-code-that-is-easy-to-read/",
          "author": "Ryan Michael Kay",
          "description": "This article is a follow up to a tweet I made on how I deal with my poor ability to remember implementation (code). It may seem funny to you, but I do actually tend to forget what I write shortly after writing it.",
          "link": "https://www.freecodecamp.org/news/clear-code-how-to-write-code-that-is-easy-to-read/",
          "publishedOn": "2022-11-28T12:26:28.000Z",
          "wordCount": 3692,
          "title": "Clear Code – How to Write Code That Is Easy to Read",
          "imageUrl": "https://www.freecodecamp.org/news/content/images/2022/11/cafe-gc5d844b68_1280.jpg"
        }
      ]
    },
    {
      "title": "Self-Hosted Alternatives to Popular Services",
      "feedUrl": "https://www.reddit.com/r/selfhosted.rss",
      "siteUrl": "https://www.reddit.com/r/selfhosted",
      "articles": [
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zvapyw/looking_for_some_advice_pointers_encouragement_etc/",
          "author": null,
          "description": "So hey guys, I've been running something very simple and have been thinking about doing some other stuff. I'm honestly not sure if this is something I can pull off to be quite honest. For several years I've been running a few things on a Synology NAS (DS920+). Basically right now I'm running Jellyfin and Omada controller in Docker on the Synology. I've read a lot of interesting stuff about other stuff like Proxmox. I got some crazy idea I wanted to do that so I got a Dell T5810 workstation with a 24c/48t processor and (so far) 64 GB RAM. The DS920+ is getting re-homed so what I want to do is use my old Synology, the DS413, as network storage with my T5810 running Proxmox. So far I think I have it set up properly with I think its called NFS.\n (A) Also, right now, I'm running OPNsense on a d…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zvapyw/looking_for_some_advice_pointers_encouragement_etc/",
          "publishedOn": "2022-12-26T00:30:48.000Z",
          "wordCount": 20178,
          "title": "Looking for some advice, pointers, encouragement, etc...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv9rhk/yunohost_alternative/",
          "author": null,
          "description": "Hi!\n I'm currently using yunohost and I am happy with it. I like this system because it is easy to use but still allows for a fair amount of flexibility. It's a system that I feel is complete and mature and works well.\n But I would like to try something else. What do you suggest that is as good or better and also allows to use docker?\n Thx\n    submitted by    /u/zwnrsx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv9rhk/yunohost_alternative/",
          "publishedOn": "2022-12-25T23:40:30.000Z",
          "wordCount": 18898,
          "title": "Yunohost alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv9odo/whats_the_prettiest_yet_most_lightweight/",
          "author": null,
          "description": "I’ve tried docsify and PineDocs; however, docisfy is incredibly slow for me over Cloudflare Tunnels for some reason\n I like PineDocs, but the mobile UI kinda sucks\n I’ve also tried wikiJS and BookStack, but didn’t really care for them either\n Any recommendations?\n    submitted by    /u/kvpop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv9odo/whats_the_prettiest_yet_most_lightweight/",
          "publishedOn": "2022-12-25T23:35:48.000Z",
          "wordCount": 18583,
          "title": "What’s the prettiest yet most lightweight self-hosted wiki service out there?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv6nhb/remote_desktop_containers/",
          "author": null,
          "description": "In the past I have used Guacamole with Docker. Now that I have switched to Kubernetes for hosting in my home lab, I have been getting weird errors when trying to use it.\n Is there any good alternatives to Guacamole? Or any recommendations?\n    submitted by    /u/BinaryNexus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv6nhb/remote_desktop_containers/",
          "publishedOn": "2022-12-25T21:04:19.000Z",
          "wordCount": 18323,
          "title": "Remote Desktop Containers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv65rm/any_google_photos_alternative_that_can_also/",
          "author": null,
          "description": "I installed Photoprism but it seems that I can't have it organize my \"Originals\" folder on the actual disk? Does anyone have any alternatives that can help moving files/organization? Example: select a bunch of photos from time range and \"move to new folder photos/My2022Trip\"\n    submitted by    /u/Intelg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv65rm/any_google_photos_alternative_that_can_also/",
          "publishedOn": "2022-12-25T20:39:33.000Z",
          "wordCount": 18342,
          "title": "Any Google Photos alternative that can also \"organize\" (create folders and move photos to new folder) from same web UI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv63er/bitwarden_app_and_cloudflare_access_integration/",
          "author": null,
          "description": "Did anyone manage to get both running together without excluding IPs etc?\n    submitted by    /u/GelosSnake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv63er/bitwarden_app_and_cloudflare_access_integration/",
          "publishedOn": "2022-12-25T20:36:16.000Z",
          "wordCount": 18423,
          "title": "Bitwarden app and cloudflare access integration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv4bu2/backup_windows_pc_to_minios3/",
          "author": null,
          "description": "I have quite a bit of open space on my home server and recently had two scares with family members having failing drives. \n I have minio running perfectly fine on my home server, and would like to setup my grandparents and parents PCs to backup to my home minio. \n Is there any good, easy to use utility for windows that would allow backup to minio? I am a good distance away and something that can run in the background would give me peace of mind for their data. \n The minio/unraid server is also backed up to cloud. So 3 separate locations should mean the data is fairly safe from loss. \n Any advice would be greatly appreciated!\n    submitted by    /u/WesBur13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv4bu2/backup_windows_pc_to_minios3/",
          "publishedOn": "2022-12-25T19:07:20.000Z",
          "wordCount": 18525,
          "title": "Backup Windows PC to Minio/S3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv40ss/thin_clients_lowend_chips_how_to_compare_what_to/",
          "author": null,
          "description": "Hello! Apologies in advance if this is not the right place to post.\n Tl;dr: how to compare low consumption chips? How does a Via vx855 or vx900 compare to a Marvell ARMADA PXA 510 v7? \n I'm only getting started with self-hosting, etc and after trying to get a rpi, I read a few posts around here recommending a thin client instead, which could potentially be cheaper, more efficient and at least as powerful (if not more) than a pi3.\n For info, my intention is to set a very simple home server so I can automate backup of my several devices, potentially self hosting nextcloud or equivalent.\n Now, my question: after reading a few posts, I went and bought off ebay (I'm in the UK in case that matters) a wyse 3010 (T10). I think it's this: https://www.wysechoice.co.uk/epages/BT4858.mobile/en_GB/?ObjectID=18010786\n Now, I haven't tested yet (Christmas and all that...) but I realised (too late, maybe?) that it's a 32bit processor, and the wyse comes without any flash storage! I know I can install Linux in a pen-drive so that's not an issue, but using the internal flash memory would be a nice addition.\n On the other hand, looking a bit more on ebay, I've found a few igel m310/320/330 for a reasonable price. They come with a chip Via Eden x2 (vx855 or vx900). All this info i found in parkytowers, which is extremely helpful but also a huge rabbit hole... And now I don't know anything anymore!\n In brief: how does a Via vx855 or vx900 compare to a Marvell ARMADA PXA 510 v7? How do these compare to an Atom e3815?\n Again, sorry if this is the wrong place to post (or the wrong way to ask!) and thanks in advance for reading and helping out!\n Ps: and merry christmas/happy new year if you celebrate in any way ;)\n    submitted by    /u/metronomme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv40ss/thin_clients_lowend_chips_how_to_compare_what_to/",
          "publishedOn": "2022-12-25T18:51:59.000Z",
          "wordCount": 19627,
          "title": "Thin clients, low-end chips: how to compare, what to buy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2uu9/personal_email_address_using_my_domain/",
          "author": null,
          "description": "I have this domain first-last.com and wanted to use it for daily personal and professional use. Just wondering if this seems like a sensical decision.\n ​\n Account logins:\n [account+twitter@first-last.com](mailto:account+twitter@first-last.com): password\n [account+reddit@first-last.com](mailto:account+reddit@first-last.com): password\n ​\n Professional/Personal emails:\n Professional [contact@first-last.com](mailto:contact@first-last.com)\n Personal [hello@first-last.com](mailto:hello@first-last.com)\n    submitted by    /u/Ok-Move-803  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2uu9/personal_email_address_using_my_domain/",
          "publishedOn": "2022-12-25T17:52:05.000Z",
          "wordCount": 21645,
          "title": "Personal email address using my domain",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2uqw/simple_linux_command_web_gui/",
          "author": null,
          "description": "Hey, I'm looking for a program that might exist that i've heard of ( or maybe i've dreamt hearing of it).\n Basically, all im looking for is a simple web app that i can configure commands for that i can run in my local network so when my partner yells \"IS PLEX DOWN?!?!\", they can just hit a button to send a \"docker container plex restart\" command to my server.\n I can probably achieve this in home assistant, but I'm trying to avoid that. I'd prefer a standalone solution of some sort.\n EDIT: Resolved. OliveTin worked perfectly and its already up and running. Took about 30 minutes to going. Thanks again to /u/alphafalcon\n    submitted by    /u/Offbeatalchemy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2uqw/simple_linux_command_web_gui/",
          "publishedOn": "2022-12-25T17:51:57.000Z",
          "wordCount": 19016,
          "title": "Simple linux command web gui?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2t4s/selfhosted_paas_no_dokku_pls/",
          "author": null,
          "description": "What do you use to host small Go/TypeScript/Python... etc. projects in your home lab? Had a look on Dokku, but it has no UI and works in single-node only.\n    submitted by    /u/Minimum-Dig3986  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2t4s/selfhosted_paas_no_dokku_pls/",
          "publishedOn": "2022-12-25T17:49:45.000Z",
          "wordCount": 19591,
          "title": "Selfhosted PaaS? (No dokku pls)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2kp0/best_backup_solution_with_encryption/",
          "author": null,
          "description": "All my main drives are luks encrypted. I have a couple Android phones I'd also like to backup + images/videos on external drives.\n I was thinking of using rsync to backup my computer drives? But I still don't know how to do encryption with that, otherwise the luks encryption is pointless?\n For android/images/videos/files I've seen that nextcloud is decent? I don't mind them not being encrypted but ideally they would be. And that nextcloud has an encryptuion addon\n I have a hetzner vps and hetzner storage box so far\n    submitted by    /u/Any-Bread2113  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2kp0/best_backup_solution_with_encryption/",
          "publishedOn": "2022-12-25T17:37:36.000Z",
          "wordCount": 21280,
          "title": "Best backup solution with encryption",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv2cn2/need_help_on_volumes_in_portainer/",
          "author": null,
          "description": "Hello all and merry Christmas! \n I installed Turnkey-core in Proxmox on a Dell server and then installed Docker and Portainer. So far so good. Only thing I don't really get is how volumes work in Portainer. So let's say I install Qbittorrent and I want it to download everything to a NFS folder on my NAS, do I have to mount that folder in Turnkey? Or do I have to add that volume in Portainer? Or do I have to do both? Please help me on this.\n Thanks!\n    submitted by    /u/babsenfred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv2cn2/need_help_on_volumes_in_portainer/",
          "publishedOn": "2022-12-25T17:26:16.000Z",
          "wordCount": 17704,
          "title": "Need help on volumes in Portainer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv1t1o/building_a_personal_arm_server_cluster/",
          "author": null,
          "description": "Hi everyone. Does anyone have resource links to how I can build an a server cluster/farm. Got my own development. I am tired of posting cloud fees. But I am willing to pay and as an investment for my own personal learning and development server. In the long run. I know it will be less hassle to run a cluster server and it might even be cheaper but I’ll not learn anything but their own version of the tools. I have read the initial intro notes on this sites and they are useful. I am looking for additional 101 step by step materials. Thanks so much.\n    submitted by    /u/Mikefoong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv1t1o/building_a_personal_arm_server_cluster/",
          "publishedOn": "2022-12-25T16:58:49.000Z",
          "wordCount": 18313,
          "title": "Building a personal arm server cluster",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv0zyi/i_wrote_a_script_that_automatically_sends_unread/",
          "author": null,
          "description": "I had been searching for a way to read articles through Kindle. I found a few solution but they were either too complicated or required paid services, so I decided to write my own script with the help of ChatGPT that\n  \n(i) Checks for new wallabag articles every X seconds\n (ii) Emails them to my kindle's email address as epub/mobi\n (iii) Marks the sent articles as read.\n  \nHere's the script:\n # Set your kindle's email adress EMAIL_ADDRESS='username_kindleid@kindle.com' # Log file LOG_FILE='/tmp/kindle-log.log' while true; do # Get the list of articles from Wallabag articles=$(wallabag list -n) # Check if there are any new articles article_list=($articles) for article_info in \"${article_list[@]}\"; do article_info_split=($article_info) id=${article_info_split[0]} # Check if id is valid if [[…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv0zyi/i_wrote_a_script_that_automatically_sends_unread/",
          "publishedOn": "2022-12-25T16:15:22.000Z",
          "wordCount": 18655,
          "title": "I wrote a script that automatically sends unread wallabag articles to Kindle",
          "imageUrl": "https://external-preview.redd.it/o52OrngMF3ebGloWnpXeFqXgekVacj5nwX4g68XgZQA.jpg?auto=webp&s=6ecbed07a2a8dcdbc945ec4f9070d0cc603ec071"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv0tb4/audio_streaming_receiver_volumio_alternative/",
          "author": null,
          "description": "Hi,\n ​\n I'm looking for a selfhosted Windows or Linux service that includes a web-based GUI and supports CD-ROM playback. I looked up Volumio however many people have had issues with it being a bit buggy and it is also requires a paid subscription to support CD playback. Preferably with Airplay support so I could stream lossless to my speakers through a DAC plugged into the streaming machine.\n ​\n Hardware at my disposal is:\n Dell Thin client with a Celeron, 2GB RAM and 4GB eMMC storage.\n Or a Late 2014 Mac Mini that is already running Windows in bootcamp, due to it being used as a low-power personal Minecraft server machine through AMP instance manager.\n ​\n Any suggestions? Anything I've found is usually Raspberry Pi - ARM based, and I don't have a spare one on hand, all of them are running their duties already.\n    submitted by    /u/jakubperhac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv0tb4/audio_streaming_receiver_volumio_alternative/",
          "publishedOn": "2022-12-25T16:05:44.000Z",
          "wordCount": 18971,
          "title": "Audio streaming receiver - Volumio alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv0c20/selfhosted_you_photography_portal_for_clients/",
          "author": null,
          "description": "Hi guys, is there a self-hosted solution that could be use for hosting pictures and provide access/download them, once client pays for them? Doesn’t need to have payment feature. Just need to have an admin and client portal\n Thanks\n    submitted by    /u/Allferry  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv0c20/selfhosted_you_photography_portal_for_clients/",
          "publishedOn": "2022-12-25T15:39:49.000Z",
          "wordCount": 18366,
          "title": "Self-hosted you photography portal for clients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv08og/smtp_login_attempts/",
          "author": null,
          "description": "To those that host their own email/smtp server are you seeing an increase in SMTP login attempts over the past few weeks? Any one have an idea which breach/attack started this?\n It Just makes the logs a real pain to go through.\n Edit: This is not a new server and I have been running my smtp server for a while (decades). I am just asking if everyone is being hit (maybe just usa ips?) and/or if anyone knows the cause.\n    submitted by    /u/prshaw2u  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv08og/smtp_login_attempts/",
          "publishedOn": "2022-12-25T15:34:23.000Z",
          "wordCount": 19121,
          "title": "SMTP login attempts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv082c/besy_way_to_automate_epubs_for_kavita/",
          "author": null,
          "description": "What is the best and most simple way of automating the process of \n Download Book -> Edit embeded metadata in Epub -> Send to Kavita\n As far as I know, currently there are 3 programs that can edit the metadata of an epub file. Readarr, Lazylibrarian, Calibre. I want to use Calibre but I think the the GUI looks not great and can be a pain to work with.\n    submitted by    /u/AlphaShiro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv082c/besy_way_to_automate_epubs_for_kavita/",
          "publishedOn": "2022-12-25T15:33:23.000Z",
          "wordCount": 18198,
          "title": "Besy way to automate epubs for Kavita?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zv04p7/intranet_caself_signed_ssl_certificate/",
          "author": null,
          "description": "Hello, don't know if this is the right place to ask this but i will try. \n I would like to to create a self signed CA to sign certificates for websites on my local network only as for anything outside is behind my reverse proxy with Lets encrypt certbot. The problem is if i import my self signed certificate on Win11 machine all browsers return that website has no trusted certificate. Am i doing it wrong or is there some sort of trick to this? Certificates/CA generation is a bit confusing for me from the technical side of things. \n Is there a tool that would help me generate a CA/self signed ssl certificates and import them or do i need to do everything by hand?\n    submitted by    /u/Dymas-CZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zv04p7/intranet_caself_signed_ssl_certificate/",
          "publishedOn": "2022-12-25T15:28:09.000Z",
          "wordCount": 19884,
          "title": "Intranet CA/self signed ssl certificate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuzlba/ssh_vs_vpn/",
          "author": null,
          "description": "Hello, I would like to access my local server at home from anywhere. \n Are there some advantages / disadvantages of opening port for SSH or using VPN server?\n What’s the best choice to provide the best security as could?\n    submitted by    /u/PatrikKnizka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuzlba/ssh_vs_vpn/",
          "publishedOn": "2022-12-25T14:57:41.000Z",
          "wordCount": 19572,
          "title": "SSH vs VPN?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuy39q/looking_for_a_selfhosted_markerio_alternative/",
          "author": null,
          "description": "Hey :)\n I'm looking for a free and/or open source self-hosted alternative to marker.io for visual bug tracking/reporting.\n On a website users can click on an element and write comments about a visual bug - mainly what marker.io does.\n It should be running in Docker and got webhooks to connect it to project management tools.\n Thanks for your suggestions!\n    submitted by    /u/ynomel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuy39q/looking_for_a_selfhosted_markerio_alternative/",
          "publishedOn": "2022-12-25T13:26:21.000Z",
          "wordCount": 20050,
          "title": "Looking for a self-hosted marker.io alternative (FOSS) - Open Source Visual Feedback and Bug Tracking / reporting tool for websites",
          "imageUrl": "https://external-preview.redd.it/OAKGuc-f5IxKIaBO6aCMxgiGiSnwk1aVZf1O4hcfTkE.jpg?auto=webp&s=d9ad46efcbf012233db482a1d3f339c348856c57"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuxv1t/simple_selfhosted_s3compatible/",
          "author": null,
          "description": "Hi all,\n I'm building an app to manage some files, and I've determined it makes the best sense to use object storage.\n I would like to host internally on my home k8s cluster to start/while I'm developing, using my NFS NAS as the actual storage backend.\n Are there any self-hostable solutions out there that can slap an S3 API in front of some NFS? Minio seems really heavyweight for my use case, plus they explicitly don't support network filesystem backends. The only other potential solution I've found is Zenko Cloudserver, and frankly, it looks like a development mess. \n Would appreciate any insight if anybody has discovered other solutions.\n //edit: to clarify, when I say simple, ideally I’m looking for something that just maps the API to files on the filesystem. Minio is great, don’t get me wrong, but I don’t need the whole HA/duplication/everything else it provides for my local needs. I just need to be able to make API calls and retrieve files. \n Thanks!\n    submitted by    /u/e3b0c442  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuxv1t/simple_selfhosted_s3compatible/",
          "publishedOn": "2022-12-25T13:10:44.000Z",
          "wordCount": 20608,
          "title": "Simple self-hosted S3-compatible",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zumi6j/my_christmas_lights/",
          "author": null,
          "description": "submitted by    /u/PovilasID  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zumi6j/my_christmas_lights/",
          "publishedOn": "2022-12-25T00:20:46.000Z",
          "wordCount": 17897,
          "title": "My Christmas lights",
          "imageUrl": "https://external-preview.redd.it/8wF-Yhb7zn_DgTRAUzS7PUxlvHwD0iwE81JMDQEHnjk.png?format=pjpg&auto=webp&s=43966f44f359ca404f3fbbcc21cc05836e7d59e7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zul0vb/gluetun_authentication_with_pia/",
          "author": null,
          "description": "I've been unable to start a Docker container with gluetun using Private Internet Access. The logs show an authentication error, but I'm positive the credentials are correct. I assume I've done something else incorrectly.\n Does anybody have a VPN set up using gluetun and PIA? I've tried most versions of the image with the same result.\n The error in the gluetun container is: \n 12/24/2022 2:58:53 PM2022-12-24T22:58:53Z ERROR [openvpn] AUTH: Received control message: AUTH_FAILED 12/24/2022 2:58:53 PM 12/24/2022 2:58:53 PMYour credentials might be wrong 🤨 \n The compose file I am using is:\n version: \"3.8\" services: qbittorrent: container_name: qbittorrent image: linuxserver/qbittorrent restart: unless-stopped network_mode: \"service:gluetun\" depends_on: - gluetun volumes: - /home/docker/qbittorrent/config:/config - /home/docker/data/torrents:/downloads environment: - PUID=1000 - PGID=1000 gluetun: image: qmcgaw/gluetun container_name: gluetun cap_add: - NET_ADMIN devices: - /dev/net/tun:/dev/net/tun ports: - 8888:8888/tcp # HTTP proxy - 8388:8388/tcp # Shadowsocks - 8388:8388/udp # Shadowsocks # qbittorrent ports - 8080:8080 - 6881:6881 - 6881:6881/udp restart: unless-stopped volumes: - /home/docker/gluetun:/gluetun environment: # See https://github.com/qdm12/gluetun/wiki - VPN_SERVICE_PROVIDER=private internet access - VPN_TYPE=openvpn - OPENVPN_USER=redacted - OPENVPN_PASSWORD=redacted - SERVER_REGIONS=US California \n    submitted by    /u/spiderguy33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zul0vb/gluetun_authentication_with_pia/",
          "publishedOn": "2022-12-24T23:00:53.000Z",
          "wordCount": 18786,
          "title": "gluetun authentication with PIA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zujp7u/should_i_switch_from_1password_to_the_self_hosted/",
          "author": null,
          "description": "The Lastpass incident woke me up and really made me think about what I was doing and why I was entrusting my passwords to others.\n Now I have come to the decision to switch to a self-hosted password manager.\n I am currently a little afraid that my current one might be hit at some point.\n I currently use 1Password and would like to switch to the self-hosted version of Bitwarden.\n What do you think, is it worth it and do I have to worry about security?\n I know a lot about securing Linux servers, so I think I'm relatively safe, but what do you think?\n Where should I host, can you recommend a secure hoster that is also trustworthy?\n I am currently thinking about using Hetzner, Ionos or AWS.\n If possible the hoster should be located in Germany.\n    submitted by    /u/MaximilianGT500  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zujp7u/should_i_switch_from_1password_to_the_self_hosted/",
          "publishedOn": "2022-12-24T21:52:08.000Z",
          "wordCount": 20575,
          "title": "Should I switch from 1Password to the Self Hosted alternative Bitwarden?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuijs2/hosting_a_windows_vm_on_a_linux_server/",
          "author": null,
          "description": "I would like to host a windows vm on my intel nuc, that you can connect via a web browser. Its for my dad that wants to run some windows software where wine will not work. So my question is, what would be good foss software, or combination of software, that could make this work. Help would be appreciated merry Christmas\n    submitted by    /u/Nartapok  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuijs2/hosting_a_windows_vm_on_a_linux_server/",
          "publishedOn": "2022-12-24T20:54:08.000Z",
          "wordCount": 21594,
          "title": "Hosting a windows vm on a linux server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuif4o/is_it_better_to_host_vpn_on_a_server_or_router/",
          "author": null,
          "description": "This is a follow up to my previous post. Is it also possible to allow certain websites to pass through outside of the VPN, like Netflix for example? Not sure if that would put the server at risk though.\n    submitted by    /u/ALCF98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuif4o/is_it_better_to_host_vpn_on_a_server_or_router/",
          "publishedOn": "2022-12-24T20:47:32.000Z",
          "wordCount": 18126,
          "title": "Is it better to host VPN on a server or router?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuidbk/access_jellyfin_through_google_compute_with/",
          "author": null,
          "description": "Hey Folks,\n So I have Jellyfin and Tailscale installed on my home desktop. I also have Tailscale installed on a Google Compute Free Tier VM and have enabled it as subnet router. The home machine with Jellyfin installed is set as an exit node. I am able to ping my Google VM Tailscale IP from home machine and ping home machine from the VM.\n My question is, how do I access Jellyfin through the internet using my VM? Basically, I want to access without using Tailscale client(because there may be instances where I cant install the client on a device)..\n I have verified I can access my Jellyfin server through other devices on my home LAN.\n    submitted by    /u/Rakeen70210  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuidbk/access_jellyfin_through_google_compute_with/",
          "publishedOn": "2022-12-24T20:45:00.000Z",
          "wordCount": 18765,
          "title": "Access Jellyfin Through Google Compute with Tailscale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zugob3/self_hosted_roundup_21/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zugob3/self_hosted_roundup_21/",
          "publishedOn": "2022-12-24T19:19:42.000Z",
          "wordCount": 18455,
          "title": "Self Hosted Roundup #21",
          "imageUrl": "https://external-preview.redd.it/rdm70f9IX6spqpg8Uh0FpFsaWjUNeyqzhMDa4K33PRQ.jpg?auto=webp&s=8a3a055f3e19f26b77d5397d54701bc3bee07e70"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zufdix/id_like_to_get_into_privately_selfhosting_for_my/",
          "author": null,
          "description": "I'd like to turn my server in the other room into a simple file hosting cloud that functions pretty much exactly like Onedrive.\n I've tried looking around but all I've found are monthly charges or just not what I'm looking for. \n My close friends and family game together, record moments, draw art and share/edit them. \n I would super appreciate any suggestions or advice you guys have. Please keep the topic on what software would be the best for what I'm looking for and not patronizing about security or judgment of character.\n Features I'd really like:\n  \nAbility to use it through File Explorer like OneDrive.\n Free.\n Fancy bells and whistles like profiles, monitoring, passwords(?), history and ability to Quota the storage into sections, etc.\n  \n​\n Features that're a must:\n  \nUsers are able to upload, download, delete, edit any files & pictures/text documents and what not as well as stream and play clips FROM my server without having to download them.\n  \nI am also open to huge one-time payment but I'm not looking for anything with monthly payments.\n The server has windows 11 pro, 128GB of dedotated WAM and 10TB of ssd storage.\n    submitted by    /u/ZaneyHD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zufdix/id_like_to_get_into_privately_selfhosting_for_my/",
          "publishedOn": "2022-12-24T18:16:13.000Z",
          "wordCount": 20303,
          "title": "I'd like to get into privately selfhosting for my close friends and family.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zudy4n/2fa_on_arr_and_jellyfin/",
          "author": null,
          "description": "Hello family,\n Merry christmas!\n I am looking to setup 2FA on Radarr, Sonarr and Jellyfin. I think I can ise authelia for Radarr and Sonarr (Not yet tested). But I could bot find anyway to implement same in jellyfin.\n Have you implemented 2FA on jellyfin and Radarr ? Please help me.\n Thanks\n    submitted by    /u/leostic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zudy4n/2fa_on_arr_and_jellyfin/",
          "publishedOn": "2022-12-24T17:06:08.000Z",
          "wordCount": 18919,
          "title": "2FA on *arr and jellyfin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuduct/can_you_recommend_any_good_calendar_todo_list/",
          "author": null,
          "description": "I am currently using Google Calendar and Trello, but it always feels a bit awkward. I'd like to write down events (and event series, ideally) and have a bit of automation with the todo list, like creating a certain todo list element at the start of the month or stuff like that.\n Is there anything good?\n    submitted by    /u/SendMeOrangeLetters  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuduct/can_you_recommend_any_good_calendar_todo_list/",
          "publishedOn": "2022-12-24T17:01:01.000Z",
          "wordCount": 19484,
          "title": "Can you recommend any good calendar + todo list software?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zub6wh/alternatives_to_myid/",
          "author": null,
          "description": "Are there any other similar services to this? It lets you use it's domain for other self-hosted services besides just static web hosting but I don't actually speak the language of the site and I just wanted to see if there were any other alternatives that didn't involve giving my phone number.\n The Service: https://www.my.id/\n Examples:\n Website: https://nekoweb.my.id/\n XMPP: https://im6.nekoweb.my.id/cakap/\n Retrowars: https://rwr.nekoweb.my.id\n    submitted by    /u/PrettyExpensiveCoat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zub6wh/alternatives_to_myid/",
          "publishedOn": "2022-12-24T14:44:26.000Z",
          "wordCount": 18087,
          "title": "Alternatives to my.id",
          "imageUrl": "https://external-preview.redd.it/w4-6gGMLuRKS8r-zDKXYJIYtq83iNAy8AGQ3YMdAyMQ.jpg?auto=webp&s=f124224d3cfc2d321900ac9f59b1838c3cc495cc"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuaqgh/help_with_storage_server/",
          "author": null,
          "description": "I have a vps server with 1tb storage and 1 cpu and 2 gb ram. What softwares are there to securely access this on Android, pc and an android tv//fire stick\n    submitted by    /u/artremist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuaqgh/help_with_storage_server/",
          "publishedOn": "2022-12-24T14:19:11.000Z",
          "wordCount": 18853,
          "title": "help with storage server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuagad/what_would_you_love_to_see_as_self_hosted_service/",
          "author": null,
          "description": "It's almost Christmas, and if you could ask Santa a self-hosted service, what would It be?\n I'm curious to know what would you would want/need, but no solution currently exists because It's too specific/a niche.\n    submitted by    /u/Tours-Petronas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuagad/what_would_you_love_to_see_as_self_hosted_service/",
          "publishedOn": "2022-12-24T14:03:38.000Z",
          "wordCount": 20545,
          "title": "What would you love to see as self hosted service?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zuaewg/selfhosted_file_download_site_in_intranet_no/",
          "author": null,
          "description": "Hi,\n I’m currently looking for a software solution to host a file download site on a companies Intranet. I noticed that searching for the phrase “Download” on the Internet is a bit tricky ^^\n My requirements are:\n  \nThe Server will have no connection to the Internet\n No Sync option like a cloud is required\n All visitors can download all released files from a web page\n Registered users can upload and manage their files via a web interface\n User can create groups and sub-groups and assign files to this groups\n Files cannot downloaded directly. Instead, the download has to be conducted via a Page for the File on which predefined text fields are shown (e.g., License, Creator, Uploader, Version-No, Contact Data etc.). Also, one or more preview pictures can be displayed.\n The download page allows to download different files (e.g. the same Bitmap in different file formats).\n  \nI hope for some advice on this, because finding software for this is really a pain in the neck. Thanks, in advanced.\n    submitted by    /u/Adzorn76  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zuaewg/selfhosted_file_download_site_in_intranet_no/",
          "publishedOn": "2022-12-24T14:01:31.000Z",
          "wordCount": 19955,
          "title": "Self-hosted File Download Site in Intranet (No Internet connection)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu91uw/first_nas_build/",
          "author": null,
          "description": "I was looking at hard drives for my first nas build and saw that many people seem to be using Ironwolf Pro drives. Since I plan on using the nas as a media drive only for movies and such, should the basic Ironwolf be enough or should I opt for the Ironwolf Pro? I would like to clarify that I’ll be getting a 2 bay unit only since I’m just starting out and only intend to use it for movies atm. I can always upgrade the unit later but I was wondering if I’ll see a significant difference between the Ironwolf and Ironwolf Pro with the differences in transfer rate, cache, etc.\n    submitted by    /u/Typical-Ad-491  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu91uw/first_nas_build/",
          "publishedOn": "2022-12-24T12:39:39.000Z",
          "wordCount": 18485,
          "title": "First NAS build",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu89r5/visionfive2_instead_of_raspberry_pi_4/",
          "author": null,
          "description": "Hi, I've been thinking about setting up my own Raspberry Pi 4 server. I want to use those services: pihole (certainly), duplicati2 (or something similar, certainly), FreeNAS/Nextcloud/Syncthing (one or two of them certainly), OpenVPN/WireGuard (maybe). I wanted to buy Raspberry Pi4 and connect 2 HDDs by USB3 to provide needed storage. I was quite certain Raspberry Pi 4 is a good idea, but the prices of 4 and 8GB editions are very high.\n Now there is those VisionFive2 that has better specs and much lower prices, but uses RISC-V processor. It's going to support Debian. Will the soft I mentioned work on it? Is it a good idea to use VisionFive2 instead of Raspberry Pi4 for such usecases?\n    submitted by    /u/Entrapped_Fox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu89r5/visionfive2_instead_of_raspberry_pi_4/",
          "publishedOn": "2022-12-24T11:46:06.000Z",
          "wordCount": 18618,
          "title": "VisionFive2 instead of Raspberry Pi 4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu7xax/ebook_library_server_with_editingannotations/",
          "author": null,
          "description": "What I would like....\n I have a relatively large academic text library in PDF, as well as the typical mobi (have kindle), epub, and even .lit (from my old surface pro days) ebook library. I would like a server that has persistent read state and ability to highlight/annotate/export annotations from the file. I would also like multi-user access.\n ​\n What I have tried.....\n Have been running calibre with calibre-web front end, which I don't mind and find the UI ok. The ability to track read status and custom column support in calibre-web is great. It's really only single user however when it comes to read states, etc. Also there is not persistent position in place.\n I have downloaded Kavita and it seems a lot closer to what I want (decide readers, syncs states, multiple user), but the metadata is horrible to non-existent for PDFs. Also when updating the container it wants to try to re-create the database each time for some reason.\n I have also tried audiobookshelf (have moved to this for audiobooks from plex/prologue). The audiobookshelf interface is great. They have ebook support in experimental which puts it beside/embedded with the audiobook, but the readers are horrible. I can just download the epub and send to my kindle or download the pdf (from web, not iOS app unfortunately), and could just upload the pdf back to audiobookshelf when completed.\n ​\n Are there any other options out there that I am missing? I have seen Koodo-reader but seems a bit early. Audiobookshelf or Kavita are developing but still not quite there yet. Calibre-web is closest (but really only single user), but still locked into calibre backend for sorting which I hate.\n Honestly considering just scrapping it and using a folder of sorted files for the time being.\n    submitted by    /u/Jmanko16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu7xax/ebook_library_server_with_editingannotations/",
          "publishedOn": "2022-12-24T11:20:40.000Z",
          "wordCount": 18697,
          "title": "Ebook library server with editing/annotations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu4xxn/convoy_v08_open_source_webhooks_proxy/",
          "author": null,
          "description": "Hey Friends, \n To close out the year, we shipped Convoy v0.8. This is such an exciting update for us; we shipped many updates we are proud of and excited to share with the community. You can just read on to learn more.\n Subscriptions Filtering\n Subscriptions Filtering is the act of subscribing for events based on the structure of the payload. It is one of our most exciting features. With this, webhook consumers can filter events they receive based on the payload. This includes two types of filters, from simple filters (exact object match) to complex matches (like $or, $in etc.) It would be best if you headed over to our docs to see a complete reference. See sample in action:\n Building a query with a sample payload\n Portal Links\n After deprecating applications, the \"app portal\" automaticall…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu4xxn/convoy_v08_open_source_webhooks_proxy/",
          "publishedOn": "2022-12-24T07:49:34.000Z",
          "wordCount": 19416,
          "title": "Convoy (v0.8) - Open Source Webhooks Proxy - Subscriptions Filtering, Static IPs, Portal Links, and much more! 🥳 🎉",
          "imageUrl": "https://external-preview.redd.it/Qf4a9s1R15F98D-YZaY17ZFeGbbNMsrx6W7n2LMyxpQ.jpg?auto=webp&s=4a8093af4e66d4060b1a707044ada1de6315a663"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu4lwu/wikijs_now_supports_asciidoc/",
          "author": null,
          "description": "https://github.com/requarks/wiki/releases/tag/v2.5.295\n    submitted by    /u/Farsighted-Chef  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu4lwu/wikijs_now_supports_asciidoc/",
          "publishedOn": "2022-12-24T07:27:16.000Z",
          "wordCount": 17874,
          "title": "Wikijs now supports AsciiDoc!",
          "imageUrl": "https://external-preview.redd.it/EBHioAUda2P5eczXBy6uZImOBgIJr9jaGA4sCQp3Duw.jpg?auto=webp&s=7b29250733539e4617f876aff759422ee0242b89"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu2nmy/any_caldav_web_client/",
          "author": null,
          "description": "I have a self hosted Baikal server and use jtx board as a client on the android phone. The android client supports \"Journals, Notes & Tasks\". I was wondering if there exists a web based client that supports all three features. I am particularly looking for the VJOURNAL and VTODO support. Thanks!\n    submitted by    /u/aadoop6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu2nmy/any_caldav_web_client/",
          "publishedOn": "2022-12-24T05:25:21.000Z",
          "wordCount": 18366,
          "title": "Any CalDAV web client ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zu256e/why_should_you_self_host/",
          "author": null,
          "description": "submitted by    /u/io-x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zu256e/why_should_you_self_host/",
          "publishedOn": "2022-12-24T04:56:09.000Z",
          "wordCount": 20593,
          "title": "Why should you self host?",
          "imageUrl": "https://preview.redd.it/8ppsm73r2s7a1.jpg?auto=webp&s=719c1563bc9ea9cc49d6dbde82aecdf61613c2d2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztx5y2/selectablesync_folder_from_my_headless_raspberry/",
          "author": null,
          "description": "I'm looking for something (possibly FOSS but I will check also paid software) that allow me to sync my external hard drive (mounted with open media vault) to google drive.\n I tried owncloud but it doesn't do it server side (and their client doesn't allow me to mount network attached storage on windows).\n Tried Rclone with Rsync as well but I need to select some folders and it's not so easy to manage through script. \n any solution is welcome. \n Sorry for any typo or error, english is not my mothertongue.\n Thanks\n    submitted by    /u/Novocaine85  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztx5y2/selectablesync_folder_from_my_headless_raspberry/",
          "publishedOn": "2022-12-24T00:32:28.000Z",
          "wordCount": 17459,
          "title": "Selectable-sync folder from my headless raspberry pi server to google drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztx59g/my_experience_standing_up_a_mastodon_instance/",
          "author": null,
          "description": "Currently stuck battling the Rona over the holidays so thought I'd write up my experience self-hosting something I didn't ever expect to - social media!\n Definitely an interesting journey - I started with the new Linuxserver.io Mastodon image, set up media storage in Backblaze, and stood up an instance of \"BirdsiteLive\" so I can still follow the twitter users I care about.\n https://eric-pierce.com/moving-to-mastodon/\n Hoping this is useful for someone, my full docker-compose is on github as well.\n    submitted by    /u/eric-pierce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztx59g/my_experience_standing_up_a_mastodon_instance/",
          "publishedOn": "2022-12-24T00:31:33.000Z",
          "wordCount": 17685,
          "title": "My experience standing up a Mastodon Instance, media hosting, and following Twitter accounts",
          "imageUrl": "https://external-preview.redd.it/zOg08DF9BYGQehZ24OsJ6TgTbJ14DQKHrCO0CsNzFX8.jpg?auto=webp&s=47d5e568c1fcf2874df02a06b13174e5a8f59a96"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztwirx/private_mastodon_or_other_alternative/",
          "author": null,
          "description": "Hi there,\n Since the borth of my daughter, I am searching a way to easily share news and photo of her with close friends and familly.\n I have a strict policy of no photos of my child on public social media.\n I was thinking making a private hosting of Mastodon but I fear that It may be overkill.\n What are your experiences managing it ?\n Is there some cool alternative out the that could be lighter ? :)\n Happy holidays everyone ;)\n    submitted by    /u/Stammfrei  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztwirx/private_mastodon_or_other_alternative/",
          "publishedOn": "2022-12-24T00:01:19.000Z",
          "wordCount": 17862,
          "title": "Private Mastodon, or other alternative ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztwgwd/self_hosting_as_a_christmas_gift/",
          "author": null,
          "description": "I’m kicking around the idea of giving “the gift of self-hosting” for next Christmas. The recipients, my nephews, are not super techy but intelligent and young enough to be relatively tech savvy. Even so, I want to streamline the setup process and minimize the amount of brainery required to use them. Here’s my thinking so far (I’d appreciate your input)…\n The giftees would receive: * An SBC-based server (inexpensive, small footprint, low power consumption) with… * An Ethernet cable to connect it to their router and… * A 4TB external storage drive * A personalized domain name * A personal website (something super simple that they could subsequently customize) or maybe a simple (i.e. TextPress) blog * Preconfigured (ImprovMX) forwarding for all their [wildcard]@mynewdomain.com email * A varie…",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztwgwd/self_hosting_as_a_christmas_gift/",
          "publishedOn": "2022-12-23T23:59:12.000Z",
          "wordCount": 20487,
          "title": "Self hosting - as a Christmas gift?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztvg9z/is_this_website_registrar_legit/",
          "author": null,
          "description": "Hey r/selfhosted,\n I'm unsure if this is the right subreddit to ask this but I'm trying to buy a domain and see one that I want available on this registrar for quite a bit cheaper than other registrars. The one I wanted was taken on other registrars but available on this one. I dont see much bad reviews or site claiming its a scam so I dont know what to think. Any thoughts? The site is regery.com\n    submitted by    /u/bIoodc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztvg9z/is_this_website_registrar_legit/",
          "publishedOn": "2022-12-23T23:11:11.000Z",
          "wordCount": 17762,
          "title": "Is this website registrar legit?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztvdvn/is_there_any_solution_available_to_backup_my_file/",
          "author": null,
          "description": "Looking for something like auto upload my photo from phone and auto sync in my home hdd.\n Also creat a two way sync for specific folder.\n    submitted by    /u/robertniro1980  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztvdvn/is_there_any_solution_available_to_backup_my_file/",
          "publishedOn": "2022-12-23T23:08:16.000Z",
          "wordCount": 16926,
          "title": "Is there any solution available to backup my file in cloud or object storage and play video or picture from there",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztvby2/strange_issue_with_nginx_proxy_manager/",
          "author": null,
          "description": "I'm not sure if my Google-Fu isn't working right or maybe I am asking the wrong question. \n I've not used NPM ever, and I am not super familiar with Nginx. I created some self-signed certificates, uploaded them in to NPM. When I access the a website it displays the error that the certificate is not valid. I do have the certificate in my trusted root, and my browsers do see it. I can't figure out why its doing this. For fun... I setup a copy of a docker container I am proxying traffic to through to NPM but, instead of using NPM with the copy I modified the local web server and added my self-signed and that works. No more errors. I didn't change the certificate in my trusted certs on my PC to make this work just didn't use NPM.\n I have no idea what I am missing. I've turned on all the radio buttons as needed ET CETRA.. Really kind of lost at this point.\n Any help?\n    submitted by    /u/AirItsWhatsForDinner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztvby2/strange_issue_with_nginx_proxy_manager/",
          "publishedOn": "2022-12-23T23:05:53.000Z",
          "wordCount": 17648,
          "title": "Strange issue with Nginx Proxy Manager??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv9vg/suggestions_for_selfhosted_cannabis_grow_journal/",
          "author": null,
          "description": "Anyone done this or alternatively have any experience running any self-hosted journals/diaries/logs that might also serve as a good grow log? \n I’ve used GrowDiaries on web as well as the GrowWithJane app, but I prefer not to have to upload all of my grow data/media in order to keep track. \n I would much rather have a self-hosted, private grow journal. I’m 100% legal, but also distrusting of other entities holding my data. Thanks for any suggestions!\n    submitted by    /u/DirtMetazenn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv9vg/suggestions_for_selfhosted_cannabis_grow_journal/",
          "publishedOn": "2022-12-23T23:03:15.000Z",
          "wordCount": 18320,
          "title": "Suggestions for Self-hosted Cannabis grow journal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv9el/simple_selfhosted_messaging_and_videocalls/",
          "author": null,
          "description": "Hi all,\n I have been working for a while in deploying a communitarian network in the rural region of Gandiol, Senegal, and I have been looking for a self-hosted messaging app like Whatsapp or Telegram. The main goal would be to have the following features:\n  \nText message exchange among individuals and groups.\n Image/Video exchange.\n  Audio/Video call support.\n  \nA solution I already found, looked promising but does not really end up working well, is to use rocket chat + jitsi. Instead of fighting to make this work properly, does anyone have some knowledge of any application that covers the features I mentioned before? Ideally would be an application that only do that, would like to avoid something more complex like Mattermost.\n Thanks everyone in advance and any idea is welcome :)\n    submitted by    /u/shunas6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv9el/simple_selfhosted_messaging_and_videocalls/",
          "publishedOn": "2022-12-23T23:02:38.000Z",
          "wordCount": 18634,
          "title": "Simple Self-hosted messaging and videocalls whatssapp/telegram like",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv877/diy_nas_truenas_scale_vs_proxmox_with_vms/",
          "author": null,
          "description": "I'm currently building a small NAS/Server to store my files and in the future host some docker containers (Tandoor, Bitwarden, Jellyfin, maybe the *arr-suite, etc.). I am using an asrock h370m itx that I plann to pair with an i3 9100 in a Jonsbo N1 with 5 HDDs for storage and 1 Sata SSD as a boot drive. In the future I could also add an nvme as a cache.\n As I understand, TrueNAS Core does not support docker as it is based on FreeBSD. TrueNAS Scale, however, does. So now I am torn between using Proxmox to setup a TrueNAS VM for my NAS use and a Linux VM for my docker/home server use.\n What option makes more sense? This is my first time building a home server that isn't just running Linux so I'm a little lost.\n    submitted by    /u/EmiMaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv877/diy_nas_truenas_scale_vs_proxmox_with_vms/",
          "publishedOn": "2022-12-23T23:01:10.000Z",
          "wordCount": 17539,
          "title": "DIY NAS - TrueNAS Scale vs Proxmox with VMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv7fe/access_a_single_file_via_nginx/",
          "author": null,
          "description": "Hi,\n I want to host a single file on my Raspberry Pi 4 using docker and nginx, such that when I go to subdomain.domain.tld it can retrieve the file contents stored on the local SD card on the RPi4. The file is an RSS file in XML format.\n How can I do this in the easiest way possible?\n    submitted by    /u/seriouslyfun95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv7fe/access_a_single_file_via_nginx/",
          "publishedOn": "2022-12-23T23:00:17.000Z",
          "wordCount": 17621,
          "title": "Access a single file via Nginx",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztv14i/help_with_mediawiki_behind_nginx_proxy_manager/",
          "author": null,
          "description": "Hi all,\n Spun up a Mediawiki install on a Debian server today, and I'm absolutely stumped trying to get this to work behind a reverse proxy. If I go to the IP of the server/wiki, it works fine, but if I go to the subdomain that I configured for this - pointed at my nginx proxy manager docker container that is handling SSL for me - it loads the default apache page instead.\n I tried specifying a custom location in the proxy host of \"/\" with the forward being 192.168.1.54/wiki/, and that just gives me the Apache 404 page.\n I've changed the $wgServer parameter in LocalSettings.php to be wiki.mydomain.com.\n I'm not sure if I should be looking at the apache configuration on my server, or additional parameters in nginx...\n I also tried editing the default config file in /etc/apache2/sites-enabled/ to point to /var/www/html/wikias that's where the PHP files are located for Mediawiki, and restarted apache. No luck.\n Does anyone have a similar setup?\n    submitted by    /u/skooterz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztv14i/help_with_mediawiki_behind_nginx_proxy_manager/",
          "publishedOn": "2022-12-23T22:52:20.000Z",
          "wordCount": 17829,
          "title": "Help with Mediawiki behind Nginx Proxy Manager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztu3t4/receiving_blog_replies_from_anywhere_on_the_web/",
          "author": null,
          "description": "submitted by    /u/spcbfr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztu3t4/receiving_blog_replies_from_anywhere_on_the_web/",
          "publishedOn": "2022-12-23T22:10:53.000Z",
          "wordCount": 17541,
          "title": "Receiving blog replies from anywhere on the web, including this very reddit post!",
          "imageUrl": "https://external-preview.redd.it/b3u2xqcox6NdwPu3zn4jeBEyjyrGfKNGkUjKM_2JH0Q.jpg?auto=webp&s=f521f534e8f1ec65a428c03419872316b02916d4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zttfal/need_getting_a_mastodon_server_up_im_so_close_i/",
          "author": null,
          "description": "I've followed this tutorial and gotten to the end but it's not quite working, I'm getting a 502 Bad Gateway error. But the reason I think I'm almost there is that the Favicon is loading correctly. https://social.pogo.community/ is where it's located at. \n I'm guessing this may be related to the fact I'm using \"Nginx Proxy Manager\" to make it so I can use this alongside my smarthome system I'm self hosting. Home Assistant. I'm not super confident I've set up that correctly. I followed a different tutorial to get that set up and I'm guessing there's just a minor configuration difference. \n During the mastodon tutorial I did skip the SSL Certbot step, since the Nginx proxy manager was already handling the SSL part, and I'm guessing this is where I screwed up. \n Here's the configuration options I tried in the Nginx proxy manager and what happened each time.\n What I did first, what I thought was correct based on the Nginx Proxy Manager I followed previously:\n ​\n When I did this, I'd get \\\"TOO MANY REDIRECTS\\\" error in the browser.\n As a test, I tried to set the scheme for https, with the forward port 443, I got this instead. Notice the mastodon favicon, that did not happen last time.\n And just for completion sake, here is the nginx configuration file on the server that's running mastodon: https://pastebin.com/aJZLKnhE\n    submitted by    /u/forte_the_infamous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zttfal/need_getting_a_mastodon_server_up_im_so_close_i/",
          "publishedOn": "2022-12-23T21:41:29.000Z",
          "wordCount": 18013,
          "title": "Need getting a Mastodon Server up, I'm so close I can taste it",
          "imageUrl": "https://external-preview.redd.it/AL7Kpmm2feaiR21UKcmKue0uX15GRyhyRZSw7Pcu-LI.jpg?auto=webp&s=96cc8cedf2f283289688ca05fe2220b0b6116b7a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zttcgu/docker_in_addition_to_scriptscode/",
          "author": null,
          "description": "I’ve lots of code on my server, mainly python and bash. A collection of them is running regularly by cronjob.\n Can I install docker and do some experiments with it without any disadvantages for my code folders?\n Thank you.\n    submitted by    /u/-happy2go  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zttcgu/docker_in_addition_to_scriptscode/",
          "publishedOn": "2022-12-23T21:38:00.000Z",
          "wordCount": 17434,
          "title": "Docker in addition to scripts/code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztsyjm/what_server_management_software_do_you_recommend/",
          "author": null,
          "description": "I have several VPSs and a homelab, it starts to be a small pain to monitor everything one-by-one so I would like to host some sort of dashboard (with controls) on one machine and aggregate information from all of my servers there.\n I know that there are solutions like pulseway, but I would like to use something selfhosted and free.\n    submitted by    /u/InkognetoInkogneto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztsyjm/what_server_management_software_do_you_recommend/",
          "publishedOn": "2022-12-23T21:20:47.000Z",
          "wordCount": 17440,
          "title": "What server management software do you recommend?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztr3ib/time_to_build_my_own_setup/",
          "author": null,
          "description": "Hey everybody! \n I have been working as a software developer for almost 10 years, and, for work stuff we always almost use cloud services.\n I love server less approaches etc, when it comes to handing a client an solution.\n But sometimes I do projects of my own, and in those cases I feel that the work becomes too much..\n Imagine just having the ability to run a Redis that allows my services to communicate, and then expose an Web App to show some data.\n So, here I am, I want to fix a home setup! \n The main goal is running small pieces of software that I build at home, and then often expose an Web App using Node to communicate with my Services.\n Where should I start? \n I have been looking at Synology and Qnap NAS as options, very cheap and seems really easy to get started with.\n Any recommendations and or guides to follow for this? \n Basically my goals are\n  \nRun Services through Docker (Only Locally)\n Expose WebApps running Node to reach the local services\n Attach Domain Names, I guess something needs to be done for DNS, or would a simple Redirect from my DomainProvider to my IP be enough? \n  \nMarry Christmas and Happy new Year\n    submitted by    /u/percybolmer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztr3ib/time_to_build_my_own_setup/",
          "publishedOn": "2022-12-23T19:58:08.000Z",
          "wordCount": 17513,
          "title": "Time to build my own setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztr2ev/festive_fun_christmas_present_checker/",
          "author": null,
          "description": "Hi r/selfhosted,\n I have created my own self hosted app (docker/python) to fill a gap in the market! A niche gap but a gap!\n Github Link : https://github.com/benkey0/ChristmasPresentChecker\n I love to make repeitive tasks slighlty easier like most of us do! Christmas presents involve lots of writing tags and lets face it tags arent fun!\n I have created a application to decode barcodes (using hardware scanner or device camera) and provide a front end solution for Christmas morning.\n You simply add sticky barcodes (printed with a thermal printer or ordered online for cheap!) onto your presents and add them into the Christmas Present Checker using the front end interface.\n Please see the below video.\n ​\n Scanning Video\n Essentialy this is my first time making something \"semi-useful\". I would appreciate some feedback and although its not as useful as most things shared here it may be something festive to play around with over this period!\n Merry Christmas!\n Ben\n    submitted by    /u/Diligent_Patience242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztr2ev/festive_fun_christmas_present_checker/",
          "publishedOn": "2022-12-23T19:56:45.000Z",
          "wordCount": 17464,
          "title": "Festive Fun ! - Christmas Present Checker",
          "imageUrl": "https://external-preview.redd.it/owXUdrMI8Fnr0hY4z_zciCLaA6tED9YDWY1i9zmFYME.jpg?auto=webp&s=35ea07721d9ad7f1fdf10c6dde8dd2c499f1f4e9"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztqzq7/a_simple_ansible_playbook_to_set_up_a_vps_with_a/",
          "author": null,
          "description": "I'm no sysadmin but I play around a lot with my VPS just for the heck of it and as a learning experience.\n I ended up automating part of my setup with Ansible.\n Host your stuff provides (among other things):\n  \nNextcloud instance (snap)\n \nVaultwarden instance (docker)\n \nSearxNG instance (docker)\n \nfail2ban\n \nBunkerweb\n \nRegular updates and backups for these services\n \nCerts using certbot\n \n This is born from my personal use case so it's pretty much a WIP and might have some rough edges here and there.\n However I though I'd share it around in case its of use for someone else.\n There are probably 100 better ways of doing this, any feedback is welcome.\n    submitted by    /u/not_real_user123321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztqzq7/a_simple_ansible_playbook_to_set_up_a_vps_with_a/",
          "publishedOn": "2022-12-23T19:53:20.000Z",
          "wordCount": 23747,
          "title": "A simple Ansible playbook to set up a VPS with a bunch of (hopefully) useful stuff",
          "imageUrl": "https://external-preview.redd.it/urlbXMSR7Sien89htGi0W1zLY4JofT-NM1BdZbrU9-A.jpg?auto=webp&s=1330c65281546f9fddab778066ef7a42aad6c10b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztphti/integrated_file_bookmark_and_note_storage_solution/",
          "author": null,
          "description": "I have been using my browsers bookmark manager to manage all of my bookmarks, but as the number of bookmarks that I have grows it is more difficult to manage them along with some problems with the manager itself. I have been trying to manage a growing number of local files, notes (notion).\n All of this has led me on a search for what I am calling an integrated storage solution, or a tool that will keep all of my files, bookmarks, and things of that nature organized. I would like to have a single file tree to manage files bookmarks notes and media. I currently use notion for my notes, and I am working on finding a way to integrate that.\n Next cloud has most of the functionality I believe I will need, and I may set up a server for it soon, but I want to see if there are any better options. I am ok with non self-hosted apps and self-hosted apps, and would prefer the software to not be a subscription (free option or one time purchase)\n Thanks for the suggestions and comments!\n    submitted by    /u/shalamander6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztphti/integrated_file_bookmark_and_note_storage_solution/",
          "publishedOn": "2022-12-23T18:47:32.000Z",
          "wordCount": 18761,
          "title": "Integrated file, bookmark, and note storage solution.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztjwce/folder_based_paperlessngx_alternative/",
          "author": null,
          "description": "I like paperless but cannot work with it without folder structure. \n Anyone knows if there is any alternative can organize files by traditional folder structure?\n    submitted by    /u/lyerx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztjwce/folder_based_paperlessngx_alternative/",
          "publishedOn": "2022-12-23T15:45:56.000Z",
          "wordCount": 18978,
          "title": "Folder based paperless-ngx alternative ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zthlti/vpn_solution_for_pesky_internet_connection/",
          "author": null,
          "description": "Hi,\n I''m spending more time than I want in some countries I don't want to name (somewhere in Asia), where the internet is sometimes problematic to use. I'll just say that they tried to use fake ssl certs on gov level before, and from my experience they are still trying to get access to peoples data.\n There are times when Wireguard works fine, then stop connecting at all. PPTP and L2TP are the most reliable (in term of creating a tunnel) but sometimes they also won't work. OVPN the same.\n Tried tailscale and netmaker, results vary.\n What do you recommend to set up on my home server (in EU) to reliably access?\n    submitted by    /u/ztardik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zthlti/vpn_solution_for_pesky_internet_connection/",
          "publishedOn": "2022-12-23T14:45:25.000Z",
          "wordCount": 18320,
          "title": "VPN solution for pesky internet connection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ztabho/critical_security_flaw_reported_in_passwordstate/",
          "author": null,
          "description": "The selfhosted password manager (Passwordstate) we use at work just released patches for multiple critical vulnerabilities.\n \"Successful exploitation allows an unauthenticated attacker to exfiltrate passwords from an instance, overwrite all stored passwords within the database, or elevate their privileges within the application\"\n    submitted by    /u/SteppkenPislmick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ztabho/critical_security_flaw_reported_in_passwordstate/",
          "publishedOn": "2022-12-23T08:32:20.000Z",
          "wordCount": 19111,
          "title": "Critical Security Flaw Reported in Passwordstate Enterprise Password Manager",
          "imageUrl": "https://external-preview.redd.it/uH26yve5W7BAGzo69LC2GTQqlYRtfPPHHfMg6rlSv_g.jpg?auto=webp&s=e6584d7afd8eb207398ca81bb444d56e74bb7e01"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt4b0m/lastpass_says_hackers_stole_customers_password/",
          "author": null,
          "description": "LastPass has issued an update about their security incident, in which apparently backups of customer vaults were accessed. I'm linking the techcrunch article as it summarizes what's new. You can read the security incident summary in its entirety here \n For those of you migrating from LastPass, note that their export tool is unreliable\n    submitted by    /u/DistractionRectangle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt4b0m/lastpass_says_hackers_stole_customers_password/",
          "publishedOn": "2022-12-23T02:39:03.000Z",
          "wordCount": 20225,
          "title": "LastPass says hackers stole customers' password vaults",
          "imageUrl": "https://external-preview.redd.it/XvgPeXQRCbjdZX0ubqq0KW7J1RjEyq_iOTYmhlHh3A8.jpg?auto=webp&s=e14c8afb5ffa7a6acd66d2c534b8e6d322eb3fd2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt2zke/minecraft_hosting/",
          "author": null,
          "description": "Hi, so I've look at the rates of minecraft server hosting providers and most are obscured but some are fair. Come to look at it, I could save a lot more by self hosting. So I've put together a list of specifications that would be amazing for my server! \n 128 GB of DDR4 RAM\n DUAL (2) CPU Slots\n 1 CPU with 3.5+ GHZ and 10+ Cores with multi threading\n NO GPU (its not needed, its just hosting)\n 200-400 GB of storage \n ​\n My budget is around 300-400, I've looked and found multiple parts just I can't find any that together. \n Thanks, Nicc\n    submitted by    /u/Nicholas_or_Nick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt2zke/minecraft_hosting/",
          "publishedOn": "2022-12-23T01:31:12.000Z",
          "wordCount": 17637,
          "title": "Minecraft Hosting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt2twd/traefik_vs_npm_vs_alternative_for_multiple/",
          "author": null,
          "description": "I'm currently hosting all my services on my Synology NAS. I've used the built in Synology reverse proxy (which uses nginx under the hood I believe) but was beginning the transition to traefik as I needed some more customizability as I was onboarding Authentik.\n I realized that one of the main advantages of Traefik is it's docker integration. Most of my services are running via docker on my NAS. I use portainer to manage my containers.\n I've got some additional machines on order which I'm intending to move several of my services to in order to lighten the load on my NAS and increase performance.\n With the use of multiple machines, Traefik docker integration may have less of an advantage. I still intend to user docker, just will be on multiple machines. Some x86 and some ARM. Should I continue with my Traefik migration or should I switch into setting up NPM or a different alternative instead?\n    submitted by    /u/speedhunter787  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt2twd/traefik_vs_npm_vs_alternative_for_multiple/",
          "publishedOn": "2022-12-23T01:23:18.000Z",
          "wordCount": 17721,
          "title": "Traefik vs NPM vs alternative for multiple machines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt26f3/pihole_dns_accessible_outside_of_network/",
          "author": null,
          "description": "Hello all, \n Just trying to educate myself and get experience with some projects and now that I have set up PiHole on my home network, I have configured a few of my devices to use the Pi’s IP for its DNS. If I were to take these said devices outside my home network, would they still be able to reach my Pi’s DNS? Or is that where I’d need to VPN in?\n Anything helps, thank you all\n    submitted by    /u/Dramatic-Ocelot-8024  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt26f3/pihole_dns_accessible_outside_of_network/",
          "publishedOn": "2022-12-23T00:51:06.000Z",
          "wordCount": 17616,
          "title": "PiHole DNS accessible outside of network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt1h49/apple_watchos_apps_with_offline_playback_for_self/",
          "author": null,
          "description": "As the title suggests, I'm looking for an Apple WatchOS app which supports offline playback for a self-hosted music streaming service. Unfortunately Plex (PlexAmp) has no interest in this despite many users requesting it.\n Other than Plex/PlexAmp, I currently have Navidrome as my streamer and substreamer client apps on Android/iOS devices. This works great for offline caching & online streaming. The only thing missing for me and family is offline playback on WatchOS for use without phone. (Think going for a run, working out in the gym etc).\n The only subsonic API compatible app that I have come across which has Apple WatchOS support for offline playback is AVSub - unfortunately the app is quite buggy and music playback on the Watch actually stops as soon as the watch screen turns off, so basically useless.\n Is there anything else out there or do I just need to pay the man and get a Tidal subscription?\n    submitted by    /u/Radiant_Armadillo489  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt1h49/apple_watchos_apps_with_offline_playback_for_self/",
          "publishedOn": "2022-12-23T00:17:05.000Z",
          "wordCount": 17012,
          "title": "Apple WatchOS apps with Offline Playback for Self Hosted music streaming.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zt19wi/how_to_access_private_services_behind_vpn/",
          "author": null,
          "description": "Hello,\n I run multiple services on a VPS, as well as a VPN.\n All of the services are exposed to the Internet and can be publically reached. Now, I would like to have certain services behind a VPN, so they are not exposed.\n How to do this?\n What do I have to do in my docker config, so that it works? And what link would I have to use to access it? Given that I am connected with my VPN, would I be able to use localhost:port?\n ​\n I am using for example the glances service. I used the following docker compose:\n version: '3' services: glances: image: nicolargo/glances:latest-full container_name: glances ports: - \"61208:61208\" - \"61209:61209\" volumes: - /var/run/docker.sock:/var/run/docker.sock:ro restart: always environment: - \"GLANCES_OPT=-w -u user\" pid: host \n For me it is clear that I should not expose any ports. But I also dont know what else to do :)\n So all help is welcome!\n    submitted by    /u/nkls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zt19wi/how_to_access_private_services_behind_vpn/",
          "publishedOn": "2022-12-23T00:07:53.000Z",
          "wordCount": 17792,
          "title": "How to access private services behind VPN?",
          "imageUrl": "https://external-preview.redd.it/Ee4t6QQ6KnWDzW2bBo7hPfjIdK9_PIV0ya97sSgVrYo.jpg?auto=webp&s=909021084bd9b9562679a27949ab6aa845520a22"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsxchw/docker_app_with_pdf_search_engine/",
          "author": null,
          "description": "So: I have accumulated lots of PDF Books, Spec sheets etc over the years. I want toto host a docker APP, wich enables me to look up a something, in multiple PDF files. A big plus would also be, text recognition for pdf files that have the \"text as photos\"(??hope you understand??) i know nextcloud has similar funkcionality, but i would perefer Docker APP´S specificly made for this.\n I hope i made you understand what i want... Thanks!\n ​\n Edit: Is Paperless-NGX a good idea for what i want?\n    submitted by    /u/TheRealFAG69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsxchw/docker_app_with_pdf_search_engine/",
          "publishedOn": "2022-12-22T21:27:20.000Z",
          "wordCount": 17328,
          "title": "Docker APP with PDF \"Search engine\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zswv8k/webmail_client_with_desktopmobile_apps/",
          "author": null,
          "description": "Hello, I am looking for a webmail client to selfhost, to which I can connect with a desktop and/or mobile app.\n The idea would be to centralize my email connections into the hosted webmail instance, and then stream the mails into my laptops and phones. Something like having a roundcube instance, with all my emails (that I can connect to on the browser), and then a desktop app (like thunderbird) that would get all that data.\n I tried cypht and roundcube, but I didn't find any way to.\n Any idea on a specific setup that could work?\n    submitted by    /u/redditubvco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zswv8k/webmail_client_with_desktopmobile_apps/",
          "publishedOn": "2022-12-22T21:06:54.000Z",
          "wordCount": 17239,
          "title": "Webmail client with desktop/mobile apps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zswi8f/homepage_kubernetes_support_a_christmas_gift/",
          "author": null,
          "description": "Having played around with a number of homepage/dashboard options, I finally came to settle on Ben Phelp's Homepage. It's fast, customisable and well implemented.\n The only problem I have with it is that it doesn't natively support Kubernetes Ingress discovery, and required me to duplicate all my ingress config in to homepage config.\n My solution? To build a sidecar process to scan my Kubernetes cluster and build a configuration file automatically.\n Current features:\n  \nIngress Discovery\n Hide/Show by default and override.\n Simple Config: \n Name\n Groups\n Descriptions\n Icons\n Ping/Healthcheck config\n \n Widget Config: \n Type\n `key` secret from kubernetes secret\n \n  \nYou can find it on GitHub here: https://github.com/uatec/homepagesc\n    submitted by    /u/uatec  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zswi8f/homepage_kubernetes_support_a_christmas_gift/",
          "publishedOn": "2022-12-22T20:51:50.000Z",
          "wordCount": 16878,
          "title": "Homepage Kubernetes Support - A Christmas Gift",
          "imageUrl": "https://external-preview.redd.it/9u6ims4xeHX3k5ec1aAYVnCtG6VyU_yuW4oDfSVdAYM.jpg?auto=webp&s=a44f7abe43d5c5f2324cce70b32988b096fdc99b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zswc7o/nextcloud_mail_sieve/",
          "author": null,
          "description": "Hello.\n Anybody is using with success the Sieve function in Nextcloud Mail (webmail) ?\n I can connect without errors but Sieve filter rules box is empty.\n Not sure how should it look since I did not use Sieve.\n Please advise.\n Thanks.\n    submitted by    /u/wideace99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zswc7o/nextcloud_mail_sieve/",
          "publishedOn": "2022-12-22T20:44:30.000Z",
          "wordCount": 17465,
          "title": "Nextcloud Mail Sieve",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsw9j6/nextcloud_on_nas_or_proxmox/",
          "author": null,
          "description": "I'm looking at setting up NextCloud on my home LAN, strictly for personal use (at this point). I have a Synology DS920 with a handful of Docker containers on, and I have Proxmox running on a 1L USFF PC that I can put a VM, container, etc. on as needed. Both are on the same gigabit LAN. \n The backend storage would probably end up being on the NAS either way, given the relative storage available between the two.\n Would I be better off setting up NC in Docker on the Synology, or in a VM or LXC container on the proxmox host, and why?\n Thanks!\n    submitted by    /u/memilanuk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsw9j6/nextcloud_on_nas_or_proxmox/",
          "publishedOn": "2022-12-22T20:41:10.000Z",
          "wordCount": 18412,
          "title": "NextCloud - on NAS or Proxmox?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsvn1h/cant_decide_between_ovh_or_hetzner_any_help/",
          "author": null,
          "description": "I run a few discord bots and some backend services such as user credentials and they require SQL server, this is not for work but rather for private usage and i also run a Pihole dns server aswell.\n ​\n I have per now:\n 3 vcore 4GB ram VPS from Hetzner and i love their hour billing and easy to scale and downscale and that you can simply delete and spin up and down servers using snapshots i really love it, however it get's more expensive in the long run and it's a VPS so the cpu will be a bottleneck in the long run.\n ​\n I also have a kimsufi\n CPU\n Intel Xeon E3-1245v2 - 4c/8t - 3.4 GHz/3.8 GHz\n RAM\n 32 GB 1333 MHz\n Data disks\n 2×800 GB SSD SATA\n ​\n However there is no RAID and a old cpu from 2012 and some slow disks that should have been replaced, i don't like that i have to monitor my disk …",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsvn1h/cant_decide_between_ovh_or_hetzner_any_help/",
          "publishedOn": "2022-12-22T20:14:14.000Z",
          "wordCount": 20490,
          "title": "Can't decide between OVH or Hetzner any help?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsvfl5/turning_my_old_pc_into_a_server_thoughts_and/",
          "author": null,
          "description": "Hi guys,\n Maybe I should start with that I'm almost a complete noob at this and I'm learning it on the go so I would be grateful if you can spare me your sarcastic comments and mockery. Thanks//\n So, I have some thoughts about turning my old PC into a server. What would I need for running it smoothly? It has a 1TB SSD, i5 3.2 processor, and 16 Gb RAM. I have 2 external HDDs so I can place my data there - music, movies, etc. I can run Docker for the servers. I'm thinking about one music server - maybe Airsonic-Advanced - to remotely access my library, one movies server - maybe Jellyfin, because I can install it on my android TV, and some proxy or VPN - maybe Tailscale, because it's easy for me to set it up.\n Right now, I've installed WSL and Docker on Windows 11 (my current PC) to run my servers, but my old PC is collecting dust and laying in the closet so I'm thinking about making it like a personal server and moving my containers there. The thing is that those VM are much RAM consuming (maybe like 40%) and I have 32 Gb. Right now I'm running Tailscale on PC so the connection with the server wouldn't be much of a problem - local and remote. I've worked all my life on Windows, but I'm eager to learn new things and I think that Linux is more appropriate for those types of stuff(or at least what I'm reading from people guides and comments).\n So my question is should I continue to work on Windows - install it on my old PC and run my Docker containers on WSL again or should I install Linux and try learning it on the go? Also, what about FreeNas or OpenMediaVault? Are those systems better for the things which I want to run and would be hard for me to configure them and access them from my PC?\n Please, tell me your thoughts about this, because I'm in a dilemma about which path I should go to. Thanks in advance!\n    submitted by    /u/No_Breakfast9359  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsvfl5/turning_my_old_pc_into_a_server_thoughts_and/",
          "publishedOn": "2022-12-22T20:05:17.000Z",
          "wordCount": 19441,
          "title": "Turning my old PC into a server - thoughts and opinions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsuy8v/open_source_webhooks_as_a_service/",
          "author": null,
          "description": "Ken from Svix here.\n We help our customers send webhooks by offering them a full webhook sending solution. We have a hosted version which is based on the Svix open source project.\n The open source project can be self-hosted (and many people do!), so I thought I'd share it here.\n I'd also love to take this opportunity to ask for feedback. What can we do to make it even easier to self-host Svix? You can check out the instructions on the README. I think things are fairly simple, but we would always like to improve.\n Here's the repo if you want to check it out: https://github.com/svix/svix-webhooks\n    submitted by    /u/SvixKen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsuy8v/open_source_webhooks_as_a_service/",
          "publishedOn": "2022-12-22T19:44:55.000Z",
          "wordCount": 17627,
          "title": "Open Source Webhooks as a Service",
          "imageUrl": "https://external-preview.redd.it/fGbRUOwzM00KeJ9qJN9CqW6kop-ZLQUSnKT0hJyx9o0.jpg?auto=webp&s=439cf3a6a66e1301f35620d36f2aa96b3b02408a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zstrjq/beginner_looking_for_more_to_self_host/",
          "author": null,
          "description": "Hi self-hosters,\n I've been silently following this subreddit for a really long time. First of all, thanks a ton to everyone out here. You guys have inspired me and motivated me to self-host.\n Cutting things short, my current set up looks like:\n An old Sony VAIO Laptop (i3 330m, 2+4GB RAM, 1TB 5400RPM HDD) as a Proxmox server with the following Ubuntu 22.04 LTS CT(s):\n  \nAdGuard Home : Primary DNS Resolver\n Radarr + Prowlarr + qBitTorrent + JellyFin : Media Server\n SnapDrop : Useful LAN File Share Utility\n ArchiveBox : Useful Web Archiving Utility\n  \nA Raspberry Pi 3B+ with Raspberry Pi OS Lite as a Backup AdGuard Home DNS Resolver (synced from Primary)\n These two together are currently serving my purposes really well, while not adding up electricity bills significantly.\n I used to host Vaultwarden and FreshRSS as well. For Vaultwarden, I do not benefit from the client-server synced up model as although I tried convincing my family, none of them uses a Password Manager. Provided it's just me and I don't really need my passwords on phone a lot, I prefer KeePassXC on my one and only Linux laptop. Same reason for FreshRSS. I used to use it with the self hosted instance of http://ftr.fivefilters.org to get Full Text RSS feeds but, I ended up feeling better with QuiteRSS. I read feeds on a single machine and full text feed isn't really a must-to-have. \n My family is really happy with Adblocking DNS, Archiving and LAN File Share utilities and mainly because of the Jellyfin media server. \n I'm really looking forward to add more useful tools/utilities. Please recommend some services that you self host yourself and are very useful/utilitarian in nature for you and your family. \n (No dashboard. No Reverse Proxy like Caddy. Already considered but I'm fine without them. I've also considered the Awesome Self-Host and Sysadmin Github repositories.)\n Thanks in advance. Peace!\n    submitted by    /u/itsmypc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zstrjq/beginner_looking_for_more_to_self_host/",
          "publishedOn": "2022-12-22T18:54:36.000Z",
          "wordCount": 18876,
          "title": "Beginner looking for more to Self Host.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zssh2o/movary_self_hosted_web_app_to_track_and_rate_your/",
          "author": null,
          "description": "Hey community!\n For years I was only a user of open source projects, now I want to give a little bit back.\n I have created movary, a self-hosted web application to track and rate watched movies, similar to services like trakt.tv or letterboxd.com. After years of tracking my watch history with commercial services I was getting afraid what would happen if one of these services would stop providing their website or if they \"lose\" their databases. What about my watch history and ratings? I wanted access to this data in an easy and reliable way, so I started working on this project. It stores all used (meta)data locally, provides third party api integrations with e.g. plex and a few things more (check the README of the project).\n I think I want to release the first stable version soon and would be happy over any feedback.\n    submitted by    /u/sysLee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zssh2o/movary_self_hosted_web_app_to_track_and_rate_your/",
          "publishedOn": "2022-12-22T18:00:41.000Z",
          "wordCount": 18155,
          "title": "Movary - Self hosted web app to track and rate your watched movies",
          "imageUrl": "https://external-preview.redd.it/ELLlB2owlf60O4F3GhOmzLoeB11JlkjPBckZBELvKmE.jpg?auto=webp&s=1afa79a78be61de84224e49d08cc6c061bfb4deb"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zss61q/introducing_nmctl/",
          "author": null,
          "description": "submitted by    /u/mesh_enthusiast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zss61q/introducing_nmctl/",
          "publishedOn": "2022-12-22T17:48:46.000Z",
          "wordCount": 17576,
          "title": "Introducing NMCTL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsqx9y/unifiedpush_a_decentralized_opensource_push/",
          "author": null,
          "description": "submitted by    /u/Routing8493  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsqx9y/unifiedpush_a_decentralized_opensource_push/",
          "publishedOn": "2022-12-22T16:59:34.000Z",
          "wordCount": 19272,
          "title": "UnifiedPush: a decentralized, open-source push notification protocol",
          "imageUrl": "https://external-preview.redd.it/buEgLaGtEpA7L6P4KxL_DpMC0HyFvA0df4c0TaIe3nc.jpg?auto=webp&s=e6e1be3f7a5c79287971bbb0e6850ced50442fff"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsqg2w/different_docker_instances_of_browser_per_user/",
          "author": null,
          "description": "Hi.\n I have synology nas server, firefox browser in docker and openvpn-client in docker as well. Firefox works via openvpn-client.\n But now i need different instances of firefox per user; the openvpn-client container better to be the global single instance for all firefoxes, but it doesn't have to be. Also i can switch to another browser if necessary, this is not a problem.\n So, when the user connects, a new browser container should be created and then deleted when the user's session is over.\n What is the best way to do it?\n    submitted by    /u/EvgeniyDoctor317  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsqg2w/different_docker_instances_of_browser_per_user/",
          "publishedOn": "2022-12-22T16:39:37.000Z",
          "wordCount": 17564,
          "title": "Different docker instances of browser per user",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zspzfx/kasm_rdp_need_some_help/",
          "author": null,
          "description": "After reading the post from yesterday about Kasm Workspaces, I've decided to try it.\n I have issues with RDP connections, none of them is working.\n Tried three different Windows machines (Win 10 variants), one local on the same VM host, one connected via LTE, 20-30 ms away (wireguard), and the third about 180 ms away (L2TP) from the KASM server.\n All of them are sitting on the loading screen, \"Creating a secure connection...\"\n At the same time if I fire up the Remmina workspace I can connect to all three without issues.\n Any hint what I'm doing wrong?\n Edit: I am running Kasm behind Nginx Proxy Manager, the Zone settings a set according to the manual.\n Edit 2: Made a short test. Connected with Remmina to the local Windows VM, then started the Workspace linked to the same machine.\n The expected result is to kick away Remmina client and accept the new one. After starting the Kasm client Remmina is still connected and stays like that.\n    submitted by    /u/ztardik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zspzfx/kasm_rdp_need_some_help/",
          "publishedOn": "2022-12-22T16:20:53.000Z",
          "wordCount": 17301,
          "title": "KASM RDP - need some help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zso6bu/a_simple_ansible_playbook_to_setup_a_self_hosted/",
          "author": null,
          "description": "submitted by    /u/GHOST__ROX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zso6bu/a_simple_ansible_playbook_to_setup_a_self_hosted/",
          "publishedOn": "2022-12-22T15:05:46.000Z",
          "wordCount": 17418,
          "title": "A simple Ansible playbook to setup a self hosted wireguard server with a web GUI to add and remove clients.",
          "imageUrl": "https://external-preview.redd.it/m2Zw83T9od5ED7MKQlgbUZ7X_1Qr4b1Olrb9TedORIg.jpg?auto=webp&s=8bc290b0c1f76e4a5584d5cecdfb8178e95a9fe5"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsnh1p/phone_system_for_small_business/",
          "author": null,
          "description": "Hi Selfhosted,\n I do not know much about VOIP/PBX systems so I aplogize if I have some information incorrect in my request. I will try to keep it in plain english.\n I am looking to have a self hosted solution that will allow me to make and receive phone call using my cell phone. I want to have a separate phone number from my personal cell number. I don't mind if the call is forwarded to my personal cell. I just do not want to give out my personal phone number. \n ​\n Are there any self hosted PBX systems available that would provide me with a phone number as well as have ability to push the calls to my cell phone or ability to take calls from my cell phone?\n    submitted by    /u/Quick_Parsley_6482  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsnh1p/phone_system_for_small_business/",
          "publishedOn": "2022-12-22T14:34:16.000Z",
          "wordCount": 19264,
          "title": "Phone system for Small Business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsmbxt/forwarding_docker_container_ports_to_subfolders/",
          "author": null,
          "description": "I am trying to get all my services as docker containers to be accessible through subfolders of the same domain.\n E.g., I have a text matching service running at the port 8080 and picoshare at 4001. I want to access these like this -> mydomain.com/text-matching and mydomain.com/picoshare. \n I can sort of do this with just nginx (without nginx proxy manager) using the conf file which looks similar to this ->\n ​\n upstream picoshare { server picoshare:4001; } server { server_name mydomain.com; listen 443 ssl; ssl_certificate ./fullchain.pem; ssl_certificate_key ./privkey.pem; ssl_dhparam ./dhparam.pem; include ./options-ssl-nginx.conf; location /text-matcher { include uwsgi_params; uwsgi_pass text_matcher:8080; } location /picoshare { proxy_pass https://picoshare; } } \n However I want to use nginx proxy manager to achieve this. I also need to redirect all HTTP calls to HTTPS.\n    submitted by    /u/nerzid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsmbxt/forwarding_docker_container_ports_to_subfolders/",
          "publishedOn": "2022-12-22T13:41:04.000Z",
          "wordCount": 18635,
          "title": "Forwarding docker container ports to subfolders under the same domain with nginx proxy manager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zshygu/web_browser_testing_tool/",
          "author": null,
          "description": "Hey, I'm looking for a secure way to host different web browsers through a portal such as Windows Remote Desktop Services or other similar alternatives. I know Remote Desktop Services wouldn't be the best way to achieve this, so I'm hoping there exists a solution specifically made for this purpose.\n I'm looking to set up something similar to Browserling.com but running locally in my network. I want a secure way to open links that may be malicious without fears of infecting my system, or just a way to test different web services with a clean browser each time.\n Are there any self hosted alternatives out there that i can set up on my VMware esxi machine? What setup would be the most secure for this?\n Any leads would be much appreciated :)\n    submitted by    /u/Benjameenn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zshygu/web_browser_testing_tool/",
          "publishedOn": "2022-12-22T09:33:12.000Z",
          "wordCount": 17135,
          "title": "Web Browser testing tool",
          "imageUrl": "https://external-preview.redd.it/hm6mn33X7woJjE5kbq9d2vK_t7H1MIILoHDErDfa2vM.jpg?auto=webp&s=01c584068e056ac294cd774a2a8b5962a85a07c7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zsf2zf/is_there_any_self_hosted_apps_available_for/",
          "author": null,
          "description": "I would like to get all the update for all people i follow? Like rss reader.\n Is any software available for that?\n    submitted by    /u/robertniro1980  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zsf2zf/is_there_any_self_hosted_apps_available_for/",
          "publishedOn": "2022-12-22T06:52:29.000Z",
          "wordCount": 16689,
          "title": "Is there any self hosted apps available for twitter like rss reader?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs7846/website_and_network_device_ping_status/",
          "author": null,
          "description": "Looking for something to replace Uptime robot now they have changed their pricing. Preferably a windows based tool that I can run on one of my internal servers that can then send an email when something goes down. Dont mind paying for a tool and have been baying $84 a year\n    submitted by    /u/Bear_Hardy_DD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs7846/website_and_network_device_ping_status/",
          "publishedOn": "2022-12-22T00:51:24.000Z",
          "wordCount": 18441,
          "title": "Website and network device ping status recommendation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs6109/is_it_ok_if_my_custom_domain_used_for_applying/",
          "author": null,
          "description": "For example, if I'm applying a role at Reddit my email will be [\"reddit@bobsmith.com](mailto:\"reddit@bobsmith.com)\".\n I personally love it, it looks cool, clean, neat and helps me track which company is spamming me. And if I don't want anymore communication from certain company I could just turn that alias off in Simple Login.\n It's the setup for my other general purpose domain which doesn't contain my name, don't know how companies considering my job application will like it.\n If this is a bad idea, how about [\"contact25@firstlast.com](mailto:\"contact1@firstlast.com)\"? So instead of company name, I'm assigning a unique number to each company.\n    submitted by    /u/JustARandomPerson135  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs6109/is_it_ok_if_my_custom_domain_used_for_applying/",
          "publishedOn": "2022-12-22T00:02:57.000Z",
          "wordCount": 19070,
          "title": "Is it ok if my custom domain used for applying for jobs looks like \"companyname@firstlast.tld\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs5qv0/engineering_a_thumbprint_in_a_digital_certificate/",
          "author": null,
          "description": "Hello everyone,\n I have seen several VoIP apps use self signed certificate thumbprints as a form of verification during key exchange. \n Two certificates cannot have the same thumbprint. However, can a certificate be engineered/coded to have the same thumbprint as the original certificate? \n If this is not, how is it not possible? \n Additionally, what is a digital signature? \n Thank you.\n    submitted by    /u/Striker0073  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs5qv0/engineering_a_thumbprint_in_a_digital_certificate/",
          "publishedOn": "2022-12-21T23:51:54.000Z",
          "wordCount": 18167,
          "title": "Engineering a thumbprint in a digital certificate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs5aac/xxxx999tld_or_xxxx24365tld_for_my_custom_domain/",
          "author": null,
          "description": "The domain that I wanted (for email only) was taken so I'm adding numbers to the end of it, like \"@xxxx999.tld\" or \"@xxxx24365.tld\". 999 is short and consists of 3 repeating numbers but could be mixed up with other numbers?? 24365 is unique because it stands for 24 hours 365 days but it's kinda long and looks bit random at first sight.\n Better ones like 123, 101, 24, 365 etc were taken so these two are the best I can come up with. Also available are 000, 222, 444, 555, 888.\n If I were to give my email to you, which one do you think looks better and is easier for you to rememer? Like it sticks and less likely to be confused with something else etc. Just like I'm not going for 3650 because people might forget the 0 at the end.\n    submitted by    /u/JustARandomPerson135  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs5aac/xxxx999tld_or_xxxx24365tld_for_my_custom_domain/",
          "publishedOn": "2022-12-21T23:34:10.000Z",
          "wordCount": 18322,
          "title": "@xxxx999.tld or @xxxx24365.tld for my custom domain?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs54wr/do_you_need_vlans_if_you_use_vpn/",
          "author": null,
          "description": "I am new to homelabbing, and I am trying to figure out networking and security. I found out that it is better to have separate subnets or vlans for your home devices and your homelab, in case the latter gets compromised. I am hosting services only for myself, so I do not really need public access to anything, but I would like to have remote access to my self-hosted services.\n I saw different solutions, like cloudflare tunnelling, port forewarding, and more, but they all \"require\" you to have the homelab at least on a different vlan to be truly \"secure\". Anyway, it is not clear for me how then the home devices will have access to the services. Do they connect to the server as if they would remotely? In any case, this is not truly important because the route I would like to follow is differe…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs54wr/do_you_need_vlans_if_you_use_vpn/",
          "publishedOn": "2022-12-21T23:28:42.000Z",
          "wordCount": 18848,
          "title": "Do you need vlans if you use vpn?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs4sq1/photo_hosting_photoprisim_alternative/",
          "author": null,
          "description": "Hey I have Photo Library with over 10k+ photos (.cr2 +Jpg). i am searching for a PhotoPrisim alternative because i does not support Multiuser login. i need \n  \nRaw suppport\n Multi user login\n Use existing library\n Share photos with Other users (without scanning the library for every user)\n Users can change their own password or some kind of signup solution inbuilt.\n  \n   submitted by    /u/Snoo_66088  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs4sq1/photo_hosting_photoprisim_alternative/",
          "publishedOn": "2022-12-21T23:15:51.000Z",
          "wordCount": 17732,
          "title": "Photo Hosting (photoprisim alternative)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs4d27/tool_to_help_me_organizing_tools_and_supplies/",
          "author": null,
          "description": "Well as having a workshop full of tools and spare parts is useful, but only useful when you actually know where the tools are, nothing worse then\n I am investing full on the millwakee packout system, and taking the time to invetory everything. I am wondering if there is a self hosted tool for this, or is a libreoffice calc spreadsheet is my best choice.\n Something web based, which good cache or offline support, and a decent mobile interface (either app, or a web that mobile friendly) would be me.\n    submitted by    /u/masterkorp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs4d27/tool_to_help_me_organizing_tools_and_supplies/",
          "publishedOn": "2022-12-21T22:59:33.000Z",
          "wordCount": 18068,
          "title": "Tool to help me organizing tools and supplies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs3qym/connecting_radarr_and_sonarr_to_my_own_seedbox/",
          "author": null,
          "description": "Hi there!\n My apologies if this seems like a lot of text. I'm trying to provide as much detail as possible! Also, I consider myself a noob, I'm just good at following the docs :)\n I have an unraid server, in location A, running all the -arrs in docker. On location B, there's a raspberry pi running transmission.\n Since both of these locations are behind a CGNAT, I'm trying to use Tailscale to connect them. However, when I try to add transmission to the -arrs using its Tailscale IP, I get this error: \"Unable to connect to transmission (Sonarr)\" or \"Unknown exception: A task was canceled. (Radarr)\"\n ​\n My setup:\n Unraid server running each -arr in a separate container, on the brigde network mode, and one container running Tailscale on the host network. I can successfully access the web dashbo…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs3qym/connecting_radarr_and_sonarr_to_my_own_seedbox/",
          "publishedOn": "2022-12-21T22:37:04.000Z",
          "wordCount": 19502,
          "title": "Connecting Radarr and Sonarr to my own seedbox through Tailscale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zs258n/question_about_how_to_get_media_on_plexjellyfish/",
          "author": null,
          "description": "I’m extremely new to all this but I was wondering how people add media like movies or tv shows onto Plex or Jellyfish. I’m still deciding between the two but I’m having trouble understanding how people download the movies and shows. Do people buy the movies/shows from somewhere? Do they pirate it? Where do people download their media from? I’ve seen YouTube videos where someone said some people turn their CDs to digital versions (onto Plex, Jellyfish, etc). But I’m not interested in owning the physical and digital copy. I do have services like Disney+, Hulu, etc. Do people somehow download the movies on there onto Plex/Jellyfish? I apologize if this sounds really dumb.\n    submitted by    /u/Typical-Ad-491  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zs258n/question_about_how_to_get_media_on_plexjellyfish/",
          "publishedOn": "2022-12-21T21:52:32.000Z",
          "wordCount": 18723,
          "title": "Question about how to get media on Plex/Jellyfish",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrzchc/npm_authentik_qbittorrent/",
          "author": null,
          "description": "I have a domain with 3 subdomains; each pointing to an app.\n Current setup: - npm.domain.com - auth.domain.com - qbittorrent.domain.com\n I managed to deploy qBittorrent behind Authentik, but what I'd like to enhance this by preventing second login page of qBittorrent.\n My current flow is: qbittorrent.domain.com -> auth.domain.com -> qbittorrent.domain.com (with second login page)\n I have a user in authentik with the same username/password for qBittorrent. So is it possible to forward the username/password given to authentik to qBittorrent.\n Thanks in advance!\n    submitted by    /u/Wils93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrzchc/npm_authentik_qbittorrent/",
          "publishedOn": "2022-12-21T20:08:44.000Z",
          "wordCount": 18466,
          "title": "NPM + Authentik + qBittorrent",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zry99b/is_it_possible_to_connect_to_a_home_server/",
          "author": null,
          "description": "I would like to have a Raspberry Pi server with a VPN so I can access it outside of my network. \n The VPN will have to be on the raspberry pi along with the server because I’m unable to instal it on a router. It’s a shared router, and other users watch Netflix, which won’t work with the VPN.\n I only want to use the VPN on client devices when outside of my network. When I connect back to my network, will I still be able to access the server without connecting to the VPN?\n    submitted by    /u/ALCF98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zry99b/is_it_possible_to_connect_to_a_home_server/",
          "publishedOn": "2022-12-21T19:28:07.000Z",
          "wordCount": 19694,
          "title": "Is it possible to connect to a home server without a VPN when at home but use one only when outside of the network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zruxhk/looking_for_a_selfhosted_management_and_patching/",
          "author": null,
          "description": "Hello, \n I am looking for a self-hosted low-cost or free solution to potentially replace Pulseway for me. I would like to find something that is along the lines of Pulseway I have tested tacticalrmm but the Linux agents are not free. I have also tried MeshCentral & Rport but they do not offer app installation or system monitoring. \n Here are things that I would like to do :\n Windows & Linux agents .. mac optional not really needed. \n Remote desktop access\n Remote file storage access\n Software management\n System recourse logging ( CPU, memory, storage, network )\n Powershell, CMD, Linux terminal to run scripts\n Patch management\n Notifications for events - high CPU / ram usage / offline device. \n I do not mind running 2 solutions so long as they can be run and remote systems can communicate without the need for VPN.\n    submitted by    /u/sesipod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zruxhk/looking_for_a_selfhosted_management_and_patching/",
          "publishedOn": "2022-12-21T17:26:14.000Z",
          "wordCount": 18942,
          "title": "Looking for a self-hosted management and patching software.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zru2ps/threshold_skill_levels_to_set_up_home_security/",
          "author": null,
          "description": "Hello, apologies in advance for formatting and also capitalization, doing this on mobile.\n I am new to this community and the concept of self hosting. I’m trying to decide if it is better to hire a local company to setup or if this is something I can or should learn to handle myself. \n I would rate my own skills between low and medium. i’ve built a couple gaming computers, i like to run mods on most games. i have a vpn on my phone, but honestly couldn’t tell you the technical side of what it does. i know i should have it on my router but i don’t. pretty basic stuff. I know very little about network architecture if that’s even the right term. Im reading through a couple DIY guides that seem to makes sense conceptually, but i am rapidly becoming overwhelmed with the technical jargon.\n The end goal is an outdoor surveillance that i can view from my phone and will give me notifications when movement is detected. i’ve been using nest but have not been impressed. Essentially that’s all the functionality i need, but might want some room to grow into automation.\n So my question is, is this worth it to push through this barrier to entry and learn or is this something best left to trusted professional? \n what does something like this even cost in terms of hardware?\n are there any recommendations for a place to start? videos? Hell, i’ll even take book recommendations. \n thanks for reading\n    submitted by    /u/Whiskey_Elemental  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zru2ps/threshold_skill_levels_to_set_up_home_security/",
          "publishedOn": "2022-12-21T16:57:26.000Z",
          "wordCount": 19073,
          "title": "threshold skill levels to set up home security system and associated questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrqxuz/what_next/",
          "author": null,
          "description": "I bought a ThinkCentre to use as a server a while back, but I'm not sure I'm ready yet. I feel like I have a decent grasp on Linux, I can vaguely understand how the internet works, I can follow installation guides for self-hosted stuff and look things up when I get stuck. But I still feel like a beginner, y'know? I don't know enough to start leaving holes in my firewall with 100% confidence that I won't get DDOSed or hacked or doxxed, so I don't. Everything I've made so far has either stayed in my private network or only been left open for a few hours at most. \n Ideally I'd like to run a simple blog website, a VPN, maybe a Minecraft server, and maaaaybe a private Mastodon instance if I can handle it. I know all of this would have to be publicly exposed, so how do I go about publicly exposing servers safely? If this is still too advanced for the level I'm at (which I imagine it is), what's the best learning path for me to get there? Books, websites, tutorials, etc?\n Thanks for your help!\n    submitted by    /u/camel-cultist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrqxuz/what_next/",
          "publishedOn": "2022-12-21T15:35:25.000Z",
          "wordCount": 19453,
          "title": "What next?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrqaeq/looking_for_a_client_server_dms_for_home_use/",
          "author": null,
          "description": "Hey everyone,\n I'm a total newbee when it comes to DMS and I am looking for a little open source DMS that I can host in my home network with proxmox.\n The idea is to use the new scanner I just got that allows my to scan to 5 different network folders that I can predefine.\n What I want\n  \npdfs should automatically be saved/converted to OCRed pdfs\n pdfs should be renamed yyyy_mm_dd (file created date)_FoldernameSomeNumber\n Client-Server DMS that let's me search for text fragments, ideally automatically reads the date from letters and puts in in a field, maybe the same for the title and idealy I can pre-configure some attributed that reoccruing letters have in order to apply certain tags, maybe even rename the documents etc.\n  \nIs that doable? Is it a reasonable approach?\n    submitted by    /u/HerrLux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrqaeq/looking_for_a_client_server_dms_for_home_use/",
          "publishedOn": "2022-12-21T15:20:41.000Z",
          "wordCount": 18608,
          "title": "Looking for a client server DMS for home use",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrogt8/folks_as_an_indie_i_have_to_pay_multiple/",
          "author": null,
          "description": "submitted by    /u/Abishek_Muthian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrogt8/folks_as_an_indie_i_have_to_pay_multiple/",
          "publishedOn": "2022-12-21T14:37:44.000Z",
          "wordCount": 17699,
          "title": "Folks, As an indie I have to pay multiple commissions for selling digital items on payments hosts like Gumroad. So I have built a self-hosted, Minimalist, FOSS(MIT), Dockerized payments host. Introducing Open Payment Host! Feedback and feature suggestions are much appreciated",
          "imageUrl": "https://external-preview.redd.it/RnN-OFnDKGDDQw2j9kKJUUfIbkubiRvR0FmqtW6jWnk.png?format=pjpg&auto=webp&s=b3f83d4fe479cbf158fd22afe116db4dee1dfb8a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrmt1t/serpbear_v02_adds_google_search_console/",
          "author": null,
          "description": "submitted by    /u/towfiqi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrmt1t/serpbear_v02_adds_google_search_console/",
          "publishedOn": "2022-12-21T13:49:20.000Z",
          "wordCount": 18536,
          "title": "SerpBear v0.2 , Adds Google Search Console Integration",
          "imageUrl": "https://external-preview.redd.it/CAkPucYOJ7xJlRyzCitYG6QuSMCiISwRB7PpjLcf08Q.png?format=pjpg&auto=webp&s=b6114440d13cc55e3cc1184a9d9764c54d54aac4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrl9xg/good_cron_gui/",
          "author": null,
          "description": "Are there any good cron WEB UI? Or some dedicated script runner?\n I want to run scripts/cli utilities and preserve their output and examine each separate run in some sort of web page\n    submitted by    /u/dmzkrsk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrl9xg/good_cron_gui/",
          "publishedOn": "2022-12-21T13:09:06.000Z",
          "wordCount": 18892,
          "title": "Good Cron GUI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrkokx/immich_and_ldap/",
          "author": null,
          "description": "I am planning to switch to Immich because it seems to be the simplest photo manager to use for my family. I am currently using Photoprism and none of my family wants to use it. Also, Immich supports multi-user which is what I after. I use FreeIPA to centralize my users (family and friends). I deploy Immich and don't see an option to do LDAP. The docs says to use OAuth. \n  \nDoes OAuth involved 3rd party service? \n Has anyone got LDAP working with Immich?\n  \nI really don't want to use the local account due to too many usernames/passwords to maintain and update.\n    submitted by    /u/forwardslashroot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrkokx/immich_and_ldap/",
          "publishedOn": "2022-12-21T12:53:35.000Z",
          "wordCount": 18724,
          "title": "Immich and LDAP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrh8bh/switching_to_promox/",
          "author": null,
          "description": "Good day\n I have a Linux machine as my server, it's currently running with a few Docker images and Linux services. And 1 VM(home assistant)\n My question is, how easy would it be to migrate to promox with my services and docker images as they are\n    submitted by    /u/Lanten101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrh8bh/switching_to_promox/",
          "publishedOn": "2022-12-21T11:09:20.000Z",
          "wordCount": 21430,
          "title": "switching to promox",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrftql/selfhosted_desktop_and_gui_application_containers/",
          "author": null,
          "description": "submitted by    /u/justin_kasmweb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrftql/selfhosted_desktop_and_gui_application_containers/",
          "publishedOn": "2022-12-21T09:45:08.000Z",
          "wordCount": 23883,
          "title": "Self-Hosted Desktop and GUI Application Containers Launched Instantly and Delivered to Your Browser with Kasm Workspaces - New Release 1.12: Windows RDP Workspaces / Gamepad Passthrough / Steaming Improvements / Updated UI",
          "imageUrl": "https://external-preview.redd.it/_7UCl5SpxbrISZOy0EsWOXCHh5kZ0CHm0RaJLpLi8D0.png?format=pjpg&auto=webp&s=a00966d40078388de5eaff3068545f16601ecd49"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zrfpc8/how_do_you_remember_all_your_local_ips/",
          "author": null,
          "description": "Between all my ipcameras, switches, computers? How to you guys keep up with your ips Spreadsheet?\n    submitted by    /u/Anooj2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zrfpc8/how_do_you_remember_all_your_local_ips/",
          "publishedOn": "2022-12-21T09:37:15.000Z",
          "wordCount": 19134,
          "title": "How do you remember all your local ips?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zr5xkc/looking_for_a_recomendation/",
          "author": null,
          "description": "Is there any way to sync my firefox profile on a self hosted server?\n    submitted by    /u/SaggingLeftNut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zr5xkc/looking_for_a_recomendation/",
          "publishedOn": "2022-12-21T01:07:11.000Z",
          "wordCount": 18662,
          "title": "Looking for a recomendation.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zr1qtw/a_twitterlike_app_for_ios_that_uses_s3compatible/",
          "author": null,
          "description": "submitted by    /u/lowonkarmaz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zr1qtw/a_twitterlike_app_for_ios_that_uses_s3compatible/",
          "publishedOn": "2022-12-20T22:27:30.000Z",
          "wordCount": 17791,
          "title": "A Twitter-like app for iOS that uses S3-compatible services (Minio support soon) as the backend",
          "imageUrl": "https://external-preview.redd.it/3FMbRj3VCqZiJU4LL1kK8mcCKoet72rC0HLjte7-Mts.jpg?auto=webp&s=3087e165a5eca657a1d885485905f655a397ac8d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zr13zi/cant_access_my_server_using_reverse_proxy_and/",
          "author": null,
          "description": "So, let me paint you a picture. :) So, I have an OpenMediaVault 6 server in the house, with some services like radarr, sonarr and so on, all in docker, with swag+duckdns for the reverse proxy setup, and that worked great, until a few days ago. In a thunderstorm, my modem and router died. I have my own modem, I don't use my ISP's modem. But now I have to, until I buy something new. So, now, with this modem I can't access my services outside the house. Not even from the house, I get this error when I test it from my PC:\n The connection has timed out\n The ports are forwarded. The weird thing is, my friend has the same setup, exept he has his own router, but he uses the same ISP modem, we are on the same ISP. I set up his OMV, everything, opened ports, all of it. And it works fine with him.\n I thought maybe the issue is because I'm using only the modem, without a router, because that's the only difference, but I had the same issue whenever I tried to swap modems, while I still had the router, during some testings and stuff.\n I've just checked the settings in his modem via AnyDesk, and they are literally the same. I can access his services from my house without issues.\n The modem is ZTE ZXHN H168N V3.1 .\n I don't know what else to post here, if you ask me I can post some screenshots or settings.\n Any ideas guys?\n    submitted by    /u/Nabukodonosor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zr13zi/cant_access_my_server_using_reverse_proxy_and/",
          "publishedOn": "2022-12-20T22:02:23.000Z",
          "wordCount": 18568,
          "title": "Can't access my server using reverse proxy and ISP's modem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zr0g8l/what_are_all_these_random_tunnel_names_that/",
          "author": null,
          "description": "submitted by    /u/CrispyBegs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zr0g8l/what_are_all_these_random_tunnel_names_that/",
          "publishedOn": "2022-12-20T21:36:21.000Z",
          "wordCount": 18630,
          "title": "What are all these random tunnel names that cloudflared keeps creating??",
          "imageUrl": "https://preview.redd.it/jez7g63kg47a1.png?auto=webp&s=584d36a18f0b36cb4fc35cb1d8a18db1c17d6d6a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqzu3v/gcloud_cloudvpn_vs_openvpn_ac/",
          "author": null,
          "description": "hello for thousands of users i will set up vpn server for vpc network on a google cloud. Do you think I should use cloudvpn or openvpn, what are the differences?\n    submitted by    /u/Eastern-Narwhal3169  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqzu3v/gcloud_cloudvpn_vs_openvpn_ac/",
          "publishedOn": "2022-12-20T21:12:22.000Z",
          "wordCount": 19258,
          "title": "gcloud cloudvpn vs openvpn ac",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqzr3i/monica_crm_install_help_it_is_working_but_not/",
          "author": null,
          "description": "I believe all my settings are correct. When I access monica from the localhost, everything works fine. When I put it behind a proxy (swag with its preconfigured conf) it strips out all the styling and says things about some content not being secure, and basically doesn't work. Any advice? Thanks.\n    submitted by    /u/superRedditer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqzr3i/monica_crm_install_help_it_is_working_but_not/",
          "publishedOn": "2022-12-20T21:09:11.000Z",
          "wordCount": 17907,
          "title": "monica CRM install help. It is working, but not behind proxy. Settings implemented following the instructions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqyire/seafile_plex_pihole_on_an_old_laptop/",
          "author": null,
          "description": "I am looking to set up a server with the following requirements-\n  \nBackup and serve my files (documents, photos and videos) across various computers and iPhone \n Serve my local movie library to my living room tv using Kodi on android tv and iOS device \n Auto backup photos from my iOS device camera roll\n View all my old photos on my iOS device in a nice gallery, by efficiently downloading just what I’m viewing and deleting after to maintain low storage usage on my phone \n Block ads on my home network \n Maybe also run a vpn to get adblocking on my iPhone when I’m on the mobile network through the pihole?\n  \nWhat’s the best way to achieve this? Based on my current research it seems like seafile + plex + pihole should do the trick. But is there a better way?\n Will running all this on an old laptop work well?\n Is there any benefit to running pihole on a standalone pi zero instead of on the laptop with all this other stuff?\n Thanks for your help!\n    submitted by    /u/Deep-Thought6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqyire/seafile_plex_pihole_on_an_old_laptop/",
          "publishedOn": "2022-12-20T20:19:48.000Z",
          "wordCount": 19514,
          "title": "Seafile + Plex + PiHole on an old laptop?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqyg79/i_created_a_library_of_fullcolor_svg_icons_of/",
          "author": null,
          "description": "TL;DR:\n 300+ full-color SVG icons of homelab-related software, products, and brands for use in dashboards, network diagrams, etc...\n https://github.com/loganmarchione/homelab-svg-assets\n See a preview of all icons here\n  \nIn my dashboards and network diagrams, I was using the already existing SVG icon sets (Simple Icons, Bootstrap Icons, Font Awesome, etc...), as well as random PNG/JPG files I found online. However, I always wanted consistently-sized full-color SVGs (instead of black/monotone or random PNG/JPG files).\n I gathered 300+ SVGs so far, and wanted to share them here.\n https://github.com/loganmarchione/homelab-svg-assets.\n I don't intend to replace any existing icon sets. Instead, I'm focused on homelab-related software, products, and brands ONLY.\n I have the following features so far:\n  \nConsistent viewbox (48x48)\n Optimized with SVGO\n Diagrams.net library (this is the reason I created this project)\n CDN (via jsDelivr)\n PHP (via Packagist)\n Node (via NPM)\n Hugo (via module)\n  \nThings I'm working on:\n  \nAdding more icons\n Gathering brand usage guidelines\n Gathering registered trademark (®) or trademark (™) symbols to be added\n Creating more automation for deployments\n  \nI created this for myself, but figured it might be useful here!\n    submitted by    /u/lmm7425  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqyg79/i_created_a_library_of_fullcolor_svg_icons_of/",
          "publishedOn": "2022-12-20T20:16:54.000Z",
          "wordCount": 17840,
          "title": "I created a library of full-color SVG icons of homelab-related software, products, and brands that I'm using in my network diagrams. It was going to be a personal project, but I thought I'd share it here.",
          "imageUrl": "https://external-preview.redd.it/Od6c8m8c_j8U4QXiuxTc9RQ89Dg-YjJ11M9dES3lZeM.jpg?auto=webp&s=05cbf4b3b987a4f32e59bc2bad7f25b5bebbdfd3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqy8q2/appsmith_selfhosted_solution_for_building/",
          "author": null,
          "description": "Hello there,\n I'm Vihar from Appsmith, and I'm here to share a major update on Appsmith's release (1.8.11).\n Introducing Auto-height for Appsmith widgets—A top requested feature, Auto-height now flexes your Appsmith apps to dynamic changes in content, conditional visibility, and end-user screens.\n With this update,\n 1️⃣ Text widgets now fold around the content inside. Smooth!\n  \n👌 unstructured content from databases like Snowflake, Redshift, and Firebase.\n 😍 for social media dashboards, consumer survey analyses, and store reviews.\n  \nAuto-height for text\n 2️⃣ Triggering the 𝚒𝚜𝚅𝚒𝚜𝚒𝚋𝚕𝚎 widget prop conditionally? Let’s take your white-space worries away.\n  \nfor apps with sidebars, as shown in our example ↓.\n  \nAuto-height for conditionally visible blocks\n 3️⃣ Auto-height-enabled widgets also change their size to change screen sizes.\n  \nfor stock inventory updates, on-site checks, and forms for field teams.\n  \nAuto-height for the mobile-layouts\n 4️⃣ What you see when building apps is what you get when viewing it, say, with Containers and the Canvas.\n Auto-height for the canvas\n What's next?\n  \n𝚖𝚒𝚗-𝚖𝚊𝚡 heights in widget props\n  \nOn by default for all widgets with 𝙻𝚊𝚋𝚎𝚕 props\n Computing auto-height when dragging a widget for better performance\n \n  \nTrack it all and comment ↓\n https://github.com/appsmithorg/appsmith/pull/18341\n P.S.: Appsmith can be run on Docker and K8s. The entire code is open-sourced under Apache-2.0 license. For more details, visit our GitHub.\n    submitted by    /u/vihar_kurama3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqy8q2/appsmith_selfhosted_solution_for_building/",
          "publishedOn": "2022-12-20T20:08:32.000Z",
          "wordCount": 19962,
          "title": "Appsmith - Self-hosted solution for building Internal Tools, CRUD Apps, Dashboards, and more - Now ships auto-height for Widgets 🎉",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqxev2/what_to_do_about_nextclouds_missing_two_way_sync/",
          "author": null,
          "description": "I've been using a managed instance of Nextcloud for some time and it's worked quite well for me so far. But since I switched to Obsidian for notetaking, the lack of two-way sync in the Android client is a huge annoyance. \n The corresponding issue on Github has been open since 2016 and even though there are a few hundred dollars bounty exposed, nothing is moving there.\n I don't even want to talk about the fact that two-way sync is the most basic feature of a cloud service.\n What can I do about it?\n  \nUsing a third-party app like folder sync contradicts the whole privacy idea of having your own Nextcloud instance\n Switching to OneDrive together with an encryption app isn't really an option since I'd like to be able to access my files for example on my work machine where I can't install any encryption apps.\n Is there an alternative to Nextcloud which is able to do two way sync on Android and Windows?\n Any other ideas...?\n  \n   submitted by    /u/wmrch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqxev2/what_to_do_about_nextclouds_missing_two_way_sync/",
          "publishedOn": "2022-12-20T19:35:13.000Z",
          "wordCount": 18518,
          "title": "What to do about Nextclouds missing two way sync?",
          "imageUrl": "https://external-preview.redd.it/b3_8daR0WBu4-TKcVtWrO6RIWUcmHrLaHF9MtGa6laY.jpg?auto=webp&s=428c9d4ba0ee05a981fc74952b01511275b40e9e"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqvzz1/i_miss_having_users/",
          "author": null,
          "description": "I ran dialup bbs's in the 90's, and I built and admin'd an \"online university\" that had a pretty decent student count, and now years later I just do back end. I kind of miss having users. What could I self host and actually have some users? I've got servers collecting dust and gigabit up/down, but I've just got no actual motivating ideas. Does anyone still know what a bbs is/was? What is the modern day equivalent? Infotainment, messagey, with games. Can run on window, linux, most databases, anything. Mastodon was fun for like a day. Fun enough to pay 11 bucks for a domain to test it, but nah, too specific. Something that can still be fun without a ton of users, couple hundred might be nice.\n    submitted by    /u/ScuzzyUltrawide  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqvzz1/i_miss_having_users/",
          "publishedOn": "2022-12-20T18:39:26.000Z",
          "wordCount": 20379,
          "title": "I miss having users",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqveqk/why_are_my_some_of_my_heimdall_tiles_sometimes/",
          "author": null,
          "description": "submitted by    /u/CrispyBegs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqveqk/why_are_my_some_of_my_heimdall_tiles_sometimes/",
          "publishedOn": "2022-12-20T18:15:50.000Z",
          "wordCount": 17855,
          "title": "Why are my some of my Heimdall tiles sometimes unresponsive? (details in comments)",
          "imageUrl": "https://external-preview.redd.it/RDyphlliu2eQTh5EQXbJvJejI8SgO9mJ4maO-Vur0oQ.png?format=pjpg&auto=webp&s=8e5e5b87f22fd6dba6366401aa0e43bcc018a3f3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqun0x/nextcloud_vs_syncthings/",
          "author": null,
          "description": "Currently using syncthings to back my phone up to storage at home and its doing the job wonderfully. A friend of mine and I were disgusting our setups and he was telling me about nextcloud doing the same thing but with more features. Neither of us had used the other so we couldn't properly compare pros and cons.\n Those who have used both, which did you end up with and why?\n    submitted by    /u/29Top  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqun0x/nextcloud_vs_syncthings/",
          "publishedOn": "2022-12-20T17:45:12.000Z",
          "wordCount": 18014,
          "title": "Nextcloud vs syncthings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqujp8/dashboard_suggestions/",
          "author": null,
          "description": "I see there are a lot of different Dashboard options. Homer, Homepage, Heimdall etc. What are the key differences between them and what do you guys use?\n    submitted by    /u/pivotpixels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqujp8/dashboard_suggestions/",
          "publishedOn": "2022-12-20T17:41:28.000Z",
          "wordCount": 18408,
          "title": "Dashboard suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqu16l/content_management_software/",
          "author": null,
          "description": "Hello, I am the tech guy of an indie game team and we are working on a game similar to Dance Central and we have songs, avatars, playlists, DLC store etc. in game.\n I am looking for a self hosted content management website where we can control mentioned content above, I have some requirements.\n  \nNo SSO behind a stupid paywall (LDAP can work too)\n A good REST API\n Ability to customize the software so I can hook it up with a custom library I made in Node that connects to our cloud service and creates folders for those songs/avatars/playlists (basically a way to hook it up when a content gets CMUD)\n  \nI have tried Strapi, it was an OK solution but not having an SSO and not being able to customize the routes to add my library was a minus.\n I tried PayloadCMS for a while and the team used it but I had to implement my own SSO which would get erased by each update to come. I like how it had a good REST API and how customizable it was but it looked very unfinished and the GUI was really empty.\n Ability to use the software in Docker compose would be a plus.\n    submitted by    /u/btt79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqu16l/content_management_software/",
          "publishedOn": "2022-12-20T17:20:37.000Z",
          "wordCount": 18809,
          "title": "Content Management Software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqtt1m/possible_to_host_podsync_on_android/",
          "author": null,
          "description": "I really want to convert YouTube channels to podcast feeds in a simple uncomplicated way. Podsync seems to tick all the boxes but I was wondering if I could host it on my android device?\n    submitted by    /u/adamjturner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqtt1m/possible_to_host_podsync_on_android/",
          "publishedOn": "2022-12-20T17:11:38.000Z",
          "wordCount": 17660,
          "title": "Possible to host podsync on android?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqrnn0/how_to_automatically_recreate_dockercompose/",
          "author": null,
          "description": "So I have a Synology NAS running docker, and a bunch of containers, that I start with sudo docker-compose up -d . \n The docker file is located in /volume/docker/docker-compose.yml and that folder is available to me on the local network, so I can just edit it directly on my PC.\n I'd like to have the containers automatically restart whenever I save changes without having to ssh into the nas to rerun the command myself. \n I could probably just write a script that will monitor the file, but is there an off the shelf solution to this that I can use?\n    submitted by    /u/Asalas77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqrnn0/how_to_automatically_recreate_dockercompose/",
          "publishedOn": "2022-12-20T15:43:13.000Z",
          "wordCount": 19336,
          "title": "How to automatically recreate docker-compose containers whenever a change is made to the YAML file?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqq86o/cannot_access_aaaa_domain_outside_of_home_network/",
          "author": null,
          "description": "Hello guys.\n I am trying to set up a self hosted server on my rasp. My Nginx server is running on docker and listening on port 80 and [::]:80 with a simple index. I bought a domain name too in which I used an AAAA record type to use the IPv6 address of the raspberry itself as my provider is using cgnat and I don't have a unique public ip for port forwarding etc. I can access the domain from all devices in my local network without a problem, my index page is showing up fine. However when I try to access it from the public, for example using my network data or from another network, chrome either doesn't load (from mobile data) or throws DNS_PROBE_FINISHED_NXDOMAIN (at least to the network my friend tried).\n I have enabled ufw in my server with opening port 80 to the public as well as allowing forwarding to docker and adding the rules found in https://github.com/chaifeng/ufw-docker. Dns seems to be completely propagated. Even if I disable ufw, the situation remains the same and no log is showing up when I access it from outside when the firewall is enabled.\n My nginx conf:\n server {\n listen 80;\n listen [::]:80;\n server_name example.com www.example.com;\n root /usr/share/nginx/html/;\n index index.html; }\n and firewall rules related to port 80:\n 80 on eth0 ALLOW Anywhere\n 80 (v6) on eth0 ALLOW Anywhere (v6)\n 80/tcp ALLOW FWD 192.168.1.0/24\n 80/tcp ALLOW FWD Anywhere\n 80/tcp (v6) ALLOW FWD Anywhere (v6)\n Even when I try to get a certificate from LetsEncrypt I get The Certificate Authority failed to download the temporary challenge files created by Certbot.\n Do you have any idea what misconfiguration could be on my side or what the problem could be?\n    submitted by    /u/UnluckyPr0gr4mm3r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqq86o/cannot_access_aaaa_domain_outside_of_home_network/",
          "publishedOn": "2022-12-20T14:41:14.000Z",
          "wordCount": 19768,
          "title": "Cannot access AAAA domain outside of home network",
          "imageUrl": "https://external-preview.redd.it/KPHRMitYZCNWtmWl2FTLICyH_UhbeuEOXK6CNV190vI.jpg?auto=webp&s=f634f819655867502f4a94eac54cb285890ab145"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqpb6w/survey_bandwidth_offerings_in_cloud_computing/",
          "author": null,
          "description": "Hey fellow Selfhosters!\n Apologies if this is the wrong place or way to ask for this help, but I need help from here for my college project, please take 3-5 mins from your time if you can :)\n I'm writing a research paper about a Fixed Cost Cloud service model where initially the user will be allotted 1Gbps as is the norm, and after 1TB (or whatever the plan might be), the user will be throttled to 50Mbps, but they won't be billed for the Transfer.\n I'm empathizing with needs of a self hosted community, a small business or a student professional whose bandwidth needs might not be a lot and the traffic is in small chunks, but they're paying the cloud providers for their Bandwidth Over usage.\n I need your advice for this project. I know it cannot work for everyone, Hence I need your response and suggestions for this.\n We (me and my batchmate) have also launched a Google Form and we'll be glad if you could take the small time to fill that.\n https://docs.google.com/forms/d/e/1FAIpQLSfBLf8M4uIy4SwSbFZkCKfEhjp49-BPeCX6IlFikfhGUqAu0g/viewform\n Any advice would be appreciated. Thank you :))\n    submitted by    /u/_diamondzxd_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqpb6w/survey_bandwidth_offerings_in_cloud_computing/",
          "publishedOn": "2022-12-20T14:01:35.000Z",
          "wordCount": 23980,
          "title": "[Survey] - Bandwidth Offerings in Cloud Computing",
          "imageUrl": "https://external-preview.redd.it/S_fx0DIFtMDmvQ_BkNiCmqnKD9E4E7Wwp-fG86u_NBU.jpg?auto=webp&s=5a43f8d566a45922586cd6827d241cb5b875babb"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqp7el/security_of_wgeasy/",
          "author": null,
          "description": "I recently installed wg-easy on my home network to be able to safely remote into my network. However, to be able to add new clients, while not being at home, I exposed the dashboard of wg-easy to the public, which is only protected by a password. \n I don't have any concerns regarding the complexity and length of my chosen password, but is it safe to exposed said dashboard to the public?\n    submitted by    /u/Inety  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqp7el/security_of_wgeasy/",
          "publishedOn": "2022-12-20T13:57:42.000Z",
          "wordCount": 18820,
          "title": "Security of wg-easy",
          "imageUrl": "https://external-preview.redd.it/ONGBEJKiR7JFRJ4ZTcLf9dOXODm0OnsZiNq5v7gapsY.jpg?auto=webp&s=c4484645a9be927cfaddce222ea4e095c4b19515"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqobcu/your_spotify/",
          "author": null,
          "description": "Hi there everyone I have been looking into Your Spotify (https://github.com/Yooooomi/your_spotify) have set everything up according to the documentation but after the redirect from the Spotify login page it won't log in and load the dashboard is there anyone that has successfully installed it and got it to work? would really love some help with this one\n    submitted by    /u/MethDonut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqobcu/your_spotify/",
          "publishedOn": "2022-12-20T13:19:45.000Z",
          "wordCount": 18529,
          "title": "Your Spotify",
          "imageUrl": "https://external-preview.redd.it/ldFRVs8-iasXgTgrs3ugXJnOiQt-pEhMlwM0CSxh89M.jpg?auto=webp&s=3714283bdc0a6f9c248ecd86e9e18e54caaaca48"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqnn4b/bypassing_university_internet_restrictions_for/",
          "author": null,
          "description": "Hey everyone,\n I'm a student at a university that's located a bit far from the city, and the WiFi and mobile data connections here are really spotty. On a good day, we might get 10-15 Mbps at best, and it's really inconsistent, especially in the dorms. The university library does have a wired fiber connection that gives us 200 Mbps+ on average, but the issue is that they have a Sophos Proxy/Firewall setup that blocks a lot of entertainment websites like Netflix, Prime Video, and Disney+. YouTube is still accessible, though.\n I have a problem where I need to update Microsoft Flight Simulator (40 GB worth of updates!) and work with my personal NextCloud Drive, which would sync a lot faster with the faster internet connection at the library. I use Tailscale and an Nginx Proxy Manager to manag…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqnn4b/bypassing_university_internet_restrictions_for/",
          "publishedOn": "2022-12-20T12:50:37.000Z",
          "wordCount": 19904,
          "title": "Bypassing University Internet Restrictions for Legal Purposes (to access my homeservers/raspberry Pis/VPS)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zqmvkj/free_and_opensource_js_form_builder_with_support/",
          "author": null,
          "description": "https://surveyjs.io/form-library/documentation/get-started\n https://preview.redd.it/9nlgxix9o17a1.png?width=1372&format=png&auto=webp&s=3aa66b677485e974150b174d8687e87e27345ffa\n    submitted by    /u/SurveyJS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zqmvkj/free_and_opensource_js_form_builder_with_support/",
          "publishedOn": "2022-12-20T12:15:08.000Z",
          "wordCount": 17860,
          "title": "Free and Open-Source JS Form Builder with support for React, Angular, Vue.js, jQuery, and Knockout. It's also server- and database agnostic. You can install the npm package and run surveys, polls, quizzes, and other web forms in your app for free. Follow the getting started link for details.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq81xm/do_you_guys_use_mealie_or_tandor_recipes/",
          "author": null,
          "description": "i have currently set up Mealie but i am wondering whether Tandoor would be something worth trying out\n    submitted by    /u/Neon_44  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq81xm/do_you_guys_use_mealie_or_tandor_recipes/",
          "publishedOn": "2022-12-20T00:01:55.000Z",
          "wordCount": 17959,
          "title": "do you guys use Mealie or Tandor Recipes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq7i0j/centralized_email_client/",
          "author": null,
          "description": "Hey Guys,\n I am not sure if this is the right subreddit to ask in, but I give it a go.\n I’m soonly deploying a truenas scale server with a couple of petabytes with data. On this server, unrelated to the data, I want to host a centralized email client. Primarily client. It maybe sounds weird, but it makes sense for my situation. To make a long story short, in bullet points what I am searching for:\n — Self hosted centralized email client\n - Readily available apps on different platforms (android, ios, ipados and preferable ubuntu/windows/etc)\n - The client has to have compatibility with exchange, google mail, smtp/imap/pop3 mailservers located elsewhere and the client also needs a server attached to serve some domain names with a mail server itself.\n ​\n The idea, in more practical terms, is to have really all the email en adresses in one place that can be accessed from anywhere. For example: if I grab a new device somewhere (shared pc, new phone on the airport, a borrowed ipad on a site somewhere, etc); I just want to be able to grab the accompanying app or use the web interface and have access to all my mails and mail adresses (from and for very different sources).\n ​\n I have looked at quite a few solutions, but nothing I found until now did have everything I need. For now I just manage many different adresses and some are loaded in some devices, some aren’t; some I just only use the web gui for the specific purpose it has. I just want to centralize everything and be able to use whatever device I can grab wherever I am to get the work done that needs to be done.\n ​\n Sorry for the long post and let me know if I overlooked some service or result or if I missed something in the rules of this sub reddit.\n ​\n Ps. Things like 2 auth and sorting/categorizing/GTD and so forth are also nice to have, and probably important. But these things pale in comparison to the functionality I‘m looking for described as above\n    submitted by    /u/Axoridex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq7i0j/centralized_email_client/",
          "publishedOn": "2022-12-19T23:39:41.000Z",
          "wordCount": 19109,
          "title": "Centralized Email Client",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq6otu/selfhosted_alternative_to_trakt/",
          "author": null,
          "description": "Hi all,\n Not sure if you know about what's been happening with Trakt these last couple of days. They had some sort of database crash and it's taking several days to recover (and it seems that data's been lost).\n Now, with the service offline, I noticed how dependent I am of it. So I was thinking about possible similar selfhosted solutions. What I'm looking for is something that:\n  \nMay import my current history from Trakt (in fact not being a VIP user I still don't know if Trakt allow history export).\n Allow Kodi scrobbling (that's important, since I manage all my media library through Kodi and it has a Trakt addon, making it trivial to automatically sync everything I watch).\n  \nI found this project (MediaTracker) that I installed a couple of days ago and seems very promising, but it apparently has no way to automatically sync from Kodi.\n Do any of you could suggest any alternative?\n    submitted by    /u/xleonardox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq6otu/selfhosted_alternative_to_trakt/",
          "publishedOn": "2022-12-19T23:08:21.000Z",
          "wordCount": 19398,
          "title": "Selfhosted alternative to Trakt",
          "imageUrl": "https://external-preview.redd.it/f8mBIANTOYw_QJZTYuFGE2WKg9L1WnVcIz67ffQMVcw.jpg?auto=webp&s=6665c93350f0c7b4117c28f9fa5e390cf3d9eee2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq3s4g/diy_router_hardware_suggestions/",
          "author": null,
          "description": "our ancient NetGear router looks like it's finally shitting the bed.\n I really would like to get a small PC/SBC with 2-4 ethernet ports and 2.4GHz WiFi with a decent range to load OPNSense on. Something like the ODroid H3+ is attractive, but it seems like overkill for JUST a router (I'd definitely reach for it if I were building a combo router-NAS), and I was wondering if anyone had any suggestions that had a lower price-point and/or more ethernet ports.\n I don't need massive range, mesh network BS, and I'd rather use as much FLOSS as possible.\n    submitted by    /u/donotlearntocode  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq3s4g/diy_router_hardware_suggestions/",
          "publishedOn": "2022-12-19T21:15:14.000Z",
          "wordCount": 18529,
          "title": "DIY Router hardware suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq2wax/anyone_have_two_instances_of_photoprisim_going/",
          "author": null,
          "description": "I come to you again Beaten and begging =_=. you all helped me once, once more i ask for support \n on my unraid server I'm running PhotoPrisim it's working fine using (MariaDB over the sqlite). I'm trying to start a second instance and it will not launch. I'm using Adminer to create a new user changed the port of the new instance and followed the same instruction that i did for the first. When\n i use the build in DB it launches so i think it's something to do with Maria DB. I'm using the same format for pointing to the Data base. DBUSER:DBPASSWORD@tcp(DBIP:DBPORT)/photoprism?parseTime=true \n ​\n The logs don't actually say anything \n started 221118-jammy as root (amd64-prod)\n init: updating filesystem permissions\n PHOTOPRISM_DISABLE_CHOWN=\"true\" disables permission updates\n Problems? Our Troubleshooting Checklists help you quickly diagnose and solve them:\n https://docs.photoprism.app/getting-started/troubleshooting/\n file umask....: \"0002\" (u=rwx,g=rwx,o=rx)\n home directory: /photoprism\n assets path...: /opt/photoprism/assets\n storage path..: /photoprism/storage\n config path...: default\n cache path....: default\n backup path...: /photoprism/storage/backups\n import path...: /photoprism/import\n originals path: /photoprism/originals\n switching to uid 99:100\n /opt/photoprism/bin/photoprism start\n I'm at a loss\n    submitted by    /u/SkittlesX9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq2wax/anyone_have_two_instances_of_photoprisim_going/",
          "publishedOn": "2022-12-19T20:40:48.000Z",
          "wordCount": 19196,
          "title": "Anyone have two instances of photoprisim going through mariaDB in unraid?",
          "imageUrl": "https://external-preview.redd.it/BOd8eK-D4w1PldDQUI-5GJRSPfNz-lhDp6n1DCmWzDQ.jpg?auto=webp&s=d35ab62013babd521aca95e2859b07b92f03ee2b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq2kni/immich_highperformance_selfhosted_backup/",
          "author": null,
          "description": "Hi all,\n Happy Holiday! \n Alex here, and I am back with another progress update on Immich (v1.39). \n Before jumping into the update, we collect feedback on integrating the directory scanning feature into Immich. Please share your feedback and thoughts in this active discussion thread https://github.com/immich-app/immich/discussions/1006\n This Christmas special update includes more customization for the application. Here are some significant features we have added since the last update. \n  \nOIDC Support\n LivePhotos Support\n User-defined Storage Structure\n  \nApplication setting and User-defined storage structure\n We have implemented a setting page for the admin, which can access on the web. This allows the admin to fine-tune the Immich instance and add support for OIDC configuration from her…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq2kni/immich_highperformance_selfhosted_backup/",
          "publishedOn": "2022-12-19T20:28:05.000Z",
          "wordCount": 23291,
          "title": "Immich - High-performance self-hosted backup photos/videos from your mobile phone (kinda like a Google Photos replacement) Dec-19-2022 - Christmas Special Release - User-defined storage structure is here 🎉",
          "imageUrl": "https://external-preview.redd.it/vHToFeAQA0ur8rMWYqiFhyaYyerEYVDeRn-YWI8oSoE.jpg?auto=webp&s=4bbfe6e78164f40ac0d7098b0153333ba7be041c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq22r8/need_help_for_alerts_in_grafana_using/",
          "author": null,
          "description": "So I am running prometheus and displaying the results in grafana.\n I use prometheus-podman-exporter, to export my prodman container metrics.\n I visualize them in grafana. \n But now i want to get alerts when for example a container is not in the running state.\n But i have no idea how to set this up. \n anyone else here using prometheus-podman-exporter?\n Who can help me with some specific questions?\n    submitted by    /u/UinguZero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq22r8/need_help_for_alerts_in_grafana_using/",
          "publishedOn": "2022-12-19T20:08:22.000Z",
          "wordCount": 19783,
          "title": "need help for alerts in grafana, using prometheus-podman-exported",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq1hk9/reccomendationsadvice_request_on/",
          "author": null,
          "description": "Hi All,\n I've made a diagram illustrating what I am preparing to set up this week to try and make my thoughts clearer. I'm new to network diagrams so please be forgiving where I've missed obvious conventions & if possible let me know so I can work on this in future.\n My aim:\n  \nBack up my synology to a remote site (friends house) (as part of 321 backups) onto my Truenas Server\n  \nOn my network side:\n  \nRun a wireguard docker container on my server\n Using IPTables, add a route to dynamicDNS setup for Friends network (\"superprivate\".duckdns.com) to go via wireguard docker network. I will be broadly following this guide: https://www.linuxserver.io/blog/routing-docker-host-and-container-traffic-through-wireguard\n All other connectivity will be routed out to the internet without this VPN in place\n  \nOn friends side:\n  \nRun WG-easy inside Truenas docker app to run as VPN server\n Run duckdns inside Truenas docker app to share dynamic IP\n Run piVPN on raspberry pi as backup VPN server should something go majorly wrong with my Truenas primary VPN server\n  \nQuestions:\n  \nPlease can you comment on my design above and let me know any shortcomings/improvements?\n My biggest unknown in the above is probably the IPTables changes to NAT, to control what connections end up where.\n The Raspberry Pi will run PiVPN as a backup for my truenas container. I'll be several thousand miles away for a few years so want to ensure I can access my truenas just incase things go very wrong. Any issue running two vpns on the same network?\n I've written some bash scripts utilising rsync to push from my synology to the truenas. As my bash scripting is a bit rusty, is it reccomended to use rsync *service* to push directly to my truenas rather than relying on my scripting?\n  \nMany thanks if you've read through this far :)\n home-network.png\n    submitted by    /u/Maximum-Warning-4186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq1hk9/reccomendationsadvice_request_on/",
          "publishedOn": "2022-12-19T19:46:07.000Z",
          "wordCount": 19292,
          "title": "Reccomendations/advice request on application/design for 321 offsite backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zq1e7z/raspberry_pi_2b_for_tailscale_vpn/",
          "author": null,
          "description": "I want to run a vpn to connect to my house while im away from home, and i can get a cheap pi 2b with 1gb ram, on the local marketplace. Would it be fast enough to use as exit node? We have 100/20 internet speeds. \n    submitted by    /u/PurplePandaYT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zq1e7z/raspberry_pi_2b_for_tailscale_vpn/",
          "publishedOn": "2022-12-19T19:42:34.000Z",
          "wordCount": 21059,
          "title": "Raspberry pi 2b for Tailscale vpn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpzmei/cross_platform_gallery_management_with_delete/",
          "author": null,
          "description": "Hi all,\n I'm after a solution to my dire photo management skills. I've got 20k photos on a server. Lots of crud. I'd like to thin the herd a bit.\n I'm looking for a way to go through them on the phone and delete as I swipe through. Ideally it would be swipe->delete->swipe->keep->swipe->delete etc. The process has been surprisingly difficult to come across.\n On the desktop, it's fine. I can use the file manager, but with kids, work, etc, i might not get to the desktop as often as i'd like which is where the phone would come in. I'm after an android app that can see the photos on the server amd delete/keep as is my wont. I don't require organisational tools, or AI, or tagging, or sharing or anything like that. \n Simple delete/keep->next, repeat ad nauseum. It doesn't have to be a gallery app, maybe a file manager would work, but the thumbnail/preview caching might be problematic.\n I don't know. There are plenty of photo management apps, but really i'm looking for an image previewer and delete button without having to confirm every single time.\n The photos themselves can be in a samba share/ftp/nextcloud instance, doesn't matter, but access from the phone to quickly delete would be incredibly helpful.\n Any ideas appreciated. Thanks.\n Afterthought: I'd be aiming for something from fdroid, but at this point I may have to forego the opensourceness.\n    submitted by    /u/gxvicyxkxa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpzmei/cross_platform_gallery_management_with_delete/",
          "publishedOn": "2022-12-19T18:36:27.000Z",
          "wordCount": 19013,
          "title": "Cross platform gallery management (with delete)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpz9ki/looking_for_a_readytoextendanddeploy_openid/",
          "author": null,
          "description": "I feel like I wasted my whole weekend. All I wanted to do is create a REST API I could develop a mobile app against. This is the first programming work I’ve done for myself in ages and is widely outside the scope of the kind of work I do for clients. I’m interested in spring because the overtime I’ve been doing has been on a spring project. \n I found this example by Baeldung after running into dead-ends with other tutorials:\n https://github.com/Baeldung/spring-security-oauth\n It’s not setup for SSL or running outside of local dev environment. So that’s where I spent my Sunday. \n I eventually got everything besides actually being able to log out to work. Also technically still have to figure out how disable the management console being reachable from outside the host. \n Surely there must be a secure, ready to deploy default that can be extended, right? \n Am I expecting too much to be done for me?\n    submitted by    /u/YouDontKnowMyLlFE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpz9ki/looking_for_a_readytoextendanddeploy_openid/",
          "publishedOn": "2022-12-19T18:23:26.000Z",
          "wordCount": 19707,
          "title": "Looking for a ready-to-extend-and-deploy OpenID + Spring REST solution.",
          "imageUrl": "https://external-preview.redd.it/6Uueggn5pcnavx68ygIRvrrAzcfgfatEedunJvIQun8.jpg?auto=webp&s=b648866b2153a6ca5902ae3525f4ecb3ee2cf2cb"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpz6jz/selfhosted_vpn_solution/",
          "author": null,
          "description": "I have finally completed my first home lab. I have a UDM Pro am running a few dockers in a Raspberry Pi4 (4GB):\n  \nPlex\n Memos\n AdGuard\n Homepage\n  \nIt took me a while to understand and set up the whole thing as this was my first time, but it is all up and running.\n I would like to make some docker containers accessible from outside of my home. After some Googling, it seems that hosting a VPN seems the way to go. I wanted to double check if that is the best path forward:\n  \nddclient for Dynamic DNS (would you use a free service like afraid.org?)\n wireguard for the actual VPN\n  \n​\n Am I missing anything else? I will be running both of those servers in docker.\n ​\n Thanks!\n    submitted by    /u/m4mazzotti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpz6jz/selfhosted_vpn_solution/",
          "publishedOn": "2022-12-19T18:20:24.000Z",
          "wordCount": 18915,
          "title": "Selfhosted VPN Solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpy2mh/what_would_insert_your_name_here_do/",
          "author": null,
          "description": "I recently bought 3 identical machines with the initial idea of running SeaweedFS or maybe CEPH or some other type of distributed filesystem.\n Now I'm doubting if I should make more use of the hardware and also add them as docker nodes in my swarm. What would the performance impact be on my filesystem? Could docker somehow get in the way of the filesystem? What are the security implications of running docker containers alongside my filesystem?\n It seems like a waste of resources to only use the 3 machines as filesystem, doesn't it? I am planning to host quite a lot of mini-websites in docker in the future, it's something to keep in mind, but they can be migrated quite easily provided there is shared storage.\n What would you do in this case?\n    submitted by    /u/Stitch10925  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpy2mh/what_would_insert_your_name_here_do/",
          "publishedOn": "2022-12-19T17:40:06.000Z",
          "wordCount": 18798,
          "title": "What would <insert your name here> do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpunzh/answer_an_opensource_go_based_qa_community/",
          "author": null,
          "description": "submitted by    /u/Bassfaceapollo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpunzh/answer_an_opensource_go_based_qa_community/",
          "publishedOn": "2022-12-19T15:32:29.000Z",
          "wordCount": 18286,
          "title": "Answer - An open-source Go based Q&A community software.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpuh3j/can_someone_explain_why_do_people_seem_to_prefer/",
          "author": null,
          "description": "Hi everyone, I'm relatively new to self hosting, and I've read lots of guides and there is something I can't get my head around. Usually people have a reverse proxy for most of their services, so they can be accessed outside of the home network. What I don't understand is - say you have something like radarr.yourdomain.com - it doesn't seem to difficult for someone to guess that URL. If they do, then all that's left stopping them from accessing your services is the authentication from each service. I have been using wireguard for accessing my services outside my home, and it works quite well, and it seems more secure given how big the private keys are etc? I understand using a reverse proxy for a media server, in case you want to share with others or on devices that you can't use a VPN client, but why have it for the other more \"private\" services?\n Thank you very much!\n Edit: Thank you everyone, that makes sense. As for reverse proxies, is it considered secure to use the services own single authentication, like radarr and sonarr, or is it recommended to set up something more complex like authelia? Of course running with SSL.\n    submitted by    /u/jpbragatti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpuh3j/can_someone_explain_why_do_people_seem_to_prefer/",
          "publishedOn": "2022-12-19T15:25:10.000Z",
          "wordCount": 22842,
          "title": "Can someone explain why do people seem to prefer Reverse Proxy instead of VPN?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpt4jm/nvr_suggestions_experienceany_decent_alternatives/",
          "author": null,
          "description": "I have a simple setup and 2 cameras connected to MotionEye docker on Raspberry Pi 4B. It's running fine except a continuous error about unable to generate thumbnail for recorded videos. I only use it to store camera feeds 24x7 to a server.\n MotionEye is great but development has been slow and current armhf docker image is 2 years old. I tried creating new image from source but some platform dependencies are not met I feel hence failing to run despite successful image creation.\n What alternatives do you suggest for motioneye? I am looking for simple NVR which just records camera streams. No object detection, motion detection etc. required.\n    submitted by    /u/hum8lefool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpt4jm/nvr_suggestions_experienceany_decent_alternatives/",
          "publishedOn": "2022-12-19T14:31:19.000Z",
          "wordCount": 18786,
          "title": "NVR Suggestions & Experience...Any decent alternatives for MotionEye?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zps9be/mounting_a_nas_folder_to_linux_raspberry_pi/",
          "author": null,
          "description": "Hi all,\n as my NAS is a bit dumb (ie Synology locked it down to only install something from their package manager), I was hoping to use my Raspberry Pi as a Jellyfin server.\n I am however having issues mounting the shared folder on Raspbian.\n I followed the instructions at https://www.gavingreer.com/2020/03/06/synology-nfs-mount but when I try to mount the drive, I don't get the expected results:\n $ sudo mount 192.168.178.69:/volume1/video /media/nas/video $ df -h | grep /media/nas/video/ $ ls /media/nas/video/ ls: cannot open directory '/media/nas/video/': Permission denied \n Anyone any idea what I might be missing?\n    submitted by    /u/stringlesskite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zps9be/mounting_a_nas_folder_to_linux_raspberry_pi/",
          "publishedOn": "2022-12-19T13:56:55.000Z",
          "wordCount": 19362,
          "title": "Mounting a NAS folder to linux (Raspberry Pi)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpr3j6/vocaroo_selfhosted_alternatives/",
          "author": null,
          "description": "As the title suggests, I’m wondering if there is anything similar to Vocaroo that I can spin up?\n    submitted by    /u/Nicnivian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpr3j6/vocaroo_selfhosted_alternatives/",
          "publishedOn": "2022-12-19T13:06:42.000Z",
          "wordCount": 18672,
          "title": "Vocaroo self-hosted alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpquz5/viseron_200_selfhosted_local_only_nvr_and_ai/",
          "author": null,
          "description": "Viseron is a self-hosted NVR deployed via Docker, which utilizes machine learning to detect objects and start recordings.\n v2.0.0 was just released which features a lot of improvements, including a fresh new frontend interface\n Check out the release notes: https://github.com/roflcoopter/viseron/releases/tag/v2.0.0\n Viserons features include, but not limited to the following:\n  \nObject detection via: \n YOLOv3, YOLOv4 and YOLOv7 Darknet using OpenCV\n Tensorflow via Google Coral EdgeTPU\n DeepStack\n \n Motion detection\n Face recognition via: \n dlib\n DeepStack\n CompreFace\n \n Image Classification\n Responsive, mobile friendly Web UI written in TypeScript React\n MQTT support\n Home Assistant MQTT Discovery\n Lookback, buffers frames to record before the event actually happened\n Supports hardware acceleration on different platforms \n CUDA for systems with a supported GPU\n OpenCL\n OpenMax and MMAL on the RaspberryPi 3B+\n video4linux on the RaspberryPi 4\n Intel QuickSync with VA-API\n NVIDIA video4linux2 on Jetson Nano\n \n Multiplatform, should support any amd64, aarch64 or armhf machine running Linux. Specific images are built to support: \n RaspberryPi 3B+\n RaspberryPi 4\n NVIDIA Jetson Nano\n \n Zones to limit detection to a particular area to reduce false positives\n Masks to limit where object and motion detection occurs\n Stop/start cameras on-demand over MQTT\n  \nCheck out the documentation here: https://viseron.netlify.app/\n https://github.com/roflcoopter/viseron\n I am really interested in feedback and features that you would like to see implemented. I respond to all comments here on Reddit, the Home Assistant forum thread or GitHub issues. \n I hope you'll find this useful!\n Some screenshots:\n ​\n Cameras\n Recordings\n Built in Configuration editor\n    submitted by    /u/roflcoopter1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpquz5/viseron_200_selfhosted_local_only_nvr_and_ai/",
          "publishedOn": "2022-12-19T12:56:20.000Z",
          "wordCount": 21039,
          "title": "Viseron 2.0.0 - Self-hosted, local only NVR and AI Computer Vision software.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpq7dq/encrypted_caldavcarddav_solution/",
          "author": null,
          "description": "I'm searching for a encrypted carddav/caldav server options.\n I have a simple vultr vps and atm am using Radicale as my solution with Davx5 on my phone with simple calendar and thunderbird on my pc.\n What I'm meaning to ask is is there any way to add encryption with radicale or if there are any opensource solutions with encryption.\n The reason for encryption is that this is a vultr vps, not my hardware. If it was I wouldn't mind with radicale as a solution but as it isn't I would like if there is something if possible. If not will have to continue with radicale.\n    submitted by    /u/CronyAkatsuki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpq7dq/encrypted_caldavcarddav_solution/",
          "publishedOn": "2022-12-19T12:25:08.000Z",
          "wordCount": 19117,
          "title": "Encrypted caldav/carddav solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpp9hc/legita_selfhosted_web_frontend_for_git_written_in/",
          "author": null,
          "description": "submitted by    /u/Icyphox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpp9hc/legita_selfhosted_web_frontend_for_git_written_in/",
          "publishedOn": "2022-12-19T11:38:32.000Z",
          "wordCount": 18523,
          "title": "legit—a self-hosted web frontend for git, written in go",
          "imageUrl": "https://external-preview.redd.it/2M0GH5nXFtZK75OaW0RzxP7fqqwaVd2kWrbywuYL1wE.jpg?auto=webp&s=ac10c3b6c2e45308bf2789f8caacd5cda9bfa71e"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpnhvc/help_with_fake_google_safe_browsing_reports/",
          "author": null,
          "description": "Hey selfhosters, \n I've recently had a problem with some apps that I'm selfhosting for our company being reported to google as phishing, including our website. This caused some issues last week as our website is listed in our signatures and Gmail flagged all our outgoing mails as phishing attempts.\n Additionally, one of the domains that has been reported is nothing more than a Bookstack wiki protected with Cloudflare Zero Trust, even if you get past Zero Trust, you'll still need to login to Bookstack. There's definitely no phishing or even anything to download there. I suspect we're being fake report bombed by someone for reasons unknown to me.\n It's causing some issues with my colleagues accessing the necessary tools we need to use if they happen to be using Chrome as their browser. Has anyone had experience with such a situation before? Apart from submitting an Incorrect Phishing Warning report, is there anything else I can do? I seriously doubt our servers have been compromised, I've looked at the logs and there's nothing that would hint at suspicious activity.\n Thanks in advance.\n    submitted by    /u/dashrandom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpnhvc/help_with_fake_google_safe_browsing_reports/",
          "publishedOn": "2022-12-19T09:57:43.000Z",
          "wordCount": 18774,
          "title": "Help with fake Google Safe Browsing reports",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpjwur/my_current_mood_when_i_had_a_drive_in_a_degraded/",
          "author": null,
          "description": "submitted by    /u/razenet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpjwur/my_current_mood_when_i_had_a_drive_in_a_degraded/",
          "publishedOn": "2022-12-19T06:16:52.000Z",
          "wordCount": 1949,
          "title": "My current mood when I had a drive in a degraded state for proxmox. Plugged the old drive back in and it seemed to chill out… for now but hot spare is in.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpaoku/torrent_downloader/",
          "author": null,
          "description": "I'm searching for a selfhosted web app that do the front end for Jackett where I can search some keywords and it shows me the details about all the torrent found, I could choose which one I want (Not fully automated like Sonarr) and when I click on it, it's sent to Transmission or qBittorrent to be downloaded.\n    submitted by    /u/Armeclemes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpaoku/torrent_downloader/",
          "publishedOn": "2022-12-18T22:46:15.000Z",
          "wordCount": 17097,
          "title": "Torrent downloader ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpa8tp/my_journey_so_far_in_selfhosting/",
          "author": null,
          "description": "https://preview.redd.it/4vgfgf8svq6a1.png?width=1167&format=png&auto=webp&s=999ad06c0e558dc7b518d93183981a92457f3def\n One year after getting into selfhosting\n I just wanted to share my path to selfhosting so far!My first intention was to host a secure passwordmanager for myself and my family (Vaultwarden).Well I got kind of addicted to selfhosting services and replace comercial services like Google Photos, OneDrive and PasteBin.\n So I want to share my current setup, consisting of some VPS's and home equipment.I'll go through everything I am running on each machine.Maybe I can inspire some of you and if you have questions, just ask away!\n I almost exclusively use Docker / Docker Compose and LXC containers to host services.\n https://preview.redd.it/g2q8sq0shq6a1.png?width=2166&format=png&aut…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpa8tp/my_journey_so_far_in_selfhosting/",
          "publishedOn": "2022-12-18T22:26:41.000Z",
          "wordCount": 18926,
          "title": "My journey so far in selfhosting!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zpa8su/with_the_k8sathome_helm_chart_repository_no/",
          "author": null,
          "description": "I have half a dozen helm charts I've deployed from the k8s-at-home chart repo - they've been issue free. Today I noticed the project has been effectively abandoned as of early november.\n I've cloned the existing git repo, so I can be sure I'll have the charts I'm using right now. That said, what sources are people using for their favorite helm charts?\n Obviously there are repos like Bitnami, but they're more component services (mysql, rabbitmq, postgres, etc) vs applications.\n    submitted by    /u/Double_Intention_641  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zpa8su/with_the_k8sathome_helm_chart_repository_no/",
          "publishedOn": "2022-12-18T22:26:39.000Z",
          "wordCount": 17537,
          "title": "With the k8s-at-home helm chart repository no longer being maintained, what are people using instead?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp9quj/running_fail2ban_synology_cloudflare_help/",
          "author": null,
          "description": "I've used various guides to configure fail2ban on a Synology in Docker, for a service (VaultWarden) running on a Synology that is using Synology's reverse proxy and also behind Cloudflare proxy DNS.\n When Fal2Ban kicks in, it bans the Cloudflare IPS and therefor, I am still able to authenticate from my TEST IPs....\n Anyone know why this is happening? I am assuming in my reverse proxy I need *something* so that it passes the real IP through, yes? I have tried various settings in the Synology GUI to no avail..\n I am using a special cloudflare.conf file in Fail2Ban to pass it the data it needs to automatically put in the bans...which works, but it ends up banning IPS belonging to Cloudflare... Any guidance appreciated. In Vaultwarden.log it is seeing cloudflare's IP and not the true IPS.\n    submitted by    /u/sqlallstar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp9quj/running_fail2ban_synology_cloudflare_help/",
          "publishedOn": "2022-12-18T22:04:16.000Z",
          "wordCount": 17181,
          "title": "Running Fail2Ban, Synology, Cloudflare - help - Fail2Ban sends Cloudflare IPS to Cloudflare",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp8xwp/dashy_multiple_pages_broken/",
          "author": null,
          "description": "I figured I'd ask here since a few of you are using Dashy. \n I've only found 1 issue on the GitHub describing this issue and there's not a lot of traction on it. \n I am resetting up Dashy on a new server (dockerized) and found that I can't get multiple pages working. When adding a secondary page and clicking it, the dashboard breaks. The best way to describe it is the theme breaks and the new page doesn't load. \n I've tried using the sample pages from the Dashy docs in case my yml was broken, but I experience the same issue. \n In the docker compose, I've declared my /opt/dashy/public dir and also the specific config files and nada. \n  volumes: - /opt/dashy/public/mainpage.yml:/app/public/conf.yml - /opt/dashy/public/testpage.yml:/app/public/testpage.yml - /opt/dashy/item-icons:/app/public/item-icons \n On the original server, it works great. Second and third pages load, but on this new instance, it's broken. \n Both instances are on the same version (2.1.1)\n Just not sure why multiple pages started giving me such an issue and was wondering if others were having the same issue.\n    submitted by    /u/iC0nk3r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp8xwp/dashy_multiple_pages_broken/",
          "publishedOn": "2022-12-18T21:29:20.000Z",
          "wordCount": 17676,
          "title": "Dashy - Multiple Pages Broken?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp8wjl/nginx_proxy_manager_vs_traefik/",
          "author": null,
          "description": "I've been using Npm for about 4 years now and never had any complaints or issues with it! However I've read alot about people having trouble with it. Are there any benefits by using traefik?\n    submitted by    /u/MethDonut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp8wjl/nginx_proxy_manager_vs_traefik/",
          "publishedOn": "2022-12-18T21:27:43.000Z",
          "wordCount": 17394,
          "title": "NginX Proxy Manager vs Traefik?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp8v13/i_have_a_server_and_a_raspberry_pi_my_server_runs/",
          "author": null,
          "description": "I started my self hosting journey with a Raspberry Pi with Pihole installed. Now that I have a server going with a bunch of docker containers, I'm wondering if I need my Raspberry Pi anymore for Pihole. I still see people mentioning their Pihole + Raspberry Pi combo so just want to make sure.\n Can I move Pihole to my server?\n Thanks\n    submitted by    /u/Melodic_Walk_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp8v13/i_have_a_server_and_a_raspberry_pi_my_server_runs/",
          "publishedOn": "2022-12-18T21:25:47.000Z",
          "wordCount": 18095,
          "title": "I have a server and a Raspberry Pi. My server runs all of my home automation and *arr stuff. The Pi runs Pihole. Can I simplify things by moving Pihole to my server? Are there any issues doing that?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp7cmu/can_i_use_ubuntu_as_router_with_one_physical/",
          "author": null,
          "description": "I have simple set up - ISP router (can be switched to modem mode), switch and multiple deviced connected to this switch via ethernet. One of these devices in ubuntu server with one physical network interface.\n With the above setup, can I use Ubuntu as a router, define new subnet for the rest of my home, etc.? Maybe with vitual NIC? Where do I start, any guidance I can follow?\n    submitted by    /u/luckylemon33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp7cmu/can_i_use_ubuntu_as_router_with_one_physical/",
          "publishedOn": "2022-12-18T20:20:13.000Z",
          "wordCount": 20046,
          "title": "Can I use ubuntu as router with one physical network interface?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp6k4a/a_self_hosted_home_inventory_management_solution/",
          "author": null,
          "description": "Hello everyone.\n I want to do a small stock of stuff I buy regularly for my home. To be able to never forget what to buy every week, I want to generate a dynamic list every X days. \n I am looking for a inventory management solution. Usage: home / personal \n Requirements : - home inventory management - manage available products with price, quantity and details (such as consumption time, that means in how many days is each product consumed) - manage list of recursive stuff to buy - access to an overview of the quantity of the products that I have in my stock and when I will have to renew them. - set notifications (emails or push) to notify me when a product inventory is lower than a certain quantity - creates automatically s list of products I need to rebuy every fix time (ex. Every week). - responsive design -self hosted\n I know that a lot of solutions exist for inventory management, but I can't try them all and I am sure that some of you have some propositions.\n Thank you for your help.\n    submitted by    /u/NotABiene  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp6k4a/a_self_hosted_home_inventory_management_solution/",
          "publishedOn": "2022-12-18T19:45:58.000Z",
          "wordCount": 17792,
          "title": "a self hosted home inventory management solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp6afv/have_you_found_your_ideal_network_setup_mine_is/",
          "author": null,
          "description": "submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp6afv/have_you_found_your_ideal_network_setup_mine_is/",
          "publishedOn": "2022-12-18T19:33:53.000Z",
          "wordCount": 18473,
          "title": "Have you found your ideal network setup? Mine is ok-ish",
          "imageUrl": "https://preview.redd.it/dm9oya53lp6a1.png?auto=webp&s=7bd6ce9c43053c6503333961f808552f20391c11"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp65by/cloudflare_tunnel_split_dns_not_working_correctly/",
          "author": null,
          "description": "Yesterday I ended up setting up a cloudflare tunnel. Previously I had been utilizing nginx proxy manager and exposed ports 80 & 443 to the internet. It was working fine, but after reading about cloudflares tunnel I determined why continue to expose ports to the internet.\n Tunnel works great, I can go to ha.mydoman.com and it brings me to home assisstant. Did the same thing with jellyfin. Then I realized when using the domain name internally it was being treated as if I was connecting externally and forcing jellyfin to transcode the videos when on my local network. This makes sense since the dns is now being routed to cloudflare back home. Previously with nginx i used hairpin nat to keep all traffic local.\n I setup dns override in unbound to point to the IP address of NGINX (using Opnsense firewall). I flushed my dns and when I ping that domain it shows the IP. In NGINX I still have setup to use the host ha.mydomain.com . \n ​\n However, when on my internal network when I go to ha.mydomain.com I get a connection refused. So I suspect the domain or something isn't properly getting passed to nginx? Therefore it can't resolve properly. When I do ha.mydomain.com:8989/sonarr I can get to sonarr (it requires the port to be specified - otherwise connection refused) via NGINX so something odd is going on. What is the best place to look? Bit stumped at this point.\n    submitted by    /u/ImperatorPC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp65by/cloudflare_tunnel_split_dns_not_working_correctly/",
          "publishedOn": "2022-12-18T19:27:41.000Z",
          "wordCount": 17796,
          "title": "Cloudflare Tunnel / Split DNS Not working correctly",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp3jkf/best_notion_selfhosted_alternative/",
          "author": null,
          "description": "Looking for a notion alternative since apparently staff at notion can look at your stuff willy nilly. And it’s not secure. \n Not the biggest fan of Joplin, and trillium can’t have multiple users. Or even if you know of a more secure option that maybe isn’t even self hosted?\n    submitted by    /u/Fission455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp3jkf/best_notion_selfhosted_alternative/",
          "publishedOn": "2022-12-18T17:25:13.000Z",
          "wordCount": 18008,
          "title": "Best notion selfhosted alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp3gal/new_a_better_plex_exporter_for_prometheus/",
          "author": null,
          "description": "There are a few Plex exporters out there to track metrics in Prometheus but they have some deficiencies: not differentiating between playing, paused, buffering streams, audio vs. video transcoding, tracking media downloads, and more.\n I decided to roll my own exporter to address these and have been running it in production for a few weeks. Please give it a try if this sounds like something that would improve your Plex dashboards — pull requests are welcome (Ruby)!\n https://github.com/axsuul/plex-media-server-exporter\n    submitted by    /u/Axsuul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp3gal/new_a_better_plex_exporter_for_prometheus/",
          "publishedOn": "2022-12-18T17:20:51.000Z",
          "wordCount": 16965,
          "title": "New: A better Plex exporter for Prometheus",
          "imageUrl": "https://external-preview.redd.it/jCn6IAeoLCOLlc9-4gUlDz5_0TPW3-X69CfPATeo0Pc.jpg?auto=webp&s=368191378aa0f4d55b4169d201c203c40c4d70df"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp2vsf/how_to_use_the_real_ip_header_in_nginx_proxy/",
          "author": null,
          "description": "I run all of my services behind cloudflare, and to stop non-cloudflare-proxied traffic reaching them, I created an access list of the cloudflare endpoints, and added the rule to all of my services. It worked before, but I then wanted to see the real client IP in my logs, so I added:\n real_ip_header CF-Connecting-IP; \n to them, in the advanced tab. Now, the requests get blocked, presumably because it uses the real-ip to filter traffic. Is there any way to get the real client IP, while still filtering non-cloudflare traffic?\n    submitted by    /u/DoUhavestupid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp2vsf/how_to_use_the_real_ip_header_in_nginx_proxy/",
          "publishedOn": "2022-12-18T16:53:43.000Z",
          "wordCount": 17932,
          "title": "How to use the real_ip_header in Nginx Proxy Manager, whilst using still using access lists for Cloudflare?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp1p9l/how_to_migrate_from_miniflux_apt_installation_to/",
          "author": null,
          "description": "Hello recently I have got into selfhosting and have selfhosted an miniflux instance on debian using their apt repo.\n Couple weeks later I have tried to use docker containers and decided to move my miniflux instance to a docker one.\n So how would I go about moving the data from the apt hosted postgres miniflux database over to the docker one?\n    submitted by    /u/CronyAkatsuki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp1p9l/how_to_migrate_from_miniflux_apt_installation_to/",
          "publishedOn": "2022-12-18T15:59:12.000Z",
          "wordCount": 20410,
          "title": "How to migrate from miniflux apt installation to docker-compose miniflux installation.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp1gza/swag_reverse_proxy_for_guacamole/",
          "author": null,
          "description": "Hey I want to set up a reverse proxy with swag for guacamole. I already set up a couple, but this one does not want to work. I used the nginx/proxy-confs/guacamole.subdomain.conf.sample and modified it to adhere to the guacamole documentation found here: https://guacamole.apache.org/doc/gug/reverse-proxy.html#nginx\n ​\n this is my conf file:\n server { listen 443 ssl; listen [::]:443 ssl; server_name guac.*; include /config/nginx/ssl.conf; client_max_body_size 0; # enable for ldap auth (requires ldap-location.conf in the location block) #include /config/nginx/ldap-server.conf; # enable for Authelia (requires authelia-location.conf in the location block) #include /config/nginx/authelia-server.conf; location /guacamole/ { # enable the next two lines for http auth #auth_basic \"Restricted\"; #aut…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp1gza/swag_reverse_proxy_for_guacamole/",
          "publishedOn": "2022-12-18T15:47:54.000Z",
          "wordCount": 18432,
          "title": "Swag reverse Proxy for guacamole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp0ctj/alternatives_to_rss_reader/",
          "author": null,
          "description": "I want a desktop software similar to an RSS Feed Reader. The articles are found by subscribing to a page or service (like copying an RSS link in a client software) or by keywords. The articles are displayed on a reader on the user’s side. \n RSS seems to be dying (see Google Reader). What are applications for this? \n It seems nextcloud has an RSS Reader. But I don’t know how it works. \n Mobile support would be nice.\n Any suggestions?\n    submitted by    /u/chaplin2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp0ctj/alternatives_to_rss_reader/",
          "publishedOn": "2022-12-18T14:53:35.000Z",
          "wordCount": 18182,
          "title": "Alternatives to RSS reader",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp0bpb/paperless_ngx_tag_by_filename/",
          "author": null,
          "description": "Hi all, is it possible that paperless-ngx also searches the file name for keywords? I also scan documents with my cell phone (Android Genius Scan) and here the scan is now and then not scanable with OCR ( text is like \"t e x t\" instead of \"text\" and so not searchable). So rework is necessary. Now it would be good if paperless would automatically tag all scans from Genius Scan. Only I can only specify the filename when scanning, but paperless doesn't seem to search it. Do you guys know a solution? Thanks.\n    submitted by    /u/marneusc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp0bpb/paperless_ngx_tag_by_filename/",
          "publishedOn": "2022-12-18T14:52:01.000Z",
          "wordCount": 20223,
          "title": "Paperless ngx - Tag by filename",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zp089g/comparison_of_ui_options_for_bulk_email_sending/",
          "author": null,
          "description": "Listmonk\n Free and open source, but the most unpolished. You may spend lots of time trying to get certain things to work and fail in the end. \n As far as I can tell, it's a \"simpler and possibly slightly more user-friendly\" version of Mautic. \n Some things are better than Sendy, others worse. Overall I prefer Listmonk, especially since it's free and open source. \n The most detailed guide: https://github.com/knadh/listmonk/issues/120#issuecomment-1314110010\n Limitations:\n As of Dec 2022. \n  \nSpam complaints are treated the same as bounces: https://github.com/knadh/listmonk/issues/497 -https://github.com/knadh/listmonk/issues/489 \n \nThere's no option to view all unsubbed or complained; both the total or per-campaign. https://github.com/knadh/listmonk/issues/391#issuecomment-1312779279\n \nYou …",
          "link": "https://www.reddit.com/r/selfhosted/comments/zp089g/comparison_of_ui_options_for_bulk_email_sending/",
          "publishedOn": "2022-12-18T14:47:26.000Z",
          "wordCount": 17812,
          "title": "Comparison of UI options for bulk email sending with Amazon SES and other SMTP providers. Review of Sendy, Mailwizz, and Listmonk.",
          "imageUrl": "https://external-preview.redd.it/zbBR07CbK4wq64--32apqgHTVkb1owDBE46TAm8MjFs.jpg?auto=webp&s=9e6c1bfbe3351fa7ebc1c3ea3d7eb886d969aa2d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zozmiw/cockroachdb_for_selfhosted_services/",
          "author": null,
          "description": "Hi, I have recently redoing my selfhosted architecture and wanted to migrate all of my services to CockroachDB for for easy cluser and replication setup (in docker) and PostgreSQL compatibility but so far, none of the services I wanted to deploy worked :\n  \nNextcloud ( using linuxserver.io image ) doesn't work (despite connecting to the database and creating table) but I think it's due to my configuration so ¯\\_(ツ)_/¯\n Coder use some PostgreSQL specific function not implemented in CockroachDB\n Wakapi doesn't work for the migration ( an issue is opened if you want to take a look) \n  \nI may be out of luck and I will revert back to a simple PostgreSQL container but does any of you use CockroachDB for his selfhosted environnement or have an alternative more compatible ?\n    submitted by    /u/cfouche  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zozmiw/cockroachdb_for_selfhosted_services/",
          "publishedOn": "2022-12-18T14:17:53.000Z",
          "wordCount": 16597,
          "title": "CockroachDB for selfhosted services",
          "imageUrl": "https://external-preview.redd.it/mtDoFYYQ9TIYo8dpb9emvmQt0yneoTONw4YKGT4QWzA.jpg?auto=webp&s=849871716211d34d12859e43dabc7052c42b3646"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zovbb3/small_factor_cheap_server/",
          "author": null,
          "description": "Hi all!\n I am looking for something that is small factory (like NUC), not too expensive and capable of running pfSense, Home Assistant and Kodi. I was thinking of running Proxmox and virtualizing all of that.\n Any suggestions what would be the best for this? I was looking at Intel NUCs but decieded to ask here if you have any better ideas.\n Also it would have to be pretty quiet, since I live in the apartment where the living room and bedroom are the same room 😅\n    submitted by    /u/GiantMoose216  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zovbb3/small_factor_cheap_server/",
          "publishedOn": "2022-12-18T10:07:48.000Z",
          "wordCount": 17667,
          "title": "Small factor cheap server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zov3r3/selfhosted_livestreaming_with_dvr_features_pause/",
          "author": null,
          "description": "I am looking for a self-hostable service that I can send live video to (with OBS for example) that has seamless pause and rewind. By this I mean very specifically, I want to be able to watch the live stream in real time and be able to pause or rewind the live stream and be able to go back to real-time. I use a browser extension called Video Speed Controller, and with this if I ever need to pause or rewind a stream I can increase playback speed and slowly work my way back to real-time. Hopefully that makes sense.\n My use for this would be to capture live Twitch streams with streamlink, then re-stream it via OBS to this self-hosted stream so that I can pause and rewind, because Twitch's player does not offer these very basic features. Currently I can achieve exactly the functionality I desire with YouTube's live streaming service, but I feel kinda icky about broadcasting someone else's Twitch live stream onto my own YouTube, even if it is a private/unlisted stream intended exclusively for my own use.\n It would also be ideal if it works with a reverse proxy so that I can use it away from home securely.\n I've briefly looked into Owncast but it does not appear to have the DVR functionality. I haven't set up an Owncast server yet to actually investigate, but I figure if it doesn't advertise that feature then it's unlikely to have it.\n Does anyone know of anything like this? Thank you.\n    submitted by    /u/Coalbus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zov3r3/selfhosted_livestreaming_with_dvr_features_pause/",
          "publishedOn": "2022-12-18T09:54:01.000Z",
          "wordCount": 17444,
          "title": "Self-hosted livestreaming with DVR features (pause and rewind)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zostpm/first_release_minmon_an_opinionated_minimal/",
          "author": null,
          "description": "Alright guys, get your xkcds ready! I programmed yet another monitoring and alarming tool because I couldn't find one I like for the use case I'm targeting. It's pretty basic right now as it only has two types of checks (filesystem and memory usage) and a bunch of actions (e-mail, log, process and webhook). As the (not very creative) name suggests, it's quite minimal in terms of configuration and code. It's also super easy to extend (which I will do; see the roadmap). It's only for Linux (for now..).\n Feedback and contributions are very welcome!\n https://github.com/flo-at/minmon\n    submitted by    /u/flo-at  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zostpm/first_release_minmon_an_opinionated_minimal/",
          "publishedOn": "2022-12-18T07:22:44.000Z",
          "wordCount": 16998,
          "title": "First release: MinMon - an opinionated minimal monitoring and alarming tool",
          "imageUrl": "https://external-preview.redd.it/Xptuo8_OiHXPLIP5jPC3s5JTdhC9k0WNDnb7nku8bwA.jpg?auto=webp&s=d7357889f65b99c72bfec9d8908fcb18a0e1d445"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zor7b4/suggest_any_selfhosted_family_games/",
          "author": null,
          "description": "Its holiday times and my fam likes board games, quizes and souch stuff.\n So I am looking for something in domain of:\n  \nKahoot\n GooseChase\n Some kind of murder mystery game\n etc\n  \nIs there any such self-hosted stuff?\n    submitted by    /u/the_kovalski  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zor7b4/suggest_any_selfhosted_family_games/",
          "publishedOn": "2022-12-18T05:40:35.000Z",
          "wordCount": 1864,
          "title": "Suggest any self-hosted family games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoldpp/huginns_ip_keeps_getting_blocked_by_kickstarter/",
          "author": null,
          "description": "Twice now I’ve had Kickstarter block the IP of the machine I have Huginn running on. I’ve had to move my Huginn instance to another hosting platform already once. How can I keep Kickstarter from blocking my IP?\n    submitted by    /u/fireshaper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoldpp/huginns_ip_keeps_getting_blocked_by_kickstarter/",
          "publishedOn": "2022-12-18T00:42:27.000Z",
          "wordCount": 16703,
          "title": "Huginn’s IP keeps getting blocked by Kickstarter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zokpn7/is_there_any_service_that_i_can_host_videos/",
          "author": null,
          "description": "I want to upload videos on my website like youtube embed.\n What can i use?\n    submitted by    /u/w0fs2aka9v6g6k9y3aac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zokpn7/is_there_any_service_that_i_can_host_videos/",
          "publishedOn": "2022-12-18T00:16:50.000Z",
          "wordCount": 17352,
          "title": "Is there any service that i can host videos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoj1fl/minimum_specs_for_nas_using_omv/",
          "author": null,
          "description": "Hi everyone! I would like to buy a low end PC to use as a NAS. Building a new rig is expensive AF but buying a workstation from a few years ago is cheaper.\n But, what would be the “minimum specs” for a NAS? I would like to use Openmediavault as the OS, but having Plex in a Docker container.\n    submitted by    /u/donrafiki25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoj1fl/minimum_specs_for_nas_using_omv/",
          "publishedOn": "2022-12-17T23:05:39.000Z",
          "wordCount": 17326,
          "title": "Minimum Specs for NAS using OMV",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoitec/what_would_it_take_to_host_chatgpt_35/",
          "author": null,
          "description": "my resources are 8TB of storage\n 32 gigs of ram total 7 - 12 to allocate\n latest i7 intel CPU\n RTX 2070 \n and the average power in and output of a gaming computer\n do i have the resources to run chatgpt if it was opensource\n    submitted by    /u/Avocado_Express  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoitec/what_would_it_take_to_host_chatgpt_35/",
          "publishedOn": "2022-12-17T22:56:05.000Z",
          "wordCount": 17157,
          "title": "what would it take to host chatgpt 3.5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoh8ab/linuxwindows_question_regarding_sharing_folders/",
          "author": null,
          "description": "So I have Hyperv running on my windows computer. Running a linux server of sorts. Lots of different dockerized services. I've been wanting to share an external Drive I have (Drobo) connected to my windows machine with the linux side. Just a few folders to be able to read/write/ and execute from both OS's and the regular user. \n Here's the rub and mind you I'm still learning linux and getting these services running is just part of my learning process.\n I've been running:\n \"sudo mount.cifs //ip/Downloads /home/user/Downloads -o user=username\"\n to share a Downloads folder on my Drobo with the one I specify on linux but everytime I run it, though it does allow me to read the content I cannot write. Despite attempting to chmod permissions it will only write for the root user. I've attempted to change to permissions at the root level and still keep running into a road block. I'm not sure if there's something I'm missing here but figured I'd throw it out to the the ether and see if I got some kind of idea.\n ​\n Thanks!\n    submitted by    /u/geoguy89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoh8ab/linuxwindows_question_regarding_sharing_folders/",
          "publishedOn": "2022-12-17T21:48:18.000Z",
          "wordCount": 16816,
          "title": "Linux/Windows Question Regarding Sharing Folders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zofpyh/memos_a_fun_twitter_like_notes_app/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zofpyh/memos_a_fun_twitter_like_notes_app/",
          "publishedOn": "2022-12-17T20:44:03.000Z",
          "wordCount": 18227,
          "title": "Memos - A fun Twitter like Notes app",
          "imageUrl": "https://external-preview.redd.it/Ua3_6I0dj_4E3rfaJ2WgdD638oDoS_V88hNzR-JRHQc.jpg?auto=webp&s=f63f30b80641d2b1a9cf07c88cb774d7de1fd17e"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zod1ik/docker_container_cant_access_another_one_via_host/",
          "author": null,
          "description": "I have two containers running on my server. One is mariadb with an opened port to the host - it's working perfectly with my IDE. The other one is a tomcat server.\n When I try to deploy a .war-file (which is also working well) inside the tomcat container it tells me, that the connection to the DB could not be established.\n What can I add to my compose-file so that the tomcat container will be able to connect to the public IP:Port of the host (regarding the DB container)?\n    submitted by    /u/Bl4ckF4k3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zod1ik/docker_container_cant_access_another_one_via_host/",
          "publishedOn": "2022-12-17T18:46:47.000Z",
          "wordCount": 19328,
          "title": "docker container can't access another one via host domain and port",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zobfbq/looking_for_bandwidth_monitoring_app/",
          "author": null,
          "description": "Hi, I'm looking for a self hosted app that can monitor how much bandwidth the server is using. My main objective is to know how much internet I used on a monthly basis.\n I don't need all the bells and whistles like intrusion detection, etc.\n Ideally with a simple web UI.\n Any advice? Thanks!\n    submitted by    /u/Issam2204  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zobfbq/looking_for_bandwidth_monitoring_app/",
          "publishedOn": "2022-12-17T17:34:28.000Z",
          "wordCount": 16976,
          "title": "Looking for bandwidth monitoring app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zob9dp/using_cfs_free_edge_certs_for_reserved_ips/",
          "author": null,
          "description": "I'm probably missing something, but I'd like:\n  \nuse tailscale as my \"VPN\" into my network\n use simple hosts like bitwarden.home.mydomain.com to access resources\n protect my bitwarden_rs instance with https (hopefully be able to use the native apps instead of the website)\n make it simple to manage (no self-hosted certs installed on end devices)\n not expose my proxy to the public web (egress is fine)\n and do it for free (other than the purchase of the domain)\n  \nMy thought was to create a DNS record in CF that points to a reserved IP, \"10.5.5.14\". Then on \"10.5.5.14\", setup a reverse proxy entry with the cert provided by CF.\n I'm guessing this isn't possible as the edge certs can only be used if you proxy requests through CF network, which isn't possible because I'm within a reserved IP range.\n Is there another way to achieve what I want to do?\n    submitted by    /u/pro547  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zob9dp/using_cfs_free_edge_certs_for_reserved_ips/",
          "publishedOn": "2022-12-17T17:26:53.000Z",
          "wordCount": 17239,
          "title": "Using CFs free edge certs for reserved IPs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoabzj/nextcloud_alternative_for_filesharing/",
          "author": null,
          "description": "Is there a good alternative to nextcloud that offers GDrive-style folder sharing via links? \n I like Nextcloud in principle but it's tendency to constantly break without any useful error messages is getting on my nerves...\n    submitted by    /u/Komari  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoabzj/nextcloud_alternative_for_filesharing/",
          "publishedOn": "2022-12-17T16:44:51.000Z",
          "wordCount": 20398,
          "title": "Nextcloud alternative for filesharing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zoa6n4/how_to_manage_multiple_port_with_adguard_personal/",
          "author": null,
          "description": "Hello i'm currently running my own server on a raspberry. But i am struggling with the port management. I can't understand. \n If i have Adguard runnning on port 80 , i need this port to have my DNS working on Adguard, but i want that my dashboard to run also on this port, like i want to just type myaddress.com or 192.168.1.20 to display my dashboard without my dns not working. \n How can i do that ? I tried reading some documentation but i couldn't understand.\n I know you can use ngninx port forwarding, but will my dns work if 80 is not the port for my dns ?\n    submitted by    /u/Biaumax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zoa6n4/how_to_manage_multiple_port_with_adguard_personal/",
          "publishedOn": "2022-12-17T16:38:06.000Z",
          "wordCount": 18192,
          "title": "How to manage multiple port with Adguard, Personal sites, Ngninx port forwarding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo9kzg/running_on_raspberry_pi_with_tailscale/",
          "author": null,
          "description": "Hi, just got Nextcloud working on my Raspberry Pi. Currently can access with http or self signed https.\n I want to make sure I access this securely from outside my LAN. Can I just use Tailscale to access it from another network?\n I’ve seen people create SSL certificates and set up reverse proxies to access their web server from outside their LAN, but couldn’t they just use Tailscale?\n    submitted by    /u/spazzyjazzy7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo9kzg/running_on_raspberry_pi_with_tailscale/",
          "publishedOn": "2022-12-17T16:11:28.000Z",
          "wordCount": 18618,
          "title": "Running on Raspberry Pi with Tailscale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo9arx/virtual_router_for_a_device_on_my_network/",
          "author": null,
          "description": "I want to have a device on my network to have its outside traffic go through a commercial VPN. \n To be more precise. I have NordVPN and want the Chromecast on my network to have its traffic go via NordVPN.\n The chromecast doesn’t support VPN settings as far as I know. My router (TP Link ER605) supports policy routing and VPN. But not NordVPN. \n Is there a way to have a very simple virtual router that supports NordVPN ? Preferably as a docker container. \n My idea would be to create a second wireless network on my ubiquity AP with this virtual router as a gateway. Not sure if it would work.\n    submitted by    /u/kouignamann_kingdom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo9arx/virtual_router_for_a_device_on_my_network/",
          "publishedOn": "2022-12-17T15:59:10.000Z",
          "wordCount": 18513,
          "title": "Virtual router for a device on my network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo88wq/recommendation_for_a_selfhosted_plex_server/",
          "author": null,
          "description": "Hello,\n I've been using Plex for a very long time. Starting with my PC as the server, then moved to a hosted VPS, and currently I'm using a Seedbox.\n The Seedbox is extremely powerful and meets all my needs, but it's getting fairly expensive upgrading storage to a higher capacity.\n I would like your opinions about self hosted solutions. I'm open to using Nas devices, or even building another PC to support it. I currently have an nVidia 1080 that I can utilize for that purpose. The only thing I need, is a solution / device that would do the transcoding on its own, because I don't want to use my PC for that. \n I'm currently serving about 4 users and max simultaneously transcoding is 2-3. Also serving 4k content so I need a device that's powerful enough.\n I'm also looking for the cheapest solution that can be used for this purpose.\n Greatly appriciate your input!!!\n    submitted by    /u/MetallicAchu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo88wq/recommendation_for_a_selfhosted_plex_server/",
          "publishedOn": "2022-12-17T15:09:12.000Z",
          "wordCount": 18013,
          "title": "Recommendation for a self-hosted Plex server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo6ojn/scraper_and_match_price/",
          "author": null,
          "description": "Hello,\n I dont know if exist but i'm looking for an app where I upload a csv file with 100 products and match price with 2 website.\n Do you think exist this? \n ​\n Thank you for your help\n    submitted by    /u/Elemis89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo6ojn/scraper_and_match_price/",
          "publishedOn": "2022-12-17T13:49:52.000Z",
          "wordCount": 17565,
          "title": "Scraper and match price",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo6860/is_there_any_self_hosted_journaling_app_you_are/",
          "author": null,
          "description": "submitted by    /u/seeking_facts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo6860/is_there_any_self_hosted_journaling_app_you_are/",
          "publishedOn": "2022-12-17T13:24:25.000Z",
          "wordCount": 17240,
          "title": "Is there any self hosted journaling app you are using and can recommend ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo6852/is_there_a_virtual_cinema_app_that_exists/",
          "author": null,
          "description": "Not a Netflix style software, like Plex or Jellyfin, but something where a user can log on, pick a \"screen\", and a movie is just playing, kind of like a virtual cinema\n It seems like a pretty niche and silly idea, so might be something I have to try and build myself, but if there's something that already exists, that'd be awesome\n    submitted by    /u/KoolKarmaKollector  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo6852/is_there_a_virtual_cinema_app_that_exists/",
          "publishedOn": "2022-12-17T13:24:23.000Z",
          "wordCount": 16680,
          "title": "Is there a \"virtual cinema\" app that exists?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo3iup/calibre_web_ldap_auth_is_anyone_able_to_point_me/",
          "author": null,
          "description": "submitted by    /u/licidil95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo3iup/calibre_web_ldap_auth_is_anyone_able_to_point_me/",
          "publishedOn": "2022-12-17T10:28:16.000Z",
          "wordCount": 19645,
          "title": "Calibre Web LDAP Auth - Is anyone able to point me in the right direction of what I'm doing wrong? Trying to setup LDAP Auth for my Calibre Web instance, and something isn't liking me. Apologies if r/Selfhosted turns out to be the wrong subreddit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo2t1j/what_lightweight_opensource_word_processor_task/",
          "author": null,
          "description": "submitted by    /u/apompon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo2t1j/what_lightweight_opensource_word_processor_task/",
          "publishedOn": "2022-12-17T09:38:47.000Z",
          "wordCount": 17047,
          "title": "What lightweight open-source word processor, task, and data management tool(s) for personal use would you advise?",
          "imageUrl": "https://external-preview.redd.it/ZqwAwrTwSZaImA5ODfHEfSMybVDV2Jaw9BvyiXcKX0Y.png?auto=webp&s=bc572284ee8ed4b6406e648ee04848679b73689c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zo0802/feature_suggestion_for_a_personal_finance_app/",
          "author": null,
          "description": "submitted by    /u/dev_reez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zo0802/feature_suggestion_for_a_personal_finance_app/",
          "publishedOn": "2022-12-17T06:41:13.000Z",
          "wordCount": 1869,
          "title": "Feature suggestion for a personal finance app.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zny6tb/from_asking_is_there_a_fing_network_monitor/",
          "author": null,
          "description": "submitted by    /u/jokob  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zny6tb/from_asking_is_there_a_fing_network_monitor/",
          "publishedOn": "2022-12-17T04:36:52.000Z",
          "wordCount": 20037,
          "title": "From asking: Is there a Fing network monitor alternative? To: Maintaining a docker image of Pi.Alert for 1 year and 100k pulls later - it's been fun 😉",
          "imageUrl": "https://external-preview.redd.it/tIOInfPaGODJBD1WZuOxbs6bftrFl6crlrwF7H6iKbM.jpg?auto=webp&s=58dd30bc1fcb57b25cb7dec7a640d745407bc1ae"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znungq/docker_secrets_without_swarm/",
          "author": null,
          "description": "I'm finding myself having to hard code passwords in docker-compose files. I'm looking for a way to have secrets for the dozen or so services I run in docker containers without having to go with Docker Swarm or Kubernetes. Using .env files is not an option either.\n Anyone have suggestions or am I going to have to go full blown Kubernetes?\n    submitted by    /u/Ohsbar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znungq/docker_secrets_without_swarm/",
          "publishedOn": "2022-12-17T01:21:29.000Z",
          "wordCount": 17563,
          "title": "Docker secrets without Swarm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znugtz/can_i_use_an_old_wireless_router_to_isolate_my/",
          "author": null,
          "description": "submitted by    /u/Melodic_Walk_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znugtz/can_i_use_an_old_wireless_router_to_isolate_my/",
          "publishedOn": "2022-12-17T01:12:07.000Z",
          "wordCount": 16919,
          "title": "Can I use an old wireless router to isolate my wireless cameras from the internet? And how do I connect my server to my infrastructure so that I can access the camera feeds (saved to my server) via my PC?",
          "imageUrl": "https://preview.redd.it/g66bp6zkzc6a1.png?auto=webp&s=8d01e91e81015c07406852eb70af9d598a7922b0"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znue1e/opensource_docker_management/",
          "author": null,
          "description": "I see products like Portainer, and unraid, are there any open source tools with a webui for managing docker containers?\n    submitted by    /u/kittywrastler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znue1e/opensource_docker_management/",
          "publishedOn": "2022-12-17T01:08:02.000Z",
          "wordCount": 17521,
          "title": "Opensource Docker Management?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znt97g/laptop_as_a_personal_home_server/",
          "author": null,
          "description": "Is a laptop (Ryzen 7 4800H) a good option if energy consumption is my main concern? I'm not sure but isn't a laptop designed to consume less energy while in idle? Also, I'm thinking about disabling CPU boost to increase energy efficiency. Any thoughts on that?\n    submitted by    /u/Rotwildus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znt97g/laptop_as_a_personal_home_server/",
          "publishedOn": "2022-12-17T00:11:37.000Z",
          "wordCount": 18223,
          "title": "Laptop as a personal home server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znsiby/any_help_on_how_to_make_an_oracle_cloud_account/",
          "author": null,
          "description": "I really need a oracle cloud account to host a videogames server, and the free tier is more than enough for me. Although the only payment method I've got in my hands is Paypal. \n Could you guys help me? I really planed to host it on my old PC, but it's not enough. Otherwise I'll have to rent a server..\n    submitted by    /u/super_probably-user  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znsiby/any_help_on_how_to_make_an_oracle_cloud_account/",
          "publishedOn": "2022-12-16T23:36:41.000Z",
          "wordCount": 16595,
          "title": "any help on how to make an oracle cloud account with Paypal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znrdx5/selfhosted_opensource_chatgpt_alternative/",
          "author": null,
          "description": "Are they any selfhosted/ open-source ChatGPT alternatives?\n    submitted by    /u/TheRealCaptCrunchy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znrdx5/selfhosted_opensource_chatgpt_alternative/",
          "publishedOn": "2022-12-16T22:45:50.000Z",
          "wordCount": 16496,
          "title": "selfhosted/ open-source ChatGPT alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znp2c2/self_hosted_voice_server_with_good_a_mobile_app/",
          "author": null,
          "description": "I'm looking to self host a 20 person audio chat server for an event. \n Normally we would Discord for something like this, but we don't have a ton of bandwidth, want to reduce lag, and everyone will be on premise.\n The server is almost beside the point here because we need a system that has a good mobile app interface. We need an app available with the following:\n  \nAndroid and iOS versions\n Push to talk, and auto mute settings\n Multiple channels\n Works with Bluetooth headsets and Airpods\n  \n   submitted by    /u/Jam3Sandwich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znp2c2/self_hosted_voice_server_with_good_a_mobile_app/",
          "publishedOn": "2022-12-16T21:04:08.000Z",
          "wordCount": 16626,
          "title": "Self hosted voice server with good a mobile app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znp1yz/best_file_system_and_backup_type_for_a_simple_4tb/",
          "author": null,
          "description": "I'm trying to share 2x 4tb NAS type hard disks for all my home computers. Right now due to limitations I'm not able to put together a NAS type of PC, but maybe in the future I will properly set it up. So the idea is to use them in my main desktop computer using samba share.\n I will store important data (precious personal stuff) and movies, so my main concern is to reduce the possibility of corruption or loss of data. I don't care too much for the speed of the share. What is the most robust configuration for this?\n I firstly thought to use them as RAID1, but as I'm reading more forums, the more I get the idea that maybe it's overkill. Maybe it's better to make a backup once a week for example and leave the possible problems of RAID missconfigurations? I'm a newbie for RAID configs.\n The other thing is the hard disk file system. Right now I'm between ZFS and EXT4. Same as before, I heard that there is not much difference between them for my size and tasks, but any little improvement over data integrity is appreciated.\n Just in case it's important, my PC has 16gb ram ddr4 and it has a mid modern cpu.\n    submitted by    /u/NavirAur  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znp1yz/best_file_system_and_backup_type_for_a_simple_4tb/",
          "publishedOn": "2022-12-16T21:03:39.000Z",
          "wordCount": 16928,
          "title": "best file system and backup type for a simple 4tb samba share in Ubuntu (2x4tb disk)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znopo2/docker_nginx_proxy_manager_real_ips_for_crowdsec/",
          "author": null,
          "description": "I have all of my services set up in docker on a Synology NAS. NPM is currently running (also in a docker) and handling all traffic wonderfully. I'm still struggling with Authentic LDAP, but I have OIDC and plex authentication working, so I feel well on my way there.\n Now I want to add crowdsec to secure NPM..... I got crowdsec up and running, but once I ingested the NPM logs, I found out that NPM sees all traffic originating from 127.24.0.1.\n I tried setting up macvlan and when I put NPM on there I could hit the management interface on its new IP from my PC, but my router couldn't see it to set the port forwards, so I revered to the bridge network.\n I've seen several guides saying this can be achieved by setting real IP headers in nginx.conf, but NPM doesn't have (at least mine doesn't) that file. ./data/nginx/default_host/site.conf is the closest thing I can find in my set-up following the official NPM install docs.\n Any pointers on how to log real IPs in a docker NPM would be greatly appreciated. \n Or if anyone knows a better way to set up crowdsec on synology, I'd love to hear those suggestions as well.\n Thanks!\n    submitted by    /u/thegreatincognitum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znopo2/docker_nginx_proxy_manager_real_ips_for_crowdsec/",
          "publishedOn": "2022-12-16T20:49:07.000Z",
          "wordCount": 19528,
          "title": "Docker Nginx Proxy Manager real IPs for Crowdsec",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znojvn/can_you_use_ocserv_with_cloudflare_proxy/",
          "author": null,
          "description": "hello\n is there anyway to use anyconnect with cloudflare proxy ? ( or any other proxy )\n    submitted by    /u/pixibooy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znojvn/can_you_use_ocserv_with_cloudflare_proxy/",
          "publishedOn": "2022-12-16T20:42:06.000Z",
          "wordCount": 17566,
          "title": "Can you use ocserv with cloudflare proxy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znnjkz/money_manager_with_iphone_app_or_mobile_friendly/",
          "author": null,
          "description": "I use an old version of YNAB (and absolutely love it) but hate the idea of only being computer based so I am in the hunt for a money manager that can be self hosted and also mobile friendly.\n Does the above exist?\n    submitted by    /u/chench0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znnjkz/money_manager_with_iphone_app_or_mobile_friendly/",
          "publishedOn": "2022-12-16T19:59:44.000Z",
          "wordCount": 16495,
          "title": "Money manager with iPhone app? (Or mobile friendly)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znmlg2/fireshare_a_simple_solution_to_self_hosting_your/",
          "author": null,
          "description": "I last posted here ~5 months ago about Fireshare, a project that I have been working on to quickly and easily share my game clips via unique links. \n It got a lot of positive feedback so I thought I would share it again since I've seen a number of people in comments and post since then asking about video sharing solutions. \n Core Features\n  \nShare h264 encoded mp4, mov and webm files via unique links\n Set videos as either public vs private. Public videos can be seen by anyone who visits your Fireshare instance. Private videos can only be seen by those with the unique link.\n Public and private upload capabilities.\n Simple setup requires basic knowledge of Docker.\n  \nYou can see it for yourself on my demo site: https://v.fireshare.net \n The github project: https://github.com/ShaneIsrael/fireshare\n I also have a complete tutorial on self hosting it which you can find here\n You can find other well put together tutorials on setting it up on YouTube and other websites that users have put together as well.\n  \nLet me know if you have questions and/or if you've used it I would love to hear your feedback. :)\n    submitted by    /u/Shane75776  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znmlg2/fireshare_a_simple_solution_to_self_hosting_your/",
          "publishedOn": "2022-12-16T19:17:04.000Z",
          "wordCount": 18148,
          "title": "Fireshare - A simple solution to self hosting your own videos / game clips via unique links.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znmj5v/which_option_to_use_to_create_a_private_network/",
          "author": null,
          "description": "So I have a macbook, PC, synology NAS, iPhone, some laptops and some raspberry pis.\n I work outside my house quite a lot from my windows laptop or run simple tasks using termius on my iphone. My macbook is always on at home so I usually ssh into it and do my work, sometimes my iphone as well.\n There are some things I cannot do with this, for example if I want to turn on my nas remotely, I can't use my iphone as the app requires you to be on the same network. Also I don't feel safe that I have exposed my devices to the internet like that.\n I want to connect all my devices onto the same network so I can access them anywhere as if they were on the same LAN network. I was looking around at options such as zerotier, nebula, tailscale, headscale, yggdrasil, innernet, openziti, tinc and wireguard and I think wireguard might be my best option as I read that it uses the least amount of resource. Also I want a free and open source and self hosted option.\n I found some of the following tools on github:\n https://github.com/psyhomb/wireguard-tools\n https://github.com/netbirdio/netbird\n https://github.com/gravitl/netmaker\n https://github.com/tonarino/innernet\n I have zero experience setting up networks like this.\n Can I get a recommendation on a good guide and/or which tools I should use to set up the network I desire so any of my devices can be used from anywhere.\n I also understand that some setups require a server to be always on, is there any way around that? I am planning to run the wireguard server from my raspberry pi 3 that also has vaultwarden running. Also must I have a static IP address? My IP address changes sometimes / every few months. If it does, will I be able to easily modify wireguard?\n Also, if there is a better alternative, please let me know.\n    submitted by    /u/areyouhourly-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znmj5v/which_option_to_use_to_create_a_private_network/",
          "publishedOn": "2022-12-16T19:14:24.000Z",
          "wordCount": 20311,
          "title": "Which option to use to create a private network (VPN) for all my devices which I can connect to from anywhere",
          "imageUrl": "https://external-preview.redd.it/CXiZYS8_48h6T-d9EHiYz4eSRlMfXEWU1VQD7wTOHdM.jpg?auto=webp&s=c51b0d297636439646b2c8b1d04e25c0decf3531"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znm7vt/cant_forward_ports_in_nginx_proxy_manager/",
          "author": null,
          "description": "The nginx proxy manager is running in docker and listening to port 80. \n I set it up so that, at the end, the source is http://example.com and the destination (a web app running in the same server) is http://example.com:5000. In terms of the diagram here \n https://forums.unraid.net/topic/110245-support-nginx-proxy-manager-npm-official/\n The “Domain name” and “Forward host to” are http://example.com, the port is 5000, and scheme is http. \n The domain http://example.com:5000 correctly resolves to the expected destination web page. The expectation is that, when I enter http://example.com, it will be forwarded to http://example.com:5000, but it doesn’t. I get a page from NPM that you have successfully set up NPM, but your destination is not correctly set up. \n What could be wrong? How to troubleshoot?\n Initially I suspected docker networking might be the issue. I thought the destination resolves inside docker, which is not defined. But the NPM docker network is a bridge, so the destination DNS query should be able to get out of the docker and resolve in host. \n The application in destination also runs in docker, but with ports mapped in the host. As noted, http://example.com:5000 is indeed accessible.\n I tried other destinations also: localhost, internal IP address of the host, docker interface Ip, etc.\n    submitted by    /u/chaplin2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znm7vt/cant_forward_ports_in_nginx_proxy_manager/",
          "publishedOn": "2022-12-16T19:00:44.000Z",
          "wordCount": 18678,
          "title": "Can’t forward ports in Nginx proxy manager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znjmpt/looking_for_a_tool/",
          "author": null,
          "description": "Hi,\n I'm looking for a solution/tool in which I can put a script, scheduled it to run on particular time/day (preferably cron), execute it and send the results to my email.\n Something similar to Jenkins, but simpler. Jenkins seems overkill for such task.. I know I can build it myself using s-nail/cron/bash, but I was looking for something ready-to-go in a container if possible.\n    submitted by    /u/luxlucius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znjmpt/looking_for_a_tool/",
          "publishedOn": "2022-12-16T17:08:28.000Z",
          "wordCount": 19270,
          "title": "Looking for a tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znjgj1/alternative_to_google_contacts/",
          "author": null,
          "description": "I'm looking for alternative to Google Contacts both the web version as well as Android. On Android I can use any phonebook but I'm expecting sync client that will sync all my contacts with the server. Any suggestions?\n    submitted by    /u/a_sugarcane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znjgj1/alternative_to_google_contacts/",
          "publishedOn": "2022-12-16T17:01:07.000Z",
          "wordCount": 16585,
          "title": "Alternative to Google Contacts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zngryi/is_there_any_best_self_hosted_service_youre_using/",
          "author": null,
          "description": "submitted by    /u/seeking_facts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zngryi/is_there_any_best_self_hosted_service_youre_using/",
          "publishedOn": "2022-12-16T15:07:03.000Z",
          "wordCount": 17108,
          "title": "Is there any Best self hosted service you're using for music ? Any Suggestion ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znglcq/self_hosted_roundup_20/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znglcq/self_hosted_roundup_20/",
          "publishedOn": "2022-12-16T14:59:12.000Z",
          "wordCount": 17851,
          "title": "Self Hosted Roundup #20",
          "imageUrl": "https://external-preview.redd.it/rDCbV6tRIvHl73_s4OAeOEF_HU5OSJK1BFMZuzIcUQk.jpg?auto=webp&s=67f0de5afb7bb7b7a6ed5b0d9f89e6b3e7ad3773"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znep9y/pikvm_v4_nextgen_open_source_kvm_over_ip_on/",
          "author": null,
          "description": "submitted by    /u/Liksys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znep9y/pikvm_v4_nextgen_open_source_kvm_over_ip_on/",
          "publishedOn": "2022-12-16T13:29:03.000Z",
          "wordCount": 19862,
          "title": "PiKVM V4 - nextgen open source KVM over IP on Kickstarter",
          "imageUrl": "https://external-preview.redd.it/mggCHtVDAGBVhVFfvlhlF53GbuO_AjgU3JQ0Rgwncy0.jpg?auto=webp&s=347863f79c7f3d772275e0fdd66d9ffe780c17ee"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zne2bc/emotions_on_self_hosting/",
          "author": null,
          "description": "When I self-host something and I feel proud, should I be proud? I am a newbie. And what I'm doing would sound trivial to an expert. So can I feel proud of the fact that I'm self-hosting things? And can I show off the docker containers to people who are less tech-savvy than me? I want to show them this server that I made. I want to show them how cool it is. But when I think more about it, it is nothing big at all...\n This is some sort of philosophical thing that I don't understand.\n Sorry to bother anyone. \n A weird topic for sure.\n    submitted by    /u/lightningdashgod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zne2bc/emotions_on_self_hosting/",
          "publishedOn": "2022-12-16T12:56:54.000Z",
          "wordCount": 19811,
          "title": "Emotions on self hosting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zndd0n/codeberg_forks_gitea_with_forgejo/",
          "author": null,
          "description": "I've just read the news that Codeberg launches Forgejo I wasn't even aware that Gitea was being turned into a for-profit organization!\n    submitted by    /u/kakamiokatsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zndd0n/codeberg_forks_gitea_with_forgejo/",
          "publishedOn": "2022-12-16T12:18:59.000Z",
          "wordCount": 18196,
          "title": "Codeberg forks Gitea with Forgejo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zncjgv/new_40_tb_nas_server_selfhosted_help/",
          "author": null,
          "description": "Hello to all, \n briefly about my environment:\n Main Server:\n i5-8600 CPU\n 32 GB RAM 1 TB SSD\n With Proxmox running my main VM's/Container's.\n Main NAS:\n Qnap TS-451D2\n 4x 8TB WD Purple \n Raid 10\n I am planning a new NAS with 4x 10 TB WD RED, Ryzen 7 2700X and 16 GB RAM And don't know exactly how to implement it.\n Either I would set up a Nextcloud VM in Proxmox, since the hardware is a bit more powerful, and I might want to run other VMs afterwards or even shut down my other compute server.\n Now the question is what is better Proxmox, Unraid or TrueNas?\n In the end, I only want the most stable and failsafe solution, because I am afraid of data loss. Backups will be made, of course.\n A ready-made NAS solution always gives me security, but I need a more powerful NAS, which can also AI image detection.\n Personally, AI image recognition is most important to me as I am looking for a strong tool to manage my images.\n Does anyone have any ideas?\n Thank you for all comments.\n    submitted by    /u/Katze_Mau  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zncjgv/new_40_tb_nas_server_selfhosted_help/",
          "publishedOn": "2022-12-16T11:31:54.000Z",
          "wordCount": 17545,
          "title": "New 40 TB NAS server self-hosted | help :(",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zncays/how_do_you_manage_your_deployments/",
          "author": null,
          "description": "Hi folks,\n I am working on the next version of the PoeticMetric (privacy-first Google Analytics alternative), and I am going to make it free and open source. However, I would like to learn how people manage their deployments nowadays, so I can provide easy deployment options. For now, I am thinking of shipping with a production-ready docker-compose.yaml, and kubernetes manifests or helm chart is the only other option I can think of. So, how do you manage your deployments?\n View Poll\n    submitted by    /u/th0th  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zncays/how_do_you_manage_your_deployments/",
          "publishedOn": "2022-12-16T11:17:36.000Z",
          "wordCount": 19050,
          "title": "How do you manage your deployments?",
          "imageUrl": "https://external-preview.redd.it/qbDe7e4LrPEldaZvdR06QhOpj7HenQQyTl7-gLiMHOc.jpg?auto=webp&s=4c4dfdcbafcef6e71c0f0509cb268d610cbb1a73"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/znca61/new_release_of_an_opensource_selfhosted_feature/",
          "author": null,
          "description": "https://github.com/featbit/featbit\n Change logs:\n  \nhttps://github.com/featbit/featbit/releases/tag/1.1.0\n https://github.com/featbit/featbit/releases/tag/1.1.1\n  \nNext milestones:\n Milestone🚀Happy new year 2023 · Discussion #129 · featbit/featbit (github.com)\n Previous post:\n Launchdarkly self-host alternative - open source feature management platform : selfhosted (reddit.com)\n    submitted by    /u/hu-beau  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/znca61/new_release_of_an_opensource_selfhosted_feature/",
          "publishedOn": "2022-12-16T11:16:11.000Z",
          "wordCount": 18378,
          "title": "New release of an open-source & selfhosted feature flags platform",
          "imageUrl": "https://external-preview.redd.it/clSFF2iTaRGZIbQfMcTAG_mh_lOnDCak0or_0CFbL2E.jpg?auto=webp&s=d6de336ffc05632aee9b2a5741299deeb6bee5ee"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn2327/move_to_bookstack_from_wikijs/",
          "author": null,
          "description": "I am currently using WikiJS for my documentation and such.\n Things I like about WikiJS:\n - Plenty of customization/administration\n - Syncs plain text to S3 storage (using Cloudflare R2)\n Things I don't like about it:\n - Clunky UI, interface, and editor\n - Pages are slow to render\n - Half of the features are \"coming soon\"\n - Directory structure/hierarchy/navigation is difficult to use properly (at least for me)\n ​\n I was thinking of moving to Bookstack. I already have this installed from when I was testing a few other solutions.\n I've heard issues with Bookstack breaking URL's, is that still an issue I should be worried about?\n I've also heard that if the Bookstack docker/OS dies/corrupts, the data is useless because it uses a database and not plain text. If I sync my docs to S3 storage, are they stored in plain text there or will I need the database? My goal is to be able to have access to all of my documentation if my entire environment collapses. Having plain text files in Cloudflare R2 achieves that goal.\n ​\n *Please do not suggest Obsidian, Joplin, Trilium, etc. as I've tried them all. The only one I still want to try is Outline Wiki, but the setup is too complex just to set up for testing purposes.\n    submitted by    /u/cjchico  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn2327/move_to_bookstack_from_wikijs/",
          "publishedOn": "2022-12-16T01:07:44.000Z",
          "wordCount": 17655,
          "title": "Move to BookStack from WikiJS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn0z56/homelab_desktop_choices/",
          "author": null,
          "description": "submitted by    /u/MrJwan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn0z56/homelab_desktop_choices/",
          "publishedOn": "2022-12-16T00:15:37.000Z",
          "wordCount": 17470,
          "title": "Homelab Desktop Choices ..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn0sg6/is_there_any_way_i_could_expose_some_docker/",
          "author": null,
          "description": "I need him to be able to connect to GitLab CE, and PostgreSQL, but I dont want him to be able to access other containers.\n    submitted by    /u/FredericoDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn0sg6/is_there_any_way_i_could_expose_some_docker/",
          "publishedOn": "2022-12-16T00:07:29.000Z",
          "wordCount": 18211,
          "title": "Is there any way I could expose some docker containers for my friend safely and live?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn0dhx/self_hosted_crm_options_apart_from_vtiger/",
          "author": null,
          "description": "I've been using vTiger for almost 20 years now but I have to say that I've never liked it too much, but since it was the well known I've never been prone to switch \n I remember back in 2014 I was using one cloud CRM called Highrise from the guys from Basecamp, and it was utterly awesome: very simple CRM with the basic functions, all I needed for my use, but this project end closed (and also the project I was conducting and using this CRM with)\n And now I have the opportunity to see new options and I was wondering if you could recommending me anything but vTiger.\n    submitted by    /u/SirLouen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn0dhx/self_hosted_crm_options_apart_from_vtiger/",
          "publishedOn": "2022-12-15T23:49:26.000Z",
          "wordCount": 17971,
          "title": "Self hosted CRM options apart from vtiger?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zn04jp/best_smtpmailserver_option_for_beginners/",
          "author": null,
          "description": "Hello everyone,\n selfhost/docker Beginner here. I already got some applications running, yay!\n But I´m currently stuck with hosting a mail/smtp application. I already tried the docker-mailserver, mailcow and as webinterfaces rainloop and sogo. But to be quite honest I am a little bit stunned by the complexity (a lot of services, ports,...) and amount of errors I am getting. I got not a single option to run correctly. I don´t know where to start.\n For me the topic selfhosted mail is the next logical step, because a lot of applications require an smtp server.\n So, had anyone a similar experience? Can someone recommend a proper, simple image or guide? What would you do?\n    submitted by    /u/Inevitable_Flight_48  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zn04jp/best_smtpmailserver_option_for_beginners/",
          "publishedOn": "2022-12-15T23:38:25.000Z",
          "wordCount": 18078,
          "title": "Best SMTP/Mailserver option for beginners",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmywy8/cloudflare_tunnel_github_authentication_limit/",
          "author": null,
          "description": "Hi Folks,\n I appreciate this isn't really a self hosted product, but if any sub on reddit knows the answer to my question, it's going to be you guys!\n I've managed to fumble my way through cloudflare zero tier to add GitHub as an identity provider, but how do I restrict which github accounts can access my tunnel - at the minute every account can log in. Is this even possible?\n Edit: Solution in the comments\n    submitted by    /u/valkyre09  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmywy8/cloudflare_tunnel_github_authentication_limit/",
          "publishedOn": "2022-12-15T22:52:33.000Z",
          "wordCount": 17454,
          "title": "Cloudflare Tunnel - GitHub Authentication - limit users?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmxo4o/sftpgo_recycle_bin_using_the_event_manager/",
          "author": null,
          "description": "Hi together. In my search for a self-hosted file server I stumbled across SFTPGo. From the documentation I see that there is an Event Manager which should make it possible to realize a recycle bin. Does anyone have experience with this and can help me out? Thanks!\n    submitted by    /u/_patrickap  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmxo4o/sftpgo_recycle_bin_using_the_event_manager/",
          "publishedOn": "2022-12-15T22:09:30.000Z",
          "wordCount": 16888,
          "title": "SFTPGo recycle bin using the Event Manager",
          "imageUrl": "https://external-preview.redd.it/VLlV3-7ARpYCY7aM7F6_un4Z-UlvDKBF_z6uqGlJTuE.jpg?auto=webp&s=e1ac44181895912fc1bf98136d5bc04ffbcdfc8f"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmx8ru/oracle_cloud_cloudflare_nginx_proxy_manager_issues/",
          "author": null,
          "description": "I have a very basic server with Oracle Cloud free tier, and I managed to use Cloudflare and Nginx Proxy Manager to reroute my subdomains with the certifications and everything. However, the only way I get it to work is to expose each container port in my ingress rules on the Oracle server. \n To my understanding (noob here), the idea of using Nginx is to be able just to expose the usual ports (80, 443) and let the rerouting to go behind that, without the need to expose rest of ther ports. Am I correct?\n I'm not sure what additional information I could give to help solve the issue, let me know if there is anything I can add.\n Thanks in advance for the support.\n    submitted by    /u/carlossgv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmx8ru/oracle_cloud_cloudflare_nginx_proxy_manager_issues/",
          "publishedOn": "2022-12-15T21:53:41.000Z",
          "wordCount": 18230,
          "title": "Oracle Cloud / Cloudflare / Nginx Proxy Manager issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmx0op/free_crm_for_small_business/",
          "author": null,
          "description": "Hi all. Pretty much as per the title. Need a CRM to handle VERY simple tasks for software tech support. Basically need to be able to create some customers, associate them to incoming email addresses from our support address (simple SMTP/IMAP), create support items specific to them (usually stemming from said emails), assign to a team member, flag them as complete, etc, etc. Nothing too crazy, small 3-5 person team. Played with self-hosted Oodo but looks like way overkill and only one \"app\" for free version so that looks to end that scheme. PLayed with SuiteCRM but I seemed to be getting random errors, lag, etc (this was on a Windows install with XAMPP).\n Any thoughts, even if cloud based but free (if that exists) I suppose would work. Thanks in advance.\n    submitted by    /u/spg01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmx0op/free_crm_for_small_business/",
          "publishedOn": "2022-12-15T21:44:20.000Z",
          "wordCount": 16896,
          "title": "Free CRM for small business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmuw21/is_there_a_ytdlp_service_that_prompts_the_user_to/",
          "author": null,
          "description": "Essentially, don't want to define a volume for videos to download, but would rather have the program prompt the user with the save-dialog. This is basically going to serve as a frontend for family for example to download videos.\n I couldn't find anything after a cursory search, but maybe I missed something. Most seem to have the feature of defining a docker volume where the vids get downloaded to.\n    submitted by    /u/lannistersstark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmuw21/is_there_a_ytdlp_service_that_prompts_the_user_to/",
          "publishedOn": "2022-12-15T20:16:36.000Z",
          "wordCount": 17771,
          "title": "Is there a yt-dlp service that prompts the user to download and save the video/playlist instead of downloading in a pre-defined DIR?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmut5p/id_like_to_share_my_selfmade_dashboard/",
          "author": null,
          "description": "Python and Django, running in docker container on my nas.\n Anime episodes are tracked daily.\n Whats the opinion on coding stuff like this?\n I know its basic as hell. But its mine :)\n ​\n https://preview.redd.it/neggy56hd46a1.png?width=925&format=png&auto=webp&s=812e1074364f35ce684bf41c2f5ba5268f7651f1\n    submitted by    /u/kidz94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmut5p/id_like_to_share_my_selfmade_dashboard/",
          "publishedOn": "2022-12-15T20:13:23.000Z",
          "wordCount": 17133,
          "title": "Id like to share my selfmade dashboard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmu59u/nextcloud_all_in_one_updated_for_v25_not_mine/",
          "author": null,
          "description": "submitted by    /u/jogai-san  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmu59u/nextcloud_all_in_one_updated_for_v25_not_mine/",
          "publishedOn": "2022-12-15T19:46:15.000Z",
          "wordCount": 17269,
          "title": "Nextcloud All In One updated for v25 [not mine]",
          "imageUrl": "https://external-preview.redd.it/ULQUMvEp-Ud3QFakG1E6-tzDLlu_Q0PQhSS5ACKUa_Y.jpg?auto=webp&s=89ad726cad77c362f2646101f887d8fa3b2d6f8b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmtkh1/ntfy_android_app_v1160_persubscription_soundsdnd/",
          "author": null,
          "description": "submitted by    /u/binwiederhier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmtkh1/ntfy_android_app_v1160_persubscription_soundsdnd/",
          "publishedOn": "2022-12-15T19:22:32.000Z",
          "wordCount": 19178,
          "title": "ntfy Android app v1.16.0 🥳 - per-subscription sounds/DND, insistent alert-style notifications, adaptive launcher icons",
          "imageUrl": "https://external-preview.redd.it/-oJd03D-zX1SXDY7BanxD1beWfmbOZVR_AIvCXns8uI.jpg?auto=webp&s=5419349fb68e9d3eb21128fabc93bb06e2193723"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmscje/nginx_proxy_manager_timezone_incorrect_how_to/",
          "author": null,
          "description": "I've setup NPM in Docker and the creation time (for SSL certs, hosts etc) is not the correct time.\n How can I change this? Any one have a clue?\n    submitted by    /u/Panja0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmscje/nginx_proxy_manager_timezone_incorrect_how_to/",
          "publishedOn": "2022-12-15T18:32:06.000Z",
          "wordCount": 17958,
          "title": "Nginx Proxy Manager - Timezone incorrect; how to change?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmr54x/medusa_the_os_shopify_alternative_just_made_a/",
          "author": null,
          "description": "I am one of the co-founders behind Medusa, a composable commerce platform built in TS/JS with a headless architecture.\n It is built out of frustration with current proprietary platforms that always forced us to build hacky workarounds whenever we tried to customize our setup.\n As devs frequently use this Selfhosted sub at Medusa, we wanted to start making our larger releases a bit more public here. Today, we'll make the first of such updates - happy to hear feedback if there are more things you'd like to hear more / less about.\n ​\n THE UPDATES\n  \n250x performance improvement: With our latest release of Medusa, we just made a huge breakthrough with a >250x performance improvement. This is obviously significant, and we will publish a comprehensive deep-dive on it soon. For now, you can enjoy…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmr54x/medusa_the_os_shopify_alternative_just_made_a/",
          "publishedOn": "2022-12-15T17:42:49.000Z",
          "wordCount": 19465,
          "title": "Medusa, the OS Shopify alternative, just made a 250x performance improvement",
          "imageUrl": "https://external-preview.redd.it/RYedSa4fwAU6dB8eGzq3D-g5e66KjCzHeNNtzqdn9vY.jpg?auto=webp&s=4f97ebdaa4a44e63c8111f0c4055ddfb006b6ff4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmqr79/help_a_newbie_to_set_up_domain_with_tailscale/",
          "author": null,
          "description": "I went through Tailscale's documentation, but they needed to be more precise about setting up the domain and mapping it to the device.\n Here is a brief about my condition - \n  \nI have hosted my services on a raspberry pi.\n \nI got a static IP with tailscale.\n \nI am using Nginx-proxy-manager to manage domains and mapping.\n \nGoal is to map my domain (purchased off go daddy) to be mapped with my tailscale account/device so that I can set up multiple sub-domains for my different services.\n \n I apologise if this question sounds a bit noob. I am fairly new to the Selfhosting side of the world!\n    submitted by    /u/shubhank1912  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmqr79/help_a_newbie_to_set_up_domain_with_tailscale/",
          "publishedOn": "2022-12-15T17:26:42.000Z",
          "wordCount": 19925,
          "title": "Help a newbie to set up domain with Tailscale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmq7x8/loving_frigate_nvr/",
          "author": null,
          "description": "Just wanted to take some time and rave about Frigate NVR. I just installed it a couple days ago on home assistant and wow. For my personal use, It blows Agent DVR (Which I had been using for several months) out of the water. Here are some of my favorite points:\n  \nAccuracy is phenomenal for AI detections. This was always an issue with Agent DVR for me. It would detect my oil tank and christmas lights as people with up to 80% confidence level. Even sunset shadows it would be up to 70% confident it was people. By the time I masked these out almost 1/2 of the screen was gone. Zero false positives so far with Frigate and no masks.\n Clips are so smooth.\n CPU (Not using Coral) usage is extremely low and getting 15 to 19ms inference times on Snapdragon 8cx Gen 3 (Running HAOS Arm64 as a Hyper-V VM on Windows Dev Kit 2023). This is something I could not have said when I was running Agent DVR. AI detection with CodeProject.AI was usually hitting 40-60% CPU utilization on a 12 core i5 1240p. Agent DVR always idled at around 12% CPU utilization.\n  \n​\n https://preview.redd.it/f5yt4y35w26a1.png?width=965&format=png&auto=webp&s=0aaaa5dbca2383c6fff63f3774b7e7ceba9e4059\n https://preview.redd.it/vscbalu2436a1.png?width=1097&format=png&auto=webp&s=9f8b63a1d47e8d3d2f76675998cfc4ead9782246\n    submitted by    /u/dro159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmq7x8/loving_frigate_nvr/",
          "publishedOn": "2022-12-15T17:05:04.000Z",
          "wordCount": 17433,
          "title": "Loving Frigate NVR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmpp74/authentik_npm_how_to_disable_authentication_for/",
          "author": null,
          "description": "I have Nginx Proxy Manager + authentik set up, authentication works great but I cannot find how to disable authentication for my own local network. I watched Cooptonioan's video but that only covers disabling MFA for the local network whereas my goal would be to trust anyone that connects from the local network (thus disabling authentication) which is absolutely needed for the wife acceptance factor. How can this be achieved?\n PS setup was done based on GeeksCircuit guide.\n Edit: typo\n    submitted by    /u/gogglesmurf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmpp74/authentik_npm_how_to_disable_authentication_for/",
          "publishedOn": "2022-12-15T16:44:21.000Z",
          "wordCount": 18600,
          "title": "Authentik + NPM: how to disable authentication for local network?",
          "imageUrl": "https://external-preview.redd.it/hMY1CAYCh37uQ-meQ_5acXRX8Q6iO-5s4wGDhcH74bQ.jpg?auto=webp&s=d682dcf765b0b999b9dc6cba495523acdd6f9a79"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmodzb/selfhosted_seo_tools_ahrefs_free_alternative/",
          "author": null,
          "description": "The free version of Ahrefs is very, very limited. Are any Self-Hosted Alternative SEO Tools like that?\n    submitted by    /u/intelligent-idiot-2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmodzb/selfhosted_seo_tools_ahrefs_free_alternative/",
          "publishedOn": "2022-12-15T15:50:45.000Z",
          "wordCount": 18879,
          "title": "Self-Hosted SEO Tools? Ahrefs Free Alternative.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmo9nm/picking_an_os_for_storage_array/",
          "author": null,
          "description": "I have an old phenom II based system that I intend to fill up with drives and leave in a corner. \n I have a few os options, originally i was going to install proxmox ve, truenas, home assistant, ubuntu for docker containers, windows ect. I would like to just run windows server as a host os because if there is an issue in windows there is a much higher chance of me being able to fix it on my own without hours of googleing. I would like to have a standard smb share for my files, raid 10 6 hdd probably, but i would also like some sort of web interface that i can upload or download files from if i can't use smb for whatever reason. I have been told by people that storage spaces in windows is a nightmare though.\n Any advice will be greatly appreciated.\n    submitted by    /u/Peewee_Doggi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmo9nm/picking_an_os_for_storage_array/",
          "publishedOn": "2022-12-15T15:45:57.000Z",
          "wordCount": 18995,
          "title": "picking an os for storage array",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmi1kf/what_kind_of_storage_bay_are_you_using/",
          "author": null,
          "description": "Hi, \n I am selfhosting a lot of services like plex, nextcloud, adguard, ... and I would like to have good perf for R/W for the services.\n Specs: - I have multiple proxmox host for HA (like Dell optiplex) - I use the ZFS features (so this storage will be on ZFS). - Storage should be on 10Gb \n I think all the virtual disks would be on this new storage but there is a problem because I need : - SSD (good perf) for virtual disks of VMs - HDD for data (like movies, doc, pic, ...)\n --> So I think I would go with 2 zfs pools\n My questions are : - Which bay storage (with ECC Ram) should I use for my case ? SAN, NAS, DAS ? - What's the size of your pool and what kind of disk? - Where are your virtual disk, host side or dedicated storage reachable via NFS ? \n Thanks\n    submitted by    /u/hafx_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmi1kf/what_kind_of_storage_bay_are_you_using/",
          "publishedOn": "2022-12-15T10:36:48.000Z",
          "wordCount": 17255,
          "title": "What kind of storage bay are you using ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zmdc1c/dropin_replacement_for_xbrowsersync_api_that_is_a/",
          "author": null,
          "description": "submitted by    /u/mrusme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zmdc1c/dropin_replacement_for_xbrowsersync_api_that_is_a/",
          "publishedOn": "2022-12-15T05:38:25.000Z",
          "wordCount": 18634,
          "title": "Drop-in replacement for xBrowserSync API that is a single binary and supports SQLite3, PostgreSQL and MySQL",
          "imageUrl": "https://external-preview.redd.it/sZmmj54DsGYpxa6WEj1VgxjnY67zc1nEgK9wSd5hcPQ.jpg?auto=webp&s=7b204c4546c710a598716c130856fb8186795129"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm9725/favorite_web_based_apps_that_are_not_plex_or_emby/",
          "author": null,
          "description": "What’s your favorite self hosted web browser based apps that are not media related? Like notes, productivity… ect…\n    submitted by    /u/Fission455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm9725/favorite_web_based_apps_that_are_not_plex_or_emby/",
          "publishedOn": "2022-12-15T02:05:15.000Z",
          "wordCount": 19310,
          "title": "Favorite web based apps that are not plex or emby?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm8jeo/automotive_forum_archiving/",
          "author": null,
          "description": "I've been poking around trying to find a solution for archiving threads from various automotive forums. For anyone who doesn't use these forums, they have been dying over the years as people move to other social media platforms and with the decline in usage comes a decline in maintenance. Sometimes all the images disappear, videos get removed, or whole forum domains go down. Most of what's on these forums isn't super useful but there's a handful of threads showing highly custom stuff that is relevant to my own projects.\n I would like to be able to archive a thread in its entirety for later reference to include images, videos, and other links. I played around with ArchiveBox some and archiving with a link depth of 1 seems to gather all that, but also grabs all the other irrelevant links that are on a forum page that I don't care for. I also can only archive a thread one page at a time using ArchiveBox, which doesn't work for threads that might go on for hundreds of pages.\n I did some research and I think what I am looking for is a web scraper tool that can snag all the thread posts and associated links on a page, then cycle to the next page in the thread and repeat until all the pages have been archived....so with all that being said I am looking for recommendations for tools that might fit this use case.\n Since I don't think there's much overlap between self hosters and people who frequent the forums (though I might be wrong) here are two links of example threads that I would love to make sure I have indefinite access to (so long as I maintain my homelab).\n  \nExample 1\n Example 2\n  \n   submitted by    /u/Blackhawk706  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm8jeo/automotive_forum_archiving/",
          "publishedOn": "2022-12-15T01:34:39.000Z",
          "wordCount": 17158,
          "title": "Automotive Forum Archiving",
          "imageUrl": "https://external-preview.redd.it/otFsC595e7JriWlRKBRpl16-sLXjaC4MXGmjZkY03Q0.jpg?auto=webp&v=enabled&s=09be11fbaa68ff2a3025af1a732df282e787e4dc"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm8cd4/no_access_to_clipboard_for_nextcloud/",
          "author": null,
          "description": "I wonder if anybody else is having this problem: I'm one of the hosts of mintCast, I also manage the mintCast.org web server on a raspberry pi in my basement. In addition to that I host a Nextcloud instance that we use for our infrastructure. Though I've got Nextcloud running on bare metal, I've got the collabora server running in a docker container on the same machine. All of this is sitting behind and Nginx reverse proxy manager which itself is running in a docker container. The problem I'm having is when I try to embed calendars from next cloud onto the WordPress site I get an error on next cloud saying it cannot copy the HTML code to the clipboard. All of the SSL is sorted. Everything behind the reverse proxy has a self-signed certificate which the proxy trusts and then Nginx handles the external stuff with let's encrypt. I've also noted that I cannot copy and paste directly onto next cloud office documents. At least not with the mouse I have to use control v etc. I'm wondering if there's something I need to pass to the reverse proxy to give stuff like next cloud behind the rivers proxy access to the clipboard. If anybody knows anything about this I would greatly appreciate it\n    submitted by    /u/wchouser3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm8cd4/no_access_to_clipboard_for_nextcloud/",
          "publishedOn": "2022-12-15T01:25:37.000Z",
          "wordCount": 17024,
          "title": "no access to clipboard for nextcloud",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm796e/run_your_own_raspberry_pi_based_translation/",
          "author": null,
          "description": "submitted by    /u/smarxx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm796e/run_your_own_raspberry_pi_based_translation/",
          "publishedOn": "2022-12-15T00:36:06.000Z",
          "wordCount": 16611,
          "title": "Run Your Own Raspberry Pi Based Translation Service With LibreTranslate",
          "imageUrl": "https://external-preview.redd.it/NoOess-o2TuKcg8yF8X3-Da5GTSzMi9wE8lycP6wLmY.jpg?auto=webp&v=enabled&s=0235ca79b7ce84d7e9372746b22e1d4bb406a08c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm78om/adguard_home_breaks_steam_connection_sometimes/",
          "author": null,
          "description": "Hey there. I am very sure that my self-hosted AdGuard Home container is causing problems for me.\n I am currently often playing Modern Warfare 2 in the evening / night and I am playing and the Steam connection is randomly lost. First I thought of the Steam servers of course but I'm the only one with problems. It happens every day or at least every second day. And then the connection is lost and won't reconnect for at least 5 minutes I guess. Then it often works again.\n I tried to change the DNS server in the settings of my ethernet adapter on Windows 11 (to 8.8.8.8 e.g. instead of the local server) where I have my server 192.168.178.xx and as second 1.1.1.1 and flushed the DNS and it instantly worked again. So it seems to be that it has something to do with my DNS by AdGuard Home. But how the hell I am I supposed to really validate it or better fix it?\n The internet stays online while this disconnect in Steam is happening. Everything keeps working. Only Steam is not.\n Does anybody have an idea? I am pretty sure its caused by the DNS...\n    submitted by    /u/CptDayDreamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm78om/adguard_home_breaks_steam_connection_sometimes/",
          "publishedOn": "2022-12-15T00:35:29.000Z",
          "wordCount": 16337,
          "title": "AdGuard Home breaks Steam connection sometimes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm6l61/zabbix_on_oci_arm_instance/",
          "author": null,
          "description": "Hi All\n I'm curious, is anybody running Zabbix on a OCI ARM instance? \n If so, do you have a docker-compose you could kindly share, I'm having no luck with it.\n Thanks\n    submitted by    /u/Fluffer_Wuffer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm6l61/zabbix_on_oci_arm_instance/",
          "publishedOn": "2022-12-15T00:06:45.000Z",
          "wordCount": 16826,
          "title": "Zabbix on OCI ARM instance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm5qym/one_large_disk_nas_set_up_unraid/",
          "author": null,
          "description": "I love unRAID I have 2 setups. I've got a dedicated HP-109a with VMs and about 30 dockers. and I've had an HP microserver N40L running for over 10 years, most of it running on unRAID. It's got about 7 disks in It. Some 4TB, 3TB, 2TB etc.. About 15TB in total. N40L is getting a bit old now.. it for the most part shares out large media files over jellyfin. \n Was thinking of just getting 1 x 20TB disk in the HP-109a and having that as my NAS and container server & VMs.. it should handle the load OK.. i Can keep the N40L as an offline backup... I can live with loosing a week or so of data without parity. Don't think I need the RAID performance.. any other considerations?\n    submitted by    /u/matda59  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm5qym/one_large_disk_nas_set_up_unraid/",
          "publishedOn": "2022-12-14T23:30:18.000Z",
          "wordCount": 16860,
          "title": "One large disk NAS set up (unRAID)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm5f01/databasespreadsheet_for_logging_and_rating_movies/",
          "author": null,
          "description": "I used to do this in spreadsheets, then I switched over to doing it in obsidian, now I'm wondering if there is a good selfhosted option for it?\n Most googling/searching brought me to baserow, which does accomplish these feet, but seems kinda overkill and resource heavy for this use.\n I was about to dive into NocoDB next, but since I'm struggling, figured I'd chime in here to see if anyone had any recommendations.\n    submitted by    /u/rectal_rocket  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm5f01/databasespreadsheet_for_logging_and_rating_movies/",
          "publishedOn": "2022-12-14T23:16:22.000Z",
          "wordCount": 16430,
          "title": "Database/spreadsheet for logging and rating movies, games, etc",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm50up/host_crashes_when_vm_puts_load_on_hardware/",
          "author": null,
          "description": "submitted by    /u/caffeineshock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm50up/host_crashes_when_vm_puts_load_on_hardware/",
          "publishedOn": "2022-12-14T23:00:14.000Z",
          "wordCount": 17198,
          "title": "Host crashes when VM puts load on hardware",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm4lv0/backups_pre_and_postcommandaware_backup_solution/",
          "author": null,
          "description": "I am looking at Restic, BackupPC and Borg right now and trying to figure out if either of them support pre- and post-commands.\n The reason is that I would like to run a few exporters first, like so:\n ``` sysupgrade -b $outname.tar.gz # Also supports printing to STDOUT, but its always .tar.gz mysqldump ... # To dump all tables, users, ...\n ... others ...\n rsync serve $type wasabi-crypt:/backups ```\n After that, I might want to run cleanup commands.\n I will be running this on: - GNU/Linux, Debian 11 - linux, OpenWrt\n As for my windows maschines, it's quite straight forward: just a directory list and possibly LudoSavi... but thats a worry for another day. First, I need to get my cruicial infrastructure (router, servers) backed up.\n As for the backend: I am using Wasabi with an encryption setup - I want to use it as my off-site backup, purely. Hence rclone mount .... I did see Restic can do that on it's own (making me believe it might just consume the RClone API) but I am not sure if Borg can.\n In the end, I am also not sure if I want to use multiple repositories or not; probably depends on the program.\n Would love if you could give me some input on this! Thanks so much :)\n    submitted by    /u/IngwiePhoenix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm4lv0/backups_pre_and_postcommandaware_backup_solution/",
          "publishedOn": "2022-12-14T22:42:52.000Z",
          "wordCount": 17017,
          "title": "Backups: Pre- and Post-command-aware backup solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm3unm/plex_app_on_samsung_required_internet_connection/",
          "author": null,
          "description": "Yesterday , my internet connection was down and also cable tv, same company etc etc , and i have configure plex both in the app and in the server that you can look up for servers in the same network , but , when internet is down ... it can ... Why ? the samsung app is bad ?\n    submitted by    /u/HauteDense  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm3unm/plex_app_on_samsung_required_internet_connection/",
          "publishedOn": "2022-12-14T22:12:00.000Z",
          "wordCount": 16245,
          "title": "Plex app on samsung required internet connection , is there any way avoiding this ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm338f/im_really_struggling_to_install_vikunja/",
          "author": null,
          "description": "I would rather self -host on my own computer. So from my understanding i need two things\n  \nBack-end service (the one that has vikunja-unstable-windows-4.0-386.exe in the folder)\n Front-end service such as the desktop client\n  \nStandard ports are already taken by XAMPP and i haven't configured \"config.yml.sample\" BUT for the sake of testing I don't have xampp running.\n I tried running it out of the box but the last line of code is:\n 2022-12-14T16:38:02.8258504-05:00: INFO ▶ [EVENTS] 093 Starting handler, subscriber_name=namespace.created.namespace.counter.increase, topic=namespace.created \n Meanwhile it says at the first lines\n 2022/12/14 16:38:02 No config file found, using default or config from environment variables. 2022-12-14T16:38:02.8222434-05:00: INFO ▶ migration/Migrate 04e Ran all migrations successfully. \n I'm pretty sure to configure the yaml file i need to remove .sample but it should work out of the box without configuring it right? Mind you during this test i'm not running any server on localhost.\n I run the client and the prompt says\n An error occurred: TypeError: Failed to construct 'URL': Invalid URL Please check if the api url is correct. \n After inserting the default port in the address:\n Could not find or use Vikunja installation at \"localhost\". Please try a different url. \n What do i do now?\n    submitted by    /u/Eriane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm338f/im_really_struggling_to_install_vikunja/",
          "publishedOn": "2022-12-14T21:41:27.000Z",
          "wordCount": 16969,
          "title": "I'm really struggling to install vikunja",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm2gsn/ssl_cert_on_an_iis_intranet/",
          "author": null,
          "description": "Trying to follow the steps on this page and am stuck at the \"http://{certserver}/certsrv\" step. Not sure what I should be putting in the \"certserver\" spot. Any ideas? \n Preventing browser security warnings for an Intranet site using an SSL Certificate generated by a Windows Domain CA | Sid's FishNet (wordpress.com)\n    submitted by    /u/ITAccount17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm2gsn/ssl_cert_on_an_iis_intranet/",
          "publishedOn": "2022-12-14T21:16:41.000Z",
          "wordCount": 16652,
          "title": "SSL Cert On An IIS Intranet",
          "imageUrl": "https://external-preview.redd.it/BW0OA2q2KiuraOrkTX_bo_GiSIFzr4xx08xVrQpGEJ4.jpg?auto=webp&v=enabled&s=595bde87e50ee81e8ec9fa754f81be1d4df0f5cd"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm1tc7/introducing_tailnet_lock_use_tailscale_without/",
          "author": null,
          "description": "submitted by    /u/bik1230  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm1tc7/introducing_tailnet_lock_use_tailscale_without/",
          "publishedOn": "2022-12-14T20:49:37.000Z",
          "wordCount": 17209,
          "title": "Introducing tailnet lock: use Tailscale without trusting our infrastructure!",
          "imageUrl": "https://external-preview.redd.it/qkp17_YDpdrBD4w-Z5hK5jxhFlLk9CVMWFOl3-jwicc.jpg?auto=webp&v=enabled&s=9310f6d4228dec3a51e13138cdc76c09a3cd41b4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zm1rty/network_file_share_with_sso/",
          "author": null,
          "description": "I currently have an instance of authentik on my server which I use for SSO with my other apps, I'm now looking to add a network file share but I'd like to use the same SSO. incant seem to find anything that fits this, initially I thought that samba would be configurable enough to point at authentik but Ive not been able to find any info on doing that.\n    submitted by    /u/samishal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zm1rty/network_file_share_with_sso/",
          "publishedOn": "2022-12-14T20:47:52.000Z",
          "wordCount": 16804,
          "title": "Network File Share with SSO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlxwm9/do_you_use_one_dashboard_for_each_host_or_a/",
          "author": null,
          "description": "I love flame because is minimal and automatically creates the link based on labels defined on the docker-compose.yml...but at the moment I have 6 different server with 6 different Flame dashboards and is becoming a bit annoying.\n I could create a single one, but then I have to maintain up to date manually...\n View Poll\n    submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlxwm9/do_you_use_one_dashboard_for_each_host_or_a/",
          "publishedOn": "2022-12-14T18:07:39.000Z",
          "wordCount": 17055,
          "title": "Do you use one dashboard for each host? or a single dashboard for everything?",
          "imageUrl": "https://external-preview.redd.it/8vnUwnFRO5ECAUz8AJOLHiHh_Z3idaJVa4Z6trtPSpI.jpg?auto=webp&v=enabled&s=469edcce33c172712b2c0d46b2d1aa75ae67ef44"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlx3yo/what_are_the_benefits_and_drawbacks_of_self/",
          "author": null,
          "description": "Absolute noob and extremely clueless and I’m been thinking of trying to self host my own cloud server, maybe vpn or ad block and financial and privacy benefits I was curious curious what made you embark on this journey\n    submitted by    /u/cursedblueberries  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlx3yo/what_are_the_benefits_and_drawbacks_of_self/",
          "publishedOn": "2022-12-14T17:36:53.000Z",
          "wordCount": 20570,
          "title": "What are the benefits and drawbacks of self hosting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlx3lq/youtube_monitor/",
          "author": null,
          "description": "Hey guys, I'm looking for a self-hosted solution that can monitor multiple youtube channels and/or playlists for uploads and notifies the user/sends an API request to an existing youtube-dl server to download them.\n    submitted by    /u/neptune909  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlx3lq/youtube_monitor/",
          "publishedOn": "2022-12-14T17:36:28.000Z",
          "wordCount": 16307,
          "title": "YouTube monitor",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlsz3i/christmas_gift_ideas_for_someone_involved_in/",
          "author": null,
          "description": "I have a family member super into Self-hosting and has their own server in their house.\n Was just wondering if there was any good christmas present ideas which someone involved in self-hosting would want but wouldn't invest time/money into as I know its already a very budget-orientated passion!\n Thanks for any of your help!\n    submitted by    /u/TylerWebb_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlsz3i/christmas_gift_ideas_for_someone_involved_in/",
          "publishedOn": "2022-12-14T14:51:53.000Z",
          "wordCount": 18124,
          "title": "Christmas Gift Ideas for someone involved in SelfHosting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlsxns/run_your_own_selfhosted_transcription_and/",
          "author": null,
          "description": "I just wrote up some docs for my generate-subtitles project which is a wrapper around OpenAI's Whisper and includes Libretranslate for automatic translation.\n You can run your own server using the instructions here: https://github.com/mayeaux/generate-subtitles\n Or test it out on my instance which is open for free use online at https://freesubtitles.ai, cheers!\n    submitted by    /u/meddit_app  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlsxns/run_your_own_selfhosted_transcription_and/",
          "publishedOn": "2022-12-14T14:50:16.000Z",
          "wordCount": 18346,
          "title": "Run your own self-hosted transcription and automatic translation service powered by OpenAI's Whisper",
          "imageUrl": "https://external-preview.redd.it/uEEDj0fgmPN-zpcjSmtDa1lp9szymoxz2BjkTvNRRj4.jpg?auto=webp&v=enabled&s=aa3a77b5304408c9436175c02b096f0dfff4e757"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlr4ek/finally_setup_my_homepage_dashboard/",
          "author": null,
          "description": "submitted by    /u/The_Dogg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlr4ek/finally_setup_my_homepage_dashboard/",
          "publishedOn": "2022-12-14T13:36:25.000Z",
          "wordCount": 17839,
          "title": "Finally setup my Homepage dashboard",
          "imageUrl": "https://preview.redd.it/yg0eur9n9v5a1.png?auto=webp&v=enabled&s=e2ea5d26a9e7bc368385c31dff431f4bc1265137"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlp0ml/lets_talk_thermostats/",
          "author": null,
          "description": "Any thermostats for my house that have an API that I can use to pull data for things like current temperature, heat/AC on/off status? \n Im not really familiar with IoT devices or other small network connected things. I'd like to stay away from anything that requires a 3rd party \"cloud\" service as a requirement to use.\n    submitted by    /u/krakah293  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlp0ml/lets_talk_thermostats/",
          "publishedOn": "2022-12-14T11:54:23.000Z",
          "wordCount": 16320,
          "title": "Let's talk thermostats.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlo463/ultimate_docker_to_podman_migration_guide/",
          "author": null,
          "description": "Hello Selfhosters! \n Many of you have probably followed or are familiar with my Docker Media Server guide. Recently, we published a comparison of Docker vs Podman and since then we received a few requests for a guide to move from Docker to Podman.\n So here is our detailed guide on moving from Docker to Podman - written by u/krair3\n Feel free to check it out and share your thoughts.\n    submitted by    /u/htpcbeginner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlo463/ultimate_docker_to_podman_migration_guide/",
          "publishedOn": "2022-12-14T11:02:18.000Z",
          "wordCount": 23858,
          "title": "Ultimate Docker to Podman Migration Guide",
          "imageUrl": "https://external-preview.redd.it/nCgjb1sB1GmkbG4Q2Ki9PPFFXZd9vxA7C-m3q3woNNU.jpg?auto=webp&v=enabled&s=10255c6392be995e812815e39ee4d1747a4b037d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlmpej/framasoft_which_develops_peertube_and_promote/",
          "author": null,
          "description": "submitted by    /u/raybb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlmpej/framasoft_which_develops_peertube_and_promote/",
          "publishedOn": "2022-12-14T09:35:30.000Z",
          "wordCount": 17456,
          "title": "Framasoft, which develops PeerTube and promote FLOSS from France are hosting an AMA!",
          "imageUrl": "https://external-preview.redd.it/75rSLWh_2hGrROPlm7aU7Gr0PJ7ZFSmtpOlTC1FahGY.jpg?auto=webp&v=enabled&s=55dec15d22a3af99deed3c0c17972c643db1439a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlg3q2/wanjohiryanqwantify_play_games_with_your_friends/",
          "author": null,
          "description": "submitted by    /u/Evil__Maid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlg3q2/wanjohiryanqwantify_play_games_with_your_friends/",
          "publishedOn": "2022-12-14T03:25:21.000Z",
          "wordCount": 22002,
          "title": "wanjohiryan/qwantify: Play games, with your friends right from the browser. No installation needed.",
          "imageUrl": "https://external-preview.redd.it/rRmz2x7-K-PzxgamlDhhdDtQsdsmarjkHTbYbwNQ638.jpg?auto=webp&v=enabled&s=ed60e324fd58ccd6c1829ef215412a9a5edcf1e8"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlcrad/fix_status_indicators_for_non_arr_apps_added_to/",
          "author": null,
          "description": "Is there any way to fix the \"status\" indicator for non -arr apps added to Homarr?\n I don't use -arr services right now, but I like Homarr as my dashboard. Unfortunately, the little \"online\" indicators all show as offline, except for Dash. (dashdot). I know the services are online, but not sure how to fix this.\n I can remove these indicators by toggling the option within the advanced options tab, but it'd be nice to have a quick visual status indicator.\n Any ideas?\n First picture shows NPM as offline, but pings show otherwise.\n    submitted by    /u/radakul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlcrad/fix_status_indicators_for_non_arr_apps_added_to/",
          "publishedOn": "2022-12-14T00:57:29.000Z",
          "wordCount": 16801,
          "title": "Fix status indicators for non -arr apps added to Homarr?",
          "imageUrl": "https://external-preview.redd.it/C5Ze1dn7H9hTdcc9w4Vc2213_-SUopVV94ATuZ94P-g.jpg?auto=webp&s=3555f1d2b9577d7056d8d942a1cd5e951824b610"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlbk74/nginx_proxy_manager_lan_requests_cant_reach_proxy/",
          "author": null,
          "description": "I have an Unraid server connected to a router that is using a DynDNS service to forward traffic from my subdomain (seafile.example.com). I am using NPM to catch network traffic arriving through this DNS. I also have a PiHole as a local DNS and DHCP server. \n I can reach the proxy host when I access the subdomain from outside my local network (i.e. using my phone's cellular data) but I am unable to reach the host locally. I am able to reach the proxy host through the IP address+port directly on LAN. \n Any help is greatly appreciated, thanks!\n    submitted by    /u/Gordogato81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlbk74/nginx_proxy_manager_lan_requests_cant_reach_proxy/",
          "publishedOn": "2022-12-14T00:06:21.000Z",
          "wordCount": 16839,
          "title": "Nginx Proxy Manager: LAN requests can't reach proxy host via domain requests, but WAN requests can",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zlau5x/monica_alternative_with_photo_gallery/",
          "author": null,
          "description": "Been searching for this for a while and just couldn't find anything like it. Checked monica but couldn't find that feature on it anywhere. \n I'm looking for something basically like monica, but where you can create a photo gallery for each contact. Or something like a social network but without other accounts where I can save notes and photos. \n Does anyone have any kind of recommendation? Maybe even some software that isn't designed for it, but can work easily in that way? Also don't need the notifications part, if that helps\n    submitted by    /u/ctaeth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zlau5x/monica_alternative_with_photo_gallery/",
          "publishedOn": "2022-12-13T23:36:18.000Z",
          "wordCount": 16779,
          "title": "Monica alternative with photo gallery?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zla0vh/how_do_you_give_an_ip_with_a_port_its_own_local/",
          "author": null,
          "description": "I am just getting into self hosting and I've started witha pihole and docker compose on my windows PC.\n I've installed Nginx, pihole and tailscale on my Pi zero W. (Nginx and tailscale dont work well but thats another issue).\n I've installed photoprism, komga, plex, tautulli and portainer on my desktop with docker compose.\n To access all my desktop docker applications its 192.168.X.X:port. Is there a way that I can give all these applications a local domain such that photoprism is photoprism.local?\n    submitted by    /u/_BluePineapple  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zla0vh/how_do_you_give_an_ip_with_a_port_its_own_local/",
          "publishedOn": "2022-12-13T23:04:19.000Z",
          "wordCount": 16813,
          "title": "How do you give an Ip with a port its own local domain?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl9y0o/soi_came_home_and_wanted_to_take_a_snapshot_of_my/",
          "author": null,
          "description": "After taking the snapshots, I try to SSH into them and nothing. So I go back, log in via the ESXI webpage and see that all my Linux VMs are now booting in emergency mode. No errors on ESXI and Linux says emergency mode. Has anyone experienced this?\n    submitted by    /u/limskey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl9y0o/soi_came_home_and_wanted_to_take_a_snapshot_of_my/",
          "publishedOn": "2022-12-13T23:01:12.000Z",
          "wordCount": 1879,
          "title": "So…I came home and wanted to take a snapshot of my ESXI VMs…but….",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl6nc2/problems_configuring_changedetectionio/",
          "author": null,
          "description": "Hi there,\n I have setup changedetection.io in a Docker and set up some test scenarios. \n I can't figure out how i can trigger from a class change. The Website I am trying to monitor has an <li class=\" signup inactive\">Signup</li> and changes it to something like <li class=\"signup active\"><a href=\"\">Signup</a></li>. how do I detect this change? I tried this with a test website but I can't get it to work since the Text dosn't change on the page. Can anyone help?\n    submitted by    /u/sasleu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl6nc2/problems_configuring_changedetectionio/",
          "publishedOn": "2022-12-13T20:54:32.000Z",
          "wordCount": 17141,
          "title": "Problems Configuring changedetection.io",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl5fub/struggling_to_get_monica_crm_working_with_ssl/",
          "author": null,
          "description": "The subject says it all, but I wanted to clarify that this is for my internal LAN with a URL of something like https://monica.int.foo.com:8080/. (This is a FQDN.) I have seen the docs and followed the various tips including adjusting APP_URL, APP_ENV and APP_FORCE_URL. Whenever I switch APP_URL to https, the site becomes inaccessible with an SSL error.\n Here are the configs: https://pastebin.com/Qccwu1LN\n As an aside, I poked around the Apache configs in the Docker container and was curious to see that there is no SSL conf in sites-enabled. There is a config in sites-available, but I think that the path to the SSL certs is wrong. Could this be causing the issue?\n It feels like, \"it just works\" for most people here, but for whatever reason, I have had nothing but problems configuring SSL. (HTTP works fine.)\n TIA\n    submitted by    /u/JL_678  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl5fub/struggling_to_get_monica_crm_working_with_ssl/",
          "publishedOn": "2022-12-13T20:07:00.000Z",
          "wordCount": 18058,
          "title": "Struggling to get Monica CRM working with SSL",
          "imageUrl": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&v=enabled&s=decc328886393c0699bb01cf9d08b602f60525c8"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl58kb/github_tailscalegolink_a_private_shortlink/",
          "author": null,
          "description": "submitted by    /u/redsashimi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl58kb/github_tailscalegolink_a_private_shortlink/",
          "publishedOn": "2022-12-13T19:59:26.000Z",
          "wordCount": 16104,
          "title": "GitHub - tailscale/golink: A private shortlink service for tailnets",
          "imageUrl": "https://external-preview.redd.it/hL3TOhfduw5xaU11iMDUla5EdWb4ZpJtP24Hp7RZsXE.jpg?auto=webp&v=enabled&s=f13aa73426ac9c44af1781041c04f0638f856c7d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl3weu/short_guide_on_custom_css_for_flame/",
          "author": null,
          "description": "Hi everyone\n I found recently the Flame dashboard and really liked the look. I had no experience in customizing such things, but found out how to do it myself and am happy to share. Hopefully it will be helpful for someone out there! :)\n I know it's not a big deal, however, I am still happy about this achievement.\n Dashboard repository: https://github.com/fdarveau/flame \n My Guide: https://github.com/DevGoran/Flame-Custom-CSS-Guide\n Any recommendation or feedback is welcome.\n    submitted by    /u/gripfly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl3weu/short_guide_on_custom_css_for_flame/",
          "publishedOn": "2022-12-13T19:05:32.000Z",
          "wordCount": 19482,
          "title": "Short guide on custom CSS for Flame",
          "imageUrl": "https://external-preview.redd.it/8EtLkLQ8No6VnMsA71YuLE7Z6kckgPVGF3FWS3p0y2s.jpg?auto=webp&s=1e8ef4d79bdd15914127d5ec901d2458eaa42a04"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl1svo/piwigo_and_syncthing/",
          "author": null,
          "description": "I want to use piwigo as my full time Google photos alternative and everytime I connect to my network I want my pictures to he backed up to my home server and I have syncthing setup for that, now I'm running both on docker and both point to a common directory ( /gallery in piwigo), how can I import those photos into my piwigo instance to view them?\n I tried going to the dashboard and doing Quick Sync, but it uses ./galleries/ which I can't find on my piwigo instance using the shell and when I try to add /gallery as a site it says the directory doesn't exist.\n If there's any other better way to sync my gallery with piwigo I would love to hear it, I'm using Android.\n I did try to use photoprism and lychee too but they didn't play well with syncthing and I didn't find any free ways to sync my gallery with either of them\n ​\n This is my docker compose for both syncthing and piwigo\n Edit: I checked with the entire file system and just had to route the shared folder of syncthing and piwigo to /gallery/galleries in the piwigo instance\n    submitted by    /u/XenoDan_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl1svo/piwigo_and_syncthing/",
          "publishedOn": "2022-12-13T17:44:50.000Z",
          "wordCount": 17039,
          "title": "Piwigo and syncthing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zl0xjv/vpn_issue_with_yunohost_that_has_been_bugging_me/",
          "author": null,
          "description": "I wanted to use the VPN client with my self hosted Yunohost but keep running into issues. I tried 4 different VPN's and as of this morning purchased a new dedicated IP with a new services.\n ​\n https://yunohost.org/en/providers/vpn\n ​\n https://github.com/YunoHost-Apps/vpnclient_ynh\n ​\n Now the issue is this, after uploading the config file ( ovpn ) through webadmin, it gives this message:\n ​\n WARNING - Job for openvpn@client.service failed because a timeout was exceeded. \n WARNING - See \"systemctl status openvpn@client.service\" and \"journalctl -xe\" for details. WARNING - tail: cannot open '/var/log/openvpn-client.log' for reading: No such file or directory \n ​\n When I SSH in and run \"systemctl status openvpn@client.service\", I get this message\"\n ​\n  DEPRECATED OPTION: --cipher set to 'AES-128-CBC' but missing in --data-ciphers (AES-256-GCM:AES-128-GCM). Future OpenVPN version will ignore --cipher for cipher negotiations. Add 'AES-128-CBC' to --data-ciphers or change --cipher 'AES-128-CBC' to --data-ciphers-fallback 'AES-128-CBC' to silence this warning. \n How do I add to Data Cipher as mentioned?\n    submitted by    /u/xkingxkaosx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zl0xjv/vpn_issue_with_yunohost_that_has_been_bugging_me/",
          "publishedOn": "2022-12-13T17:11:20.000Z",
          "wordCount": 1976,
          "title": "VPN issue with Yunohost that has been bugging me!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkyp9z/forms_builder_with_prefill_from_url_function/",
          "author": null,
          "description": "Hello, Reddit! (Sorry for my english)\n I'm looking for a simple self-hosted Forms Builder with a really important feature. It should have an option to prefill some fields using attributes from URL\n I have an example - https://github.com/ohmyform/ohmyform\n So if i'll use link http://myip:5200/form/gdR6dx?field1=text1 I'll get prefilled field \"field1\" with \"text1\"\n I guess you've got the idea. But this APP is buggy and is not really supported how I can see. So I'm looking for another one with same feature\n Also https://forms.yandex.com/ provide the same feature, but it's not a self-hosted app\n https://cloud.yandex.com/en-ru/docs/forms/pre-fill\n I checked a few posts with same topic but didn't find exactly what I'm looking for\n Apps which I already tried:\n https://github.com/ohmyform/ohmyform\n https://github.com/Budibase\n https://github.com/formio/formio\n Thanks for your help!\n    submitted by    /u/LittleShok  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkyp9z/forms_builder_with_prefill_from_url_function/",
          "publishedOn": "2022-12-13T15:40:56.000Z",
          "wordCount": 18177,
          "title": "Forms Builder with \"prefill from url\" function",
          "imageUrl": "https://external-preview.redd.it/DV1lEUgPol4XLquQ4y1_kt1Tzf1-jyLnghC9aPJwgzY.jpg?auto=webp&s=53044a6a37c4f675b656fdf4204268b31fe05765"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkxyl0/i_need_ideas_for_my_new_project/",
          "author": null,
          "description": "Hey there,\n I'm working on a open source self-hosted dashboard that has the following core functionalities: hardware monitoring and file storage/management. My goal is to make it as minimalistic and user friendly as possible. The current name I have in mind is X-Panel. I'm looking for suggestions for a good name and some more features for this web app. I want a name that is easy to remember and accurately reflects the functionality of the web app. Any suggestions or ideas for improving the current name or coming up with a new one would be greatly appreciated! I have also added some screenshots of the web interface.\n Thanks in advance for any help.\n ​\n https://preview.redd.it/8qjjknboko5a1.png?width=1920&format=png&auto=webp&s=bf1d67a50c411278f831357547784e748954dc2e\n https://preview.redd.it/4zouvqboko5a1.png?width=1920&format=png&auto=webp&s=6806e47c84e9db8b145a84ccef5eb33051c155d6\n https://preview.redd.it/b4ax8mboko5a1.png?width=1920&format=png&auto=webp&s=90fbbea103e46a897bc700a5f41e4d4f23ebdc11\n    submitted by    /u/Different_Carpet_479  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkxyl0/i_need_ideas_for_my_new_project/",
          "publishedOn": "2022-12-13T15:06:52.000Z",
          "wordCount": 17866,
          "title": "I need ideas for my new project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkxseh/anything_like_sendsafely_thats_free_and_can_be/",
          "author": null,
          "description": "submitted by    /u/ChrisOSSTMM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkxseh/anything_like_sendsafely_thats_free_and_can_be/",
          "publishedOn": "2022-12-13T14:59:29.000Z",
          "wordCount": 16421,
          "title": "Anything like sendsafely that’s free and can be self hosted? Thx",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkwgfe/most_secure_and_easy_way_to_store_photos/",
          "author": null,
          "description": "Hey everyone. I am trying to find a solution to store all the family photos on a VPS. I'd like to have end-to-end and server side encryption. Seafile seems ideal, but heard some critique regarding the way files are stored and issues that could happen if something happens to the database. \n We all use Apple devices, so syncthing is not so good either as their iOS app is really awful. \n Nextcloud feels very sluggish and OwnCloud Infinite Scale is very young with not lots of documentation (not even sure it has server side encryption).\n Any recommendations on that matter? Thanks!\n    submitted by    /u/WEZANGO  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkwgfe/most_secure_and_easy_way_to_store_photos/",
          "publishedOn": "2022-12-13T14:00:55.000Z",
          "wordCount": 17901,
          "title": "Most secure and easy way to store photos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkw21v/koreui_a_keycloak_login_theme/",
          "author": null,
          "description": "Hi all,\n I’m happy to present a new Keycloak login theme based od CoreUI.\n I started to develop this theme for myself, but I hope it will be useful to others too.\n You can find and download the theme on my github page.\n    submitted by    /u/nkelemen18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkw21v/koreui_a_keycloak_login_theme/",
          "publishedOn": "2022-12-13T13:42:53.000Z",
          "wordCount": 16436,
          "title": "Koreui a Keycloak login theme",
          "imageUrl": "https://external-preview.redd.it/wlbJlmWqA0iEvceUeSXLb3pWVUNXNQKQ7JYS47zJVb0.jpg?auto=webp&s=a43f1f478440ba781e6c5b91f857c5652097cbac"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkumqk/status_pages_with_manual_on_an_off_button/",
          "author": null,
          "description": "Hallo and greetings from Red Cross Germany.\n We are building an Intranet and I am looking for something like https://www.apple.com/support/systemstatus/ \n BUT something where I have the option to manually click or select what service is offline or online.\n uptime-kuma is cool but it lacks the manual Intervention. \n any help would be great :)\n    submitted by    /u/Exciting_Habit_129  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkumqk/status_pages_with_manual_on_an_off_button/",
          "publishedOn": "2022-12-13T12:33:39.000Z",
          "wordCount": 18203,
          "title": "status pages with manual on an off button?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zksbyf/learn_all_about_peertube_v5/",
          "author": null,
          "description": "submitted by    /u/Framasoft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zksbyf/learn_all_about_peertube_v5/",
          "publishedOn": "2022-12-13T10:17:52.000Z",
          "wordCount": 17140,
          "title": "Learn all about PeerTube v5!",
          "imageUrl": "https://external-preview.redd.it/EH2OKJVz-ec_6l8OGFc9jO9OcTwPnQvUrAxYp1ugvD0.jpg?auto=webp&s=5d2658d6c8cedba6a017047cef317cef91ee9606"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zks8xn/looking_for_seaweedfs_experiences/",
          "author": null,
          "description": "TLDR;\n I'm torn between wanting to use SeaweedFS and worrying about data availability/recoverability. Hence I am looking for some (long-term) experiences from people who have tried or are using SeaweedFS.\n Full story;\n I have been following SeaweedFS for quite some time and I loved it initially, however, as time progresses and I learned more about it I got a bit worried about its recoverability.\n I tested it locally and had some issues with it, but those were mainly due to my own lack of knowledge with regards to SeaweedFS and Linux. My failures are what made me initially doubt the recoverability potential of the software since I did have data-loss during my tests. Luckily it was only test-data.\n When you initially start reading about SeaweedFS it sounds really easy to set up and get started with, and it is, but there are so many things to be aware of when using it \"in production\" that are not always clear in the beginning. For example: The Filer *IS* a single point of failure if you don't back it up (even though the GitHub page states that there is no single point of failure). Or that it's best to use config files instead of cli parameters when running in production.\n On the other hand, if you know you need to keep these things in mind, then it doesn't really form an issue.\n I'm really torn between wanting to use SeaweedFS and worrying about data availability and recoverability, and I'm looking for some experiences from people that have tried it are using SeaweedFS, especially long-term use.\n    submitted by    /u/Stitch10925  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zks8xn/looking_for_seaweedfs_experiences/",
          "publishedOn": "2022-12-13T10:12:03.000Z",
          "wordCount": 17311,
          "title": "Looking for SeaweedFS experiences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zks324/simple_useful_apps_that_you_selfhost/",
          "author": null,
          "description": "Anything that you self-hosted recently that provoked a thought like \"hell, so simple, yet so useful. why haven't I found it before...\"? \n Lemme list a couple of things I \"discovered\" by myself:\n - miniflux - the best self-hosted rss ever. fast (due to spartan UI), yet extensible via customized CSS and tons of extensions. Integrates nicely with Mac's Reeder and Reeder app on iOS (which is an essence of brilliant UX/UI for me).\n - kanboard - extremely simple kanban board, still so powerful and elegant. An essence of extreme usefulness combined with almost no UI.\n - flame - a simple dashboard. Hell, I wish I found it before - it would save me a lot of time setting up my family's bookmarks. Being able to see different set of bookmarks depending on whether you're \"signed-in\" or not was the game changer for me.\n - metube - best tool to fetch YouTube music to feed your AzuraCast home radio\n    submitted by    /u/haksior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zks324/simple_useful_apps_that_you_selfhost/",
          "publishedOn": "2022-12-13T10:01:13.000Z",
          "wordCount": 20076,
          "title": "Simple, useful apps that you self-host?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkqtap/doomsday_drive/",
          "author": null,
          "description": "Long story short I have been trying to put together documentation together or more so a large list of items related to my self hosting setup, important personal information(not particular to self hosting) and resources for the items. This was originally brought up by my brother since my family more or less relies on alot of my self hosted items and would not know what to do if I \"got hit by a bus\". I'm calling this my doomsday drive, as I'm hoping to store this in a safe at my parents home and potentially safe within my home.\n ​\n I'm curious if anyone has any templates out there or has any ideas for this. My documentation has by no means been good and I'm trying to get better and by adding items into my notion.so account (not self hosted, may get smite'd for this).\n ​\n Edit:\n Taking all the feedback I received this is the plan I'm going with:\n  \nMoving from LastPass over to Bitwarden (this has been on my mind for awhile but this gave me the momentum to go through with it).\n Using https://github.com/potatoqualitee/eol-dr provided from u/felipefideli as a template for accounts and just general personal info that will be stored within Bitwarden.\n Continuing documentation and building a static website for the documentation with instructions of how to spin up the container as well as a copy of it so it can be ran on a rasp pi which will be stored in my parents safe. Will also be writing these in text(markdown) files as well, will be encrypted as well.\n Recovery codes are going to be stored within bitwarden as well as physical copies stored at my bank and at my parents safe, this is only in case something were to happen to my phone as my fiancé knows how to access it. \n Currently in the process of learning Ansible and setting up AWX so if something fails in the short term (like NVR) I will have templates to easily fix it.\n Continuing teaching my brother my environment.\n  \n   submitted by    /u/JANGxBANGER  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkqtap/doomsday_drive/",
          "publishedOn": "2022-12-13T08:36:28.000Z",
          "wordCount": 19335,
          "title": "Doomsday drive",
          "imageUrl": "https://external-preview.redd.it/gk5c58dd5_1T5gdwVU4V-F44A0FTpgI4H5Kbn_1Y3-I.jpg?auto=webp&v=enabled&s=6aef2c01d9930fb8983bb6e568da0e8250faf6be"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkpeok/les_pas_270/",
          "author": null,
          "description": "submitted by    /u/lespasapp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkpeok/les_pas_270/",
          "publishedOn": "2022-12-13T07:10:15.000Z",
          "wordCount": 16611,
          "title": "Les Pas 2.7.0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkl5ee/is_it_safe_to_leave_vaultwarden_login_page_public/",
          "author": null,
          "description": "I am self-hosting through Vaultwarden. I'm using Cloudlfare and nginx reverse proxy because, as you know, it requires an SSL certificate and an HTTPS connection. I've acquired a domain name to do it. However, is it safe to leave it like that? Is there a way to close the publicly accessible page and just use Wireguard so that only I can connect?\n    submitted by    /u/greenlightison  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkl5ee/is_it_safe_to_leave_vaultwarden_login_page_public/",
          "publishedOn": "2022-12-13T03:35:44.000Z",
          "wordCount": 19518,
          "title": "Is it safe to leave Vaultwarden login page public?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkevcs/for_those_with_colo_servers_how_do_you_access/",
          "author": null,
          "description": "I'm thinking of getting a 1U server and putting it in colo. Since it would be driving distance, I can set it up and bring it in but in case I need to reboot or update hypervisor I would need to access IPMI.\n I know there is a firewall feature on some Supermicro servers but tech support answer was it doesn't work because no one is using it.\n Having it exposed to net is a no go. But if I go with some VPN device I will need to pay for another U.\n    submitted by    /u/Otaehryn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkevcs/for_those_with_colo_servers_how_do_you_access/",
          "publishedOn": "2022-12-12T23:07:45.000Z",
          "wordCount": 17338,
          "title": "For those with colo servers, how do you access IPMI/ILO/IDRAC/IMM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zke683/is_seafile_any_good_compared_to_nextcloud_just/",
          "author": null,
          "description": "Thanks\n    submitted by    /u/Kraizelburg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zke683/is_seafile_any_good_compared_to_nextcloud_just/",
          "publishedOn": "2022-12-12T22:41:32.000Z",
          "wordCount": 15434,
          "title": "Is seafile any good compared to nextcloud just for file storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkdr80/running_containerized_x_server/",
          "author": null,
          "description": "Hi everyone. I have a home server where I run all of these lovely services we like to use in this community. This server happens to be pretty near my TV. And even though I do access some of these over the network I always thought that it would be nice to have some graphic interface on the server and access it just by plugin a HDMI to the TV. I'm with a shameless Ubuntu server 20.04 without X nor any windows server and all of the services with Podman.\n I'd like to keep my host clean, so the idea would be to run either a full os with vagrant or something similar or just run a container with the X server installed and some devices mounted. I don't necessarily want to run a whole wm nor anything similar, I guess I will mostly use it to run regular desktop apps or even just a browser.\n Does it makes sense ? Is any of you doing anything similar ?\n    submitted by    /u/contre95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkdr80/running_containerized_x_server/",
          "publishedOn": "2022-12-12T22:26:59.000Z",
          "wordCount": 16572,
          "title": "Running containerized X server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkcd46/minimalistic_watchlist_appsite_something_like/",
          "author": null,
          "description": "Hey, I'm currently writing an auto-stream downloader for my grandparents.\n I need to fast/easy select Movies, episode/s, season/s, and complete series with something like an API or email notification\n Thx\n (sorry for my English)\n Edit: Overseerr dont have single episode feature\n    submitted by    /u/Ok-Dingo-9988  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkcd46/minimalistic_watchlist_appsite_something_like/",
          "publishedOn": "2022-12-12T21:38:21.000Z",
          "wordCount": 16311,
          "title": "minimalistic Watchlist App/Site something like justwatch.com with API",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zkc46g/website_status/",
          "author": null,
          "description": "Hello, im looking for a cms Who check if website is online. \n But i want to limit only for my client and they easy check without login or Signup.\n    submitted by    /u/Elemis89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zkc46g/website_status/",
          "publishedOn": "2022-12-12T21:29:18.000Z",
          "wordCount": 18943,
          "title": "Website status",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zka1j8/should_i_create_multiple_vms_with_dockerengine_or/",
          "author": null,
          "description": "Basically if I have only 1 server with Proxmox VE, is there any advantage to spin up for example 3 VMs and install Docker-Engine on each, acting like a cluster? \n Or should I just keep 1 VM and run all my containers on the one VM?\n    submitted by    /u/Julwazza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zka1j8/should_i_create_multiple_vms_with_dockerengine_or/",
          "publishedOn": "2022-12-12T20:14:58.000Z",
          "wordCount": 15439,
          "title": "Should I create multiple VMs with Docker-Engine or a single one for all my containers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk9sun/using_google_compute_instance_with_tailscale_and/",
          "author": null,
          "description": "I work in a small company and there are about 8 of us that remote in to our respective workstations from time to time. Currently, we use RealVNC but I have been thinking about replacing that with Tailscale and Apache Guacamole. I like the idea of a clientless solution for remote access.\n In terms of the Guacamole server, I was wondering if it would work to use a small Google Compute instance, install tailscale and the guacamole server on that, and then install tailscale on the various workstations and connect them all up. The users would login to the Guacamole server running on the google compute platform and then from there access their machines. \n If this works, then since this instance of Guacamole would be public facing, I would enable the 2FA plugin. Any other security recommendations? Reverse proxy?\n Any thoughts, suggestions, concerns are welcome. Thanks in advance.\n    submitted by    /u/No_Excuse_889  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk9sun/using_google_compute_instance_with_tailscale_and/",
          "publishedOn": "2022-12-12T20:05:53.000Z",
          "wordCount": 15705,
          "title": "Using google compute instance with tailscale and apache guacamole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk8lfu/spare_pi4_uses/",
          "author": null,
          "description": "Hi all, since repurposing an old mini pc to proxmox and migrating VMs and services there my dear Pi4 is collecting dust… At first it was running PiHole and OMV but now…. I have no idea what do do with it :/ Suggestions?\n    submitted by    /u/VengefulMustard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk8lfu/spare_pi4_uses/",
          "publishedOn": "2022-12-12T19:22:31.000Z",
          "wordCount": 15957,
          "title": "Spare Pi4 uses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk7sre/question_is_there_selfhosted_email_server_with/",
          "author": null,
          "description": "submitted by    /u/sheerun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk7sre/question_is_there_selfhosted_email_server_with/",
          "publishedOn": "2022-12-12T18:54:05.000Z",
          "wordCount": 18519,
          "title": "Question: Is there selfhosted email server with spam filtering by offline AI model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk7cs0/domain_name_registrar/",
          "author": null,
          "description": "I need a domain name registrar that allows PTR records. My current one dynadot don't support it. Does anyone have any recommendations for one?\n    submitted by    /u/LeastZombie3436  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk7cs0/domain_name_registrar/",
          "publishedOn": "2022-12-12T18:39:17.000Z",
          "wordCount": 16959,
          "title": "Domain name registrar",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk6swi/help_port_forwarding_with_gluetun_and_selfhosted/",
          "author": null,
          "description": "Hi all.\n I'm setting up an Ubuntu homeserver w/ a lot of docker containers organized in stacks.\n One of my stacks is an entertainment stack w/ qbittorrent, jackett and amule as the downloading part of the stack.\n For security reasons this stack connect to the outside via a vpn.\n The vpn is a wireguard vpn created w/ pivpn in an oracle cloud instance (ubuntu server).\n This is a semplified schema: \n  torrent vpn schema \n This is my docker compose:\n version: '3.5' services: gluetun: image: qmcgaw/gluetun container_name: vpn cap_add: - NET_ADMIN volumes: - /srv/docker/wireguard/casalt.conf:/gluetun/config.conf:ro ports: - 9117:9117 # jackett - 8090:8090 # qbittorrent - 6881:6881 # qbittorrent - 6881:6881/udp # qbittorrent - 4711:4711 # amule - 4783:4783/tcp # amule - 4786:4786/udp # amule - 47…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk6swi/help_port_forwarding_with_gluetun_and_selfhosted/",
          "publishedOn": "2022-12-12T18:19:29.000Z",
          "wordCount": 17142,
          "title": "[HELP] port forwarding with gluetun and selfhosted VPN",
          "imageUrl": "https://external-preview.redd.it/H3exIxBA37Hc0kfKKAFNA6FQslO0lQ7I8MJc_ShILxw.jpg?auto=webp&s=90aa0aed7fa1e57df342af7ab57f0f97a67303a8"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk6k3w/gtd_methodology_tools/",
          "author": null,
          "description": "Someone else using gtd methodology of David Allen for personal and work related \"stuff\"?\n If yes: What (self-hosted) tools do you use?\n I'm currently only using my dsNotes app on my synology. Works for me but probably not the most beautiful solution compared to these dashboards you can set up in notion for example.\n    submitted by    /u/yannbros  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk6k3w/gtd_methodology_tools/",
          "publishedOn": "2022-12-12T18:10:04.000Z",
          "wordCount": 15885,
          "title": "GTD methodology tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk5fhj/ticketing_system/",
          "author": null,
          "description": "does anyone know of a self-hosted ticketing system to track customer service/helpdesk tasks for a company?\n    submitted by    /u/uncmnsense  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk5fhj/ticketing_system/",
          "publishedOn": "2022-12-12T17:30:15.000Z",
          "wordCount": 15417,
          "title": "ticketing system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk3n4t/storing_homelab_passwords_and_information/",
          "author": null,
          "description": "I was wondering where most people store all of those little bits of information, and VM passwords, IP addresses, service port numbers etc. for their Homelabs? \n I've been putting mine in my password manager, but it looks ugly in there.\n    submitted by    /u/80Ships  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk3n4t/storing_homelab_passwords_and_information/",
          "publishedOn": "2022-12-12T16:24:38.000Z",
          "wordCount": 18278,
          "title": "Storing Homelab Passwords and Information?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk303p/self_host_rss_reader_why/",
          "author": null,
          "description": "I'm currently using feedme on Android to follow and download a couple of feeds. It 'just' uses Feedly (free). \n As I have a server running, I was wondering what advantage freshrss or others could have, but it was surprisingly hard to find comparisons. Maybe completely overlooked? Is there some features that I'm not seeing yet?\n I could think of privacy and unlimited number of feeds / articles. What else?\n    submitted by    /u/wokkieman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk303p/self_host_rss_reader_why/",
          "publishedOn": "2022-12-12T16:01:24.000Z",
          "wordCount": 17223,
          "title": "self host rss reader. why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zk197w/pihole_and_pivpn_you_have_to_try_them_together/",
          "author": null,
          "description": "I know I'm late to the game, but I just tried this couple of tools and I really love them. \n PiHole is super convenient to:\n - prevent _some_ advertisement on websites\n - it can also offer an interface in front of DNSMasq\n - and can also work as DHCP server.\n If you use the DHCP feature, you can associate each DNS request to an hostiname, in case you're curious to know which website you're wife is browsing ;) \n I wanted to use the raspberry as VPN server and I tried WireguardEasy, it's a nice project but could not make PiHole to answer to the DNS requests coming from Wireguard running as docker. \n Then I tried PiVpn, the installation took just few seconds and automatically recognize I had PiHole installed, configuring it to listed on the VPN interface. \n Overall took me a few hours to find the right tool, but if you read this post you can just install PiHole and PiVPN in just a minute.\n    submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zk197w/pihole_and_pivpn_you_have_to_try_them_together/",
          "publishedOn": "2022-12-12T14:55:26.000Z",
          "wordCount": 16675,
          "title": "PiHole and PiVPN, you have to try them together!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjzf0r/media_processing_workflow_orchestration_framework/",
          "author": null,
          "description": "submitted by    /u/Bikiew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjzf0r/media_processing_workflow_orchestration_framework/",
          "publishedOn": "2022-12-12T13:40:50.000Z",
          "wordCount": 16489,
          "title": "media processing workflow orchestration framework",
          "imageUrl": "https://external-preview.redd.it/kr2XTWvOFvayEPHx5YAbXkeFPcxWOmjLyYUhEVnDtTM.jpg?auto=webp&s=ae485bb38e6aba2d8382d80ab8f96882966d1849"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjy129/free_selfhosted_file_and_project_management/",
          "author": null,
          "description": "​\n Cospace\n Hey. We are launching a FREE self-hosted collaboration tool. It's a simple alternative to slack, Monday, dropbox, and asana. You can plan your daily to-dos, assign tasks, manage projects, store large files, create your own documents, etc.\n We made sure installation is as easy as it can be with single-line installation - https://cospace.mytwigex.com/en/Installation\n You can find us here- https://www.reddit.com/r/cospace/\n ​\n    submitted by    /u/rutinja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjy129/free_selfhosted_file_and_project_management/",
          "publishedOn": "2022-12-12T12:44:04.000Z",
          "wordCount": 17799,
          "title": "Free self-hosted file and project management.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjw2mk/domain_problem_httpswww/",
          "author": null,
          "description": "Hey! I got a new domain name from \"porkbun\" and attached the Server IP with it. I also got an SSL Cert (https) set up. Now when i connect to the site in my browser using\n www.name.com, or https://name.com, or just name.com\n i get \"https://www.name.com\"\n How do i get rid of that additional \"www.\"?\n Edit: its just a simple apache2 server, no reverse proxy. Edit 2 : on the porkbun dns site, when you add a record, it asks you to put something in the \"host\" field. I typed www in there, because i have seen this working on other sites. Now i left the field empty and it worked.\n    submitted by    /u/5calV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjw2mk/domain_problem_httpswww/",
          "publishedOn": "2022-12-12T11:16:11.000Z",
          "wordCount": 18401,
          "title": "Domain Problem? https://www.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjvxld/witch_music_server_handles_mp3tags_the_best/",
          "author": null,
          "description": "Hello all. I spent my last weekend completely on tagging my music collection on my NAS. Scanning folder by folder with the Mp3tag software and giving it the correct album information one by one.\n Today I was adding the complete library in Plex... The outcome was not as expected... I have far more albums in Plex than folders on my NAS. In Plex, I see some albums multiple times, each with only two or three numbers of that album.\n I tried in Navidrome but that was even worse...\n What am I doing wrong? Is the tagging done wrong? Is there a better server solution?\n Thanks!\n    submitted by    /u/babsenfred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjvxld/witch_music_server_handles_mp3tags_the_best/",
          "publishedOn": "2022-12-12T11:09:42.000Z",
          "wordCount": 16683,
          "title": "Witch music server handles mp3tags the best?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjuomt/nginx_proxy_manager_use_same_cloud_host_or_use/",
          "author": null,
          "description": "I have a server (host) which I use primarily for my Nextcloud VMs, Adguard Home, and a few other services. I also use a Synology NAS and utilize Nginx Proxy Manager to reach them outside my home. My question is, does it matter which server (host) I put my NPM on? Or should I separate it from my main cloud services host? I have two other available servers (hosts) but didn’t know what would be the best set up. I don’t want to affect the cloud server’s (Host’s) Nic…if that is even a thing. \n Appreciate the help in advance!\n    submitted by    /u/flyjim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjuomt/nginx_proxy_manager_use_same_cloud_host_or_use/",
          "publishedOn": "2022-12-12T10:09:05.000Z",
          "wordCount": 20055,
          "title": "Nginx Proxy Manager - Use same cloud host or use separate host?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjph76/cloudflare_tunnel_does_cloudflare_analyse_the/",
          "author": null,
          "description": "Hi all,\n I would really love to use Cloudflare Tunnel for usecases where a VPN isn't possible. E.g. usage via company notebook.\n The great thing is the possibility to secure it directly via Cloudflare with Two-Factor Authentication, so any request must past Cloudflare Auth before getting to my private NGINX. For me much more secure when opening ports directly.\n However, as Cloudflare is generating the HTTPS certificate, they can as Man in the Middle read my traffic (passwords, data, etc) in plain text. Right?\n So is there any possibility to use Cloudflare Tunnel but to secure my data so it cannot be encrypted via Cloudflare?\n    submitted by    /u/Simplixt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjph76/cloudflare_tunnel_does_cloudflare_analyse_the/",
          "publishedOn": "2022-12-12T06:09:24.000Z",
          "wordCount": 1935,
          "title": "Cloudflare Tunnel - does Cloudflare analyse the traffic? Can I prevent it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjo0j0/looking_for_a_specific_gallery_app_with_precise/",
          "author": null,
          "description": "Hi everyone!\n TLDR : i'm looking for an image gallery capable of precise geotagging, and showing it on a map at very little scale (~500m²).\n Full version : I'm in the team of an outdoor event, and each year we take a lot of technical pictures (where a thing is plugged, did we installed a trash here or here, where the hell water distribution was routed, etc.). Those images are invaluable for planning and correcting errors the next year, because plans rarely adapt to the reality, and details evolve organically.\n Generally, we have 700-1000 pictures, from diverse sources. It's complicated when all you have is a big folder to search in.\n So, i'm looking for a selfhosted app where you can geotag a photo, and show it on a map very close, showing roughly 500m² of terrain or less. Ideally an orientation indicator would be useful. A good point would be filtering the points/pictures by tags on the map. For tagging, OpenStreetMap is exact where we are, because of micro-mapping and high precision points, and all that matters is relative positioning anyway.\n I'm already testing apps, but what i want is never a selling point. Map view are often limited to a low zoom, or the pictures shown in full instead of points. Basically i need to install every single one listed on the big list, and it's not an efficient process, when i can ask for help here too ! ;)\n Thanks !\n    submitted by    /u/Moff_Tigriss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjo0j0/looking_for_a_specific_gallery_app_with_precise/",
          "publishedOn": "2022-12-12T05:09:26.000Z",
          "wordCount": 16482,
          "title": "Looking for a specific gallery app with precise geotagging",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjhtt9/help_how_to_make_your_own_smtp_relay_server/",
          "author": null,
          "description": "Hello, I come to ask for some guidance for the creation of SMTP only for sending emails. I have installed poste.io on my synology working but I need to be able to send emails from my poste.io and that my server postfix in vps in hetzner (I am waiting for port unblocking) whoever sends all the emails, I know this is very risky but I have sendinblue and when I send emails this company saves all the info and that makes me have little confidence\n ​\n I have already installed postfix configured as it indicates in the digital ocean tutorial I use smtp as I only send\n ​\n But now, how do I add a user who is the one who posts in my iposte.io as smtp relay and how to send all the emails that I have in my poste.io through the postfix of my vps\n ​\n What I need is a server equal to sendgrid, mailgun, etc. in my own vps. How do I protect and connect to my server in the vps?\n ​\n I have installed\n ​\n -----postfix\n -----libsasl2-2 sasl2-bin\n ​\n My user already creates my user but I cannot connect to my server with these led credentials I leave as I have my sudo nano /etc/postfix/main.cf\n test\n    submitted by    /u/armando0000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjhtt9/help_how_to_make_your_own_smtp_relay_server/",
          "publishedOn": "2022-12-12T01:19:17.000Z",
          "wordCount": 17187,
          "title": "Help how to make your own smtp relay server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjhdhe/i_would_love_for_a_couple_of_people_to_give_me/",
          "author": null,
          "description": "I would love people that are interested in self-hosting and curating media collections could look at this and let me know\n 1) Is this interesting at all to you?\n 2) Why or why not? Is it missing features? (Cloud sources or backups, etc)\n Most media servers let you quickly find something to watch, then you watch it in full on a chosen device. I wanted something else that was for browsing around and adding more granular metadata.\n I made a thing for digging around in your content and adding tags to specific moments. It has animated thumbnails and you can transcribe media that have no subtitles.\n https://gridly.media/\n I have been trying to decide what direction to take this in, but I have been struggling to find people to ask.\n    submitted by    /u/GridlyMedia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjhdhe/i_would_love_for_a_couple_of_people_to_give_me/",
          "publishedOn": "2022-12-12T01:03:14.000Z",
          "wordCount": 16231,
          "title": "I would love for a couple of people to give me some feedback on my media collection project",
          "imageUrl": "https://external-preview.redd.it/1RuOL76MtRhXO0tPbvHBKBiIbDHrubQwF39m4UvV5CI.jpg?auto=webp&s=de29bc86e5dc896bf6e25944a62ca03836d0a521"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjh92q/i_cant_use_bookstack_with_cloudflare_tunnel/",
          "author": null,
          "description": "Hi everyone. Sorry i am newbie here. I have some trouble to setup Bookstack with Cloudflare Tunnel. This is my Bookstack stack file which i was deploy on portainer\n  \nversion: \"2\" services: bookstack: image: lscr.io/linuxserver/bookstack container_name: bookstack environment: - PUID=1000 - PGID=1000 - APP_URL=localhost:6875 - DB_HOST=bookstack_db - DB_USER=bookstack - DB_PASS=<yourdbpass> - DB_DATABASE=bookstackapp volumes: - /path/to/data:/config ports: - 6875:80 restart: unless-stopped depends_on: - bookstack_db bookstack_db: image: lscr.io/linuxserver/mariadb container_name: bookstack_db environment: - PUID=1000 - PGID=1000 - MYSQL_ROOT_PASSWORD=<yourdbpass> - TZ=Europe/London - MYSQL_DATABASE=bookstackapp - MYSQL_USER=bookstack - MYSQL_PASSWORD=<yourdbpass> volumes: - /path/to/data:/config restart: unless-stopped\n I can access bookstack in my local with address http://localhost:6875. But when I setup a cloudflared tunnel with a subdomain point to http://localhost:6875. It just show a white window on my browser. Anyone know what is wrong with my bookstack? How can I fix this? Thanks\n    submitted by    /u/tuong_dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjh92q/i_cant_use_bookstack_with_cloudflare_tunnel/",
          "publishedOn": "2022-12-12T00:59:10.000Z",
          "wordCount": 15521,
          "title": "I can’t use bookstack with Cloudflare Tunnel",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjftoz/looking_for_selfhosted_realty_search_zillow/",
          "author": null,
          "description": "Is anyone aware of a selfhosted app that scrapes Zillow, Redfin and the likes for property? Maybe let you search by specific parameters, and provide updates for changes?\n    submitted by    /u/tgp1994  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjftoz/looking_for_selfhosted_realty_search_zillow/",
          "publishedOn": "2022-12-12T00:11:26.000Z",
          "wordCount": 16569,
          "title": "[Looking for] Selfhosted Realty Search - Zillow, Redfin companion?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjcps6/uptime_kuma_tcp_ping_always_fails/",
          "author": null,
          "description": "Hi, so I'm trying to monitor Tautulli and Plex (among other things) using TCP port in Uptime Kuma, but it always gives an error.\n My plex is hosted at: 192.168.1.2:32400 but kuma always states: \n [Plex] [DOWN] Connect EHOSTUNREACH 192.168.1.2:32400\n Does anyone have any idea what I might be doing wrong? Plex is hosted on a windows server machine, and kuma is inside a docker container running inside an ubuntu server vm on the same device (vm's private ipv4 is 192.168.1.3) TIA.\n    submitted by    /u/80Ships  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjcps6/uptime_kuma_tcp_ping_always_fails/",
          "publishedOn": "2022-12-11T22:37:34.000Z",
          "wordCount": 16033,
          "title": "UpTime Kuma TCP Ping always fails",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zjbihs/self_hosting_nextcloud_via_vpn/",
          "author": null,
          "description": "I’m struggling here.\n I’d like to run Nextcloud so that it syncs only when my iOS devices are either 1) locally connected to network or 2) VPN’d remotely.\n I don’t want to expose a public IP or use reverse proxy.\n VPN is setup and working properly on my router & router has ddns address.\n Nextcloud All-In-One docker is installed on Mint Linux box but during setup NC asks for domain and does not allow IP (why?)\n Now I’m stuck bc I dont have a public domain. I have a ddns IP from NoIP for the VPN but not sure this NoIP domain is what I want to use (along with router port forwarding) since its public facing.\n I think an option is to create a private domain via technitium’s zone and point the router to this DNS so that the iOS devices use the DNS but I’m not sure this will work when VPN’d.\n    submitted by    /u/Hubba_Bubba_Lova  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zjbihs/self_hosting_nextcloud_via_vpn/",
          "publishedOn": "2022-12-11T22:09:46.000Z",
          "wordCount": 17764,
          "title": "Self hosting Nextcloud via VPN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj8get/selfhosted_backup_solution/",
          "author": null,
          "description": "heya selfhosters and homelabbers\n i‘m trying to get rid of acronis , since it‘s a little messy with my macbook ..\n does anyone have a backup solution in place which cover macOS as well windows?\n thanks!\n    submitted by    /u/Two-Nearby  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj8get/selfhosted_backup_solution/",
          "publishedOn": "2022-12-11T20:54:56.000Z",
          "wordCount": 16814,
          "title": "selfhosted backup solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj6sd9/vm_works_container_doesnt_proxmox_radarr_portainer/",
          "author": null,
          "description": "I am having a whole world of difficulty getting this stuff to work the way I would expect it to, but I am very new to Docker. I guess some people would say this should go in a proxmox/docker/servarr subreddit, but figured it was generic enough to put it here.\n I have a Synology NAS for all my storage. \n ​\n I have two hosts running proxmox in a cluster prox1 has vpn to lan, lisc lxcs and prox2 has PLEX. Plex is working.\n ​\n I have been mounting my network shares from my NAS via CFIS in fstab with the following:\n //192.168.1.2/Media /media/Media cifs username,password,iocharset=utf8,noperm 0 0\n This has been successful in many iterations of my PLEX server on Ubuntu server on bare metal, and now in an LXC with debian base for PLEX.\n ​\n I've been banging my head on the wall trying to get Overs…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj6sd9/vm_works_container_doesnt_proxmox_radarr_portainer/",
          "publishedOn": "2022-12-11T20:16:07.000Z",
          "wordCount": 20562,
          "title": "VM works, Container doesn't: Proxmox, Radarr, Portainer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj5one/best_approach_for_pihole_unbound_access_from/",
          "author": null,
          "description": "Hi, new on here and generally new to the whole self hosting thing apart from pihole.\n Currently I’m running just pihole and unbound on raspberry B+ (2014) model on dietpi. My goal is to be able to use it outside of my home network in the SAFEST way possible with least amount of lag possible.\n I would rather spend some extra time to achieve both (if possible) than to take a shortcut. I’ve heard about wireguard, Tailscale and zetotier but not looked deep enough to decide which one is the best approach of the three.\n What i was hoping to do was fresh install of everything on a new sd card for two reasons; in case things go south i still have copy of current setup on old card and secondly so that i can easily follow certain guide as its been a while since i setup the pihole. I have some extra questions i want to ask for future planning.\n  \nHow many things can i run on this raspberry pi? In near future i want to try few other things I’ve come across such as bookmark manager like shiori or password manager like Bitwarden/vaultwarden2.\n if I can run more than just the pihole setup mentioned in second paragraph, whats the best approach? And how?\n Does it make sense to use flash drive (if possible) to run this on for extra reliability.\n say someone is able to access my pihole, aside from my dns queries what other data can they access\n  \nMy ultimate goal for future would be to use pihole as primary dns and have everything else running on some server (post for another day)\n I would really appreciate any help you guys can provide. Thanks in advance\n    submitted by    /u/C0mpleteAnnihilation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj5one/best_approach_for_pihole_unbound_access_from/",
          "publishedOn": "2022-12-11T19:46:46.000Z",
          "wordCount": 17734,
          "title": "Best approach for pihole + unbound + access from anywhere",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj5g9w/manage_services_running_on_local_machines/",
          "author": null,
          "description": "Hello. A while ago I started building a solution for managing my projects. Even though I kind of have it working, I feel like there should be an existing solution for this that could be of more value for me. Here is my situation:\n I have a few machines running on my network, each of them runs some projects of mine. When I want to run a project, I log on to the machine, clone the repo and run a command to build and serve it.\n I develop and update projects from my main machine, and whenever I push an update I have to log on to the relevant machine and do the whole process manually over again.\n What I would like is to be able to upgrade, rebuild, and rerun the projects on each machine, from a central dashboard of some sort, eliminating the need to log on to each machine. Ideally I would like to hook this up with some git events so that the whole process is automated.\n I feel like there has to be some software that does this, that's not enterprise level. I was recently looking at portainer, which I think does what I want, but I don't have everything in containers so it doesn't work for me.\n ​\n Surely someone here has experience with this problem and can offer some advice!\n Thanks a lot in advance for any help.\n ​\n    submitted by    /u/modenv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj5g9w/manage_services_running_on_local_machines/",
          "publishedOn": "2022-12-11T19:38:57.000Z",
          "wordCount": 15621,
          "title": "Manage services running on local machines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zj52dr/setup_to_automate_jellyseer_google_drive_jellyfin/",
          "author": null,
          "description": "Hey,\n any good solution out there to download a folder from google drive when requested via Jellyseer? And rename the episodes after that for Jellyfin? Only DIY possible or is there some sort of tool which \"bridges\" that gap?\n    submitted by    /u/st01x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zj52dr/setup_to_automate_jellyseer_google_drive_jellyfin/",
          "publishedOn": "2022-12-11T19:27:30.000Z",
          "wordCount": 15664,
          "title": "Setup to automate Jellyseer + Google Drive + Jellyfin?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zizzk1/can_i_host_multiple_services_at_the_same_public/",
          "author": null,
          "description": "Hi all - I'm just getting started in self-hosting and I've set up a homebrew calendar application in Django that used to be rent-hosted. So now I have it run on a old laptop in my office, and I use ddns.org for dynamic DNS. I'd like to start up a second service on the same machine, and access the original calendar service at a URL like myfake.ddnsdomain.org/calendar/ and the new notes-like service at myfake.ddnsdomain.org/notes/\n I tried using nginx to redirect the /calendar/ URL suffix from my HTTP port to a different port on which the Django app was running, and that worked for the initial page, but that same suffix was not appended the follow-up HTTP requests from the client side. How can I achieve this behavior without modifying the code for the calendar app? (Of course, I can technically do it for the calendar app, but then I wouldn't have a solution for the other services...)\n Is this possible? Or do I have to do something different, like should I do a 301 request to a different port and open multiple on my home router?\n    submitted by    /u/MrMallIronmaker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zizzk1/can_i_host_multiple_services_at_the_same_public/",
          "publishedOn": "2022-12-11T17:10:01.000Z",
          "wordCount": 16599,
          "title": "Can I host multiple services at the same public IP using URL patterns?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zizqnj/unified_messaging_platform/",
          "author": null,
          "description": "Hi! \n I'm looking for a unified messaging app. What this means is a web browser based or programm that allows me to have all my messages in 1 place from different apps. \n An example of this is: Texts \n https://texts.com/ \n Not sure if something excists but i'm looking forward to your answers!\n    submitted by    /u/jorissels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zizqnj/unified_messaging_platform/",
          "publishedOn": "2022-12-11T17:03:19.000Z",
          "wordCount": 15713,
          "title": "Unified messaging platform.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ziyyb6/synlogy_ds214play_upgradealternatives_with_docker/",
          "author": null,
          "description": "Looking for some advise from more experienced friends.\n I currently have Synlogy DS214Play with two 4TB HDDs.\n I have a cctv software with one camera and plex installed, and they work great.\n Unfortunately Docker is not supported on DS214Play and I'm looking for some alternatives.\n My requirements are:\n - Network storage\n - Plex\n - Ability to install various packages, for example https://www.home-assistant.io/ or similar.\n - Ability to install a few CCTV cameras with CCTV management software. I would prefer something different than built-in synology software.\n Basically it would be nice if I could run everything on docker.\n What hardware do you recommend that is similar in physical size to synology boxes (can be synology). I don't have a space for a rack in my flat.\n    submitted by    /u/f899cwbchl35jnsj3ilh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ziyyb6/synlogy_ds214play_upgradealternatives_with_docker/",
          "publishedOn": "2022-12-11T16:41:15.000Z",
          "wordCount": 16169,
          "title": "Synlogy DS214Play upgrade/alternatives with docker",
          "imageUrl": "https://external-preview.redd.it/UJkqXw8jYcOSjjqxZvMXdvsyZBUeXSy1eKeKStW6xFQ.jpg?auto=webp&s=b2b48b101fa6f1058daa3ecfc92f13bc42212363"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ziw5tz/limiting_ssh_access_to_vpn/",
          "author": null,
          "description": "Hi\n I am running several Ubuntu VPS and I am thinking about limiting ssh access to only my VPN (ZeroTier). I have no reasons to want ssh to be exposed to the Internet.\n However, is that a good idea? What if a server restarts and can't load/connect to the ZeroTier VPN?\n    submitted by    /u/TedBob99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ziw5tz/limiting_ssh_access_to_vpn/",
          "publishedOn": "2022-12-11T15:21:31.000Z",
          "wordCount": 16453,
          "title": "Limiting ssh access to vpn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ziv8vo/grist_alternatives/",
          "author": null,
          "description": "Hello there, I’m looking for a self hosted spreadsheet software for multi user usage with customisable user roles (able to edit, delete, create rows)\n I’ve tried Grist, Baserow and Seatable but it is unable to customise user roles.\n Any recommendations?\n    submitted by    /u/Express_Steak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ziv8vo/grist_alternatives/",
          "publishedOn": "2022-12-11T14:58:15.000Z",
          "wordCount": 17129,
          "title": "Grist alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zitmds/proxmox_homeserver/",
          "author": null,
          "description": "Quick question: I recently set up Proxmox VE on an old desktop I had lying around (Specs: i5 6600, 16gb DDR4 Memory, 500gb ssd, Gigabit LAN) and I also have HomeAssistant up and running on a VM.\n Now I'd like to install quite a few services that usually run in a docker container like piHole/Adguard, Whoogle, TrueNas or similar for Storage, and maybe Yacht so that I am able to install more services easily.\n My question is, what is the best way to go to set these up? Should I use Proxmox LXC Containers, a designated linux vm in Proxmox or should I directly run the services as docker containers on the Proxmox Debian installation?\n Thanks in advance\n    submitted by    /u/StefanArts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zitmds/proxmox_homeserver/",
          "publishedOn": "2022-12-11T14:14:45.000Z",
          "wordCount": 17364,
          "title": "Proxmox Homeserver",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zirgvf/self_hosted_appointment_software_calandlylike/",
          "author": null,
          "description": "Hi guys, \n I'm in the process of launching my own digital agency and I'm looking for a software solution so the customer could book appointment with me. I'm thinking of something like calandly, but preferably self-hosted / FOSS, so I can integrate it in my website. \n Does any of yee have any experience with calandly, easy-appointement, cal.com, meetsy,...? Any feedback? I'd appreciate the following feature: \n - self-hosted Frontend and API\n - Calandar integration\n - Sending appointement reminder\n - Integration with jitsy or zoom?\n    submitted by    /u/trollfre3account  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zirgvf/self_hosted_appointment_software_calandlylike/",
          "publishedOn": "2022-12-11T13:14:13.000Z",
          "wordCount": 15867,
          "title": "Self hosted appointment software? (calandly-like)",
          "imageUrl": "https://external-preview.redd.it/mpwVK4VfbYoKCUAxw8JWVkQh3l9fxwBZ3Xe05u-oWoA.jpg?auto=webp&s=0446bcb6a9f7dfd024fa974e67ffe9b663e3b987"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zinppw/how_important_to_have_tlsa_records/",
          "author": null,
          "description": "I just got to setup my dns server(s) properly with DNSSEC. Now reading further I got to TLSA records and thinking about how important it is in current state? Before I used DNS server from provider where I didn't heart about TLSA and didn't it setup for years. Are there known issues/restrictions by not setting it up?\n    submitted by    /u/champonthis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zinppw/how_important_to_have_tlsa_records/",
          "publishedOn": "2022-12-11T10:46:26.000Z",
          "wordCount": 18384,
          "title": "How important to have TLSA records?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zinp3e/anyone_ever_successfully_self_host_simplelogin_on/",
          "author": null,
          "description": "I've been struggling to self host SimpleLogin on my home server where my internet provider provided a public ip which is usually changed from time to time because I do not subscribe for the much higher price fixed public ip.\n simple-login/app: The SimpleLogin back-end (github.com) \n I understand that the installation guide provided in the GITHUB link above is based on the self-host environment where the server has a permanent fixed public IP?\n I've installed it on the home server and added all the DNS records required on Cloudflare where I managed my registered domain. I can open up the SimpleLogin signup webui and the signup email verification was successfully sent to Yahoo by postfix (I know by looking at the /var/log/mail.log), but my yahoo inbox/spam box never got the mail. So I'm stuck. I suspect it has something to do with the system mail name, my domain, etc. that I setup for Postfix. \n My internet provider doesn't block port 25, so it is not a port problem.\n My home servers:\n - PfSense box running HAProxy as a reversed proxy\n - Self-hosted SimpleLogin was installed on Debian VM (which runs on my Unraid server)\n - mydomainname.com was registered at Namecheap but I transferred the DNS management to Cloudflare. All subdomains set on Cloudflare DNS are working fine hand in hand with my pfSense HAProxy. \n Any advice would be appreciated.\n    submitted by    /u/europacafe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zinp3e/anyone_ever_successfully_self_host_simplelogin_on/",
          "publishedOn": "2022-12-11T10:45:34.000Z",
          "wordCount": 16642,
          "title": "Anyone ever successfully self host SimpleLogin on your home server?",
          "imageUrl": "https://external-preview.redd.it/36T2m9krmTYHKICNIbRcIap1V56wdIjX5ZKeURovHoU.jpg?auto=webp&s=eae392cf7d4dda51f700c5c63d3a051dbae491b3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zile9g/creating_own_rss_feed_from_database/",
          "author": null,
          "description": "Hi everyone,\n A bit new to selfhosting - currently have a RPi4 running FreshRSS & NextcloudPi behind an nginx reverse proxy, all hosted in docker containers.\n I have a database of articles including a section and article link - there are a total of about ~10,000 articles in it. I would like to create an RSS feed that randomly picks up one article every day and sends it to FreshRSS, so I can read the articles on my phone/linux system. \n Any information on how to do this easily is very much appreciated. Thank you!\n    submitted by    /u/seriouslyfun95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zile9g/creating_own_rss_feed_from_database/",
          "publishedOn": "2022-12-11T08:58:12.000Z",
          "wordCount": 16460,
          "title": "Creating own RSS feed from database?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zikqoj/best_python_script_orchestrator/",
          "author": null,
          "description": "Hey all. \n I have a number of different small scripts to automate and integrate various tasks. I've used UnRaid's Custom User Scripts to host these over the past couple years. Things are starting to become unmanageable and I've starting looking into a more robust solution.\n At the end of the day, I'm looking for some application to run python scripts, manage environments, integrate with GitHub, and have some centralized scheduler. Things like logging, error notifications, or managing credentials would all be solid extras. \n Most of the applications I've found seem overly complex, resource intensive, or just completely miss the mark. Things like JupyterHub, Jenkins, Airflow, VS Code Server, and others. \n Airflow is probably the front runner, however it is still much, much more than what I'm really looking for. I feel like I'm searching the wrong keywords...\n Any recommendations?\n    submitted by    /u/Rebeleleven  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zikqoj/best_python_script_orchestrator/",
          "publishedOn": "2022-12-11T08:27:07.000Z",
          "wordCount": 16905,
          "title": "Best (Python) Script Orchestrator?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zif4d3/pros_and_cons_of_an_onion_homeserver/",
          "author": null,
          "description": "I've been thinking of the implications of a homeserver based on the tor network. Assuming that the users apply the best practices, would some anonymity be achieved by this kind of setup? Also, ⠀would an obfuscated bridge help?\n    submitted by    /u/AmandaPolx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zif4d3/pros_and_cons_of_an_onion_homeserver/",
          "publishedOn": "2022-12-11T04:39:53.000Z",
          "wordCount": 17082,
          "title": "Pros and cons of an .onion homeserver .",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zidehg/can_a_2012_emachine_computer_be_my_web_server/",
          "author": null,
          "description": "Found this old computer in my basement and I wanna use it as web server for my web app. With these specs do you think it hold high traffic (10k visitors a day)\n Should I just use a raspberry pi instead of this?\n Is it possible to use both as a server for the same web app?\n Keep in mind, I don’t want to spend money if I don’t have to!\n    submitted by    /u/QualityOrnery282  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zidehg/can_a_2012_emachine_computer_be_my_web_server/",
          "publishedOn": "2022-12-11T03:35:10.000Z",
          "wordCount": 18689,
          "title": "Can a 2012 Emachine computer be my web server",
          "imageUrl": "https://preview.redd.it/1q4ckjm7d85a1.jpg?auto=webp&s=a2f0ebbdcd0440a5404ec08b63396469cf6a1374"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi62v9/how_would_pomerium_authentik_compare_to_traefik/",
          "author": null,
          "description": "Hi all! I've been working on my homelab slowly for the past six months or so when I have time. I'd really like to host some services for my friends, though not all are web-based. I heard about Pomerium and am a little confused as to why people are using it in conjunction with Traefik. It seems to me that practically it is traefik for my k8-less uses but would allow for easier monitoring of who is using my services? I really like the idea of having to approve of each device on Pomerium before they can use any service of mine, and I'm not sure if that's possible with Authentik.\n If anyone has any knowledge they could enlighten me with here that would be cool! Does Traefik + Authentik work well for hosting a game server?\n    submitted by    /u/alexlyee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi62v9/how_would_pomerium_authentik_compare_to_traefik/",
          "publishedOn": "2022-12-10T22:45:14.000Z",
          "wordCount": 16182,
          "title": "How would Pomerium + Authentik compare to Traefik + Authentik?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi5yto/raspberry_pi_stream_filestorrents_to_tv/",
          "author": null,
          "description": "Hello,\n This sub inspired me to create something selfhosted with my Raspberry Pi, so thank you!\n I just bought a new TV(Android TV) for my family and I thought how could I stream/watch my downloaded movies/TV series easier. \n What I have done so far - Installed DietPi on my Raspberry Pi 3B, added external HDD storage, created remote access to it.\n Maybe someone can explain the next process? What setup should I use and how it actually works?\n    submitted by    /u/tasesmuemils  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi5yto/raspberry_pi_stream_filestorrents_to_tv/",
          "publishedOn": "2022-12-10T22:40:37.000Z",
          "wordCount": 15974,
          "title": "Raspberry Pi - stream files/torrents to TV",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi5goi/shoutout_for_linkding_bookmark_manager/",
          "author": null,
          "description": "i've had linkding on my list of things to install for ages, and finally got around to it this week. so far, it's great.\n imported all of my pinboard.io bookmarks, my firefox bookmarks, and when i find it i'll import an old bookmarks file i've had lying around somewhere for a decade.\n i also really like the linkding injector browser plugin. now, every time i search on google or duckduckgo it also searches my own bookmarks and reminds me of any relevant searches. \n https://preview.redd.it/gzed07thb55a1.png?width=2048&format=png&auto=webp&s=c64e09086a397cb8d803dfdab27a21b11feb204f\n    submitted by    /u/adamshand  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi5goi/shoutout_for_linkding_bookmark_manager/",
          "publishedOn": "2022-12-10T22:20:30.000Z",
          "wordCount": 16265,
          "title": "shoutout for linkding bookmark manager",
          "imageUrl": "https://external-preview.redd.it/rexUR795_LYewaXbxIYQLET1WDJAcIe_HHd8MbHQFEU.jpg?auto=webp&s=4201395de942f0f8db8af1588b1114f5fd27466d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi33gz/lets_say_im_gonna_get_a_domain_name_for_my_home/",
          "author": null,
          "description": "Thinking about getting a proper domain name rather than duckdns just for the sake of it;\n But I never experienced with normal domains names neither do I know how they work.. (Really wondering how a domain name costs more or less on some websites and how do they all know that I own it ?)\n So, if I should know anything before buying it, tell me !\n    submitted by    /u/Daitan_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi33gz/lets_say_im_gonna_get_a_domain_name_for_my_home/",
          "publishedOn": "2022-12-10T20:48:18.000Z",
          "wordCount": 16277,
          "title": "Let's say I'm gonna get a domain name for my home server, what should I know before ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi27ol/looking_for_a_cool_domain_name/",
          "author": null,
          "description": "Don't know where to ask this bot I'm really uncreative so do you guys have any inspiration for a cool domain?\n    submitted by    /u/Im1Random  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi27ol/looking_for_a_cool_domain_name/",
          "publishedOn": "2022-12-10T20:12:20.000Z",
          "wordCount": 15515,
          "title": "Looking for a cool domain name",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zi1m7u/solution_to_track_progress_in_graphs/",
          "author": null,
          "description": "Hey guys! \n I am looking for something selfhosted ( preferable ARM compatible and mobile friendly ) where i can have different databases which i can input data in everyday to track my overal health and performance as a human beeing. \n For example; \n Everyday of the week i need to give myself a score starting from 1 -10: \n - mentally\n - how i slept good/bad\n - how many hours i slept\n - did i go to the gym that day yes/no\n etc\n Then i would like to have graphs of all of them so i can check for example how productive am i on a monday compared to next monday and what changed? \n If someone has sugestions I would love to hear it! Doesn't necesarraly have to be exactly this, I'm open to anthing! \n Thank you all in advance!\n    submitted by    /u/jorissels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zi1m7u/solution_to_track_progress_in_graphs/",
          "publishedOn": "2022-12-10T19:49:28.000Z",
          "wordCount": 15522,
          "title": "Solution to track progress in graphs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhzhu3/how_to_set_up_cloudflare_zero_trust/",
          "author": null,
          "description": "I'm trying to set up cloudflare zero trust, so I can generate some traffic over it. I will be honest, I'm doing this just so I can get a code for yubikey, since I'm interested in a hardware 2FA key and how they work and this is a deal which I wouldn't want to miss. I know the deal is valid until the end of December, so I want to try to get the code. \n So far, I applied for the offer, but I got an email saying right now, I'm not eligible. What I did meantime is:\n  \nRun a vaultwarden docker container on a laptop which has an IP 192.168.1.x and I can access it from other local devices.\n On zero cloud website under Access > Applications, I added the app, with a type \"Private net\" and application url is the IP above, allow rule for policies\n Created a tunnel under access > tunnels and run a connector on the same laptop where the docker is. Once it was run, status was connected on the website\n Next thing I did is I created a user under my team > users. Login method is one-time PIN which gets sent on the email.\n When I login, I type team domain I got from settings > general, it asks for email, sends the code, I type it in and it shows the app I created in the step two.\n The problem is, when I click the app, it redirects me to the IP 192.168.1.x as it's an application url, but only if I'm on the local WiFi. If I try the procedure from my mobile data, obviously it fails as it redirects to the mentioned IP\n  \nIn both cases (WiFi and mobile data) it doesn't generate any traffic on cloudflare website at all as DNS requests, top logins by app are empty. So can someone tell me what I'm doing wrong or which step I'm missing?\n    submitted by    /u/OkKitchen1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhzhu3/how_to_set_up_cloudflare_zero_trust/",
          "publishedOn": "2022-12-10T18:22:44.000Z",
          "wordCount": 15986,
          "title": "How to set up Cloudflare zero trust?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhz3us/selfhosted_cctv_footage_browser/",
          "author": null,
          "description": "I have few IP cameras which saves footate directly to NAS when detect motion. Now I would like to be able to view it from some web app - do you know if is there any?\n    submitted by    /u/witek_smitek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhz3us/selfhosted_cctv_footage_browser/",
          "publishedOn": "2022-12-10T18:07:08.000Z",
          "wordCount": 15996,
          "title": "Selfhosted CCTV Footage browser",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhz00a/miniflux_remove_hostory/",
          "author": null,
          "description": "Hello everyone. Sorry if this has been asked before, but I couldn’t find it. I just installed Miniflux on my raspberry pi. Everything is running great. However, s there a way to disable the history option? I found the cleanup parameters, but that doesn’t seem to be what I’m looking for. If there is no way, I can keep the parameters set to 1 day. Thank you for your help\n    submitted by    /u/cyberFish79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhz00a/miniflux_remove_hostory/",
          "publishedOn": "2022-12-10T18:02:52.000Z",
          "wordCount": 16517,
          "title": "Miniflux remove hostory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhtr1x/self_hosted_podcasts/",
          "author": null,
          "description": "Exactly what the title says Any docker app for doing this ? Currently working with music on navidrome and jellyfin So if those have any plugins or stuff that's welcome too \n Thanks for any help :)\n    submitted by    /u/Least_Toe_8980  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhtr1x/self_hosted_podcasts/",
          "publishedOn": "2022-12-10T14:22:28.000Z",
          "wordCount": 16023,
          "title": "self hosted podcasts ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhtnqm/what_is_the_best_practice_and_and_best_way_deploy/",
          "author": null,
          "description": "Hello everybody. I'm having as slight problem. I usually deploy my selfhosted app locally, but after some down time in some work critical apps (my isp sucks), i decided to go VPS route for those that i need high availability. The problem i came across is that now i have to use firewall to restrict access to ports i dont want to be access from the outside. Here comes the problem, I tried iptables, ufw, firewalld always worked fine till a restart, after that i found that docker overwirtes the rules and pass its rules first... \n I found whalewall, and I get some success with it, but i ask myself, that is the best way to do it? Can some of you with more experience and knowledge about this give me a few directions for this simple situation.\n My objective is to pass most my docker apps through nginx proxy, with a exception of one or another.\n Thanks\n    submitted by    /u/DelScipio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhtnqm/what_is_the_best_practice_and_and_best_way_deploy/",
          "publishedOn": "2022-12-10T14:18:36.000Z",
          "wordCount": 16162,
          "title": "What is the best practice and and best way deploy docker containers and restrict some ports to local access?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhskkw/i_need_a_little_help_with_a_corrupted_boot/",
          "author": null,
          "description": "submitted by    /u/Leozunic7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhskkw/i_need_a_little_help_with_a_corrupted_boot/",
          "publishedOn": "2022-12-10T13:28:01.000Z",
          "wordCount": 16559,
          "title": "I need a little help with a corrupted boot partition on SSD -> recover data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhskhi/powerdns_admin_project_update/",
          "author": null,
          "description": "submitted by    /u/TesNikola  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhskhi/powerdns_admin_project_update/",
          "publishedOn": "2022-12-10T13:27:53.000Z",
          "wordCount": 15629,
          "title": "PowerDNS Admin Project Update",
          "imageUrl": "https://external-preview.redd.it/7-V5tnHg3RbUhmMJfpD_MYFQ8bn3_NJhgkV3WRKkvJ0.jpg?auto=webp&s=5c4ec621d1c55d95ace1c6cb10fc1453f7792fc4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhs6nw/personal_data_tracking/",
          "author": null,
          "description": "What personal data to you track? Like mood, food/water intake etc.. And what do you use for this?\n    submitted by    /u/Clean_Smile5680  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhs6nw/personal_data_tracking/",
          "publishedOn": "2022-12-10T13:09:41.000Z",
          "wordCount": 19877,
          "title": "Personal data tracking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhqjcd/traefik_behind_tailscale_how_to_configure/",
          "author": null,
          "description": "I use tailscale and I can reach my server using the domain offered by them: \n curl <my\\_machine\\_name>.<domain\\_from\\_tailscale>.ts.net\n The entry point on my server is a traefik instance and I'm trying to configure it to route to all other services:\n This is my usual configuration on the docker-compose.yml \n ````\n labels:\n - \"traefik.enable=true\"\n - \"traefik.http.services.flame.loadbalancer.server.port=5005\"\n - \"traefik.http.routers.flame.rule=Host(`flame.<tailscaledomain>.ts.net`)\"\n - \"traefik.http.routers.flame.entrypoints=web\"\n ```\n ​\n but that doesn't work, I guess because tailscale doesn't know how to route this sub domain.\n is anyone having a similar setup?\n    submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhqjcd/traefik_behind_tailscale_how_to_configure/",
          "publishedOn": "2022-12-10T11:41:17.000Z",
          "wordCount": 17089,
          "title": "Traefik behind tailscale, how to configure subdomains?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhq5kw/an_ode_to_software_products_over_software/",
          "author": null,
          "description": "submitted by    /u/joingardens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhq5kw/an_ode_to_software_products_over_software/",
          "publishedOn": "2022-12-10T11:21:10.000Z",
          "wordCount": 15122,
          "title": "An Ode to Software Products over Software Services (Basecamp, Hey Founder)",
          "imageUrl": "https://external-preview.redd.it/jsSIQcBsghwPBH8wSxS0HiYm4W_NFefV4TLpzH9I4_Q.jpg?auto=webp&s=155e1d6bed9c2e02412a8a78caf5e8b2e1bd9818"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhpsgy/kopia_correct_way_to_schedule_snapshots/",
          "author": null,
          "description": "Hi! I've installed kopia cli on my home server from the apt repository.\n A bit confused - do I need to setup a cron to have regular snapshots? \n I've setup a global schedule with a snapshot time of 0:00 but the history and logs say that no snapshots were taken so far. Do I need to have a kopia daemon/service/container for regular snapshots?.. What is the correct way of setting this up?\n    submitted by    /u/a-lagopus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhpsgy/kopia_correct_way_to_schedule_snapshots/",
          "publishedOn": "2022-12-10T11:02:08.000Z",
          "wordCount": 15957,
          "title": "Kopia: Correct way to schedule snapshots?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zho6bx/combine_knowledge_base_as_notes_and_bookmarks/",
          "author": null,
          "description": "I do have some problems with my browsing, bookmarks and notes taking situation: \n  \nmillions of tabs open on my phone not worth a bookmark because used for a specified topic which will be done in a couple of weeks\n millions of tabs open on my PC (same situation like the tabs on my phone)\n family Callander app on my phone to share notes and a calendar with the family \n markdown file on my main PC as knowledge database \n google notes on my PC and phone to share my notes \n  \nI'd like to combine all this: Have a markdown based knowledge base with headlines which will be folder for my bookmarks. So if I add a bookmark on my Firefox it should be printed in the markdown file and vis versa. I want to take notes in the knowledge base regarding the bookmark.\n Want to share notes with other people and between PC and android. The notes and knowledge base should be shomehow combined, but I'm not sure how to do that\n Is there anything like that available on the market?\n    submitted by    /u/Traditional_Sky_7824  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zho6bx/combine_knowledge_base_as_notes_and_bookmarks/",
          "publishedOn": "2022-12-10T09:36:30.000Z",
          "wordCount": 18538,
          "title": "combine knowledge base (as notes?) and bookmarks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhnx4z/to_minipc_or_not_to_minipc_that_is_the_question/",
          "author": null,
          "description": "Hi all,\n I've currently got a DS918+ running lots of docker containers, including Plex (which I've shared with a few friends in different countries), and I'm considering moving my containers to an NUC-like machine from Beelink - SEI12. Has anyone had any experience with this device, or would you recommend another, or in fact, would you suggest I just stick with running everything on my 918+??\n Thanks!\n    submitted by    /u/reddit_lanre  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhnx4z/to_minipc_or_not_to_minipc_that_is_the_question/",
          "publishedOn": "2022-12-10T09:22:28.000Z",
          "wordCount": 18009,
          "title": "To miniPC, or not to miniPC? That is the question...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhn422/press_enter_to_run_a_speedtest_update_v254/",
          "author": null,
          "description": "submitted by    /u/GoRedPlanet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhn422/press_enter_to_run_a_speedtest_update_v254/",
          "publishedOn": "2022-12-10T08:33:07.000Z",
          "wordCount": 16825,
          "title": "Press 'Enter' to Run a SpeedTest (Update v2.5.4) - Self-Hosted SpeedTest - Docker",
          "imageUrl": "https://external-preview.redd.it/J8TGf9AQ4TCStlv-yvzpsK3X1nHNqxzd7RFIpKcM39Q.png?format=pjpg&auto=webp&s=9a5fe46cd8fed4a16302fdf030838ef3e8702841"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhmyvx/should_i_use_a_raspberry_pi_cluster_or_dedicated/",
          "author": null,
          "description": "I'm developing my own SaaS platform, and I'd like to host it myself. I want to host it using a cluster of RPIs, but I don't know if they'll be powerful enough. \n The project uses microservices with k3s, and I have a service which builds containers based on a GitHub repo the user uploads. The cluster is also responsible for taking the built containers and running them in their own separate namespace. I'm skeptical that the Pis won't be powerful enough to host all the services as well as build and run containers simultaneously, and I don't know how well it will scale either.\n I wanted to start with a 3-4 node cluster of RPI CM4s, but are there any alternatives I should consider over an RPI cluster?\n    submitted by    /u/Time-Conference-4083  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhmyvx/should_i_use_a_raspberry_pi_cluster_or_dedicated/",
          "publishedOn": "2022-12-10T08:24:06.000Z",
          "wordCount": 15923,
          "title": "Should I use a Raspberry Pi cluster or dedicated server for my Kubernetes cluster?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhmgje/how_to_create_a_custom_lab_environment_for_each/",
          "author": null,
          "description": "I am developing an educational software.\n I need to create a lab environment for each user.\n Users will be able to open a specially created linux machine with novnc and manage it through the browser. By running vulnerable machines in a lab environment, isolated machines and networks must be created for each user.\n If the user wants to scan the vulnerable target machines isolated for him using his own physical computer, he will be able to access it with VPN.\n If he does not want to use VPN and physical computer, he will be able to reach target machines with novnc.\n All they need to do is press a button.\n I tried using proxmox, openvpn, pfsense for this, I tried to create vlans for each user, but I thought it would be inefficient and difficult.\n I am currently researching cloud management software in the style of cloudstack, how do you think I can do this?\n    submitted by    /u/Eastern-Narwhal3169  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhmgje/how_to_create_a_custom_lab_environment_for_each/",
          "publishedOn": "2022-12-10T07:53:35.000Z",
          "wordCount": 16071,
          "title": "How to create a custom lab environment for each user?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhibio/those_of_you_who_use_transmission_how_do_you/",
          "author": null,
          "description": "I just installed Umbrel on my server and I am currently setting it up. I am following this guide that I found on this sub to set up a Jellyfin Media Server. The guide uses qBittorent in the set up, but sadly Umbrel doesn't have it in its app store. I am still new to this, so I would prefer to avoid the figuring out of how to install it manually and enable access to other containers like Radarr and Sonarr from it.\n So is there any way to use Transmission to have multiple download folders? IPer the tutorial, categories are created in qBittorrent with different save paths. So that torrents from Radarr download into one folder and torrents from Sonnar download into another folder. Making it much easier to organize a Jellyfin library. Is something like this possible with Transmission? If not, those of you who use transmission, how do you organize your Jellyfin library?\n P.S. I saw Umbrel has community stores you can add. Any trustworthy one that has qb there?\n    submitted by    /u/DryHumpWetPants  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhibio/those_of_you_who_use_transmission_how_do_you/",
          "publishedOn": "2022-12-10T04:02:54.000Z",
          "wordCount": 16129,
          "title": "Those of you who use Transmission, how do you organize your Jellyfin library?",
          "imageUrl": "https://external-preview.redd.it/C0kOOjBNJ7urmNBSB5BYBFrjDkgfJvMpQ-7QHfGyJAE.jpg?auto=webp&s=f58e82fedab7c7b5994944c5d8e27efde7d12429"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zhec1z/flagdown_the_open_source_configcat_alternative/",
          "author": null,
          "description": "submitted by    /u/BetaThing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zhec1z/flagdown_the_open_source_configcat_alternative/",
          "publishedOn": "2022-12-10T00:54:16.000Z",
          "wordCount": 15666,
          "title": "Flagdown: The open source ConfigCat alternative",
          "imageUrl": "https://external-preview.redd.it/CfNJQJVB1iRkTvkrM0h7ePNepbluga-mP2-_QTp7AeM.jpg?auto=webp&s=b665772ba8fc3775e7a26ca8a12dd9fffe9e71a4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zha71y/noise_reduction_on_local_server/",
          "author": null,
          "description": "Hi, I've had this big 4u server in my living room for a long time now. it's a great box and could do a lot, but it's really loud. I like to work on audio editing/etc also in the same room. Anyone have any tips or tricks for something that might reduce the noise output from this system? Thanks,\n    submitted by    /u/sorressean  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zha71y/noise_reduction_on_local_server/",
          "publishedOn": "2022-12-09T22:05:49.000Z",
          "wordCount": 15773,
          "title": "noise reduction on local server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh9gh6/looking_for_tips_on_how_to_improve_speed_of_my/",
          "author": null,
          "description": "Computer Specs:\n  \nAMD Ryzen 7 3700X 8-Core Processor\n \nCORSAIR Vengeance LPX 32GB (4 x 8GB) 288-Pin PC RAM DDR4 3200\n \nASUS ROG Strix GeForce RTX 2080 Ti 11GB GDDR6 (for plex encoding/transcoding, I used it because I had it)\n \n OS: TrueNAS-SCALE-22.02.4\n Storage:\n  \n1 X 18tb, 1 x 4tb, 2 x 6tb drives all in one zfs pool (I know, no redundancy, very bad)\n \nsooner than later I will be upgrading to two a 2 x 18tb zfs pool with a 2 X 18tb mirror\n \n Apps are run one of two ways:\n  \nNatively as truenas \"apps\" either from truenas or truecharts in truenas's kubernetes cluster\n \nAs regular docker containers in a portainer instance running in truecharts' docker compose app\n \n Hosting: \n  \nCloudlfare free tier\n \napps are connected to my domain via truecharts' traefik reverse proxy app\n \n The problem:…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh9gh6/looking_for_tips_on_how_to_improve_speed_of_my/",
          "publishedOn": "2022-12-09T21:35:07.000Z",
          "wordCount": 17000,
          "title": "Looking for tips on how to improve speed of my selfhosted apps. Setup info in post, any advice would be appreciated",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh7p15/how_to_create_and_use_vms_in_a_headless_linux/",
          "author": null,
          "description": "I have a headless Ubuntu server. I connect to it using SSH. How can I create VMs using qemu-kvm from the command line (no GUI or monitor)?\n Something like (I just made these up):\n qemu-virt —ram 2g —disk 20g —network bridge —name ubuntu \n qemu-virt start ubuntu\n qemu-virt status ubuntu\n    submitted by    /u/chaplin2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh7p15/how_to_create_and_use_vms_in_a_headless_linux/",
          "publishedOn": "2022-12-09T20:24:22.000Z",
          "wordCount": 15658,
          "title": "How to create and use VMs in a headless Linux server from the command line",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh656m/strange_ssh_last_login/",
          "author": null,
          "description": "submitted by    /u/Vicuuu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh656m/strange_ssh_last_login/",
          "publishedOn": "2022-12-09T19:23:24.000Z",
          "wordCount": 18741,
          "title": "Strange SSH Last Login",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh5nwf/s3backed_image_host/",
          "author": null,
          "description": "I've used Piwigo for years to host my photos, and I want to move them to AWS where object storage is cheap. There's a piwigo plugin for this, but it's 9 years old and doesn't claim compatibility with any recent release.\n With the widespread use of AWS free tier and also homemade k8s and the like I'd sort-of expected this to be a well-worn problem, but I've scanned the docs for all the self-hosted image galleries I can find and none seem to claim to do this.\n Has anyone got any recommendations for a gallery that does this, or one that has a plugin I've not found? I upload with shotwell and would like to keep that if I can.\n I know I can s3fs it but that feels a bit bodgy and likely to have odd problems.\n    submitted by    /u/BigRedS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh5nwf/s3backed_image_host/",
          "publishedOn": "2022-12-09T19:04:14.000Z",
          "wordCount": 16963,
          "title": "S3-backed image host?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh4ot3/alternatives_to_casaos_umbrel/",
          "author": null,
          "description": "I am running CasaOS on my Raspberry PI , also tested umbrel but with umbrel I don't know how to install Apps that is not listed on the AppStore. CasaOS is good, but I need more widgets. \n -> 1 Click Docker Apps Install\n -> Good UI\n -> Large App Collection.\n I like to know which is your dashboard or Home Cloud System.\n If possible please post a screenshot and name of the OS/Dash.\n    submitted by    /u/DinkanGod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh4ot3/alternatives_to_casaos_umbrel/",
          "publishedOn": "2022-12-09T18:25:54.000Z",
          "wordCount": 16157,
          "title": "Alternatives to CasaOS & Umbrel",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh3ouf/reprovisioning_time_should_i_keep_nextcloud/",
          "author": null,
          "description": "When I moved to proxmox, I left some of my original server intact as a Debian LXC tucked within the proxmox hypervisor. Since then I've been migrating services from that \"master\" LXC into dedicated containers, which was particularly useful for Home Assistant, which is increasingly a total nightmare to run pretty much anywhere outside HAOS. So, HASS, Unifi and Logitech Media Server all live outside that LXC, and they're pretty happy living outside on their own. I don't mind taking the slight hit to memory as I've got plenty in the server.\n But now I'm wondering if I should move nextcloud outside as well. Can folks recommend an approach? Looks like NextCloudPi is one option. Any opinions from others who are in the same sort of proxmox deliberations? Best to give nextcloud it's own pasture, or is it happy grazing alongside the general rabble of sonarr, radarr, etc etc\n    submitted by    /u/Kidwellj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh3ouf/reprovisioning_time_should_i_keep_nextcloud/",
          "publishedOn": "2022-12-09T17:48:45.000Z",
          "wordCount": 17912,
          "title": "Reprovisioning time: should I keep nextcloud inside general purpose debian LXC or inside its own container?",
          "imageUrl": "https://external-preview.redd.it/RzKdR0O_D1IRWusZj4iWaOA11FiCE9t_mXhjSVSpu3E.jpg?auto=webp&s=dc18c938e95a8c78aee911a66585b14911650f40"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh3jcq/wireguard_client_unable_to_access_webserver/",
          "author": null,
          "description": "Hi selfhosted, \n I have a nginx webserver to access some services from outside my home network. I have a Wireguard server to access some services that are not exposed via webserver. When I'm not connected to the wireguard server, I can access the webserver exposed services without any errors.\n The problem I am having is when my phone (wireguard client) is connected to the wireguard server and tries to access the webserver services (https://app.domain.tld), it keeps giving an `NET::ERR_CERT_AUTHORITY_INVALID` error and message that says \"Your connection is not private\". \n However, while connected to the wireguard server, my client is able to access internet and LAN services using hostname:port (http://192.168.1.6:3030). \n I am not sure why this is case. Oddly enough, I am able to access my webserver services from within my LAN as long as i am not connected to the wireguard server.\n ​\n Any help on this would be greatly appreciated. It is quite annoying to having to connect/disconnect to my wireguard vpn server in order to access different services.\n    submitted by    /u/Quick_Parsley_6482  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh3jcq/wireguard_client_unable_to_access_webserver/",
          "publishedOn": "2022-12-09T17:42:46.000Z",
          "wordCount": 18474,
          "title": "Wireguard client unable to access webserver services",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh1rog/best_self_hosted_iptv/",
          "author": null,
          "description": "Hi everyone, I hope you all are doing well. is there any iptv server to host on docker? Thank you.\n    submitted by    /u/Kaziopu123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh1rog/best_self_hosted_iptv/",
          "publishedOn": "2022-12-09T16:32:41.000Z",
          "wordCount": 15600,
          "title": "Best self hosted iptv?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh1i8v/i_need_a_chatgpt_for_all_my_self_hosted/",
          "author": null,
          "description": "submitted by    /u/a_sugarcane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh1i8v/i_need_a_chatgpt_for_all_my_self_hosted/",
          "publishedOn": "2022-12-09T16:22:14.000Z",
          "wordCount": 15588,
          "title": "I need a ChatGPT for all my self hosted applications!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zh0i74/any_self_hosted_or_similar_programs_rtp_detection/",
          "author": null,
          "description": "Can you recommend any self hosted or similar programs to that of Malwarebytes.\n Specifically free and one that can block real time threats just like this program does in the photo?\n link to photo imgur\n I have Avast but that doesn't seem to do what Malwarebytes does in this manner of blocking incoming threats like this or that is displays.\n    submitted by    /u/AmIBeingObtuse-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zh0i74/any_self_hosted_or_similar_programs_rtp_detection/",
          "publishedOn": "2022-12-09T15:41:28.000Z",
          "wordCount": 16456,
          "title": "Any self hosted or similar programs rtp detection",
          "imageUrl": "https://external-preview.redd.it/DkVJzlt0Am4fSfjG-jO_jjySRJCoJZONvCY5tZadAbA.jpg?auto=webp&s=2bf9c2b5b1df90cbc220b1059f83be53583efbc9"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgznby/self_hosted_email_server/",
          "author": null,
          "description": "I have my own email server I used emailwiz to set it up. I also used dynadot for a domain name registrar. I switch from epik to dynadot but when I send an email I get this error in postfix\n Dec 9 13:01:18 rebootcyber postfix/smtp[17781]: 13236278774: to=<Email@email.com>, relay=mxa-002d4f01.gslb.pphosted.com[148.163.155.171]:25, delay=29806, delays=29797/0.03/8.7/0, dsn=4.0.0, status=deferred (host mxa-002d4f01.gslb.pphosted.com[148.163.155.171] refused to talk to me: 554 Blocked - see https://ipcheck.proofpoint.com/?ip=207.148.23.122) \n If this is not the right sub let me know.\n    submitted by    /u/LeastZombie3436  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgznby/self_hosted_email_server/",
          "publishedOn": "2022-12-09T15:05:55.000Z",
          "wordCount": 16488,
          "title": "Self hosted email server",
          "imageUrl": "https://external-preview.redd.it/Mesj1M03bQDyhM0T863a1GezGDZvtMn6QAjhPZzvEeg.jpg?auto=webp&s=0e9cf4010e0133beeff54739d1525cd87625de88"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgz1b2/photo_and_video_viewing_recommendations/",
          "author": null,
          "description": "This is my first ever Reddit post so apologies I'm if doing Reddit wrong :P. I have gone through a number of recommendations on this subreddit but run into trouble after installing with it not having features etc. It also seems as though the list of active projects is constantly in flux.\n I have 1TB of photos currently synced via OneDrive. They are organized by year/month and have tags of names and star ratings. Unfortunately, the Onedrive backend is slow (especially for 4k video) and is limited in features. My dream would be to have a shared self-hosted lightroom replacement but my realistic workflow is to use lightroom for editing and then have a full-library export that will be viewable by family members online. I was wondering if ya'll could give me a recommendation. Here is what I am looking for:\n Minimum:\n  \nNavigate images/videos by folder structure\n Authentication (would be great if you could use google for the login flow and just save a list of permitted email addresses).\n Searchable, including keywords and star ratings\n A nice interface that will get the stamp of approval from the lady\n Web interface\n Feature complete or actively updated\n Free OR a perpetual license (no subscriptions!)\n  \nReally want:\n  \nTranscoding to stream 4k videos over 5mbps up data pipe (hardware transcoding preferred). I have an AMD cpu and graphics card.\n Search includes things automatically identified in the images (beach, tree, ball - nothing crazy). Facial recognition could be nice too.\n  \nNice to Have\n  \nMap view\n Be able to work on the main database:\n Phone upload (android and ios)\n Can view Canon raw files (Canon R7 and old EOS images) - could just be the preview thumbnail\n Can view .heif files\n The source of truth is the file system - Any modifications made in the UI (keywords, captions, rating) are stored in the file itself (not an app database)\n  \n   submitted by    /u/Objective_Medium_763  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgz1b2/photo_and_video_viewing_recommendations/",
          "publishedOn": "2022-12-09T14:40:45.000Z",
          "wordCount": 16197,
          "title": "Photo and Video viewing recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgyxrw/trying_to_improve_network_security_a_bit/",
          "author": null,
          "description": "Hiya, i'm a bit choice paralyzed when it comes to buffing the home network.\n Our main services run on a Synology NAS, HomeAssistant on a NUC, PiHole (for local DNS too) and NPM on 2 different RasPis and all that goes through a ASUS Router with Merlin Firmware.\n I'm exposing the Ports on NPM so I can access Bitwarden and HomeAssistant, other services like Plex do it on their own (UPNP?).\n Any general advice I could follow? I wanted to use Cloudflare tunnels with Google auth, but it seems anyone with Google auth could log in there, lol...? didn't seem to be whitelist-able? But that has the downside of not being able to use Bitwarden. \n Maybe I have a fundamental misunderstanding on those things. Since I plan on re-doing my networking soon I thought I ask now :) Thanks for any advice.\n    submitted by    /u/Saeris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgyxrw/trying_to_improve_network_security_a_bit/",
          "publishedOn": "2022-12-09T14:36:37.000Z",
          "wordCount": 17682,
          "title": "Trying to improve network security - a bit overwhelmed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgyl48/economical_vps_provider_for_offsite_backup/",
          "author": null,
          "description": "Hello fellow self-hosters!\n I'm looking to expand my homelab out to the cloud, namely in order to have off-site backup capabilities. I want to continue to manage my own services, so Backblaze, while superb, isn't something I want to pursue for this (though, I do use Backblaze to backup the computer I'm currently sitting at).\n Can anyone direct me to the absolute cheapest VPS provider you can find? Number of cores is unimportant, nor is RAM. The biggest criteria is cheap storage. To do that, I'm 100% fine with using legacy spinning storage rather than SSD's and NVMe.\n Ideally, looking for a VM with 1-2 TB of storage in the $10-15 range. I don't know if that's too optimistic.\n Any ideas?\n Thanks!\n    submitted by    /u/AuthenticImposter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgyl48/economical_vps_provider_for_offsite_backup/",
          "publishedOn": "2022-12-09T14:21:35.000Z",
          "wordCount": 18268,
          "title": "Economical VPS provider for off-site backup?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgxryn/anonymous_photo_upload_with_lychee_or_alternatives/",
          "author": null,
          "description": "I have the following scenario: Several tech-unsavvy people took pictures at a wedding. I would like to host a website where everyone can upload their pictures, ideally from their phones, and have access to each others' pictures.\n I am trying to set up Lychee, but so far I have not managed anonymous upload. I don't want everyone to register or create a dummy account that they have to use. Is this even possible with Lychee or are there better alternatives?\n    submitted by    /u/Detectorbloke  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgxryn/anonymous_photo_upload_with_lychee_or_alternatives/",
          "publishedOn": "2022-12-09T13:46:53.000Z",
          "wordCount": 15276,
          "title": "Anonymous photo upload with Lychee (or alternatives)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgx034/centralize_all_notifications/",
          "author": null,
          "description": "I am looking for an open-source self hosted solution to centralize all my notifications from social networks, emails and home assistant and receive them on mobile phone by priority. And have different notification profiles based on priority. For example a profile for notify all notifications for working hours. a profile to only notify the items with high priorities during the weekend and etc.\n    submitted by    /u/yottanami  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgx034/centralize_all_notifications/",
          "publishedOn": "2022-12-09T13:11:58.000Z",
          "wordCount": 15620,
          "title": "Centralize all notifications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgvswx/sending_emails_without_smtp_relay/",
          "author": null,
          "description": "Hi, usually on my servers I configure msmtp with an external free mail service provider to send e-mail notifications to myself. But this has one limitation. I can only send from the registered e-mail address (eg. secretname@provider.com) because everything else (eg. secretname@mydomain.com) wouldn't be allowed by that specific mail provider.\n This isn't a problem when I'm sending notifications to myself, but some self hosted services rely on e-mail. For example Gitea \"anonymizes\" emails like github does. So it gives users mail addresses like skdfhskdjf@noreply.my-gitea-instance.de\n This is a feature that I can't use with above limitations. Now I am searching for a better solution where I can send e-mails from my own domain or whatever else.\n Should I host a very basic (sending only) mail server myself? Or should I register somewhere, where I can create unlimited e-mail accounts for my own domain and still use the msmtp route?\n The last one seems difficult because I already use that domain for my private e-mail. So in that domain's DNS is already the MX records of my mail provider. Which doesn't allow multiple accounts etc. I'm not sure if I can set MX records of another provider on the same domain... PS: I don't want to switch away from my existing mail provider.\n What would you do?\n    submitted by    /u/Trevor_Tn1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgvswx/sending_emails_without_smtp_relay/",
          "publishedOn": "2022-12-09T12:16:37.000Z",
          "wordCount": 18456,
          "title": "Sending emails without smtp relay",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgtyac/i_made_p%C3%B8nskelisten_a_selfhosted_wishsharing/",
          "author": null,
          "description": "submitted by    /u/oysteinsv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgtyac/i_made_p%C3%B8nskelisten_a_selfhosted_wishsharing/",
          "publishedOn": "2022-12-09T10:47:33.000Z",
          "wordCount": 19580,
          "title": "I made Pønskelisten, a self-hosted wish-sharing platform, for my family! You can share wishlists and claim gift ideas. It's really early in development currently so not friendly to install, but it is available at aunefyren/poenskelisten on GitHub. Is this something people find useful?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgt0lj/best_self_hosted_service_youre_using_for_music/",
          "author": null,
          "description": "Hi everyone, I hope you all are doing well. I want to make a server for my music. Any recommendations? Thank you.\n    submitted by    /u/Kaziopu123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgt0lj/best_self_hosted_service_youre_using_for_music/",
          "publishedOn": "2022-12-09T09:59:29.000Z",
          "wordCount": 16298,
          "title": "Best self hosted service you're using for music?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgsf6k/announcing_changedetectionio_0400/",
          "author": null,
          "description": "Hi all! We are proud to announce the newest major release of our self hosted website change detection and notification app, whats new? Browser steps - Interact with the browser (login to sites, accept cookies etc) before change-detection, Dark mode - because you love it Automatically follow LDJSON price data - on websites that support it, More notification hooks - not just messaging (slack/discord/telegram etc) but also post://, get:// and others to make driving other services easier Extract data as CSV for example, watch realestate websites and easily make a CSV of the number of houses for sale, or your favourite whiskey's price! enjoy! and please help spread this app :) https://github.com/dgtlmoon/changedetection.io\n https://preview.redd.it/ho3wsk6ocu4a1.png?width=1302&format=png&auto=webp&s=e5522a3f718dc38d7e52421d8605d855cdf50685\n    submitted by    /u/dgtlmoon123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgsf6k/announcing_changedetectionio_0400/",
          "publishedOn": "2022-12-09T09:27:49.000Z",
          "wordCount": 17856,
          "title": "Announcing changedetection.io 0.40.0 !",
          "imageUrl": "https://external-preview.redd.it/FgP6DjSXT_qCq-i3koJCv0YDbC913R-6HDEIWzCR0OM.jpg?auto=webp&s=6a2d3cd50067050e0a862a82d5c6d75e771c5a6b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgrhc9/never_really_understood_how_to_use_docker/",
          "author": null,
          "description": "submitted by    /u/nkls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgrhc9/never_really_understood_how_to_use_docker/",
          "publishedOn": "2022-12-09T08:36:38.000Z",
          "wordCount": 17619,
          "title": "Never really understood how to use docker networks. I just asked the new AI ChatGPT to explain it in a proper way to me. 🤯",
          "imageUrl": "https://preview.redd.it/jgvx0fkj3u4a1.png?auto=webp&s=3f66c53cef9d6e49f7f7e26c4e44690a5602728a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgm9ax/is_a_thinkcenter_m900_tiny_with_i56500t_and_16gb/",
          "author": null,
          "description": "I've just recently started to self host, i have a raspberry pi running nextcloud and i got an awesome rush out of setting it all up, i don't have a public IP so i even had to setup an ssh tunnel between an oracle VPS and the RPI to enable access everywhere.\n Anyways, i want to keep playing with selfhosted services but I ran out of VPS and i want to get a PC i can use as a home server to play with.\n I found a good deal for the M900 tiny and i plan to install Ubuntu on it and play with virtual machines on it. \n I'm completely amateur, i don't have any formal IT training but i do know a bit about networking, web development, python programming and I know fairly well my way around Linux although I'm far from a sysadmin. \n So I would like to ask for advice regarding if this computer is a good place to start my home lab. I don't have a much of a budget.\n These are kind of services would I like to run off the computer in the VMs I'd set up: -mail in a box -adguard -plex -mysql -mongo -some websites -many discord bots \n I wouldn't run all, and definitely not at the same time. They're just examples.\n So is this computer good for me? Should I look for something else? What are your recommendations?\n Edit: Thanks everyone for answering, I just order it. I'll try to run everything on docker containers to use the most out of the pc. I'll be updating how it goes\n    submitted by    /u/alexdewa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgm9ax/is_a_thinkcenter_m900_tiny_with_i56500t_and_16gb/",
          "publishedOn": "2022-12-09T04:02:37.000Z",
          "wordCount": 18208,
          "title": "Is a thinkcenter M900 tiny with i5-6500T and 16GB ram good for my first lab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgj2lc/selfhosted_solution_solution_like_cloudflare/",
          "author": null,
          "description": "Does anyone know of a self-hosted solution to protect website access from bots?\n - Routing on nginx based on IP location(or other criteria) - either to website directly(white IP) or captcha page (grey IP)\n - if captcha is successfully resolved, provide access to the website.\n It seems to be quite a simple thing so there should be some already made solutions?\n    submitted by    /u/jester_juniour  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgj2lc/selfhosted_solution_solution_like_cloudflare/",
          "publishedOn": "2022-12-09T01:37:21.000Z",
          "wordCount": 16267,
          "title": "Self-hosted solution solution \"like Cloudflare\" - dynamic captcha for website access?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgic0u/document_photo_ingest_solution/",
          "author": null,
          "description": "I'm curious to hear how people are ingesting and organizing their documents (bills, receipts, etc.) and photos. I want to start making a habit of ingesting documents into my NAS with OCR and some auto categorization features. Curious what hardware and software combos people are using for this. \n Also looking to ingest a mass of pictures without a ridiculous amount of time and effort. Also open to suggestions on hardware for this?\n    submitted by    /u/ColonelRyzen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgic0u/document_photo_ingest_solution/",
          "publishedOn": "2022-12-09T01:08:03.000Z",
          "wordCount": 16269,
          "title": "Document + Photo Ingest Solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zghodq/tailscale_how_to_restict_access/",
          "author": null,
          "description": "I've installed tailscale and added 3 servers from home network: hs1, hs2, hs3 and 4 public vps servers: vp1,vps2, vps3, vps4.\n I want my home servers to be able to access vps servers, but not the other way around. \n How would I set that up?\n    submitted by    /u/cronicpainz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zghodq/tailscale_how_to_restict_access/",
          "publishedOn": "2022-12-09T00:41:39.000Z",
          "wordCount": 17219,
          "title": "tailscale - how to restict access",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zggnoi/i_own_a_domain_need_free_web_host_advice/",
          "author": null,
          "description": "I'd appreciate adviice as to hosting a simple website for the domain I own. A free one would be ideal, especially one to which I can easily transfer domain. but also, if necessary, transfer out. \n Many thanks. Peter\n    submitted by    /u/psilversmith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zggnoi/i_own_a_domain_need_free_web_host_advice/",
          "publishedOn": "2022-12-09T00:03:03.000Z",
          "wordCount": 15707,
          "title": "I own a domain - need free web host advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgf3mn/is_it_a_bad_idea_to_host_a_pihole_remotely_on_a/",
          "author": null,
          "description": "I guess this is a two part question:\n  \nWhat kind of latency should I look for from DNS? My closest VPS location is Vultr in Seattle which averages about 16-18MS most of the time.\n Are there security implications of hosting a DNS server on the public internet?\n  \nNever done this before but being able to use it on the go without a VPN sounds nice.\n    submitted by    /u/SLJ7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgf3mn/is_it_a_bad_idea_to_host_a_pihole_remotely_on_a/",
          "publishedOn": "2022-12-08T23:06:55.000Z",
          "wordCount": 16767,
          "title": "Is it a bad idea to host a PiHole remotely on a VPS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgd9bd/store_tick_data_in_postgres_using_celery_rabbitmq/",
          "author": null,
          "description": "I am using websocket to stream quotes close to 100 stocks and sending to celery rabbitmq task to insert the tick datas to Postgres DB. I am using evenlets for concurrency , wanted to know what thread size I should be using ? Seems default concurrency is 8. But seems task are getting struck and celery is stopped working .\n    submitted by    /u/Few_Faithlessness_96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgd9bd/store_tick_data_in_postgres_using_celery_rabbitmq/",
          "publishedOn": "2022-12-08T22:02:54.000Z",
          "wordCount": 16273,
          "title": "Store tick data in Postgres using Celery & RabbitMQ - Python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zgc8yd/homer_background_image_customization/",
          "author": null,
          "description": "I recently installed homer and just finished adding all of my groups and apps to it. I'm using the \n background-image: \"/assets/tools/image.png\" \n command so that I can add my desired picture. I saw in the documentation on github that you can create custom configurations. I tried looking up how to do this since the yml file is in html I believe. I tried using the things listed such as \n background-size: background-position: \n but these did not help with anything. I'm new to editing scripts like this and am looking for some guidance. I'd like position the picture in the center of my screen instead of it automatically enlarging itself. I would also like to add an image to the header since I saw that was possible in one of the custom configs. Would I need to create a new yml file or can I edit this into my current one?\n    submitted by    /u/DocRobertz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zgc8yd/homer_background_image_customization/",
          "publishedOn": "2022-12-08T21:27:44.000Z",
          "wordCount": 16414,
          "title": "Homer Background Image Customization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg8pqi/any_selfhosted_iam_tool_which_provides/",
          "author": null,
          "description": "I'm looking for an IAM service that offers Multi-factor or Standard Username/Password authentication for my self-hosted apps that lack a native authentication system.\n I'm familiar with Authelia, but they don't support apps hosted through the Cloudflare tunnel.\n ​\n Do you have any recommendations for an easy-to-use IAM system?\n    submitted by    /u/ajnerd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg8pqi/any_selfhosted_iam_tool_which_provides/",
          "publishedOn": "2022-12-08T19:26:12.000Z",
          "wordCount": 16254,
          "title": "Any Self-hosted IAM tool which provides Multi-factor or basic username/password Auth for self-hosted Apps?",
          "imageUrl": "https://external-preview.redd.it/cu_yt9TGy0XOd61Tpoo55Hi3PMpAZCAxbkWaMQIFawg.jpg?auto=webp&s=02ff51de33eed61cf2487f251e1754f311ecbbae"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg7i1s/web_app_for_searching_music_with_tags/",
          "author": null,
          "description": "Hey guys, \n I have recorded manny records from my vinyls to MP3 files. Sometimes I have problems to find the right music to prepare my mix with my dj controller. So I want to tag my mp3s, like in paperless DMS. For example: Feral - Medium #techno #deep #key:minor #intro\n I would like to search the tracks and create a tracklist and later download the mp3 files.\n It sounds a little complicated, it probably is, but I can't remember any artistic names to search the tracks. For me it's by feel and this feel I would like to write in tags. If there is such a thing I would be happy if you can tell me such a web application. If you are DJs yourselves and you have a better idea, then I would be happy about advice and ideas.\n    submitted by    /u/_akadawa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg7i1s/web_app_for_searching_music_with_tags/",
          "publishedOn": "2022-12-08T18:44:55.000Z",
          "wordCount": 15455,
          "title": "Web App for searching music with tags",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg7aga/hamachi_tailscale_zerotier_hosting_games_for_a/",
          "author": null,
          "description": "Hi selfhosted\n I couldnt find a definitiv answer for this. Ill make it real simple\n I want to host games and servers for a community where complete strangers have access, aswell as its a little bit of a shady one. So the chances of a hacking attack is increased.\n I have read that hamachi basically cuts out the protection you would usually have with a firewall and the internet. So im assuming that a attack becomes much more sucessfull.\n Do any of the virtual network programs guarantee security from hackers, or are there ways to make it secure.\n ​\n thanks in advance for help\n    submitted by    /u/Edwo123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg7aga/hamachi_tailscale_zerotier_hosting_games_for_a/",
          "publishedOn": "2022-12-08T18:37:42.000Z",
          "wordCount": 16245,
          "title": "Hamachi, Tailscale, Zerotier, Hosting games for a small community security risks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg6gvw/a_web_based_note_taking_toolmapping_similar_to/",
          "author": null,
          "description": "Im looking for something to take notes on while I study for some certifications but I'd like to access it remotely and not require a specific device to use it. \n I know I could go the wiki route but I enjoy how obsidian/dendron does the note mapping.\n    submitted by    /u/HardChalice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg6gvw/a_web_based_note_taking_toolmapping_similar_to/",
          "publishedOn": "2022-12-08T18:08:45.000Z",
          "wordCount": 15875,
          "title": "A web based note taking tool/mapping similar to like Obsidian or Dendron?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg40pi/new_to_docker_trying_to_get_changedetectionio_up/",
          "author": null,
          "description": "Hi guys, I've spent the last few hours trying to run changedetection.io on my raspberry pi. Throughout this process I have completely uninstalled and re-installed Docker and/or Docker-Compose, starting from scratch each time to make sure no past mistakes are leftover to interfere with new attempts. At no point have I been able to access the web UI, though I'm pretttty sure the container is running?\n I installed docker-composer by running \n $ sudo apt install docker-compose\n Among the installation output is:\n The following NEW packages will be installed: cgroupfs-mount docker-compose docker.io golang-docker- credential-helpers libintl-perl libintl-xs-perl libmodule-find-perl libmodule-scandeps-perl libproc-processtable-perl libsort-naturally-perl libterm-readkey-perl needrestart python3-cac…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg40pi/new_to_docker_trying_to_get_changedetectionio_up/",
          "publishedOn": "2022-12-08T16:36:01.000Z",
          "wordCount": 17920,
          "title": "New to Docker, trying to get changedetection.io up, help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg30dd/is_there_anything_that_can_replace_calibre/",
          "author": null,
          "description": "Calibre just always ends up being the default even as people architect around its shortcomings (e.g., Calibre-Web, COPS, etc.)\n We have photo organizers galore, other media apps, but ebooks seem stuck.\n Am I missing something out there?\n    submitted by    /u/LoPanDidNothingWrong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg30dd/is_there_anything_that_can_replace_calibre/",
          "publishedOn": "2022-12-08T16:00:44.000Z",
          "wordCount": 17891,
          "title": "Is there anything that can replace Calibre?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg2jyq/windows_server_cant_see_my_microsoft_sql_container/",
          "author": null,
          "description": "Hey all,\n I have a Proxmox host running two VMs. One is Ubuntu Server and another is Windows Server 2022. The Ubuntu VM is a docker host with a Microsoft SQL Server container running on it. Here is the docker-compose.yml I used: \n version: \"3.2\" services: mssql: image: 'mcr.microsoft.com/mssql/server:2022-latest' container_name: orion_db hostname: sql1 ports: - '1433:1433' environment: - ACCEPT_EULA=Y - SA_PASSWORD=<insertpassword> volumes: - '/.drive:/var/opt/mssql' \n Both VMs are on the same subnet with a firewall rule for the Ubuntu VM to explicitly allow connections from the Windows Server VM over ports 1433 and 1434. The DB server has also been configured to allow outbound connections through the CLI.\n However, when launching Microsoft SQL Server Management Studio on the Windows Server VM, I am only able to see the databases running on the Windows Server VM, even when selecting \"Network Servers\". Is there a step I missed or did I misconfigure something?\n    submitted by    /u/Extension_Lunch_9143  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg2jyq/windows_server_cant_see_my_microsoft_sql_container/",
          "publishedOn": "2022-12-08T15:44:27.000Z",
          "wordCount": 17109,
          "title": "Windows Server can't see my Microsoft SQL Container",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg2j2r/is_ocis_owncloud_infinite_scale_usable_yet/",
          "author": null,
          "description": "I've been running a Nextcloud instance for a few years now, and while I am quite happy with its extensibility, I've been looking to switch to OCIS. I tried setting it up (though, the documentation is still quite sparse at the moment), and while I got it working, I wasn't sure if it is considered to be stable or usable yet. What are your thoughts?\n    submitted by    /u/Tyetsa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg2j2r/is_ocis_owncloud_infinite_scale_usable_yet/",
          "publishedOn": "2022-12-08T15:43:30.000Z",
          "wordCount": 16188,
          "title": "Is OCIS (Owncloud Infinite Scale) usable yet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg16wq/looking_for_adive_and_good_practices_to_backup/",
          "author": null,
          "description": "TL;DR:\n I am asking for advice on the technologies I should use to setup a good backup strategy of both systems (VMs in Proxmox and docker containers on Intel servers, Raspberries, VPS) and data (user's homes on GNU/Linux laptops.\n I am currently considering Proxmox Backup Server and Borg as backup solutions. \n Long version:\n I've been using GNU/Linux both server side and desktop side (mostly Debian) for 25 years. Now I have self hosted all the services my small nonprofit organisation needs (30 users). I need advice and guidance on a backup solution. I have read a lot of material online. But I want to have advice from real people from the self hosting community. \n Everything is Linux. Desktops, laptops, servers. There is no MacOS or Windows laptops. \n Here is the global architecture: 2 phy…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg16wq/looking_for_adive_and_good_practices_to_backup/",
          "publishedOn": "2022-12-08T14:54:53.000Z",
          "wordCount": 17778,
          "title": "Looking for adive and good practices to backup Proxmox, Dockers and user's data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zg11ik/selfhosted_journaling_app/",
          "author": null,
          "description": "Is there a self hosted journaling app you use and can recommend? I don’t need it to be accessible from outside my home network.\n    submitted by    /u/fredflintstone88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zg11ik/selfhosted_journaling_app/",
          "publishedOn": "2022-12-08T14:49:11.000Z",
          "wordCount": 17792,
          "title": "Self-hosted journaling app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfzru9/ending_support_for_gitpod_self_hosted_and_moving/",
          "author": null,
          "description": "submitted by    /u/geoffreyhuntley  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfzru9/ending_support_for_gitpod_self_hosted_and_moving/",
          "publishedOn": "2022-12-08T14:01:33.000Z",
          "wordCount": 16041,
          "title": "Ending support for Gitpod Self Hosted and moving our source to AGPL",
          "imageUrl": "https://external-preview.redd.it/YX-ISt0ebTL_8Y85SI4pqHUsgGv6Yquve23Jd4sk9-E.jpg?auto=webp&s=085cf9e9bbc2eca8cbdc126a103974cfa5b4b80c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfyxw7/odyssey_of_finding_a_selfhosted_personal/",
          "author": null,
          "description": "Hi all,i'm getting a little frustrated trying to find a to-do app with kanban-view. There are some cool approaches on the market - but they are never thought through to the end.\n What do I need?\n  \nMultiple listview (= Categories) for managing\n  \n Tasks\n Subtasks\n Recurring-Tasks\n Due-Dates\n Priority\n  \n Kanban-View for drag & drop between stages (Backlog, Planned, This Week, Today, Done)\n Mobile-Support for\n  \n Creating new tasks\n Push-Notifications (Due-Dates)\n  \nNice to have\n  \nTime Tracking\n Kanban with Swimlanes (e.g. List-Categories as Swimlanes)\n Additional Labels, Search-Function, etc.\n  \nWhat I tried:\n  \nFocalboard -> Nice Web UI, but not mobile-friendly (e.g. Reminder / Push), no recurring tasks\n Nextcloud -> No recurring tasks, buggy combination with Deck for Kanban\n Vikunja -> CalDAV-Sync is great, but it's not supporting Subtask-Sync and Recurring-Task-Sync\n  \nMy dream would be a Vikunja with better Subtask-Creation (it's a pain doing this via UI) and CalDAV implementation, that I could use in combination with Tasks.org Android App with full features (recurring and subtasks) ...\n Any alternative on the market?\n    submitted by    /u/Simplixt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfyxw7/odyssey_of_finding_a_selfhosted_personal/",
          "publishedOn": "2022-12-08T13:28:48.000Z",
          "wordCount": 16169,
          "title": "Odyssey of finding a self-hosted personal Kanban/ToDo-Webapp with Mobile-App",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfxppo/hosting_my_own_website/",
          "author": null,
          "description": "I have a static IP and I want to host my own website. I used XAMPP, opened port 80 on the router and it worked, but after an hour got scared and stopped hosting. Every blog I've read said that it is a bad idea to do what I did because of possible DDOS attacks and other dangers, but how do to defend my website from that?\n    submitted by    /u/Paltsm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfxppo/hosting_my_own_website/",
          "publishedOn": "2022-12-08T12:37:49.000Z",
          "wordCount": 19036,
          "title": "hosting my own website",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfvuy3/discussion_the_value_of_mobile_apps/",
          "author": null,
          "description": "Not really a substantive post, but I was wondering on this sub’s opinion on mobile apps for self hosted services. Do you consider them essential, a nice bonus or not needed at all?\n I can personally get by with PWAs, but I vastly prefer having native applications, especially for services my partner also uses. As an iOS user I’m also kind of jealous of all of you in Android land, because that (unsurprisingly) seems to be the main focus for native apps for self hosted services.\n Also, what are some projects with nice mobile apps?\n    submitted by    /u/RandomName01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfvuy3/discussion_the_value_of_mobile_apps/",
          "publishedOn": "2022-12-08T11:04:15.000Z",
          "wordCount": 17925,
          "title": "[Discussion] The value of mobile apps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zftscj/joining_a_wifi_network_with_style/",
          "author": null,
          "description": "Hi r/selfhosted,\n Something a bit different from me this time :)\n If you need a guest Wi-Fi network for your home, office, or a coffee shop, you might as well do it with style!\n https://youtu.be/APTqu29ApRc\n Detailed instructions and a few tricks available at https://github.com/predmijat/qr_wifi\n I hope you like it!\n    submitted by    /u/predmijat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zftscj/joining_a_wifi_network_with_style/",
          "publishedOn": "2022-12-08T09:00:12.000Z",
          "wordCount": 15945,
          "title": "Joining a Wi-Fi network with style!",
          "imageUrl": "https://external-preview.redd.it/jc9rqJMwk8CL2NXgfp7sNUqGfUqDl7Q14TsbkkuvV4o.jpg?auto=webp&s=7500979ad0bd0f346d3d52c65aab878568ac2f05"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfo6nr/fyi_shopgoodwillcom_has_a_bunch_of_dell_wyse/",
          "author": null,
          "description": "I just snagged one with 8gb ram for 37 bucks. These go for 100+ on ebay. It's an auction thing so I had to bid at the last minute to get one. Upgrading my raspberry pi 4.\n    submitted by    /u/mattalat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfo6nr/fyi_shopgoodwillcom_has_a_bunch_of_dell_wyse/",
          "publishedOn": "2022-12-08T03:56:41.000Z",
          "wordCount": 17456,
          "title": "FYI: shopgoodwill.com has a bunch of Dell Wyse 5070's on sale for cheap",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfk332/namecheap_expired_domain_auction_redemption_period/",
          "author": null,
          "description": "Hi - if there is a better sub for this please let me know.\n I purchased a domain for a business idea a bit ago, things took longer to get going than I anticipated. Nothing was hosted on it yet, but it is the name I would like to launch this business under.\n I forgot (stupidly) to renew my domain. It expired at the end of September. It is currently in the \"redemption period.\" My registrar was Namecheap. They said I could get it out of redemption for about $100 (I forget the exact amount) or that if I just waited eventually it would be released *as long as nobody buys it at the auction.* My initial plan was to just wait it out, and I should be getting close to the time where it is released per Namecheap's associate... Today, the Whois is still saying Namecheap redemption period.\n But I was thinking today, where is this auction? I can't seem to find anything with google. There shouldn't basically any value to this website (I did have content on it like 10 years ago but that has long since been taken down), but I don't really want to lose it to someone who might get it at an auction because I'm being cheap. So, if I could just go to the auction and win it there...wouldn't that work?\n I'm a little over my head in this one and appreciate any help. Thanks!\n    submitted by    /u/metaphysicalreason  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfk332/namecheap_expired_domain_auction_redemption_period/",
          "publishedOn": "2022-12-08T01:00:15.000Z",
          "wordCount": 16616,
          "title": "Namecheap Expired Domain Auction / Redemption Period",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfjw3e/self_host_a_video_course_website_like_udemy/",
          "author": null,
          "description": "I have some courses on my hard drive that I would like to follow on a selfhosted platform that similiar to something like Udemy and Skillshare. It's for my own personal use. Some people on other Reddit posts said that Moodle is a great option. But if there are any different options I would love to know.\n    submitted by    /u/sappigekip  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfjw3e/self_host_a_video_course_website_like_udemy/",
          "publishedOn": "2022-12-08T00:52:28.000Z",
          "wordCount": 16288,
          "title": "Self host a video course website like udemy, skillshare",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfiv9d/file_upload_to_seafile_super_slow_over_cloudflare/",
          "author": null,
          "description": "Took almost 20 minutes to upload a 1gb iso I was testing. It was like the file stopped uploading then uploaded and then stopped. It dropped the the kb speed range a lot. An I using a setting wrong?\n    submitted by    /u/Fission455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfiv9d/file_upload_to_seafile_super_slow_over_cloudflare/",
          "publishedOn": "2022-12-08T00:10:04.000Z",
          "wordCount": 15754,
          "title": "File upload to seafile super slow over cloudflare tunnel?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfga4y/whats_on_your_selfhosted_christmas_list/",
          "author": null,
          "description": "Still figuring out mine but I'm interested in all of yours !\n    submitted by    /u/Zareix33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfga4y/whats_on_your_selfhosted_christmas_list/",
          "publishedOn": "2022-12-07T22:30:16.000Z",
          "wordCount": 16306,
          "title": "What's on your (selfhosted) Christmas list ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zffrsr/my_howto_on_installing_portainer_on_docker_on/",
          "author": null,
          "description": "My experience and how-to on installing and using portainer for docker containers on Ubuntu 22.04 server LTS. I won't pretend to understand every part of the below. I'm a noob on it mostly which made it not so easy for me so i'm hoping to help others as it was more confusing to this guy. My main hang up was trying to use a network share that was on my TrueNAS and Windows file server as i wanted this to almost store 0 files locally. I may edit this once i figure out more to save docker container files to a remote share. \n Install Ubuntu via live ISO. \n  \nNote: i'm doing this on vmware. \n Note: i used 2 CPU, 2 GB RAM\n Note: i used a 100GB drive. (possibly overkill but my other system i started with 20 and had to go through the pain of expanding)\n Note: I selected most defaults other than the …",
          "link": "https://www.reddit.com/r/selfhosted/comments/zffrsr/my_howto_on_installing_portainer_on_docker_on/",
          "publishedOn": "2022-12-07T22:12:31.000Z",
          "wordCount": 19278,
          "title": "My How-To on installing Portainer on Docker on Ubuntu Server 22.04 LTS with CIFS / SMB Shares as mounts for Docker Containers",
          "imageUrl": "https://external-preview.redd.it/nE_aFzXP7wrBN0unQmswrHbk5W009XTiLS7Z0KbEH_Q.png?auto=webp&s=b9e4dd49234f0c2a7047b84f66685e0ff1d4f1a3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zffjmd/if_selfhosting_kubernetes_sounds_too/",
          "author": null,
          "description": "Hey! I've been running a cluster of between 9-20 nodes on the Hashicorp stack for a while now, and it's been fantastic for everything between homelabbing to production applications. \n ​\n It is, however, a little annoying to get a development cluster up and running to play with, so I wanted to share a *very* simplified set of ansible scripts for folks to get started with, quickly, because it's fantastic.\n ​\n If you're unfamiliar with the Hashicorp Stack, I put together a very brief write-up on its major components (Consul, Vault, Nomad), along with a repo with some ansible scripts and a Vagrant file for y'all to play around with.\n ​\n Repo: https://github.com/momer/kwuxlab-free\n    submitted by    /u/Momer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zffjmd/if_selfhosting_kubernetes_sounds_too/",
          "publishedOn": "2022-12-07T22:05:01.000Z",
          "wordCount": 18409,
          "title": "If self-hosting kubernetes sounds too complex/annoying; consider the hashicorp stack! Here's a quick overview of the main components.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zff5yf/new_deployment_option_for_selfhosting_bitwarden/",
          "author": null,
          "description": "submitted by    /u/nickexyz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zff5yf/new_deployment_option_for_selfhosting_bitwarden/",
          "publishedOn": "2022-12-07T21:52:04.000Z",
          "wordCount": 1830,
          "title": "New Deployment Option for Self-Hosting Bitwarden",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfd0is/why_do_you_selfhost_what_is_your_use_case_poll/",
          "author": null,
          "description": "Hello there! \n Very curious to know what use case everyone here covers with self-hosting. \n Added some examples for each option, hopefully these are helpful. \n View Poll\n    submitted by    /u/joingardens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfd0is/why_do_you_selfhost_what_is_your_use_case_poll/",
          "publishedOn": "2022-12-07T20:38:49.000Z",
          "wordCount": 19859,
          "title": "Why do you self-host? What is your use case? (Poll)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfcykv/nonsonos_home_audio_airplaydaapdowntone/",
          "author": null,
          "description": "Currently my \"stereo\" is an old Android phone with a 3.5mm jack that runs Plexamp and AirReceiver, an app which lets it act as a Chromecast or AirPlay receiver. I had been using the Plexamp cast function and chromecasting from PodcastAddict on my regular phone to the stereo-phone when needed. I really like that with Plexamp I can use the \"cast\" menu to remotely control play/pause and volume as well as queuing up playlists etc, and I wanted that for podcast playback as well. I got some of that (play/pause and volume) on my desktop and other devices via KDE Connect, but not the ability to choose what's playing. Podcast Addict living on my phone also means that I don't have a way to maintain local copies, progress, and play history aside from the app's own backup and OPML exports.\n This week …",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfcykv/nonsonos_home_audio_airplaydaapdowntone/",
          "publishedOn": "2022-12-07T20:36:23.000Z",
          "wordCount": 16656,
          "title": "Non-Sonos Home Audio - airplay/daapd/owntone, subsonic/airsonic/navidrome, chromecast, or something else?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfc7cz/is_a_proxmox_full_backup_good_enough_for_seafile/",
          "author": null,
          "description": "If I run my backups on proxmox once every other day, is that good enough to count on for data recovery if seafile goes down, or another app gets corrupted?\n    submitted by    /u/Fission455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfc7cz/is_a_proxmox_full_backup_good_enough_for_seafile/",
          "publishedOn": "2022-12-07T20:10:25.000Z",
          "wordCount": 16597,
          "title": "Is a proxmox full backup good enough for seafile and other apps data backup?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zfb5hm/new_to_selfhosting_looking_for_cool_services/",
          "author": null,
          "description": "submitted by    /u/shalamander6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zfb5hm/new_to_selfhosting_looking_for_cool_services/",
          "publishedOn": "2022-12-07T19:34:41.000Z",
          "wordCount": 16873,
          "title": "New to self-hosting, looking for cool services.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zf98hq/digital_copies_of_important_documents/",
          "author": null,
          "description": "Hiya people, \n I was wondering what solutions you guys are implementing to keep digitised versions of important documents. \n I think I've outgrown my basic folder structure and wanted something that could replace it. \n I don't have any significant requirements, though I would prefer that files are stored as files and not in a database, for ease of retrieval in case something goes wrong. \n Cheers\n    submitted by    /u/py2gb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zf98hq/digital_copies_of_important_documents/",
          "publishedOn": "2022-12-07T18:29:22.000Z",
          "wordCount": 15618,
          "title": "Digital copies of important documents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zf7oy7/calendar_sync_across_multiple_calendars/",
          "author": null,
          "description": "I have multiple clients from different companies that need to schedule meetings and I need a way to add busy blocks on all my calendars based on other calendars. for examples:\n Google calendar 1\n Google calendar 2\n Microsoft calendar 1\n Microsoft calendar 2\n Microsoft calendar 3\n Microsoft calendar 4\n icloud calendar 1\n icloud calendar 2\n ​\n I want to see busy times on each of these calendars based on meetings/events on the other calendars. Preferably something selfhosted/opensource\n potentially something that I can connect all calendars to and automatically update it across them. I.e. New calendar event on google calendar 1 means add busy block on all the others.\n I am not looking something like calendly that will create a link to show available times. if it does the above and also provide a link that would be okay.\n    submitted by    /u/Quick_Parsley_6482  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zf7oy7/calendar_sync_across_multiple_calendars/",
          "publishedOn": "2022-12-07T17:38:28.000Z",
          "wordCount": 16333,
          "title": "Calendar Sync across multiple calendars",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zf6fjn/dns_error_in_redditcom_domain/",
          "author": null,
          "description": "so i am in a strange situation when using both pihole as well as adguard home , everything works perfectly except reddit even on default setup or whitelisting the domain using wildcard as a last resort \n so far i have tested two setups \n 1- plain old pihlole/adguard in a docker and changing dns on my router to point my raspberry ip \n 2- using tailscale vpn to get ad blocking on the go \n my error is the reddit never resolves no matter what i do even after disabling all adlist & blacklists\n is this something unique to me or have you all also faced this + do guide me on how to rectify this error \n both setups were tested ad different times and using both pihole and adguard individually\n    submitted by    /u/DadOfLucifer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zf6fjn/dns_error_in_redditcom_domain/",
          "publishedOn": "2022-12-07T16:55:57.000Z",
          "wordCount": 16783,
          "title": "dns error in *.reddit.com domain",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zf5tio/what_equipment_are_you_using_for_your_self_hosted/",
          "author": null,
          "description": "Hi there!\n I'm simply using a Raspberry Pi 4 8GB with an 2TB external HDD for all of my self hosted stuff. I'm pretty happy with it but I'm curious what equipment other people are using and why they have what they have. I've been using my setup for several months now and I love it. I was considering sinking some more money into a more professional setup like a rack of some kind and a little more horsepower for game servers and whatnot.\n What equipment do you have?\n    submitted by    /u/paperjace_v2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zf5tio/what_equipment_are_you_using_for_your_self_hosted/",
          "publishedOn": "2022-12-07T16:35:08.000Z",
          "wordCount": 16284,
          "title": "What equipment are you using for your self hosted projects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zf58up/harvest_time_tracking_alternative/",
          "author": null,
          "description": "The last time there was a robust conversation about this question was a little over a year ago, but I have to imagine that today there are lots of self-hosted alternatives to Harvest for time tracking. Yet, most of the open source self-hosted alternatives that I am seeing are either full-blown project management suites or fairly outdated timesheet tools. \n Is there any simple, elegant, basic time-tracking and invoicing tool out there, like Harvest?\n    submitted by    /u/kaelon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zf58up/harvest_time_tracking_alternative/",
          "publishedOn": "2022-12-07T16:15:40.000Z",
          "wordCount": 15912,
          "title": "Harvest Time Tracking Alternative",
          "imageUrl": "https://external-preview.redd.it/mT2j2WPX58bGgNlaUSz2yup5RvNJEBFUbXLOYBYbC_o.jpg?auto=webp&s=1b4c21a790635cdc440aaee138a193339a26de4a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zf544g/selfhosted_foss_ecommerce_solution_suggestions/",
          "author": null,
          "description": "Hi All...\n Which self-hosted Free and open source eCommerce solution would you suggest and why? I am looking for the one with the most free features without having to pay for plugins. Drupal commerce has caught my eye, but please try and convince me otherwise.\n ​\n I know some will say it depends on lots of things, but why would you suggest one over the other in a general sense?\n ​\n I would also appreciate any article links on my choices, but must be a list of FOSS suggestions, please?\n ​\n Thank you\n Darius\n    submitted by    /u/Superdarius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zf544g/selfhosted_foss_ecommerce_solution_suggestions/",
          "publishedOn": "2022-12-07T16:11:11.000Z",
          "wordCount": 15816,
          "title": "Self-hosted FOSS eCommerce solution suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zf41yz/my_homepage_dashboard/",
          "author": null,
          "description": "submitted by    /u/rursache  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zf41yz/my_homepage_dashboard/",
          "publishedOn": "2022-12-07T15:34:59.000Z",
          "wordCount": 17868,
          "title": "My Homepage dashboard",
          "imageUrl": "https://preview.redd.it/ccq6noaewh4a1.jpg?auto=webp&s=0b28461b639ee35dfbfe290ee34ced1091b0dda3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zf37ux/jellyfin_vpn_pihole_nginx_proxy_manager_setup/",
          "author": null,
          "description": "Hi all,\n I am trying to deploy my own self hosted services in an home server, and I want to do it in the most secure way I can, thus exposing only a vpn to the internet.\n I will take Jellyfin as and example of service, but I also want to host nextcloud and a password manager for example.\n SETUP description: I have a bare metal ubuntu server install, running all services in docker containers. all services have static ips both on the LAN and in the docker network.\n - container 1: pihole connected to 2 networks: a macvlan and a bridge network called \"proxy\"\n - container 2: nginx proxy manager connected to the network \"proxy\", exposed ports on the host machine (will remove the dashboard when configured probably)\n - container 3: Jellyfin connected to the network \"proxy\", no posts exposed on the…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zf37ux/jellyfin_vpn_pihole_nginx_proxy_manager_setup/",
          "publishedOn": "2022-12-07T15:00:30.000Z",
          "wordCount": 17102,
          "title": "Jellyfin + VPN + Pi-hole + Nginx proxy manager setup",
          "imageUrl": "https://external-preview.redd.it/C0SrTnuTRSy7lSz8c-omDQPEOCqYwtrogyflsjoJQ7I.jpg?auto=webp&s=d3ff5630dbcf31d5519692eb8a447bdee7432735"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zf0e4b/selfhosted_photo_app_with_map_view_photoprism/",
          "author": null,
          "description": "Hi all,\n I'm looking for a new Selfhosted Photo-App via Docker-Container.\n - I want to upload my Smartphone-Photos to a Nextcloud-Folder, e.g. directly \"/Photos\" or \"/Import\"\n - The PhotoApp should automatically scan this folder and generate Thumbnails / Face recognition / etc.\n - I want to have a Map-View, and automatically filter my photos for different places (e.g. Rome)\n - I want to be able to edit the \"/Photos\" Folder with 3rd-Party-Apps (e.g. Nextcloud), and the Photo-App should recognize these changes\n - I want to use the Photoapp without registration (secured via Authentik Forward Proxy) or via Authentik SSO\n Photoprism was really close after some customizations. However, after updating my docker container now, I lost the access to the normal Map-View (via Street/Satelitte), as they put this feature behind a paywall. However, this was my main usecase.\n Nothing wrong with creating new premium features for monetisation. However, removing existing features and destroying my running setup was a no-go for me, and I don't want to support this. \n Any suggestions for alternatives? :)\n    submitted by    /u/Simplixt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zf0e4b/selfhosted_photo_app_with_map_view_photoprism/",
          "publishedOn": "2022-12-07T12:51:28.000Z",
          "wordCount": 18325,
          "title": "Selfhosted Photo App with Map view - Photoprism alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zewmx1/openai_is_fully_opensource_will_they_ask_for_money/",
          "author": null,
          "description": "I saw Github projects by OpenAI. Also, they offered 18$ credit for using some of the services. If I run out of that $18, I need to pay. Can I Self-Host OpenAI at home?\n Edit-1: Top comments on this post says OpenAI is not \"fully\" open source.\n Then the usage of \"Open\" in the Name is deceiving?\n Edit-2: An Average Tech illiterate guy like me thinks this way, for example :\n OpenSpeedTest is Free and Opensource Software. As the name says, I can run the SpeedTest from the OpenSpeedTest website or host it on my home server or cloud server. Anything Open in the name means Opensource. That is what I know, like most people in r/selfhosted. Thanks for the clarification.\n    submitted by    /u/DinkanGod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zewmx1/openai_is_fully_opensource_will_they_ask_for_money/",
          "publishedOn": "2022-12-07T09:16:19.000Z",
          "wordCount": 16557,
          "title": "OpenAI is fully Open-source? Will they ask for money?",
          "imageUrl": "https://external-preview.redd.it/HAlPHuv1z_UZeoZHOcIPZK-rJk1x8kFzHOBjH7mqC2w.jpg?auto=webp&s=4e39a6dd0e5b776f90182c37ab4f0ce05d2237ee"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zewhol/webmin_virtualmin_alternative/",
          "author": null,
          "description": "Any Open-Source Alternative that is better than Webmin/Virtualmin? \n I have been using Webmin & Virtualmin for the last ten years. Now I am going to rebuild my production server. I just wanted to know anything better out there or not.\n    submitted by    /u/DinkanGod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zewhol/webmin_virtualmin_alternative/",
          "publishedOn": "2022-12-07T09:06:34.000Z",
          "wordCount": 16320,
          "title": "Webmin & Virtualmin Alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zeu3ik/anything_like_chatgpt_that_you_can_run_yourself/",
          "author": null,
          "description": "I assume there is nothing nearly as good, but is there anything even similar?\n    submitted by    /u/lukeprofits  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zeu3ik/anything_like_chatgpt_that_you_can_run_yourself/",
          "publishedOn": "2022-12-07T06:28:24.000Z",
          "wordCount": 18009,
          "title": "Anything like ChatGPT that you can run yourself?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zeombf/i_want_to_serve_my_email_locally_from_my_linux/",
          "author": null,
          "description": "Hi all!\n I wanted to add my request for info on the super TALL heap of the same thing. I know it's a common request because my Google searches on the subject returned a LOT of information. I sifted through it all and still do not have a working solution. But I'm close.\n I started out using Postfix and Getmail. I am able to pull my email from my GMAIL account and store it on my local linux server.\n And then I added Procmail, to be able to sort it to folders based on content. I learned a lot about it and how to configure it, but not there yet as a functional solution.\n Where I am stuck is implementing a web-based interface to view that pulled email. And the next stage is sending email through my GMAIL account, although I was successful with an example. I am not to that stage yet.\n I errantly…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zeombf/i_want_to_serve_my_email_locally_from_my_linux/",
          "publishedOn": "2022-12-07T01:40:36.000Z",
          "wordCount": 17522,
          "title": "I Want To Serve My Email Locally From My Linux Server With a Web-Based Interface",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zenu6m/not_able_to_install_pgadmin4_in_oracle_cloud_with/",
          "author": null,
          "description": "When I try to install Pgadmin4 in Oracle cloud with Ubuntu 22.04 am getting below error .\n Following packages unmet dependencies\n pgadmin4-server (=6.17) but it is not installable \n pgadmin4-desktop (=6.17) but it is not installable \n pgadmin4-web (=6.17) but it is not installable \n Am struck with this , any help appreciated, Thanks\n    submitted by    /u/Few_Faithlessness_96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zenu6m/not_able_to_install_pgadmin4_in_oracle_cloud_with/",
          "publishedOn": "2022-12-07T01:02:54.000Z",
          "wordCount": 16073,
          "title": "Not able to install Pgadmin4 in oracle cloud with Ubuntu 22.04",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zentxh/how_to_stop_nginx_from_converting_to_2b/",
          "author": null,
          "description": "Hi, I want a way to tell nginx to stop switching the special character '+' to be %2B because I need it to be passed to the web app to process the request. I tried to use rewrite, but it did not work, so is there a way?\n    submitted by    /u/c1npxrfq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zentxh/how_to_stop_nginx_from_converting_to_2b/",
          "publishedOn": "2022-12-07T01:02:33.000Z",
          "wordCount": 16740,
          "title": "How to stop nginx from converting + to %2B?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zensti/need_help_managing_contacts/",
          "author": null,
          "description": "Crowd-sourcing workflows and good habits to managing contacts. Currently, my contacts are a mess. Whatsapp has their own copy, Telegram has their own copy, Google has their own..and then there's my phone. \n Three things I need help with. 1) Deciding on what contacts are for. 2) Deduplicating contacts 3) Maintaining good house keeping habits for contacts\n For 1, I feel contacts should be a somewhat maintained list of \"people I feel I may want to reach out to\". I am unsure if it should extend to \"people who will want to reach out to me\". That way, I get rid a lot of noise, I reduce situations where I contact a stranger cause he/she picked up the old number of an acquaintance. Im just curious if there's any lost to losing people's contact. It happens all the time right?\n For 2, what's a good way to deduplicate them on all platforms? I have started with the contacts in Google. I went through each contact, cleaned up and standardized the data fields. Moving onto Telegram, I see a tonne of repeats. I feel I should sync between the curated Google contact list and Telegram, pray for some magic deduplication, and then sort through the rest again. Rinse and repeat for Whatsapp, then phone. Thing is, I'm unsure how the syncing works and if it will result in many more duplication on all involved platforms. There's v little visibility into which way the sync occurs. If it's 'To Google contacts', I can see what's out of place and edit accordingly. But anything else, manual curation and I'm bound to make mistakes cause I'm human.\n For 3, really, how do you do it?\n    submitted by    /u/pestlemortar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zensti/need_help_managing_contacts/",
          "publishedOn": "2022-12-07T01:01:05.000Z",
          "wordCount": 17128,
          "title": "Need help managing contacts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zen8p7/best_way_to_make_sure_that_bitlocker_keys_are/",
          "author": null,
          "description": "So I want to ask how do you all manage your bitlocker recovery keys? Is there something that you all host that you can upload the keys to for easier management and storage? Do you just keep it on a USB somewhere that you won't use it? I just want an easier method than keeping the files on my network share and in AD.\n    submitted by    /u/Dudefoxlive  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zen8p7/best_way_to_make_sure_that_bitlocker_keys_are/",
          "publishedOn": "2022-12-07T00:33:50.000Z",
          "wordCount": 16333,
          "title": "Best way to make sure that Bitlocker Keys are stored",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zemyva/anything_like_budibase_but_for_public_deployment/",
          "author": null,
          "description": "Hey\n I've spent a good amount of time learning to use budibase and even if some obvious functions are (in my opinion) missing, even if the doc is reaaaaally limited... I quite like it. The thing is, I started using it only to build a PUBLIC form ; then it just showed me all the possibilities for all the workflow automation, all the admin functionnalities I could create for my compagny. But I've learnt -the hard way- that Budibase really isn't meant to build ant kind of app that has a public side.\n So I have two options : either I use my website (ghost) for the content and Budibase for data management and workflow ease / automation AND a form builder like limesurvey for the forms or I find something that can do both what Budibase can and can't do. Honnestly, two softwares is already enough softwares. I'd rather not use three.\n Is there anything that would fit the requirement ? I prefer open source but I can consider paid services if they're cheap bithout limiting functionalities to the bare minimum (like 500 submitions per months for 20$ and this kind of nonsense).\n Thanks !\n    submitted by    /u/gregfdzd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zemyva/anything_like_budibase_but_for_public_deployment/",
          "publishedOn": "2022-12-07T00:21:01.000Z",
          "wordCount": 17037,
          "title": "Anything like Budibase but for public deployment / use, with ability to still build an admin dashboard ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zellt5/how_are_you_managing_http_without_s_traffic_and/",
          "author": null,
          "description": "So I have a bunch of dockerized services. Most of them are setup with a self-signed certificate to work via https, so chrome shuts up whenever I visit them. There are two problems with this: It's a pain in the ass and some services just refuse to do SSL.\n Reverse proxies to the rescue, right? There even is this docker image, that promises to magically do the job: https://hub.docker.com/r/jwilder/nginx-proxy But then I have to deal with a bunch of DNS crap. My router knows that \"pi\" is supposed to be 192.168.178.3, but has no idea what nextcloud.pi is supposed to be.\n So as far as I know I could either buy a domain with subdomains or I could host my own DNS. I tried the adguard home docker image to host my own DNS and could even resolve the nslookup when explicitly told to resolve via the selfhosted DNS, but my router does not like that. I configured the router to use my selfhosted DNS for DNSv4 requests, but left the DNSv6 on default, since I don't think I can assign a static IPv6 to my raspberry pi that runs the DNS. I believe it is using that DNSv6 server, though. Also, I don't want to have no working internet whenever my raspberry pi has issues, so I don't like doing it this way.\n At this point I tried going the simple route: Just tell Chrome to shut the hell up whenever I go to that one server. But it seems like that also just will not work. \n So do I have to buy a random domain to get this to work? That seems no less annoying. Is there no better way? Am I getting anything wrong? Should I just switch to Firefox?\n    submitted by    /u/SendMeOrangeLetters  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zellt5/how_are_you_managing_http_without_s_traffic_and/",
          "publishedOn": "2022-12-06T23:24:03.000Z",
          "wordCount": 17525,
          "title": "How are you managing http (without s) traffic and browsers complaining about it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zeksob/how_to_link_domain_name_to_ip_for_a_website/",
          "author": null,
          "description": "Have bought a domain and on the registers website added the dns A record for my ip, I’ve also set up a port forward for ports 80 and 443 to go to 80 and 443 on the local home server ip. That seems like it will work ok once the dns servers update but i want to use this domain for my vpn hosted on my home server aswell maybe using a sub domain like vpn. But the vpn uses ports 443 which would clash my vpn is in a different vm so would i in open vpn set it to use a different port that links to the 443 international port? Thanks\n    submitted by    /u/redisgoodboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zeksob/how_to_link_domain_name_to_ip_for_a_website/",
          "publishedOn": "2022-12-06T22:52:50.000Z",
          "wordCount": 17362,
          "title": "How to link domain name to ip? For a website",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zek59e/whats_a_good_platform_that_i_can_start_as_blog/",
          "author": null,
          "description": "I'm starting a business and it will start out as a blog but as our product line rolls out we will need to sell products on the website.\n What's a good platform for accomplishing this? I was thinking Ghost CMS and host it on AWS Elastic Beanstalk for scaling.\n Does anyone have any other good suggestions or is Ghost CMS good enough?\n    submitted by    /u/YoshiFelipe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zek59e/whats_a_good_platform_that_i_can_start_as_blog/",
          "publishedOn": "2022-12-06T22:27:47.000Z",
          "wordCount": 17028,
          "title": "What's a good platform that I can start as blog and expand to e-commerce in the future?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zei2hl/is_it_possible_to_access_paperlessngx_with_https/",
          "author": null,
          "description": "Hello everyone, \n I've set up a Paperless-NGX Docker and would like to connect to it from the outside with https. Is that possible? I also have nginx proxy manager running. I know I can VPN into my network and prolly should do that but I'm just asking.\n Thanks!\n    submitted by    /u/skorpion1298  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zei2hl/is_it_possible_to_access_paperlessngx_with_https/",
          "publishedOn": "2022-12-06T21:05:36.000Z",
          "wordCount": 16126,
          "title": "Is it possible to access Paperless-NGX with https?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zehwjh/my_new_homepage_dashboard/",
          "author": null,
          "description": "submitted by    /u/Hecbert4258  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zehwjh/my_new_homepage_dashboard/",
          "publishedOn": "2022-12-06T20:59:05.000Z",
          "wordCount": 17256,
          "title": "My new Homepage Dashboard ⭐",
          "imageUrl": "https://preview.redd.it/ntz8nr03dc4a1.png?auto=webp&s=2146a56a95853d3a89ffca1850a15a6d2ddcf63e"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zedtg0/hello_selfhosters/",
          "author": null,
          "description": "I am planning on build a new home server. Currently I am running on RPi4 4GB, but I think it is time, to move things a little bit higher. I am trying to build a low power consumption that will run good.\n I don't have much experience with building a machine, but I can learn and in no hurry to build. Are this components compatible with each other and will give me what i want? \n AMD Athlon 3000G with Radeon Vega 3\n ASUS Prime A520M-K\n Patriot Signature Line 16GB DDR4-2666, DIMM, CL19\n LC Power LC500H-12 500 W\n 3x HDD for data\n 1x SSD for system \n Thank you all!\n    submitted by    /u/Jesenican2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zedtg0/hello_selfhosters/",
          "publishedOn": "2022-12-06T18:19:01.000Z",
          "wordCount": 25081,
          "title": "Hello Selfhosters!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zedsgf/simplex_chat_the_first_messaging_platform_without/",
          "author": null,
          "description": "SimpleX Chat was first released in March – huge thanks to support from r/selfhosted community – and its security assessment was completed by Trail of Bits in November.\n The new version 4.3 adds: - instant voice messages! - irreversible deletion of sent messages for all recipients (with the recipient consent). - improved self-hosted server configuration and support for server passwords – also see the new guide on self-hosting the servers. - privacy and security improvements.\n See more details in the announcement and download the apps via the website.\n The links to answer the most common questions:\n Why user identifiers are bad for privacy and how SimpleX delivers messages without them.\n Technical details and limitations.\n How SimpleX is different from Session, Matrix, Signal, etc..\n    submitted by    /u/epoberezkin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zedsgf/simplex_chat_the_first_messaging_platform_without/",
          "publishedOn": "2022-12-06T18:17:54.000Z",
          "wordCount": 16068,
          "title": "SimpleX Chat – the first messaging platform without any user profile identifiers (not even random numbers) – v4.3 with instant voice messages and better support for self-hosted servers is released.",
          "imageUrl": "https://external-preview.redd.it/vRD51aHBr090zXnz4B2uqEu_a5fZE2fmjXu1gJkS8B8.jpg?auto=webp&s=58dcbb331fb1d8bc2d13b3d6690661cda6d86c96"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zedpy3/nginx_reverse_proxy_strange_internal_routing/",
          "author": null,
          "description": "I am using an Apache webserver internally to serve SSL pages to my local LAN and publicly. My LAN supports LE certificates. Let's say my public cert is *.foo.com and my internal is *.priv.foo.com. I use Apache name-based routing. The following pages are example internal-only sites and both work perfectly. My goal is expose them publicly.:\n  \nhttps://host1.priv.foo.com\n https://host2.priv.foo.com\n  \nThis seems easy and so I configure NPM proxy hosts as follows:\n  \nDomain name:host1.foo.com, Scheme: https, Forward Hostname: host1.priv.foo.com, Port:443\n Domain name:host2.foo.com, Scheme: https, Forward Hostname: host2.priv.foo.com, Port:443\n  \nhost1.foo.com works as expected; however, host2.foo.com routes to https://host1.priv.foo.com. I am trying to understand why this is happening especially since the internal pages work fine. Do you have any ideas on how to troubleshoot this? I have full access to both NPM and Apache and so can make any needed config changes.\n TIA!\n Update for future viewers:\n This was not an NPM issue, but an Apache one. The solution was to add a \"ServerAlias\" directive in the config file. See below for details.\n    submitted by    /u/JL_678  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zedpy3/nginx_reverse_proxy_strange_internal_routing/",
          "publishedOn": "2022-12-06T18:15:08.000Z",
          "wordCount": 17010,
          "title": "NGINX Reverse Proxy - Strange internal routing problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zed3kk/selfhosted_videoiptv_streaming_scheduling_options/",
          "author": null,
          "description": "Hey all! I'm not really sure what exactly I am looking for. I have a reasonably sized plex library, and while plex is great for video on demand, I'd like to do something like pluto, but with my own videos. I had looked into tvheadend, but didn't see that it supports local video for inputs. It'd be great to have like a channel that I can have my sci-fi shows play on and just bring it up whenever and play whatever is currently on when I need some background noise.\n Does anyone have any suggestions for this type of software? Or can you tell me what the name for this type of software would be and I can do some better searching?\n Thanks! I appreciate any advice you all can provide.\n    submitted by    /u/spillman777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zed3kk/selfhosted_videoiptv_streaming_scheduling_options/",
          "publishedOn": "2022-12-06T17:50:28.000Z",
          "wordCount": 17470,
          "title": "Self-hosted video/IPTV streaming / scheduling options?",
          "imageUrl": "https://external-preview.redd.it/HagxvJAmZiYg1bWf4MQBOgEH5v_8gU-uqTcerlDhaqs.jpg?auto=webp&s=eea7d273222fe359b552f7b6f3ab1d3d7bad2055"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zecsrd/can_i_allow_access_of_an_endpoint_to_only_1/",
          "author": null,
          "description": "Here's my use-case for this. All my devices are connected to WireGuard, and they can access everything. However, I have a work laptop that I want to connect to my BitWarden, without connecting it to WireGuard. I should also mention that I cannot install any VPNs or tunneling software on it, so VPNs/CloudFlare tunnel are out.\n I have NGINX acting as a reverse proxy, and I use CloudFlare for traffic not coming from WireGuard (I have 1 public endpoint for Home Assistant's API for Google Home devices since they're a pain). I'm using all the geo-blocking and fail2bans, but how can I limit an endpoint's access to just 1 specific device if the traffic is from Cloudflare (I still want traffic from local network or WireGuard to pass through), regardless of IP?\n    submitted by    /u/azn4lifee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zecsrd/can_i_allow_access_of_an_endpoint_to_only_1/",
          "publishedOn": "2022-12-06T17:37:53.000Z",
          "wordCount": 17506,
          "title": "Can I allow access of an endpoint to only 1 machine outside of local network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zecror/would_you_put_that_you_contributed_to_the_arrs_on/",
          "author": null,
          "description": "I have a project i’m working on that’s similar to Ombi and the like. I’m a student and this project would show a lot of my skill, however how would I explain that this project ties into something that essentially pirates media?\n Follow up question would be if an interviewer checked your github and saw you contributing to the ARRs would this be a red flag for them?\n    submitted by    /u/sufyspeed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zecror/would_you_put_that_you_contributed_to_the_arrs_on/",
          "publishedOn": "2022-12-06T17:36:44.000Z",
          "wordCount": 19073,
          "title": "Would you put that you contributed to the ARRs on your resume?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zecjm2/solutions_for_using_codeserver_with_multiple_users/",
          "author": null,
          "description": "submitted by    /u/geoffreyhuntley  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zecjm2/solutions_for_using_codeserver_with_multiple_users/",
          "publishedOn": "2022-12-06T17:28:09.000Z",
          "wordCount": 18608,
          "title": "Solutions for using code-server with multiple users",
          "imageUrl": "https://external-preview.redd.it/3Zu5jRqQCg3NKuWNLGc5YagRCcd16M_FwllStws-VaY.jpg?auto=webp&s=f452857c0fb9f6a9411f934e31e4f3693fee4aa9"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zeafna/self_hosted_digital_signage/",
          "author": null,
          "description": "Probably been asked before one here, but I'm just checking to see if anyone has any recommendations for self-hosted digital signage.\n    submitted by    /u/MaliciousMango1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zeafna/self_hosted_digital_signage/",
          "publishedOn": "2022-12-06T16:04:11.000Z",
          "wordCount": 16419,
          "title": "Self Hosted Digital Signage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ze74ye/google_drive_alternative_thats_not_nextcloud/",
          "author": null,
          "description": "Just need simple cloud based storage. I use onlyoffice already. But scanning files and stuff for work to my server at home would be nice. I use cloudflare tunneling to most my hosted things so any recommendations?\n    submitted by    /u/Fission455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ze74ye/google_drive_alternative_thats_not_nextcloud/",
          "publishedOn": "2022-12-06T13:43:07.000Z",
          "wordCount": 19334,
          "title": "Google drive alternative that’s not nextcloud?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ze44tu/novu_the_1st_opensource_notification/",
          "author": null,
          "description": "submitted by    /u/Alternative-Rich-578  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ze44tu/novu_the_1st_opensource_notification/",
          "publishedOn": "2022-12-06T11:30:26.000Z",
          "wordCount": 16883,
          "title": "Novu - The 1st open-source notification infrastructure for developers",
          "imageUrl": "https://external-preview.redd.it/DKUjbYm6W3VN4MjmKcMRM44PNAt41lotT7p3if2AZmE.jpg?auto=webp&s=73cd7ebf5891f16ec82b4d10093a97c927cdcae6"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ze3a83/is_there_a_dashboard_like_heimdall_which/",
          "author": null,
          "description": "I mean i launch a local wordpress at <mylocalserver>:8000 and I'd like teh dashboard automatically detect it, like Portainer find open ports\n    submitted by    /u/grigio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ze3a83/is_there_a_dashboard_like_heimdall_which/",
          "publishedOn": "2022-12-06T10:50:39.000Z",
          "wordCount": 17341,
          "title": "Is there a dashboard like Heimdall which automatically detectes active web apps?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/ze0ims/taking_notes_with_vs_code_and_obsidian_mobile/",
          "author": null,
          "description": "submitted by    /u/mzfr98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/ze0ims/taking_notes_with_vs_code_and_obsidian_mobile/",
          "publishedOn": "2022-12-06T08:29:49.000Z",
          "wordCount": 20183,
          "title": "Taking notes with VS Code and obsidian mobile",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdrf9p/confarr_quickly_configure_arr_apps/",
          "author": null,
          "description": "submitted by    /u/tylergets  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdrf9p/confarr_quickly_configure_arr_apps/",
          "publishedOn": "2022-12-06T01:49:26.000Z",
          "wordCount": 18353,
          "title": "Confarr - Quickly configure *arr apps",
          "imageUrl": "https://external-preview.redd.it/Ssx0TDToHD1kZtuiH8Vd2L9s6vuIiRDhYCs-9NOzkcM.jpg?auto=webp&s=dbf330363f1301eee6ecaef873ae7d4f2b363993"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdpogu/cryptodash_a_single_file_crypto_currency_dashboard/",
          "author": null,
          "description": "Hi crypto enthusiasts!\n I've made a simple dashboard to view live prices of crypto currencies and would like some feedback on features, usability, performance issues, and your honest opinion in which direction should I push the project and what to focus on next.\n The code can be viewed here: https://github.com/mprajescu/cryptodash\n A live preview can be accessed here: https://mprajescu.github.io/cryptodash/cryptodash\n Unfortunatley I don't have enough comments karma to post in r/CryptoCurrency and if someone would be kind enough to share it there, I would appreciate it. \n ​\n Main features\n  \nPortability - It's a single HTML file. You can host it anywhere, no backend, no database required, no users. You can also run it locally.\n Data is stored as JSON format in Application Local Storage\n Export settings and move your dashboard anywhere\n Highly customizable with different themes, light/dark mode, rearrange trackers in your preferred order, wallpapers\n Add up to 32 trackers that will automatically self-update\n Set alerts and get notified when the tracked Crypto Currency goes up in value or down. You can enable sound notifications\n View charts and history for different trackers\n See Crypto assets values update in real-time in multiple currencies USD/GBP/EUR\n  \n​\n Upcoming features\n  \nNews Dashboard\n Improve UX and UI\n Allow multiple notifications and alarms\n Allow changing the sound notification\n Improve performance\n Documentation\n  \n​\n Screenshots\n Tokens/Crypto currencies\n Light Mode\n Dark Mode\n    submitted by    /u/mprajescu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdpogu/cryptodash_a_single_file_crypto_currency_dashboard/",
          "publishedOn": "2022-12-06T00:33:16.000Z",
          "wordCount": 13309,
          "title": "CryptoDash - a single file crypto currency dashboard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdof91/swapping_out_hardware_for_low_power_alternatives/",
          "author": null,
          "description": "With the current energy crisis going on in the UK (and elsewhere!) I have been thinking like many about reducing my power usage footprint.\n My setup used to be:\n  \nSynology DS918+ - NAS for Plex, *arr apps in Docker, NFS for other apps storage\n Mac mini (Mid 2011, i5, 16GB RAM) - Proxmox host running a VM to then host Portainer and\n a plethora of Docker apps. All the container data volumes point to the Synology NFS to allow for backup and the VM is backed up regularly using Proxmox.\n Intel NUC D54250WYKH (Intel Core i5-4250U) - Home-Assistant box. Running in fanless enclosure.\n  \nI then had a couple of spare (I know, first world problem) Mid 2011/2012 Mac minis of a similar spec that I would also use as a Proxmox playground for testing etc.\n This worked great for me when we didn't care abo…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdof91/swapping_out_hardware_for_low_power_alternatives/",
          "publishedOn": "2022-12-05T23:44:46.000Z",
          "wordCount": 16779,
          "title": "Swapping out hardware for low power alternatives amid the UK energy crisis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdo2i5/is_possible_to_run_an_ip_camera_just_making/",
          "author": null,
          "description": "Hi, I wanna but an ip camera for my house so I can monitor when I’m outside but I don’t really need the video. \n I was thinking in link C210.\n    submitted by    /u/Kraizelburg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdo2i5/is_possible_to_run_an_ip_camera_just_making/",
          "publishedOn": "2022-12-05T23:32:12.000Z",
          "wordCount": 13114,
          "title": "Is possible to run an ip camera just making snapshots rather than continuous video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdmese/fully_automated_homelabs/",
          "author": null,
          "description": "Hey Self Hosted Community,\n I want to be able to deploy a full homelab, authentication, backups, logs, DNS, VPN access etc... as automated as reasonable. I want to just be able to point at something like Vultr or Kubernetes running on TrueNAS Scale then be able to log in to a dashboard like yacht or portianer with a list of apps I can boot up for the first time.\n I have been personally working on something like this and want to get some some feedback from yall, or find the project that does this all already so I can throw away my code. Currently my project deploys on Vultr or a VM. sets DNS records, basic Auth on required applications, as well as a Yacht instance for oneself to manage apps easily. I have a roadmap here. I would not reccomend anyone run it... yet\n P.S. Any reccodmentdations for self hosting an Obsidian Vault let me know, the options I tried so far suck\n    submitted by    /u/Wh0_am_1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdmese/fully_automated_homelabs/",
          "publishedOn": "2022-12-05T22:36:02.000Z",
          "wordCount": 13294,
          "title": "Fully Automated Homelabs?",
          "imageUrl": "https://external-preview.redd.it/ZquPAU8cZhn0mo04ZhRduLjfjWqLtXZZPPqxxp1O98E.jpg?auto=webp&s=e2e2a035683b076a2e9c6ed930d86f533801fc00"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdmahi/db_web_interface_with_moviedb/",
          "author": null,
          "description": "Hey I’ve got someone I know who would like a website with all of these special film things on the website, in tables, with data pulled from themoviedb, something that is able to have tables added by admins and rows etc, but public can just see a nice database, any ideas?\n    submitted by    /u/Lowlowsomehow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdmahi/db_web_interface_with_moviedb/",
          "publishedOn": "2022-12-05T22:31:53.000Z",
          "wordCount": 13047,
          "title": "DB Web interface with moviedb?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdltq8/how_can_i_portforward_using_a_vps/",
          "author": null,
          "description": "Hi,\n I have an windows server at home that I would like to access remotely. I can’t port forward it through my router because I don’t have a static IP and my ISP blocks port forwarding.. \n How can I use an VPS with an static IP to “forward” my home server?\n    submitted by    /u/doctorecu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdltq8/how_can_i_portforward_using_a_vps/",
          "publishedOn": "2022-12-05T22:16:11.000Z",
          "wordCount": 13299,
          "title": "How can I portforward using a VPS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdlihu/self_hosted_task_app_like_rtm/",
          "author": null,
          "description": "Every year when I receive the $40 receipt for Remember the milk it reminds me that I shall be using a self hosted task system but I have never got to find anything better. In some way I like how RTM works but in another I hate how vintage it is \n Any ideas I could be testing?\n This year I found Timetagger which is my new time tracking gem. Hope to find my new tasks gem also...\n    submitted by    /u/GrapeMassive1097  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdlihu/self_hosted_task_app_like_rtm/",
          "publishedOn": "2022-12-05T22:05:57.000Z",
          "wordCount": 16704,
          "title": "Self hosted task app like RTM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdle1i/looking_for_mfa_authenticator_tool_selfhosted/",
          "author": null,
          "description": "Hey I am currently looking for a MFA Authenticator Tool (selfhosted).\n It should be possible to access with different users (or just a single user everyone will login as) to the Multifactor Access codes of multiple e.g. office365 accounts. (like with the Google Authenticator )\n ​\n Maybe there is already something out there. but I didnt find it yet ^^\n ​\n Wish you a great day and thanks in advance :D\n    submitted by    /u/Kugeki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdle1i/looking_for_mfa_authenticator_tool_selfhosted/",
          "publishedOn": "2022-12-05T22:01:53.000Z",
          "wordCount": 13118,
          "title": "Looking for MFA Authenticator Tool (Selfhosted)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdkns5/best_music_server_other_than_airsonic/",
          "author": null,
          "description": "Best music server other than Airsonic / Airsonic-Advanced / Libresonic / Madsonic / Subsonic\n I've really tried it but every Android client have multiple flaws.\n ​\n EDIT: must be open-source\n    submitted by    /u/atomic_ozzy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdkns5/best_music_server_other_than_airsonic/",
          "publishedOn": "2022-12-05T21:38:02.000Z",
          "wordCount": 13419,
          "title": "Best music server other than Airsonic?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdjh4j/self_hosting_applications/",
          "author": null,
          "description": "Hello friends I want to make a home server and here are some of the application i want to run on my server Omv Nextcloud Pihole Plex Bitwarden Watchtower Duplicati I make this thread cuz i want to find more self hosting apps about my home server.\n    submitted by    /u/Zealousideal_Ask6654  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdjh4j/self_hosting_applications/",
          "publishedOn": "2022-12-05T20:59:20.000Z",
          "wordCount": 16555,
          "title": "Self hosting applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdjdbn/sync_a_webdav_folder_to_my_mac_for_offline_usage/",
          "author": null,
          "description": "I started using todo.txt, and I want to synch the todo.txt file across all my linux and mac. I have already a webdav share on my server that I can mount from my mac, but I'd rather have a sync of the folder, for offline usage.\n what tool would you suggest? I was thinking about rClone with some cron job, but I'm sure someone has a better idea.\n ​\n PS: some macs are work related, the less I install on those, the better.\n    submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdjdbn/sync_a_webdav_folder_to_my_mac_for_offline_usage/",
          "publishedOn": "2022-12-05T20:55:43.000Z",
          "wordCount": 15816,
          "title": "Sync a WebDav folder to my mac for offline usage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdii7l/how_to_share_my_nas_space_with_various_docker/",
          "author": null,
          "description": "Hi,\n I'm trying to make my own QTS/Synology replacement with my NAS and various NUC.\n The idea is to have my main NAS with OpenMediaVault, which will have 3x 8TB in a RAID. It will also have Portrainer+docker swarm.\n I've then several devices(Zimaboard 832) that I would like to use as node of my docker swarm.\n Then I've a lot of different container that I want to dispatch accross the nodes, the ones I could think right now being:\n  \nPyMedusa\n Plex server\n Transmission\n Prism(photo library)\n Paperless(achiving of docs)\n NextCloud(network share)\n OpenVPN\n Home Assistant\n Heimdall for input dashboard\n revert proxy\n  \nJust to give an idea:\n ​\n https://preview.redd.it/m23s9dd6254a1.jpg?width=1752&format=pjpg&auto=webp&s=9ec4f708ad3ad0fa10bb99dbd1855176a66ef445\n ​\n I'm not familiar yet with docker swarm(comfortable with docker though), but since all my storage space will be available on the main NAS, and some of those container will have to use some common folder(typically, pymedusa-plex server-transmission), what is my best option to provide the different storage to my containers, that might be on different docker node? Does my architecture make sense?\n    submitted by    /u/j4n  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdii7l/how_to_share_my_nas_space_with_various_docker/",
          "publishedOn": "2022-12-05T20:26:21.000Z",
          "wordCount": 16860,
          "title": "How to share my NAS space with various docker swarm container?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdht70/digital_business_card/",
          "author": null,
          "description": "Hey hosters! Anyone ever thought of self-hosting a digital business card (maker)? I’m looking for something similar to commercial services that allow to visually build a number of “cards” in a way of a pages with contact data and a vcf download link. I’m not sure if it is okay to give references to the sites I try to mimic to have control over my card(s). EnBizCard is probably the only attempt on this from the OSS community that I was able to find. It is a different approach though.\n    submitted by    /u/joyfulmarvin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdht70/digital_business_card/",
          "publishedOn": "2022-12-05T20:02:47.000Z",
          "wordCount": 16840,
          "title": "Digital Business Card",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdgwmw/tips_or_guides_for_homeade_nas/",
          "author": null,
          "description": "Taking 2 weeks off work and was going to build a NAS. Thinking $4-$500 budget. \n I have little knowledge of NAS, but was going to dig in a bit. I want to use my NAS drives (probably 2 X 2TB) as backups mirroring my volume on Hetzner storage. \n I also wanted to have a fallback load balancer present in case my VPS is down, which proxies connections to my DNS server and wireguard, so I’ll be hosting some application containers on here. I mention this because this is one main reason I’m not interesting in synology (I want to run computationally expensive jobs)\n Anything people recommend to read outside just the hardware stuff for self managing a NAS?\n    submitted by    /u/forlatertesteracct  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdgwmw/tips_or_guides_for_homeade_nas/",
          "publishedOn": "2022-12-05T19:31:57.000Z",
          "wordCount": 16695,
          "title": "Tips or guides for homeade NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdfbwm/sip_reverse_proxy/",
          "author": null,
          "description": "Goal: Isolated SIP servers on same LAN serving two isolated remote sites.\n  \nSite 1's SIP phones point to PBX1 at pbx1.fakedomain.com \n Site 2's SIP phones point to PBX2 at pbx2.fakedomain.com\n \"Reverse Proxy\" forwards data to relevant SIP server on LAN\n Single set of port forwards permitting relevant traffic from remote sites to the \"reverse proxy\" which forwards on to SIP server based on subdomain. (like NGINX would do with http/s traffic)\n  \nI started to dig into traefic a bit but don't want to go to far down the rabbit hole if it is not feasible.\n Is there a service that can do this? Ideally this would be an opensource solution but would consider a paid option if necessary. Am I better off just using a vpn than getting this configuration set up/working?\n Thank you for any insight anyone can provide.\n Edit: I would be interested in trying this with some other non-http services as well (specifically video) which is why I am considering this path.\n    submitted by    /u/tubzero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdfbwm/sip_reverse_proxy/",
          "publishedOn": "2022-12-05T18:38:00.000Z",
          "wordCount": 17118,
          "title": "SIP Reverse Proxy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdehjc/pingvin_share_the_selfhosted_file_sharing/",
          "author": null,
          "description": "Hey everyone\n A few months ago I introduced Pingvin Share in this community and I got many recommendations.\n In my free time I tried to implement these features:\n  \nSetup wizard\n Admin functionalities like managing users and configurations right on the website\n Email recipients\n Allow creating shares without an account\n Improved the security\n  \nWhat's next?\n  \nAudit\n Logging\n  \n... and maybe you have some recommendations ;)\n I want to thank you for the recommendations and contributions recently :)\n If you want to try or contribute to Pingvin Share just visit the repository.\n    submitted by    /u/GeneralXHD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdehjc/pingvin_share_the_selfhosted_file_sharing/",
          "publishedOn": "2022-12-05T18:10:04.000Z",
          "wordCount": 13716,
          "title": "Pingvin Share the self-hosted file sharing platform implemented your features 🎉",
          "imageUrl": "https://external-preview.redd.it/i85eAtpDQahXOPR5N2yBzOjKvFtTO5QiyhET0n3kLPA.jpg?auto=webp&s=a85c9e6435eca5152e37f7bf45b86ed8cff467aa"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zde5w8/i_guess_this_belongs_to_this_group_credits/",
          "author": null,
          "description": "submitted by    /u/zmbcgn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zde5w8/i_guess_this_belongs_to_this_group_credits/",
          "publishedOn": "2022-12-05T17:59:48.000Z",
          "wordCount": 16904,
          "title": "i guess this belongs to this group 😂. credits: @joe@mastodon.joedean.dev",
          "imageUrl": "https://preview.redd.it/ohsim8ahc44a1.png?auto=webp&s=1715e54cd2b08eebde765f8169c8d1da33f43ce0"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zdd1ns/looking_for_an_online_ide/",
          "author": null,
          "description": "Hey there,\n I am looking for a nice online IDE (like VS code).\n As I want to expose it to the internet it would need to have an OIDC/SAML/OAuth2 compatible authentication.\n Anything you know? What where your experiences with it?\n    submitted by    /u/Lord_Grafnus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zdd1ns/looking_for_an_online_ide/",
          "publishedOn": "2022-12-05T17:20:54.000Z",
          "wordCount": 13130,
          "title": "Looking for an online IDE",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zd6b07/any_recommendation_on_selfhosted_filedisk/",
          "author": null,
          "description": "Hello everybody I have multiple external drives that I kept all my files. I have used \"whereisit\" software for cataloging and to save content of these discs. It was a great software because it scans all the files inside a drive and save the content of this drive to its database. Then whenever I am looking for a file I search through whereisit database without even connecting the related external drive.\n As far as I understand from the whereisit web site it is discontinued so I am looking for an self hosted alternative software to make a catalogue of a drive if there is one.\n Primarily it will be used for scan and cataloging/searching a file inside offline hard drives. I will scan the files and find the which disk contains this file. Primarily I want to access GUI from web browser and search or browse files inside disks. If I can scan network mapped drives it will be awesome. \n ​\n Thanks in advance\n    submitted by    /u/polarbattaniye  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zd6b07/any_recommendation_on_selfhosted_filedisk/",
          "publishedOn": "2022-12-05T13:06:18.000Z",
          "wordCount": 16865,
          "title": "Any recommendation on selfhosted file/disk catalogue service",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zd67yn/oracle_oci_cloud_free_tier_what_do_you_use_it_for/",
          "author": null,
          "description": "Most of us already know about Oracle OCI Cloud Free Tier. I'm just asking about those of you who use it regularly.\n What do you use it for most often?\n Have you integrated Oracle VM with your home self-hosted systems?\n ​\n For now, I only used it to scan different networks from outside ... (Nmap), And now I'm considering moving some of my containers there (monitoring, some static sites, etc.), maybe with some Kubernetes cluster.. (but I'm still learning them)\n What is your experience? :)\n    submitted by    /u/Voklav  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zd67yn/oracle_oci_cloud_free_tier_what_do_you_use_it_for/",
          "publishedOn": "2022-12-05T13:02:17.000Z",
          "wordCount": 14134,
          "title": "Oracle OCI Cloud Free Tier. What do you use it for?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zd402v/selfhosted_s3_storage/",
          "author": null,
          "description": "Beforehand: I know about minio. Been using it since years, but in the recent updates it seems to get more bloated with features I don't need, weird access bugs (maybe only my configuration?) and most importantly wont work with unraids multidisks setup afaik\n I'm now searching for a new selfhosted S3 Storage, but mostly found software designed for multi node setups and incomplete documentation for single node, file system storage setups.\n I just want a docker image and point it to a directory and run it, maybe some per bucket access control but that's it..\n    submitted by    /u/stehen-geblieben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zd402v/selfhosted_s3_storage/",
          "publishedOn": "2022-12-05T11:09:00.000Z",
          "wordCount": 13277,
          "title": "Selfhosted S3 Storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zd2zrt/photo_managementorganization/",
          "author": null,
          "description": "At the start of this year, I finally ditched my iPhone for an Android phone and have since been having one particular issue: I have many, many gigabytes of old pictures that are quasi unorganized (thanks, iTunes...) but have all the proper meta-data - and that from all the way back of owning an iPhone 3GS on 3.1.3 no less! So the backlog is pretty big - and many memorable memories are hidden within.\n I looked at Damselfy but it seems to be geared more towards photographers, not for point-and-shoot type photography like random ol' me just snapping a picture because of something happening.\n Do you know of one that can: - Iterate through all my files and organize them by their (EXIF, largely) metadata? - Has an Android app so I can view them when on the go? (Yes, my hosted instance will be available outside through a Nebula VPN setup.) - Optionally recognize and thus \"tag\" pictures by faces? It'd be neat to pull up all the pictures with a specific person in it.\n Thanks! :)\n    submitted by    /u/IngwiePhoenix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zd2zrt/photo_managementorganization/",
          "publishedOn": "2022-12-05T10:09:51.000Z",
          "wordCount": 17045,
          "title": "Photo Management/Organization?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zd1tr5/kubero_the_heroku_alternative_supports_now_gitlab/",
          "author": null,
          "description": "Hi everyone,\n I'm the creator of Kubero, the open-source Heroku alternative for Kubernetes. For version 1.3.0 I focused on self-hosting.\n It should be your own choice where you want to host your code and your application. And this was something a really disliked on Heroku, that you can only deploy from GitHub.\n I'm happy to announce that Kubero now supports\n  \nGitLab\n Gitea\n Gogs\n Bitbucket\n GitHub.\n  \nYou can now automatically deploy your apps with a git push\n from any of these git providers. It does not matter if it's hosted on codeberg.org or gitlab.com or your self-hosted instance.\n I hope you like it, and if you have any feedback, or suggestions for other git repositories, please let me know.\n PS: Onedev was also planned, but I was not able to find any API documentation. I hope someone can guide me in the right direction. It is still on my roadmap. Thanks! \n ​\n https://preview.redd.it/6ejnvzq5o14a1.png?width=727&format=png&auto=webp&s=0fe2ce889470b35614ebf83e52cd31f5007a3169\n    submitted by    /u/2containers1cpu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zd1tr5/kubero_the_heroku_alternative_supports_now_gitlab/",
          "publishedOn": "2022-12-05T09:00:27.000Z",
          "wordCount": 16942,
          "title": "Kubero the Heroku alternative, supports now GitLab, Gitea, Gogs, Bitbucket, and GitHub",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zd02o2/free_course_to_teach_you_how_to_set_up_your_own/",
          "author": null,
          "description": "Hello everyone,\n A little more than a month ago I published my course and posted some 100% OFF coupons here on r/selfhosted: https://old.reddit.com/r/selfhosted/comments/yo0qmt/free_course_to_teach_you_how_to_set_up_your_own/\n Majority of you really liked it! Now that I have a new 100% OFF coupon, I'm posting it here again:\n https://www.udemy.com/course/real-world-devops-project-from-start-to-finish/?couponCode=FREEDEVOPS2212FIVQG\n To pay my dues, it will be exclusively here on r/selfhosted for 48 hours, after which I will post it on some other places too if there are any left.\n Edit: aaand it's gone!\n Happy learning, Predrag\n    submitted by    /u/predmijat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zd02o2/free_course_to_teach_you_how_to_set_up_your_own/",
          "publishedOn": "2022-12-05T07:17:42.000Z",
          "wordCount": 15185,
          "title": "Free course to teach you how to set up your own infrastructure, round 2",
          "imageUrl": "https://external-preview.redd.it/Kl0UYOIhr38bnc5eSL9O-d1idDlkkPqORhk6VCNJNog.jpg?auto=webp&s=d3c351e2bf47ba095b70f4f61fa0620a65d05641"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcsbmq/looking_for_cheap_cloud_options/",
          "author": null,
          "description": "I want to find a cloud service that will suit my needs.. I will be storing maybe 3~5 TB's of data.I tried the 3$ ones that they sell on an online shop (I wont call out), \"lifetime\" onedrive 5TB ones, and after 2 weeks it just went poof lol\n    submitted by    /u/Atsukiri  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcsbmq/looking_for_cheap_cloud_options/",
          "publishedOn": "2022-12-05T01:16:18.000Z",
          "wordCount": 15889,
          "title": "Looking for cheap cloud options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcrt14/any_ideas_for_a_self_hosted_twitch/",
          "author": null,
          "description": "I want to make a self hosted twitch service for me and my friends to all stream on do you have any ideas. it has to allow for multiple accounts to stream to the service and for multiple accounts. It should take an rtmp to work and should be free as in cost. any ideas will be nice. \n    submitted by    /u/whypickthisname  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcrt14/any_ideas_for_a_self_hosted_twitch/",
          "publishedOn": "2022-12-05T00:56:09.000Z",
          "wordCount": 15851,
          "title": "Any ideas for a self hosted twitch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcqhdu/grafana_alerts_via_gotify_how_can_i_set_priority/",
          "author": null,
          "description": "I've seen a few people using Gotify here, but I can't for the life of me figure out how to get the notification to have any value other than 0 when sending from Grafana.\n Sending with the example bash curl script works fine.\n    submitted by    /u/ikidd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcqhdu/grafana_alerts_via_gotify_how_can_i_set_priority/",
          "publishedOn": "2022-12-05T00:04:19.000Z",
          "wordCount": 16640,
          "title": "Grafana alerts via Gotify: how can I set priority to trigger notification sounds on Android app?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcpo1m/collabora_local_instance_docker_compose/",
          "author": null,
          "description": "I am trying to set up a Collabora server instance via Docker compose, and as of right now, I'm only doing everything locally and using IP.Addy.No:Port for accessing my services. However, all of the guides I can find online seem to require using a reverse proxy and a domain name to get Collabora working. Everything I've been able to find says that using localhost doesn't work.\n Does anyone know of any useful resources for connecting a Collabora server in a docker container with a Nextcloud instance in a separate container without using reverse proxies and domains? (I eventually do want to get into reverse proxies, but I'm doing this a little bit at a time, trying to get the most pertinent services up and running first) I am very new to Docker and running server services, so I haven't been able to make the logical leap over the gray area in all of the current guides I've seen.\n Thanks in advance.\n    submitted by    /u/modspyder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcpo1m/collabora_local_instance_docker_compose/",
          "publishedOn": "2022-12-04T23:33:20.000Z",
          "wordCount": 16739,
          "title": "Collabora local instance Docker Compose",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcouwe/calibre_xorgxrdp_log_files_is_it_safe_to_manually/",
          "author": null,
          "description": "I've googled and cant seem to find any information on the .xorgxrdp log files generated in/under the Calibre docker directory folder - I must not be using the correct search syntax. \n Would anyone know if it is safe to remove the files manually without it corrupting anything. Here is a example of the directory listing where i setup and deployed Calibre docker awhile back. \n Greatly appreciate any insight in advance.\n -rw-r--r-- 1 2408 Dec 23 2021 .bashrc\n drwxrwxr-x 6 4096 Sep 21 12:57 .cache\n drwxrwxr-x 148 12288 Dec 1 23:48 'Calibre Library'\n drwxr-xr-x 5 4096 Nov 28 00:14 .config\n drwx------ 3 4096 Dec 23 2021 .dbus\n -rw-rw-r-- 1 650 Dec 23 2021 docker-compose.yml\n drwx------ 3 4096 Dec 23 2021 .local\n -rwxr-xr-x 1 82 Dec 23 2021 startwm.sh\n -rw-r--r-- 1 4422975 Dec 1 11:00 .xorgxrdp.10…",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcouwe/calibre_xorgxrdp_log_files_is_it_safe_to_manually/",
          "publishedOn": "2022-12-04T23:01:46.000Z",
          "wordCount": 17085,
          "title": "Calibre .xorgxrdp Log files - Is it safe to manually remove them",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcoma6/pretty_distraught_setting_up_nextcloud_erased_my/",
          "author": null,
          "description": "I spun up a nextcloud instance via docker compose and when I was creating the volumes, I wanted to add my folder with all of my images. When I did docker-compose up, now the entire folder is gone, nothing in trash.\n I’m beyond upset. I lost photos of my father who passed away, my old pets, my whole life. I recently spent so much time downloading all of stuff from google and the like and kept this hard drive close like gold. Now it’s gone.\n I doubt anything can be done, but I’m just venting. What an absolute kick in the gut. I’m devastated.\n Edit: you’re probably wondering about backups- I had Duplicati set up to backup my whole server once a week to an S3 bucket but apparently it’s just been making empty buckets. I was too trusting of the notifications to try to look for myself. \n There is no backup of this drive because of this, and I am aware it’s my fault.\n    submitted by    /u/fossilsforall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcoma6/pretty_distraught_setting_up_nextcloud_erased_my/",
          "publishedOn": "2022-12-04T22:53:06.000Z",
          "wordCount": 16920,
          "title": "Pretty distraught: setting up nextcloud erased my entire harddrive. Did I just lose the last 10 years of files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcnb9q/my_website_domain_will_expire_in_2_days_what_do_i/",
          "author": null,
          "description": "In 2 days, my domain name will expire. If i renew it at the same place i bough it, will i have to renew the ssl wildcart cert and all the .pem and crap like this to something else. \n I bought it last year at ionos and they were offering free ssl wildcart cert with each domain name purchased. Installalling them was a nightmare under debain server with proxmox running under the hood. I was starting from 0 and ask a lot of information everywhere to achieve 100% what i want at this moment.\n I went on the website to renew my order and i would like to know how much it will cost, I can't see how much money i need to prepare with taxes and how much money i need to get for the ssl sert / domain guard and renewal of the domain name. \n I dont feel for renewing the files physically to something else. Can i avoid this part for the next 5 years to something else and mess with my website access security. i had problem making them works with the information i was seeing last time.\n    submitted by    /u/Boring_Twist_4975  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcnb9q/my_website_domain_will_expire_in_2_days_what_do_i/",
          "publishedOn": "2022-12-04T22:04:53.000Z",
          "wordCount": 16795,
          "title": "my website domain will expire in 2 days.... what do i need to do to preserve it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcmqj6/raspberry_pi_audio_shields_for_whole_home_audio/",
          "author": null,
          "description": "https://www.howtogeek.com/852455/raspberry-pi-has-new-hi-fi-audio-boards-for-your-diy-project/\n The audio hats for the Pis have just been updated, apparently. Does anyone know of projects that could be installed on a pi and used with this for whole home audio? \n I found this post which mentions a few projects but wanted to run it by this sub, first. https://www.reddit.com/r/RASPBERRY_PI_PROJECTS/comments/lnhqpc/is_there_a_good_way_to_multiroom_audio_in_2021\n My preference is to be able to use Google casting, but if I had to use another solution, that's fine. \n My main source for audio is Airsonic, though as the project is old and older now I may have to move to Jellyfin. I have tried Navidrome and generally find it inferior to Airsonic, with very little interest in using it as my main player. \n My goal would be to be able to queue up music from my phone to play in various rooms throughout the house. \n I like the ability to control each room's volume from my phone (like Google home, however their multi room audio has been terrible since they lost the Sonos lawsuit. I don't even bother with it anymore) as well as toggling rooms on and off. If it was possible to send different streams to different rooms simultaneously, that would be incredible. \n Lastly I might be interested in Home Assistant integration, though it's not a requirement. The companion app is okay, but maybe not where I'd want to be managing everything from. \n Obviously this is a big wish list, but I'd be curious to hear what you all are doing?\n    submitted by    /u/kulps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcmqj6/raspberry_pi_audio_shields_for_whole_home_audio/",
          "publishedOn": "2022-12-04T21:44:21.000Z",
          "wordCount": 16232,
          "title": "Raspberry Pi audio shields for whole home audio?",
          "imageUrl": "https://external-preview.redd.it/BlyHW7DNcI7KOkQLC-KvqpLub7zvlCkvMMeilS97v3M.jpg?auto=webp&s=6a210f2d47271df0e731b4878b5a51ee4e1c90ce"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcmp78/will_the_raspberry_pi_decrease_my_wifi_speed_for/",
          "author": null,
          "description": "Sorry if this seems like a stupid question,I’m new to this. but I wanna connect my raspberry pi which will be a web server for about 3 websites. Will this cause my wifi to slow down in my house? Will my server run slow if my wifi is not good enough?\n    submitted by    /u/QualityOrnery282  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcmp78/will_the_raspberry_pi_decrease_my_wifi_speed_for/",
          "publishedOn": "2022-12-04T21:42:56.000Z",
          "wordCount": 18357,
          "title": "Will the raspberry pi decrease my wifi speed for every everyone else",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcm931/how_to_start_with_my_journey/",
          "author": null,
          "description": "Hi, I'm looking for a way to have multiple raspberry pis (care about power consumption) do multiple tasks. I would like to have a website (blog + portfolio(already know html)), Home assistant, and more in the future. I would like to also have a whole dashboard and monitoring for my mini home lab. Soon might add a Pi nas as well. Looking to integrate all of thees things together. I heard some stuff about kubernetes, but I have no idea how it would run home assistant as a vm with addons.\n If somebody could help me get started you would make my day. Thanks.\n    submitted by    /u/Janiskooo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcm931/how_to_start_with_my_journey/",
          "publishedOn": "2022-12-04T21:26:48.000Z",
          "wordCount": 16335,
          "title": "How to start with my journey?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zclln5/odoo_alternative/",
          "author": null,
          "description": "Hello\n I have a lot of problem to find a true odoo developer for follow my business. Im building my saas and i need a big support and partner for long term. \n Can you suggest me another self hosted crm With a custom website like odoo? \n At moment this is the most problem work other crm.\n    submitted by    /u/Elemis89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zclln5/odoo_alternative/",
          "publishedOn": "2022-12-04T21:03:46.000Z",
          "wordCount": 16938,
          "title": "Odoo alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zck097/container_windows_on_mac/",
          "author": null,
          "description": "Hello, is it possible to run a container windows also on the macbook with the m1/m2 chips, or it need the intel chip like for the full virtual machine?\n    submitted by    /u/fafo17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zck097/container_windows_on_mac/",
          "publishedOn": "2022-12-04T20:05:47.000Z",
          "wordCount": 16612,
          "title": "Container windows on Mac",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zciuxm/apache_log_viewers_beautifiers_and_analytics/",
          "author": null,
          "description": "submitted by    /u/brisray  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zciuxm/apache_log_viewers_beautifiers_and_analytics/",
          "publishedOn": "2022-12-04T19:23:45.000Z",
          "wordCount": 16828,
          "title": "Apache log viewers, beautifiers and analytics",
          "imageUrl": "https://external-preview.redd.it/sxS-YKHsoSFaYdu0tYx2K395Orq3bAEsrIIsB6h69O0.jpg?auto=webp&s=0100787a3818a997607a7a23a0c8928de3e0b870"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcicz4/question_regarding_self_hosting_an_art_image/",
          "author": null,
          "description": "Hey there,\n I'm debating what I can host that can give me a very simple and easy layout to work with on an existing Nginx website that can help me create an art gallery and corresponding 'shop' section for some art for a client, similar to something that looks like this:\n  \nhttps://www.jessicakarpishin.com/\n  \n​\n Does anyone know if there is any kind of easy to use software that would be able to be deployed on Nginx? Is the only option Wordpress with a theme, if so what specific theme?\n    submitted by    /u/BackToPlebbit69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcicz4/question_regarding_self_hosting_an_art_image/",
          "publishedOn": "2022-12-04T19:05:11.000Z",
          "wordCount": 16210,
          "title": "Question Regarding Self Hosting An Art Image Gallery",
          "imageUrl": "https://external-preview.redd.it/YLwdU3SLKHngpTP_kAyoP2ai4r28hMm_D7KdMi6J6yA.jpg?auto=webp&s=9b5b2836e2371951d29e750c69db13fcbef0cd1f"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcdrud/is_there_a_selfhosted_web_scraper_that_lets_me/",
          "author": null,
          "description": "Let's say I want to target an item from a shop\n I want the scraper to notify me, if $('#item-price') is lower than 69.99EUR. Also configurable when ran (eg thrice a day). I'd then like to get a notification on let's say, Discord, that this event happened.\n I could also set up multiple of such events. Some that just look up the weather in the morning before my alarm and tells me to take an umbrella if rain is forecasted.\n I can program all of this myself with eg. Selenide, but I'd rather use a solution that's already available to save time.\n Does something like this exist? I'm cool with it if it requires writing scripts as well\n    submitted by    /u/waterslurpingnoises  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcdrud/is_there_a_selfhosted_web_scraper_that_lets_me/",
          "publishedOn": "2022-12-04T16:15:35.000Z",
          "wordCount": 16601,
          "title": "Is there a self-hosted web scraper that lets me target website elements and get notifications on changes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcd2b8/learning_shared_storage_for_proxmox_what_are/",
          "author": null,
          "description": "Good day all,\n I have a lab and I'm interested in expanding my ProxMox cluster to include a shared-storage option to make VM migrations fast.\n Setup:\n I have 3 matching systems (PX1, PX2, PX3) that currently have 500GB SSD drives in each. Running ProxMox 7.1.7.\n I have read much about Ceph, and also have Truenas option. I have done test migrations between PX systems, but these transfers take a while running 1GB Ethernet. I would like to add a shared storage cluster so the VMs will move faster.\n Do you recommend a Truenas ZFS external machine? Ceph on Ubuntu? I've also seen the Ceph setup inside ProxMox video that looks like it wants 3 matching drives, one dedicated for each PX system.\n What does the group recommend?\n    submitted by    /u/AustinGroovy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcd2b8/learning_shared_storage_for_proxmox_what_are/",
          "publishedOn": "2022-12-04T15:48:39.000Z",
          "wordCount": 18772,
          "title": "Learning shared storage for Proxmox - what are recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcctaj/tracking_and_analyzing_location_data/",
          "author": null,
          "description": "submitted by    /u/gue-niiiii  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcctaj/tracking_and_analyzing_location_data/",
          "publishedOn": "2022-12-04T15:38:27.000Z",
          "wordCount": 16902,
          "title": "Tracking and Analyzing Location Data",
          "imageUrl": "https://external-preview.redd.it/CwHPVZAoRfU-AbjkRqVXS3vLnBP_D-IOeQC9tETO3x8.jpg?auto=webp&s=bf2678b36d9a88485204b7e2f1bbdd58c1510eac"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcc4d8/new_webrtc_realtime_cam_2_cam_video_calls/",
          "author": null,
          "description": "New release, MiroTalk C2C, a WebRTC real-time cam 2 cam video calls, end-to-end encrypted, to embed in any website with a simple iframe.\n GitHub: https://github.com/miroslavpejic85/mirotalkc2c\n Demo: https://c2c.mirotalk.com/\n MiroTalk C2C\n    submitted by    /u/mirotalk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcc4d8/new_webrtc_realtime_cam_2_cam_video_calls/",
          "publishedOn": "2022-12-04T15:11:07.000Z",
          "wordCount": 16364,
          "title": "New WebRTC real-time cam 2 cam video calls, end-to-end encrypted.",
          "imageUrl": "https://external-preview.redd.it/thRUC_VGWWbBcDNnaZR573q020KcMdupHZfjifMqptY.jpg?auto=webp&s=f047cdd7d7323c50f2489db6d5a96cadcd85826f"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zcbryj/low_power_small_efficient_media_server_options_in/",
          "author": null,
          "description": "Hi all,\n I've been using a Raspberry 3 as my media server since a while and everything was fine. \n Sadly, some kind of power surge fried the board yesterday and it's at the worst period. I'm really short of options.\n Do you have a suggestion of what alternative SBC I could use as a media server? \n I have a simple setup and simple needs:\n  \nKodi\n HDMI out composite which \n gets to a box which splits audio via optical output to my audio decoder and video through HDMI to my beamer\n \n the box will only be on when I'll be watching a movie, so basically 4-5 times / week for 2 hours maximum (I don't watch TV).\n  \nThank you for your input\n    submitted by    /u/I-need-a-proper-nick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zcbryj/low_power_small_efficient_media_server_options_in/",
          "publishedOn": "2022-12-04T14:57:45.000Z",
          "wordCount": 18421,
          "title": "Low power, small, efficient media server options in those difficult times",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zc6vz3/should_i_use_ddns_with_nginx_reverse_proxy/",
          "author": null,
          "description": "I am planning to deploy a server with nginx reverse proxy, I don’t have dedicated iPs, so should I use a DDNS service, what ddns service if so? And would I just point a A record to the IP of the ddns?\n    submitted by    /u/Lowlowsomehow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zc6vz3/should_i_use_ddns_with_nginx_reverse_proxy/",
          "publishedOn": "2022-12-04T11:00:16.000Z",
          "wordCount": 17471,
          "title": "Should I use DDNS with nginx reverse proxy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zc5t35/silver_bullet_personal_knowledge_management/",
          "author": null,
          "description": "submitted by    /u/ankitrgadiya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zc5t35/silver_bullet_personal_knowledge_management/",
          "publishedOn": "2022-12-04T09:58:53.000Z",
          "wordCount": 19237,
          "title": "Silver Bullet - Personal Knowledge Management",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zc3cha/nginx_proxy_manager_vaultwarden_from_wan_not/",
          "author": null,
          "description": "My Goal is to use nginx Proxy Manager to reach different webservices under the same domain name on different ports. In this case I need a reverse proxy for vaultwarden to have Let's Encrypt certificate.\n From a WAN address I would like to reach my Vaultwarden Docker with https certificate by using a subfolder if that's possible.\n E.g. when opening https://home.mydomain.com/vw I'd like to reach my Vaultwarden which listens to port 7010 which is mapped to 443 within the container.\n This is what I've tried, without luck...\n Domain (Dynamic DNS): home.mydomain.com\n All docker containers are deployed with Portainer.\n Vaultwarden: IP 192.168.3.50 Port 7010 mapped to 443 inside container and 7011 -> 80.\n nginx Proxy Manager: IP 192.168.3.50, Port 80,81,443\n I've tried this Proxy Host config in npm Source: home.mydomain.com Destination: http://192.168.3.50:80 Block common exploits, Websocket Support SSL certificate assigned (Lets Encrypt), Force SSL, HTTP/2 Support\n with different custom locations:\n 1) Custom location: /vw Destination: http://192.168.3.50:7011\n When opening http://home.mydomain.com/vw from a WAN adress I get a 404 \"bitwarden...Page not found!...\" page. I can load the bitwarden login page from the local network using http://192.168.3.50:7011 \n 2) Custom location: /vw Destination: https://192.168.3.50:7010\n When opening https://home.mydomain.com/vw from a WAN adress I get 502 Bad Gateway....openresty \n    submitted by    /u/exp0sure74  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zc3cha/nginx_proxy_manager_vaultwarden_from_wan_not/",
          "publishedOn": "2022-12-04T07:18:01.000Z",
          "wordCount": 20696,
          "title": "Nginx Proxy Manager, Vaultwarden from WAN not working",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zc2m12/open_source_camera_board/",
          "author": null,
          "description": "I'm curious if anyone know what project wyze or other low cost cameras are based on. For the price I find it hard to believe it was home brewed. And all the over sees camera always seem to use the same softwareso there has to be some open source project i have not yet discovered.. Look what happened to ring. That was home made but it costs a pretty penny lol.\n From a quick search I see esp32 projects but I'm wondering what else is out there.\n Long story short when I'm at an airbnb or traveling I'd like a camera to watch the entrances or valuables. A propped up tablet is just too obvious.\n    submitted by    /u/eagle6705  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zc2m12/open_source_camera_board/",
          "publishedOn": "2022-12-04T06:31:20.000Z",
          "wordCount": 17414,
          "title": "Open source camera board",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbwrl1/self_hosted_photo_viewer_with_ldap/",
          "author": null,
          "description": "I have been wanting a photo viewer for a long time now because of Nextcloud Photos bugs. The upload process is amazing from my Pixel 6 but the viewing process is laggy. And Facial Recognition completely broke in Nextcloud 25. My hardware is underpowered either, I have an i5-8250u running just nextcloud and a 3 player minecraft server.\n ​\n Every one of my services is authenticated with LDAP, if OAUTH is available that also works since I run Authelia (planning to switch to keycloak in the near future). It also needs to work entirely in a browser.\n I have checked a lot of the go-to image viewers with facial recognition and none of them seem to support LDAP login... some don't even support proper user authentication.\n ​\n Thanks in advance\n    submitted by    /u/TeraBot452  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbwrl1/self_hosted_photo_viewer_with_ldap/",
          "publishedOn": "2022-12-04T01:29:52.000Z",
          "wordCount": 17596,
          "title": "Self hosted photo viewer with LDAP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbvnl5/announcing_duplicati_dashboard/",
          "author": null,
          "description": "​\n Task view\n The final release has been launched ! After two moths of development, the sotware is finished (for now).\n This version includes this features:\n  \nAdd / delete hosts\n Add / delete tasks\n Modify database connection\n Some graphs for statistics\n A history for every task\n etc.\n  \nYou can always open a new issue to ask for another one ! You can take a look in this repo and try it with Docker.\n    submitted by    /u/MarcOrfila  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbvnl5/announcing_duplicati_dashboard/",
          "publishedOn": "2022-12-04T00:36:48.000Z",
          "wordCount": 17462,
          "title": "Announcing Duplicati Dashboard",
          "imageUrl": "https://external-preview.redd.it/sFaWl4nV6opctRT-wlAEspRMfIYVmlk8I1he5ltmfV4.jpg?auto=webp&s=c321dc17fc4c218b4dc8730429fc45ea949b8aa1"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbvlb9/xmpp_server_on_custom_ports_is_it_possible/",
          "author": null,
          "description": "Due to my ISP not forwarding ports, I rely on my VPN to port forward, but I can only do it on randomly assigned ports over 1024, how o will that work if I want to host my own XMPP server?\n    submitted by    /u/No_Explanation_248  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbvlb9/xmpp_server_on_custom_ports_is_it_possible/",
          "publishedOn": "2022-12-04T00:33:58.000Z",
          "wordCount": 16822,
          "title": "XMPP server on custom ports, is it possible?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbuzey/domain_name_vs_duckdns_issue/",
          "author": null,
          "description": "I'm having an issue where I hadn't used some of my subdomains for some time with nextcloud. I have been using a duckdns link for when my public IP changed. Now I am getting warnings about some certificates expiring and I've found that none of subdomains I've had for years now with Google are working however my duckdns link is still accessing nextcloud properly and when I use a browser to try the subdomains I'm getting that \"congratulations you've successfully started the Nginx Proxy Manager\". So if from a browser off my LAN my duckdns link is working what is causing my subdomains to not load. For example b***.***server.com and *****.duckdns.org both go to nextcloud but only duckdns loads it. \n Thanks in advance for any help!!\n    submitted by    /u/JoeyZimbada  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbuzey/domain_name_vs_duckdns_issue/",
          "publishedOn": "2022-12-04T00:06:12.000Z",
          "wordCount": 17594,
          "title": "domain name vs duckdns issue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbug3z/homepage_by_ben_phelps_has_to_be_a_new_go_to_for/",
          "author": null,
          "description": "submitted by    /u/TechShocked  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbug3z/homepage_by_ben_phelps_has_to_be_a_new_go_to_for/",
          "publishedOn": "2022-12-03T23:42:35.000Z",
          "wordCount": 17411,
          "title": "Homepage by Ben Phelps has to be a new go to for dashboards, one of my favorites I've used",
          "imageUrl": "https://preview.redd.it/7uipvngqrr3a1.png?auto=webp&s=caa4bf27b6944153509832233f43371bb638106c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbu669/allowing_access_for_a_couple_friends/",
          "author": null,
          "description": "Hi, I host a truenas instance with a couple of apps. I’d like to allow a couple friends onto the network. I know I could use vpn or Tailscale but they are unable to install apps on their machines for one reason or another. So I’d like to open it up. I understand the risks etc. \n I do own a domain name from an old website I used to run. It would be cool to use the domain from it It’s no longer indexed via google. I have Xfinity internet. \n I did some researching and it seems that cloudflare tunnels would work but I can’t seem to figure it out. I think I set my dns up wrong from google to cloudflare. Idk\n Anyway is there a tutorial for this? Like something that’s detailed and step by step lol. I’m dumb I guess.\n    submitted by    /u/Steeler_Train  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbu669/allowing_access_for_a_couple_friends/",
          "publishedOn": "2022-12-03T23:30:27.000Z",
          "wordCount": 17628,
          "title": "Allowing access for a couple friends",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbu0ft/alternatives_to_jellyfin/",
          "author": null,
          "description": "Hi All,\n I switched to Jellyfin a while back after having a minidlna based setup, because I fell in love with the UI. However it has so many bugs which go ignored by the devs, it's becoming more of a pain than a joy to use.\n What are people using for self-hosted movie collections? My other-half has gotten used to the netflix-style ui of Jellyfin, so something similar is high on the list of reqs!\n Cheers!\n    submitted by    /u/ModerateBiscuit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbu0ft/alternatives_to_jellyfin/",
          "publishedOn": "2022-12-03T23:23:31.000Z",
          "wordCount": 17195,
          "title": "Alternatives to Jellyfin?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbtfpo/vm_dmz_with_a_vlan/",
          "author": null,
          "description": "I have a VM running some docker containers that I want to expose through a VPN. I have a VPS that I’m planning on using with a WireGuard tunnel and nginx reverse proxy. \n Online I found some stuff about a DMZ, but it mostly mentions a separate host that isn’t physically connected to your internal network. \n I have proxmox connected to an Omada switch, and then to my pfSense firewall…can I create a VLAN that blocks traffic from my internal network and put that on the VM? So I can connect to the VM from inside my network, but it’s only one way. \n I know that using WireGuard makes it safer than port forwarding, but just trying to not wake up and my NAS and other servers are owned 😂. Thanks!\n    submitted by    /u/MeerkatMoe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbtfpo/vm_dmz_with_a_vlan/",
          "publishedOn": "2022-12-03T22:59:22.000Z",
          "wordCount": 18269,
          "title": "VM DMZ with a VLAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbt2au/made_a_script_to_easily_set_up_a_secure_server/",
          "author": null,
          "description": "All info and code can be found on github: https://github.com/henrygd/docker-server-setup\n Only for Debian / Ubuntu for now. You can run it with the one liner below.\n If you proxy traffic through Cloudflare and want to run Fail2ban, there is some manual configuration you need to do.\n Pull requests welcome!\n curl -s https://raw.githubusercontent.com/henrygd/docker-server-setup/main/setup.sh > setup.sh && chmod +x ./setup.sh && ./setup.sh \n    submitted by    /u/Hal_Incandenza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbt2au/made_a_script_to_easily_set_up_a_secure_server/",
          "publishedOn": "2022-12-03T22:43:11.000Z",
          "wordCount": 17510,
          "title": "Made a script to easily set up a secure server with Nginx Proxy Manager, Fail2ban, Portainer, and File Browser",
          "imageUrl": "https://external-preview.redd.it/HMGXtg4SJYkpIQslo7A7yOHmlpI0vRapGLF89UPa0xA.jpg?auto=webp&s=c7dac47ffb50f974b198bc9d75a049af810eaa6b"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbsb3f/websites_on_remote_machines/",
          "author": null,
          "description": "This may be the noobest of questions but can my web server (nginx or caddy) serve sites where the files/directories are on a different physical machine? If so, what does that look like?\n    submitted by    /u/OctavioMasomenos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbsb3f/websites_on_remote_machines/",
          "publishedOn": "2022-12-03T22:11:59.000Z",
          "wordCount": 16601,
          "title": "Websites on remote machines?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbs2ff/membershipgroup_management/",
          "author": null,
          "description": "Any suggestions for a self hosted preferably docker like membership group management with some sort of email distribution system?\n    submitted by    /u/AmIBeingObtuse-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbs2ff/membershipgroup_management/",
          "publishedOn": "2022-12-03T22:02:03.000Z",
          "wordCount": 17746,
          "title": "Membership/group management",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbquhn/multiple_databases_with_one_container/",
          "author": null,
          "description": "Hi there,\n I was going to deploy some new docker container some of them are using Mariadb, now I thought why not deploy one mariadb container for all of them?\n Before doing that I wanted to ask, would it even noticeable save resources? Or will I introduce other disadvantages to my setup?\n If not what would be the best way to deploy it?\n Thanks in advance\n    submitted by    /u/haeth189  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbquhn/multiple_databases_with_one_container/",
          "publishedOn": "2022-12-03T21:12:33.000Z",
          "wordCount": 16714,
          "title": "Multiple Databases with one container?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbq1lg/any_selfhosted_order_management_systems/",
          "author": null,
          "description": "So I am building an ecommerce delivery system and I want to see if there are any systems that can optimize shipping routes for the orders... So lets say I have 50 orders to be delivered to 50 customers at 50 different locations... what I want to achieve is to automatically group orders and assign them to drivers, so drivers will deliever multiple orders on 1 go (like if the locations are near each other).\n Any systems you think of that I can use or tweak or use as a starting point to achieve this?\n Many thanks.\n    submitted by    /u/sdekna  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbq1lg/any_selfhosted_order_management_systems/",
          "publishedOn": "2022-12-03T20:39:26.000Z",
          "wordCount": 16594,
          "title": "Any selfhosted order management systems?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbp1z7/exploring_webiny_and_payload_for_a_web_project/",
          "author": null,
          "description": "Am currently in process of shortlisting and after checking on\n DirectUs Contentful Contentstack Storyblok Sanity Strapi Webiny Payload CMS\n I decided for solutions which are self hosted, and also have options (ideally to publish pages and basic SEO). I have now landed on Webiny and Payload (taking into account self hosted and pricing - otcourse payload wins here).\n Webiny - they clarified on their security (firewall, code security scans), they support multi site, and also have a page builder - that are some strong plus points. And they aren't too expensive for users.\n Payload - of course free, but I see nothing about security and its too developer dependent (good for something's, but not if I want some content guys to run independent fast)\n My requirements: will be building a product comparison web platform, that will scale really fast in terms of visitors. And I will decide on hiring freelance developers, once I close on this.. But will also discuss with my devs later on the solution.\n Inherent Security, Multi Site / Language, User Authentication, Page Builder / Form Builder / File Manager, SEO\n Would be great if I can hear about people who are using these.\n    submitted by    /u/AtomicFurion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbp1z7/exploring_webiny_and_payload_for_a_web_project/",
          "publishedOn": "2022-12-03T19:59:21.000Z",
          "wordCount": 16318,
          "title": "Exploring Webiny and Payload for a web project.. any feedback from people who use these?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbod2i/how_to_organize_drives_on_casaos/",
          "author": null,
          "description": "I'm using my 2018 year old pc and convert it to a server, I'm using CasaOS software docker ui, it is nice and everything but when I try to organize the drives I get a mess, to be clear I use 1 ssd 120gb for ubuntu server and 1 hdd 7tb for media and torrents, when I want to use the hdd to save the torrent files, I use qbittorrent docker image, not responding to the magnet urls, I tried another torrent client and gives me the same issue, when I reinstall the torrent client and don't change anything it is work but it is save the files on the 120gb drive not the 7tb drive, I tried to install ubuntu on the 7tb drive and install CasaOS but the drive reduced from 7tb to 90gb and I don't know why, if I install ubuntu server on ssd and mount hdd then install CasaOS on the hdd it will work? \n help me please\n    submitted by    /u/Mohammed-Alsahli  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbod2i/how_to_organize_drives_on_casaos/",
          "publishedOn": "2022-12-03T19:30:01.000Z",
          "wordCount": 17271,
          "title": "How to organize drives on CasaOS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbntgw/home_assistant_or_openhab/",
          "author": null,
          "description": "Looking to start creating my own smart home and have narrowed down to HA or OHAB. I'm fairly technically capable, Linux is my favourite OS, I play with r-pi's a fair amount and I code in various languages - these days mostly code Python with a little C++. Run a few servers at home, love the command line, and have experience with cloud computing. With that said, I'm a bit of a jack of all trades but master of non but not afraid of the unknown.\n I instantly loved the flexibility of OHAB and was wary of the easy to use for non-technical people focus of home assistant. However, the java backend of HA makes me worry. Sorry if this is stupid but in the past I've had jvm version conflicts with stuff and am a bit wary of that but I don't really know if that is relevant. Do I need to even worry about that with HA?\n Additionally, whilst I love flexibility and tinkering, my current work is very full on so I don't actually have that much spare time so maybe \"easy to use but less flexible\" is better for me these days??\n Does anybody have any experience and words of advice?\n Finally, is there a good place where people talk about and share smart home setups and configs etc?\n    submitted by    /u/Thinker83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbntgw/home_assistant_or_openhab/",
          "publishedOn": "2022-12-03T19:06:50.000Z",
          "wordCount": 19500,
          "title": "Home assistant or OpenHAB?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbk9w0/barrage_minimal_deluge_web_ui_with_full_mobile/",
          "author": null,
          "description": "submitted by    /u/maulik9898  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbk9w0/barrage_minimal_deluge_web_ui_with_full_mobile/",
          "publishedOn": "2022-12-03T16:34:22.000Z",
          "wordCount": 18445,
          "title": "Barrage: Minimal Deluge Web UI with full mobile support",
          "imageUrl": "https://external-preview.redd.it/F_k6Z8zhz2W8FcOpYNHVZTJfvKZoXTEeYo5FfjmeyvI.jpg?auto=webp&s=76bba458ecda5e150d5aaa862408c97b12cddb1f"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbk2hy/dasherr_now_supports_displaying_stats_from/",
          "author": null,
          "description": "submitted by    /u/erohtar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbk2hy/dasherr_now_supports_displaying_stats_from/",
          "publishedOn": "2022-12-03T16:24:48.000Z",
          "wordCount": 16514,
          "title": "Dasherr now supports displaying stats from multiple servers (running Glances) v1.04",
          "imageUrl": "https://preview.redd.it/jbmpyx8xkp3a1.png?auto=webp&s=eac97f2c65943fed2cbd3f5aa9fdd94ceff78c6d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbj0dc/update_16_for_bucket_budgeting_app_openbudgeteer/",
          "author": null,
          "description": "Hello community,\n I want let you know that I have just released Update 1.6 for OpenBudgeteer, a budgeting app based on the Bucket Budgeting Principle. The Update contains some new features, optimizations and a few fixes. Check out the Changelog for the full list of changes. Below some highlights of the new update:\n Recurring Transactions & Split:\n It's now possible to manually split a Bank Transaction for multiple Buckets. In addition, if the amount assigned to a Bucket is lower than the Transaction itself, the remaining amount is displayed. Creation of Recurring Transactions has been added too. This is useful if you mainly add your Bank Transactions manually instead of importing txt/csv files.\n Themes:\n Themes are now supported. Visit Bootswatch for more details. To select a theme use the new option APPSETTINGS_THEME as docker environment variable or in the appsettings.json file.\n Import Page Redesign:\n Import page got some slight redesign. You can now switch between all steps in an accordion view, where each section is enabled depending on your input.\n As usual any kind of feedback is highly appreciated.\n    submitted by    /u/The_Axelander  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbj0dc/update_16_for_bucket_budgeting_app_openbudgeteer/",
          "publishedOn": "2022-12-03T15:37:07.000Z",
          "wordCount": 16574,
          "title": "Update 1.6 for Bucket budgeting app OpenBudgeteer",
          "imageUrl": "https://external-preview.redd.it/zUc1O1nZY1jYurArxmAcu-Hwcx5bhCyoEPHhqnEeCik.jpg?auto=webp&s=6a43049cbeeabb07f62371602e2b60c3343b6aab"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbhsem/which_os_i_should_flash_to_my_raspberry_pi_4_4gb/",
          "author": null,
          "description": "My plan is to start with running a container for Pihole, maybe unbound, for starters and then go from there. Maybe NextCloud.\n So what OS do you recommend?\n    submitted by    /u/th0mas-anders0n  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbhsem/which_os_i_should_flash_to_my_raspberry_pi_4_4gb/",
          "publishedOn": "2022-12-03T14:40:44.000Z",
          "wordCount": 17011,
          "title": "Which OS I should flash to my Raspberry Pi 4 (4GB) as I plan to run Docker and start selfhosting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbhnu6/mail_muxer_self_hosted_inbox_filter/",
          "author": null,
          "description": "submitted by    /u/protoplancton  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbhnu6/mail_muxer_self_hosted_inbox_filter/",
          "publishedOn": "2022-12-03T14:34:36.000Z",
          "wordCount": 16861,
          "title": "Mail Muxer - self hosted Inbox filter",
          "imageUrl": "https://external-preview.redd.it/MgSI5K_v2A16eM_-8F2s3uQfkwE_5PqFGrJ1_6NxgX4.jpg?auto=webp&s=8abf0796e2a1d13eb908e0aeba262860fdaa1b65"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbgnac/tailscale_funnels_are_great/",
          "author": null,
          "description": "I really struggled to expose my Plex instance properly to the Internet before Tailscale Funnels released. Because im behind Carrier Grade NAT i cant just expose a port to the internet and be done with it. Also struggled with other solutions like using gluetun to route it through a Port forwarded from Mullvad(VPN Provider)\n It was a breeze to setup their Documentation is 100% on point i didnt have to quess anything or spend time googling configuration examples and i was done with it in like half an hour and its running great ever since.\n Only snag i hit is that you have to get the tailscale package from their unstable branch because the funnel features are not on stable branch yet.\n I really hope they dont go down the same route as cloudflared and banning media from the service\n    submitted by    /u/BigPPTrader  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbgnac/tailscale_funnels_are_great/",
          "publishedOn": "2022-12-03T13:45:30.000Z",
          "wordCount": 17698,
          "title": "Tailscale Funnels are great!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zbbdwe/note_app_that_is_web_based/",
          "author": null,
          "description": "Hi, I use Joplin server on my rpi but I’ve realised the I prefer jus a web app than standalone, and I ended using much more nextcloud notes. But I Nextcloud has much more stuff that I don’t need/want. Is there any good alternatives just for notes, not wiki, etc\n    submitted by    /u/Kraizelburg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zbbdwe/note_app_that_is_web_based/",
          "publishedOn": "2022-12-03T08:16:41.000Z",
          "wordCount": 17099,
          "title": "Note app that is web based?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zb3y36/firewall_rules_for_containers/",
          "author": null,
          "description": "I have my firewall to be set to subnets only, with an exception for containers as I want my media server to be able to fetch info etc.\n Is this safe? Should I have any more specific rules around it than just an allow for containers? \n Thanks!\n    submitted by    /u/stuaker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zb3y36/firewall_rules_for_containers/",
          "publishedOn": "2022-12-03T01:22:53.000Z",
          "wordCount": 17176,
          "title": "Firewall rules for containers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zb2wdl/introducing_the_dark_mode_of_nice_little_note/",
          "author": null,
          "description": "Hi everyone, I'm one of the main contributors to memos.\n About half a month ago, a friend sent me a link to a heated discussion on reddit. So I found the reddit self-hosted forum, and there were many comments about memos. The most mentioned one was dark mode, so we did our best to make a usable and readable version of dark mode.\n 👇 Here is the new version of memos with dark mode. Please enjoy.\n Dark mode in memos v0.8.1\n BTW. Personally, I really like services that support self-hosted, like trilium, mastodon and so on. From the first day when I created the repo of memos, I decided that it should be permanently free and open source, and mainly support self-hosted. In this way, most developers can easily deploy their own note-taking service locally or on their server.\n ​\n GitHub repo: https://github.com/usememos/memos\n    submitted by    /u/stevenlgtm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zb2wdl/introducing_the_dark_mode_of_nice_little_note/",
          "publishedOn": "2022-12-03T00:32:54.000Z",
          "wordCount": 17390,
          "title": "Introducing the Dark Mode of \"Nice little note taking app - Memos\"",
          "imageUrl": "https://external-preview.redd.it/cO6sqW1x8pHIcl6BguxpVT74AlvRzFQ97NLNbJVsKmE.jpg?auto=webp&s=081dc56eadf0df4c7afb77e2bf227129f66d4fb7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zb1upr/running_a_hypervisor_vm_on_windows_server/",
          "author": null,
          "description": "I currently have a Windows Server box with a tonne of Linux VMs for all my home services.\n I use VMWare Workstation to manage them all.\n I was wondering if it was worth having one ProxMox hypervisor VM and running and managing all the other VMs through that?\n I have my reasons for not wanting to do a bare-metal PM install right now, so was wondering if there would be an advantage to this method? Easier management etc?\n    submitted by    /u/TekgeckoStudios  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zb1upr/running_a_hypervisor_vm_on_windows_server/",
          "publishedOn": "2022-12-02T23:45:04.000Z",
          "wordCount": 17246,
          "title": "Running a Hypervisor VM on Windows Server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zb0wbs/network_monitor_with_web_gui/",
          "author": null,
          "description": "Hey guys, I was wondering is there any kind of network monitor for linux? I have a raspberry pi 4 that acts as a network ad blocker (AdGuard Home) and I tried Grafana + Prometheus combo, but thats a bit too much for me. I also tried some CLI stuff, but that didn't work, I told them to monitor the eth0 but it gave me just like few mbs even when I was downloading few Gigs.\n    submitted by    /u/Ill_Energy7165  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zb0wbs/network_monitor_with_web_gui/",
          "publishedOn": "2022-12-02T23:03:03.000Z",
          "wordCount": 16290,
          "title": "Network monitor with web GUI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zb08bw/this_is_what_my_first_automations_looked_like/",
          "author": null,
          "description": "submitted by    /u/Melodic_Walk_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zb08bw/this_is_what_my_first_automations_looked_like/",
          "publishedOn": "2022-12-02T22:38:07.000Z",
          "wordCount": 16453,
          "title": "This is what my first automations looked like",
          "imageUrl": "https://external-preview.redd.it/JlqU41F6YTbA6TRpq8Mwu-_vQixZvb90h2_ayCXnkso.png?format=pjpg&auto=webp&s=1806c0e6e5f68c23b8216d529c97adca71c96169"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zb07p0/playlet_an_invidious_frontend_for_roku_tv/",
          "author": null,
          "description": "This is not exactly a self hosted app, but it is a frontend to the great self hosted Invidious for watching Youtube.\n While most systems focus on the web (which covers almost all platforms) unfortunately, for someone like me who enjoys watching Youtube on TV, I'm stuck watching obnoxious unskippable ads the from the Roku Youtube app.\n I've had enough, that's why I created Playlet: a Roku TV app that integrates Invidious and SponsorBlock, so I can have the watching experience I needed.\n Find the repo here https://github.com/iBicha/playlet - v0.5.0 just released!\n I created this app for my own use, but I thought maybe few folks here might find it useful (honestly I don't even know who would be interested outside of this sub).\n It's in a usable state, but lots of features are on the roadmap, and I'm only getting started.\n If you do end up trying it out, I would appreciate any feedback!\n    submitted by    /u/iBicha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zb07p0/playlet_an_invidious_frontend_for_roku_tv/",
          "publishedOn": "2022-12-02T22:37:27.000Z",
          "wordCount": 16112,
          "title": "Playlet: an Invidious frontend for Roku TV",
          "imageUrl": "https://external-preview.redd.it/2aLv-NA_gtJKtKwNMowbp5CLAwLt343yzNZWdKJoDUc.jpg?auto=webp&s=c7e14ca159a689afaca4119999815024e1d85990"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zazut3/is_cloudflare_tunnel_safe/",
          "author": null,
          "description": "I'm self hosting some apps in docker. I exposed it to internet with Cloudflare tunnel. Is it safe that tunnel can connect to any device in local network. How to block it and only have access to server from tunnel?\n    submitted by    /u/MiCash545  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zazut3/is_cloudflare_tunnel_safe/",
          "publishedOn": "2022-12-02T22:24:19.000Z",
          "wordCount": 17187,
          "title": "Is Cloudflare tunnel safe?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zaz8fj/is_it_a_good_idea_to_selfhost_email_clients_on_a/",
          "author": null,
          "description": "My guess: the answer is no (but I am still happy to hear your thoughts).\n I have somewhat around ~20 IMAP email accounts (more like ~50 when you count all the aliases) with different domains, servers and whatnot. It's always a hassle when something changes to also update my email clients on various computers, smartphones and so on. Also: I have a laptop for work on which I don't want to install a private email client. \n The obvious answer to my \"problem\" is to have a webmail client which has access to all my IMAP mailboxes ... but I am not sure if I am comfortable with putting a service out there that can access all my personal data. I have basic knowledge of IT security and high respect of selfhosting critical applications on internet-connected machines. \n As convenience is always kinda opposed to security, I guess, my question is: how big is the risk when using something like RoundCube on a VPS? Can I easily harden it to a degree that it is still comfortable to use but also secure (enough)? How can I test security and monitor dangers like automated attacks or hacking attempts? Is it a good balance between secure and convenient to not host on a public VPS but on a sever that is only reachable via VPN/wireguard/tailscale...?\n TL;DR: How would you set up a webmail client that has access to all your mailboxes in a way that makes you feel safe?\n    submitted by    /u/juekr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zaz8fj/is_it_a_good_idea_to_selfhost_email_clients_on_a/",
          "publishedOn": "2022-12-02T22:01:34.000Z",
          "wordCount": 16388,
          "title": "Is it a good idea to selfhost email clients on a VPS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zaxxwd/does_mattermost_track_any_activity_when_installed/",
          "author": null,
          "description": "Asking because my employer wants us to download it. I know there is a web version but I'd rather download it, I just want to know if they can track my activity if I install it, and if so what.\n    submitted by    /u/Motor_Solid9841  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zaxxwd/does_mattermost_track_any_activity_when_installed/",
          "publishedOn": "2022-12-02T21:16:56.000Z",
          "wordCount": 16016,
          "title": "Does Mattermost track any activity when installed on a computer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zax74p/cloudflare_zero_trust_http_tunnel/",
          "author": null,
          "description": "Hi everyone. Slowly learning more about setting up a homelab and I am starting small. Hope I have the correct subreddit for my question :)\n I have an old pc that runs docker and manage it through portainer. Looking at lots of YouTube video's how to savely expose my Nextcloud instance. Well, I found a very interesting option called Cloudflare Zero Trust. No need to open ports on my router and use a proxy for save connection.\n I have setup a tunnel with a subdomain nextcloud.mydomain.com with service HTTP and url 192.168.x.xx:8080. After that created an application that bypasses my home ip. Now I can access Nextcloud via http://nextcloud.mydomain.com. Till now I get it and works, but my question is...\n Is using HTTP a bad thing? Is the connection between the browser and cloudflare HTTPS and between cloudflare and my server HTTP?\n Hope someone might explain a bit more and if there are any tips how to improve the setup. Thanks!\n    submitted by    /u/Verwi159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zax74p/cloudflare_zero_trust_http_tunnel/",
          "publishedOn": "2022-12-02T20:50:15.000Z",
          "wordCount": 17816,
          "title": "Cloudflare Zero Trust HTTP tunnel",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zawzrk/i_wanted_a_self_hosted_alternative_to_atlassian/",
          "author": null,
          "description": "For the last month, I have been working on an alternative to the proprietary StatusPage application by Atlassian.\n Meet ProdManager ! A lightweight application to display the current status of a service, infrastructure and many more. The last version 0.18.0 was just release 4 days ago.\n It features :\n  \nScopes to split your environment into smaller chunks\n Services to match your production environment\n Monitors to display your Scopes/Services status\n Install custom integration to fetch and update status from external sources \n Currently supported : Datadog, Jenkins, DNS, HTTP\n \n Track Incident status and resolution\n Plan Maintenances when updating your Service\n Mail notifications when creating or updating an Incident/Maintenance\n ICalendar download for Maintenances\n API endpoints\n API Python library\n Support for standalone deployment (Docker container) or Cloud Native (Kubernetes)\n  \nThe software is OpenSource and open to contribution. Feel free to bring your ideas and contribute the development of the application.\n Related resources :\n  \nDocumentation\n Sources\n Live Demo with demonstration data (secret: changeit)\n Contribution guide\n  \n   submitted by    /u/False_Lunik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zawzrk/i_wanted_a_self_hosted_alternative_to_atlassian/",
          "publishedOn": "2022-12-02T20:41:40.000Z",
          "wordCount": 15913,
          "title": "I wanted a self hosted alternative to Atlassian status page so I build my own application !",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zaucmi/looking_into_checking_out_frigate_cant_find_any/",
          "author": null,
          "description": "Can anyone point me to a frigate community?\n I want to know if the coral USB is compatible with the R710 and Unraid/Dockers.\n    submitted by    /u/sIlverbulette  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zaucmi/looking_into_checking_out_frigate_cant_find_any/",
          "publishedOn": "2022-12-02T19:00:28.000Z",
          "wordCount": 15764,
          "title": "Looking into checking out Frigate, can't find any support forums.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zau1cf/iscsinextcloud_vs_nfssmb/",
          "author": null,
          "description": "I have an old NAS (ix4-300d) which obviously can't have software upgrades or run containers.\n I also have a rpi4 with docker.\n Currently, I need android+win+mac backup support. Will running a nextcloud container based on iscsi mount from the nas to rpi affect the performance? should i just use smb+nfs? I can't figure out a good way to enable automatic backups from android...\n ​\n View Poll\n    submitted by    /u/arimal199  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zau1cf/iscsinextcloud_vs_nfssmb/",
          "publishedOn": "2022-12-02T18:48:27.000Z",
          "wordCount": 17322,
          "title": "iscsi+nextcloud vs NFS/SMB?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zatys1/i_created_a_guide_showing_how_to_utilize/",
          "author": null,
          "description": "submitted by    /u/Boonigan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zatys1/i_created_a_guide_showing_how_to_utilize/",
          "publishedOn": "2022-12-02T18:45:47.000Z",
          "wordCount": 17012,
          "title": "I created a guide showing how to utilize Terraform with Proxmox",
          "imageUrl": "https://external-preview.redd.it/ZDMI5xXmyBgH4wnOn1JyXGxj_hV8pZWNCiRKjSqcbQE.jpg?auto=webp&s=43a9b07d9a1550d2e51f01c1094a4f50749f8ab7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zascyf/authentik_doesnt_play_nice_with_firefox/",
          "author": null,
          "description": "So I will preface this by saying I have authentik set up already and everything else is working normally. I'm having some users on my network trying to access resources and when they receive the login portal, after entering their username it never transitions to allowing them to enter their password. There are no errors in the web browser itself and there are no errors reported in the logs on the server. Interestingly, if you follow the same exact procedure in a private window it works fine. Can't seem to figure out why it doesn't work in a regular browser window. I will also note that this is a issue pertaining to just firefox. But it is happening across several machines. I have tried deleting cookies and cache but both do not fix this problem. Has anyone seen similar Behavior?\n    submitted by    /u/kraxyk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zascyf/authentik_doesnt_play_nice_with_firefox/",
          "publishedOn": "2022-12-02T17:42:58.000Z",
          "wordCount": 17293,
          "title": "Authentik doesn't play nice with Firefox?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zarpv9/how_can_i_self_host_a_cloud_storage_to_store/",
          "author": null,
          "description": "submitted by    /u/impeter991  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zarpv9/how_can_i_self_host_a_cloud_storage_to_store/",
          "publishedOn": "2022-12-02T17:17:42.000Z",
          "wordCount": 16819,
          "title": "How Can I Self Host A Cloud Storage to Store Pictures, Videos, Files on Local WiFi Network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zar8uj/looking_for_advice_on_what_to_look_out_for_when/",
          "author": null,
          "description": "Now that I am hosting a few services that I would like to expose to the internet (vaultwarden, wallabag, etc), I would like to move away from simply having duckdns domains for everything and get a domain name. I have never done this before, and I wanted to ask what I should be looking out for when purchasing domain and web hosting. I was looking at hostinger who is offering more than what I can think of for $1.99/month, which seems like a good deal, but not sure if I am missing some important details, especially about security and privacy.\n    submitted by    /u/fredflintstone88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zar8uj/looking_for_advice_on_what_to_look_out_for_when/",
          "publishedOn": "2022-12-02T16:59:20.000Z",
          "wordCount": 17387,
          "title": "Looking for advice on what to look out for when choosing a web hosting plan",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zaquxo/trying_to_configure_nginx_proxy_manager/",
          "author": null,
          "description": "Im trying to configure nginx proxy manager in unraid but when I go to the url it shows a page from my router saying I dont have internet (not true if I try to open a website everything works fine). \n The ports i setup are the following:\n Public Port 443 --> LAN port 18443\n Public Port 80--> LAN port 1880\n These are forwarded to the ip 192.168.0.220 the ip of my server\n and when I try to enter in the proxy I get redirected to http://192.168.0.1/interception.html\n What im doing wrong?\n Dont know if it matter but im using IONOS for the domain.\n    submitted by    /u/gerardit04  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zaquxo/trying_to_configure_nginx_proxy_manager/",
          "publishedOn": "2022-12-02T16:43:30.000Z",
          "wordCount": 17415,
          "title": "Trying to configure Nginx proxy manager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zaqiok/looking_for_inventory_for_music_albums/",
          "author": null,
          "description": "I am looking to create a basic inventory system for music albums. This would be to help me keep track of what I have and what I don't have.\n Ideally, this would be a database to which I can add entries (the albums) and hopefully add custom fields (release years, record labels, where to buy it, etc.).\n Is there something I could make fit this need?\n    submitted by    /u/colorfularchipelago  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zaqiok/looking_for_inventory_for_music_albums/",
          "publishedOn": "2022-12-02T16:29:04.000Z",
          "wordCount": 16363,
          "title": "Looking For: inventory for music albums",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zaoy47/looking_for_self_hosted_time_keeping_software/",
          "author": null,
          "description": "I'm having trouble finding a self hosted time keeping project to use for our internal team. I've checked out the ones listed in the AwesomeSelfHosted github, but they seem geared to billing time to a customer. \n Does anyone know of a self hosted project where its centered around just tracking hours for employee's office hours? Then, at the end of the period, the manager can go get a report that shows X employee has X hours for X pay period? \n Thanks!\n    submitted by    /u/iC0nk3r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zaoy47/looking_for_self_hosted_time_keeping_software/",
          "publishedOn": "2022-12-02T15:22:52.000Z",
          "wordCount": 16285,
          "title": "Looking For: Self Hosted time keeping software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zaonzp/tube_archivist_v030_now_archiving_comments/",
          "author": null,
          "description": "It has been a few months since last posting here about progress happening with Tube Archivist, your self hosted YouTube media server. In case you have missed it, some recent notable additions and improvements:\n  \nYou can now archive and browse comments, wiki\n Every video has a similar videos section, showing a selection of related videos over your index, wiki\n There is LDAP authentication support with environment variables, as documented here\n You can filter videos in the download queue by channel, same with the channel pages, you can see pending videos of this channel\n Metadata snapshots, a new and better way of how to backup your metadata, deduplicated, significantly faster, and much more reliable, as documented here\n  \nAnd of course, let’s not forget the browser extension Tube Archivist Companion, which got basically a rewrite with v0.1.0. Download and subscribe buttons are now injected directly into the YouTube page, so very conveniently, you can send links from YouTube to Tube Archivist with just one click as you browse, see some screenshots and installation instructions here.\n We have come a long way since our humble beginnings little over a year ago. Nonetheless, we aren't out of ideas on how to improve and extend this project. Your help is needed: Any development help is highly appreciated, we are very grateful to the many people here who have helped with bug reports, improvements, pull requests and just general emotional support for the success of this project.\n The project: GitHub, help us reach 2k stars!\n The documentation: wiki and FAQ\n The browser extension: GitHub\n The Discord server: Link \n If you find this project useful, please donate.\n    submitted by    /u/bbilly1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zaonzp/tube_archivist_v030_now_archiving_comments/",
          "publishedOn": "2022-12-02T15:10:46.000Z",
          "wordCount": 16915,
          "title": "Tube Archivist v0.3.0 - Now Archiving Comments",
          "imageUrl": "https://external-preview.redd.it/XZ6gf87rBSQtr77em9ls4M7FYvO_At9dPZ-dI4Iwgvg.jpg?auto=webp&s=77f649b6d933c8d25d6c158c0452ed6b927750dc"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/zanpa2/recommendations_on_hardware_for_somebody_starting/",
          "author": null,
          "description": "OneDrive finally pissed me off badly enough that I am done using it. I was looking into Synology, since they have a photo setup that lets me search people by name, but I don't know that I even want to trust Synology. SyncThing looks really nice, but doesn't help me when I need to access files on my phone that are on one of my computers.\n I found NextCloud as a potential solution.\n I have no idea what it takes to get anything like this set up. I currently have about 4 TB worth of data that I need to store/access remotely. Any recommendations on hardware or just in general for getting things set up?\n    submitted by    /u/Elarionus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/zanpa2/recommendations_on_hardware_for_somebody_starting/",
          "publishedOn": "2022-12-02T14:29:33.000Z",
          "wordCount": 18128,
          "title": "Recommendations on hardware for somebody starting out?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/za9bbs/selfhosting_email_server/",
          "author": null,
          "description": "Hello. I am new to self-hosting, but I am learning, and I am very glad that I found this sub.\n ​\n A friend of mine asked me for some advice that is beyond me, so I am bringing the situation to you fine folks. He has an account with GoDaddy that provides him 100 email addresses (and I assume the web site) for his business. He has had this for a long time, but recently GoDaddy has changed and has become way more expensive than what he is willing to pay.\n ​\n He asked me how difficult it would be to set up an email server in his home to handle the email for his business. I looked over the intro post for this sub, but as I am just getting into this sort of thing, most of the stuff on Github was beyond me. Is this something that could be self-hosted? I should say, is this something that could be self-hosted and administered easily? I have some background with IT and networking, but he doesn't have any, and I don't want to get him set up with something that is going to turn into a full-time job for me, you know?\n ​\n I appreciate any help/advice, web sites, etc.\n ​\n Edit: Thank you to everyone that responded. I definitely need to get more information from him (how many accounts currently, how much mail sent/received per month on average, what his budget looks like, etc), but I will definitely bring your thoughts to him and see what he thinks. Thank you very much!\n    submitted by    /u/WWANormalPersonD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/za9bbs/selfhosting_email_server/",
          "publishedOn": "2022-12-02T03:02:07.000Z",
          "wordCount": 22042,
          "title": "Self-Hosting Email Server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/za7vpi/feature_release_nocodb_v01001_qr_code_keyboard/",
          "author": null,
          "description": "GitHub: https://github.com/nocodb/nocodb\n Hey Everybody, Everybody, 👋👋\n What's new .. What's fresh?\n ​\n v0.100.1 major updates\n 🎬 QR Code\n We are excited to announce a new column type: QR Code! This generates QR Code for any row of data, right in the spreadsheet itself. \n ​\n  \nAnd the more exciting bit about this feature is that it's from our community contributor \"Daniel Spaude\" (@spaudanjo) - Daniel is a software engineer by profession and is passionate about simplifying tech used in humanitarian crisis area. He has dedicated his time aside & raised grants to work on Noco.\n  \n⌨️ Keyboard Shortcuts\n Trigger some of the often-used actions without moving your mouse with combinations of keys.\n 🆒 Copy and Paste\n With 'Ctrl+C' and 'Ctrl+V', we can now copy the data from one cell to another…",
          "link": "https://www.reddit.com/r/selfhosted/comments/za7vpi/feature_release_nocodb_v01001_qr_code_keyboard/",
          "publishedOn": "2022-12-02T02:05:35.000Z",
          "wordCount": 19218,
          "title": "🚀 Feature Release: NocoDB v0.100.1 : QR Code, Keyboard Shortcuts and ... 🚀",
          "imageUrl": "https://external-preview.redd.it/7bTqhUi1BZBRoqEgkN8o6HYUJ9BaPpUfzghYke0k9_g.jpg?auto=webp&s=90e2611b3d83194522f3d7bfa9ea30658d5db519"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/za69ve/questions_regarding_self_hosting_photos_on_lan/",
          "author": null,
          "description": "Hey there,\n Issue:\n  \nMy partner just got a new iPhone, and has a ton of old photos on the old iPhone\n They want to be able to somehow view the older photos on the new iPhone without moving them over\n  \nResearch:\n  \nI looked into this issue, and only found 'My Photo Stream' which appears to be a shitty way for Apple to force people to basically sign up for their Apple iCloud service.\n The problem with this is that you're only able to see the photos from the last 30 days which is obviously shilling towards having to buy an iCloud storage account.\n They also appear to be kind of limiting the service as well and it appears to be discontinuing in the near future, so this isn't even a long term solution.\n  \nQuestion:\n  \nWith this in mind, I wanted to ask if anyone knew anything I can host on my local LAN file server that could automatically show an image gallery similar to the 'Photos' app that exists on iPhone itself? \n I figured there's gotta be a way around this, and I will even pay for a stupid iOS app that would allow for this as well (once, not subscription based though etc).\n  \n​\n Me as the hardcore Linux / Android user cringes with this kind of scenario however you can't change Apple fans for some reason unfortunately. As much as I hate this scenario, I figured maybe someone might help me out and this would be a good reference for someone as well.\n ​\n Thanks!\n    submitted by    /u/BackToPlebbit69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/za69ve/questions_regarding_self_hosting_photos_on_lan/",
          "publishedOn": "2022-12-02T01:02:54.000Z",
          "wordCount": 17275,
          "title": "Questions Regarding Self Hosting Photos On LAN File Server To Be Accessed By iPhone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/za2s7j/teddit_on_raspberry_pi_docker/",
          "author": null,
          "description": "Is a fully working version of Teddit in Docker on a Pi possible? I have Teddit and Redis running in Docker containers and I can open the main page, but nothing else works. It just hangs and then fails when I try to access a subreddit. So, I guess it's partially working. Or a fair facsimile thereof.\n    submitted by    /u/boc1892  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/za2s7j/teddit_on_raspberry_pi_docker/",
          "publishedOn": "2022-12-01T22:50:50.000Z",
          "wordCount": 16867,
          "title": "Teddit on Raspberry Pi (Docker)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/za2c2h/options_for_decreasing_media_server_latency_when/",
          "author": null,
          "description": "I manage an emby server that i share with my friends / family. On a recent trip across the globe, i noticed that emby load times were pretty slow from very far away (>5000 miles) . This was not an internet speed issue as the internet was very fast and the server is on gigabit. Direct SSH connections to my server were also significantly slower. Struggling to scp files at 5MB/sec.\n What can i do to significantly decrease remote server latency when accessing from very far away, specifically for emby?\n - I just turned on cloudflare proxy while being careful to disable caching since video streaming is technically against their terms of service. I'm not sure if this will help but i assume so due to increased peering\n - Would a kubernetes cluster help? Has anyone tried creating a CDN with kubernetes? Or would this not help since volume data is still mounted far away?\n - Other cheap CDN services that people use / recommend?\n    submitted by    /u/Exact-Improvement-80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/za2c2h/options_for_decreasing_media_server_latency_when/",
          "publishedOn": "2022-12-01T22:34:49.000Z",
          "wordCount": 16332,
          "title": "Options for decreasing media server latency when accessing from very far away",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/za0i95/expose_markdown_files_in_web_interface/",
          "author": null,
          "description": "I do most of my note taking in markdown in emacs. I used to sync and backup these files with Nextcloud but now I scrapped that for Syncthing. Nextcloud had an iOS client that was kind of flaky but it would sort of let me search and read my markdown files on the go. Is there a tool that will expose a directory tree of markdown files via a simple web interface?\n    submitted by    /u/oivvio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/za0i95/expose_markdown_files_in_web_interface/",
          "publishedOn": "2022-12-01T21:31:55.000Z",
          "wordCount": 16157,
          "title": "Expose markdown files in web interface",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9zwg9/website_to_selfhost/",
          "author": null,
          "description": "I'm having a hard time describing what I'm looking for. But the general idea is it's a website where users can choose a time to sign up and they will be given a unique id, number or qr code to confirm their seat for the event. \n The even is a weekly one and there will be multiple hours to choose from.\n ​\n I know there is a name for this type of thing but I forgot the name and could not find it online, and I would rather have it be selfhosted.\n    submitted by    /u/delta2905  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9zwg9/website_to_selfhost/",
          "publishedOn": "2022-12-01T21:10:57.000Z",
          "wordCount": 16925,
          "title": "Website to selfhost",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9xsnv/portainer_now_has_a_home_student_license/",
          "author": null,
          "description": "For anyone that wants portainer business features beyond the 5 nodes free, there is now a home and student license available.\n    submitted by    /u/DiHannay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9xsnv/portainer_now_has_a_home_student_license/",
          "publishedOn": "2022-12-01T19:54:08.000Z",
          "wordCount": 16675,
          "title": "Portainer now has a home & student license",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9xon5/influx_db_native_mqtt_support/",
          "author": null,
          "description": "I’ve seen that Influx DB is offering native collectors for MQTT. It looks like it’s advertised for Influx DB cloud. Does anyone know if it works on self hosted versions?\n It looks like it would be possible to cut out node-red type requirements for potentially high traffic messages. Exciting!\n    submitted by    /u/Illustrious_Fruit657  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9xon5/influx_db_native_mqtt_support/",
          "publishedOn": "2022-12-01T19:49:48.000Z",
          "wordCount": 16447,
          "title": "Influx DB native MQTT support",
          "imageUrl": "https://external-preview.redd.it/_GRuBgagP2FrOnhb6sTHuIdme0mH6q9YT8a5UlENLe8.jpg?auto=webp&s=a9567640ff96ce9b1be682230975d6d477069ca3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9x17k/download_from_google_photos_programmatically/",
          "author": null,
          "description": "Hi All!\n I want to backup my google photos and videos, and I want to do it programmatically, ideally once a day at the end of the day. Problem that I'm facing is that all instruction for programmatic access to google photos using OAuth have a WebUI step where you need to click to confirm access. It's like they are built for me as a service provider that needs access to users photos and I ask the user to enter their info so my software can interact with their library.\n Does anyone know of a process where I can auth against my google photos, get the token and then manipulate my library without any UI interactions?\n Thank you!\n    submitted by    /u/Fluffy_Initial596  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9x17k/download_from_google_photos_programmatically/",
          "publishedOn": "2022-12-01T19:25:51.000Z",
          "wordCount": 16909,
          "title": "Download from Google photos programmatically",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9wdp5/owncloud_infinite_scale_is_finally_released_after/",
          "author": null,
          "description": "submitted by    /u/dashcubeit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9wdp5/owncloud_infinite_scale_is_finally_released_after/",
          "publishedOn": "2022-12-01T19:02:01.000Z",
          "wordCount": 18501,
          "title": "Owncloud Infinite Scale is finally released after 4 years",
          "imageUrl": "https://external-preview.redd.it/w8t1vK2NR8yJoeaA8wduZhGuoG5Vwp24hVIUTduH7Q0.jpg?auto=webp&s=1f35fd982bad3bc2ddf34d98402276fe0d90e603"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9u066/only_you_and_mods_of_this_community_can_see_this/",
          "author": null,
          "description": "I just created a post - I'm desperate for help on a Wordpress database connection issue - but under my post it says \"Only you and mods of this community can see this\". What's up with that? Do all posts have to be approved by mods? Or am I just restricted because of my low karma (i'm fairly new to Reddit - started in August) or maybe because my profile was set to \"NSFW\"? (Not sure how/why - I don't remember setting that but I've turned it off now.) \n It seems like I'm far more likely to get help if the whole community can see my post.\n    submitted by    /u/OctavioMasomenos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9u066/only_you_and_mods_of_this_community_can_see_this/",
          "publishedOn": "2022-12-01T17:38:46.000Z",
          "wordCount": 15317,
          "title": "Only you and mods of this community can see this -- huh?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9tiyn/error_establishing_wordpress_database_connection/",
          "author": null,
          "description": "I was running Wordpress in 2 docker containers. It worked locally but I couldn't make it work using a Cloudflare tunnel so I tried restarting the containers and now I can't even run it locally - \"Error establishing a database connection\".\n My first thought was to just export the database and setup WP from scratch and import the db. (I know my way around databases a little.) So I used mysqldump to export it but when I open the exported file, the only post is the initial/generic \"My first post\". None of my posts are there!?!\n OK, I thought, let's try to fix the database connection. I looked in both containers (as well as the host volume) and found the wp-config.php file - but it has absolutely nothing in it about my database. It says \"define( 'DB_USER', getenv_docker('WORDPRESS_DB_USER', 'example username') );\" I'm pretty sure that \"WORDPRESS_DB_USER\" is a variable but it's not defined in the wp-config.php file. Where does it get the values for the vars?\n I'm starting to freak out, here. I spent a lot of time on a lot of posts and now I can't seem to find them anywhere. They can't be gone, can they? Just from restarting the containers? I'm obviously very limited in what I can do, here (partly by my limited knowledge and partly) because it's running in a container with no GUI and no way (that I know of) to run phpMySql. I *do* know the MYSQL_USER and MYSQL_PASSWORD but I can't figure out where to use them.\n PLEASE HELP!\n    submitted by    /u/OctavioMasomenos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9tiyn/error_establishing_wordpress_database_connection/",
          "publishedOn": "2022-12-01T17:20:41.000Z",
          "wordCount": 16953,
          "title": "Error establishing (Wordpress) database connection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9tfd6/self_hosted_booruimage_viewer_with_tagging/",
          "author": null,
          "description": "As a artist and someone with a lot of reference image material and artbooks, is there anything similar to a self hosted booru in the sense of extremelly complex image tagging capabilities? like, instead of separating images per folder since some elements can overlap and be of interest (ex. images contain a relevant clothing type and also some kinda of hairstyle and pose), somewhere where you can search for automatically or manually inserted tags like: black hair, short, long, leather jacket, short sleeves, sitting, sipping tea, holding a bat etc... etc.. etc... because more often than not I need references for specific pieces of clothing, poses or hair styles and remember that I have something like that but not exactly WHERE it is, and end up losing a lot of time searching for the needed references. I liked the way paperless-ng tags everything so you can easily find needed documents by the tags, but it uses OCR and text, my idea is something similar but for image even if I would have to spend some time manually tagging the pictures.\n    submitted by    /u/Kaikidan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9tfd6/self_hosted_booruimage_viewer_with_tagging/",
          "publishedOn": "2022-12-01T17:17:01.000Z",
          "wordCount": 16089,
          "title": "Self Hosted booru/Image viewer with tagging?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9sbex/problems_with_cloudflarenpm/",
          "author": null,
          "description": "Is anyone else having issues with Cloudflare Tunnels?\n For quite some time now, I've had 3-4 different hosts set up with Cloudflare Tunnels. Public hostname set to hit NPM instance, then handling all subdomains/subfolders/SSL from there. At some time last night, it all stopped working.\n I changed from wildcard to just base domain and pointed at insert dashboard here with Cloudflare and that works, but pointing a subdomain/subfolder to a different service does not. \n I later updated a different domain name with my home IP and did the old school port forwarding 443 to NPM and that works. \n So this tells me it's something with Argo?\n    submitted by    /u/thehomebiscuit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9sbex/problems_with_cloudflarenpm/",
          "publishedOn": "2022-12-01T16:32:39.000Z",
          "wordCount": 16172,
          "title": "Problems with Cloudflare/NPM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9n8ul/using_cloudflare_tunnel_auth_with_gitea/",
          "author": null,
          "description": "I’m currently using Cloudflare Zero-Trust Tunnels to access my self-hosted services, and I use their application authentication to restrict anyone else from accessing my tools. Just spun up a Gitea instance in Docker, and I’m wondering how to pass the CF service token when accessing a git repo. Has anyone used a configuration like this before?\n    submitted by    /u/John_Mason  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9n8ul/using_cloudflare_tunnel_auth_with_gitea/",
          "publishedOn": "2022-12-01T12:59:32.000Z",
          "wordCount": 16879,
          "title": "Using Cloudflare Tunnel Auth with Gitea",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9n5ng/my_wordpress_sites_are_refusing_connections_with/",
          "author": null,
          "description": "I'm using proxmox, Turnkey Linux WordPress containers 17.1. I have nginx proxy manager in front. The issue started when I moved my websites to 17.1 from 16.1. I made the move because I needed php7.4. I still have 1 website on 16.1 and it works fine on all devices. It's only the ones I updated that won't load on IOS. Getting connection refused. Like it can't parse the response. Any ideas would be helpful. Thanks.\n    submitted by    /u/BubbaBallyhoot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9n5ng/my_wordpress_sites_are_refusing_connections_with/",
          "publishedOn": "2022-12-01T12:55:10.000Z",
          "wordCount": 16080,
          "title": "My wordpress sites are refusing connections with IOS devices only.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9n5h7/will_booting_an_rpi_zero_from_an_ssd_be_worth_it/",
          "author": null,
          "description": "I have a few M.2s lying around I want to mount to my raspberry pi zero. Has anyone tried and noticed better performance? Also does anyone know if there's an adapter that can make it connect?\n    submitted by    /u/_xxx420xblazexitx___  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9n5h7/will_booting_an_rpi_zero_from_an_ssd_be_worth_it/",
          "publishedOn": "2022-12-01T12:54:59.000Z",
          "wordCount": 16023,
          "title": "Will booting an rpi zero from an SSD be worth it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9mq19/acces_local_webinterfaces_remotely/",
          "author": null,
          "description": "Besides using a vpn - is there any other reasonable way to access local web services (all browser based) behind my router without exposing each service via port forwardung ?\n I don't want to (cannot) install anything on external devices (e.g. at work), so a browser based interface would be great,\n I tried Firefox in Docker but it was awkwardyl slow and I have no idea how to password protect it.\n I think I'm not looking in the right direction ... any other idea?\n    submitted by    /u/abcdefghijklmopqrstx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9mq19/acces_local_webinterfaces_remotely/",
          "publishedOn": "2022-12-01T12:33:26.000Z",
          "wordCount": 18030,
          "title": "Acces local webinterfaces remotely",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9k91v/nezha_lightweight_monitoring_server_with_remote/",
          "author": null,
          "description": "submitted by    /u/kamikazechaser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9k91v/nezha_lightweight_monitoring_server_with_remote/",
          "publishedOn": "2022-12-01T10:13:44.000Z",
          "wordCount": 16533,
          "title": "Nezha: lightweight monitoring server with remote access features.",
          "imageUrl": "https://external-preview.redd.it/axakLmuoSnAPqkPWNySgEmPMuk-w_vtHEZV7zD524xg.jpg?auto=webp&s=059391fc2c7eea33934d61eb463bd2bafce4306e"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9jo9n/as_an_admin_i_can_access_all_the_email_messages/",
          "author": null,
          "description": "Hello,\n I've recently started creating an managing websites, so now I have to setup mailboxes for my clients. I use a separate cPanel account for every clients, and use that to setup the mailboxes, and it is working fine.\n What is troubling me is that as a user I always assumed the content of my email messages was encrypted and hidden even to the system admin and didn't suspect I, as an admin, could access freely my client's mailboxes. I assumed this was why you send a link to ask them to set their own password. However, disregarding on how the password is choosen, I simply have to click \"Check mail\" in cPanel to access whatever I want.\n I understand this is because I'm using client's cPanel to set their mailboxes, but they would never be able to do the job by themselves, so I guess I have no other option.\n Unfortunately, when dealing with one particular client, I also assured them I cannot access their email accounts. Now I'm pretty sure this is not even legal, and it looks like a huge privacy flaw to me.\n So, how can this be normal?\n Is there a way to avoid being able to access my clients' mailboxes?\n Thank you very much!\n    submitted by    /u/sblanzio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9jo9n/as_an_admin_i_can_access_all_the_email_messages/",
          "publishedOn": "2022-12-01T09:38:11.000Z",
          "wordCount": 19510,
          "title": "As an Admin I can access all the email messages for every client's Webmail mailboxes. Is this normal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9j22u/private_go_links_for_your_tailnet/",
          "author": null,
          "description": "submitted by    /u/gmemstr2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9j22u/private_go_links_for_your_tailnet/",
          "publishedOn": "2022-12-01T08:59:13.000Z",
          "wordCount": 16556,
          "title": "Private go links for your tailnet",
          "imageUrl": "https://external-preview.redd.it/6dYYEUHM6bmC0wfENwL3okKNcmVFn2P2ZvZV6g_1HJc.jpg?auto=webp&s=8f2334af457b2b5f807f4dd257a5018097cec02a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9hvnl/paperless_ngx_folders_for_multiple_people/",
          "author": null,
          "description": "Hey guys,\n I want to set up paperless ngx this weekend, did a lot of research and looking forward to use it.\n BUT ... is there any way to automaticaly sort documents in folders for different adresssants?\n I know its possible to automatically sort it into {created_year}/{correspondent}/{title} ... with a few other parameters.\n Background of this is, I want to sort in documents for my father and for me to seperate folder structures like {myself}/{created_year}/{correspondent}/{title} and {my_dad}/{created_year}/{correspondent}/{title}\n Any idea if this is possible? Weather automatically or manually?\n Important for me is, that it is really a folder structure, not only tagged.\n    submitted by    /u/Manto82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9hvnl/paperless_ngx_folders_for_multiple_people/",
          "publishedOn": "2022-12-01T07:42:20.000Z",
          "wordCount": 17801,
          "title": "paperless ngx - folders for multiple people",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9hhm7/lastpass_notice_of_recent_security_incident/",
          "author": null,
          "description": "submitted by    /u/ufo56  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9hhm7/lastpass_notice_of_recent_security_incident/",
          "publishedOn": "2022-12-01T07:17:47.000Z",
          "wordCount": 18693,
          "title": "LastPass - Notice of Recent Security Incident",
          "imageUrl": "https://external-preview.redd.it/G9jqQ8RKKkA421WBahtFV4b3_3mlgA2H-Iq22bbBPdU.jpg?auto=webp&s=4093177df40355f323662df05b2196068595db62"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9akjo/expanding_storage_without_losing_data/",
          "author": null,
          "description": "Hey guys, I have a 3tb hdd mounted for my jellyfin media and I want to add another 3tb to it. How should I combine the new hdd with the existing one without losing data on the existing one? I'm open to other strategies as well. Thanks.\n    submitted by    /u/dogcat0035  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9akjo/expanding_storage_without_losing_data/",
          "publishedOn": "2022-12-01T01:51:58.000Z",
          "wordCount": 16684,
          "title": "Expanding storage without losing data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z99z99/some_kind_of_virtual_pet_of_terrarium_or_even/",
          "author": null,
          "description": "Has anyone come across the above, like some kind of virtual pet, or cactus, or Conway's game of life variants that I can just sort of watch when I'm taking a break or something? That sorta grows over time, that's self hosted?\n    submitted by    /u/Hopeful-Animator6155  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z99z99/some_kind_of_virtual_pet_of_terrarium_or_even/",
          "publishedOn": "2022-12-01T01:26:52.000Z",
          "wordCount": 16708,
          "title": "Some kind of virtual pet of terrarium or even Conway's game of life variants",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z940ff/hosting_signal_frontend_on_a_local_server_like/",
          "author": null,
          "description": "So I just want to have a Signal desktop app but in the browser as a website. Like using a regular Signal desktop app but accessing it through a website, hosted on server (available only in local network of course).\n I am very used to FB Messenger and having it in a browser tab. The requirement of having an extra app is just odd and inconvenient for me.\n    submitted by    /u/kemot10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z940ff/hosting_signal_frontend_on_a_local_server_like/",
          "publishedOn": "2022-11-30T21:34:45.000Z",
          "wordCount": 16433,
          "title": "Hosting Signal frontend on a local server (Like Signal desktop but through website)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z93sss/tdarr_on_an_old_plex_laptop_server/",
          "author": null,
          "description": "Hello, I have a question about using Tdarr.\n I have an old Acer Aspire lying around which I turned into a Plex server. The OS is Ubuntu 20.04.5 LTS. It doesn't have that much space, and I heard that you could use Tdarr to compress video files. Is there any way I can run it on my laptop? Most of what I saw online about Tdarr was using it on something like a NAS or Unraid PC using Docker.\n    submitted by    /u/DisgustingFiend  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z93sss/tdarr_on_an_old_plex_laptop_server/",
          "publishedOn": "2022-11-30T21:27:01.000Z",
          "wordCount": 16745,
          "title": "Tdarr on an old Plex laptop server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z93f68/authentik_install_with_portainer_guide/",
          "author": null,
          "description": "Note! I wrote up this guide on just the basic way to get Authentic up and running. i myself am a beginner so any pointers would be much welcomed. It was super frustrating trying to get this up and running initially so I decided to give share my way of doing it in hopes of helping somebody in the same boat as me. I myself typically only browse Reddit and decided only right now to create an account and port this. Enjoy! I apoligize for the way this post is structured...the editor is kinda ass...I myself use Bookstack for my Wiki so that is why it looks badly put together\n This installation method is for test-setups and small-scale productive setups.\n Requirements\n ​\n  \nA Linux host with at least 2 CPU cores and 2 GB of RAM.\n docker\n docker-compose\n working Portainer Server or Edge Agent\n  \nD…",
          "link": "https://www.reddit.com/r/selfhosted/comments/z93f68/authentik_install_with_portainer_guide/",
          "publishedOn": "2022-11-30T21:13:14.000Z",
          "wordCount": 17977,
          "title": "Authentik install with Portainer (guide)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z92w3j/im_speechless_for_services_like_tailscale_whats/",
          "author": null,
          "description": "I lived under a rock, and only today I found a service called Tailscale.com . I think other provider offers the same thing, one alternative seems to be zerotier.com \n Basically I needed to expose an home server and I was ready to do the usual dance of enabling port forward on the router, expose SSH server to public internet, maybe install wireguard...etc.\n I looked into this sub for inspirations and I found tailscale, and it blew my mind. All devices are connected just \"like magic\"....now I'm wondering \"where is the bad news?\" \n I can imagine that someone doesn't like to use private service for network routing, but if that's the only problem, I can live with that :)\n    submitted by    /u/not-the-real-chopin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z92w3j/im_speechless_for_services_like_tailscale_whats/",
          "publishedOn": "2022-11-30T20:53:24.000Z",
          "wordCount": 17758,
          "title": "I'm speechless for services like Tailscale, what's the downside?",
          "imageUrl": "https://external-preview.redd.it/Ssi9-rid5q7xGFCN14pVfBNoJ21mwxgsCRQLdmGD3dA.jpg?auto=webp&s=a0b8114216605dd0b3a3bbf4f848eefbd0cad8b2"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z91l7u/using_ai_to_write_python_formulas_in_a/",
          "author": null,
          "description": "Wanted to share what we've been working on at Grist. We've been experimenting with AI-generated Python formulas to help everyday spreadsheet users write formulas in spreadsheets. Why? Spreadsheets are the original low-code platform – sprinkle in a little bit of code and you get a big benefit. But that little bit of code can be daunting for some. What if AI could bridge the gap between what the user needs a formula to do, as expressed in plain English, and the correct formula?\n While AI spreadsheet formula writing is not new, Grist has two benefits:\n  \nGrist supports Python formulas in the spreadsheet. Current AI models are quite good at writing Python code, and getting better. As a bonus, by writing formulas in Python, this tool could help spreadsheet users learn Python, a more universal and capable language than traditional spreadsheet functions.\n A Grist document is a relational database with its schema neatly described in Python in Grist's \"Code View,\" which is available to the bot, helping it make inferences.\n  \nWe tested the experiment using formulas from our template gallery to approximate real use cases. The AI-generated formulas were correct 36 out of 48 times in the minimal experiment dataset. You can view the results of that test here: https://public.getgrist.com/n3jAtRYDSVWe/AI-Formula-dataset\n And a gif to show it in action! \n https://i.redd.it/2tlx5xfl953a1.gif\n While this feature is not yet a part of Grist for the everyday spreadsheet user, we wanted to share the experiment's code with self-hosters who might want to play with it.\n  \nSource code: https://github.com/gristlabs/grist-core/pull/345\n Documentation: https://github.com/gristlabs/grist-core/blob/formula-prompt/documentation/llm.md\n \n If you're unfamiliar with Grist, here's a recap from an earlier Reddit post: https://www.reddit.com/r/selfhosted/comments/su6tv3/grist_free_open_source_alternative_to_airtable/\n    submitted by    /u/anaisconce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z91l7u/using_ai_to_write_python_formulas_in_a/",
          "publishedOn": "2022-11-30T20:03:40.000Z",
          "wordCount": 17040,
          "title": "Using AI to write Python formulas in a spreadsheet with OpenAI + Grist, an open source relational spreadsheet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z91gm5/accounting_software_and_logistics_software/",
          "author": null,
          "description": "So I run a small business and I am looking for an accounting software to assist in tracking my expenses mainly as well as revenue. For the logistics software I am just looking for something that can help me track packages and add updates as well as probably the cost of items. \n ​\n I have tried Odoo and I only really like it for the their POS module and quotations module. Any and all suggestions are appreciated.\n    submitted by    /u/dante_logan99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z91gm5/accounting_software_and_logistics_software/",
          "publishedOn": "2022-11-30T19:59:18.000Z",
          "wordCount": 16760,
          "title": "Accounting Software and Logistics software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z9138d/adguardhome_doh_and_latency/",
          "author": null,
          "description": "Hi guys, So, I'm selfhosting AdGuardHome DNS on my VPS and using it as DoH I haven't exposed the port 53 to public in order to avoid spam and have only exposed the secure DNS ports as 853 Now, if I use DNS, then my ping timings are increasing to around 400 MS and whereas without the DNS they are only 8-10 MS. (I'm on Windows) Is it possible that Windows is first trying to resolve the DNS via plane IP address on port 53 before falling back to DoH? I feel this because Windows asks for the DNS IP as well as DoH URL.\n    submitted by    /u/EroticTonic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z9138d/adguardhome_doh_and_latency/",
          "publishedOn": "2022-11-30T19:44:48.000Z",
          "wordCount": 19194,
          "title": "AdGuardHome DoH and latency?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z90qwn/parental_control/",
          "author": null,
          "description": "Any recommendations when it comes to parental controls, I'm looking for something that I can specify how much time user can spend on specific computer. Web and App control not necessary.\n    submitted by    /u/DinamoXP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z90qwn/parental_control/",
          "publishedOn": "2022-11-30T19:31:57.000Z",
          "wordCount": 17115,
          "title": "Parental Control",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8zw6q/selfhosted_unified_device_managementmobile_device/",
          "author": null,
          "description": "I've been shopping around for various Unified Device Management solutions that would allow the workers at my small company to sign in to their devices with SSO (OpenID Connect or SAML) or LDAP. Additionally, I would like to be able to manage the policies on these devices.\n Ideally, we'd like something self-hosted, but I have not found anything that comes even close to meeting these criteria.\n The closest options we've found:\n - Mesh Central - If we used this solution, then it seems like we'd only be able to use *remote* machines. Such as self-hosted remote workspaces. Not sure if it allows for policy management in addition to access management.\n - VMware Workspace One - Offers exactly what we need, including LDAP sync, but is not self-hosted and requires a 25-user or 25-device minimum, which is much more than we need at the moment.\n -PGina - It is free, open source, and self-hosted but not actively maintained and only offers Windows Authentication and no policy controls.\n We've also considered spinning up a Microsoft Active Directory instance, establishing a trust between it and our FreeIPA instance, and having Windows computers access it over VPN, but that only solves the problem for Windows computers.\n Are any of you familiar with any self-hosted applications which allow for Unified Device Management similar to what we are looking for?\n    submitted by    /u/Filiecs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8zw6q/selfhosted_unified_device_managementmobile_device/",
          "publishedOn": "2022-11-30T19:01:12.000Z",
          "wordCount": 17280,
          "title": "Self-hosted Unified Device Management/Mobile Device Management solutions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8zsw9/domain_name_works_on_external_networks_but_not_on/",
          "author": null,
          "description": "I am pointing a subdomain to DuckDNS which is pointing to my home server which is hosting my website on Nginx.\n The DNS is set up as follows:\n site.mydomain.com ---CNAME---> site.duckdns.org ---> Server Dynamic IP\n Port forwarding is set up on my router which routes 80 to 80, 443 to 443, and 2200 to 22 (Port 22 is used by my router itself) of the home server's internal IP.\n I have managed to get it working but the weird part is that this setup only works when I'm connecting from outside the network. When I'm in the network, everything (HTTP, HTTPS, SSH) doesn't work at all. What could be possibly the issue here? Pinging from the terminal, however, seems to be working fine.\n I have also tried those 3 services using both the domain site.mydomain.com and site.duckdns.org but both aren't working. It however works if I'm using the Internal IP 192.168.0.XXX. Public IP doesn't work too unless I'm not connected to the same network.\n    submitted by    /u/TheOriSudden  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8zsw9/domain_name_works_on_external_networks_but_not_on/",
          "publishedOn": "2022-11-30T18:58:17.000Z",
          "wordCount": 17402,
          "title": "Domain name works on external networks but not on the internal network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8ymft/rocketchat_vs_matrix/",
          "author": null,
          "description": "Hello,\n So I'm looking into options to take a group of roughly 40 people off Facebook. Right now we use a mixture of FB groups and email to communicate, and multiple Google calendars to organise us. Cost is pretty crucial, as in I don't really have money to spend. I can spare up to $15 on a VPS or root server but that's about it. I'm an absolute novice when it comes to self hosting but I can find my way around a console if there's a good tutorial. \n So far I had rocket.chat running in a VM and I like a lot. It does everything I want more or less out of the box. The thing I'm worried about is the notification limit on the free tier, 10 000 notifications / user / month comes down to 8.33 / user / day with a group of 40. Not a lot. Then again I'm unsure how much the DM function will be used so maybe it's fine? Compiling and distributing my own mobile apps is a bit much. Or is it? \n I've seen matrix with element recommended a lot but I don't quite get what the difference between the free and commercial element tiers are? Should I host my own element instance? What about mobile apps if I self host?\n Bonus question, jitsi looks great and is easy to integrate. Do I need to host my own server? I can't quite figure out what the limitations of meet.jit.si are?\n Apologies for the wall of text. This is all new to me and I'm quite surprised and exciting by the options out there!\n    submitted by    /u/PowderPuffGirls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8ymft/rocketchat_vs_matrix/",
          "publishedOn": "2022-11-30T18:16:16.000Z",
          "wordCount": 17590,
          "title": "rocket.chat vs matrix",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8wxnp/help_with_hosting_pleroma_instance_issue/",
          "author": null,
          "description": "I'm having an issue getting pleroma to work properly. I've been trying to host a pleroma instance on debian 11 bullsyeye. Installed pleroma and nginx using this guide: https://docs-develop.pleroma.social/backend/installation/debian_based_en/. When I access pleroma using localhost:4000, I can see my instance, but it is not connected to the outside world (The search bar doesn't return anything). In the pleroma server terminal I get this warning: \n [warn] Rate limiter disabled due to forwarded IP not being found. Please ensure your reverse proxy is providing the X-Fowarded-For header or disable the remote IP plug/rate limiter.\n When I try and access pleroma using my domain, I just get infinate loading. Meanwhile the pleroma server shows GET requests. Almost like pleroma is receiving the requests but the information is not getting out to the user. \n My Pleroma.nginx config is enterly stock apart from changing the server name and certificate locations.\n I have portfowarding configered on my router, and when I access my domain name without pleroma running, I get a defult Nginx is working, but you need to configure it. Which implies my domain name does point towards my debain machine. So im completely stuck. Installed and reinstalled pleroma and nginx and even the OS a few times. \n Any help or ideas would be appreciated, I am new to linux and networking.\n    submitted by    /u/timcoe4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8wxnp/help_with_hosting_pleroma_instance_issue/",
          "publishedOn": "2022-11-30T17:10:46.000Z",
          "wordCount": 18148,
          "title": "Help with hosting pleroma instance Issue.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8ut33/introducing_allnew_chevereto_free_edition/",
          "author": null,
          "description": "Dear reddit,\n My name is Rodolfo Berrios and I'm an indie developer from Chile.\n I created an image sharing software called Chevereto (username checks out) which I introduced in 2007. Chevereto enables to create your own image sharing website. Pretty much like your own Imgur/Flickr/etc. It is made to replace the need for these services and cheaply run it on your servers. The idea came when ImageShack removed pictures that I was hot-linking at online forums and here we are after all these years.\n Chevereto is a family company, I'm in charge of the software and my wife does marketing. We are a small team and we love what we do.\n I'm posting here to introduce our new free edition, AGPLv3 licensed, now available at chevereto/chevereto. This edition is focused in personal usage and it is on pair with our paid releases.\n Hope you can give it a try and thanks for reading!\n P.S. You can learn more about this new Chevereto free edition in a post I wrote at my blog.\n    submitted by    /u/chevereto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8ut33/introducing_allnew_chevereto_free_edition/",
          "publishedOn": "2022-11-30T15:46:54.000Z",
          "wordCount": 16922,
          "title": "Introducing all-new Chevereto free edition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8um0d/seatable_alternatives/",
          "author": null,
          "description": "Any alternative for Seatable?\n I’ve tried Grist, Baserow but it is not suitable to my needs.\n    submitted by    /u/Express_Steak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8um0d/seatable_alternatives/",
          "publishedOn": "2022-11-30T15:38:54.000Z",
          "wordCount": 17142,
          "title": "Seatable alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8th8a/launchdarkly_selfhost_alternative_open_source/",
          "author": null,
          "description": "https://github.com/featbit/featbit\n    submitted by    /u/hu-beau  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8th8a/launchdarkly_selfhost_alternative_open_source/",
          "publishedOn": "2022-11-30T14:53:35.000Z",
          "wordCount": 19622,
          "title": "Launchdarkly self-host alternative - open source feature management platform",
          "imageUrl": "https://external-preview.redd.it/09r_HFlgv_TI4j614jqT0dax_lvRUfXFGzHRYYAF7x4.jpg?auto=webp&s=b58e6dfe3cc0039c6aaa1db9b3b9acb523e9a1c1"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8t26k/i_built_an_open_source_search_engine_position/",
          "author": null,
          "description": "submitted by    /u/towfiqi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8t26k/i_built_an_open_source_search_engine_position/",
          "publishedOn": "2022-11-30T14:35:59.000Z",
          "wordCount": 18536,
          "title": "I Built an Open Source Search Engine Position Tracker",
          "imageUrl": "https://external-preview.redd.it/Buzvc1_amKbvqgxWxsUJCIWrs2MqGNmBtdWFIEKBYwQ.png?format=pjpg&auto=webp&s=82e1692f79260ee70580077192fecb7ca72cd7a8"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8spym/one_rpi_now_two_cloud_vms_everything_chugging/",
          "author": null,
          "description": "submitted by    /u/erohtar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8spym/one_rpi_now_two_cloud_vms_everything_chugging/",
          "publishedOn": "2022-11-30T14:21:36.000Z",
          "wordCount": 16381,
          "title": "One rPi + Now two Cloud VMs. Everything chugging along nicely",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8sf5h/grafana_high_severity_security_fix_for/",
          "author": null,
          "description": "submitted by    /u/DisturbedBeaker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8sf5h/grafana_high_severity_security_fix_for/",
          "publishedOn": "2022-11-30T14:08:36.000Z",
          "wordCount": 16203,
          "title": "Grafana high severity security fix for CVE-2022-31097",
          "imageUrl": "https://external-preview.redd.it/JoN0gyjmFyRaLrTFLIyer3rTuZ6y-OHlZWkN0z2Yqx4.jpg?auto=webp&s=d8c6c90382e6b014b9ec3899f7fbe667ba926e4c"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8saqr/cilicon_low_maintenance_selfhosted_macos_ci_on/",
          "author": null,
          "description": "submitted by    /u/traderepublic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8saqr/cilicon_low_maintenance_selfhosted_macos_ci_on/",
          "publishedOn": "2022-11-30T14:03:14.000Z",
          "wordCount": 17972,
          "title": "Cilicon - Low Maintenance Self-Hosted macOS CI on Silicon using Apple's Virtualization Framework",
          "imageUrl": "https://external-preview.redd.it/39wORmb2O_b1cL-Bc9KIC904pvqFu6xlMbGN6WSd_Gs.jpg?auto=webp&s=2119eae637ca5074ebd7e6b781a2babcffe3a7c0"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8q89y/warning_to_all_those_still_using_epikcom/",
          "author": null,
          "description": "Some of us were to busy or lazy to leave after the massive exploit of usernames, passwords, home addresses, credit card numbers, etc. over at Epik.com. Hopefully this story will have those of you like me retreat before your well...screwed frankly. \n Today I tried to login to my account and was faced with the normal 2FA they, not unreasonably, forced on users. No problem, right? Well, the Epik was unable to submit the SMS Authentication. When looking for assistance, I was told that I have provide them with a \"selfie\", a government issued ID, and a copy of my utility bill. See image for exact details. \n If your one of the few still on Epik.com, please heed the warning. Also, if you have any advice for me, I'm all ears. \n ​\n https://preview.redd.it/bh0e9vja033a1.png?width=1196&format=png&auto=webp&s=ce376b3bbec3b7e1df3136204b63eb6d38933db0\n    submitted by    /u/m-o_o  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8q89y/warning_to_all_those_still_using_epikcom/",
          "publishedOn": "2022-11-30T12:27:39.000Z",
          "wordCount": 18248,
          "title": "Warning to all those still using Epik.com",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8nzn5/gps_tracker_platform_for_sinotrack_st90x_devices/",
          "author": null,
          "description": "PHP alternative to Traccar built with Laravel 9 + PHP 8.1 and MySQL 8. Currently only support Sinotrack ST-90x devices using H02 protocol.\n My focus is develop a simple and easy to manage Traccar alternative to servers with PHP support.\n Project Home https://github.com/eusonlito/GPS-Tracker\n English README https://github.com/eusonlito/GPS-Tracker/blob/master/README.en.md\n Feedback is welcome :)\n    submitted by    /u/eusonlito  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8nzn5/gps_tracker_platform_for_sinotrack_st90x_devices/",
          "publishedOn": "2022-11-30T10:22:21.000Z",
          "wordCount": 17693,
          "title": "GPS Tracker platform for Sinotrack ST-90x devices built with Laravel 9 + PHP 8.1 and MySQL 8.",
          "imageUrl": "https://external-preview.redd.it/bPcHAkOOfaasI4hvSUvHpkCZiL0I7m97EJmLHKTeizI.jpg?auto=webp&s=a8c7c48a01890fd206bcd2fb33c2bab3caa091c3"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8f4k1/in_light_of_the_recent_eufy_controversy_what_door/",
          "author": null,
          "description": "https://www.reddit.com/r/EufyCam/comments/z397hp/tech_youtuber_paul_moore_recently_dropped_a/\n Anyone know a doorbell camera that can send notifications to my phone with video but not use the cloud? I'd prefer it if I could keep the data local, preferably on my home server.\n    submitted by    /u/burger4d  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8f4k1/in_light_of_the_recent_eufy_controversy_what_door/",
          "publishedOn": "2022-11-30T02:57:54.000Z",
          "wordCount": 16574,
          "title": "In light of the recent Eufy controversy, what door bell camera would you recommend?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8d7pc/coder_v2_lessons_learned_from_v1_and_oss_to/",
          "author": null,
          "description": "submitted by    /u/geoffreyhuntley  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8d7pc/coder_v2_lessons_learned_from_v1_and_oss_to/",
          "publishedOn": "2022-11-30T01:40:11.000Z",
          "wordCount": 16443,
          "title": "Coder v2 - Lessons learned from v1, and OSS to Enterprise Editions",
          "imageUrl": "https://external-preview.redd.it/cCjTciBIam7MA0uqWwmS_71wYdc4BRJX1f1_7Q-HJ7A.jpg?auto=webp&s=0ffec390dc218e222b5fb9fc0b61e5943b61b952"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8bp3f/please_tell_me_a_free_service_that_runs_python/",
          "author": null,
          "description": "I've been using heroku so far, but the free plan has ended. So I tried it with Render and mogenius, but it didn't work with the free plan (insufficient memory?). \n Could you please tell me the information that selenium was able to run with Render or mogenius, or that you were able to run it with other services? I like the service that does not require a credit card even with the free plan.\n    submitted by    /u/Consistent_Copy5292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8bp3f/please_tell_me_a_free_service_that_runs_python/",
          "publishedOn": "2022-11-30T00:38:34.000Z",
          "wordCount": 16587,
          "title": "Please tell me a free service that runs python and selenium environments.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z89i5k/self_hosting_but_not_missing_out_on_new_music/",
          "author": null,
          "description": "Hey guys, new here\n I have a small plex media server I use for porn primarily and movies secondary. I really like the idea of being self-hosted and I like the experience of having reliable access to my media on my terms. I'm thinking of moving over all my stuff to a Jellyfin server (including music and personal photos) once I can get that working. I like how Jellyfin is open source because it makes me feel as though I can use it indefinitely as long as I have access to the source code, and I can configure it as I please.\n The only media application I don't think I can fully replace is Spotify/Apple Music soley because I like being recommended new music. Is there a way to bypass having to manually download music so that I can get new music recommendations that just magically appear on my media server?\n    submitted by    /u/Bulbapoor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z89i5k/self_hosting_but_not_missing_out_on_new_music/",
          "publishedOn": "2022-11-29T23:13:51.000Z",
          "wordCount": 16729,
          "title": "self hosting but not missing out on new music",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z898yr/is_it_a_bad_idea_to_whitelist_ips_by_sending_a/",
          "author": null,
          "description": "Hi!\n I've been hosting a few http services both in my Pi at home, and in a public cloud and I don't like the VPN way of accessing my services. Sometimes I need to browse my server in a friends computer or phone, and it gets messy or impractical, so I end up exposing the services to the public web sometimes. I worry quite a bit about forgetting to update my software and finding my server being used to host sketchy bank scams.\n What I have been thinking of doing is blacklisting every IP in my nginx reverse proxy, but allowing a single HTTP endpoint to be accessed, like \"allow.domain.com\", where after receiving any http request, it would add the origin IP into the whitelist for a set amount of time (a few hours). I would also setup geoblock to only allow the endpoint to be accessed from my country.\n The point is that I don't need a super locked-down set up, I just want the peace of mind that my server is not just visible to anyone. If I am at work I can authorize my ip for a few hours just by accessing a simple endpoint, if I want to share a file with a friend I can forward them a link without having to worry about setting up a VPN connection for them, just letting them know they first have to go to allow.domain.com before trying to open my link every few hours or days. \n Is that ok? I searched a bit to see if there's something like this prod. ready but I couldn't find. I know it's still the single point of failure of the http service being open to the web, and the fact that it's a bit \"security through obscurity\", but I just need something to give a little reassurance and more security than just being blindly open to the world. I am not hosting copyrighted media, or anything illegal, just a few status servers, change detection, python-notebook, a few api's I made for my work, non-private files, etc.\n    submitted by    /u/mefudi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z898yr/is_it_a_bad_idea_to_whitelist_ips_by_sending_a/",
          "publishedOn": "2022-11-29T23:03:41.000Z",
          "wordCount": 19638,
          "title": "Is it a bad idea to whitelist IP's by sending a HTTP request to an endpoint on my public facing server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z88hth/how_can_i_create_my_own_spf_subdomain/",
          "author": null,
          "description": "I'm self-hosting my email server and realized I want/need a more uniform way of including my SPF records for other domains.\n Does anyone have any info on how I can achieve wrapping all of my IPs into a single subdomain?\n include:spf.mydomain.com\n ​\n edit:\n it looks like maybe I just create the TXT record on the host domain then I can include: THAT??\n    submitted by    /u/xwayfarer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z88hth/how_can_i_create_my_own_spf_subdomain/",
          "publishedOn": "2022-11-29T22:35:24.000Z",
          "wordCount": 17113,
          "title": "How can I create my own SPF subdomain?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z87qlf/backup_solution_over_network/",
          "author": null,
          "description": "I am using raspberry pi with a 1tb disk a nas on my home network. I would like to back this up (preferably incrementally) to another machine on the network daily. Any recommendations for doing this? I am looking for a tool which does not use proprietary format to store backup and it will be great if it has a UI.\n    submitted by    /u/Reasonable_Island943  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z87qlf/backup_solution_over_network/",
          "publishedOn": "2022-11-29T22:06:10.000Z",
          "wordCount": 16030,
          "title": "Backup solution over network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z87jw3/one_time_password_protected_download/",
          "author": null,
          "description": "I'd love to be able to give a one time password to a buddy for a one time download of a file, looking to send some raw audio tracks for him to mix.\n What are the current self-hosted solutions for this?\n    submitted by    /u/FoolHooligan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z87jw3/one_time_password_protected_download/",
          "publishedOn": "2022-11-29T21:59:10.000Z",
          "wordCount": 16536,
          "title": "One time password protected download",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z87ct3/what_does_a_web_server_do_when_sent_a_request_for/",
          "author": null,
          "description": "Given a standard setup of\n end user -> web server -> application server -> DB, for a web application\n I have two questions:\n  \nIs a web server in charge of these two things?\n  \ni. serving up static content (.css, .js, .HTML)\n ii. forwarding (proxying) requests to the application server and relaying the application server's response to the end user\n  \nIf ii above, could you clarify exactly what happens?\n  \nThank you.\n    submitted by    /u/JonathanMonathan62  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z87ct3/what_does_a_web_server_do_when_sent_a_request_for/",
          "publishedOn": "2022-11-29T21:51:17.000Z",
          "wordCount": 16912,
          "title": "What does a web server do when sent a request for application server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z86p78/is_there_an_open_source_alternative_to_grammerlys/",
          "author": null,
          "description": "submitted by    /u/SuperNo59  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z86p78/is_there_an_open_source_alternative_to_grammerlys/",
          "publishedOn": "2022-11-29T21:25:45.000Z",
          "wordCount": 17423,
          "title": "Is there an open source alternative to grammerly's AI-powered full-sentence rewrites feature?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z867nl/server_client_tool_for_replacing_twetter_account/",
          "author": null,
          "description": "Hi, I use Twitter as a sort of public log for my thoughts, sort of pure microblogging (no chat, no thread, no social features...). Is there a stable, future-proof, well-supported, mature, easy... tool server (plus mobile app) that I might selfhost to replace it? Best option should also be able to import actual tweets so I could close my twetter account. Suggestions?\n    submitted by    /u/wireless82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z867nl/server_client_tool_for_replacing_twetter_account/",
          "publishedOn": "2022-11-29T21:07:36.000Z",
          "wordCount": 16561,
          "title": "Server + client tool for replacing Twetter account used a microblog.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z8402w/i_built_a_tiny_slack_alternative_for_the/",
          "author": null,
          "description": "submitted by    /u/doublejay1999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z8402w/i_built_a_tiny_slack_alternative_for_the/",
          "publishedOn": "2022-11-29T19:48:33.000Z",
          "wordCount": 17048,
          "title": "I built a tiny slack alternative for the decentralized web",
          "imageUrl": "https://external-preview.redd.it/GsPdeh1GdtKd6qv9mDU5lBYAp9JfNOlLDR2faqJK9Z4.jpg?auto=webp&s=79b7fd9df52224d28ff0991c8e211052eaf6433d"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z81xze/please_confirm_my_understanding/",
          "author": null,
          "description": "I've been trying to understand the full-stack pipeline (the process of fetching files and data from the end-user). From my research, there are two main diagrams that people use to describe this (for web applications!).\n  \nEnd user -> Frontend -> Backend -> Database\n End user -> Web Server (also serves frontend files)-> Application Server -> Database\n  \nMy question: Isn't #1 diagram flawed? I started off learning the #1 diagram, but it has made it much more difficult to learn how web applications actually work with the #2 diagram.\n Work:\n https://preview.redd.it/wmadezwvox2a1.jpg?width=1668&format=pjpg&auto=webp&s=fea8d1471200dfccffbb95f76b54861621836a71\n ​\n Could someone review my work and tell me if my final iteration is correct and if my negative view of the #1 diagram is valid?\n    submitted by    /u/JonathanMonathan62  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z81xze/please_confirm_my_understanding/",
          "publishedOn": "2022-11-29T18:31:56.000Z",
          "wordCount": 19266,
          "title": "Please confirm my understanding!!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z812gi/generate_fake_email_address_forward_to_real_email/",
          "author": null,
          "description": "hi\n I'm currently using Ironvest(aka maskme\\abine) when creating account on websites\n It generates for me an email address that forwards to my real email. These website never know my real email address.\n I can stop the forwarding any time and delete the generated email\n I'm afraid they close or stop their free service, it there any similar selfhosted container?\n thanks\n I have a domain, so I could use it\n    submitted by    /u/chamallowdesbois  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z812gi/generate_fake_email_address_forward_to_real_email/",
          "publishedOn": "2022-11-29T17:59:39.000Z",
          "wordCount": 18079,
          "title": "Generate fake email address + forward to real email address",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z80cgw/how_do_i_put_my_website_on_the_internet/",
          "author": null,
          "description": "So I built my website, setup the nginx server on my raspberry po and have a domain name.\n All the port forwarding tutorials tutorials online are for home networks. Is it possible to do it with my university’s wifi? If so than how?\n Is there another or better option for my situation\n    submitted by    /u/QualityOrnery282  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z80cgw/how_do_i_put_my_website_on_the_internet/",
          "publishedOn": "2022-11-29T17:32:33.000Z",
          "wordCount": 16758,
          "title": "How do I put my website on the internet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7ytt6/any_up_and_coming_rpg_rulebook_services/",
          "author": null,
          "description": "Of all the media I host, it seems like RPG Rulebooks are the odd one out in that nothing works great for them. Big PDF files that need to be organized by Game, and subfolders for different resources per game (Maps, Adventures, Rule Books, Player Guides, etc).\n This 'hierarchical' structure becomes a real issue when trying to use any current solution out there for PDFs, because they really need to be grouped together, but nothing provides a folder level grouping. \n  \nPaperless - No folder grouping at all. No way to subdivide rpgs into various groups without a ton of manual tagging, which should just be read at the folder level\n \nKomga - Doesn't read folder hierarchy. It reads the individual folders, but it doesn't nest folders in the UI\n \nKavita - Doesn't display folder based hierarchy, and instead shows each individual PDF\n \n Are there any good PDF organization tools that can use nested folders and possibly even tags properly to organize RPG Rulebooks?\n    submitted by    /u/XxNerdAtHeartxX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7ytt6/any_up_and_coming_rpg_rulebook_services/",
          "publishedOn": "2022-11-29T16:34:40.000Z",
          "wordCount": 17312,
          "title": "Any up and coming RPG Rulebook services?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7xqoo/im_provisioning_and_deployng_baremetal_machines/",
          "author": null,
          "description": "submitted by    /u/gaga0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7xqoo/im_provisioning_and_deployng_baremetal_machines/",
          "publishedOn": "2022-11-29T15:53:02.000Z",
          "wordCount": 16211,
          "title": "I'm provisioning and deployng baremetal machines of my homecluster (shitcluster what i do call it) with MAAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7xkde/are_there_any_good_selfhosted_alternatives_to/",
          "author": null,
          "description": "I’ve been on the hunt for a good self hosted “notes” app for a while now, but apparently that’s not the right word to use for what I’m looking for. \n Apps like MilaNote is more what I’m looking for. I’m currently using Notability, but don’t like being tied to iCloud.\n I am still currently playing around with Etherpad, but it doesn’t allow embedding PDFs, and lacks any serious way to organize different pads. Plus I can’t find much of a community. \n AppFlowy looks promising but is lacking most of what I currently need. \n Affine has started over so it currently lacks everything I need, but I’m keeping an eye on it. \n I have found a few projects that run in browser, but most don’t allow importing PDFs which is big for me. And none seem to have any “in app” organization.\n    submitted by    /u/relink2013  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7xkde/are_there_any_good_selfhosted_alternatives_to/",
          "publishedOn": "2022-11-29T15:46:08.000Z",
          "wordCount": 16376,
          "title": "Are there any good Selfhosted alternatives to things like OpenBoard or Milanote?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7uo0r/best_way_for_highavailable_database_at_home/",
          "author": null,
          "description": "At this moment I have a high available k3s cluster running on proxmox containing ZFS storage with several applications like Authentik, jellyfin, firefly, sonarr, radarr, nextcloud, and much more. I have some applications running on a docker host as well. Every application that doesn't use sqlite has it's own database statefullset with a PVC using longhorn or NFS. The docker apps have a docker container with docker volume. Since I now have different approaches, I would like to migrate this so all applications use 1 external high-available database.\n I don't have much experience with HA databases, so I can't really decide which way I should go. I found a postgres-operator to be run on a kubernetes cluster: https://github.com/zalando/postgres-operator. And a guide to setup postgres HA with patroni: https://arctype.com/blog/postgres-patroni/\n Which approach do you use at home? Any other recommendations?\n    submitted by    /u/MrrFresh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7uo0r/best_way_for_highavailable_database_at_home/",
          "publishedOn": "2022-11-29T13:51:56.000Z",
          "wordCount": 17868,
          "title": "Best way for high-available database at home?",
          "imageUrl": "https://external-preview.redd.it/lbBAP7rMI4qTOAXT8PNKoblhUlqYcaVznBVvMJRrdNQ.jpg?auto=webp&s=c429d9f31dd1c8016a0284662239c4e82912e707"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7u6gs/how_do_you_backup_your_docker_volumes/",
          "author": null,
          "description": "I am managing my self-hosted applications via Docker Compose. As the number of applications is growing, I am thinking about a backup strategy for my data stored in the Docker volumes.\n I still haven't decided whether it is better to use named Docker volumes, or just simple local volume mounts. For local volume mounts, backup would be fairly easy to do (just tar everything a move to a backup storage). For named Docker volumes, it seems like the process is a bit more complicated, since Docker doesn't seem to provide any built-in commands for backup and restore.\n How do you backup your Docker stuff? Does anyone know of applications making those things a bit easier?\n    submitted by    /u/eight_byte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7u6gs/how_do_you_backup_your_docker_volumes/",
          "publishedOn": "2022-11-29T13:32:02.000Z",
          "wordCount": 18091,
          "title": "How do you backup your Docker volumes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7twnn/looking_for_a_simple_docker_dashboard/",
          "author": null,
          "description": "I am currently managing my self-hosted application via Docker Compose manually from the command line (what I personally prefer over using tools like Portainer etc. for various reasons). However, I am looking for a simple dashboard application which gives me some statistics about my containers like CPU & memory usage etc. I am using Portainer for this single purpose right now. But since I am not managing my containers via Portainer, it seems like the wrong tools for the job. Can someone recommend something similar what gives me some stats about the containers I am running?\n    submitted by    /u/eight_byte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7twnn/looking_for_a_simple_docker_dashboard/",
          "publishedOn": "2022-11-29T13:20:31.000Z",
          "wordCount": 18946,
          "title": "Looking for a simple Docker dashboard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7rr37/a_good_low_power_arm_sbc_for_running_an_sftp/",
          "author": null,
          "description": "I'm looking for solutions for remote backup \"servers\".\n Basically I want to leave an HDD in one or multiple off-site locations and send a copy of the backups to this HDDs.\n I think a good solution is running an SFTP server on a low power SBC.\n I was looking into Raspberry pi Zero 2W but it seems quite limited in terms of Network Bandwidth.\n Anybody has a better idea for an SBC or solution to this need?\n    submitted by    /u/ZioTron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7rr37/a_good_low_power_arm_sbc_for_running_an_sftp/",
          "publishedOn": "2022-11-29T11:43:44.000Z",
          "wordCount": 17774,
          "title": "A good low power ARM SBC for running an (S)FTP server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7qqkb/check_out_baserow_113_with_rolebased_access/",
          "author": null,
          "description": "We are excited to announce the release of Baserow 1.13 and introduce two new security features as a part of Baserow Enterprise: role-based access control and single sign-on. We also launched Baserow on Product Hunt and would appreciate if you support us: https://www.producthunt.com/posts/baserow-2.\n More information at: https://baserow.io/blog/1-13-release-of-baserow.\n Try it out at: https://baserow.io\n GitLab repository: https://gitlab.com/bramw/baserow\n Our community forum: https://community.baserow.io/\n Product Hunt: https://www.producthunt.com/posts/baserow-2\n    submitted by    /u/bram2w  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7qqkb/check_out_baserow_113_with_rolebased_access/",
          "publishedOn": "2022-11-29T10:53:11.000Z",
          "wordCount": 16760,
          "title": "Check out Baserow 1.13 with role-based access control and SSO + support us on Product Hunt 🚀 - Open Source Airtable alternative",
          "imageUrl": "https://external-preview.redd.it/oURCd8UIkTR_4xdPgU_x87UaUyx9v4CVFMEaa_UF4eM.jpg?auto=webp&s=a784f4dca10907ca3f7a415893bd57de5b395ecd"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7p6ty/joinpeertube_gets_a_redesign_peertube_v5_on_its/",
          "author": null,
          "description": "submitted by    /u/Framasoft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7p6ty/joinpeertube_gets_a_redesign_peertube_v5_on_its/",
          "publishedOn": "2022-11-29T09:34:33.000Z",
          "wordCount": 17768,
          "title": "JoinPeertube gets a redesign, PeerTube v5 on its way!",
          "imageUrl": "https://external-preview.redd.it/EH2OKJVz-ec_6l8OGFc9jO9OcTwPnQvUrAxYp1ugvD0.jpg?auto=webp&s=5d2658d6c8cedba6a017047cef317cef91ee9606"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7oo2r/whats_the_best_selfhosted_vpn/",
          "author": null,
          "description": "Preferably with an webgui to manage users/devices. \n Specs of VPS 4GB Ram 50GB SSD 5TB Bandwidth a month\n Devices that will be connecting 2 macOS devices 3 iOS devices 2 Windows Devices\n    submitted by    /u/doctorecu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7oo2r/whats_the_best_selfhosted_vpn/",
          "publishedOn": "2022-11-29T09:06:37.000Z",
          "wordCount": 17806,
          "title": "What’s the best selfhosted VPN?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7fcs0/got_my_asn_and_now/",
          "author": null,
          "description": "Today I got my ASN, got a black friday promo and ordered, now that I have it with an /40 block, what I can do? \n Build a VPN from my virtual bgp router on vultr and point each ip to each service? \n Any other ideas?\n    submitted by    /u/little-pdh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7fcs0/got_my_asn_and_now/",
          "publishedOn": "2022-11-29T01:29:58.000Z",
          "wordCount": 16814,
          "title": "Got my ASN and now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7dyqt/any_addition_security_for_my_server/",
          "author": null,
          "description": "So I've had a home server up and running for a few months, at first it was just local with only plex exposed. Now I am going to visit family in December and I want to access my media server while I'm away, and I've got that working. I've done the following for my server and i want to know if I need to do anything else, security-wise.\n - I have NOT exposed the unRAID web UI to the internet.\n - All exposed containers are running on a customer bridge network.\n - Nginx reverse Proxy manager manages which ports are exposed to subdomains.\n - Nginx has an SSL certificate and all containers are forced to use HTTPS.\n - In Cloudflare, I've set the domain to full SSL/TLS encryption.\n - All containers have different passwords to access.\n The only thing I can think of doing next is adding a VPN, but I'd like to know from you guys how important you think it is to implement.\n    submitted by    /u/Sally_san  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7dyqt/any_addition_security_for_my_server/",
          "publishedOn": "2022-11-29T00:29:22.000Z",
          "wordCount": 17050,
          "title": "Any Addition security for my server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7dqvq/free_or_cheap_alternative_to_google_forms_with/",
          "author": null,
          "description": "Hi,\n I'm building a website for a political party and we need something similar to Google Forms but with the ability to ask the user to confirm his entry by clicking a link sent in his emails. Compatibility with Zapier is a really nice bonus, but at least ease of integration for third party APIs or webhooks is required (we'll need it to link the forms to compagnies' API in order to send mail IRL when an entry is confirmed, and we're also working with Ghost's member panel).\n I spoted Budibase, which looks quite cool and way simpler / cheaper than Backendless for what we'll do with it. (two or three forms) But I can't find any documentation mentionning the ability to require the user to click on a confirmation link. Is it doable ?\n ​\n Thanks\n    submitted by    /u/gregfdzd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7dqvq/free_or_cheap_alternative_to_google_forms_with/",
          "publishedOn": "2022-11-29T00:20:00.000Z",
          "wordCount": 17031,
          "title": "Free or cheap alternative to Google Forms with custom confirmation email & link",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7d0ac/metabase_or_redash_or_what/",
          "author": null,
          "description": "Trying to decide which BI/dataviz to deploy and I’m curious if anyone knows of another option I’m unaware of that’s also foss like metabase or redash. \n I have large amounts of sql and excel table data in the real estate and finance world I’m trying to consolidate to run better analysis on to build visuals for client reports. \n I had planned on running a cloudron build via droplet or on my AWS which has another cloudron instance I’ve deployed. (Trying to stay with what I know) both metabase and redash are available as app on cloudron, that’s why I’m considering them.\n    submitted by    /u/crispins_crispian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7d0ac/metabase_or_redash_or_what/",
          "publishedOn": "2022-11-28T23:51:16.000Z",
          "wordCount": 16928,
          "title": "Metabase or Redash or what?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7cvm9/tunneling_services_that_support_tk_domains/",
          "author": null,
          "description": "Currently setting up a website with a free domain as a hobby, but cloudflare tunnels and packetriot don't support .tk top level domains. Anyone know of any I could use?\n    submitted by    /u/FaDe_Flamez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7cvm9/tunneling_services_that_support_tk_domains/",
          "publishedOn": "2022-11-28T23:46:19.000Z",
          "wordCount": 17360,
          "title": "tunneling services that support .tk domains?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7atrk/is_there_an_easy_way_to_use_owntracks_in_docker/",
          "author": null,
          "description": "Hi all, I'm trying to use OwnTracks with just two devices, so a large setup doesn't matter. I don't have HomeAssistant and would rather not install it just for this. Looking around the web it seems that there's a general consensus that OT servers are rather difficult to set up, but is there something relatively easy for a barebones setup? Any help appreciated!\n Thanks!\n    submitted by    /u/1v605v4f  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7atrk/is_there_an_easy_way_to_use_owntracks_in_docker/",
          "publishedOn": "2022-11-28T22:29:04.000Z",
          "wordCount": 17695,
          "title": "Is there an easy way to use OwnTracks in docker without HomeAssistant?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z7aqv4/is_kubernetes_good_single_server/",
          "author": null,
          "description": "Dear all that read this,\n I’m new in this self-hosting game, I’ve been watching this sub and looking into self hosting myself for quite some time but haven’t been able to for money reasons.\n I want to self host for multiple reasons. First reason, chalenge, i don’t have much infra/system/server/network experience, i have a beginning diploma but I don’t have the school smarts to continue. Second reason, fun, I like tech, always have and I love having these kind of projects. Third, privacy, in my tech journey I’ve discovered how messed up compagnies handle your data and i don’t like it. Fourth and important one for this post, I kind of want to put this in my resume somehow, might even be a part of my resume, or even could be the full resume if I can somehow.\n So, my actual question is : since i want my self hosting on my resume, and i know that in entreprise level hosting, they mostly use Kubernetes and not docker (wich i am currently using but can change that, I’m not toi far yet) should I and can I use Kubernetes on my main and only server as a server with no Kubernetes clients attached to it, I might and probably will attach more servers to it in the future but for now is it actually doable and is it worth it ? I could also make multiple VMs in my main server and cluster those together but i know that doesn’t go too well with the Kubernetes philosophy so not too sure what to think about that. Anyway, I’m waiting on all of your opinions to see what i can/should do, thanks !\n    submitted by    /u/Luckeysthebest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z7aqv4/is_kubernetes_good_single_server/",
          "publishedOn": "2022-11-28T22:26:06.000Z",
          "wordCount": 17222,
          "title": "Is Kubernetes good single server ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z79trv/any_selfhosted_service_similar_to_nearpod_for/",
          "author": null,
          "description": "submitted by    /u/storyteller-here  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z79trv/any_selfhosted_service_similar_to_nearpod_for/",
          "publishedOn": "2022-11-28T21:52:59.000Z",
          "wordCount": 16081,
          "title": "Any self-hosted service similar to NearPod for interactive learning and teaching?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z79rmj/looking_to_install_a_nas_on_my_raspberry_pi/",
          "author": null,
          "description": "Hi, I recently installed adguard on my raspberry pi in order to block ads on my home network. \n I would now like to experiment with self-hosting and to create a NAS server with my raspberry pi, would it still be possible to install it alongside adguard or do I need to purchase another raspberry pi for NAS purposes? I have already 1tb ssd drive by the way.\n Apologies if it sounds like a silly question :-) and thanks in advance frens\n    submitted by    /u/trempao  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z79rmj/looking_to_install_a_nas_on_my_raspberry_pi/",
          "publishedOn": "2022-11-28T21:50:52.000Z",
          "wordCount": 18027,
          "title": "Looking to install a NAS on my Raspberry pi alongside adguardhome",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z782wv/help_with_linux_and_mono_hijacking_default_command/",
          "author": null,
          "description": "Hi i hope this question is ok to ask here.\n On my homeserver i'm running an Ubuntu 18.04 VM on which i'm running a slightly old C# console application that i wrote myself. It is made in .NET Framework 4.7.2 so it needs an application called Mono to run. In case anyone doesn't know, Mono is a conversion layer to run .NET Framework applications on Linux.\n Now on the same VM i'm trying to run another console application i wrote, but this one is written in .NET 6. This version of .NET does not need mono anymore, so my exe should be able to run natively (as long as i have the .NET 6 packages installed which i do). However Mono has hijacked my './' command so now when i try to run the .NET 6 exe i get a mono error.\n What i want to achieve is to be able to run the .NET 6 normally, and explicitly use the 'mono' command when i want to run older .NET framework exe's. I don't want it to run mono when i use the './' command. How can i achieve this?\n    submitted by    /u/YourNightmar31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z782wv/help_with_linux_and_mono_hijacking_default_command/",
          "publishedOn": "2022-11-28T20:50:26.000Z",
          "wordCount": 16739,
          "title": "Help with Linux and Mono hijacking default './' command.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z77mwq/simplex_messaging_protocol_server_v40_with_basic/",
          "author": null,
          "description": "https://github.com/simplex-chat/simplexmq/releases/tag/v4.0.0\n The new server version is a major update with the support for basic client authentication - previously all servers were public, now you can deploy your private servers (or change the configuration of the ones that are already deployed), so that only you and your friends can use them to receive the messages, and any other contacts will only be able to send the messages, as the invitation links you share with them in SimpleX Chat do not include server password.\n The latest version v4.3-beta of SimpleX Chat apps also includes server testing and sharing/adding servers via QR code, but the server authentication.\n We have also prepared a detailed guide about self-hosting the SimpleX messaging servers.\n SimpleX Platform\n SimpleX is the first and afaik the only communication platform that has no user profile identifiers of any kind - not even random numbers, unlike Signal, Matrix, Session, Briar, Jami, Cwtch, etc.\n Instead of user identifiers it uses temporary pairwise connection identifiers and anonymous credentials, allowing the servers to asynchronously deliver messages without having knowledge about how many users are there and how they are connected on the protocol level (some transport-level and timing correlation is possible, of course, and there will be further improvements to mitigate it).\n The security of SimpleX platform was recently assessed by Trail of Bits - see the announcement.\n    submitted by    /u/epoberezkin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z77mwq/simplex_messaging_protocol_server_v40_with_basic/",
          "publishedOn": "2022-11-28T20:34:19.000Z",
          "wordCount": 17196,
          "title": "SimpleX Messaging Protocol server – v4.0 with basic authentication is released and other updates",
          "imageUrl": "https://external-preview.redd.it/PJjQYyjvNtWkdWN02vZ98Fub5XGwFrqNDQFfPpkrBpQ.jpg?auto=webp&s=89eaebba2aa591c6491a5c573efa86487a4a05c0"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z752v2/does_anyone_have_a_parsec_relay_for_remote_access/",
          "author": null,
          "description": "I'm looking to get away from teamviewer to a selfhosted remote access solution for family IT support. I know, I'm late to the party.\n I played with Parsec and was really impressed with the smoothness of the remote feed. Curious if folks selfhost their own relay server and use Parsec for a similar use case?\n    submitted by    /u/whiteytighties  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z752v2/does_anyone_have_a_parsec_relay_for_remote_access/",
          "publishedOn": "2022-11-28T19:01:47.000Z",
          "wordCount": 16936,
          "title": "Does anyone have a parsec relay for remote access?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z70q04/looking_for_a_picture_hosting_app_similar_to/",
          "author": null,
          "description": "So I’m trying to get away from Instagram but I’d still like a way to share my photos.\n Is there any self hosted program that I could upload photos to and have it display them on a front end? \n Something like Fireshare, but instead of videos have it be pictures :-)\n    submitted by    /u/Neldonado  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z70q04/looking_for_a_picture_hosting_app_similar_to/",
          "publishedOn": "2022-11-28T16:20:49.000Z",
          "wordCount": 17008,
          "title": "Looking for a picture hosting app similar to Instagram (kinda?)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z70gfx/uptime_monitoring_1000_urls/",
          "author": null,
          "description": "Like https://www.reddit.com/r/selfhosted/comments/w1qo9p/what_is_the_best_self_hosted_uptime_monitor_to/ I'm browsing the internet for a good uptime monitoring tool. We've used Kuma in the past, but it's unable to handle more than 300 urls. We're currently using our self made tool, which checks realtime http status and SSL validity (and a few client specific monitoring). \n What we'd like to have:\n - Capacity voor atleast around 1000 urls\n - Uptime monitoring (history isn't needed, as long as we know a recent (5~10 minute difference, uptime status)\n - Current status page (sites that are down have to be visible in one view)\n - SSL expiry check (list those who will expire within the next 21 days)\n - optional: Notifications in teams (this is something we currently don't have but would really like)\n - optional: Notifications via mail\n We've tried zabbix, kuma, upptime and one self developed sollution, but none seem to fully qualify. I've been scrolling github for about an hour, and figured it might be time to ask for some help, so here I am.. \n I would love to hear some of your suggestions!\n    submitted by    /u/Professional_Bar_688  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z70gfx/uptime_monitoring_1000_urls/",
          "publishedOn": "2022-11-28T16:10:35.000Z",
          "wordCount": 19317,
          "title": "Uptime monitoring (~1000 urls)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6zrlu/authentik_anonymous_ldap_search/",
          "author": null,
          "description": "I’ve spent the last few days trying to configure the LDAP authentication features in Authentik. After a lot of research and trial/error I’ve finally got the LDAP Outpost up and running and responding the ldapsearch queries from the terminal. I’m stuck now trying to figure out if there’s a way to configure the LDAP outpost to respond to anonymous queries, for example Mealie doesn’t have configuration options for a bind user.\n As far as I understand in a general LDAP implementation this shouldn’t be a problem as LDAP queries can either be submitted anonymously or as an unauthenticated user. What I can’t figure out is whether or not Authentik supports this and if it does how it should be configured in the outpost. I’ve been through all the Authentik documentation and every community guide I could find for integrating with other services that use LDAP but I’ve had no luck so far.\n    submitted by    /u/Blackhawk706  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6zrlu/authentik_anonymous_ldap_search/",
          "publishedOn": "2022-11-28T15:43:02.000Z",
          "wordCount": 16327,
          "title": "Authentik Anonymous LDAP Search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6zqvo/ip_triggering_on_opnsense_router/",
          "author": null,
          "description": "I have two routers; my ISP provided router, which handles my IoT and families devices on subnet 192.168.0.0, and my OPNSense router sitting behind my IPS router, which handles my server and personal devices on subnet 192.168.1.0.\n When my laptop is connected to the internet, it connects to my home server something like this:Laptop => https://nextcloud.foo.bar (123.45.67.89) => ISP router => OPNSense router => home server\n This configuration does not work when I am connected to my OPNSense router because my ISP router believes the connection is a loopback (Or at least, that's what I can infer). For this reason I am not able to connect to my home server without adding a line to my host file for every subdomain on my home server, which is a pain.\n TL;DR I would like to configure OPNSense to forward all connections which are directed towards my public IP, say either https://nextcloud.foo.bar or 123.45.67.89, towards my server's local IP instead, say 192.168.1.2. Basically, I'm trying to MitM myself. DNS entries will not work because my devices use a secure DNS.\n I was hoping to discover a setting similar to port triggers, except for IPs instead of ports.\n    submitted by    /u/CringeXP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6zqvo/ip_triggering_on_opnsense_router/",
          "publishedOn": "2022-11-28T15:42:13.000Z",
          "wordCount": 17274,
          "title": "IP triggering on OPNSense router",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6zhrt/scrutiny_help/",
          "author": null,
          "description": "hey everyone! \n im trying to install scrutiny on my dockerized ubuntu server \n i keep getting this wierd error: :panic: failed to check influxdb setup status - parse \"://:\": missing protocol scheme\"\n i couldn't find enything regarding this error and nothing in general from recent years. \n have any of you encountered this error?\n    submitted by    /u/amitsh_f456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6zhrt/scrutiny_help/",
          "publishedOn": "2022-11-28T15:32:11.000Z",
          "wordCount": 16115,
          "title": "scrutiny help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6zdqm/issue_with_pleroma_federation_issues/",
          "author": null,
          "description": "Hi all,\n Recently set up my own personal Pleroma instance as I wanted to run my own single user instance. I was able to install Pleroma on the VPS and it runs without errors. When trying to move & follow others on other servers, it can show their profile but not their posts and when trying to follow, the follow functionality doesn't work.\n I also tried to find my own profile on my new Pleroma instance but other instances can't seem to find my instance at all saying it doesn't exist. I also tried to register my instance on instances.social as a test and it errors out saying that there's no Mastodon or Pleroma instance found on my hostname.\n Federation seems to be enabled but I'm not sure if it's actually working. I initially thought that running through Cloudflare was an issue but I disabled the proxy and that didn't fix the issue...\n I'm a Pleroma/Mastodon admin newbie and I'm not sure if I'm missing anything here. Anything assistance is much appreciated.\n    submitted by    /u/deltatux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6zdqm/issue_with_pleroma_federation_issues/",
          "publishedOn": "2022-11-28T15:27:48.000Z",
          "wordCount": 17034,
          "title": "Issue with Pleroma - Federation Issues?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6y3gl/surveillance_station/",
          "author": null,
          "description": "What is the best surveillance station software you can host yourself for free whit an unlimited amount of cameras to use.\n    submitted by    /u/PrimeskyLP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6y3gl/surveillance_station/",
          "publishedOn": "2022-11-28T14:33:19.000Z",
          "wordCount": 16181,
          "title": "surveillance station",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6xxxu/combining_wireguardbased_p2p_network_with_private/",
          "author": null,
          "description": "submitted by    /u/wiretrustee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6xxxu/combining_wireguardbased_p2p_network_with_private/",
          "publishedOn": "2022-11-28T14:26:51.000Z",
          "wordCount": 18023,
          "title": "Combining WireGuard®-based P2P network with private DNS management",
          "imageUrl": "https://external-preview.redd.it/CeQfEDc3rt6-ieRl_J2jrdkXU6iyDZOZPU2rJT66M70.png?format=pjpg&auto=webp&s=6e0273b2cc17e29ebd083a12b37c8a2f298bef38"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6uvad/im_looking_for_selfhosted_alternative_for_notion/",
          "author": null,
          "description": "I have checked this post here in this sub:\n https://www.reddit.com/r/selfhosted/comments/gx538n/self_hosted_notion_alternative/\n But i'm looking for more options.\n Also, I'm looking for something that able to work on Windows, since it's my main OS rn. Maybe on docker is okay, ig.\n Thanks in advance.\n --\n Update: check my comment\n    submitted by    /u/m-primo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6uvad/im_looking_for_selfhosted_alternative_for_notion/",
          "publishedOn": "2022-11-28T12:07:57.000Z",
          "wordCount": 18246,
          "title": "I'm looking for self-hosted alternative for Notion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6t71u/the_simplest_way_to_run_your_own_heroku_on/",
          "author": null,
          "description": "submitted by    /u/2containers1cpu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6t71u/the_simplest_way_to_run_your_own_heroku_on/",
          "publishedOn": "2022-11-28T10:33:37.000Z",
          "wordCount": 7047,
          "title": "The simplest way to run your own Heroku on Kubernetes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6smma/keepass_self_hosting_strategy/",
          "author": null,
          "description": "I've been using keepass2 for a while and it's a love hate thing. Installing the app, putting the addons in, using a key file so I can store the database in the cloud (I know this isn't recommended but it needs to be usable). Setting it up on the phone, database backups, ssh key addons\n What is your work flow ? Is there a way to make it easily manageable ?\n I've considered moving to bitwarden (and keepassxc), and I've heard great things about pass. What is the best way to self host passwords in a consistent, reliable, backed up and cloud hosted way ?\n Cheers\n    submitted by    /u/simonmcnair  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6smma/keepass_self_hosting_strategy/",
          "publishedOn": "2022-11-28T10:00:27.000Z",
          "wordCount": 22750,
          "title": "keepass self hosting strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6r9x1/webui_for_whisper_an_awesome_audio_transcription/",
          "author": null,
          "description": "Hey!\n I built a web-ui for OpenAI's Whisper. The features available in this web-ui are:\n  \nRecord and transcribe audio right from your browser. \n Upload any media file (video, audio) in any format and transcribe it. \n Option to cut audio to X seconds before transcription. \n Option to disable file uploads. \n \n Select input audio language \n Translate input audio transcription to english (any language to english). \n Download .srt subtitle file generated from audio. \n Choose the Whisper model you want to use (tiny, base, small...) \n Supports many languages (and more can be added, just open an issue)\n Lightweight and beautiful UI. \n Self-hosted. No 3rd parties. \n Docker compose for easy self-hosting \n Privacy respecting: - All happens locally. No third parties involved. \n Audio files are deleted immediately after processing. \n \n Backend written in Go \n Frontend written with Svelte and Tailwind CSS. \n Uses C++ whisper version from whisper.cpp. \n You don't need a GPU, uses CPU. \n No need for complex installations.\n \n  \nYou can find the repo with more details here: https://codeberg.org/pluja/web-whisper\n Screenshots are available here: https://codeberg.org/pluja/web-whisper#screenshots\n Edit: added a Github issue tracker: https://github.com/pluja/web-whisper\n    submitted by    /u/hoiru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6r9x1/webui_for_whisper_an_awesome_audio_transcription/",
          "publishedOn": "2022-11-28T08:38:24.000Z",
          "wordCount": 18910,
          "title": "Web-UI for Whisper, an awesome audio transcription AI. Easy to self-host.",
          "imageUrl": "https://external-preview.redd.it/TVEfcJVkZcDsG4jkzKigR9F1VoUSLhcGDh16VRR0bss.jpg?auto=webp&s=cd8cda23d7ae93bd1f933f4d6d0c42f2b7dc65d4"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6r4ux/recommendation_for_getting_things_done_task/",
          "author": null,
          "description": "Looking for essentially To-doist Pro (https://todoist.com/pricing) but FOSS self-hosted.\n Features I'm looking for\n  \nAdd one-off tasks\n Set up recurring tasks\n Have reminders or some kind of \"jobs to do today\" mobile page or similar\n Two users so my other half can help\n Can run via Docker as easily as possible i.e. there are pre-built images on a registry and all I gotta do is run them, have found a few but I have to compile my own images or clone a github and faff and fiddle - and that's a level of skill & concentration I can't manage :(\n  \nI have add and I humungously struggle with starting and completing tasks but I have worked in IT for decades and when I had a helpdesk ticket I could always GTD. So hoping something similar can help my private life.\n It doesn't have to be a specific task management / to-do software, it could be a FOSS Service Desk / Ticket System which also has a Task management module, for example.\n    submitted by    /u/iamdadmin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6r4ux/recommendation_for_getting_things_done_task/",
          "publishedOn": "2022-11-28T08:29:58.000Z",
          "wordCount": 18622,
          "title": "Recommendation for getting things done / task / recurring task / reminder software",
          "imageUrl": "https://external-preview.redd.it/vaqoUW3Hp5g6g-cyn5scC1iTQX3yXeRJwWlXfwje4T0.jpg?auto=webp&s=95a7f2d428c748032b32e8c435abc7af7b08a47a"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6i5dn/do_you_even_use_the_synology_apps/",
          "author": null,
          "description": "I recently acquired a second-hand Synology DS218 and am trying to find out how best to use it. I see a lot of people on here mentioning that they do indeed have some kind of Synology DS, but never mention any of the apps provided by Synology.\n For the following intention, do you even boot DSM (and what do you do next to, e.g., install and then run photoprism/lychee/librephoto or nextcloud or jellyfin)?\n What I'd like to set up, is 1. a file server to share with my family and maybe a few friends, 2. a photo server where my family members can all upload their images and then share specific albums or pictures with specific outside people, restricting unintended people from access, 3. syncing our contact lists, so I don't need to register contacts my wife has already added, 4. aggregating all the digital music from my family members, 5. shared task management and \"project\" organizing, 6. co-journaling 7. a postgresql db (that should be higher up there...) 8.9.10.11. etc.\n I am looking into port forwarding to make all of this accessible from the outside, but I've already found out this isn't trivial at all. I'll get there, I'm confident.\n Where do I start? Install software like nextcloud and docker through DSM and continue from there or do you circumvent DSM completely and ... ? Well, what, actually? or do you use any of the Synology software, and if yes, what are your experiences?\n I am not a programmer, but know how to RTFM and I am pretty patient and happy to learn.\n    submitted by    /u/MolecularMacMansion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6i5dn/do_you_even_use_the_synology_apps/",
          "publishedOn": "2022-11-28T00:51:22.000Z",
          "wordCount": 16586,
          "title": "Do you even use the Synology apps?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6g33b/emby_premiere_vs_jellyfin/",
          "author": null,
          "description": "Given that Emby Premiere is on sale right now, I wanted to learn if there were major benefits between Emby Premiere and Jellyfin, since I know that Plex is getting questionable with its privacy and practices.\n I’ve seen the table comparing features, but wanted to know if anyone had any thoughts on the real world differences between them. I currently run Jellyfin on my server right now, and it’s slow on library indexing and it’s mobile clients (including offline downloads) just lacks polish. Any thoughts would be great!\n    submitted by    /u/redditnetizen_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6g33b/emby_premiere_vs_jellyfin/",
          "publishedOn": "2022-11-27T23:22:09.000Z",
          "wordCount": 17226,
          "title": "Emby Premiere vs Jellyfin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6fqxu/android_app_for_self_hosted_voice_assistants/",
          "author": null,
          "description": "Hi,\n I'm looking for a voice assistant on my Android phone (running GrapheneOS) to fill the void of Google Assistant. From my cursory research, I have found Mycroft and Leon, but both aren't very well supported for an Android application.\n Ideally, I'd like to host the assistant as a docker container on my RPi 4 and have the android app use that to do all the processing. Is there such a solution available today?\n Thanks!\n    submitted by    /u/seriouslyfun95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6fqxu/android_app_for_self_hosted_voice_assistants/",
          "publishedOn": "2022-11-27T23:08:33.000Z",
          "wordCount": 16238,
          "title": "Android app for self hosted voice assistants?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6dt56/best_setup_method/",
          "author": null,
          "description": "I am making alot of improvements to my self hosted server, and moving it to its own dedicated computer. It has 16 Gb of ram, a 128 ssd, and a 4 Tb hard drive. I want to have multiple services running on it like jellyfin, smb shares, deluge, etc. What do you think is the best way to do this? I know proxmox might be a good way, due to the fact that I want different ip addresses for all these, but any ideas are welcome. Thank you!\n    submitted by    /u/Larsenic13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6dt56/best_setup_method/",
          "publishedOn": "2022-11-27T21:53:13.000Z",
          "wordCount": 16285,
          "title": "Best setup method",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6dg8y/qbittorrentvpn_docker_container_giving_me_this/",
          "author": null,
          "description": "Here is my config:\n --- version: \"3\" services: qbittorrentvpn: image: trigus42/qbittorrentvpn container_name: qbittorrentvpn privileged: true environment: # - VPN_USERNAME= # - VPN_PASSWORD= - PUID=0 #optional - PGID=0 #optional - WEBUI_PORT_ENV=8991 #optional. - INCOMING_PORT_ENV=8999 #optional - VPN_ENABLED=yes - VPN_TYPE=wireguard - LAN_NETWORK=192.168.1.0/24 - DISABLE_IPV6=0 - NAME_SERVERS=1.1.1.1,1.0.0.1 ports: - 8991:8080 - 8999:8999 - 8999:8999/udp volumes: - /mnt/main_pool/qbittorrentvpn/config:/config - /mnt/main_pool/qbittorrentvpn/downloads:/downloads # restart: unless-stopped \n Inside of my config folder I have my wireguard folder which then has my simple wireguard vpn config file to connect to the VPN. I don't really like openvpn so thats why I'm using wireguard instead. I hav…",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6dg8y/qbittorrentvpn_docker_container_giving_me_this/",
          "publishedOn": "2022-11-27T21:39:36.000Z",
          "wordCount": 16989,
          "title": "qbittorrentvpn docker container giving me this same error no matter what I try..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6d3ka/liveask_is_a_simple_free_and_opensource_solution/",
          "author": null,
          "description": "submitted by    /u/Extrawurst-Games  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6d3ka/liveask_is_a_simple_free_and_opensource_solution/",
          "publishedOn": "2022-11-27T21:25:46.000Z",
          "wordCount": 16120,
          "title": "Live-Ask is a simple, free and open-source solution for realtime live event Q&As",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6b2h2/one_time_login_with_authelia_question/",
          "author": null,
          "description": "I have authelia setup with haproxy via pfsense. Everything works fine except, I'll just jellyfin for this example, I'll login with authelia, then I need to login to jellyfin.\n I have them both use the same ldap server with the same account. Is there a way for me to login with authelia and it automatically login to jellyfin after that?\n    submitted by    /u/Zackptg5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6b2h2/one_time_login_with_authelia_question/",
          "publishedOn": "2022-11-27T20:05:58.000Z",
          "wordCount": 16050,
          "title": "One time login with Authelia Question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6b0jr/codeserver_not_using_htpps_and_thus_not_loading/",
          "author": null,
          "description": "I am trying to open a png file through code server but I have been doing some reading and people mention that it isn't loading because I'm using HTTP. How can I get code-server to use HTTPS? \n ​\n I have no idea about encryption or anything like that as I usually do everything through wire guard and nothing is directly exposed to the internet.\n https://preview.redd.it/yyo1psk5vj2a1.png?width=2208&format=png&auto=webp&s=c1983d9d17989fbcb4ad7ceae345bd72a99e5f47\n    submitted by    /u/mgr1397  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6b0jr/codeserver_not_using_htpps_and_thus_not_loading/",
          "publishedOn": "2022-11-27T20:03:55.000Z",
          "wordCount": 17527,
          "title": "Code-Server not using HTPPS and thus not loading images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z6aalp/is_synology_officedrivecalendar_a_better/",
          "author": null,
          "description": "I've been running Nextcloud for about a year and have been frustrated by its instability and performance. I've tried all the various tweaks I've read about, but nothing seems to make it much better. I recently picked up a Synology NAS and am wondering how the overall experience is with their Office/Calendar/Drive apps? I have been testing them out and already I'm finding missing features compared to Nextcloud. That said, they appear quite polished. Has anyone made this jump or have any experiences to share?\n    submitted by    /u/drunkenjack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z6aalp/is_synology_officedrivecalendar_a_better/",
          "publishedOn": "2022-11-27T19:35:35.000Z",
          "wordCount": 17383,
          "title": "Is Synology Office/Drive/Calendar a better alternative to Nextcloud?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z69wk0/running_multiple_services_on_one_server_possible/",
          "author": null,
          "description": "I'm having trouble adding a Jellyfin docker to my server, and I'm hoping someone can point me in the right direction.\n ​\n I have a NextCloud instance on my old laptop (the AIO version, in Docker) with an external URL. I set up port forwarding and a static IP for it. I've now set up a Jellyfin instance (also docker, this time with docker-compose) on the same device, and I want to be able to access it, but only within the network. The problem is that I can't get to it from other devices on the network. I tried 196.168... and 196.168...:8096 or 8920. \n On Firefox, I get \"Secure Connection Failed\" for all versions. It keeps redirecting to https, though. I don't know if http would work, but I tried from the Jellyfin android app as well and all its \"candidates\" (including http) failed. I assume that it's because of some conflict with the NextCloud instance, but I don't really know how to even debug that.\n    submitted by    /u/mymonstersprotectme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z69wk0/running_multiple_services_on_one_server_possible/",
          "publishedOn": "2022-11-27T19:20:16.000Z",
          "wordCount": 16717,
          "title": "Running multiple services on one server - possible conflict",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z687om/homelab_bit_the_dust/",
          "author": null,
          "description": "Arrived home to a displeasing analog clock sound and was confused. Till I went to my rack and heard a disc suffering. Logged in to see what was happening and a filesystem was missing, a disc too. Check documentation to see what disc had failed and what was in it and saw it was no valuable data and though I could just buy a new HDD and copy over the backup. Went to check other applications on the same machine and realized docker was running but not the containers. The disc where I mount all my docker volumes and keep the docker compose files is gone too. Backup discs also gone. Ups logs show no power failure. 4hddw decided to die on me the same day.\n Let's hope I can find a nice deal tomorrow on HDD or I'll be taking a break from hosting my stuff at home. \n Check you backups and smart status. And backup at least your config elsewhere.\n I'm down and feel pretty dumb right now.\n    submitted by    /u/mancostation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z687om/homelab_bit_the_dust/",
          "publishedOn": "2022-11-27T18:14:07.000Z",
          "wordCount": 15957,
          "title": "Homelab bit the dust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z67yh1/synapse_matrix_integration_managerfederation_issue/",
          "author": null,
          "description": "Hello!\n I have been trying to set up Synapse Matrix server and have been having an issue with its Integration Manager. I was wondering if someone with similar setup could help me here.\n My setup is, Synapse in Docker, using element web in docker and windows Element client in Traefik instance.\n The point is to have a private server, non federated but using Element's integration manager. But for these tests I tried to run in federated anyway but it still did not work.\n We can connect to Synapse just fine, chat with each other, send files etc. Location also works, only Integration manager fails to connect. Using Federation tester at: https://federationtester.matrix.org passes all green, no errors. Using Dimension's widget shows there is a problem: https://prnt.sc/YWtVFDlrw0Th\n I have followed…",
          "link": "https://www.reddit.com/r/selfhosted/comments/z67yh1/synapse_matrix_integration_managerfederation_issue/",
          "publishedOn": "2022-11-27T18:03:54.000Z",
          "wordCount": 16916,
          "title": "Synapse Matrix Integration Manager/Federation issue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z67pw2/email_server/",
          "author": null,
          "description": "If for instance, my email server were to be offline and someone sends me a message. Is it possible to set up a email cache on a VPS service like linode to actually receive the email so the receiver doesn't get a undeliverable ping and email gets to my server once it's online?\n    submitted by    /u/Interesting-Yak9118  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z67pw2/email_server/",
          "publishedOn": "2022-11-27T17:54:57.000Z",
          "wordCount": 15744,
          "title": "Email server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z66yo9/mynixos_create_and_share_nix_and_nixos/",
          "author": null,
          "description": "Hello r/selfhosted!\n Posting about MyNixOS here for the first time. This is a tool I've been working on to help build and share Nix and NixOS configurations. Nix is a powerful tool to deploy software in a reproducible way, and with NixOS you can control your whole operating system through a declarative configuration.\n Starting out with Nix was exciting, but it definitely had a challenging learning curve. This made me start building a website focused on making it easier to create and share Nix flakes, which are the core unit of software deployment in Nix.\n Using the website, you can create flakes without knowing the Nix configuration language, as the necessary Nix files are generated for you. I hope this can be useful for those interested in trying out Nix for self-hosting. I'm currently us…",
          "link": "https://www.reddit.com/r/selfhosted/comments/z66yo9/mynixos_create_and_share_nix_and_nixos/",
          "publishedOn": "2022-11-27T17:25:41.000Z",
          "wordCount": 17693,
          "title": "MyNixOS - Create and share Nix and NixOS configurations",
          "imageUrl": "https://external-preview.redd.it/9_QVHEqbHSpi-2kHwhO1wrIYPlDZttU-nBj899VjCKs.jpg?auto=webp&s=e3ca97e4d05ed029638496831fc876ed4e68e55f"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z66ugw/benotes_an_opensource_app_for_boomarks_and_notes/",
          "author": null,
          "description": "​\n https://preview.redd.it/4di2g2m81j2a1.png?width=2220&format=png&auto=webp&s=a1fd65303ace05c090477312787578e19c1abd83\n An open-source, self-hosted web app that allows you save boomarks and posts side by side.\n https://github.com/fr0tt/benotes\n https://benotes.org/\n Works on any device with a browser and can be installed (as a PWA) on both mobile and desktop devices.\n I'm working on it for quite some time now but it seemed like the appropriate place and time to share it with. Let me know what you think about it ;)\n    submitted by    /u/TheEmp1re  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z66ugw/benotes_an_opensource_app_for_boomarks_and_notes/",
          "publishedOn": "2022-11-27T17:21:13.000Z",
          "wordCount": 16407,
          "title": "Benotes - An open-source app for boomarks and notes",
          "imageUrl": "https://external-preview.redd.it/T-61HwmQZzC3bRp0VBZpAidGrwwe8FSFkZsCa60-O8o.png?auto=webp&s=32c26b5d5a85cce5d54beda9dffe218c499d0785"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z66sib/im_stuck_with_low_home_upload_speeds_is_there_a/",
          "author": null,
          "description": "I'm setting up a media server with Jellyfin, which will be fine while I'm at home. However, when I'm traveling (or want to provide access to someone not on my lan), I'd like to move media up to a server with high upload (but not sufficient storage for my whole library). Any ideas about what would be the simplest interface to accomplish this?\n    submitted by    /u/ashooner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z66sib/im_stuck_with_low_home_upload_speeds_is_there_a/",
          "publishedOn": "2022-11-27T17:19:06.000Z",
          "wordCount": 15886,
          "title": "I'm stuck with low home upload speeds. Is there a tool to sync my media to a faster server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z66b1f/anything_self_hosted_like_paperlessio/",
          "author": null,
          "description": "Is there any self hosted solution like paperless.io?\n https://www.paperless.io/\n A fully integrated suite to build scalable and custom document workflows - No-Code Editor - Workflow Automation - E-Signature - Integrations & API\n Would be nice if it could be connected to EspoCRM for creating document Workflows with customer.\n    submitted by    /u/SwimmingSubmarine23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z66b1f/anything_self_hosted_like_paperlessio/",
          "publishedOn": "2022-11-27T17:00:41.000Z",
          "wordCount": 16677,
          "title": "Anything self hosted like paperless.io?",
          "imageUrl": "https://external-preview.redd.it/xTZ9K65INwVnUn08_zbTAFTTuAgOxEk_HzpbVBk7mEI.jpg?auto=webp&s=7cdb1377a0665d1eddfd7d47baa8a3ec252003c7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z65gjj/self_hosting_a_vpn_server_what_defines_speed/",
          "author": null,
          "description": "Server Speedtest: Download : 833mbps Upload: 36 mbps\n From not that far away location:\n Without vpn: Download : 122 mbps Upload : 32 mbps\n With vpn: Download: 33mpbs Upload: 26 Mbps \n I’m using pritunl server openvpn ( UDP ) Tried changing encryption but never goes faster.\n Does the upload speed of the server limit the speed of using the vpn?\n    submitted by    /u/BlowIzzy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z65gjj/self_hosting_a_vpn_server_what_defines_speed/",
          "publishedOn": "2022-11-27T16:27:53.000Z",
          "wordCount": 16388,
          "title": "Self hosting a VPN server… what defines speed?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z64sgy/user_group_permissions_for_kanboard_volume/",
          "author": null,
          "description": "This is more a docker question than a selfhosting one but I hope that maybe someone knows this specific docker container so here we are...\n I'm using the docker hub image for Kanboard: https://hub.docker.com/r/kanboard/kanboard\n The issue I'm having is that the data and plugins volume files/folders do get assigned odd user and group permissions on the host. I understand why but I can't find a way to change them.\n Specifics:\n  \nFrom inside the container the nginx:nginx user/group have userid (UID) 100 and groupid (GID) 101.\n On the host UID 100 is assigned to user _apt, GID 101 is assigned to group systemd-journal. \n So this user/group combination is being set for all files / folders from the volumes.\n  \nThings I've tried:\n  \nIt doesn't make a difference if I mount them as volumes or bind the folder.\n There doesn't seem to be a way to pass UID and GID in the docker compose file as environment variables.\n Setting user in the compose file through user: \"${UID}:${GID}\" does change UID/GID of the container root user, not nginx.\n  \nDoes anyone have an idea how to correct the file permissions on the host without building my own docker image?\n    submitted by    /u/biochronox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z64sgy/user_group_permissions_for_kanboard_volume/",
          "publishedOn": "2022-11-27T16:01:26.000Z",
          "wordCount": 16460,
          "title": "user / group permissions for Kanboard volume",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z63jbf/lxc_nginx_proxy_manager_with_different_networks/",
          "author": null,
          "description": "Hello,i recently moved all my homelab on proxmox,i currently have 4 networks,lan 4 vlans,my problem is with npm witch is on my lan,it forwards the ssl connection to the lan machines without a issue,but I can't send to the vlans,i ping the vlan machine from the npm,in my pfsense i currently have only the default allow all( i will setup my fw rules after i figure this out) i aldo have pihole that resolves all the local dns to the npm ip ,is there anything particular that i need to have on npm to forward the request to a host on a different network? I added a second ip on the npm with a ip on the vlan but it still doesn't work,what am i missing? Thanks in advance if someone answers\n    submitted by    /u/t1nk_outside_the_box  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z63jbf/lxc_nginx_proxy_manager_with_different_networks/",
          "publishedOn": "2022-11-27T15:11:30.000Z",
          "wordCount": 16358,
          "title": "lxc nginx proxy manager with different networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z62yrz/selfhosted_schedulers/",
          "author": null,
          "description": "I like the idea of motion very much, and I'd like a scheduler that I can give tasks with deadlines as well as fixed points such as lectures, and have it sort out my schedule automatically, however I am a university student and not in the position to pay £20-40 a month for it, are there any self-hosted alternatives (I have a server for it to run on)\n ​\n Edit: the thing I particularly like about this webapp is the fact that it combines a calendar and to-do list automatically, it tells me what needs to be done but also when to do it\n    submitted by    /u/danielandastro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z62yrz/selfhosted_schedulers/",
          "publishedOn": "2022-11-27T14:47:12.000Z",
          "wordCount": 16900,
          "title": "Self-hosted schedulers?",
          "imageUrl": "https://external-preview.redd.it/yvcNgJF3OsSz1INQOor5wmwNiZdve_e_gNl01dBj6U4.jpg?auto=webp&s=14f441ee2661bc4556e5c5d3bf3c21b8656fc6d1"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5zxa7/very_basic_power_meter_plug/",
          "author": null,
          "description": "I'm looking for a plug that will report the electricity usage, I don't care for any other features but my primary requirements:\n  \n Can be connected to Home Assistant \n Local only (No talking to 3rd party servers, stays within my network)\n  \nFor the second point I can probably block the traffic but I just need to be sure that the plug doesn't stop working just because it can't reach outside. Any suggestions?\n    submitted by    /u/SugarMaendy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5zxa7/very_basic_power_meter_plug/",
          "publishedOn": "2022-11-27T12:21:39.000Z",
          "wordCount": 17384,
          "title": "Very basic power meter plug",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5w7qm/is_plex_pass_worth_it/",
          "author": null,
          "description": "Just built a nas/steaming box and I see plex pass is on sale. Is it worth it in your opinion?\n    submitted by    /u/v-a-g  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5w7qm/is_plex_pass_worth_it/",
          "publishedOn": "2022-11-27T08:52:38.000Z",
          "wordCount": 18614,
          "title": "Is plex pass worth it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5t25k/looking_for_a_markdown_editor_like_hedgedochackmd/",
          "author": null,
          "description": "I like HedgeDoc, but the editor panel is a markdown first with a preview panel. I need a visual WYSIWYG editor because the rest of my team are less technologically-inclined.\n I'm exploring Joplin but it requires Nextcloud, which is an overkill. Obsidian looks nice but their sync feature is a paid service.\n Any recommendations?\n Thanks.\n    submitted by    /u/OfTachosAndNachos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5t25k/looking_for_a_markdown_editor_like_hedgedochackmd/",
          "publishedOn": "2022-11-27T05:48:30.000Z",
          "wordCount": 16176,
          "title": "Looking for a Markdown editor like HedgeDoc/HackMD but with a WYSIWYG-first visual editor",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5o3bc/am_i_able_to_recover_deleted_volumes_done_by/",
          "author": null,
          "description": "I was curious what 'docker volume prune' would prune and so I ran it. Well, it deleted all of my volumes! I've lost all of my configs for my docker containers.\n Is there any way to recover them?\n Not sure if this would help but this is an example of my compose file:\n version: 3.3 services: mosquitto: image: eclipse-mosquitto container_name: mosquitto volumes: - /var/lib/docker/volumes/mosquitto_data/data:/mosquitto/data - /var/lib/docker/volumes/mosquitto_data/log:/mosquitto/log - /var/lib/docker/volumes/mosquitto_data/certs:/mosquitto/config/certs - /var/lib/docker/volumes/mosquitto_data/config:/mosquitto/config ports: - 1883:1883 - 9001:9001 restart: unless-stopped \n It took me months to set up everything so your help is much appreciated!\n    submitted by    /u/Melodic_Walk_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5o3bc/am_i_able_to_recover_deleted_volumes_done_by/",
          "publishedOn": "2022-11-27T01:39:38.000Z",
          "wordCount": 16618,
          "title": "Am I able to recover deleted volumes done by 'docker volume prune'?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5kbvf/location_of_server/",
          "author": null,
          "description": "Is it best to have a server in the basement or the attic/top floor? I am leaning towards attic or top floor. My reasoning is water damage. What do you all think? It's easier to work with gravity than not right? Need a new line? Drill a hole adjacent to the hole on the bottom floor and drop a fish line.\n    submitted by    /u/Interesting-Yak9118  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5kbvf/location_of_server/",
          "publishedOn": "2022-11-26T22:47:48.000Z",
          "wordCount": 16906,
          "title": "Location of server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5iy4a/ltb_a_minipc_or_other_smff_machine_that_can/",
          "author": null,
          "description": "Hey folks,\n I've been thinking of \"upgrading\" to a proper server for some time for my home services. I currently run everything out of an old laptop (4th i7 from 2014 w/ 16GB RAM) and it's fine, but I'd like a more dedicated machine. More specifically, I'd like to do some large-scale network automation exercises, so to run CML2 or GNS3 I would ideally like 128GB of RAM, but 64GB would be a minimum.\n I've found most mini PC's can get up to 16/32, but not as many with 64 or 128. Any good recommendations ahead of Cyber Monday?\n My budget is preferably <$500. I can pull 32GB of DDR4 from my desktop (and upgrade in the process) and I have SSD's/M.2 drives, so I'm not concerned about storage. Thanks!\n Edit: I think I may have found one that might fit my needs - https://www.amazon.com/dp/B09NKQQSQP/ref=emc_b_5_i?th=1\n I'm thinking worst case, if I outgrow it, I can easily turn this thing into a replacement for my Raspberry Pi retro gaming station.\n    submitted by    /u/radakul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5iy4a/ltb_a_minipc_or_other_smff_machine_that_can/",
          "publishedOn": "2022-11-26T21:48:06.000Z",
          "wordCount": 17666,
          "title": "LTB a mini-PC or other SMFF machine that can support up to 128GB RAM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5ittm/need_help_self_hosting_web_shop_nginx_proxy/",
          "author": null,
          "description": "Basically followed the instructions on the Nginx Proxy Manager website and am looking for confirmation for whether or not my self hosted Web Shop on my PC is safe to run and introduce WAN traffic to. Should I direct traffic to port 80 and 443? are there safer ports? Excuse my ignorance if I've mentioned something that doesn't make sense.\n Any Feedback+resources for a total noob who's struggling his ass off would be great!!! I'm looking into utilizing a database to include customer info too if anyone has resources for this and any other tips!!\n    submitted by    /u/byaah919  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5ittm/need_help_self_hosting_web_shop_nginx_proxy/",
          "publishedOn": "2022-11-26T21:43:01.000Z",
          "wordCount": 17016,
          "title": "Need Help Self Hosting Web Shop + Nginx Proxy Manager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5if3i/best_use_of_multiple_ssds_for_vms/",
          "author": null,
          "description": "I have 4 demanding virtual machines. And 4 fast SSDs. \n I see 2 options. \n A- 1 disk dedicated to each VM\n B- 4 disks with RAID0 or any stripping option, pooled together and the pool is used by the 4 VMs. \n Option B makes more sense in terms of storage. \n But in terms of pure performance, which one do you think is better ?\n Edit 1: Additional information: - The 4 VMs are desktops. - 99% tiny files constantly read and written. - each ssd is directly connected in sata to the motherboard. - all ssd are in the 370-450 MB/s speed range (simple hdparm test speed) - I do not want any redundancy. Just max speed.\n    submitted by    /u/GrilledGuru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5if3i/best_use_of_multiple_ssds_for_vms/",
          "publishedOn": "2022-11-26T21:25:55.000Z",
          "wordCount": 17630,
          "title": "Best use of multiple SSDs for VMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5iaik/recommendations_for_file_backup_app/",
          "author": null,
          "description": "So, I need an app or something, that can help me to send files from my phone to my OMV6 NAS server when I'm outside of my house, so with external access. I need an app that I can deploy in docker. NextCloud is an overkill for me. I don't need syncing or anything. I just need when I have a photo or a file that I can tap share on my phone and select that app which is connected to my home NAS.\n For my regular in-house syncing via WiFi I use Foldersync Pro. I just need something for some random single file sending to my server. Any suggestions?\n    submitted by    /u/Nabukodonosor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5iaik/recommendations_for_file_backup_app/",
          "publishedOn": "2022-11-26T21:20:27.000Z",
          "wordCount": 16744,
          "title": "Recommendations for file backup app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5hgwg/using_rclone_as_a_backend_for_kopia/",
          "author": null,
          "description": "Hi guys.\n First of all, I'm just a hobbyist trying new things. I've taught myself the very basics of Debian and Docker, and I'm not a native English speaker. So bear with me if I mention or say silly stuff.\n I was willing to ditch Duplicati as I just had my second corrupt database in a couple of months and I also find it desperately slooooow.\n As I mentioned above, I'm a real noob, so I was looking for a FOSS alternative with a GUI of some sort as CLI is not my cup of tea (I still have to get confortable with it and I don't have much time for this now).\n I decided to try Kopia that has the wind in its sails at the moment. From my beginner's perspective, it isn't as polished as I'd like, but it's fast and powerful. So here I am, after 3 weeks hardly working to understand how to run it, with…",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5hgwg/using_rclone_as_a_backend_for_kopia/",
          "publishedOn": "2022-11-26T20:45:19.000Z",
          "wordCount": 20147,
          "title": "Using RClone as a backend for Kopia.",
          "imageUrl": "https://external-preview.redd.it/aQ9bKocvXwwWnOY2kcCGatOWF7ZaqledfDN1L1sSEqA.jpg?auto=webp&s=da1f5e37cc1e51c8284dc9470c7e3b934120f4a7"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5hel7/recommendations_for_multi_room_speaker_setup_that/",
          "author": null,
          "description": "Hi all, I used to have google minis all over my house but I've become more privacy conscious lately and I did away with them. Is there an open source alternative that achieves the same? I would like to have a speaker in every room that I can connect to via wifi/BT and broadcast my music accessed via Jellyfin to all of them simultaneously. I'm not tied to using Jellyfin but it would be nice.\n I have looked at Sonos speakers but apparently they come with Alexa built in.\n    submitted by    /u/ProximtyCoverageOnly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5hel7/recommendations_for_multi_room_speaker_setup_that/",
          "publishedOn": "2022-11-26T20:42:29.000Z",
          "wordCount": 17226,
          "title": "Recommendations for multi room speaker setup that works without internet access (LAN only, with media from Jellyfin)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5h9x2/how_many_of_you_selfhost_your_own_weather_station/",
          "author": null,
          "description": "submitted by    /u/MzCWzL  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5h9x2/how_many_of_you_selfhost_your_own_weather_station/",
          "publishedOn": "2022-11-26T20:36:54.000Z",
          "wordCount": 18396,
          "title": "How many of you self-host your own weather station? I got mine hooked up to Home Assistant to view & store all info locally",
          "imageUrl": "https://external-preview.redd.it/4VrNnfIypA4snPtLzj6dk0H2LwwxpeEPZ5rnz4_Yp0I.jpg?auto=webp&s=6880f82aee1fba7f9441c746fce0414de4418905"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5h70t/selfhost_books_and_audiobooks_from_windows/",
          "author": null,
          "description": "Hello! \n I'm sorry if this is a silly question but after perusing the \"about\", the wiki and searching through here I'm not sure exactly what to search for what I want. \n I currently run a Plex Media server and use it for movie / tv. I can download stuff to my devices, stream, etc. \n I would like to create the same thing for ebooks but more importantly audiobooks. I would like to run it from Windows. It seems most things around here run on Linux and that is something I'm not comfortable with unfortunately. Any thoughts or am I asking for a unicorn? \n Thanks!\n    submitted by    /u/WinterInWinnipeg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5h70t/selfhost_books_and_audiobooks_from_windows/",
          "publishedOn": "2022-11-26T20:33:30.000Z",
          "wordCount": 18198,
          "title": "Selfhost books and audiobooks from Windows",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5en3k/selfhosted_eyecandy/",
          "author": null,
          "description": "I've been running Geiss and AVS the last couple of days for a nice little WinAmp throwback and it got me to thinking. \n Are there any selfhosted eye-candy type of apps out there? Geiss in a browser window, screensaver type stuff, or just general cute/interesting animations that can be accessed from systems/devices on the network?\n I can think of many different ways to accomplish this and I may just end up making something myself. However, I'd love to see what's out there first! \n Thanks for any recommendations, you all have a great weekend! I'll just be here jamming out to 90s music in WinAmp.. the way it was intended by everyone except Lars. IYKYK.\n    submitted by    /u/xantheybelmont  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5en3k/selfhosted_eyecandy/",
          "publishedOn": "2022-11-26T18:42:40.000Z",
          "wordCount": 16760,
          "title": "Selfhosted eye-candy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5dgkj/problem_registering_logging_into_firefly_iii_with/",
          "author": null,
          "description": "I am having a problem registering an initial username and password in my newly installed Firefly III in Docker. It does nothing when I click on \"Register\" button. Please help. I know someone should have had the same problem somewhere. Thank you in advance.\n    submitted by    /u/Superdarius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5dgkj/problem_registering_logging_into_firefly_iii_with/",
          "publishedOn": "2022-11-26T17:52:42.000Z",
          "wordCount": 16663,
          "title": "Problem registering/ logging into Firefly III with first run",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5cxig/taking_first_steps_towards_selfhosting_would/",
          "author": null,
          "description": "I have been looking to selfhost numerous things. I picked up a Beelink SEi12 yesterday for $350, comes with 16gb of ram and 500gb storage.\n I currently use my PC to serve Plex to my family, but am looking to move that to the Beelink (I got the SEi12 instead of a Ryzen box to take advantage of QuickSync). I'm also looking to host my own Bitwarden, Lightning wallet, DNS, usenet, cloud storage... basically anything I can.\n I use 3.5\" HDDs to store video and large files. Obviously those will not fit inside the little Beelink. Whats the best solution for housing HDDs? Would a DS220j work? Or something similar?\n TLDR; setting up first home server. Best way to attach storage (NAS? Just external drives by USB?) to something like a Beelink SEi12? Appreciate any advice!\n    submitted by    /u/dirtsmurf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5cxig/taking_first_steps_towards_selfhosting_would/",
          "publishedOn": "2022-11-26T17:30:01.000Z",
          "wordCount": 17426,
          "title": "Taking first steps towards self-hosting, would appreciate feedback/assistance!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5cara/manage_users_selfhost_ldap_or_3rd_party/",
          "author": null,
          "description": "Hi,\n I have now a handful of users and I'm looking for a directory-based solution that would run on kubernetes. It should have functionality to allow users to restore their passwords and an admin UI.\n What do you recommend? FreeIPA seems to be a resource hog but the best one I've seen so far.\n Should I use a cloud provider like jumphost, that allows for 10 free users?\n Any other cool projects or recommendations?\n Thanks\n    submitted by    /u/Flicked_Up  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5cara/manage_users_selfhost_ldap_or_3rd_party/",
          "publishedOn": "2022-11-26T17:03:01.000Z",
          "wordCount": 17150,
          "title": "Manage users, self-host LDAP or 3rd party?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z58u4g/using_home_assistant_authentikauthelia_or_wanting/",
          "author": null,
          "description": "submitted by    /u/chrg_nl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z58u4g/using_home_assistant_authentikauthelia_or_wanting/",
          "publishedOn": "2022-11-26T14:29:39.000Z",
          "wordCount": 18475,
          "title": "Using Home Assistant + Authentik/Authelia? Or wanting HA + OIDC? Add your vote!",
          "imageUrl": "https://external-preview.redd.it/UJkqXw8jYcOSjjqxZvMXdvsyZBUeXSy1eKeKStW6xFQ.jpg?auto=webp&s=b2b48b101fa6f1058daa3ecfc92f13bc42212363"
        },
        {
          "id": "https://www.reddit.com/r/selfhosted/comments/z5803x/remote_audio_player/",
          "author": null,
          "description": "I'm having a hard time finding what I'm looking for, was hoping this sub could help. If I have some music on a share and a computer (can be laptop, Pi, any other SoC) connected to a amp, is there any player/server that I can control the player on the laptop or pi? Sorta like how you can remote control spotify, looking for a player that I can control with self hosted music? Does that make sense?\n    submitted by    /u/fusion_ogbetas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/selfhosted/comments/z5803x/remote_audio_player/",
          "publishedOn": "2022-11-26T13:50:02.000Z",
          "wordCount": 18209,
          "title": "Remote Audio Player",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "homelabbity",
      "feedUrl": "https://www.reddit.com/r/homelab.rss",
      "siteUrl": "https://www.reddit.com/r/homelab",
      "articles": [
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvbo5n/can_proxmox_or_xcpng_do_gpu_partitioning_between/",
          "author": null,
          "description": "Anyone know if this is possible?\n    submitted by    /u/pzach3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvbo5n/can_proxmox_or_xcpng_do_gpu_partitioning_between/",
          "publishedOn": "2022-12-26T01:21:19.000Z",
          "wordCount": 14033,
          "title": "Can Proxmox or XCP-NG do gpu partitioning between VM’s?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvbk6b/dell_7040_sff_supports_2tb_sata_hdd/",
          "author": null,
          "description": "I just got a Dell 7040 SFF and am about to get a 6-8TB (or larger if I've weak) HDD when I was doing some research the manual states that it only supports up to 2TB. I've found a posting saying they did it, but I want to be 100% sure.\n Has somebody successfully used a >2TB drive?\n    submitted by    /u/Malvane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvbk6b/dell_7040_sff_supports_2tb_sata_hdd/",
          "publishedOn": "2022-12-26T01:15:26.000Z",
          "wordCount": 13820,
          "title": "Dell 7040 SFF supports >2TB SATA HDD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zvav1d/best_home_email_server/",
          "author": null,
          "description": "I want to create email server for just internal LAN use so apps (like nessus scans, proxmox backup confirmations) can use SMTP and I can read this mails via web gui, what do you recommend? Probably will be hosted on Ubuntu server, and the best would be if it's something popular in enterprise world to learn something that may be valuable.\n    submitted by    /u/bitstrim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zvav1d/best_home_email_server/",
          "publishedOn": "2022-12-26T00:38:38.000Z",
          "wordCount": 14401,
          "title": "Best home email server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zva8gl/looking_for_suggestions_for_virtual_homelab_host/",
          "author": null,
          "description": "Basically want 1 machine with virtualization to run about 5 or so VMs. My old virtual lab Windows Pro w Hyper V tower is pretty old and noisy, and probably too outdated at about 10 years old. My daily machine is now a MacBook pro m1 with 8GB RAM, so not a lot of room for VMs there.\n Want one machine, don't want to get into a lot of equipment. Don't want it to be \"always on\", and don't care about HA. Prefer quiet hardware as I would probably put it in my home office. I could put something in my basement but I imagine it would be a hassle turning it on remotely, since I don't want always on. Most familiar with Windows Hyper V or VMware, but am open to other options.\n Reason for lab is to test ansible/Jenkins/terraform (among others) development to Windows and Linux guests (VMs), and also some Active Directory too. \n Does someone have a similar setup, or any general suggestions of how to spec out something like this, what the options are?\n    submitted by    /u/VerySpecialStory  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zva8gl/looking_for_suggestions_for_virtual_homelab_host/",
          "publishedOn": "2022-12-26T00:05:08.000Z",
          "wordCount": 15539,
          "title": "Looking for suggestions for virtual homelab host server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv9x2c/recommendations_for_a_quiet_poe_125510g_mgig/",
          "author": null,
          "description": "Hi guys - Looking to upgrade the core switch in my network. Needs to be one single switch that has decent fan curves so my wife doesn't go crazy (1U is the only space we have in our closet).\n  \nNeed at least 8x mgig 2.5/5/10 Gbps ports that support POE (POE for Wifi6E APs)\n Need at least 8x 1GbaseT ports that support POE\n 4x SFP+ ports (uplink to 10G router and servers)\n 2x QSFP+ ports (not required but would be nice for upgradability)\n  \nRight now the only one I've found is the Meraki MS355 but the licensing fees really turn me off. The product stops switching if the license expires and I'm unsure of the fan noise.\n I believe Cisco has variants in the 9300 series but I'm very nervous about the fan noise.\n Any other recommendations?\n Thank you\n    submitted by    /u/ajgnet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv9x2c/recommendations_for_a_quiet_poe_125510g_mgig/",
          "publishedOn": "2022-12-25T23:48:50.000Z",
          "wordCount": 14167,
          "title": "Recommendations for a quiet POE 1/2.5/5/10G mgig switch (24 ports) with SFP+ and QSFP+ uplinks.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv9wq4/dell_r220_is_randomly_powercycling/",
          "author": null,
          "description": "I am sorry if this is the wrong place to ask this, but I'm at my wits' end. I am new to actual servers because I usually just use old PCS, but I recently got an R220 server off eBay. This server will sometimes randomly restart and will sometimes randomly power off. The memory scans good with memtest and all other hardware appears to be okay. The weird thing is that I don't think it is actually shutting windows itself down. I left a notepad file up on the server as a test to see when it shuts down, but when I power the server back up the notepad file was still open. I also don't see anything in event viewer. It looks like it is maintaining the last OS state somehow. Through Googling I found out that it might be related to iDrac, but I don't know enough about what that is to know for sure. I did go ahead and update iDrac and the BIOS though and that didn't fix it. Any advice would be helpful. Thanks!\n    submitted by    /u/ORION93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv9wq4/dell_r220_is_randomly_powercycling/",
          "publishedOn": "2022-12-25T23:48:19.000Z",
          "wordCount": 14430,
          "title": "Dell R220 is randomly power-cycling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv9t2f/help_with_case_for_home_nas/",
          "author": null,
          "description": "i would like to get a different case for my home nas i am using some random office PC but i would like more room and more drive bays theses are the cases that i have been looking at i am on some what of a budget. \n Fractal Design FD-CA if i got this i would try to mod it to have more bays.\n fractal r5 this would be the best case i just don't like the price new and the used ones but this would be the best one.\n i haven't seen really anything other then those two recommended in other subs or youtube.\n    submitted by    /u/Rasr123105  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv9t2f/help_with_case_for_home_nas/",
          "publishedOn": "2022-12-25T23:42:52.000Z",
          "wordCount": 13819,
          "title": "help with case for home nas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv9qjd/dell_r720_still_a_good_choice/",
          "author": null,
          "description": "I'm about to buy an used dell r720 for almost 900€. Is it old or still a good option for a homelab? It would be my first server.\n 2x intel xeon e5-2670 128gb RAM 2tb sas disk\n    submitted by    /u/Bullinh0s  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv9qjd/dell_r720_still_a_good_choice/",
          "publishedOn": "2022-12-25T23:39:09.000Z",
          "wordCount": 14682,
          "title": "Dell R720 still a good choice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv8kcw/reusing_an_sff_pc_as_a_nas/",
          "author": null,
          "description": "So I have a small PC from zotac that I can't update my plan was to add to that computer a good HDD thunderbolt drive bay and turn it into a NAS (or just a hyper converged docker server) my only need is drive redundancy actually so if one fail I have a spare.\n Now how can I achieve that ? Can I simply do some sort of software raid and let an Ubuntu server handle the whole thing ? \n Thanks for any feedback !\n    submitted by    /u/SirSirae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv8kcw/reusing_an_sff_pc_as_a_nas/",
          "publishedOn": "2022-12-25T22:39:27.000Z",
          "wordCount": 13939,
          "title": "Reusing an SFF PC as a NAS ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv7v4g/ideas_to_go_about_improving_this_mess/",
          "author": null,
          "description": "submitted by    /u/mrabstract29  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv7v4g/ideas_to_go_about_improving_this_mess/",
          "publishedOn": "2022-12-25T22:04:49.000Z",
          "wordCount": 14888,
          "title": "Ideas to go about improving this mess?",
          "imageUrl": "https://preview.redd.it/yanvidxxr58a1.jpg?auto=webp&s=a97a0801334baf6848156e11862e54e1f60cbd5b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv7mom/super_confused_about_good_storage_setup_and_file/",
          "author": null,
          "description": "I got a HP elitedesk 800 G2 SFF system from work with a i5 6500 and 32gb of 2133 MHz ram (4x8) which I wanted to turn into a server for me. \n Server would consist of probably a few VMs, including a game server, home automation stuff, seafile, perhaps a simple NAS, and as many of them as possible in Docker containers I think. So I think Proxmox would be a good fit for this.\n The system has a random 500GB HDD in it and a 500GB Samsung nvme drive. I installed Proxmox already to it with ZFS and both drives in raid 0 because I read that I should use ZFS because that gives snapshotting and it seems like a good thing to have. Also ZFS seemed like a good option (albeit a bit complicated) in general. Well I noticed that my NVME drive fails SMART check as it apparently has 255% of its lifetime used …",
          "link": "https://www.reddit.com/r/homelab/comments/zv7mom/super_confused_about_good_storage_setup_and_file/",
          "publishedOn": "2022-12-25T21:53:09.000Z",
          "wordCount": 15379,
          "title": "Super confused about good storage setup and file system for Proxmox (beginner).",
          "imageUrl": "https://external-preview.redd.it/tKnhjAyvwSTtr2LNKY-hES1R6Y2PdKZI7kISjxn6kwQ.jpg?auto=webp&s=54bd72d804703c3915ad7aef8b2b8cf04206c161"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv7m0f/250_home_lab/",
          "author": null,
          "description": "Hi. I'm thinking making a 250$ home lab after I played around with nextcloud and plex on my old laptop.\n I would use the server for running Nextcloud so i can stop using google drive , plex or jellyfin for movies and tv series and maybe some other self hosted applications.\n I have a 250$ budget including drives ( I don't think i need more than 1 or maybe 2tb). I would be nice if it was small and energy efficient.\n Do you guys have any recommendations of what to buy?\n    submitted by    /u/PawysV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv7m0f/250_home_lab/",
          "publishedOn": "2022-12-25T21:52:12.000Z",
          "wordCount": 14826,
          "title": "250$ Home Lab.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv63yy/rework_of_my_mobile_labdemo_setup/",
          "author": null,
          "description": "submitted by    /u/lupuscon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv63yy/rework_of_my_mobile_labdemo_setup/",
          "publishedOn": "2022-12-25T20:37:04.000Z",
          "wordCount": 15355,
          "title": "Rework of my mobile Lab/Demo setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv5m9v/pcie_cards_being_renamed_after_an_addition/",
          "author": null,
          "description": "How can I best fix this issue I am having - I installed a GPU and now my ethernet port is not working. I believe it is due to linux doing renaming, sorry I am a newb and don't know all the terms. I plan to add an additional card so I would hate losing my internet again as I try to run this headless on proxmox.\n I am referencing this recommendation .\n I ran the following:\n journalctl -b 0 | grep renamed \n And it states that \"....enp3s0: renamed from eth0\"\n What do I need to type in order to get the correct namesso that my ethernet will work again?\n    submitted by    /u/h0va4life  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv5m9v/pcie_cards_being_renamed_after_an_addition/",
          "publishedOn": "2022-12-25T20:12:05.000Z",
          "wordCount": 15119,
          "title": "PCIE cards being renamed after an addition (ethernet doesn't work after adding gpu)",
          "imageUrl": "https://external-preview.redd.it/tKnhjAyvwSTtr2LNKY-hES1R6Y2PdKZI7kISjxn6kwQ.jpg?auto=webp&s=54bd72d804703c3915ad7aef8b2b8cf04206c161"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv5ef8/help_with_hdd_partition_in_esxi/",
          "author": null,
          "description": "First time using any sort of VM software. I've downloaded and installed ESXI 8 on my mini pc as I plant to run Home Assistant on a VM. After logging in to EXSI and trying to create a VM it doesn't show any storage options. \n I've got a 128gb SSD but after install it's showing nothing available. I can only assume I need to resize my HDD and create a partition?\n Any help appreciated.\n    submitted by    /u/Reep881  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv5ef8/help_with_hdd_partition_in_esxi/",
          "publishedOn": "2022-12-25T20:00:54.000Z",
          "wordCount": 16737,
          "title": "Help with HDD partition in ESXI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv440k/what_do_most_of_you_server_owners_use_the_servers/",
          "author": null,
          "description": "submitted by    /u/Pepek23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv440k/what_do_most_of_you_server_owners_use_the_servers/",
          "publishedOn": "2022-12-25T18:56:31.000Z",
          "wordCount": 17925,
          "title": "What do most of you server owners use the servers for",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zv1hnj/quiet_and_dustless_apartment_homelab/",
          "author": null,
          "description": "submitted by    /u/cbapel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zv1hnj/quiet_and_dustless_apartment_homelab/",
          "publishedOn": "2022-12-25T16:41:51.000Z",
          "wordCount": 16393,
          "title": "Quiet and dustless apartment homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuyvuu/does_it_exist_dual_motherboard_hard_drives_dual/",
          "author": null,
          "description": "Hi there, and happy holidays! I’m trying to find a single case that can house my two Optiplex 390s DT (I think they’re mini-ATX motherboards) their power supplies, and a bunch of 3.5 inch hard drives. \n Does this exist? Any suggestions? Thanks!!\n    submitted by    /u/TwoDogDad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuyvuu/does_it_exist_dual_motherboard_hard_drives_dual/",
          "publishedOn": "2022-12-25T14:15:48.000Z",
          "wordCount": 16221,
          "title": "Does it exist? Dual motherboard, hard drives, dual power supply, rack mounted case.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuylpz/best_wlan_aps/",
          "author": null,
          "description": "Hello, please give your recommendations for WLAN access points, VLAN capability and multiple SSIDS would be nice. Gladly include your personal experience!\n Thanks in advance\n    submitted by    /u/Bubbleqq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuylpz/best_wlan_aps/",
          "publishedOn": "2022-12-25T13:59:03.000Z",
          "wordCount": 17648,
          "title": "Best WLAN APs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zusek9/what_is_the_difference_between_these_drives/",
          "author": null,
          "description": "submitted by    /u/santosaunders  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zusek9/what_is_the_difference_between_these_drives/",
          "publishedOn": "2022-12-25T06:31:21.000Z",
          "wordCount": 15078,
          "title": "What is the difference between these drives?",
          "imageUrl": "https://preview.redd.it/cmsd4rhe518a1.jpg?auto=webp&s=a6fe88522dfef032d51488c0e4fa52c000e63d97"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zupbpe/i_got_the_r630_specific_rail_kit_supposedly_is_it/",
          "author": null,
          "description": "Been having a pretty rough time with rack assembly the past couple days but come now, shouldn't the fronts of the units be flush at least? I'd like to be able to close the front door of the cabinet :,)\n    submitted by    /u/UnknownSP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zupbpe/i_got_the_r630_specific_rail_kit_supposedly_is_it/",
          "publishedOn": "2022-12-25T03:11:09.000Z",
          "wordCount": 15619,
          "title": "I got the R630 specific rail kit supposedly, is it really supposed to stick out like that?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuom8v/a_complete_redesign_of_my_network_before_this_it/",
          "author": null,
          "description": "submitted by    /u/iKill101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuom8v/a_complete_redesign_of_my_network_before_this_it/",
          "publishedOn": "2022-12-25T02:27:10.000Z",
          "wordCount": 16586,
          "title": "A complete redesign of my network. Before this, it was all on 10.0.0.0/8 and the documentation was only in DokuWiki. Still early days for the diagram.",
          "imageUrl": "https://external-preview.redd.it/Y_KooBeFcp7ejMD2uutAXcaCVezqw-aEtkIJoq9IEdA.png?auto=webp&s=fd5669a54f4c526ca35c7c0dd450fcd301393dee"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zunl27/what_will_you_build/",
          "author": null,
          "description": "If you had a 2018 Dell Precision 5820 with 128GB of RAM and 2TB of storage, what will you build?\n    submitted by    /u/mossiboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zunl27/what_will_you_build/",
          "publishedOn": "2022-12-25T01:23:40.000Z",
          "wordCount": 13758,
          "title": "What will you build?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zunb54/best_way_to_setup_iaas_for_my_friends/",
          "author": null,
          "description": "I have rather a lot of compute power, and I'd like to find a way to rent it to my friends. Any solutions for this?\n    submitted by    /u/decduck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zunb54/best_way_to_setup_iaas_for_my_friends/",
          "publishedOn": "2022-12-25T01:07:17.000Z",
          "wordCount": 13784,
          "title": "Best way to setup IaaS for my friends",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zumrp8/new_home_lab/",
          "author": null,
          "description": "Hello,\n I'm going through my spare parts bins and junk that I have access to, and have come up with this so far:\n x56 ASUS P6T mobo\n i7 920 CPU -or- Xeon x5690 (probably go with the X5690)\n 24Gb matching GSkill Ripjaw DDR3 1600 RAM (not ecc obvs)\n big ATX case\n I took an ancient Geforce GTX 480 off the mobo, and have several smaller GPUs to use, MUCH less power consumption than this GTX480. Surprisingly the GTX480 works great, but its a power hog for sure! I suppose I could easily go headless, once the server is up and running anyway.\n I'm hoping to do something you all probably think is simple enough, but I'm new to this stuff.\n I'd like to run Proxmox - virtualization is cool. I've loaded it once or twice on a few SSDs I've got, and just getting used to it a bit. I'm not sure how but Pro…",
          "link": "https://www.reddit.com/r/homelab/comments/zumrp8/new_home_lab/",
          "publishedOn": "2022-12-25T00:36:05.000Z",
          "wordCount": 14778,
          "title": "New home lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zumq5s/technotims_homelab_tour/",
          "author": null,
          "description": "submitted by    /u/geerlingguy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zumq5s/technotims_homelab_tour/",
          "publishedOn": "2022-12-25T00:33:34.000Z",
          "wordCount": 13814,
          "title": "TechnoTim's Homelab tour",
          "imageUrl": "https://external-preview.redd.it/BhbBYG5E8OLdYnQSap30ovKwRKBSio-n9ac65xA7txw.jpg?auto=webp&s=867759d14a710084cd800cf935f2a6c4242c927a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zumlxz/nvidia_k80_in_dell_r720/",
          "author": null,
          "description": "submitted by    /u/International-Fee473  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zumlxz/nvidia_k80_in_dell_r720/",
          "publishedOn": "2022-12-25T00:26:48.000Z",
          "wordCount": 14251,
          "title": "Nvidia k80 in Dell r720?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zukpzg/i_just_got_ups_apc_bx950mi_not_user_replacable/",
          "author": null,
          "description": "I am pretty sure the last model was listed as user replaceable, but I now realize this one says its not user replacable but still lists replacement battery for it.\n I just want to know, so I know when the time that will eventually come, comes:\n Is it actually hard to replace, or is it simple and I can do it, but they say its not to cover their asses?\n    submitted by    /u/TheMihle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zukpzg/i_just_got_ups_apc_bx950mi_not_user_replacable/",
          "publishedOn": "2022-12-24T22:44:53.000Z",
          "wordCount": 15100,
          "title": "I just got UPS APC BX950MI, not user replacable batteries?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zukfzo/i_want_to_start_a_home_server/",
          "author": null,
          "description": "I am trying to figure what to get for my first home server. I have an extra itx motherboard and a 6th generation Intel i7 processor. I am wanting to make a good server. The main thing is cloud and NAS for projects. I want to learn to be a system admin.\n    submitted by    /u/VirusNegativeorisit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zukfzo/i_want_to_start_a_home_server/",
          "publishedOn": "2022-12-24T22:30:17.000Z",
          "wordCount": 14952,
          "title": "I want to start a home server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuic6c/dell_t5600_sata_and_sas_drives_in_esxi/",
          "author": null,
          "description": "So I've got ESXI 6.7 running on a dell precision T5600 (Dual Intel(R) Xeon(R) CPU E5-2690) that has the onboard SAS port / controller. I have a 1 TB 2.5 inch SSD as the boot drive for ESXI 6.7 and a 2 TB HDD for VMs. I've recently installed an ICY DOCK Tray-Less 4 x 2.5 SATA HDD Hot-Swap Docking Enclosure in the 5.25\" Bay directly beside the disk drive and used a Cable Matters Internal Mini SAS to SATA Cable to plug into the SAS port of the system and fan out to the 4 ports on the hot swap bay. \n ​\n However, I'm not getting ESXI to see any drives connected in the hotswap bay. while in the bios I'm able to see the one test drive I have connected and I verified the drive is functional in my main computer. Current configuration I have for the bios is that I have SATA/RAID enabled and AHCI set, I have also installed the megarid sas drivers into esxi but still no luck. Has anyone tried this before, is the bios on the T5600 a SAS or SATA type deal where only one port type works?\n    submitted by    /u/CortexAnthrax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuic6c/dell_t5600_sata_and_sas_drives_in_esxi/",
          "publishedOn": "2022-12-24T20:43:18.000Z",
          "wordCount": 15261,
          "title": "Dell T5600 Sata and SAS drives in ESXI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuhzwn/x99_c612_dual_xeon_2696v4_help/",
          "author": null,
          "description": "Went ahead and tried a Chinese board, decided to get one on Amazon instead of Aliexpress and wait until Feburary.\n Running two 2696V4's on a Shangzhaoyuan C612 chipset mobo...\n https://www.amazon.com/dp/B0B9FY9YK5?psc=1&ref=ppx_yo2ov_dt_b_product_details\n Everything works great, however, OCCT and HWINFO show both CPU Package powers capped at 23Watts. PSU we're using is a, 1300W EVGA G2.\n https://www.amazon.com/gp/product/B00COIZTZM/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&psc=1\n I've messed around with BIOS settings and edited C-States and what not, I got a net gain on benchmarks/Prime95/OCCT/Furmark from 20W capped to now a 30W capped. Throwing WHEA errors on HWINFO/OCCT.\n I have two separate EPS rails per socket power. CPU1, CPU2. EVGA's rails rate \"108AMPS/120Watts\" per 12V rail, not sure if I'm reading that right... or am I missing something here in BIOS, or on the board itself?\n I've used this power supply to push 300 watt CPU package spikes on a 5950X with PBO curves, I don't think it is the PSU?\n Maybe the board just isn't able to report actual power draw, I'm not sure.\n Fixed WHEA error 19, but no change in actual draw. Running Stress/OCCT/Cinebench/Prime95 over the course of two days everything looks fine otherwise.\n    submitted by    /u/Cythisia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuhzwn/x99_c612_dual_xeon_2696v4_help/",
          "publishedOn": "2022-12-24T20:25:52.000Z",
          "wordCount": 15384,
          "title": "X99 C612, dual Xeon 2696V4 help.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zug16z/what_else_could_i_add_to_my_homelab_my_comment/",
          "author": null,
          "description": "submitted by    /u/BouncyPancake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zug16z/what_else_could_i_add_to_my_homelab_my_comment/",
          "publishedOn": "2022-12-24T18:48:38.000Z",
          "wordCount": 14469,
          "title": "What Else Could I Add to My Homelab ? (My comment will explain what the VMs are)",
          "imageUrl": "https://preview.redd.it/u3wq6mg86w7a1.png?auto=webp&s=a820530de3d0ab3e5089c30dec95dd11f12de783"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zug11y/total_run_time_1374_years_61_days_world_community/",
          "author": null,
          "description": "Total run time: 1,374 years 61 days -- World Community Grid Homelab team stats for Saturday, 12/24/2022\n  \nCurrent Members 245 (#33 in the world)\n Total Run Time (y:d:h:m:s) (Rank) 1374:061:09:39:49 (#145)\n Points Generated (Rank) 2,351,407,143 (#126)\n Results Returned (Rank) 3,835,954 (#131)\n  \nHomelabbers who have joined the Homelab team and are processing datasets for World Community Grid are working on the following projects:\n  \n Project Points Generated Results Returned Total Run Time (y:d:h:m:s) \n  \n OpenPandemics - COVID-19 438,170,950 655,764 205:213:22:15:20 \n  Africa Rainfall Project 29,124,496 6,722 15:246:20:47:57 \n  Help Stop TB 2,624,907 1,068 1:237:01:20:12 \n  Mapping Cancer Markers 1,331,464,680 1,860,297 846:204:16:29:35 \n  Beta Testing 588,775 966 0:125:19:17:04 \n  Microbiome Immunity Project 233,228,063 555,814 126:303:09:50:12 \n  OpenZika 56,754,339 148,682 27:023:07:53:07 \n  FightAIDS@Home - Phase 2 75,951,773 100,228 50:357:19:14:52 \n  Outsmart Ebola Together 61,922,110 115,152 29:077:20:37:22 \n  FightAIDS@Home 4,068,979 67,396 2:152:07:48:41 \n  Smash Childhood Cancer 117,508,071 323,865 67:308:08:05:27 \n \n Join the Homelab team here: \n (if you already participate in World Community Grid)\n https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n (if you are new to World Community Grid)\n https://join.worldcommunitygrid.org?teamId=124DTPZ682\n Link to team statistics: https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n    submitted by    /u/homelabber12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zug11y/total_run_time_1374_years_61_days_world_community/",
          "publishedOn": "2022-12-24T18:48:26.000Z",
          "wordCount": 14342,
          "title": "Total run time: 1,374 years 61 days -- World Community Grid Homelab team stats for Saturday, 12/24/2022",
          "imageUrl": "https://external-preview.redd.it/wIj6ygk01ih8oIHxFRQ6FPPWByQkwZHSYkhAwFSPi5g.jpg?auto=webp&s=695923a3c1648c33a1135adf2092e5d80a1fa37d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuflas/new_rescue_lulo_loves_the_latest_addition_to_the/",
          "author": null,
          "description": "submitted by    /u/jotafett  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuflas/new_rescue_lulo_loves_the_latest_addition_to_the/",
          "publishedOn": "2022-12-24T18:26:53.000Z",
          "wordCount": 14096,
          "title": "New rescue (Lulo) loves the latest addition to the catlab. I mean homelab.",
          "imageUrl": "https://preview.redd.it/napfuebb2w7a1.jpg?auto=webp&s=04c8b6bcd840f21c660f323706dba11346d8b0b4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zudpsi/my_homelab_has_changed_again/",
          "author": null,
          "description": "submitted by    /u/Techno-Tim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zudpsi/my_homelab_has_changed_again/",
          "publishedOn": "2022-12-24T16:54:56.000Z",
          "wordCount": 17075,
          "title": "My HomeLab has changed again...",
          "imageUrl": "https://preview.redd.it/u2vrdfj6mv7a1.jpg?auto=webp&s=7bd3a95a9182029ec44ec0b2698cd2de44a9f752"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zucfs0/proxmox_ve_72_on_intel_compute_stick_stk2m3w64cc/",
          "author": null,
          "description": "Hi everyone!\n First: Why?\n Well, a low power node to run the network's essentials is never a bad thing, and I didn't wanted to go for a RaspberryPI, because it's both expensive for what it is at the moment due to shortages, and also because I prefer to reduce the number of different environments I'm running, just for cohesion.\n Though, as a piece of tech from 2017, it sure needed fresh thermal paste. Thankfully, they are quite easy to open and clean. 1 screw under the back sticker, clips all around, 4 screws on the cooler (1 on the back of the board into the cooler, 3 from the front into the chassis), and the fan is just clipped in the removed panel.\n ​\n Second: How?\n Well sure, the compute stick only have wifi and bluetooth, and rely on proprietary blobs I can't (or am too lazy to) find, …",
          "link": "https://www.reddit.com/r/homelab/comments/zucfs0/proxmox_ve_72_on_intel_compute_stick_stk2m3w64cc/",
          "publishedOn": "2022-12-24T15:49:46.000Z",
          "wordCount": 16556,
          "title": "Proxmox VE 7.2 on Intel Compute Stick STK2M3W64CC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zubrhl/grafana_dashboard_for_my_current_instance_of_home/",
          "author": null,
          "description": "submitted by    /u/chkpwd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zubrhl/grafana_dashboard_for_my_current_instance_of_home/",
          "publishedOn": "2022-12-24T15:14:29.000Z",
          "wordCount": 14968,
          "title": "Grafana Dashboard for my current instance of Home Prod",
          "imageUrl": "https://preview.redd.it/01jts7n74v7a1.png?auto=webp&s=7dadb1583d7767c3ba5abf1c5d8090832ad34e06"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zuboet/are_usb_enclosure_more_prone_to_errors/",
          "author": null,
          "description": "Hi everyone,\n I was thinking to upgrade my NAS from an intel G4400 to a Intel NUC+some HDD \"rack\" like Yottamaster, Terramaster or Fantec like this ones:\n https://www.amazon.it/Yottamaster-Esterno-USB3-0-modalit%C3%A0-Silenzioso/dp/B084Z2Y97C\n https://www.amazon.it/Yottamaster-Alluminio-Esterno-Ventilatore-Silenzioso/dp/B083Q8Z2KM\n https://www.amazon.it/QB-35US3-6G-Esterno-pollici-Ventola-Sensore/dp/B07DD1QZY7\n https://www.amazon.it/TerraMaster-Storage-esterno-Enclosure-Diskless/dp/B08CN4Z4PC\n I read that this kind of USB cases are more prone to errors compared to SATA disk connected diractly to the motherboard. Is it true? If yes, there is some way to avoid it without using ECC RAM?\n    submitted by    /u/TopdeckIsSkill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zuboet/are_usb_enclosure_more_prone_to_errors/",
          "publishedOn": "2022-12-24T15:10:00.000Z",
          "wordCount": 14902,
          "title": "Are USB enclosure more prone to errors?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zubmdm/first_actual_server_market_place_for_130_let_the/",
          "author": null,
          "description": "submitted by    /u/Spiritual_Panda_8392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zubmdm/first_actual_server_market_place_for_130_let_the/",
          "publishedOn": "2022-12-24T15:07:05.000Z",
          "wordCount": 16232,
          "title": "First actual server, market place for 130. Let the fun begin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zubf3x/psa_tva_electric_customers/",
          "author": null,
          "description": "submitted by    /u/mspencerl87  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zubf3x/psa_tva_electric_customers/",
          "publishedOn": "2022-12-24T14:56:52.000Z",
          "wordCount": 16955,
          "title": "PSA: TVA electric customers",
          "imageUrl": "https://preview.redd.it/bobd6wkoiw7a1.jpg?auto=webp&s=60e57c997972b00cbf8a396d14283a9717b68a48"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zub19t/squeaky_wheel_gets_the_oil/",
          "author": null,
          "description": "submitted by    /u/RoyRock413  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zub19t/squeaky_wheel_gets_the_oil/",
          "publishedOn": "2022-12-24T14:35:42.000Z",
          "wordCount": 20751,
          "title": "squeaky wheel gets the oil! 😳",
          "imageUrl": "https://external-preview.redd.it/1hxJs-JteUq8ibpLueXxZO-dgF9X8mbn9mR74vNKosA.png?format=pjpg&auto=webp&s=3beff9f6b4b8dba29d2a0a39af11f0755212bcb9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zu9hdq/how_do_i_keep_a_10gb_nic_cool_in_a_nonserver_case/",
          "author": null,
          "description": "I got myself an early Christmas present and put together a NAS inside a Define R6 case. I threw in a 10Gb NIC (Intel X520) to speed up transfers from my main PC. Airflow isn't bad, but it's not as good as you'd find in a server chassis - especially over the PCIe area.\n https://preview.redd.it/2ra57acm6u7a1.jpg?width=1024&format=pjpg&auto=webp&s=feab3bcbd1f9e114c8751e146ed1ea717587a8ab\n After being powered on for only a few minutes I noticed the NIC was getting extremely warm with the heatsink being too hot to touch. I took a look with a thermal camera and it was by far the warmest part in the system. The heatsink was too reflective to get an accurate temperature but the back of the board was around 70°C.\n https://preview.redd.it/30h3qgq3eu7a1.jpg?width=512&format=pjpg&auto=webp&s=255f5483a9e963f844a931bae48c8316dbe6948b\n https://preview.redd.it/fc512lz4eu7a1.jpg?width=512&format=pjpg&auto=webp&s=a78e04df7ced4a4bd504617f44a92728f55a7ce8\n I took a look at the X520's datasheet and it requires a minimum air flow of 100LFM. I don't have anything to measure this, but I don't expect I'm even close. I can't see anywhere good to mount a fan nearby, but I might be able to go wild with some zip ties and make something work. I'd be interested to know what people have done to keep their NICs cool in cases they're not designed for. Thanks!\n    submitted by    /u/_jackTech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zu9hdq/how_do_i_keep_a_10gb_nic_cool_in_a_nonserver_case/",
          "publishedOn": "2022-12-24T13:07:06.000Z",
          "wordCount": 17261,
          "title": "How do I keep a 10GB NIC cool in a non-server case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zu8sac/though_i_occasionally_have_negative_paid_to_use/",
          "author": null,
          "description": "Prices trended in the high $2-3 until morning. Are server naps a regular thing for any of you these days?\n    submitted by    /u/Tri_Ban_Had  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zu8sac/though_i_occasionally_have_negative_paid_to_use/",
          "publishedOn": "2022-12-24T12:21:52.000Z",
          "wordCount": 15278,
          "title": "Though I occasionally have negative (paid to use) electricity rates, which caused a bit of a stir here previously. I also wanted to share the part of that program where I decide to shut the rack down for 12 hours. Are server naps a regular thing for any of you these days?",
          "imageUrl": "https://preview.redd.it/q4iuj7q0rv7a1.jpg?auto=webp&s=bd8abca90c21c92ddf5d9f70955a36ac94eda88b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztxurv/help_identifying_a_nic/",
          "author": null,
          "description": "I have 2 X520-SR2 NICs that I bought off eBay. 1 had a yottamark and verified fine, the other did not. I’m having issues with speed with the second one, not hitting 10gb using iperf. I tested with the X520 and the old Mellanox connectX3 I had, to verify it was the NICs issue. I’m trying to see if I got a counterfeit card so I can file a dispute for one of them. I was looking at the product ID and I can’t find it anywhere. \n E70856-013 (I thought E70856 was sun/Oracle but I can’t find anything with -013). I’m trying to ID this card so I can further troubleshoot. \n https://imgur.com/a/9nGCwOu/\n Thank you all!\n    submitted by    /u/FinancesAr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztxurv/help_identifying_a_nic/",
          "publishedOn": "2022-12-24T01:06:45.000Z",
          "wordCount": 13903,
          "title": "Help identifying a nic",
          "imageUrl": "https://external-preview.redd.it/8RmRGh4f5UV6k5-4bu3RLbjPz7VHtZ4VH27mRtww44Y.jpg?auto=webp&s=3ef0afadc26a2810502e4488c2d13b698e7453a0"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztxty2/so_my_house_is_setup_for_cat_6_and_cant_find_any/",
          "author": null,
          "description": "submitted by    /u/4runner99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztxty2/so_my_house_is_setup_for_cat_6_and_cant_find_any/",
          "publishedOn": "2022-12-24T01:05:38.000Z",
          "wordCount": 14205,
          "title": "so my house is setup for cat 6 and can't find any Jack's..has coax in said rooms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztxgu5/dell_perc_h700_marking_4tb_drives_as_failed/",
          "author": null,
          "description": "The Dell PERC H700 inside of my Powervault NX300 is detecting these OEM Seagate ST4000NM0023's (SAS), but displays them as \"Failed\". As you can see by the image at the imgur link, they're showing \"No Fault\" on SMART status. I've seen plenty of weird compatiblity issues, but this one is entirely new to me. Controller is running latest firmware, BIOS has also been upgraded to latest. The drives are firmware 7FA6, and the previous drives I had installed were of the OEM Hitachi Enterprise 2TB SAS variety.\n PERC H700 Config Screen\n ​\n To add to the weirdness, when I first boot into the controller, they display as \"Ready\". Only after I try to add them to a VD do they go to \"Failed\" status.\n ​\n Any help is appreciated :)\n    submitted by    /u/tipripper65  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztxgu5/dell_perc_h700_marking_4tb_drives_as_failed/",
          "publishedOn": "2022-12-24T00:47:27.000Z",
          "wordCount": 14865,
          "title": "Dell PERC H700 Marking 4TB Drives as Failed",
          "imageUrl": "https://external-preview.redd.it/IY7RqOFd7ZeUaElaC3Wg4yavfe3wJy16RxWtdrjJlBA.png?auto=webp&s=3e555422fcb98505e156b72597605915fa7ccd24"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztw19n/setting_up_windows_storage_space_for_colorist/",
          "author": null,
          "description": "Hi, \n I feel like every time I think I figured something out with Storage Spaces, I read something else and I'm even more confused. \n Here's my situation: \n I'm a colorist, doing color grading on 4K+ projects for Web and TV, as well as occasionnal video editing. I work from home, so I'm setting up a network that would be used by 1, occasionnally 2 workstations.\n I usually have a few hundreds of gigs to a TB of media of projects I'm working on but I like to keep everything accessible, so I currently have about 50TB of storage in my machine, that I'm moving to a server to free up airflow, and allow for expandability and have a permanent FTP server for clients. Most of the files I work with are multiple gigs or tens of gigs, excluding project cache files, but those are stored on an NVME SSD o…",
          "link": "https://www.reddit.com/r/homelab/comments/ztw19n/setting_up_windows_storage_space_for_colorist/",
          "publishedOn": "2022-12-23T23:38:07.000Z",
          "wordCount": 16449,
          "title": "Setting up Windows Storage Space for colorist home studio",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztvsn6/25_hdd_recommendations/",
          "author": null,
          "description": "Does anyone have any recommendations for reliable 2?5\" HDDs? SSDs are also of interest to me, but not as much.\n I've poked around some used markets but I'm unsure of which ones are reputable.\n    submitted by    /u/Senkyou  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztvsn6/25_hdd_recommendations/",
          "publishedOn": "2022-12-23T23:26:52.000Z",
          "wordCount": 14110,
          "title": "2.5\" HDD recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztvbo9/45drives_av15_zpool_configuration/",
          "author": null,
          "description": "I just acquired a 45Drives AV15 server. Currently, I have a Synology ds1813+ with 8x3TB WD Reds. I want the AV15 to replace the ds1813, but I need to get a 16TB to back up the Synology data first. Once I do that, I want to develop the best ZFS design for the av15 based on my current needs. So I’ll have 12x3TB WD Reds and 3x1TB SSD drives that I can use. My current setup is as follows. \n Synology ds1813 Shares folders Media streaming (jellyfin) Music, airsonic Photos, dsphoto app ISO files and other data stored in the ds1813 VMBackups VMdata (stores some light lxd and vms disk)\n Lenovo m920q. (Proxmox host) VMs and Docker containers are running on it. Backup all proxmox VMs to VMBackups NFS shared\n The plan is to do a hyper-converged on the av15 with proxmox and the Huston gui. I’m new to ZFS and looking for advice on the design of the zpool or pools. \n Possible considerations Scenario 1 1. zpool with 12 HDD and 3 SSD 1. Two or three VDEV (raidz1,2,3)? 1. Store everything on the zpool\n Scenario 2 1. zpool for the SSD only (raidz1 or mirror) 1. Store VMs on ssd pool 2. Zpool for the HDD (add third SSD for cache)? 1. 2 VDEV raidz1,2? 2. Store media on HDD pool\n Everything will be back up to the 16TB I’ll use to copy the data from the Synology temporarily. \n Thoughts and suggestions are much appreciated. \n Thanks Dan\n    submitted by    /u/nodejson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztvbo9/45drives_av15_zpool_configuration/",
          "publishedOn": "2022-12-23T23:05:33.000Z",
          "wordCount": 14137,
          "title": "45Drives AV15 zpool configuration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztv6q6/replaced_cyberpower_1500_sla_with_lifep04_2_for/",
          "author": null,
          "description": "I am in the old part of town with frequent power outages. Unmonitored situation with 8 computers. Get about 2 years out of the original batteries but the SLA quickly lose capacity since they are totally discharged every time the power goes out. Then when we are at work the UPS are only useful for power blips and brownouts. The the power goes out we only get 5-10 min actual run time. I expect this situation will improve with the LiFeP04 and the overall cost will be much lower. Even deep cycle SLA do not tolerate frequent full discharges so that technology is not useful to me.\n    submitted by    /u/Turbulent-Apricot680  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztv6q6/replaced_cyberpower_1500_sla_with_lifep04_2_for/",
          "publishedOn": "2022-12-23T22:59:42.000Z",
          "wordCount": 13925,
          "title": "replaced Cyberpower 1500 SLA with LiFeP04 2 for $75 8Ah works well",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztv515/dl380_g5_g4_servers/",
          "author": null,
          "description": "I happen to have a bunch of old g4 & g5 servers and some fiber channel stuff. I am at a loss as to what to do with it all as most of it is useless (to me).\n Do I recycle it all? Try to do some ATX case conversions? Give them away? Part them out on eBay (seems like a waste of time and money to me but hey).\n    submitted by    /u/No_Stretch_9237  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztv515/dl380_g5_g4_servers/",
          "publishedOn": "2022-12-23T22:57:25.000Z",
          "wordCount": 14099,
          "title": "DL380 g5 &g4 Servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztuk18/pondering_pastebin_alternatives_after_reading/",
          "author": null,
          "description": "Hi all,\n There have been many posts here on this topic, but after reviewing most of them I emerge perplexed. What I like about Pastebin is the ability to login and see your past pastes. I also like the ability to modify or even delete posts. Obviously, it is multi-user, but that is not needed in the homelab.\n The options that I have considered are LenPaste and Privatebin, but both seem to have a concept of creating a paste that has no editability or even in some cases visibility after creation. (For example, neither seem to allow edit or deletion of pastes after creation.) I think that the they do this to ensure privacy and security, but I prefer something more Pastebin like even if it requires a security trade off.\n I am confused about why these seemingly basic features are nowhere to be found in OSS pastebin alternatives. Am I missing something? Are there other options that I should be considering that have these features?\n TIA!\n    submitted by    /u/JL_678  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztuk18/pondering_pastebin_alternatives_after_reading/",
          "publishedOn": "2022-12-23T22:30:33.000Z",
          "wordCount": 13999,
          "title": "Pondering Pastebin alternatives after reading many posts here",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztuefj/evga_supernova_450_gm_6pin_sataperif/",
          "author": null,
          "description": "Hi. I need to connect 8 SATA HDDs (mix of Seagate and HGST, <10W) to my EVGA SuperNOVA 450 GM. Since I want to avoid Molex-to-SATA adapters, is it possible to connect a 6-pin to 4x SATA (EVGA) to the 6-pin PERIF connector (PSU side)? Looking around, I found that the only difference is the absence of the 3.3v pin. Am I right?\n ​\n https://preview.redd.it/ofhsebbg3q7a1.jpg?width=2048&format=pjpg&auto=webp&s=1a8806e4f845e0e47faf61ac4fad3da00628edb9\n    submitted by    /u/icantfindac00lname  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztuefj/evga_supernova_450_gm_6pin_sataperif/",
          "publishedOn": "2022-12-23T22:23:17.000Z",
          "wordCount": 15020,
          "title": "EVGA SuperNOVA 450 GM 6-pin SATA/PERIF interchangeable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztucqw/newbie_here_recommendation_for_4u_rack_case/",
          "author": null,
          "description": "I currently have somewhat of a setup(s) in my living room and want to potentially movie both the systems to a rack in the garage\n System1:\n  \nAsrock Steel Legend X570 \n Ryzen 3900X\n 32GB RAM (thinking might add another 64GB here and increase the number of VM's to include some other things like pfSense, VPN, etc..)\n HDD: 512 GB SSD for OS + 4TB + 8TB + 12TB + 14TB\n This is currently running proxmox and 2 VM's \n Ubuntu - running multiple services in a docker\n Home Assistant OS\n \n  \nSystem2:\n  \nHP Z800 w/Intel Xeon X5650 (Dual Configuration)\n 64GB RAM (ECC)\n HDD: 512GB SSD (OS) + 3x14TB\n This system is currently running proxmox and 1 single VM \n Truenas\n \n  \n​\n So far it seems like the only 4u case that does not break the bank a lot is the RSV-L4000U from Rosewill . Is it a good choice? Are there any other recommendations? \n Also seems like the prices are currently elevated (supply chain issues still?) Any guidance on if waiting a bit longer would bring sanity to the prices? I've read that the Rosewill RSV-L4000U used to be around $130 not too long ago.\n ​\n Thanks in advance!\n    submitted by    /u/presler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztucqw/newbie_here_recommendation_for_4u_rack_case/",
          "publishedOn": "2022-12-23T22:20:58.000Z",
          "wordCount": 14872,
          "title": "newbie here, recommendation for 4U rack case ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztt6a1/hpe_spp_for_dl360g9_and_ml350g8/",
          "author": null,
          "description": "Hi. \n Could someone please confirm for me which are the latest SPP's available to download for the 2 models of servers below: \n 755258-B21\n 646676-001\n ​\n Thank you!\n    submitted by    /u/networkn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztt6a1/hpe_spp_for_dl360g9_and_ml350g8/",
          "publishedOn": "2022-12-23T21:30:20.000Z",
          "wordCount": 13731,
          "title": "HPE SPP For DL360G9 and ML350G8",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztsz7w/refurbished_supermicro_x9dblif_wont_boot/",
          "author": null,
          "description": "Hey guys,\n I just bought a 1u server off eBay with the motherboard in title.\n It came with with everything it should need to run. The seller listed it saying it posted and that’s as far as they tested.\n When I power it on, the fans spin up for a few seconds, then it shuts off.\n I have connected the ipmi lan Port and was able to get on the ipmi web page, but the default credentials don’t work.\n When I connect my monitor, it switches on to react to the new connection, but doesn’t display anything when the server powers on.\n I have tried my gaming pc power supply connected to the main board but it does the same thing. My pc psu only has 1 8pin cpu connector and this motherboard needs 2 8 pins. \n I tried taking the memory out to try get a beep code, but it acted exactly the same.\n There is definitely a cpu in the socket.\n Visually the motherboard looks ok. No burst caps or anything.\n Am I looking at a dead server or am I missing something?\n    submitted by    /u/fusrohdann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztsz7w/refurbished_supermicro_x9dblif_wont_boot/",
          "publishedOn": "2022-12-23T21:21:37.000Z",
          "wordCount": 14940,
          "title": "Refurbished supermicro x9DBL-IF won’t boot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zts7ym/registered_vs_unregistered_vs_buffered_vs/",
          "author": null,
          "description": "I am in search for a ram for Supermicro X11SSH-F. It takes unbuffered ECC ram. I see so many ebay listings and some of them mention being ECC but sometimes without other words like unregistered or unbuffered\n Is registered and buffered used interchangeably and same for unregistered and unbuffered? Or its different terms?\n Little education may help me to find something in reasonable price. I am looking for 8gb or 16gb RAM for pfsense. I know pfsense doesn’t use much but if it is cheaper, I don’t mind it goes to waste.\n    submitted by    /u/PirateParley  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zts7ym/registered_vs_unregistered_vs_buffered_vs/",
          "publishedOn": "2022-12-23T20:47:25.000Z",
          "wordCount": 15939,
          "title": "Registered vs unregistered vs buffered vs unbuffered",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztrxl0/my_lack_rack_home_lab/",
          "author": null,
          "description": "submitted by    /u/iamtehstig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztrxl0/my_lack_rack_home_lab/",
          "publishedOn": "2022-12-23T20:34:31.000Z",
          "wordCount": 14126,
          "title": "My lack rack home lab",
          "imageUrl": "https://external-preview.redd.it/UttTcRV0eZw2wjwEwuM4VKanPmXSILTfcei3OnpZOk0.jpg?auto=webp&s=e080e89775373f2ea17653e89bb8bc2d22c4f0be"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztqna8/firewall_recommendations/",
          "author": null,
          "description": "I am looking for firewall recommendations other than pfsense. I love pfsense, but how it handles NAT is a pain. I have done plenty of researching and trouble shooting but I can have two pcs trying to play games on the same network. Does anyone have a recommendations on a firewall?\n    submitted by    /u/4MAZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztqna8/firewall_recommendations/",
          "publishedOn": "2022-12-23T19:37:47.000Z",
          "wordCount": 15403,
          "title": "Firewall recommendations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztpthb/lastpass_users_your_info_and_password_vault_data/",
          "author": null,
          "description": "submitted by    /u/ThatGuy_ZA  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztpthb/lastpass_users_your_info_and_password_vault_data/",
          "publishedOn": "2022-12-23T19:01:25.000Z",
          "wordCount": 16752,
          "title": "LastPass users: Your info and password vault data are now in hackers’ hands. Password manager says breach it disclosed in August was much worse than thought.",
          "imageUrl": "https://external-preview.redd.it/1A3tQAM8v9bkoFfDEZWJ85ON6AQPTCOZXiAt_LkGFnk.jpg?auto=webp&s=9aa3fc7c54688d3ae48ada453fdf05659e58dc36"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztklzh/accidentally_corrupted_my_proxmox_cluster_on/",
          "author": null,
          "description": "submitted by    /u/Theduke322  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztklzh/accidentally_corrupted_my_proxmox_cluster_on/",
          "publishedOn": "2022-12-23T16:05:18.000Z",
          "wordCount": 15504,
          "title": "Accidentally corrupted my Proxmox cluster on Christmas Eve Eve... welcome XCP-NG!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztihct/hi_i_am_slowly_making_my_own_home_lab_and_i_have/",
          "author": null,
          "description": "submitted by    /u/HieroglyphicEmojis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztihct/hi_i_am_slowly_making_my_own_home_lab_and_i_have/",
          "publishedOn": "2022-12-23T15:04:31.000Z",
          "wordCount": 15475,
          "title": "Hi! I am slowly making my own home lab and I have questions. (I’m new! But I’ve been reading a lot!) So, I have a few photos and then I need advice, please.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztclqr/how_to_you_reduce_your_energy_usage/",
          "author": null,
          "description": "Our energy bills skyrocket (even more if you're unfortunate to live in a middle of Europe), and most of us start thinking twice before adding shiny new refurbished server into our racks. I wonder how do you folks optimise energy usage for your homelab? \n The path I went through recently began from re-thinking the purpose of all my boxes:\n  \nwhich ones need to run constantly 24h/day?\n which ones should run during a day, when most of my (and my family's) activity happens?\n which ones should run occasionally, when one needs to access concrete services?\n  \nSurprisingly, the answer for 1. was \"none\" - I don't need to keep anything running during a night and this way I also discovered I may \"sleep\" and \"wake-up\" on predefined schedule all of my servers, including Synology NAS. Proxmox behaves a bit weird (for example I can't log-in to certain nodes after wake up for some reason), but I can live with it.\n The answer for 2nd question was more tricky. Definitely NAS with couple of crucial docker containers (like paperless, dashboard) and AzuraCast are something that everyone at home uses a lot and it should run at least till 22:00. This is where I discovered that all these services are lightweight enough to locate them on single raspberry pi. \n The answer for 3rd question was the easiest - everything else should run \"on-demand\". In particular things related to software dev (Gitea, Drone CI, Coolify, etc.) should start when needed. I managed to reduce required hardware to 2 boxes only - Intel NUC for Kubernetes cluster and Lenovo m720q for the rest, and move them straight onto my desk. They are extremely quiet so no feeling of sitting next to the jumbo-jet.\n I'm still curious how much does it save (maybe not worth the effort), still measuring energy usage. Along the way, I also had to re-evaluate my plans to buy Dell r720. Would be great to have those 48 threads for my hungry clojure containers, but I guess I would have to find another job to pay crazy bills :)\n    submitted by    /u/haksior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ztclqr/how_to_you_reduce_your_energy_usage/",
          "publishedOn": "2022-12-23T11:00:01.000Z",
          "wordCount": 17011,
          "title": "How to you reduce your energy usage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ztacy0/jonsbo_n1_11_drive_itx_nas_5_hdd_6_25_ssd/",
          "author": null,
          "description": "Meant to post a while ago but life has been busy, felt like sharing probably the densest NAS build I've made.\n I was looking for something that could hold some hard drives but I wanted to explore doing a all flash based vdev, managed to shove all of it inside this ITX case with barely any room to spare. SSDs are in raidz1, 8TBs are mirrored archival, 16TBs are in raidz1 for a redundant copy of data and things I don't care too much about. 3-2-1.\n This thing gets toasty though, the case is nice but isn't built well for airflow. I get way better performance leaving the outer shell off. It draws more power than I intended, might explore the Atom based platforms next.\n Max capacity of this this thing could be insane with ~100TB of HDD capacity, 48TB of 2.5\" SSD capacity, and another 40TB of NVM…",
          "link": "https://www.reddit.com/r/homelab/comments/ztacy0/jonsbo_n1_11_drive_itx_nas_5_hdd_6_25_ssd/",
          "publishedOn": "2022-12-23T08:35:01.000Z",
          "wordCount": 16009,
          "title": "Jonsbo N1 - 11 Drive ITX NAS (5 HDD, 6 2.5\" SSD)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zta2ub/the_4_dashboards_of_my_homelab_network_home/",
          "author": null,
          "description": "submitted by    /u/giuliomagnifico  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zta2ub/the_4_dashboards_of_my_homelab_network_home/",
          "publishedOn": "2022-12-23T08:16:46.000Z",
          "wordCount": 17205,
          "title": "The 4 dashboards of my homelab (network, home appliances, weather, pihole) + my homelab hardware",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zt2n5l/work_was_going_to_throw_this_away_they_didnt/",
          "author": null,
          "description": "submitted by    /u/JanitorPants  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zt2n5l/work_was_going_to_throw_this_away_they_didnt/",
          "publishedOn": "2022-12-23T01:14:09.000Z",
          "wordCount": 15122,
          "title": "Work was going to throw this away, they didn't understand why I would want it but were happy to have me take it from them.",
          "imageUrl": "https://external-preview.redd.it/Zh_zV_LkbzXBIc_Z63DpdoiEBLfqdk9EOPvBbmFGbF0.jpg?auto=webp&s=1c09ff1d8d4e4d5f15aca284b5acd529c6b9e841"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zt2mg4/looking_to_start_a_home_lab_will_this_be_enough/",
          "author": null,
          "description": "I am looking to make a home server to use as a homelab for mostly coding VMs and hosting a MC server. Will the following specs suffice? For 120 dollars: Intel xeon w3670 (6 core 12 thread) 24gb ram (only 1066 mhz I think D:) 500gb hdd (I'm not worried about boot times, and I plan to upgrade in the future) Quadro 600\n    submitted by    /u/UpbeatAardvark2307  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zt2mg4/looking_to_start_a_home_lab_will_this_be_enough/",
          "publishedOn": "2022-12-23T01:13:10.000Z",
          "wordCount": 14252,
          "title": "Looking to start a home lab. Will this be enough?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zt2c0z/pendulum_temperature_monitor/",
          "author": null,
          "description": "Seems reliable for detecting over temperature.\n    submitted by    /u/StraightOuttaCanton  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zt2c0z/pendulum_temperature_monitor/",
          "publishedOn": "2022-12-23T00:59:00.000Z",
          "wordCount": 14182,
          "title": "Pendulum temperature monitor",
          "imageUrl": "https://external-preview.redd.it/YLAF7P_HG6H367la65eyQVFpDqdr8pdwWMSMYymeMRM.png?format=pjpg&auto=webp&s=08419d22d0d42a38438f71527859820d51feccfe"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zt0ixo/how_do_you_guys_incorporate_homelab_experience_on/",
          "author": null,
          "description": "I've seen a number of articles on how to add Homelab experience to your resume, but can't seem to find any good ones on how to add it to your LinkedIn.\n    submitted by    /u/Aehri  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zt0ixo/how_do_you_guys_incorporate_homelab_experience_on/",
          "publishedOn": "2022-12-22T23:35:00.000Z",
          "wordCount": 14615,
          "title": "How do you guys incorporate Homelab experience on your LinkedIn profiles?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zszzzz/esxi_and_nas_on_same_hardwaredrives/",
          "author": null,
          "description": "New home labber, bought a Dell Optiplex 7040 for cheap to be me home server. Currently have ESXI up and running. I mainly want a NAS, Plex, Linux fuck around box. \n The machine currently has a 256Gb SSD and I have 2x 3Tb drives on the way. I’d like to use the Tb drives to be all of the storage for the VMs with some redundancy. \n Can I virtualize a TrueNAS or Unraid setup on part of the drives and leave part for storage on any other machines? Part of the use case would be virtualized Plex, pointing to files on the NAS. Is this a bad idea? What are my other options without spending money on additional hardware?\n    submitted by    /u/citrus_based_arson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zszzzz/esxi_and_nas_on_same_hardwaredrives/",
          "publishedOn": "2022-12-22T23:18:24.000Z",
          "wordCount": 15185,
          "title": "ESXi and NAS on same hardware/drives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zszyr6/ryzen_4300u_apu_passthrough_for_windows_10_vm/",
          "author": null,
          "description": "Hi, \n I am currently trying to pass through the 4300U APU on my Gigabyte Brix 4300U running Proxmox to a windows 10 VM. \n Unfortunately, I could not achieve any result despite following a guide on passing the graphic on 5700G. So the only hope I have right now would be to post something here.\n Really appreciate if anyone who have done this before could share what they did to make it work.\n Again, much thanks\n    submitted by    /u/Specialist_Track_430  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zszyr6/ryzen_4300u_apu_passthrough_for_windows_10_vm/",
          "publishedOn": "2022-12-22T23:17:14.000Z",
          "wordCount": 15013,
          "title": "Ryzen 4300U APU passthrough for windows 10 vm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zszuvx/holiday_homelab_checklist/",
          "author": null,
          "description": "Holidays Homelab Checklist 2022\n Are you ready for the holidays? Are you ready for the next year? Make sure you go through this basic checklist. Comment with suggestions.\n  \nDo you have backups? Have you tested restoration? (this should be a 24/7-365.25 day goal, but eggnog and family may spell disaster)\n If you’re hosting, is your guest network ready? Have you tested it DHCP and DNS? Is the password posted for all to see?\n If you’re hosting, have you made sure your computer and lab are locked up and protected? Some of us have LEDs and toddlers like things to grab and bright lights. So do drunk adults. And people in general. Assume it's not safe unless locked. Locked well.\n If you’re hosting, do you have decoys ready? \n If your family/guests ask you to work on their computers, are you read…",
          "link": "https://www.reddit.com/r/homelab/comments/zszuvx/holiday_homelab_checklist/",
          "publishedOn": "2022-12-22T23:12:52.000Z",
          "wordCount": 14863,
          "title": "Holiday Homelab Checklist",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsyqt6/controlling_desktop_pc_located_in_server_room/",
          "author": null,
          "description": "I just started a Truenas storage server, backup server, and moved all my networking gear to my \"server homelab room.\" I have a pretty specked out desktop PC I use for 4k video editing with Davinci Resolve studio on windows. Due to the size of the RTX 4090 and 360 degree rad, and with all my peripherals plugged in, it takes up a ton of space in my office. Moving my primary desktop to my server room so that everything is in one place and out of the way seems like an attractive idea. I was thinking of having my main desktop in my sever room running a VM software such as proxmox, vmware, or virtualbox with a windows VM connected to a 10G switch via ethernet, then adding a mini ITX build in my office connected to the 10G LAN network, and having the VM stream(not sure this is the right terminolo…",
          "link": "https://www.reddit.com/r/homelab/comments/zsyqt6/controlling_desktop_pc_located_in_server_room/",
          "publishedOn": "2022-12-22T22:25:48.000Z",
          "wordCount": 15392,
          "title": "Controlling desktop PC located in server room, with another computer located in office, via ethernet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsyesl/a_storm_is_coming/",
          "author": null,
          "description": "So I'm resilvering my 4th of 4 drives that I'm upgrading in my truenas scale nas. I'm at 60% completed with about 3.3 (of 9) days left to go. I don't have a ups and there's a good chance we'll have a power outage because of the storm headed to my part of the US tonight into tomorrow evening. Can/should I power down the nas now? Will it pickup where it left off when I boot it up again?\n Any insights are appreciated. TIA\n    submitted by    /u/SurenAbraham  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsyesl/a_storm_is_coming/",
          "publishedOn": "2022-12-22T22:11:35.000Z",
          "wordCount": 14594,
          "title": "A storm is coming",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsy144/what_is_the_optimal_number_of_ram_modules_for_a/",
          "author": null,
          "description": "​\n I am working on the RAM spec of a Dell PowerEdge R730 with dual Xeon E5-2620 v4\n ​\n The Xeon E5-2620 v4 CPU details listed here:\n https://www.intel.ca/content/www/ca/en/products/sku/92986/intel-xeon-processor-e52620-v4-20m-cache-2-10-ghz/specifications.html\n ​\n Here is the CPUs memory specification:\n https://preview.redd.it/g3uf4b5jti7a1.png?width=811&format=png&auto=webp&s=ebd3e791801cdc6833dda7aa789048690a80d99b\n According to the specification, Max number of Memory Channels is 4\n Considering that I have two of the CPU, is it safe to assume that the server perform better with 2x4 = 8 modules?\n If the answer is no, how do I find the optimal number of DDR DIMMs for the server?\n    submitted by    /u/RevolutionaryHunt753  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsy144/what_is_the_optimal_number_of_ram_modules_for_a/",
          "publishedOn": "2022-12-22T21:56:35.000Z",
          "wordCount": 15736,
          "title": "What is the optimal number of RAM modules for a server with dual Xeon E5-2620 v4",
          "imageUrl": "https://external-preview.redd.it/Hlbf52-zMgk3lZiQPiNlVwXxuQqfSuHNMRFDsvyExVQ.jpg?auto=webp&s=0402e358a1b5b71d7e7e3840908c20761a156712"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsx8sv/much_needed_and_cheap_upgrade/",
          "author": null,
          "description": "submitted by    /u/ilvyker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsx8sv/much_needed_and_cheap_upgrade/",
          "publishedOn": "2022-12-22T21:22:52.000Z",
          "wordCount": 14857,
          "title": "much needed and cheap upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zswv0u/finally_getting_2gbps_internet_and_have_some/",
          "author": null,
          "description": "I’ve been struggling for the longest time with 50mbps ISP service where I’m located. I just received a door hanger yesterday from Frontier that they’re expanding fiber to my address and it looks like I’ll be signing up for their 2gig service.\n With that in mind, all of my existing networking is setup at a pretty basic level since I’ve only been working with a 50mbps service. My setup comes from my ISP source and goes into a Linksys Velop WHW03 and then into a basic 1g switch that then goes to the rest of my network. Everything is utilizing Cat5 or Cat5e. I also have an UnRaid server running on a Dell R720 that I’d like to optimize for my network traffic since I run a Plex server, Nextcloud and other services on it.\n Frontier is running a promo where they provide a free Eero 6 mesh system during setup, so I should be ok from a router/AP standpoint.\n I’m mostly wanting to know what the most optimal, budget friendly setup would be from a cabling standpoint, and what network switch I should go with. I’m wanting to do it as cheaply as possible while still making use of the upgraded ISP speeds.\n Thanks!\n    submitted by    /u/lifeisruf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zswv0u/finally_getting_2gbps_internet_and_have_some/",
          "publishedOn": "2022-12-22T21:06:38.000Z",
          "wordCount": 15145,
          "title": "Finally getting 2gbps internet and have some questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsw4qc/h8sglf/",
          "author": null,
          "description": "Hey guys I’m trying to understand the purpose of this board and what it can do. I’ve done some research but I’m not really sure on what I’m looking at and it’s purpose, it has been sitting around my house for a while but I’d like to understand it and be able to utelize it. If anyone could educate me on this matter I’d be grateful.\n :D thanks\n    submitted by    /u/Tall_Author_8945  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsw4qc/h8sglf/",
          "publishedOn": "2022-12-22T20:35:19.000Z",
          "wordCount": 14610,
          "title": "H8SGL-F",
          "imageUrl": "https://preview.redd.it/ttme74y4xj7a1.jpg?auto=webp&s=2e650e261c40923d79cb61348094a7b70a09ee4c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsv2zo/best_use_of_150month_azure_credit/",
          "author": null,
          "description": "Through my employer I get a $150 azure credit/month. I’m planning on just using it for cloud storage for back ups (1TB) but from what ive seen that would eat up like $120-130. Better ideas? \n  \noff load game servers from my main server to the cloud\n off load some constantly running python scripts maybe?\n  \n   submitted by    /u/le_velocirapetor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsv2zo/best_use_of_150month_azure_credit/",
          "publishedOn": "2022-12-22T19:50:21.000Z",
          "wordCount": 15995,
          "title": "Best use of $150/month azure credit?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsudvu/got_old_ups_for_free_looking_for_purchasing/",
          "author": null,
          "description": "submitted by    /u/SonicDart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsudvu/got_old_ups_for_free_looking_for_purchasing/",
          "publishedOn": "2022-12-22T19:20:39.000Z",
          "wordCount": 15700,
          "title": "Got old ups for free, looking for purchasing advice for batteries.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsrl9y/dell_t620_issues_with_installing_server_2019/",
          "author": null,
          "description": "I am about to loose my ever-loving sh**. I have a T620 that I've put together with a mix-match of used parts I find on ebay in bulk. I paid 35 bucks for the server fully intact and have just upgraded since.\n When I was first getting started in automation and VMs I put a few things together in different raid configurations to try and test performance.. I never intended for anything to stay permanent because I was using used retired SAS drives in the raid. Well, you know how that goes, skip forward 4 years and things were left to collect dust and just run. A month or so ago my hass.io instance stopped responding and I kept putting it off until two weeks ago when we had a snow storm that kept me home for a week. I finally started digging in to it and found that one of the drives in my raid-0 …",
          "link": "https://www.reddit.com/r/homelab/comments/zsrl9y/dell_t620_issues_with_installing_server_2019/",
          "publishedOn": "2022-12-22T17:25:29.000Z",
          "wordCount": 16562,
          "title": "Dell T620 issues with installing Server 2019",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsokj9/connecting_proxmox_truenas_servers_via_peer_to/",
          "author": null,
          "description": "So I have a Proxmox server and TrueNAS server that I want to connect directly to each other to get 10GbE speeds between the two. Looking for the cheapest route. So I’m thinking of getting a 10g RJ-45 PCIE NIC for each server and connecting the two via CAT6. Then configuring each NIC with an IP on a different subnet than my current LAN. If my understanding is correct, this should work right? Wanted to upgrade my entire LAN to 10g but prices of switches and other needed hardware are kinda high right now. Also only really need 10g between the two servers. I can make it happen for around $30-$50 buying used NICs on eBay. Already have the CAT6 cabling.\n    submitted by    /u/Techie_19  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsokj9/connecting_proxmox_truenas_servers_via_peer_to/",
          "publishedOn": "2022-12-22T15:23:23.000Z",
          "wordCount": 15895,
          "title": "Connecting Proxmox & TrueNAS Servers via Peer to Peer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zso19e/recommendations_for_10gbps_switches/",
          "author": null,
          "description": "Hello, r/homelab,\n My ISP now offers 1.5+ gbps (3 gbps is already available, with 8 gbps coming early 2023). So that means upgrade time for my network.\n I have been looking for a 10 gbps switch/router, with a preference for a managed, L3 switch. 8+ ports (either copper of fiber as converters exists anyway). Interconnect is 2 X NAS systems, main desktop, 2-3 servers running Kubernetes (might be on a separate l2 switch as a bit far. None currently have 10 gbps adapters so will need to be purchased. All on copper at this time. Also I have APs and a few other devices that will remain on 1gbps. I already have a m,icrotik router that I can reuse (1gbps, 10 ports).\n I am in a fairly small space so noise is an important factor. Here is what im looking at for now:\n L3:\n New - Microtik CRS309-1G-8S+IN:\n Looks decent, 8 x sfp+ ports. I have experience with Microtik and am used top their OS, however specs are low, especially on L3. It is cheap and should be silent. about 280$USD\n Used - Arista DCS 7X series, 1U. 24X+ SFP+, good manageability, no experience with Arista but thats fine (I have dealt with Juniper and Cisco in the past). Worried about noise... About 400$USD on ebay.\n New - NETGEAR 10-Port Multi-Gigabit/10G Ethernet Smart Managed Pro Switch (MS510TXM) :\n Looks ok but I have heard of issues with Netgear stuff. Mostly copper so less work as installing fiber is more complex, however 2.5 gbps/10gbps copper is more expensive. Also 2x more expensive the others at about 600$USD. Might be worth the cost if silent and ok l3 features.\n I have also looked at Cisco and Jiuniper, but noise levels and cost are really high on those, so im really not sure it makes sense.\n L2:\n Ubiquiti Networks UniFi 8-Port 10G SFP+, looks ok, cost-effective, but out of stock everywhere.\n Anyone has go to models for this? Its a lot more complex then I taught it would be, so many options.\n    submitted by    /u/neurotix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zso19e/recommendations_for_10gbps_switches/",
          "publishedOn": "2022-12-22T15:00:04.000Z",
          "wordCount": 17509,
          "title": "Recommendations for 10Gbps+ Switches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsnnfo/two_nas_or_just_one/",
          "author": null,
          "description": "I'm planning on doing a major rebuild of my homelab, hopefully starting it this weekend, and completing by next. I've been going back and forth on whether I should keep a second NAS running for an additional backup location or not.\n The main NAS will be a TrueNAS and main pool will be a 5 disc raid z2 configuration. Raid is not a backup, I know this. I typically keep very important data also saved, less frequently, to an external HDD that spends most of its life unplugged.\n Finally I'm planning to hopefully get an offsite TrueNAS setup in either my office (different state) or mother's home (also different state) that I can remotely backup to.\n I have everything to setup a second unRaid at home. My thought is it's a second backup location, and using unRaid means I can just dump drives as needed into it to grow the pool with little thought to the structure compared to TrueNAS?\n Thoughts from you other homelabbers?\n View Poll\n    submitted by    /u/IroesStrongarm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsnnfo/two_nas_or_just_one/",
          "publishedOn": "2022-12-22T14:42:27.000Z",
          "wordCount": 15905,
          "title": "Two NAS or just one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsmfgl/nginx_reverse_proxy_docker_network_and_homenetwork/",
          "author": null,
          "description": "I want to use nginx reverse proxy to reverse proxy my home network and my docker network.\n If i visit docker1.mydomain.ns i want to access a container in my docker network.\n If i visit server1.mydomain.ns i want to access a server in my home network.\n All of them have the same public ip.\n What is the best way to archive this?\n    submitted by    /u/Transistor4aCPU  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsmfgl/nginx_reverse_proxy_docker_network_and_homenetwork/",
          "publishedOn": "2022-12-22T13:46:05.000Z",
          "wordCount": 19431,
          "title": "NGINX reverse proxy docker network and homenetwork",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsjl3o/how_to_isolate_a_vm/",
          "author": null,
          "description": "Hi all. I want to better secure my homelab by isolating the VM with internet facing services. Ideally the rest of the network should be able to talk to this VM, as one of the internet facing services is overseerr, and I'll need to be able to make changes with it anyway. But in the interest of security, I don't want someone accessing this VM then getting into the rest of the network from it. Does anyone have any advice on the best way to go about this?\n The VM is running in esxi and I'm using unifi networking gear\n    submitted by    /u/Malromen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsjl3o/how_to_isolate_a_vm/",
          "publishedOn": "2022-12-22T11:08:33.000Z",
          "wordCount": 15763,
          "title": "How to isolate a VM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsi3y0/got_a_new_domain_for_cloudflare_tunnels_2_days/",
          "author": null,
          "description": "I recently learned how to use Cloudflare Tunnels to expose services hosted at my home lab (the recent NetworkChuck Video). I got a new domain, linked a couple of my homelab services (jellyfin, tinytiny rss feed aggregator) to it and it worked great (having 500/500mbps fiber connection).\n 2 days later google flagged the main domain and all subdomains as dangerous (Phishing and malware).\n I connected my domain with Google Search Console/Webmaster tools, and it shows that the tinytiny-rss feed aggregator subdomain as the main culprit for the dangerous site.\n I removed the suspected hostname/subdomain from the tunnel 24 hours ago, and still my main site url is still flagged, and even many AV software and firewalls are continuously flagging my domain as malware. I was able yesterday to open my service in Chrome by click continue to the site, but now my AV and firewall refuses the connection.\n I requested google to re-check the domain, but it seems this is not going to work.\n Any tips? Why did even Google flag it? I never published the domain to anybody, it is just for personal use and personal services.\n    submitted by    /u/tech_engineer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsi3y0/got_a_new_domain_for_cloudflare_tunnels_2_days/",
          "publishedOn": "2022-12-22T09:42:17.000Z",
          "wordCount": 17285,
          "title": "Got a new domain for CloudFlare tunnels, 2 days later domain got flagged as dangerous.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsgs94/my_server_seems_like_hacked_and_encrypted_by/",
          "author": null,
          "description": "​\n https://preview.redd.it/sg58xd4zse7a1.png?width=2008&format=png&auto=webp&s=84d475637267ad4cffabfa109832448bf0abf30d\n    submitted by    /u/SatisfactionHead9119  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsgs94/my_server_seems_like_hacked_and_encrypted_by/",
          "publishedOn": "2022-12-22T08:23:02.000Z",
          "wordCount": 20035,
          "title": "My server seems like hacked and encrypted by hackers what can I do ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zsfdk9/any_12_bay_small_to_medium_size_case/",
          "author": null,
          "description": "My use case here is a 12 3.5in bay offsite backup. Grunt isn't really required outside of just being able to manage the disks, it's largely about the bays and if i can get unraid running on it. Hotswap is also something i would prefer due to how i store drives during transport. Not looking for anything rack mounted as that's just too much for this purpose.\n So i have two possibilities: \n  \nI can try to find a 12 bay case of the small to medium size variety and work around that(maybe with 5.25\" hot swap expanders?)\n I can find a consumer NAS that can have it's OS changed(i.e a terramaster, QNAP, etc) and use one of those if i can find one that isn't egregiously expensive, as they tend to have smaller form factors than most DIY cases.\n  \nAnybody have any ideas on suggestions for either the former or the latter? 12 seems to be a pretty odd non-rack form factor so there's not a whole lot out there i could find. Stuff like the QNAP TS-1655 might work but i couldn't find any to even get a price. The Terramaster T12-423 looked promising but i was wondering if i could find anything cheaper. Old consumer NAS units might be the way to go but i'm not familiar enough with the model numbers of said units to know what to search for. Most case searches yielded not a whole lot.\n    submitted by    /u/zeronic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zsfdk9/any_12_bay_small_to_medium_size_case/",
          "publishedOn": "2022-12-22T07:07:20.000Z",
          "wordCount": 16765,
          "title": "Any 12 bay small to medium size case possibilities? Or possibly retrofitting a consumer NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs83yg/thoughts_on_new_network_setup_omada_over/",
          "author": null,
          "description": "Situation\n I want to upgrade my network due to inconsistent performance (poor reception / unexpected drop outs of non-moving devices), and a desire to roam around my house without the network dropping while working from home. I'd appreciate any thoughts you all have on my plan.\n Constraints\n My brick house is a 2800 sq. ft. split-level with five half-levels that need coverage and a 1/4 acre backyard that needs coverage. Walls are a combination of plaster and drywall.\n Current Setup\n I'm current running a TP-Link Archer C9 router/AP (flashed with DD-WRT) from the top floor on one side of the house and a TP-Link powerline Wi-Fi AP to the third floor on the other side of the house. In general, it works pretty well when near the APs -- within 20 ft sphere of it.\n Proposed Setup\n I examined Ubi…",
          "link": "https://www.reddit.com/r/homelab/comments/zs83yg/thoughts_on_new_network_setup_omada_over/",
          "publishedOn": "2022-12-22T01:28:50.000Z",
          "wordCount": 14628,
          "title": "Thoughts on New Network Setup - Omada over InstantOn or UniFi",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs83hl/thoughts_on_swapping_an_hpe_jg927a_for_a_netgear/",
          "author": null,
          "description": "Hi everyone! Currently I'm using an HPE V1920-48G (JG927A) for my homelab and recently I was given a Netgear GS752TPP for free from work. I dug into the spec sheets for both and from what I can find they seem pretty comparable to each other (except for the Netgear having POE). \n I was wondering if anyone has had experience with one versus the other or knew of any features that one might have over the other. In general though, I'm just curious about people's opinions for whether I should \"switch\" (no pun intended) out what I have for what I received. As of right now, the only positive I can find for doing so is having POE. \n Thanks!\n    submitted by    /u/thebootsie123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs83hl/thoughts_on_swapping_an_hpe_jg927a_for_a_netgear/",
          "publishedOn": "2022-12-22T01:28:14.000Z",
          "wordCount": 14176,
          "title": "Thoughts on swapping an HPE JG927A for a Netgear GS752TPP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs81xl/can_i_use_this_wireless_card_to_broadcast_my/",
          "author": null,
          "description": "submitted by    /u/Saajaadeen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs81xl/can_i_use_this_wireless_card_to_broadcast_my/",
          "publishedOn": "2022-12-22T01:26:21.000Z",
          "wordCount": 14047,
          "title": "Can I use this wireless card to broadcast my homelab wifi network and allow clients to connect?",
          "imageUrl": "https://preview.redd.it/gd97zn1fqc7a1.png?auto=webp&s=1076b94835bcf521b2599355165a0ad2a0899d4e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs81nm/why_do_rj45_sfps_exist/",
          "author": null,
          "description": "Why wouldn't you just use an RJ45 port on the switch? I thought the purpose of SFPs was to easily connect different fiber connectors.\n    submitted by    /u/mopman34  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs81nm/why_do_rj45_sfps_exist/",
          "publishedOn": "2022-12-22T01:26:02.000Z",
          "wordCount": 14268,
          "title": "Why do RJ45 SFPs exist?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs6ru9/i_have_got_a_router_what_should_i_do_with_it/",
          "author": null,
          "description": "Hey guys i have got a technicolor TC7200.1dl router need suggestions what to do with it. Thinking about flashing it with ddwrt or openwrt but the device isnt listed in both sites also there isnt much info about hardware specifications. It has a single lan port and a coax connector.\n    submitted by    /u/jisaaddafifig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs6ru9/i_have_got_a_router_what_should_i_do_with_it/",
          "publishedOn": "2022-12-22T00:33:09.000Z",
          "wordCount": 15571,
          "title": "I have got a router what should i do with it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs6kfs/noise_levels_of_nas_hdds/",
          "author": null,
          "description": "I currently am planning to build a homelab, but I live in a very small studio apartment, so the PC must be in the room with me when I sleep. Currently I am planning on getting 3-5 WD Red Plus HDDs that I will RAID-Z together. How loud will these drives be? Is there any way I can cheaply quiet them down? For reference, I have an i7-8700k that I plan to cool with either 1 or 2 Noctua NF-A15 fans, which will hopefully be fairly quiet.\n    submitted by    /u/Corroddity  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs6kfs/noise_levels_of_nas_hdds/",
          "publishedOn": "2022-12-22T00:24:40.000Z",
          "wordCount": 14285,
          "title": "Noise levels of NAS HDDs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs4jhg/iscsi_san_w_3rd_party_drives/",
          "author": null,
          "description": "I have a Dell MD1200 I use with a H800 controller in my homelab. I would like to \"upgrade\" to a iSCSI SAN device so I can share volumes between multiple computers. I looked at the Dell MD3600f/i series but it appears they only work w/ Dell-certified drives (compared to my MD1200 which is running non-Dell 14TB drives at the moment)\n Can anyone recommend an iSCSI SAN appliance which will work w/ 3rd party 3.5\" SATA drives?\n    submitted by    /u/DisposableAccount712  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs4jhg/iscsi_san_w_3rd_party_drives/",
          "publishedOn": "2022-12-21T23:05:53.000Z",
          "wordCount": 15041,
          "title": "iscsi SAN w/ 3rd party drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs3t35/windows_server_install/",
          "author": null,
          "description": "Since I started my homelab around a year ago, I have been running windows 10 as my server with hyper-v. I have wanted to move away from JumpCloud and properly set up Active Directory on Windows Server 2022. I already moved all my VM's to a second hard drive (and physically unplugged it), so nothing important is on my C drive. I also made a windows server USB flash drive with Rufus, but I am not sure what the best way to install it is. My server is in my basement and does not have a monitor, keyboard, or mouse plugged into it. I have always used MeshCentral/Team Viewer to access it. \n Is there a way to remotely install Windows Server, such as through TeamViewer? Obviously, TeamViewer wouldn't work because the os is being installed, but there has to be an easier way than to sit there with a monitor and keyboard. Does anyone know of any software that would allow me to remotely install an OS, or even a way to install TeamViewer/MeshCentral after install automatically? I use NTLite to install Windows 10 with PowerShell scripts to install everything, but would that work for Windows Server?\n Edit: To clarify, NTLite does work for Windows Server, but even that still requires me to click on the screen to start the install. It’s a lot less clicks, but still requires interaction with a monitor/keyboard.\n    submitted by    /u/BothConsequence5513  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs3t35/windows_server_install/",
          "publishedOn": "2022-12-21T22:38:44.000Z",
          "wordCount": 14484,
          "title": "Windows Server Install",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs3rbk/hp_z620_max_specs/",
          "author": null,
          "description": "Hi guys. I just got my hands on a HP Z620 for relatively cheap and I plan to use it to learn more about Ubuntu server, containerization and multi-threading. What I have is the 2013 boot block version, with the CPU raiser card (2x Xeon E5-2603), 64 Gb Ram.\n I want to know what CPU would you recommend. I read the max core count for dual cpu is 16 core but I have seen that some second hand shops sell this with a configuration of 2x E5-2680v2 (10 core per CPU). Did i misread or the 2013 boot block motherboard supports more than 16 core total?\n Also I was thinking of upgrading to 2x E5-2667v2. What are your thoughts? Thanks\n    submitted by    /u/Bakersor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs3rbk/hp_z620_max_specs/",
          "publishedOn": "2022-12-21T22:37:19.000Z",
          "wordCount": 15033,
          "title": "HP Z620 max specs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs3qn2/how_do_you_set_up_idrac7_and_8_so_you_can_access/",
          "author": null,
          "description": "I've been smashing my head against this for a week, I want to be able to access the idrac web gui for my r720 and my r730 from a browser using a fully qualified domain name (ex: idracdnsname.dnsdomain.name ) instead of an ip address within my internal network.\n I tried setting idrac dns name and static dns name in idrac network settings but that didn't work.\n I don't know if I have to set up something outside of the idrac or what I have done incorrectly. \n Help would be very appreciated please.\n    submitted by    /u/Computer-bomb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs3qn2/how_do_you_set_up_idrac7_and_8_so_you_can_access/",
          "publishedOn": "2022-12-21T22:36:48.000Z",
          "wordCount": 14365,
          "title": "How do you set up idrac7 and 8 so you can access it with an fqdn?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs354g/requirements_for_grounding_a_patch_panel_in_wall/",
          "author": null,
          "description": "Residential. Texas, US. House built in 2015. The patch panel I purchased has come with a grounding wire. House is wired for UTP CAT5, and patch cables where used are UTP CAT6. CAT6 is used for two POE Unifi AP’s. The rack is wall mounted and the rack mount power strip is plugged into a UPS that sits on the floor, but will soon be wall mounted with a R720 server - very close to rack in question. There is a Unfii Dream Machine SE and QNAP NAS in the rack, both have three prong plugs. The POE ports on the DMSE will plug into patch panel and then continue on there way. \n Do I need to ground the rack? Should I ground the rack? If I do, can I attach ground cable to the rack and bolts where DMSE connects to the rack where there is bare metal? I don’t see a grounding point on the rack - although might have missed it. If my situation doesn’t require grounding, is there a possible home lab/networking upgrade path where I would need to ground? Thanks in advance for any advice. \n Links Patch Panel: Patch Panel 24 Port Cat6A with Inline Keystone 10G Support, Rapink Coupler Patch Panel STP Shielded 19-Inch with Removable Back Bar, 1U Network Patch Panel for Cat7, Cat6, Cat6A, Cat5e, Cat5 Cabling https://a.co/d/5G9LnNl Wall mounted rack: RackPath 12U Performance Wall... https://www.amazon.com/dp/B0995K2KRQ?ref=ppx_pop_mob_ap_share Rack power supply: StarTech.com 8 Outlet Horizontal 1U Rack Mount PDU Power Strip for Network Server Racks - Surge Protection - 120V/15A - w/ 6ft Power Cord (RKPW081915) https://a.co/d/8BzwjOO\n    submitted by    /u/hive5mind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs354g/requirements_for_grounding_a_patch_panel_in_wall/",
          "publishedOn": "2022-12-21T22:20:29.000Z",
          "wordCount": 15271,
          "title": "Requirements for grounding a patch panel in wall mounted rack. UTP cabling.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs2zha/double_plex_library_project_questions/",
          "author": null,
          "description": "Hey Homelab crew,\n I would like to setup a second plex instance from my current homelab, I would like to have the exact same library for now and I wanted to know what would be the best way to have it automatically do that. Is there a way one Ombi request can populate or communicate with 2-3 sonar and radarr instances ? Thanks for any info\n    submitted by    /u/Iceman-1317  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs2zha/double_plex_library_project_questions/",
          "publishedOn": "2022-12-21T22:15:31.000Z",
          "wordCount": 15164,
          "title": "Double plex library project questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs2t4r/homelab_setup/",
          "author": null,
          "description": "Ok, so I know I have a lot of options here but Im throwing this out there for some recommendations. I started building a lower end Home Lab without going full server or even full NAS. I have two different Macbook Pros that I work on. Here is what I have:\n  \nLenovo ThinkCentre M910Q Tiny Desktop Computer, Intel Core i7-6700T , 32GB RAM, 1TB NVMe SSD\n 4 Raspberry Pis 8GB RAM with SSD drives and cables\n 1 Raspberry PI 4 GB RAM with SSD\n Couple of TP Link desktop switches\n Protectli 2 port running OpenSense\n Older Apple Time Capsule 1TB\n  \nCurrently running a pi server with a variety of Docker containers (Ad Guard, Homepage, Grafana, Prometheus, portainer, Bitwarden, Homebridge\n OMV NAS with 3TB also running Plex, Nextcloud, FileBrowser, Portainer and Yacht\n Home Assistant on a Rasp Pi\n Will have two clean Rasp Pis and the ThinkCenter...Im thinking Proxmox on the ThinkCenter, not sure about the rest. What are some options and should I go Proxmox on the Lenovo?\n Interested in home automation, learning and just general tinkering.\n ​\n ​\n    submitted by    /u/djshaw0350  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs2t4r/homelab_setup/",
          "publishedOn": "2022-12-21T22:10:54.000Z",
          "wordCount": 14166,
          "title": "Homelab setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zs1vzm/question_about_the_future_of_10g_baset/",
          "author": null,
          "description": "I have been wiring rooms in my house with some Cat 6 ethernet cables (20-30m) as I wanted some future proofing for 2.5Gbe, 5Gbe and potentially 10Gbe. Currently 10Gbase-T seems very demanding on amount of power draw and the cooling required for anything more than just a single port. I know there are fiber options but bending OM3 cables around corners fills me with dread.\n Just wanted to know is the power draw due to the amount of processing required to send and read data? Will power/heat come down in the future as we get more efficient/faster chips to the point where we can get affordable consumer grade switches/routers. Was transitioning from 100 mbe to 1 Gbe similar in that the power/heat was significant but came down over time?\n    submitted by    /u/binary101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zs1vzm/question_about_the_future_of_10g_baset/",
          "publishedOn": "2022-12-21T21:44:02.000Z",
          "wordCount": 15552,
          "title": "Question about the future of 10G Base-T",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrveci/computer_infrastructure_in_your_garage_workshop/",
          "author": null,
          "description": "Hey all, as I have a bit of free time during the holidays, I'm beginning to think about building out some network infrastructure in my garage which mostly serves as a wood working workshop, but which also includes a workbench that I use for some minor experimentation with ham radio and electronics. I currently have two POE cables running into the room to power a pair of POE cameras that I use to monitor a feral cat that I feed inside, but I don't have any other cabling currently: it's a blank slate.\n Basic needs are perhaps six or so ports that are routed to my electronics bench, another four or so which are POE ports that I can use to power my existing cameras, plus an extension, and maybe an inexpensive 2.4G access point to provide more reliable access to some Tasmota sensors. I currently am using a https://www.amazon.com/gp/product/B08GS211V9 hooked to my pfsense router, which may get repurposed out to the garage. 1GB networking is probably fine here, I'll probably create a subnet using one of the spare ports on my KingNovy pfsense box, which technically opens up the possibility of 2.5GB networking, but no device I'm likely to have in the garage \n Has anyone else done something like this? I am interested in seeing other similar small network setups. The environment is likely to be fairly dusty (working on better dust collection in the shop, but again, that's another project). I'm probably going to build a small case to house the major bits, with just a small switch mounted to the workbench, with some little silicone dust caps to keep the worst of the dust out when not in use? \n I recognize this isn't a very fancy project, but I'm interested in doing a better job than just laying cables around everywhere willy nilly.\n Thank you all for your advice!\n    submitted by    /u/CommitteeTop5321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrveci/computer_infrastructure_in_your_garage_workshop/",
          "publishedOn": "2022-12-21T17:42:20.000Z",
          "wordCount": 15733,
          "title": "Computer infrastructure in your garage workshop?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrtw5t/dont_expect_a_raspberry_pi_5_next_year/",
          "author": null,
          "description": "submitted by    /u/jesse_james  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrtw5t/dont_expect_a_raspberry_pi_5_next_year/",
          "publishedOn": "2022-12-21T16:49:54.000Z",
          "wordCount": 15692,
          "title": "Don’t Expect a Raspberry Pi 5 Next Year",
          "imageUrl": "https://external-preview.redd.it/f7XBrrI-7LP8t6T_uNwtDo0a9dIsrCHItSdmOTGc_DQ.jpg?auto=webp&s=f3ccef45180a3b46f984eb08e952ffc49084d324"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrt3t0/help_me_to_identify_the_ram_module/",
          "author": null,
          "description": "​\n https://preview.redd.it/jf642css1a7a1.jpg?width=2016&format=pjpg&auto=webp&s=d36ac9ed6c2a59c205423a3db9943a48587a0606\n Here I'm sharing two RAM module, on first.jpg (above) I can easily identify its DDR3 12800 (Mhz) to replace the ram i have to take care of these number\n But look at the below image second.jpg RAM module has weird marking that i do not understand, can someone help me to understand what is this marking and what could be the replacement\n second.jpg\n Second.jpg is installed in leptop if i replace it with first it does not work, but i checked first.jpg in some other laptop its working fine as well. \n ​\n ​\n    submitted by    /u/sairfan1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrt3t0/help_me_to_identify_the_ram_module/",
          "publishedOn": "2022-12-21T16:26:49.000Z",
          "wordCount": 15259,
          "title": "Help me to identify the RAM module",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrrbfy/do_i_need_unraid/",
          "author": null,
          "description": "Specs: i5 Gen 11, 32 gb ram, 3 HDD (4tb + 1tb + 500gb) , 500gb NVME SSD, 3 16TB HDD (to be installed after rebuild)\n Currently, I am running Proxmox and have 4 VM + 4 LXC running on it. I have the following services: https://imgur.com/a/POaQFhG\n I want to have redundancy on my drives. I initially planned on installing OMV and using RAID5 config. for the drives. The machine will be used for media storage only. I have another machine for NAS stuff. I plan to backup all the media to Backblaze B2.\n I recently was in talks with a developer for Bazarr app, he suggested that I go with unRAID. So, I got a trail for unRAID. It's nice and simple. Few click here, few click there and you are done.\n I managed to mock migrate all my current services to unRAID docker containers just fine. Played around with caching too.\n After using it for about a week, I am still questioning whether it is a necessary purchase for me.\n My main questions are:\n  \nHow different is unRAID's parity disk approach from RAID5?\n How reliable is OMV?\n Most importantly, do I need unRAID?\n  \n   submitted by    /u/trainwreck_summer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrrbfy/do_i_need_unraid/",
          "publishedOn": "2022-12-21T15:44:11.000Z",
          "wordCount": 17066,
          "title": "Do I need unRAID?",
          "imageUrl": "https://external-preview.redd.it/b6crZmHgAC7CxXBFEb6MBuot2mehNBC2ATmoWhg-Eog.jpg?auto=webp&s=52b641a46b6dc1e70e52a78be1dc50116f4ca261"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrkpkm/what_is_your_disaster_recovery_plan/",
          "author": null,
          "description": "I came across a good article in a magazine about how one should have a good disaster recovery, whether is from a data breach or data disaster. Also the importance of offsite backups and data encryption. I wanted to know how many of us have an actual plan to go from 0 to 100% recovered.\n    submitted by    /u/D3imOs8910  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrkpkm/what_is_your_disaster_recovery_plan/",
          "publishedOn": "2022-12-21T12:54:20.000Z",
          "wordCount": 18524,
          "title": "What is your disaster recovery plan?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrklre/thoughts_on_my_setup/",
          "author": null,
          "description": "​\n https://preview.redd.it/bk9ycj4hz87a1.jpg?width=4000&format=pjpg&auto=webp&s=22be43abeed338b64783992d54d5b8296a9d9fbd\n My Home lab Setup.\n  \nDesktop Server \n \nAsus Chromebox 3 with custom BIOS and Proxmox \n \nTP-Link AXE95\n \nTP-Link AX50\n \n350/350 Mbps ISP Fiber Connection\n \n ​\n A. Desktop Server \n  \nIntel i5 3570K \n \n16GB DDR3 RAM \n \nGTX 1650 (Plex Transcoding)\n \n16TB SATA Storage (4*4)\n \n2 Gigabit NICS\n \nUnraid \n \n B. Asus Chromebox\n  \nIntel i7 8550U \n \n16GB DDR4 \n \nWifi 6\n \nGigabit NIC \n \n2 Ubuntu Servers, 1 Win 11 & OpenWRT VMs\n \n Using AXE95 as my main access point as it gives near gigabit throughput on wifi 6. \n Using AX50 with Proxmox Openwrt & Nordvpn as a VPN router. \n ​\n What you guys think ?\n    submitted by    /u/adasmalakar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrklre/thoughts_on_my_setup/",
          "publishedOn": "2022-12-21T12:51:32.000Z",
          "wordCount": 16196,
          "title": "Thoughts on My Setup ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrgmwr/iperf3_between_openmediavault_servers_only/",
          "author": null,
          "description": "I'm pulling my hair out over this, but I have 2 openmediavault servers that I'm running (one is going to be the new daily driver and the other will become my backup machine). I want to get evertyhing copied over from the existing one and I have dual 10gig NICs in each of them so I'd like to use that lane for the initial copy and subsequent scheduled backup.\n I have the 10gig interfaces configured like so for each server (only posting the image of one)\n ​\n https://preview.redd.it/hfpn8913b87a1.png?width=2358&format=png&auto=webp&s=a148539f3913b3b9c8480d1c5971d30690d9fece\n When I run iperf3 from one of them as the 'server' and the other as the 'client' I can't get more than 980 mbps for transfers. One thing to note: when I run the client command I use the IP of the other server, but it's not the IP of either of the above interfaces. If I try to call it with one of the 10gig IPs from the image above it just hangs there.\n So i feel like the issue with my test is that iperf3 isn't actually using the NICs for the transfer. Am I doing something wrong in iperf or in the setup, or both?\n    submitted by    /u/FourTimesRadical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrgmwr/iperf3_between_openmediavault_servers_only/",
          "publishedOn": "2022-12-21T10:34:46.000Z",
          "wordCount": 17630,
          "title": "iperf3 between openmediavault servers only showing up to 980mbps with 10gig cards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrgh4o/bought_2_raspberry_pi_4_accidentally/",
          "author": null,
          "description": "So wanted to buy one rpi but bought 2 with bunch of sensors etc. Now no option to cancel. Bit pissed with myself but also excited... Give me some cool project ideas, please 😂\n    submitted by    /u/adasmalakar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrgh4o/bought_2_raspberry_pi_4_accidentally/",
          "publishedOn": "2022-12-21T10:25:04.000Z",
          "wordCount": 15042,
          "title": "Bought 2 Raspberry Pi 4 accidentally!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zrdg4w/taking_care_of_a_friends_sugar_glider_for_a_few/",
          "author": null,
          "description": "submitted by    /u/feelingsupersonic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zrdg4w/taking_care_of_a_friends_sugar_glider_for_a_few/",
          "publishedOn": "2022-12-21T07:20:35.000Z",
          "wordCount": 16698,
          "title": "Taking care of a friend's sugar glider for a few days. They like warm temperatures, so Penny is now A+ certified.",
          "imageUrl": "https://preview.redd.it/xsrfhdppc77a1.jpg?auto=webp&s=13ec89cebcf20e4039eaa1ef71dcc510e77eec59"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr5gzm/homelab_firewall/",
          "author": null,
          "description": "Hello, I am thinking of buying a used firewall for my homelab from ebay. I just bought a 42u server rack, and I just upgraded one of my Dell Powervault DR4100 server with 192GB of memory. I also have a cisco catalyst 4948 switch as well. I was thinking of buying a Forigate Fortinet firewall, I have seen other people recommend untangle firewall as well. I have heard mixed reviews on both. I was wondering, If I am correct in saying, that if the license is expired, I cannot use most of the features. Including the web filtering feature. Is there any firewall I can buy off of ebay to either test or possibly implement down the road with that doesn't require a license to use these features?\n Thank you.\n    submitted by    /u/IceCreamMan1776  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr5gzm/homelab_firewall/",
          "publishedOn": "2022-12-21T00:49:43.000Z",
          "wordCount": 14209,
          "title": "Homelab firewall.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr52zt/looking_for_long_endurance_ssds_12tb_1pbw/",
          "author": null,
          "description": "I am looking for some advice regarding ssd choice for a new system\n (planing to run 3 in raidz1 for vms + logging and another 2 for caching)\n Since it should last as long as possible and the server is going to be used for extensive writing (logging as well as cache for some jbods/hdd pools) i am looking for at least 1pbw better 4+pbw lifespan.\n I already looked through used enterprise ssds on ebay for a couple hours but didnt decide yet.\n One that caught my attention is the Toshiba THNSN81Q92CSE (1.92tb for 120$) but i couldnt find any documentation regarding lifespan.\n Would it be a good choice?\n I also looked through many intel ones but got a bit confused regarding their naming (and vastly different endurance ratings according to the wikipedia article)\n What can you recommend?\n    submitted by    /u/Pommes254  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr52zt/looking_for_long_endurance_ssds_12tb_1pbw/",
          "publishedOn": "2022-12-21T00:37:34.000Z",
          "wordCount": 14245,
          "title": "Looking for long endurance SSDs | 1-2tb | 1+pbw",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr52np/looking_for_help_flushing_out_my_new_setup/",
          "author": null,
          "description": "I have a new machine I have built that I am looking to help work the way I envision, and need some help ensuring I know what I need next to make this happen. I apologize as I am a bit of a noob both proxmox and zfs.\n Machine Ryzen 5700x, msi b550m pro-vdh wifi, 16gb ram.\n pci sata card: https://www.startech.com/en-ca/cards-adapters/pexesat322i\n Drive 1x 500gb SSD, 3x3TB HDD, 1x1TB HDD\n Looking to run Proxmox, and virtualize unRaid purely as a NAS, and using proxmox as I need to virtualize a couple other environments.\n I did one pass and got everything up and running with proxmox install in xfs, however I want to encrypt all of the drives.\n Following the guide here I can encrypt the Proxmox install:\n https://herold.space/proxmox-zfs-full-disk-encryption-with-ssh-remote-unlock/\n ​\n However, I need a sanity check on what I need to do to make this work effectively:\n  \nGet another SSD, and install it zfs in raid1 on JUST the SSDs and encrypt the zfs\n Get a larger pci raid card and pass through the pci card with all drives to unRaid have unraid encrypt xfs / zfs and manage\n Get a 3rd SSD for a cache drive connected to the raid card, or can I virtualize this from extra space on the zfs drives\n Backup all my files from my VM's on unRaid\n  \nOption 2: Set all drives to ZFS (pool 0 - SSD) (pool1 - HDD) by proxmox and nas some other way.\n Option 3: Option 2 + Pass virtualized drives to unRaid? I think I lose access to smart data etc if I do it this way.\n My goal is just encrypted fault resistant storage of my VM's and Data.\n    submitted by    /u/c_o_f_f_e_e  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr52np/looking_for_help_flushing_out_my_new_setup/",
          "publishedOn": "2022-12-21T00:37:13.000Z",
          "wordCount": 14503,
          "title": "Looking for help flushing out my new setup",
          "imageUrl": "https://external-preview.redd.it/s6zz1vUgVar8Sy-ud-LjA71yJTC-3ExGVoRv89-qCq0.jpg?auto=webp&s=cd3944b7221dfd2739453fd3533007aeebb63c64"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr45uw/my_attempt_at_a_homelab_from_old_work_pc_and/",
          "author": null,
          "description": "submitted by    /u/Important-Duty-5608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr45uw/my_attempt_at_a_homelab_from_old_work_pc_and/",
          "publishedOn": "2022-12-21T00:06:37.000Z",
          "wordCount": 14332,
          "title": "My attempt at a homelab from old work pc and server.",
          "imageUrl": "https://preview.redd.it/zhym6q24p67a1.png?auto=webp&s=e43f3949760b02cfbc790d0b4039ba6e673c000d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr3pxr/building_a_home_lab_for_nas_and_machine_learning/",
          "author": null,
          "description": "Hey everyone, my name is Jay\n I am currently in the possession of three Dell T5810s with varying specifications that I want to turn them into a NAS storage, regular PC, and a machine learning workstation, but to make the purpose of all of these machines easier, I'm just going to call them - Alpha, Bravo, and Charlie. Here's the current specification for each of these machine once I upgrade the CPU: \n Alpha Machine\n  \nIntel Xeon E5-2650v4\n 16GB (2x4) DDR4 RAM\n Nvidia GTX 1060\n Samsung 500GB EVO Drive\n used Western Digital 1TB 7200RPM Drive\n \n425W Dell Power Supply\n Bravo Machine\n \nIntel Xeon E5-2650v4\n \n16GB (4x4) DDR4 RAM\n \nNvidia Quadro 600\n \nNvidia Quadro K2200\n \nSamsung 500GB EVO Drive\n \nused Western Digital 1TB 7200RPM Drive\n \n425W Dell Power Supply\n \n Charlie Machine\n  \nIntel Xeon E5-…",
          "link": "https://www.reddit.com/r/homelab/comments/zr3pxr/building_a_home_lab_for_nas_and_machine_learning/",
          "publishedOn": "2022-12-20T23:48:03.000Z",
          "wordCount": 14728,
          "title": "Building a home lab for NAS and Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr2dki/i_recently_passed_my_a_and_im_excited_to_get/",
          "author": null,
          "description": "I’ve tried using Virtual box to install Server 2016, Parallels and tried using Azure but keep getting repeated errors. \n I’ve googled a ton and watched a ton of YouTube videos on how to set up windows sever as a VM. I’ve also read a few things which suggest that it is not possible to set Windows sever on a MacBook with an M1 processor. \n Does anyone have any other suggestions of how I could set up windows sever and AD? Thanks in advance.\n    submitted by    /u/GlassMountain9473  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr2dki/i_recently_passed_my_a_and_im_excited_to_get/",
          "publishedOn": "2022-12-20T22:53:28.000Z",
          "wordCount": 15227,
          "title": "I recently passed my A+ and I’m excited to get started in IT. For the past 2 days I’ve been trying to set up Windows sever on a VM on a MacBook Pro M1 and have encountered a few issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr250h/acquired_a_poweredge_t130_with_7tbs_of_hdd_space/",
          "author": null,
          "description": "Hey y’all. It came with 3x 2tb 3.5 and 1x 1tb 3.5\n Questions are.\n Can I put more HDD’s in? Maybe some 2.5?\n If I set it up as a NAS now then decide later I want bugger HDDs can I just add them to the system or do I need to start a new instance of the NAS some how? \n Lastly, TrueNAS scale or core ?\n    submitted by    /u/Dev-N-Danger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr250h/acquired_a_poweredge_t130_with_7tbs_of_hdd_space/",
          "publishedOn": "2022-12-20T22:43:43.000Z",
          "wordCount": 14149,
          "title": "Acquired a poweredge T130 with 7Tbs of Hdd Space. Planning on using this for NAS but have a couple questions…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr0yok/which_type_of_switch_should_i_get/",
          "author": null,
          "description": "I am new to the home lab environment and I am wondering whether I should get a managed or unmanaged switch. I have done some research before posting here but i am still unsure.\n I have read many articles saying that managed switched are useful for homes that have a lot of IoT devices, which I have a ton of (smart lighting, smart sockets and digital assistants in almost every room of my house). I don't know if the ability to create VLANs will be necessary for me as it will only be used for my main machine and 2 servers, one that will be running a webserver and a game server, each in its own docker container and then the other as a NAS.\n Based on this would it be worth getting a managed switch anyway, and spending the time learning the necessary network management skills, or just getting an unmanaged switch for the simplicity.\n    submitted by    /u/nuratic0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr0yok/which_type_of_switch_should_i_get/",
          "publishedOn": "2022-12-20T21:56:52.000Z",
          "wordCount": 15149,
          "title": "Which type of switch should I get?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zr029g/looking_for_a_hardware_vpn_gateway/",
          "author": null,
          "description": "Hey!\n My homelab grows little by little, and I want to have access to it outside of my LAN, via VPN. Now, I could install Wireguard on my server, but I mess a lot with it, and it has big chance of being broken. More over, since it's a simple ThinkCentre that does not support wake-on-wan, theoretically I could lose connection in case of power outage while I'm away.\n So I'm looking for a dedicated device that will run only VPN, and maybe DNS (AdGuard Home). I could get a Pi for that, but I kind of don't understand their point. They are not cheap, and they run on SD cards which a prone to corruption (eventually).\n Another option is to run the VPN on my router, but Omada currently supports only OpenVPN and not Wireguard, and I have no idea when, or if, they will support it.\n I found this one GL.iNet - GL-MT2500 / Brume 2 which is in pre order and pretty affordable. It runs Wireguard and AdGuard home, and acts as both VPN server and client. I've heard about GL.iNet before, but I still worry about their reputation (although it seems they run mainly on open source software).\n Appreciate if someone can shed some light on that particular device or suggest something else.\n Thanks!\n    submitted by    /u/skwee357  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zr029g/looking_for_a_hardware_vpn_gateway/",
          "publishedOn": "2022-12-20T21:21:11.000Z",
          "wordCount": 15136,
          "title": "Looking for a hardware VPN Gateway",
          "imageUrl": "https://external-preview.redd.it/d9CE0i8tWzmBbSItKfejFKjaJN8gNMJM4GbTv3PFAYY.jpg?auto=webp&s=a5c224bfa9cacc525a37c7cdfbebabdc07681b88"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqzp5h/help_evaluating_lsi_92118i_authenticity/",
          "author": null,
          "description": "Hey gang, I've spent a solid day of interspersed researching on these cards and found a lot of guidance that says these things usually have an LSI logo, but not neccesarily that its fake if it doesn't. I bought https://www.ebay.com/itm/155042469639 this card recently and it hasn't arrived yet, but I'd love to understand if there are any signs this is either legitimate or fake from the stock images.\n Particulary, it looks like it has the words \"FastPCB\" where I'd expect a logo to go. However, the seller has extensive and positive feedback (5 digits of positive). \n The card itself looks to be an Inspur with a model #YZCA-00019-101 found on the back of the image. \n I tried googling for this metadata and found nothing really to say yes or no for counterfeit signs or if the logo should be missing.\n Basically I'm struggling to reach a good stopping point here and would love this squad's advice on any and all analysis of this offering's legitimacy. \n Thanks so much in advance.\n    submitted by    /u/cadorett  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqzp5h/help_evaluating_lsi_92118i_authenticity/",
          "publishedOn": "2022-12-20T21:06:57.000Z",
          "wordCount": 14579,
          "title": "Help evaluating LSI 9211-8i authenticity",
          "imageUrl": "https://external-preview.redd.it/l25Q1ECbqNx-4aWFMaA3F-xarkYoOMZKPgqdKMUFsB0.jpg?auto=webp&s=a71454b5641a2ce550e090e77f9140e52460505a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqydo9/help_with_permissions_of_an_smb_share_from/",
          "author": null,
          "description": "Edit: I forgot to add the UID and GID of the users needing access to the share when mounting in CIFs.\n ​\n Hi All, not sure if this is the best place to post, but thought I'd try.\n ​\n I'm rebuilding some of my VMs and am running into some permissions problems. I am able to write to the share with one VM, but not the other, with the built in user 'radarr'.\n ​\n Both the old (left) and the new (right) VMs have the same SMB share mounted to /mnt/media using cifs. The cifs credentials are the same in each VM and allows me to have full control of the data from TrueNAS under my admin user 'andrew'.\n ​\n You can clearly see in the picture that the permissions of the old VM are set as rwxrwxrwx, while the new is missing write for groups and other. I believe I may have used chmod -R 777 /mnt/media on the old VM, but I honestly can't remember and I'm not sure how to see this (I've since started documenting all changes I make and what they do so this won't happen in the future). I'd also prefer to not 777 an entire dataset, even if it is not sensitive data.\n ​\n I know I can fix this by changing the user running the service, but I want to keep the radarr service running as the user radarr as that is best practice for linux.\n ​\n Any help or pointing to an article I can read would be much appreciated.\n ​\n https://preview.redd.it/yhhsy9tew37a1.png?width=1766&format=png&auto=webp&s=fa73c6aa0cdebb300cd8f1bbe9b1fc186a4ecbaf\n    submitted by    /u/WhatsAQazza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqydo9/help_with_permissions_of_an_smb_share_from/",
          "publishedOn": "2022-12-20T20:14:08.000Z",
          "wordCount": 16095,
          "title": "Help with permissions of an SMB share from TrueNAS on a Linux VM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqy6sb/where_do_you_store_encryption_keys/",
          "author": null,
          "description": "I'm starting to setup backups of my VMs/containers, and want to make sure everything is encrypted when it goes to backblaze...but what if I lose the key/salt? Currently I have\n  \nVM backups important data in .tar.gz files daily\n VMs add the .tar.gz files to an NFS share running on truenas\n Truenas runs multiple snapshots and uploads dataset to B2 with an encryption key/salt\n  \nEverything seems fine and I have reminders to test it...but where do you safely story those keys? Currently I wrote it down on a sticky note in my wallet and in bitwarden. Safe enough lol?\n    submitted by    /u/MeerkatMoe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqy6sb/where_do_you_store_encryption_keys/",
          "publishedOn": "2022-12-20T20:06:17.000Z",
          "wordCount": 15529,
          "title": "Where do you store encryption keys?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqx96g/rebuilding_the_home_network_is_a_unified/",
          "author": null,
          "description": "Hi /r/homelab,\n I've been deep in research for weeks now looking into all the possible ways to go for a home network rebuild. For a long time I was putting a high value on unified management / SDN solutions like Unifi or TP-Link Omada, but I am beginning to rethink that. It seems like both platforms have the kinds of drawbacks (support, hardware quality and availability, feature roadmaps that never materialize) that I would find endlessly frustrating as someone with a day job in IT.\n I know the sub is geared more toward learning and experimentation, and I value that too, but I have to balance that with reliability and availability of the network, particularly as I work remotely. Central management seemed very appealing for a no-nonsense setup, but now I am less sure that I will see long-term value from buying into such a stack.\n So I'm looking for input on this -- is the single pane management of something like Unifi or Omada worth the other headaches from these companies? Or would I be better served going with older \"best of breed\" enterprise equipment for switching and wireless, paired with something like pfSense for routing? I lose the central management, but it seems clear that I would have better hardware for similar expense.\n If you lean enterprise in your response, please mention what hardware you prefer for APs, switching, and routing. I would especially like to hear your opinions on mixed environments. ATM I am considering Ruckus AP / Aruba ION switching (local control) / pfSense as a potential build if dissuaded from Unifi or Omada, for example.\n    submitted by    /u/DullFuplex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqx96g/rebuilding_the_home_network_is_a_unified/",
          "publishedOn": "2022-12-20T19:29:00.000Z",
          "wordCount": 17218,
          "title": "Rebuilding the home network. Is a unified management stack (e.g. Unifi) really worth the drawbacks of such a platform?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqwo4m/expanded_storage_for_a_bitfenix_ghost_case/",
          "author": null,
          "description": "Hello r/Homelab,\n I've recently come into 8x6TB WD Red drives and I plan to configure these all in RAID6. I've already got an LSI-9211 RAID card for the setup.\n My problem is that my case, which I otherwise love, doesn't have enough storage for 8 3.5\" drives. Here's a link to the specs of the case that I have and it only has 4 internal 3.5\" bays. I'm okay with removing any or all of the 2.5\" bays or the 5.25\" bays if needed, but I haven't found a suitable storage method for what I would put in place for those drives.\n Has anyone had experience or luck expanding storage in their homelab? Are there any other concerns I should be aware of? I know heat may be an issue, but there are two 80mm fans directly in front of the drive bays, and the processor is watercooled by a Swiftech H220 so the internals of the computer don't get too hot as it's configured now.\n    submitted by    /u/Ponderputty  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqwo4m/expanded_storage_for_a_bitfenix_ghost_case/",
          "publishedOn": "2022-12-20T19:05:46.000Z",
          "wordCount": 15257,
          "title": "Expanded storage for a BitFenix Ghost case?",
          "imageUrl": "https://external-preview.redd.it/A5d58aFKsRHnVxTf5Ohr80852B4FclBcJltwzKF_wF0.jpg?auto=webp&s=3b05ec3e127740af13862c31dfa651d7c908dc43"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqvxjh/dell_r210_ii_still_a_good_option_for_pfsense/",
          "author": null,
          "description": "I'm currently running my pfsense virtualized under proxmox on a small white-box i prepared myself. The thing is that I've become tired of the problems of not having it bare metal and I'm seeking for a new box.\n I've come into an offer for a r210 II and I've read good things about it, but i was wondering if it is old info and if there are currently better options.\n I have several vlans and unfortunately my switch showed as a fake L3 one, so i need inter-vlan routing at router level. But i also seek for low power consumption, as my homelab runs on sun power. 😎\n I bought two NUCs, but they simply didn't seem good to use them for pfsense. I repurposed them as Iot machines.\n Thanks guys for your suggestions 🙂\n Edit: Ah, and I'm running it on a stick, i would put a 10gbe card on it.\n    submitted by    /u/Qbic_dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqvxjh/dell_r210_ii_still_a_good_option_for_pfsense/",
          "publishedOn": "2022-12-20T18:36:41.000Z",
          "wordCount": 16746,
          "title": "Dell r210 II still a good option for pfsense?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqs9kj/looking_for_opinions_on_thinclient_rtsp_streaming/",
          "author": null,
          "description": "Some backstory before the question:\n I've had some suspicious activity in my neighborhood lately. I have some outdoor facing PoE cameras on my network that are currently accessible to the internet so we can view them when not home (using BlueIris). I've been doing some more networking at work and want to really isolate everything correctly on my home network. Separating the cameras and BlueIris VM onto their own vlan, setting up routes to only allow certain IPs to connect, things like that. I think it would be good exercise to learn more on networking along with properly securing my network.\n The end goal is to view the RTSP streams of the cameras on a single monitor without having to RDP into my blue iris VM. Being able to do that without having to do anything except start the device would be great too, but thats more of a wish because I don't know if it is possible yet.\n I've been looking at Thin-Clients like a Dell Wyse 3040 or an HP T620 to view camera streams either through VLC or to just load a webpage that is hosting the RTSP streams on. I see a lot of raspberry pi suggestions online for my use-case, but the shortage and prices make it completely out of the question. I want to have this device on the same vlan as the cameras/BlueIris VM/Webserver hosting the streams, only connected to a monitor so my non-tech-savy other half doesn't have to do anything but turn the monitor on. \n The question:\n Has anyone used thin-clients to achieve something similar? I don't think viewing the streams is that resource intensive, but I don't have any experience with thin-clients. Are they are powerful enough to view all the streams at the same time, whether on VLC locally, or viewing them on a webpage? I figured I would take a shot in the dark and ask before spending anything on this idea.\n Thank you for reading and considering my rambling\n    submitted by    /u/damiwork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqs9kj/looking_for_opinions_on_thinclient_rtsp_streaming/",
          "publishedOn": "2022-12-20T16:08:25.000Z",
          "wordCount": 16374,
          "title": "Looking for opinions on Thin-client / RTSP Streaming idea",
          "imageUrl": "https://external-preview.redd.it/ZQg-d3Rxfb5B3H_4d8OJMdgJJdRgzCwGkrySCJT0Bg8.jpg?auto=webp&s=97f5f0edbce2461088c47ccbbcd15496d191015d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqs2ub/power_usage_of_e52630l_v3_vs_e52620_v4_compared/",
          "author": null,
          "description": "I have seen people ask in the past about the power difference going from v3 to v4 processors, so I wanted to share my experience, your results may vary this is just what happened with my particular TrueNAS Scale server.\n For starters, it's a Dell T-7910 with 128GB of DDR4 ECC memory, 4x6TB WD Red's and 4x800GB Intel DC S3610 SSD's, a Quadro K2200 for the o/s and Quadro P600 video card passed thru to a vm and an Asus quad nvme card with 2 Samsung 1TB 970 evo's. Currently running TrueNAS Scale 22.02.4 with a few apps and a few vm's running game servers and plex, this is not idle power as my system is never truly idle.\n When it had dual E5-2630l v3 processors it averaged 23% cpu utilization as reported by TrueNAS and was pulling on average 165 watts as reported by a kill-a-watt\n With the dual E5-2620 v4 processors installed with the same apps and vm's running, TrueNAS reports 12% utilization and kill-a-watt is reporting 148 watts on average. \n I thought this would be a decent comparison since both of these models are 8 core 16 thread cpu's, however there is a small difference in clock speeds. 1.8 on the L version v3 and 2.1 on the v4. the L version also has a tdp of 55 watts where the v4 has a TDP of 85 watts. The v3 is a Haswell and the v4 is a Broadwell. \n These were averages over a 24 hour period of normal use, so all in all it saved only 17w doing the upgrade to the newer processors under my particular use case. These are approximations and not scientific by any means but just wanted to share my results.\n    submitted by    /u/Lab_IT_Guy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqs2ub/power_usage_of_e52630l_v3_vs_e52620_v4_compared/",
          "publishedOn": "2022-12-20T16:00:45.000Z",
          "wordCount": 15567,
          "title": "Power usage of E5-2630l v3 vs E5-2620 v4 compared in a Dell T-7910",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqr47i/my_first_homelab_setup/",
          "author": null,
          "description": "​\n https://preview.redd.it/09qgf0zmm27a1.jpg?width=2268&format=pjpg&auto=webp&s=1c5d7e0337ff98a56a8717e6ad5f4dc14d011a05\n    submitted by    /u/DaggerBomb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqr47i/my_first_homelab_setup/",
          "publishedOn": "2022-12-20T15:20:29.000Z",
          "wordCount": 14340,
          "title": "My first Homelab setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqk5pb/a_rack_accessory_for_all_the_smokers_out_there/",
          "author": null,
          "description": "submitted by    /u/B09DBWW92D  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqk5pb/a_rack_accessory_for_all_the_smokers_out_there/",
          "publishedOn": "2022-12-20T09:36:29.000Z",
          "wordCount": 16855,
          "title": "A rack accessory for all the smokers out there",
          "imageUrl": "https://preview.redd.it/uiwe5qlvd27a1.jpg?auto=webp&s=e92693859f22723d8f478faeb8fc0f3194c010d9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqezxu/my_very_old_school_setup_circa_2001_see_comments/",
          "author": null,
          "description": "submitted by    /u/skunkwoks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqezxu/my_very_old_school_setup_circa_2001_see_comments/",
          "publishedOn": "2022-12-20T05:00:29.000Z",
          "wordCount": 19775,
          "title": "My very old school setup (circa 2001), see comments for details",
          "imageUrl": "https://preview.redd.it/o0v3nh61jz6a1.jpg?auto=webp&s=81a852146d32fdda15c5db557e5ef302a12937ea"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zqdlnu/3_dell_r710_short_rack_aquarium_filters_for_air/",
          "author": null,
          "description": "I wasn’t sure this would work but it is keeping the dust out pretty well. I cut some cheap aquarium filter material to size to fit under the faceplates. It gets pretty dusty without it. Thoughts?\n I was running ESXi 6 with vSphere 6 but switched to Azure Stack HCI when VMUG announced they were discontinuing everything before vSphere 7, which would have meant replacing 3 raid controllers and even then expecting no support.\n    submitted by    /u/Syroxieon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zqdlnu/3_dell_r710_short_rack_aquarium_filters_for_air/",
          "publishedOn": "2022-12-20T03:55:39.000Z",
          "wordCount": 15053,
          "title": "3 Dell R710 short rack, aquarium filters for air intake in cool basement.",
          "imageUrl": "https://preview.redd.it/jf5e55d2p07a1.jpg?auto=webp&s=f56989fcdfa576a242ef92f15d27a46e73f498d8"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq8x6a/is_my_outlet_already_appropriate_for_240v/",
          "author": null,
          "description": "I have a server that I want to plug into my wall outlet in my loft. It says load with all drives occupied uses about 900W, there are two power supplies (one for failover). The input voltage needs to be 208 or 240 V AC. The plug that comes with the server is 3 prong type B.\n Do I need to get an electrician to change anything? The breaker for that outlet on my breaker box says 120/240v. Will it already provide 240v power to this outlet?\n Breaker\n https://imgur.com/KgZGuxs\n Plug\n https://imgur.com/FxxIcNm\n    submitted by    /u/Hot-Guest1275  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq8x6a/is_my_outlet_already_appropriate_for_240v/",
          "publishedOn": "2022-12-20T00:36:39.000Z",
          "wordCount": 14802,
          "title": "Is my outlet already appropriate for 240V?",
          "imageUrl": "https://external-preview.redd.it/zDpG6SyvT4nxKRsFgYLYM0cv6PAkGyEwenffeDZATlg.jpg?auto=webp&s=7a008dac5857231571e0080411a6ad1f9aa283e4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq81t5/got_this_switch_for_free_from_my_workplace_can_i/",
          "author": null,
          "description": "submitted by    /u/AsifBhai001  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq81t5/got_this_switch_for_free_from_my_workplace_can_i/",
          "publishedOn": "2022-12-20T00:01:47.000Z",
          "wordCount": 14316,
          "title": "Got this Switch for free from my Workplace. Can I use it on my home lab for practice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq7hhw/dual_4090_or_a6000_in_antec_p101/",
          "author": null,
          "description": "Any one manage to fit a 4090 or a600 in this case? According to the math I need to remove the middle 4 hdd trays.\n If you have a build a photo would be nice or even another suggestion. What I need is something that can accomdate dual 4090s and still have room for 8 HDDs\n    submitted by    /u/eagle6705  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq7hhw/dual_4090_or_a6000_in_antec_p101/",
          "publishedOn": "2022-12-19T23:39:08.000Z",
          "wordCount": 14234,
          "title": "Dual 4090 or A6000 in antec p101",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq69hq/how_do_i_get_these_drives_to_work_in_a_non_dell/",
          "author": null,
          "description": "submitted by    /u/Deepspacecow12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq69hq/how_do_i_get_these_drives_to_work_in_a_non_dell/",
          "publishedOn": "2022-12-19T22:51:34.000Z",
          "wordCount": 14494,
          "title": "How do I get these drives to work in a non dell server(x3650 m5)? I was told on r/computers that they use custom firmware. My m1215 raid controller says that they are unsupported and states them as \"unconfigured good\". Only thing I can di is \"prepare for removal\" in the imm",
          "imageUrl": "https://preview.redd.it/usftwqf0px6a1.jpg?auto=webp&s=f98be4d5120382e3fcb435b80164aba0cd8e5e5d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq55pk/so_my_mother_has_a_server_rack_now/",
          "author": null,
          "description": "submitted by    /u/wannabe_nerd2811  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq55pk/so_my_mother_has_a_server_rack_now/",
          "publishedOn": "2022-12-19T22:08:04.000Z",
          "wordCount": 15976,
          "title": "So... my mother has a server rack now!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq4r2x/cheap_affordable_server_rack_cases/",
          "author": null,
          "description": "Hi,\n I hope this type of post is not considered off-topic here. I have read the rules and I think my question is appropriate for this sub-reddit.\n First of all, this is my very first post in this subreddit 😄\n I have a question relating to server racks i.e. server rack cases specifically.\n I'm not in the position to afford expensive server computers that are rack mountable, and even if I could, it would be unreasonable for my use case.\n What I wanna do is \"migrate\" (I have some servers in a normal desktop tower case) my existing hardware into a setup that is rack-mountable.\n So, I wanna buy a rack cabinet (10\" or 19\" doesn't really matter to me) and put my \"cheap\" desktop gear into it.\n I have searched the internet for \"server rack cases\" and I've found some matches, but they're generally quite tall and bulky.\n There also seem to be cases that are rack-mountable, but they don't have any mount points for, like let's say, a motherboard.\n My existing servers all have an ATX sized motherboard, if possible I'd like to keep them.\n Are there cheap \"desktop\" (preferably slim) cases that are made to be mounted in a rack cabinet?\n (I know that \"desktop\" PC and \"rack mountable case\" are a bit mutually exclusive, why would a normal user want to have their PC in a rack :D)\n    submitted by    /u/moronwithinternet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq4r2x/cheap_affordable_server_rack_cases/",
          "publishedOn": "2022-12-19T21:52:54.000Z",
          "wordCount": 14626,
          "title": "Cheap / Affordable Server Rack Cases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq47kc/how_do_you_monitor_power_usage/",
          "author": null,
          "description": "I am looking to start doing power monitoring of my lab and I was wondering how you guys go about doing your lab power monitoring?\n    submitted by    /u/RockisLife  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq47kc/how_do_you_monitor_power_usage/",
          "publishedOn": "2022-12-19T21:32:02.000Z",
          "wordCount": 14400,
          "title": "How do you monitor power usage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq3o3j/new_virtual_install_cant_connect_to_the_network/",
          "author": null,
          "description": "submitted by    /u/cberm725  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq3o3j/new_virtual_install_cant_connect_to_the_network/",
          "publishedOn": "2022-12-19T21:10:50.000Z",
          "wordCount": 15263,
          "title": "New virtual install can't connect to the network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq0sn6/what_could_go_wrong/",
          "author": null,
          "description": "submitted by    /u/rynot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq0sn6/what_could_go_wrong/",
          "publishedOn": "2022-12-19T19:20:03.000Z",
          "wordCount": 14836,
          "title": "What could go wrong?",
          "imageUrl": "https://preview.redd.it/fus9hxt25y6a1.jpg?auto=webp&s=39635fe7407bfb33d69fdcb7a12793ddd6c243ad"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq0lmw/cabling_wall_to_rack/",
          "author": null,
          "description": "OK homelabbers, I'm looking for some advice. I have a wall-mounted cabinet terminating the Cat5 cable runs in the house. I now need to run fibre from the wall cabinet to a free-standing 19\" 27U rack. \n The rack is on wheels and needs to be moved about a bit in a tight space to replace equipment now and then, so some \"slack\" in the fibre is needed? \n Do I run the fibre along the floor and up into the rack? That seems to be asking for trouble. \n Do I try and dangle it from the ceiling into the rack on some hooks?\n Why don't they make fibre in old-school-curly-phone-handset style ;)\n    submitted by    /u/beerygaz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq0lmw/cabling_wall_to_rack/",
          "publishedOn": "2022-12-19T19:12:40.000Z",
          "wordCount": 14252,
          "title": "Cabling wall to rack",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq0a70/need_ideas_for_pc_upgrade_shelving_and_server/",
          "author": null,
          "description": "I am a beginner in Linux and homelab. Very beginner in web hosting. I have inherited a Windows 7 Gateway desktop PC: https://uk.pcmag.com/desktops/20161/gateway-dx4860-ub33p?specs\n I have loaded with Ubuntu 22.04 server and have been running Plex server and Foundry VTT via docker. Using SFTP / FileZilla for simple file storage. Also working to self host static site with Caddy and Porkbun. Having some learning trials getting things from local to public. \n I am wanting to reconfig a bit and need some suggestions. Some items I have been considering:\n  \nupdate RAM from 8gb to 16gb\n add additional SSD for boot drive and use full 1TB HDD as storage only\n TBD add external Nvidia GPU\n get a short floor case / shelving to house PC and boot drives\n TBD power backup (storm season in my area)\n  \nAny suggestions on SSD / Nvidia shelving combos? What other upgrades for this server have I not considered? Not looking to buy expensive NAS, routers, or racks at this time. (Moving in April so my setup is temporary-ish)\n Any advice as I reconfig my boot drive and migrate? I may be early enough that I could just start from scratch but prefer to learn migration process.\n I’m going to post a separate post on my hosting challenges lol.\n    submitted by    /u/unmyxtic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq0a70/need_ideas_for_pc_upgrade_shelving_and_server/",
          "publishedOn": "2022-12-19T19:00:38.000Z",
          "wordCount": 16738,
          "title": "Need Ideas for PC Upgrade, Shelving, and Server Migration",
          "imageUrl": "https://preview.redd.it/ujn5e09m1y6a1.jpg?auto=webp&s=33f0ea8f00bd3d5f99bf71964592c1a130a3ae02"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq07vb/what_are_cover_blank_caddy_fillers/",
          "author": null,
          "description": "Hi, I'm looking forward buying a used server. I found a Dell PowerEdge R320 for a good price.\n I'm not very familiar with server hardware, but as far as I understand I have to buy a Drive Caddy for each drive I'm going to use to keep them in place.\n I looked for caddies on the same website where the server is, and I found these: https://www.interbolt.eu/en/spd/009666/Dell-PowerEdge-SFF-2-5-Cover-Blank-Caddy-Filler-De\n They're way less expensive than these trays I found on the same website: https://www.interbolt.eu/en/spd/007596/Dell-PowerEdge-SFF-2-5-SAS-SATA-HDD-Hot-Swap-Tray\n Now my question is: are cover blank caddy fillers just something to cover empty drive slots? Is there a way to use them with a Hard Drive? If not, do I really have to buy the more expensive caddies?\n Thanks A LOT in advance!\n    submitted by    /u/DFalconD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zq07vb/what_are_cover_blank_caddy_fillers/",
          "publishedOn": "2022-12-19T18:58:33.000Z",
          "wordCount": 14620,
          "title": "What are \"cover blank caddy fillers\"?",
          "imageUrl": "https://external-preview.redd.it/0YtuhbUqmMcWcICgeCqCpKPql0bhZUE6Tc-GngDYAgY.jpg?auto=webp&s=548ca7d6bec0a5b38cc7b404e82120a903e11d83"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq03ju/lab_build_rfc/",
          "author": null,
          "description": "Hi, Guys (and any Gals that are here).\n After a long hiatus due to work and personal issues, I'm back to building my first homelab.\n A quick recap: I'm building a moderate size physical cluster consisting of 9 m-ITX blades each with an i3-10105T, 32Gb DRAM and 512Gb NVME boot drive. Two of the blades have four 2.5\" hot swap bays in which I'll have a total of eight 2Tb SSDs.\n There are also two mini-PCs (Bee-link Gti11s that are i5-11s with 16Gb DRAM and 512Gb NVME boot drive). One of them will be a dedicated pfSense firewall (have to use the development build of pfSense 2.7 so it will recognize my i225 NICs) and the other will be running Ubuntu Desktop for an inside the lab management interface.\n When I say inside the lab, I want the everything from the pfSense FW down on its own IP range …",
          "link": "https://www.reddit.com/r/homelab/comments/zq03ju/lab_build_rfc/",
          "publishedOn": "2022-12-19T18:54:00.000Z",
          "wordCount": 14954,
          "title": "Lab Build RFC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zq0291/home_nasserver_a_quick_check_before_i_bite_the/",
          "author": null,
          "description": "PCPartPicker Part List\n  \n Type Item Price \n  \n CPU Intel Core i5-12400 2.5 GHz 6-Core Processor $328.99 @ PB Technologies \n  CPU Cooler Deepcool AK400 66.47 CFM CPU Cooler $58.99 @ PB Technologies \n  Motherboard MSI PRO B660M-A WIFI DDR4 Micro ATX LGA1700 Motherboard $245.00 @ 1stWave Technologies \n  Memory Corsair Vengeance LPX 32 GB (2 x 16 GB) DDR4-3200 CL16 Memory $179.00 @ 1stWave Technologies \n  Storage Crucial BX500 1 TB 2.5\" Solid State Drive $98.99 @ PB Technologies \n  Storage Seagate BarraCuda 1 TB 3.5\" 7200 RPM Internal Hard Drive $65.00 @ Computer Lounge \n  Storage Seagate BarraCuda 1 TB 3.5\" 7200 RPM Internal Hard Drive $65.00 @ Computer Lounge \n  Storage Seagate IronWolf Pro 18 TB 3.5\" 7200 RPM Internal Hard Drive $589.95 @ Newegg New Zealand \n  Storage Seagate IronWolf Pro …",
          "link": "https://www.reddit.com/r/homelab/comments/zq0291/home_nasserver_a_quick_check_before_i_bite_the/",
          "publishedOn": "2022-12-19T18:52:34.000Z",
          "wordCount": 17936,
          "title": "Home NAS/Server - a quick check before I bite the bullet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpz8k7/will_this_hurt_anything_long_term/",
          "author": null,
          "description": "submitted by    /u/RickoT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpz8k7/will_this_hurt_anything_long_term/",
          "publishedOn": "2022-12-19T18:22:28.000Z",
          "wordCount": 15931,
          "title": "will this hurt anything long term?",
          "imageUrl": "https://preview.redd.it/mb3ztszsux6a1.jpg?auto=webp&s=0fb6ad5e5b7e0a427b9777b53e3413f641885148"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpy0qf/best_approach_for_ssl/",
          "author": null,
          "description": "Greetings,\n In my homelab, I have a synology NAS that has docker running on it with a bunch of containers. One of those containers is a NGINX reverse proxy. Currently, the various UIs for a number of containers, as well as for the synology itself, are running over http. It's all internal, so it's not the end of the world if it isn't https, but I'd like to fix it so that everything does use https. I've noticed in some cases that chrome assumes that sites are https and that things don't work as a result.\n The problem is, none of these things are exposed to the open internet (and I don't want to expose them), so it looks like Let's encrypt is out. Further complicating things, their hostnames are all configured to be subdomains of my main domain (which does have a website out there with a Let's Encrypt cert on it). What's the sanest approach here?\n 1) Do whatever shenanigans Let's Encrypt needs at the domain level to get a wildcard cert? What would I need to do to keep child domains updated in this case?\n 2) Make a self-signed certificate and trust it on all my devices. How hard will it be to keep NGINX updated with this cert?\n Just needing a bit of guidance here, because when I've dealt with certs, it has either been in a production web environment with a \"real\" certificate authority or it has been Let's Encrypt provided by a webhost. Not sure what to do in a homelab.\n    submitted by    /u/williamwgant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpy0qf/best_approach_for_ssl/",
          "publishedOn": "2022-12-19T17:38:02.000Z",
          "wordCount": 16374,
          "title": "Best approach for SSL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpx2bx/suggestions_to_replace_my_cherry_g844400_usb/",
          "author": null,
          "description": "I kept a Cherry G84-4400 (USB version) keyboard in my 'head tote' with an LCD panel, power strip, and odds and ends for when a headless box needs direct attention.\n Eventually the cord went bad and the Cherry got recycled. I'd like to get another, but $80+ is a bit steep for very occasional use.\n Perix has a couple trackball and touchpad keyboards - any thoughts on those, or other options in the sub US$50 price range?\n    submitted by    /u/ggibby  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpx2bx/suggestions_to_replace_my_cherry_g844400_usb/",
          "publishedOn": "2022-12-19T17:02:49.000Z",
          "wordCount": 15205,
          "title": "Suggestions to replace my Cherry G84-4400 USB keyboard with integrated trackball?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpvw8j/unifiopenvpndell_poweredgeproxmoxtruenasrsyncplex/",
          "author": null,
          "description": "The last 6 or so months (through a busy summer and sick kids) I've been working my way through creating creating my own off-site backup at my dad's house. Cause if one home lab is good then 2 is definitely better! I deployed it a few days ago and everything is operational which was a huge validation to a lot of \"I'm pretty sure I can do this\" a long the way. \n  \nHome Site: \n UDMP\n UNVR-Pro\n RPS\n Dell PowerEdge T440 - Proxmox \n TrueNAS\n 2x PiHole\n Plex\n Home Assistant\n Docker Portianer\n \n 2x UPS\n \n Remote Site \n UDMP-SE\n Dell PowerEdge T320 - Proxmox (with X-windows for local GUI access to VMs if needed) \n TreuNAS\n 2x PiHole\n Plex (Because why not have a Plex Mirror)\n \n 2x UPS\n \n  \nBoth routers are setup with NoIP DDNS service and since I'm dealing with URLs I used OpenVPN to link them. Eac…",
          "link": "https://www.reddit.com/r/homelab/comments/zpvw8j/unifiopenvpndell_poweredgeproxmoxtruenasrsyncplex/",
          "publishedOn": "2022-12-19T16:19:12.000Z",
          "wordCount": 15841,
          "title": "Unifi-OpenVPN-Dell PowerEdge-Proxmox-TrueNAS-Rsync-Plex and a Partridge in a Pear Tree",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zptkaz/my_mini_homelab_in_a_typical_dutch_fuse_box/",
          "author": null,
          "description": "submitted by    /u/liamhildebrand  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zptkaz/my_mini_homelab_in_a_typical_dutch_fuse_box/",
          "publishedOn": "2022-12-19T14:49:21.000Z",
          "wordCount": 15288,
          "title": "My mini homelab, in a typical dutch fuse box ;)",
          "imageUrl": "https://preview.redd.it/yuwyx05ssw6a1.jpg?auto=webp&s=d652c6578514f11e77da5b9c9f656772c946e5fb"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpsgfv/silencing_a_dell_powerconnect_7024/",
          "author": null,
          "description": "submitted by    /u/lucaci32u4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpsgfv/silencing_a_dell_powerconnect_7024/",
          "publishedOn": "2022-12-19T14:04:38.000Z",
          "wordCount": 15014,
          "title": "Silencing a Dell PowerConnect 7024",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpmvjc/any_help/",
          "author": null,
          "description": "Got my hands on an old Dell EMC CX4-120 storage system connected to the maintenance network but requires password to login which I can’t find and need to reset have tried google but with no luck any suggestions\n    submitted by    /u/Acceptable-Resist-79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpmvjc/any_help/",
          "publishedOn": "2022-12-19T09:18:07.000Z",
          "wordCount": 16459,
          "title": "Any Help",
          "imageUrl": "https://preview.redd.it/61xdeaho5v6a1.jpg?auto=webp&s=2e674ba597c293677a8a70e7c34aa1438cca51d5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpl0zz/does_this_count_lol_opnsense_mini_pc_and_my_first/",
          "author": null,
          "description": "submitted by    /u/tharussianbear  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpl0zz/does_this_count_lol_opnsense_mini_pc_and_my_first/",
          "publishedOn": "2022-12-19T07:21:53.000Z",
          "wordCount": 16500,
          "title": "Does this count? Lol opnsense mini pc and my first switch!",
          "imageUrl": "https://preview.redd.it/ixl2jd2yku6a1.jpg?auto=webp&s=920de47a4965ee481528555e6ec37b8c47f22fa5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpikcv/psa_avoid_sfp_10gbs_connectors_model_ftlx8571d3bcv/",
          "author": null,
          "description": "TLDR: get FTLX8571D3BNL instead of FTLX8571D3BCV SFP+ Transceivers if you don't want to hate your life\n I got some Intel FTLX8571D3BCV-IT SFP+ connectors for my 10gbs fiber homelab setup. I wasted a week trying to get them to work.\n Despite them being listed as 1gbs/10gbs compatible connector, they were never able to actually connect at 10gbs. ethtool even showed supported modes as 10000baseCR/Full and 10000baseSR/Full, but that's a load of BS.\n I compiled the intel ixgbe driver by hand and it still didn't help. Confirmed fiber cables and switch were known good by swapping out parts - it is definitely the FTLX8571D3BCV connectors being dumb.\n After checking online, seems this is a known issue. Want to spread the word here on reddit as well so that no one else gets bit by this buggy hardware.\n    submitted by    /u/vaniaspeedy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpikcv/psa_avoid_sfp_10gbs_connectors_model_ftlx8571d3bcv/",
          "publishedOn": "2022-12-19T05:04:13.000Z",
          "wordCount": 17145,
          "title": "PSA: Avoid SFP 10gbs Connectors model FTLX8571D3BCV",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpduha/can_tripp_lite_ps7192_su1500rtxl2ua_have_extended/",
          "author": null,
          "description": "Could the Tripp Lite SU1500RTXL2UA be wired up with additional batteries to extend the run time without using the Tripp Lite BP48V24-2U battery extender chassis?\n I could certainly try wiring the extra batteries up to the internal pack but it would likely be really ugly as I might have to drill a hole somewhere in the chassis or leave the front panel off.\n    submitted by    /u/CharacterLock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpduha/can_tripp_lite_ps7192_su1500rtxl2ua_have_extended/",
          "publishedOn": "2022-12-19T01:11:39.000Z",
          "wordCount": 14147,
          "title": "Can Tripp Lite PS7192 (SU1500RTXL2UA) have extended batteries without the BP48V24-2U chassis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpdtz2/selfhosted_solution_like_hdhomerun/",
          "author": null,
          "description": "Hi,\n So, like the title says, I would be looking for a self-hostable solution to replace a box like HDHomeRun.\n Basically the idea would be to have a USB or PCIE card adapter to be able to use a TV antenna on my server and basically get the live TV channels it gets and then use them in Plex directly as a DVR exactly as I would with hdhomerun. \n Currently, I am using xteve for iptv, but I'd like to be able to use a TV antenna, but I don't want to buy a proprietary box like the hdhomerun one.\n Is there a solution that exist out there that anyone knows of? And would it be viable compared to a premade solution? \n Thanks in advance for any suggestion, and don't hesitate if I'm missing details.\n    submitted by    /u/jeremyy44  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpdtz2/selfhosted_solution_like_hdhomerun/",
          "publishedOn": "2022-12-19T01:10:59.000Z",
          "wordCount": 14350,
          "title": "Self-hosted solution like HDHomeRun",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpdkhj/dell_r620_pcie_netowrk_card/",
          "author": null,
          "description": "I recently bought a R620, my first rack mount server purchase. It came with a 4-port Broadcom network card but I wanted to add some more ports just for fun and to experiment with Proxmox.\n It is an Intel 4-port PCI-E card I pulled from a Dell Optiplex 7040 desktop where it worked fine.\n When I boot the server it seems to initialize, it shows up in the system inventory, but not in the hardware network devices. When I plug a cable into it I get nothing.\n I tried digging around the Life Cycle Controller thinking maybe it had to be manually enabled but didn't see anything that jumped out at me. It is installed currently in PCI-E slot 1, but I have tried the others as well.\n Oddly, Proxmox sees the card (though I have not made use of it there, yet). Is there anything I need to do to get it to show up within the server itself (iDrac web interface, LCC, etc.) or is this just normal?\n    submitted by    /u/StormStrikes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpdkhj/dell_r620_pcie_netowrk_card/",
          "publishedOn": "2022-12-19T00:58:35.000Z",
          "wordCount": 14327,
          "title": "Dell R620 PCI-E Netowrk Card",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpdek6/how_things_begin_excited_to_go_from_lurker_to/",
          "author": null,
          "description": "submitted by    /u/gusontherun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpdek6/how_things_begin_excited_to_go_from_lurker_to/",
          "publishedOn": "2022-12-19T00:50:29.000Z",
          "wordCount": 14302,
          "title": "How things begin! Excited to go from lurker to homelab beginner!",
          "imageUrl": "https://preview.redd.it/qqigzvza5r6a1.jpg?auto=webp&s=a5506f9742399f4c9ea50fd33d1df9ec0cfb879b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpd9i3/anyone_running_oracle_or_mssql_in_your_lab/",
          "author": null,
          "description": "So one of the things I'm doing in my lab is maintaining a practice and development environment for multiple languages and frameworks, such as Python, PHP, and even *shudders* Ruby, crossed with various Databases, such as PostgreSQL, MariaDB, MongoDB, and other tools like rabbitmq, mqtt, and memcached and redis. So I'm thinking about expanding the database assortment into the 'commercial' realm of applications, so I'm looking at setting up an MS server with IIAS and .NET for web development, and databi for both OracleSQL and MSSQL. But licensing. Does anybody have any practical experience running these in the home lab? Do MS and Oracle make these available under home, lab, or student licenses for free or reduced cost? I couldn't even find a \"Buy it now\" purchase link on Oracle's website, and I'm trudging through their XE process now and finding that the generous '2GB in Memory' limit they place may not be as generous as I thought, since on a stock empty install it's already using over 1.5GB. So how do you license your MSSQL and OracleSQL in your home lab?\n    submitted by    /u/AsYouAnswered  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpd9i3/anyone_running_oracle_or_mssql_in_your_lab/",
          "publishedOn": "2022-12-19T00:43:40.000Z",
          "wordCount": 16209,
          "title": "Anyone running Oracle or MSSQL in your lab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpai9n/help_with_wd_8tb_nas_drive_not_showing_up_in_linux/",
          "author": null,
          "description": "Hello,\n ​\n I am new here and posting as someone from TrueNAS forum suggested I ask for advice here.\n My plan was to use 3 WD 8 TB Red Plus HDD's with TrueNAS Scale. (https://www.bhphotovideo.com/c/product/1731377-REG/wd_wdbc9v0080hh1_wrsn_8tb_red_plus_cmr.html)\n The rest of the hardware is (an old gaming pc):\n msi x79a-gd45 plus (has 6 SATA Slots)\n i7-4930K\n 250GB SSD\n 16 GB RAM\n I could not get the HDD's to show up with that machine and I used TrueNAS Scale and Ubuntu on flash drive. I then tried attaching the HDD's one at a time to a WIN10 machine and still couldn't get them to show up. \n The only way it would show up is in BIOS.\n Then I ordered an external HDD Hub that I plugged into the PC. It showed up and I ran some Linux commands from the TrueNAS Forum recommendations. \n Please see …",
          "link": "https://www.reddit.com/r/homelab/comments/zpai9n/help_with_wd_8tb_nas_drive_not_showing_up_in_linux/",
          "publishedOn": "2022-12-18T22:38:26.000Z",
          "wordCount": 14915,
          "title": "Help with WD 8TB NAS Drive not showing up in Linux",
          "imageUrl": "https://external-preview.redd.it/vWgwg6OS3aoeZDK2xXf6Tfox6WpY-GDoa5xn3Zh9qno.jpg?auto=webp&s=56503d6252338f39a94ca245db651fc383252afe"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpahzn/bought_a_new_case_have_questions_about_sas_hookup/",
          "author": null,
          "description": "Hey I recently bought a supermicro 36 bay server. A 847E16-R1400LPB if it matters. And had a question about the sas cables.\n https://imgur.com/a/1Fp9nfm\n From what I can see there's 4 hookups for the front backplane, and 8 on the rear with only 4 hooked up. With 4 free ports. And only 4 cables to plug into a raid card.\n From what I can tell it looks like two of the front backplane cables goes to the rear backplane, with only two from each free to plug into a raid card.\n I'm coming from a r710 so I'm still a bit of a newbie here. So just want to know if it's all good. I need to get new cables anyhow, as my gear is 8087. So I'll need to buy new cables. Just need to see if I need 4, 8, 12, or what's up.\n Thanks for any and all help!\n    submitted by    /u/Happy-Firefighter-30  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpahzn/bought_a_new_case_have_questions_about_sas_hookup/",
          "publishedOn": "2022-12-18T22:38:05.000Z",
          "wordCount": 15325,
          "title": "Bought a new case, have questions about sas hookup.",
          "imageUrl": "https://external-preview.redd.it/wVKw0Dzy-YJasjUbOyCtSMrX-gY8BVKWD8TOEZDJNNM.jpg?auto=webp&s=8909fa4f45a0a23e7c4cf4fe9ac78480bc3433c1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zpahcp/any_problem_with_using_external_25in_hdds_in_a_nas/",
          "author": null,
          "description": "I've been doing back and forth on whether or not I should move away from my current NAS solution that is simply just 2x external HDDs connected to a Lenovo SFF (m710q). It is plenty powerful for my few tasks, but I am not super stoked about having to use external drives, since there is obviously no room for internal upgrades. I only need two drives, as I don't need a whole ton of capacity, but like having the failsafe in case of a drive failure. Currently, I am just using robocopy script to copy any changes made on one drive to the other via a scheduled task but have been tinkering with TrueNAS as a more professional solution with less overhead than windows.\n So, my question: is there any inherent downside to using external HDD enclosures and 2.5in drives in a NAS? Obviously, they are slightly more expensive, but less expensive than building a new machine to do the same tasks...\n    submitted by    /u/Gusmanbro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zpahcp/any_problem_with_using_external_25in_hdds_in_a_nas/",
          "publishedOn": "2022-12-18T22:37:14.000Z",
          "wordCount": 15563,
          "title": "Any problem with using external 2.5in HDDs in a NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp9hln/ip_kvm_questions/",
          "author": null,
          "description": "Before I head to the questions, here is what I think that I know so far:\n  \nThe setup - 9 machines in two areas of the house that I would like to be able to manage from a single chair, USB keyboard and mouse, 1920x1200 monitor.\n \nMachines have disparate video connections, so I know I will need adapters from HDMI/DP/VGA to whatever the KVM is using. \n \nI know I should be using IPMI when possible, but only 3 of the 9 machines have this capability.\n \nI understand I can run a remotely switchable KVM into a PiKVM or TinyKVM as an option, and I am looking into that as well, but not really seeing cost savings here with a KVM for each room plus the box.\n \nI would like to do IP KVM rather than RDP or other remote access, as I would like to be able to deal with everything from the BIOS up, and also …",
          "link": "https://www.reddit.com/r/homelab/comments/zp9hln/ip_kvm_questions/",
          "publishedOn": "2022-12-18T21:53:12.000Z",
          "wordCount": 17282,
          "title": "IP KVM Questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp8wwc/gsa_server/",
          "author": null,
          "description": "So, a few weeks ago, I purchased 3 Google Search Application servers. They are just branded Dell servers. 1 is an r710, 1 is a r720xd, and the last is a r730xd. The 710 and 720 boot right into the bios. The 730, on the other hand, boots into a password protected bios. I have tried resetting the cmos and jumping the pins. And none of the instructions on the Google are working either. Does anybody have any ideas. I figure I'm just going to have to replace the motherboard.\n    submitted by    /u/kbhutson868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp8wwc/gsa_server/",
          "publishedOn": "2022-12-18T21:28:09.000Z",
          "wordCount": 14163,
          "title": "GSA Server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp8ina/goodbye_old_friend/",
          "author": null,
          "description": "Bought two identical Hitachi drives in July 2011 for RAID 1 setup.\n After almost 100k hours, one of them showed bad sectors:\n 1989 bad sectors, pulled out to see, if can be salvaged\n other one is still going strong, so far:\n fingers crossed for 100k hours\n    submitted by    /u/_WreakingHavok_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp8ina/goodbye_old_friend/",
          "publishedOn": "2022-12-18T21:10:58.000Z",
          "wordCount": 14655,
          "title": "goodbye old friend",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp8fgp/how_come_i_dont_see_many_people_using_hyperv/",
          "author": null,
          "description": "submitted by    /u/Cody_Cal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp8fgp/how_come_i_dont_see_many_people_using_hyperv/",
          "publishedOn": "2022-12-18T21:07:06.000Z",
          "wordCount": 15536,
          "title": "How come I don’t see many people using Hyper-V server with Windows Admin Center which are both free and enterprise grade? Tried proxmox and it’s quite lackluster in comparison. Hyper-V and WAC you name it, it does it at Enterprise level and no you don’t need a AD domain.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp75ej/this_thing_is_starting_to_get_out_of_hand/",
          "author": null,
          "description": "submitted by    /u/InvisibleCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp75ej/this_thing_is_starting_to_get_out_of_hand/",
          "publishedOn": "2022-12-18T20:11:34.000Z",
          "wordCount": 15120,
          "title": "This thing is starting to get out of hand...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp735z/virtualizing_opnsense_getting_a_wan_and_lan_ip/",
          "author": null,
          "description": "Optiplex 5060 w/ i7-8700, 32gb RAM, 1x i340-T2 for OPNSense specifically, 1x HBA LSI card to passthrough drives to TrueNAS. Proxmox is installed on the bare metal. The purpose of OPNSense is to have my set up like this: BGW210 -> OPNSense -> TL-SG2008P Switch (for wired devices) -> EAP 225 AP (for wireless devices).\n This is also how I have it mapped out: https://drive.google.com/file/d/19dzpxdCUSIhxP3qEwpXexkBlIll7E1Z0/view?usp=sharing\n I recently taken an interest in homelabbing and my latest endeavor is trying to virtualize OPNSense in Proxmox for VLAN features as my current AT&T Uverse BGW210 box doesn't support it. Also, I am forced to use Uverse in order to get internet, I cannot replace it.\n I have been following TechnoTims video on how to do this. It is pfSense but the tutorial sho…",
          "link": "https://www.reddit.com/r/homelab/comments/zp735z/virtualizing_opnsense_getting_a_wan_and_lan_ip/",
          "publishedOn": "2022-12-18T20:08:58.000Z",
          "wordCount": 19234,
          "title": "Virtualizing OPNSense, getting a WAN and LAN IP, but not only unable to access the WebGUI, but I can't get access to Internet through the switch either.",
          "imageUrl": "https://external-preview.redd.it/37ZTvwrMcJF_eLUbOGgs939jnCe73OY4yY9z7LtxxTQ.jpg?auto=webp&s=6da78299ea3c3cd17f6e9b2147a3d441fb8667de"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp552q/ups_hunting/",
          "author": null,
          "description": "I have needed a UPSS for a while but I keep putting it off due to cost, features, lifespan, support, etc. but maybe you can recommend something that meets the criteria I have? \n Features required to make it \"the one for me\":\n  \nNetwork interface for SNMP/alerts/monitoring/etc.\n Battery replacement for when the day comes\n 1 or 2U rack mountable\n  \nPower requirements (what will it run during a power outage):\n  \n1 PA-440 firewall\n 1 Unifi 48 port POE switch\n 1 Arris SB6190 modem (do not care if this gracefully shuts down but needed for any alerts)\n 2 ESX servers running on old low power Dell OptiPlex hardware\n 1 NAS server also running on old low power OptiPlex hardware\n  \nA huge concern I have is that power will go out in the middle of the night so it would be nice to have the UPS be smart enough to trigger some sort of API calls or scripted shutdowns but at the very least send some sort of alert to my phone to wake me up for manual shut downs. If the hardware itself sounds an alarm there is no way I will hear it from 3 floors up while sleeping. Am I just dreaming a perfect UPS or does something exist that can do \"all the things\"?\n    submitted by    /u/orthonovum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp552q/ups_hunting/",
          "publishedOn": "2022-12-18T18:42:23.000Z",
          "wordCount": 14664,
          "title": "UPS Hunting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp3h58/new_a_better_plex_exporter_for_prometheus/",
          "author": null,
          "description": "There are a few Plex exporters out there to track metrics in Prometheus but they have some deficiencies: not differentiating between playing, paused, buffering streams, audio vs. video transcoding, tracking media downloads, and more.\n I decided to roll my own exporter to address these and have been running it in production for a few weeks. Please give it a try if this sounds like something that would improve your Plex dashboards — pull requests are welcome (Ruby)!\n https://github.com/axsuul/plex-media-server-exporter\n    submitted by    /u/Axsuul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp3h58/new_a_better_plex_exporter_for_prometheus/",
          "publishedOn": "2022-12-18T17:22:00.000Z",
          "wordCount": 14554,
          "title": "New: A better Plex exporter for Prometheus",
          "imageUrl": "https://external-preview.redd.it/jCn6IAeoLCOLlc9-4gUlDz5_0TPW3-X69CfPATeo0Pc.jpg?auto=webp&s=368191378aa0f4d55b4169d201c203c40c4d70df"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp1dvb/hard_drive_write_noise/",
          "author": null,
          "description": "I just recently got new 18tb seagate drives. When writing data it’s seems like there’s quite a bit of noise coming from the drive head. I just want to be sure that this noise is either expected or that there is an in fact an issue with the drives here.\n Link to drives: https://www.newegg.com/seagate-exos-x18-st18000nm000j-18tb/p/1B4-00VK-00616?item=1B4-00VK-00616\n Thank you!\n    submitted by    /u/RedditGuru-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp1dvb/hard_drive_write_noise/",
          "publishedOn": "2022-12-18T15:43:38.000Z",
          "wordCount": 15111,
          "title": "Hard drive write noise",
          "imageUrl": "https://external-preview.redd.it/FdDABZFnEgJyNVZ8Ifi08oPJVT9jL8Z_3gSmkC-K5do.png?format=pjpg&auto=webp&s=3ba29b643604c20e56a89d2981c49967a2bf291e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zp13dg/help_me_decide_on_first_homelab/",
          "author": null,
          "description": "submitted by    /u/Auburnfan96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zp13dg/help_me_decide_on_first_homelab/",
          "publishedOn": "2022-12-18T15:29:31.000Z",
          "wordCount": 16303,
          "title": "Help Me Decide on First homelab",
          "imageUrl": "https://preview.redd.it/md4m01e1vp6a1.png?auto=webp&s=e0222e37c2e869c9b879f24959ebdac38a6f6aa4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zozjq8/homelab_internet_failover_using_an_old_phone/",
          "author": null,
          "description": "submitted by    /u/mrln_bllmnn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zozjq8/homelab_internet_failover_using_an_old_phone/",
          "publishedOn": "2022-12-18T14:13:56.000Z",
          "wordCount": 16295,
          "title": "Homelab Internet Failover using an old phone (OPNsense)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zoue4p/whats_the_best_method_of_rust_removal_from_zinc/",
          "author": null,
          "description": "I've got a Chenbro RM31300 server case but it has some rust spots on it. Normally I would gently sand back, use rust converter and then spray with a zinc paint. \n Are there any better methods to do this in 2022?\n    submitted by    /u/kester76a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zoue4p/whats_the_best_method_of_rust_removal_from_zinc/",
          "publishedOn": "2022-12-18T09:05:12.000Z",
          "wordCount": 15725,
          "title": "Whats the best method of rust removal from zinc server case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zotxzo/macos_content_caching_server_can_old_macos_serve/",
          "author": null,
          "description": "I'm trying to set up a system to host copies of macOS updates locally, so that when a device needs it it will download locally instead of from Apple's servers each time (for download speed reasons, I often have several machines that need the same update). I'm aware Apple's Content Caching feature is meant to do exactly this, but does it have version limitations? As in, can a system running macOS Catalina 10.15.7 store and host updates for macOS 11/12/13? What about for older versions, like 10.11 or 10.13? Does the server OS losing security update support mean it won't be able to fetch updates for peer machines on newer OSes either? Thanks in advance!\n    submitted by    /u/vinaypundith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zotxzo/macos_content_caching_server_can_old_macos_serve/",
          "publishedOn": "2022-12-18T08:35:35.000Z",
          "wordCount": 14734,
          "title": "macOS Content Caching server - can old macOS serve new updates?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zor3dq/i_know_the_cables_could_use_work_but_im_really/",
          "author": null,
          "description": "submitted by    /u/SamPlaysKeys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zor3dq/i_know_the_cables_could_use_work_but_im_really/",
          "publishedOn": "2022-12-18T05:34:11.000Z",
          "wordCount": 15897,
          "title": "I know the cables could use work, but I'm really proud! (details below)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zom6jw/newbie_advice/",
          "author": null,
          "description": "I am new to the subreddit, and new to doing any substantial work involving computers in general. I apologize if I don't express my goals properly / go over something that has already been covered.\n ​\n Bit of a background on me: I hate subscription services. Whether I am paying monthly to watch movies/ tv shows, listen to music, play video games, or even just store data on someone else's computer (\"cloud\"), I hate it. At this point, I would rather spend exponentially more than I ever would for the subscriptions if it means I get to build/own it. Having said that, I don't really have a specific budget in mind, but I am okay with this being a costly venture that takes a couple of years to perfect.\n ​\n These are the things that I want to be able to do with my homelab:\n - NAS\n - Media Server (P…",
          "link": "https://www.reddit.com/r/homelab/comments/zom6jw/newbie_advice/",
          "publishedOn": "2022-12-18T01:16:54.000Z",
          "wordCount": 14947,
          "title": "Newbie Advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zol9hq/local_rdp_alternatives_with_robust_resolution/",
          "author": null,
          "description": "Hello. I have a home lab where I have my main desktop connected to 2 massive 49 inch displays (1 on top of the other) and several servers connected over the local network. \n ​\n Up until now I controlled those servers over windows RDP however now that I have these new screens I want to have finer control over the resolution so I can scale it by clicking and dragging the corner like I would any other window. I tried NoMachine but for some reason that I can't figure out, NoMachine is bugging out on my win server 2019 system (the main server) greying out the \"share screen\" option. I don't need external access I just want something that is locally hosted and is better than the garbage built-in RDP (and free)\n ​\n Any suggestions. Thanks\n    submitted by    /u/NepNep_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zol9hq/local_rdp_alternatives_with_robust_resolution/",
          "publishedOn": "2022-12-18T00:37:29.000Z",
          "wordCount": 14159,
          "title": "Local RDP Alternatives With Robust Resolution Options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zol1ro/installing_a_nvidia_tesla_m10_in_a_dell_r730xd/",
          "author": null,
          "description": "So I'm getting a Nvidia Tesla M10, planning to add it to my Dell R730XD in Riser 2. \n Looking everywhere for the proper cable I cannot find the correct cable... Can someone potentially link me a verified one that won't end up frying the GPU? or a model number... \n Thank You!\n    submitted by    /u/Hexers  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zol1ro/installing_a_nvidia_tesla_m10_in_a_dell_r730xd/",
          "publishedOn": "2022-12-18T00:29:17.000Z",
          "wordCount": 14089,
          "title": "Installing a Nvidia Tesla M10 in a Dell R730XD; need assistance with correct cable.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zojyr5/please_help/",
          "author": null,
          "description": "I have read through all the intro stuff but can’t find just a simple list of what I need for a physical lab set up like computers, routers, switches, etc. I just want something basic to set up with physical devices to dip my toes in to learn with something.\n    submitted by    /u/Sea-Zookeepergame584  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zojyr5/please_help/",
          "publishedOn": "2022-12-17T23:46:29.000Z",
          "wordCount": 14325,
          "title": "Please help.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zojo1t/30_network_drops_how_do_i_make_the_install_look/",
          "author": null,
          "description": "I am in the process of hardwiring all of the tvs; apple tvs; gaming systems and computers. All told, I will have about 30 to 35 drops. \n I have about 10 already completed and have been using a 4 port wall plate at the rack but I don't think I will like the way it looks when I have to have 9 4 port wall ports. What have others done?\n edit prior to the patch panel. I want the cables coming out of the wall to look clean.\n    submitted by    /u/bucket46  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zojo1t/30_network_drops_how_do_i_make_the_install_look/",
          "publishedOn": "2022-12-17T23:34:00.000Z",
          "wordCount": 14398,
          "title": "30 network drops, how do I make the install look clean in my house?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zojmt4/hi_guys_would_love_some_ideas_on_a_homelab/",
          "author": null,
          "description": "I currently wanted to have a home-lab setup on my resume as I am a cyber security student\n I own a RPI-4 I was planning on setting up a hybird setup containing VMs and my PI\n I was going to use ansible to deploy my infastructure\n I plan on creating a DNS-Server (LINUX), SMB server (LINUX), DHCP server (RPI) , I would love some more ideas maybe AD server etc.\n    submitted by    /u/Tilted_Towers33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zojmt4/hi_guys_would_love_some_ideas_on_a_homelab/",
          "publishedOn": "2022-12-17T23:32:33.000Z",
          "wordCount": 14372,
          "title": "Hi guys would love some ideas on a home-lab ,",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zoi0xe/dell_r620_ssd_compatibility/",
          "author": null,
          "description": "I have an r620 with h310 raid controller and I'm having trouble finding compatible ssd's. So far nearly everything I have laying around shows a \"fault detected on drive\" error - even on new drives. The only ones I've found so far that work are teamgroup vulcan g (not z).\n Anyone know of any others that work? Would I have better luck with a different raid controller?\n Edit: Updating to solved. Looks like samsung evo ssds are the way to go - and an update to the h710 or h710p to improve performance. Thanks for the help guys!\n    submitted by    /u/whimsical-wizardry  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zoi0xe/dell_r620_ssd_compatibility/",
          "publishedOn": "2022-12-17T22:22:06.000Z",
          "wordCount": 14357,
          "title": "Dell R620 SSD Compatibility?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zogg9n/how_high_is_your_internet_traffic_per_month/",
          "author": null,
          "description": "submitted by    /u/_c0der  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zogg9n/how_high_is_your_internet_traffic_per_month/",
          "publishedOn": "2022-12-17T21:15:23.000Z",
          "wordCount": 15003,
          "title": "How high is your internet traffic per month?",
          "imageUrl": "https://preview.redd.it/vxb8toq0yi6a1.png?auto=webp&s=0322723bd1b578131dc108df859094705e43f9ad"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zog6n4/the_suitcase_server_project/",
          "author": null,
          "description": "I've been looking for a performant server that can stack 8-16 SSDs, run a handful of VM's, and connect at 10+gbps while fitting in a suitcase. I've got a plan now and want to see if anyone has any feedback before I place the orders.\n  \nCase: PLink IPC-2022M (would remove the 3.5 HDD trays for more room)\n Mobo: AsRock Rack X570D4U\n CPU: AMD Ryzen 9 5950X\n CPU Cooler: Dynatron A24\n RAM: 4x Crucial 32GB DDR4 3200MHz CT32G4DFD832A \n PSU: Seasonic Prime PX-750\n HBA: LSI 9305-16i Low Profile\n NIC: Mellanox MCX314A-BCCT (have 40gbe at home, can adapt to SFP+ as needed)\n Storage: 2x NVMe for boot and VM storage. 1 or 2 ICYDOCK MB998IP-B filled with 8TB Samsung QVO SSDs. \n OS: Proxmox with linux/windows VMs\n  \nAny and all feedback is welcome!\n    submitted by    /u/certifiedintelligent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zog6n4/the_suitcase_server_project/",
          "publishedOn": "2022-12-17T21:04:08.000Z",
          "wordCount": 14206,
          "title": "The suitcase server project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zofoej/new_used_poweredge_r730xd_bootingdisplay_issue/",
          "author": null,
          "description": "I have a VGA to HDMI cord plugged into the front port of the server and a cat5e cable plugged into the idrac port on the back of the server.\n I seem to be unable to have it show up in my router for an ip address or display onto a monitor for bios or anything. Am I missing something super obvious? The activity light on the front is blue which seems to indicate that the server is fine.\n Thanks for any help you can provide.\n    submitted by    /u/CrazyPsychic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zofoej/new_used_poweredge_r730xd_bootingdisplay_issue/",
          "publishedOn": "2022-12-17T20:42:02.000Z",
          "wordCount": 15598,
          "title": "New (Used) Poweredge R730xd Booting/Display Issue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zofn7q/my_beginner_level_homelab/",
          "author": null,
          "description": "submitted by    /u/chrisraydj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zofn7q/my_beginner_level_homelab/",
          "publishedOn": "2022-12-17T20:40:36.000Z",
          "wordCount": 14679,
          "title": "My beginner level homelab",
          "imageUrl": "https://preview.redd.it/fgawot32si6a1.jpg?auto=webp&s=e9f12f7b8853adb34e9077af993ac51887302696"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zofgrp/what_the_best_and_cheapest_10_gbe_switch_from_ebay/",
          "author": null,
          "description": "submitted by    /u/AdslModem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zofgrp/what_the_best_and_cheapest_10_gbe_switch_from_ebay/",
          "publishedOn": "2022-12-17T20:32:48.000Z",
          "wordCount": 14155,
          "title": "What the best and cheapest 10 Gbe switch from Ebay?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zof81x/gpu_options/",
          "author": null,
          "description": "submitted by    /u/BadCoNZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zof81x/gpu_options/",
          "publishedOn": "2022-12-17T20:22:25.000Z",
          "wordCount": 14189,
          "title": "GPU Options?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zoe9qa/proxmox_hosting_pfsense_how_to_update/",
          "author": null,
          "description": "HI all, I'm trying to figure out how to get PVE to stay updated while hosting my router. I've got pfSense running as my main home firewall, virtualized in Proxmox, running on one of those Topton N5015 4-interface boxes. NICs are used as follows:\n  \nWAN (PCI passthrough, to cable modem)\n LAN (PCI passthrough, pfSense at 192.168.1.1)\n (unused)\n Proxmox management (192.160.0.100)\n  \nThe interaction with Proxmox here is kind of clunky. I don't have a management network or anything, so if I want to log into the PVE on this one, I have to go down into the basement where this thing lives, and directly plug in an a cable, and set a static IP and finally connect. That's clunky but workable. The real issue is that PVE can't see the internet, and therefore can't get updates or anything. And if I want to run other services on PVE here, they don't run on my LAN network, and they can't see the internet either.\n The real issue to solve is getting updates for PVE. Any tips on how to do that? It seems like I could use NIC 3 to connect into the LAN - and connect to the internet in a sort of Inception-style labyrinth. Is that wise or even possible? Is there some way to update PVE offline with a usb stick or something?\n (I suppose one solution is to ditch proxmox and run pfSense bare metal. I liked the idea of being able to snapshot my firewall in case anything goes wrong, and the little Topton unit is almost overpowered to just run as a firewall, so I figured it would be nice to use any extra power for other services. But I am open to running bare metal if it makes more sense.)\n    submitted by    /u/macgood  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zoe9qa/proxmox_hosting_pfsense_how_to_update/",
          "publishedOn": "2022-12-17T19:41:27.000Z",
          "wordCount": 15722,
          "title": "Proxmox hosting pfSense - how to update?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zodjfy/wifi_heat_map_for_home/",
          "author": null,
          "description": "Did you make a WiFi heat map for your home? If so what software did you use?\n    submitted by    /u/albertyiphohomei  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zodjfy/wifi_heat_map_for_home/",
          "publishedOn": "2022-12-17T19:08:46.000Z",
          "wordCount": 14185,
          "title": "WiFi heat map for home",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zocqhf/query_homelab_to_find_update_in_osservers/",
          "author": null,
          "description": "Does that things exist ? A program who query your home lab to find update and notify you ? Like some docker , os , installed webserver, proxmox, esx, nas etc… and you receive a nice email with current version vs new version all in one place ?\n    submitted by    /u/toasterqc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zocqhf/query_homelab_to_find_update_in_osservers/",
          "publishedOn": "2022-12-17T18:33:16.000Z",
          "wordCount": 16878,
          "title": "Query homelab to find update in os/servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zocn1x/jailbroke_an_old_surface_2_rt_with_windows_10/",
          "author": null,
          "description": "submitted by    /u/abcmitch123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zocn1x/jailbroke_an_old_surface_2_rt_with_windows_10/",
          "publishedOn": "2022-12-17T18:29:18.000Z",
          "wordCount": 14357,
          "title": "Jailbroke an old Surface 2 RT with Windows 10, repurchased it to be a wall tablet, unfortunately it can't run Lovelace dashboard no matter how hard I tried, but it can at least do HADashboard from Appdaemon!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zoalmk/have_any_hp_gen8_server_owners_done_cpu_upgrades/",
          "author": null,
          "description": "Currently running an e3-1220 v3 on my ML310e and would like to pick up a e3-1275L v3 to reduce power consumption and add some much needed hw encoding igpu. \n The cpu isn’t officially listed as supported and I’m not sure if the motherboard even supports using the igpu. \n I know the HW is kinda old but wondering if anyone else here have gone through the same thing and can confirm the cpu is a drop in replacement. \n Thanks!\n    submitted by    /u/machineglow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zoalmk/have_any_hp_gen8_server_owners_done_cpu_upgrades/",
          "publishedOn": "2022-12-17T16:57:10.000Z",
          "wordCount": 15798,
          "title": "Have any HP Gen8 server owners done CPU upgrades?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zo7toa/small_homelab/",
          "author": null,
          "description": "Hi ! Created my new homelab :) . I hope having finished to connect it, and set configuration with hypervisors in few days.\n    submitted by    /u/Spiritual-Cell-5775  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zo7toa/small_homelab/",
          "publishedOn": "2022-12-17T14:48:52.000Z",
          "wordCount": 14250,
          "title": "Small homelab !",
          "imageUrl": "https://preview.redd.it/xm41ia1uii6a1.jpg?auto=webp&s=7ff31a7284282fbaaf43c5bce75bc7b77730358e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zo5vj7/my_portable_homelab_in_a_box/",
          "author": null,
          "description": "submitted by    /u/itschalee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zo5vj7/my_portable_homelab_in_a_box/",
          "publishedOn": "2022-12-17T13:03:47.000Z",
          "wordCount": 16633,
          "title": "My portable homelab in a box",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zo4g8v/my_basic_setup_pi4_ssd/",
          "author": null,
          "description": "submitted by    /u/yimejky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zo4g8v/my_basic_setup_pi4_ssd/",
          "publishedOn": "2022-12-17T11:31:59.000Z",
          "wordCount": 15494,
          "title": "My basic setup: PI4 + SSD",
          "imageUrl": "https://preview.redd.it/ls4u95cd1g6a1.jpg?auto=webp&s=a074019acb317146c4947ae515ab7b15a0b4b233"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zo13kn/action_required_lastpass_security_incident_email/",
          "author": null,
          "description": "submitted by    /u/ultrahkr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zo13kn/action_required_lastpass_security_incident_email/",
          "publishedOn": "2022-12-17T07:39:07.000Z",
          "wordCount": 18617,
          "title": "Action Required: LastPass Security Incident (Email from LastPass)",
          "imageUrl": "https://external-preview.redd.it/G9jqQ8RKKkA421WBahtFV4b3_3mlgA2H-Iq22bbBPdU.jpg?auto=webp&s=4093177df40355f323662df05b2196068595db62"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znunqf/dont_know_to_match_all_my_needs_beginner/",
          "author": null,
          "description": "Hi to everyone,\n I'm really new here and very newbie at this topic. But I've been reading a lot since some time ago.\n I want to host some services at home, but I really don't know how to match all my ideas.\n First, I'm going to change my router's ISP Provider. I think I'm going to buy a Netgear x4s R7800 and to install OpenWRT on it. I was about to buy a a Turris Omnia for 170€, but it was out of my price range. And I can get the Netgear for just 60€.\n Second, I have a Qnap TS-431P2 with 8GB and 2x10TB HDD. But I'd like to sell it because I'd like to install another OS, like Debian.\n I'd like to have these services at home, only for LAN accessing:\n - OpenMediaVault? I have thousands of photos, and we'd like to backup my photos from our android and laptop devices.\n - Nextcloud.\n - Suricata to monitor all my network.\n - Some application to see the all the photos.\n - Pi-hole.\n Then, I've thought to get a device like a mini-pc to handle all of that. Install a linux on it, and create all that services as containers. Is it possible to do it like that? First I thought to buy a Rpi 4 8GB, but I've seen a Fujitsu Q920, which I think is better, and I can get one second handly even cheaper than a Rpi. Any other better HW solution?\n Please, any comments, advices or links would be really appreciated.\n Thank you in advance.\n    submitted by    /u/t0uxe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znunqf/dont_know_to_match_all_my_needs_beginner/",
          "publishedOn": "2022-12-17T01:21:52.000Z",
          "wordCount": 14150,
          "title": "Don´t know to match all my needs - Beginner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znuaq9/building_my_network_topology/",
          "author": null,
          "description": "I found this very good software for make my network topology (only for MacOS)\n Link: https://ermitacode.com/networkview.html\n ONU: DATACOM DM986-100\n Router: Mikrotik RB750GR3\n Switch: TPLINK 1008G\n WIFI: TLINK DECO M4\n Subnets: 10.1.1.0/24 - DECO WIFI / 192.168.100.1 - RB LAN\n Screenshots\n Physical Infra\n Logical Infra\n Deco Wireless LAN\n Subnet 10.1.1.0/24 LAN\n    submitted by    /u/jraimonxd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znuaq9/building_my_network_topology/",
          "publishedOn": "2022-12-17T01:03:15.000Z",
          "wordCount": 13716,
          "title": "Building my network topology",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znt7ab/got_this_from_work_did_i_score/",
          "author": null,
          "description": "submitted by    /u/BeachOG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znt7ab/got_this_from_work_did_i_score/",
          "publishedOn": "2022-12-17T00:09:11.000Z",
          "wordCount": 14570,
          "title": "Got this from work, Did I score?",
          "imageUrl": "https://preview.redd.it/vspvmpix5e6a1.jpg?auto=webp&s=1d821aa5199d5069d4f4912cc016e063c6f9541e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znt2wz/what_are_some_good_network_documentation_programs/",
          "author": null,
          "description": "Working on a project that will later be manged by different people in the future and i need a good program/services to make my documentation.\n    submitted by    /u/Twitch_Exicor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znt2wz/what_are_some_good_network_documentation_programs/",
          "publishedOn": "2022-12-17T00:03:17.000Z",
          "wordCount": 13768,
          "title": "What are some good network documentation programs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znsvpw/where_to_even_start_looking_for_another_ups/",
          "author": null,
          "description": "I'm pretty burned out after the whole cyberpower fiasco, thank god for costco's 1 year return policy at least.\n I don't think i'll be able to go without a UPS again, the power lines entering my neighborhood will fall if you look at them funny and it's been useful more than a dozen times this year and it saved me from quite an extreme brownout we had a few months ago. I've been looking around online and here's what I've been looking for.\n - ~1500VA\n - 900+W\n - Pure Sinewave \n I've heard quite a lot of good things about Eaton and thus i've been looking at the Eaton 5SC1500 recently, however the only thing holding me back is all the reviews and mentions online about the fan noise. \n Specs are listing 40dB at 1m, that's insane. I have my UPS under my desk and I sleep in the same room, from what I've heard the fan runs 24/7 and not just when the inverter is running, I wouldn't have a problem with that if it weren't so loud though. \n I've heard about some people replacing the fan with a noctuca fan but I'm not sure if i'm comfortable with this, a lot of the posts mentioning this don't specifically mention which model they're working on so I'd rather not just go out and replace the fan off a vague guide. \n It's really a bummer given that everything else about the UPS sounds perfect and is as close as it gets to the cp1500pfclcd.\n Does anyone have any ideas? Either towards the eaton unit or some other recommendations, I'm quite busy day to day and in my spare time i've been trying to look around for something that doesn't break the bank (<$500) but my attempts seem to be futile and it's getting really tiring.\n    submitted by    /u/Distinct-Guidance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znsvpw/where_to_even_start_looking_for_another_ups/",
          "publishedOn": "2022-12-16T23:54:13.000Z",
          "wordCount": 14349,
          "title": "where to even start looking for another UPS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znsqsg/having_issues_with_a_10gb_connection_to_nas/",
          "author": null,
          "description": "About 2 years ago, I decided to start on a homelab of my own beginning with a Dell R720 running TrueNAS. Everything has been running well, but given that I've been throwing 150 gig archives to it constantly, I decided it was time to upgrade from the base nic to one with 10GbE capabilities in a direct attach/peer to peer config with my main desktop. The x540 with 2 RJ45 10GbE and 2 1GbE ports installed nicely and has connected to my 1GbE network albeit limited to the slower speeds.\n My current issue is getting my desktop to connect to the R720. Turns out the card I purchased is an x540 Convergence Network Adapter. After installing the drivers from Intel, I'm not getting any network activity when plugged into the R720 nor when plugged into the switch (I've tried a crossover cable and a patch cable). \n Am I missing anything or do I need to find another NIC?\n    submitted by    /u/iamthesargent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znsqsg/having_issues_with_a_10gb_connection_to_nas/",
          "publishedOn": "2022-12-16T23:47:28.000Z",
          "wordCount": 13966,
          "title": "Having issues with a 10gb connection to NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znsll5/virtualize_cisco_deviceshomelab/",
          "author": null,
          "description": "I'm currently studying for my ccna. I'm about halfway through the content and would like to implement knowledge I've learned in a homelab setup I have on esxi on a Dell server.\n My question is..is their anyway to virtualize a cisco router/switch? All the things I found are deprecated abd no longer supported by esxi. I recognize this is overkill for. Ccna but it'd be a fun project abd would give me lots of practice\n    submitted by    /u/Party-Molasses-6130  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znsll5/virtualize_cisco_deviceshomelab/",
          "publishedOn": "2022-12-16T23:40:57.000Z",
          "wordCount": 13792,
          "title": "virtualize cisco devices...homelab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znrdkq/it_happened/",
          "author": null,
          "description": "I’ve been offered a security position as a promotion from my current “help desk masquerading as Jr sys admin” role that I’ve had. So many of the interview questions weren’t things I encountered in my day to day work life, but are things I’m at least beginning to understand thanks to my homelab and self-hosted projects!\n That’s all I came to say. To everyone else that’s plugging away in their homelabs, never discount the value the knowledge you’re accumulating. \n I’m trying to figure out what my reward should be once this change makes its way to my paychecks… expand the capabilities of my proxmox cluster with another node, with more ram for an existing node, of by getting myself a legacy Unix workstation (Sun or SGI)…. I know what will pay off in the long term; it’s just not nearly as fun sounding compared to other idea, which will be self gratifying but completely useless :)\n    submitted by    /u/AuthenticImposter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znrdkq/it_happened/",
          "publishedOn": "2022-12-16T22:45:23.000Z",
          "wordCount": 14255,
          "title": "It happened!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znqg3l/looking_for_homelab_ideas_to_use_as_playground_to/",
          "author": null,
          "description": "It seems like a lot of the labs on here are focused on personal projects like creating a server to store media for example, and there’s also a pretty overwhelming amount of info on here\n Does anyone have any recommendations or resources to learn and practice as many IT skills as possible? Like a homelab that I can use as a playground to practice sysadmin and networking \n Ideally either virtual or with hardware I can get cheap too\n    submitted by    /u/Altruistic-Carpet-43  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znqg3l/looking_for_homelab_ideas_to_use_as_playground_to/",
          "publishedOn": "2022-12-16T22:05:07.000Z",
          "wordCount": 14478,
          "title": "Looking for homelab ideas to use as playground to learn and practice IT concepts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znphig/storage_redesign_question/",
          "author": null,
          "description": "So currently my homelab is a single R720 running Esxi hosting all my VMs, and a homebuilt 4U storage server running TrueNAS. I recently decided to upgrade my storage and have a NetApp DS4246 on the way.\n ​\n To save rack space, I was considering either virtualizing TrueNAS or using possibly Windows Server Storage Spaces and direct attaching it to the R720 instead. Has anyone have experience with a TrueNAS virtualized and using a disk shelf?\n    submitted by    /u/Ironfox2151  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znphig/storage_redesign_question/",
          "publishedOn": "2022-12-16T21:22:52.000Z",
          "wordCount": 14192,
          "title": "Storage Redesign question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znoui6/home_lab_set_up_help/",
          "author": null,
          "description": "Anyone available to help out with setting up my homelab?\n I created a local server and was advised that I should set up a virtual server instead. So I'm trying to start from scratch. Will I have to reinstall os? \n Is there anyway to go back to the point that I started at. I basically just did the wizard and installed Active directory, DHCP, and DNS. So I suppose i may just need to remove those roles. \n ​\n Any info would be appreciated.\n    submitted by    /u/givenofaux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znoui6/home_lab_set_up_help/",
          "publishedOn": "2022-12-16T20:54:41.000Z",
          "wordCount": 14404,
          "title": "Home lab set up help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znmddb/are_these_any_good_new_workplace_said_i_could/",
          "author": null,
          "description": "submitted by    /u/CaptBobRoss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znmddb/are_these_any_good_new_workplace_said_i_could/",
          "publishedOn": "2022-12-16T19:07:16.000Z",
          "wordCount": 14761,
          "title": "Are these any good? New workplace said I could take it. Thought it might be useful for learning vlans and switch management.",
          "imageUrl": "https://preview.redd.it/qay3dg32oc6a1.jpg?auto=webp&s=a4ec914250915d5c8f1f2832e061d65e0cdca588"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znm26n/finally_caved_in_and_bought_a_2d_printer_and_put/",
          "author": null,
          "description": "submitted by    /u/dheera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znm26n/finally_caved_in_and_bought_a_2d_printer_and_put/",
          "publishedOn": "2022-12-16T18:53:47.000Z",
          "wordCount": 14656,
          "title": "Finally caved in and bought a 2D printer and put it on a sliding drawer",
          "imageUrl": "https://preview.redd.it/ivkhwpq04b6a1.jpg?auto=webp&s=bf99927d89693796384df042572eaf62785df447"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znluuf/is_this_overkill_for_a_home_labnetwork/",
          "author": null,
          "description": "Mikrotik 1072 will handle NAT and most routing\n I am debating whether to use OPNsense as a firewall in front of the Mikrotik or to just use its built in firewall. Suggestions would be greatly appreciated.\n HP 2920 will be used as the core, also have a brocade 6610 available if that is a better option\n Access points will connect to 24 port Ubiquiti switch\n Wired clients will connect to hp 2530\n DHCP and RADIUS servers will live on a Supermicro server.\n Some of the subnets are temporary to keep the family online until RADIUS is fully set up.\n I would love to hear your thoughts on this as well as any suggestions for additional things I should do.\n    submitted by    /u/bigmac_9000__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znluuf/is_this_overkill_for_a_home_labnetwork/",
          "publishedOn": "2022-12-16T18:44:49.000Z",
          "wordCount": 18220,
          "title": "Is this overkill for a home lab/network?",
          "imageUrl": "https://preview.redd.it/ufzyvh82kc6a1.jpg?auto=webp&s=66ee4295d891f82692c70352815e945f5b23f441"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znlgca/cooling_options/",
          "author": null,
          "description": "submitted by    /u/redfoxkiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znlgca/cooling_options/",
          "publishedOn": "2022-12-16T18:26:54.000Z",
          "wordCount": 14425,
          "title": "Cooling options?",
          "imageUrl": "https://preview.redd.it/v6c81y0sgc6a1.jpg?auto=webp&s=5686ea956d8b7ecad7a8d43fda9801e3d834762c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znjlai/homelabnetwork_evolution/",
          "author": null,
          "description": "submitted by    /u/nowhereman1223  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znjlai/homelabnetwork_evolution/",
          "publishedOn": "2022-12-16T17:06:46.000Z",
          "wordCount": 16918,
          "title": "HomeLab/Network Evolution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znibv9/cpu_upgrade_go_with_xeon_e516xx_v4_e526xx_v4_or/",
          "author": null,
          "description": "Are there any other considerations besides TDP, core and thread count, and price?\n They all seem to work in single CPU systems but the prices vary quite a bit on eBay between these. \n Should I go for the best combination of price, cores, TDP or is there more to it than that between single, dual, and quadruple capable Xeons?\n It’s to put in a Z440 workstation with 128GB RAM running proxmox. Currently running an E5-1620v4. \n Main concern is power usage as a kWh is 0.30$ here. Workload is containers and VMs.\n    submitted by    /u/phowntabir  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znibv9/cpu_upgrade_go_with_xeon_e516xx_v4_e526xx_v4_or/",
          "publishedOn": "2022-12-16T16:12:53.000Z",
          "wordCount": 16235,
          "title": "CPU upgrade: go with Xeon E5-16xx v4, E5-26xx v4, or E5-46xx v4?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zngx8b/an_ode_to_obsolescence_lets_appreciate_our_old/",
          "author": null,
          "description": "I see a lot of posts here showing off people's nice-looking racks. You know what I mean, you perverts. Lots of 1U servers and 48 port switches and fiber runs and disk chassis and the like. It's all pretty cool, but I usually find myself wondering \"what in the world are these people doing with all this gear, and also how much is their power bill?\"\n I don't have a rack, but I do have a lot of shelf space, and I have my old workhorse which sits in my basement that deserves some accolades. It's the Ford F150 of virtualization servers. It's running mostly hardware ranging between 2014-2017, but it serves literally everything in my house and has more than enough overhead for anything else I'd require or add to it. The newest thing about it is the case, a Fractal Define 7, that I migrated it in t…",
          "link": "https://www.reddit.com/r/homelab/comments/zngx8b/an_ode_to_obsolescence_lets_appreciate_our_old/",
          "publishedOn": "2022-12-16T15:13:38.000Z",
          "wordCount": 20364,
          "title": "An ode to obsolescence (let's appreciate our old workhorses!)",
          "imageUrl": "https://external-preview.redd.it/EiVhwXJd0pVUZIYSNHgQRZF_EMNDjtt06HeSRyxgV74.jpg?auto=webp&s=0c05e12811231e0e14bfd8978667169c20669561"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zncq1z/found_some_old_pictures_of_my_home_lab_that/",
          "author": null,
          "description": "submitted by    /u/kjp12_31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zncq1z/found_some_old_pictures_of_my_home_lab_that/",
          "publishedOn": "2022-12-16T11:43:10.000Z",
          "wordCount": 15355,
          "title": "Found some old pictures of my home lab that helped me with the CCIE DC Lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znbram/16gb_ram_enough_for_nas/",
          "author": null,
          "description": "I read TrueNAS recommends 32GB RAM So maybe another OS ? OMV?\n Super old HP MicroServer (4bays).\n    submitted by    /u/Inevitable-Cow-7057  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znbram/16gb_ram_enough_for_nas/",
          "publishedOn": "2022-12-16T10:41:56.000Z",
          "wordCount": 15673,
          "title": "16GB RAM enough for NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/znbk4c/i_have_quite_a_few_sata_ssds_drives_left_over_all/",
          "author": null,
          "description": "Based in the Netherlands. Give them to a charity? Find other homalabbers in 'need' to send them to? I usually use NVMe's for OS installs, and use SATA ports for either spinning disks or 4/8TTbyte SSDs and these smaller drives are just not worth 'wasting' a SATA port over.\n Anyone have a similar problem? How did you solve it?\n https://preview.redd.it/zk8h59g2m86a1.jpg?width=4080&format=pjpg&auto=webp&s=0de4bcdf0af19e760f71d2e2929f62bcf1e0ca91\n    submitted by    /u/campr23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/znbk4c/i_have_quite_a_few_sata_ssds_drives_left_over_all/",
          "publishedOn": "2022-12-16T10:28:20.000Z",
          "wordCount": 15822,
          "title": "I have quite a few SATA SSDs drives 'left over', all 128Gbyte or 256Gbyte, what to do with them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn7n5o/i_only_wanted_a_place_to_put_my_udm_se/",
          "author": null,
          "description": "submitted by    /u/charisbee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn7n5o/i_only_wanted_a_place_to_put_my_udm_se/",
          "publishedOn": "2022-12-16T06:03:51.000Z",
          "wordCount": 15416,
          "title": "I only wanted a place to put my UDM SE",
          "imageUrl": "https://preview.redd.it/uuu8v8bas86a1.jpg?auto=webp&s=0de2c20f5576cbfc57f38a1be4e05bbcd012cf33"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn6k18/home_lab_fail/",
          "author": null,
          "description": "Picked up a P400 Quadro to put in my Dell t440 and pass through to a Plex VM. It was delivered today. Today was also the day I found out that the sole 16x slot on the mobo is tied to CPU2. I don't run a second CPU. 🤬 🤦 \n Needed to share that one.....\n    submitted by    /u/tiberiusgv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn6k18/home_lab_fail/",
          "publishedOn": "2022-12-16T05:00:18.000Z",
          "wordCount": 15036,
          "title": "Home Lab Fail",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn29f4/amd_opteron_6234_not_showing_correct_core_count/",
          "author": null,
          "description": "As the title states, I recently purchased an old HP DL585 G7 to use as a game server. It is posting saying only 8 active cores per chip when it should be 12. Is this something similar to the bulldozer cpu debacle with amd, (Claimed 8 core on a 4 core chip) or is there a bios setting I might be able to access to utilize all cores on all 4 chips?\n Also, is there a way to set the fan speed? It's a bit loud sitting on my desk.\n    submitted by    /u/jwvan82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn29f4/amd_opteron_6234_not_showing_correct_core_count/",
          "publishedOn": "2022-12-16T01:16:25.000Z",
          "wordCount": 14027,
          "title": "AMD opteron 6234 not showing correct core count",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn1hi3/mass_loaded_vinyl_rack/",
          "author": null,
          "description": "I just got my first rack and after some blunders got everything together. It's not obnoxiously loud most of the time, but its noticeable in the background. Got a Dell R620 with dual E5-2643 V2 chips. I read someone had mentioned Mass Loaded Vinyl as an option and I wanted to know if anyone had experience creating a \"wall\" out of one for the sides of the rack, and if that actually dampened the volume. I thought about using the insert holes on the sides of the rack to affix a panel to the side.\n ​\n Secondly, I grabbed a static rack kit from dell not quite realizing what static really implied, which wouldn't be a huge deal but when I attempted to remove the server, I can pull it out about 6 inches and then it almost seems to catch on something and won't come out further. Anyone experience that, is that normal? I pretty much have to remove the rails and make sure there is lots of clearance around the rack if I ever want to take it out all the way (and I'm dreading the thought).\n https://preview.redd.it/50227k60p56a1.jpg?width=1195&format=pjpg&auto=webp&s=87c1e972d8e9902aa89651d3a2f2f0a2ed9d730d\n    submitted by    /u/breadcrumb1977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn1hi3/mass_loaded_vinyl_rack/",
          "publishedOn": "2022-12-16T00:39:10.000Z",
          "wordCount": 14207,
          "title": "Mass Loaded Vinyl Rack",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn1aym/refactored_my_proxmox_terraform_code/",
          "author": null,
          "description": "Hey y'all,\n A while back I got started using terraform to create/manage VMs on my proxmox homelab (thank you to those of you who have shared blog posts about this). \n One thing that bothered me was how I was essentially copy/pasting the resource definitions when I wanted to create a new VM, so I recently went through a big refactor to reduce the amount of configuration required to create a new vm and wanted to share with this community in case others find it useful. With this setup I can now define a new VM with three lines of yaml, push my changes and have them deployed by the gitlab ci/cd pipeline. \n https://github.com/nohbdy1745/proxmox-terraform \n I have this deployed on a gitlab instance running in a proxmox VM, with gitlab managing my terraform state, and have the gitlab ci/cd pipeline setup so I can push changes to my terraform configuration and have them deployed from there. I set it up so that you don't need to have gitlab managed terraform state, you would just have to change the backend in main.tf and you can use the make commands to run everything. \n Hope this is useful to someone else. I'm also not an expert with terraform so if you happen to take a look and have feedback please let me know! \n    submitted by    /u/nbdy1745  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn1aym/refactored_my_proxmox_terraform_code/",
          "publishedOn": "2022-12-16T00:30:46.000Z",
          "wordCount": 2038,
          "title": "Refactored my proxmox terraform code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn13p6/building_first_nas/",
          "author": null,
          "description": "Im going to build my first NAS will this be good?\n ​\n CPU: AMD Ryzen 3 3100 Motherboard: ASUS ROG Strix B550-I Cooling: Stock cooler GPU: GTX 1660 Super Overclocked 6GB PSU: Corsair RMX Series (2021), RM650x, 650 Watt, Gold, Fully Modular Power Supply Drives: Crucial MX500 500GB 3D NAND SATA 2.5 Inch Internal SSD and Western Digital 6TB WD Red Plus NAS Internal Hard Drive HDD Ram: 16gb 3600 Case: Fractal Design Node 804 OS: Will be using unraid\n ​\n Going to use this for storing media, streaming movies/shows, hosting csgo or minecraft servers and seeding torrents\n    submitted by    /u/Mr_TuxCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn13p6/building_first_nas/",
          "publishedOn": "2022-12-16T00:21:19.000Z",
          "wordCount": 14319,
          "title": "Building first NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn0whm/homelab_desktop_choices/",
          "author": null,
          "description": "Hi guys \n Help me choose one of these :\n 1.from Local 2nd hand store : \n Dell OptiPlex 3050 MT Core i7 7th Gen 32 GB ddr4 2400t 16x2 Nvidia gt 730 2gb gddr5\n 330$ \n Or \n 2.From Alibaba : \n x99+2690v4+4*16g DDR4 ECC RAM (64G)+ CPu fan + Power Supply 600w + 512G m.2 = 300$\n The 2nd offer gives Xeon 2690 V4 with 14 cores and 28 threads The first gives 4 cores ...8 threads . .... My build is for : \n 1.media server and I have 4×6TB and I am thinking of running Proxmox with VMs .then Dockers on VMs . \n 2.nextcloud for family . \n 3.NVR sys for house .\n    submitted by    /u/MrJwan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn0whm/homelab_desktop_choices/",
          "publishedOn": "2022-12-16T00:12:30.000Z",
          "wordCount": 14033,
          "title": "Homelab Desktop Choices ..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn0ees/do_sata_power_switches_work_well_power_onoff/",
          "author": null,
          "description": "Do SATA power switches such as these work well or is the feature considered hacky? They don't seem to be popular--does SATA not support this? I would think SATA being hot swappable means this is also a supported feature.\n Basically I have a couple of external drives for cold storage that take up space and I want to chuck them into my case. I was going to shuck them but leave the USB to SATA logic board intact and route the USB and AC power cable through PCIe slot into the case. Unfortunately the logic board prevents the drives from being mounted properly in my Node 304 case (also, somehow my WD Reds and another Seagate drive only support 3 screw mounts? Did Fractal mess up?).\n    submitted by    /u/rofic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn0ees/do_sata_power_switches_work_well_power_onoff/",
          "publishedOn": "2022-12-15T23:50:29.000Z",
          "wordCount": 14103,
          "title": "Do SATA power switches work well? Power on/off drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zn0bxi/10gb_or_25gb/",
          "author": null,
          "description": "Hello, I have a Supermicro Unraid server that I would like to connect to my Windows PC. I’ve been researching 10GB over SFP+ and 25GB over SFP28 SFP+. Do you know if the NAS could take full advantage of 25GB or would it be bottlenecked by the hard drive read/write speed of 160MB/s? What speeds could I realistically expect when transferring files between the server and PC? Thank you for any help!\n    submitted by    /u/BlueGalaxy1000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zn0bxi/10gb_or_25gb/",
          "publishedOn": "2022-12-15T23:47:27.000Z",
          "wordCount": 14529,
          "title": "10GB or 25GB?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmzske/dell_t330_without_a_service_tag/",
          "author": null,
          "description": "Hi, i recently bought on ebay a used Dell T330 with idrac8 board already installed, but i notice the enterprise license are not present, so i go to check the service tag trough the idrac base menu, i found out this: Service tag: XXXXXXX , i start thinking is not normal. What I can do now?\n    submitted by    /u/Virtual_Surround  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmzske/dell_t330_without_a_service_tag/",
          "publishedOn": "2022-12-15T23:26:14.000Z",
          "wordCount": 14168,
          "title": "Dell T330 without a service tag",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmz508/dell_poweredge_r240_supporting_intel_quick_sync/",
          "author": null,
          "description": "I see the E-2XXXG processors all support it but wondering if anyone tried?\n I'm looking for low powered 1U machines that support QSV.\n    submitted by    /u/keithah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmz508/dell_poweredge_r240_supporting_intel_quick_sync/",
          "publishedOn": "2022-12-15T23:00:53.000Z",
          "wordCount": 13901,
          "title": "Dell PowerEdge r240 supporting Intel Quick Sync using a E-2144G?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmz3ib/proxmox_ve_on_a_server_or_proxmox_ve_on_an_intel/",
          "author": null,
          "description": "I want a homelab for virtual pentesting and a NAS. I'm 16 years old so I still live with my parents, and they take care of the electricity bill. I also have a budget of under 1000.\n    submitted by    /u/MKzlol  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmz3ib/proxmox_ve_on_a_server_or_proxmox_ve_on_an_intel/",
          "publishedOn": "2022-12-15T22:59:41.000Z",
          "wordCount": 14149,
          "title": "Proxmox VE on a server OR Proxmox VE on an Intel® NUC Mini PCs with nas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmym21/workstation_mainboard_for_ryzen_5_5600x/",
          "author": null,
          "description": "My current homeserver is getting too small.\n I currently have a board that barely holds my GPU and ssd extension card. For future plans I need a mainboard that has more slots but I wonder if there is any workstation focused mainboard out there. Or are the gaming mainboards already the best to get when it comes to connectivity?\n ​\n The scenario:\n I have a server that runs Proxmox. I then have a bunch VMs/containers for my workload. All pretty basic except the gaming VM. I passthroguh my GPU, mouse and keyboard and connect to a screen.\n I might need more connectivity for that vm. E.g. to handle sound easily. I was thinking to buy a Thunderbolt extension card, also give that to the VM and then simply connect a docking station to it and be good. But for that I need at least one more card in the system... which does not fit currently.\n    submitted by    /u/soupdiver23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmym21/workstation_mainboard_for_ryzen_5_5600x/",
          "publishedOn": "2022-12-15T22:42:15.000Z",
          "wordCount": 14513,
          "title": "Workstation mainboard for Ryzen 5 5600X?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmxr81/how_have_you_racked_your_raspberry_pis/",
          "author": null,
          "description": "I am currently running two R Pis, and I dont see myself getting anymore (atleast not wired in this rack). Im trying to figure how would I \"rack\" them. Should I just leave them on a rack shelf, or have you people tried these different 3D printed/ metal Pi rack holders?\n ​\n Would love to hear any experiences!\n    submitted by    /u/gilfslayer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmxr81/how_have_you_racked_your_raspberry_pis/",
          "publishedOn": "2022-12-15T22:12:20.000Z",
          "wordCount": 15387,
          "title": "How have you \"racked\" your Raspberry Pis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmx019/powervault_tl2000_lto_library_buying_advice/",
          "author": null,
          "description": "submitted by    /u/31899  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmx019/powervault_tl2000_lto_library_buying_advice/",
          "publishedOn": "2022-12-15T21:43:34.000Z",
          "wordCount": 14338,
          "title": "Powervault TL2000 LTO Library Buying Advice",
          "imageUrl": "https://preview.redd.it/6vg1ryj6t46a1.jpg?auto=webp&s=540e6617780f592ce71cb4bddba4203ebeb335ae"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmv771/done_famous_last_words_haha/",
          "author": null,
          "description": "submitted by    /u/williamd002  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmv771/done_famous_last_words_haha/",
          "publishedOn": "2022-12-15T20:29:47.000Z",
          "wordCount": 16244,
          "title": "'Done'. Famous last words haha",
          "imageUrl": "https://external-preview.redd.it/fnDQxmHWF4428vE99hspVopgbQ1PQUqavL6OTLjTqPs.jpg?auto=webp&s=a90fe65afdb846f3ab9ddc7c95b7e0b93b2c4408"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmu17e/hp_prodesk_400_g4_i_can_install_linux_but_i_cant/",
          "author": null,
          "description": "Hi everyone, I just bought an HP Prodesk 400 G4 to start a home lab, but no matter what I do I can't seem to boot Linux.\n I installed both Proxmox and Ubuntu without any problem, but when I try to boot I just can't.\n I disabled secure boot from the BIOS settings and enabled Legacy mode, I downgraded BIOS firmware, but nothing worked.\n The computer previously had a 1TB hard disk, I installed Ubuntu on it and it won't boot either.\n Before I formatted the hard disk had Windows on it and it worked. My thoughts are that maybe the computer has some Linux block, so it can't boot Linux.\n Is there someone who maybe had the same issue and can help me?\n Thanks!\n    submitted by    /u/templare25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmu17e/hp_prodesk_400_g4_i_can_install_linux_but_i_cant/",
          "publishedOn": "2022-12-15T19:41:34.000Z",
          "wordCount": 15375,
          "title": "[HP Prodesk 400 G4] I can install Linux but I can't boot it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmtxs6/security_scanning/",
          "author": null,
          "description": "Looking for recommendations, either free or cheap to do an external scan for vulnerabilities. Can't seem to find anything that does much more than a basic port scan.\n    submitted by    /u/TechDiverRich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmtxs6/security_scanning/",
          "publishedOn": "2022-12-15T19:37:51.000Z",
          "wordCount": 14263,
          "title": "Security scanning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmtagk/home_nas_issues/",
          "author": null,
          "description": "Hey all.\n TLDR: What do you use for your home NAS (OS or Appliance)? Do you have a separate computer/server to run apps and use your NAS for storage?\n A few months ago, I switched from OMV to TrueNAS SCALE. I wanted stability and ease of use for my NAS because my family also relies on my NAS. I found OMV to be buggy, and not intuitive. In my opinion, I could not trust OMV. Now I am considering going back to OMV.\n TrueNAS SCALE has been great for me, at least if I used the very basic features of having a ZFS pool with a few SMB/NFS shares, but I wanted to run apps as well, such as Plex, Nextcloud, etc..., but that has been the biggest hassle for me, and I miss being able to use Docker Compose and apps just working.\n I added TrueCharts to my NAS to get all the apps I would want to run but li…",
          "link": "https://www.reddit.com/r/homelab/comments/zmtagk/home_nas_issues/",
          "publishedOn": "2022-12-15T19:11:03.000Z",
          "wordCount": 16536,
          "title": "Home NAS Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmt9a4/first_home_lab_build/",
          "author": null,
          "description": "I am building my first homelab, with spare pc part from a previous pc build of mine. Specs:\n Processor: i5 7500k Mobo: ASRock H270M-ITX Cooler: Noctua LH9i RAM:16gb 3200 Storage: WD blue 500gb | Segate 2tb GPU: NVIDIA 1060 3gb PSU: HDPLEX 400w w/ jhax 24pin mod connector Case: S4mini NFC OS: Ubuntu Server\n This would be used for a few thing hosting a Minecraft server for a few friends, hosting some local games emulators for my partner and I, media( tv movies, etc), and finally home assistant. Would the specs as is be able to handle this? And do you have any tips or recourses for set up? I am honestly pretty new when it come to trying to set up the cloud end of the gaming portion.\n    submitted by    /u/trevDaRev_ts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmt9a4/first_home_lab_build/",
          "publishedOn": "2022-12-15T19:09:54.000Z",
          "wordCount": 15572,
          "title": "First home lab build",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmsg10/update_meshlicious_9x_bay_unraid_nas_finally/",
          "author": null,
          "description": "submitted by    /u/stoph007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmsg10/update_meshlicious_9x_bay_unraid_nas_finally/",
          "publishedOn": "2022-12-15T18:36:12.000Z",
          "wordCount": 17302,
          "title": "Update - Meshlicious 9x Bay unRAID NAS Finally Filled!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmmb81/jankiest_setup_ever/",
          "author": null,
          "description": "submitted by    /u/NUCL3ARN30N  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmmb81/jankiest_setup_ever/",
          "publishedOn": "2022-12-15T14:24:59.000Z",
          "wordCount": 14855,
          "title": "Jankiest setup ever",
          "imageUrl": "https://preview.redd.it/c6o7ccbs446a1.jpg?auto=webp&s=2351c8411fedf4bdd1dcd01d8af931b345cb4253"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmhalb/use_my_public_ip_dynamic_as_a_proxy_in_second_pc/",
          "author": null,
          "description": "submitted by    /u/amannarula77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmhalb/use_my_public_ip_dynamic_as_a_proxy_in_second_pc/",
          "publishedOn": "2022-12-15T09:47:49.000Z",
          "wordCount": 18240,
          "title": "Use my Public IP( Dynamic ) as a Proxy in second PC ?",
          "imageUrl": "https://preview.redd.it/soyoqovp916a1.png?auto=webp&s=b7258019480e2df1551cf3ba99106a9ff0d7cf37"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zmg3kj/my_home_server/",
          "author": null,
          "description": "submitted by    /u/Outrageous-Painter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zmg3kj/my_home_server/",
          "publishedOn": "2022-12-15T08:27:53.000Z",
          "wordCount": 14957,
          "title": "My Home Server",
          "imageUrl": "https://preview.redd.it/f7en0gijv06a1.jpg?auto=webp&s=90eecec5c354b215aff3be90f6848e57cfa0548f"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm8mmp/any_app_on_linux_for_recording_sensor_data_wave/",
          "author": null,
          "description": "I'm looking for an app to real-time receive and plot sensor data (through TCP, sent by MCU with wifi) and save them for future analyzing. Like a PC oscilloscope.\n The features I need are: 1. Real-time receive and plotting 2. Data source can be TCP socket or named pipe (whatever as long as I can write a python script to be a middle converter) 3. Allow me to select a x-axis range to save a part of received data\n I've tried: - PulseView (can't real-time continuously receive) - LabPlot (KDE) (can't select a part of received data to save. And easy to crash) - Audacity (which is a sound wave editing software. Good for range selecting, but, can't set real-time data source to be other than mic. And can't show the wave if Y value larger than 1)\n Thank you guys\n    submitted by    /u/ArtisticJicama3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm8mmp/any_app_on_linux_for_recording_sensor_data_wave/",
          "publishedOn": "2022-12-15T01:38:58.000Z",
          "wordCount": 14193,
          "title": "Any app (on Linux) for recording sensor data (wave plot) sent from TCP ? (like oscilloscope)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm8gdt/should_have_bought_a_proper_rack/",
          "author": null,
          "description": "submitted by    /u/plantinspace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm8gdt/should_have_bought_a_proper_rack/",
          "publishedOn": "2022-12-15T01:30:39.000Z",
          "wordCount": 14865,
          "title": "Should have bought a proper rack...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm7whc/dont_act_so_surprised_ive_moved_on/",
          "author": null,
          "description": "submitted by    /u/Tri_Ban_Had  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm7whc/dont_act_so_surprised_ive_moved_on/",
          "publishedOn": "2022-12-15T01:05:36.000Z",
          "wordCount": 13948,
          "title": "Don’t act so surprised. I’ve moved on.",
          "imageUrl": "https://preview.redd.it/hdsv6746606a1.jpg?auto=webp&v=enabled&s=bddf52f87325fa5b62f48d324819b592cbc6c0b9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm7d5x/email_solutions_ses_vs_selfhosted/",
          "author": null,
          "description": "Hoping my fellow homelab community can weigh in on this. I run a few websites that send email (~1-5k per month) and have a bunch of homelab stuff on different domains that sends transactional emails (~500 per month).\n I have been using Mailgun for the last few years and whilst good, I have started having to pay each month as the amount of emails sent goes over the free tier. This has at most been around $6-$10 in a single month. I have been tying with the thought of switching over to amazon SES as its ridiculously cheaper. I then happened to stumble on the delights of Postal (postalserver.io).\n I am now stuck toying with the idea of SES or do I host my own Postal on a VPS somewhere? I send emails from roughly 20 different domains and would like to utilise security features where possible. I understand the issues with IP reputation that comes from email delivery.\n Am i better off just sticking with SES? Overall it will probably be cheaper. Or do I go Postal with slightly more VPS monthly cost but with the freedom and much better UI / dashboards?\n ​\n OR even better can I host Postal on AWS and get postal to send via SES and utilise the 62k free emails per month (i assume this either wont work or will require each domain to be verified in SES anyway?)\n    submitted by    /u/spudd01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm7d5x/email_solutions_ses_vs_selfhosted/",
          "publishedOn": "2022-12-15T00:41:14.000Z",
          "wordCount": 13803,
          "title": "Email Solutions (SES vs Selfhosted)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm701g/equallogic_type_10_controllers_sfp_10g_to_copper/",
          "author": null,
          "description": "Hello! I'm hacking around with an equallogic system that uses the type 10 controllers. I purchased some FSP+ -> RJ45 (copper) transceivers. I can only get them to link with my 10g switch if I force them 1g; hardly a solution. \n I've just tried them back-to-back with some 10g server ports ( for link/ping tests ) and that doesn't seem to function either. Does anyone have these running with copper interface SFP+ modules? Do you have a part number if so?\n    submitted by    /u/coldnight3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm701g/equallogic_type_10_controllers_sfp_10g_to_copper/",
          "publishedOn": "2022-12-15T00:24:53.000Z",
          "wordCount": 14203,
          "title": "Equallogic type 10 Controllers - SFP+ / 10G to copper woes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm6ll9/dl380_g6_not_posting/",
          "author": null,
          "description": "Hello all,\n I've recently gotten my hands on an HP DL380 G6 that I cannot for the life of me get to post. No matter what I've tried I cannot get any video output, not even as much as seeing the HP splash screen. Any help is greatly appreciated.\n I can't reach iLO by domain name, and does not show up in device list on my router so I cannot find an IP address (server may not even have a valid license).\n Last owner of the server was able to reach the BIOS, and did not make any configuration changes before I got it.\n Front panel indicators:\n  \nServer health indicator: solid green\n Server power indicator: solid green\n DIMMs: off\n Power supplies: off\n Processors: Solid amber\n Hard drive lights: come on for a split second and turn off almost immediately\n Fans: off\n Over temp: off\n Power cap: off\n  \nFixes I've tried are as follows: \n  \nResocketing CPUs, along with running each CPU individually\n Running minimum amount of DIMMs\n Using only 1 power supply\n Resocketing the power supplies\n Swapping the power supplies\n Changing VGA port used \n Did not try a different cable as I know for a fact the one I was using works\n \n Changing to a different monitor\n Flipping DIP switch 6 to on, letting system idle, then flipping it off (turning server off and removing power supplies before flipping it each time obv)\n Flipping DIP switch 1, 5, 6 to on, letting system idle, then flipping them off\n Simply letting it sit for an hour or so to see if it was just taking an absurd amount of time to boot\n  \nIf any more information is needed I'll happily provide it, and once again thank you for your help.\n    submitted by    /u/Typical-Voice-7350  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm6ll9/dl380_g6_not_posting/",
          "publishedOn": "2022-12-15T00:07:15.000Z",
          "wordCount": 15327,
          "title": "DL380 G6 not posting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm6fgw/december_2022_wiyh/",
          "author": null,
          "description": "Acceptable top level responses to this post:\n  \nWhat are you currently running? (software and/or hardware.)\n What are you planning to deploy in the near future? (software and/or hardware.)\n Any new hardware you want to show.\n  \nPrevious WIYH\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm6fgw/december_2022_wiyh/",
          "publishedOn": "2022-12-15T00:00:12.000Z",
          "wordCount": 14147,
          "title": "December 2022 - WIYH",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm68fq/network_map_application_in_docker/",
          "author": null,
          "description": "does anyone know of any application in docker (or no) that it is possible to create interactive network map, such as zabbix?\n    submitted by    /u/jraimonxd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm68fq/network_map_application_in_docker/",
          "publishedOn": "2022-12-14T23:51:28.000Z",
          "wordCount": 13942,
          "title": "Network Map Application in Docker",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm4kno/12v_car_battery_and_12v_device_advice/",
          "author": null,
          "description": "i live in car/camper van. i have some device. like rb4011 。and some poe camera.\n as far as i know all my device is ok with 12v dc. maybe +-25% votage range. \n but my problem is car battery votage change. like 9v-14.2 v . \n do i need DC-DC Converter like \n Victron Orion-TR DC-DC Converter - 12 VDC to 12 VDC - 9AMP Isolated ??????\n or i can connect most 12v device to battery directly. ?????\n i dont want damage my devices..\n but if i use Converter. i will lose some efficiency.... during dc to dc converter....\n    submitted by    /u/AmbulacneXu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm4kno/12v_car_battery_and_12v_device_advice/",
          "publishedOn": "2022-12-14T22:41:29.000Z",
          "wordCount": 14928,
          "title": "12v car battery and 12v device advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm4cj2/how_can_i_limit_internet_on_a_specific_device_for/",
          "author": null,
          "description": "I would like to provide only 1 hour of internet a day for a specific advice. \n What would be the best way and easiest to achieve this?\n    submitted by    /u/nambi_2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm4cj2/how_can_i_limit_internet_on_a_specific_device_for/",
          "publishedOn": "2022-12-14T22:32:20.000Z",
          "wordCount": 14282,
          "title": "How can I limit internet on a specific device for 1 hour a day",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm3za9/do_you_need_traefik_for_docker_swarm/",
          "author": null,
          "description": "I don't understand why so many tutorials and guides tells you to use traefik for docker swarm.\n as docker swarm should have built in load balancing, you would just access any node on the swarm at a certain port and you should be redirected to an active node right? so why the need for traefik?\n    submitted by    /u/BenPoss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm3za9/do_you_need_traefik_for_docker_swarm/",
          "publishedOn": "2022-12-14T22:17:23.000Z",
          "wordCount": 14828,
          "title": "do you need traefik for docker swarm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm0trl/stealth_quiet_rackmount_chassis_with_maximum/",
          "author": null,
          "description": "I have a 42U rack in my office and it needs to be filled! I have a 4U Rosewill 15bay that is 'quiet-ish', but im looking for a massive amount of bays, but it must be quiet.\n Any recommendations?\n --\n Goals:\n  \nRack mount\n Super quiet, upgrades or swapping out for consumer / quiet is fine, but it must be quiet \n The SuperMicro SQ PSU is not that quiet, I have that also, its still loud, but quieter than a jet turbine hahaa\n \n Maximum bays count\n Good build quality, I don't want cheap chassis to kill me with slow death of annoyance and failure\n  \n   submitted by    /u/cs_legend_93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm0trl/stealth_quiet_rackmount_chassis_with_maximum/",
          "publishedOn": "2022-12-14T20:08:12.000Z",
          "wordCount": 15106,
          "title": "Stealth quiet rackmount chassis - with maximum drive bays are the only requirement - any recommendations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm0nu2/uk_ups_sanity_checkrecommendations/",
          "author": null,
          "description": "Hello,\n I'm not sure if this is the right sub, but I tried posting on r/buildapc and it didn't get any responses. I've moved recently, and I'm on a new build estate which seems to be suffering with brown outs a few times a week. I've been told this will stop next year as the other side of the estate is connected, however it's worrying me a little as my NAS, PC and Mac mini have all been unexpectedly shutdown a few times. I'd like to attach:\n  \nSynology DS1817+ (5-60W)\n PC (750wPSU) (70-500W)\n Mac Mini (2-80W)\n Network gear (50-100W complete guess as I've not attached the meter yet)\n  \nI'm not much of a gamer, so the PC is very rarely pulling 500W+, it tends to idle at 70W and normal use may take it to 150W. I've been looking at a few of the calculators and for 3 minutes runtime something rated around the 1500VA/900W seems to be recommended. I've got no experience with UPSs at home, we use Eaton at work, but I've never had much to do with their configs. I think I can budget around £300, but I could stretch that a little. I've got some rack gear, so I'm open to either rack or freestanding units. These models seem to come up, or their rack equivalent:\n  \nCyberPower CP1500EPFCLCD\n Powercool Smart UPS 2000VA\n APC BX1600MI\n Eaton 5P850i\n  \nI'd be grateful for any feedback, recommendations and I can provide any other info if it helps. I'm slightly confused by the price differences for similar headline specs, I'm not sure if this is just a brand thing or some feature I should be focussing on. Any recommendation for the software setup, mainly for the Mac and NAS as they are always on. \n Thanks in advance :-)\n    submitted by    /u/trickster-is-weak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm0nu2/uk_ups_sanity_checkrecommendations/",
          "publishedOn": "2022-12-14T20:01:38.000Z",
          "wordCount": 16389,
          "title": "UK UPS Sanity Check/Recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zm0iyw/specs_or_user_feedback_regarding_touch_screens_on/",
          "author": null,
          "description": "submitted by    /u/Relaxybara  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zm0iyw/specs_or_user_feedback_regarding_touch_screens_on/",
          "publishedOn": "2022-12-14T19:56:28.000Z",
          "wordCount": 14958,
          "title": "Specs or user feedback regarding touch screens on Dell Optiplex AIO systems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlzwmv/wifi_ap_guest_access/",
          "author": null,
          "description": "I have been looking for a while and I'm a bit confused. As many others, my lab is composed of (close to) free stuff I gathered for years, I'd rather make things work with what I have.\n I recently upgraded my simple network (fritzbox + fritzrepeater, main network + guest access) to a more complex setup: fritzbox (as a vdsl modem), apu4c board running opnsense, Netgear GS324T managed switch, fritz repeater as an AP.\n As you can see, the fritzbox and the repeater are now far apart thus the mesh feature stopped working and with it the guest access, that's to be expected. What I don't understand is the following: for the guest access to work between the fritzbox and the repeater, there has to be some vlan shenningans, I doubt AVM invented a brand new mechanism to separate traffic. My guess was that somehow all fritzbox ports were trunked with the default vlan being for the main network and all traffic from guest access was tagged with a vlan id.\n I tried setting it up like that, but I couldn't identify the vlan id (tried a bunch but that's tedious and I'm unsure how to inspect traffic at the switch, never done port mirroring before, not sure how to use linux to listen to it).\n Anyway, my question is, does anyone know if AVM could be using some other technology? Is there another way to use a fritz repeater to have two separate networks?\n    submitted by    /u/bendem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlzwmv/wifi_ap_guest_access/",
          "publishedOn": "2022-12-14T19:29:35.000Z",
          "wordCount": 14375,
          "title": "Wifi AP guest access",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlzpso/i_need_to_mount_these_in_my_rack_but_i_find_it/",
          "author": null,
          "description": "submitted by    /u/igmyeongui  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlzpso/i_need_to_mount_these_in_my_rack_but_i_find_it/",
          "publishedOn": "2022-12-14T19:21:14.000Z",
          "wordCount": 15054,
          "title": "I need to mount these in my rack but I find it hard to find information about the right brackets online. Any help would be appreciated!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlxqm5/smart_home_and_homelab_network_diagram_after_4/",
          "author": null,
          "description": "submitted by    /u/FoxxMD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlxqm5/smart_home_and_homelab_network_diagram_after_4/",
          "publishedOn": "2022-12-14T18:01:06.000Z",
          "wordCount": 19099,
          "title": "Smart Home and Homelab network diagram after 4 years of evolution",
          "imageUrl": "https://preview.redd.it/8stun1nvkw5a1.png?auto=webp&v=enabled&s=4b6d31911af263643c7e72e1b9f307befef942cc"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlw716/does_anyone_know_what_this_is_the_port_in_red/",
          "author": null,
          "description": "submitted by    /u/daelikon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlw716/does_anyone_know_what_this_is_the_port_in_red/",
          "publishedOn": "2022-12-14T17:00:55.000Z",
          "wordCount": 15429,
          "title": "Does anyone know what this is? (the port in red circle)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlsldx/thats_just_bad_luck_double_battery_failure/",
          "author": null,
          "description": "submitted by    /u/Wobblycogs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlsldx/thats_just_bad_luck_double_battery_failure/",
          "publishedOn": "2022-12-14T14:36:42.000Z",
          "wordCount": 15242,
          "title": "That's just bad luck, double battery failure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlru2z/found_a_nice_low_power_vm_host/",
          "author": null,
          "description": "I needed to replace my older desktop PC that I was using as a VM host due to hardware failure. Wanted something small that could be tucked away in a corner but have enough to run the few VM's I use and came across this (MINIS FORUM U820). Not supper powerful, but out of the box, this thing is quick. I kept the 512 M.2 drive it came with for holding ISO's and so on and added in 2 1TB SSD's and upgraded the RAM to 32GB. The only issue I have so far is vanilla ESXi 7 will not see either NIC, but vanilla ESXi 8 will see the 2.5GB port (which is what I needed). I am sure if I played around with it, I could get the 1GB port working. Just thought I would pass this along for anyone looking at something small.\n    submitted by    /u/fieroloki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlru2z/found_a_nice_low_power_vm_host/",
          "publishedOn": "2022-12-14T14:06:30.000Z",
          "wordCount": 15303,
          "title": "Found a nice low power VM host",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zloit2/how_do_you_all_name_the_hosts_in_your_homelab/",
          "author": null,
          "description": "Everytime I set up a new project in my homelab I am stuck at which host name to assign. For debug and simplicity using the software and/or purpose seems to be the most sane answer.\n What do you do? Generic host names? Numbering? Software names? Anything creative? Do you follow a theme like greek letters/zodiacs/whatever?\n router dot domain is not that creative, neither is media dot domain. I saw someone using planets or stars but I guess that could become messy and not that obvious when debugging stuff not touched for a long time\n    submitted by    /u/carlinhush  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zloit2/how_do_you_all_name_the_hosts_in_your_homelab/",
          "publishedOn": "2022-12-14T11:26:32.000Z",
          "wordCount": 21570,
          "title": "How do you all name the hosts in your homelab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlnfxi/what_measures_are_other_european_homelabbers/",
          "author": null,
          "description": "Hey everyone,\n I'm living in europe and I've noticed that electricity prices in my area (Germany) have been exponentially increasing, thanks to Putin... (0,23€/kWh to 0,44€/kWh)\n I'm looking for ways to reduce my energy consumption and cut down on costs, and I'm wondering what measures other European homelabbers have taken to combat rising electricity prices.\n Currently i setup my Fujitsu Primergy RX600 S6 to only run from 9AM to 1AM so i can at lease save a third of the costs, by running it 16 hours a day im actually awake instead of 24/7. Also i configured power savings mode in iRMC. It is still running at 170 Watts.\n Any further advice, hints or suggestions would be greatly appreciated!\n    submitted by    /u/Alfagun74  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlnfxi/what_measures_are_other_european_homelabbers/",
          "publishedOn": "2022-12-14T10:20:54.000Z",
          "wordCount": 17636,
          "title": "What measures are other European homelabbers taking to combat rising electricity costs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlfjfa/just_moved_my_home_lab_to_the_new_jonsbo_n2/",
          "author": null,
          "description": "submitted by    /u/L680C  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlfjfa/just_moved_my_home_lab_to_the_new_jonsbo_n2/",
          "publishedOn": "2022-12-14T02:59:43.000Z",
          "wordCount": 16476,
          "title": "Just moved my home lab to the new Jonsbo N2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlesb5/homelab_the_before_and_after_the_glow_up/",
          "author": null,
          "description": "submitted by    /u/FoxInATrenchcoat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlesb5/homelab_the_before_and_after_the_glow_up/",
          "publishedOn": "2022-12-14T02:25:21.000Z",
          "wordCount": 15725,
          "title": "Homelab: The before and after (the glow up)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zld1sl/the_fusionio_ssd_original_documentation_so_it/",
          "author": null,
          "description": "submitted by    /u/_Fra_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zld1sl/the_fusionio_ssd_original_documentation_so_it/",
          "publishedOn": "2022-12-14T01:09:41.000Z",
          "wordCount": 13858,
          "title": "The fusion-io SSD original documentation, so it doesn't get lost",
          "imageUrl": "https://preview.redd.it/umkv10e5kr5a1.jpg?auto=webp&v=enabled&s=7c2851fe5d9c41ee3b89181813758562bc1a3b8c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlcycj/linux_mdadm_reduce_disk_count_but_increase_size/",
          "author": null,
          "description": "I have 6 4TB drives in RAID 6 on a server. I want to replace them with 4 14TB drives and keep it as RAID 6.\n Is there a way to increase the size of the array while decreasing the amount of disks, or do I have to rebuild everything.\n    submitted by    /u/Particular-Dog-1505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlcycj/linux_mdadm_reduce_disk_count_but_increase_size/",
          "publishedOn": "2022-12-14T01:05:31.000Z",
          "wordCount": 13958,
          "title": "Linux mdadm: Reduce disk count but increase size of RAID 6",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlcmev/thunderx2_28core_cpus/",
          "author": null,
          "description": "Hello, I have some CN9975 ARM CPUs but have not been able to find motherboards or servers that fit these CPUs. I also don’t know much about these CPUs in general. If anyone would happen to know something more about these, feel free to share.\n TIA\n    submitted by    /u/zeJuaninator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlcmev/thunderx2_28core_cpus/",
          "publishedOn": "2022-12-14T00:51:35.000Z",
          "wordCount": 13918,
          "title": "ThunderX2 28Core CPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlce4s/recipe_for_high_iopsthroughput_storage/",
          "author": null,
          "description": "Has anyone built a homelab storage solution that achieves: \n  \nlarge sized volumes, say 30TB or larger (so simply using expensive SSD arrays isn’t an option)\n high IOPS, say 5-10k (so a simple mechanical array isn’t an option)\n utilizing 2.5GbE network capacity \n  \nOr, if you wanted to build a NAS solution with about 30TB of working data, with lots of small I/O, and fully utilizing a 2.5GbE network, what would you build?\n Synology SSD read-write cache is insufficient, Intel CAS is commercial and is designed for Optane primarily I think, Intel SRT is discontinued, storage spaces with an SSD tier might be an option but they really want you to use an expensive Windows Server install and spaces seems to be unwieldy, Linux bcache might be an option, ZFS or Unraid with an SSD cache might be an option…\n    submitted by    /u/pixlatedpuffin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlce4s/recipe_for_high_iopsthroughput_storage/",
          "publishedOn": "2022-12-14T00:41:39.000Z",
          "wordCount": 14102,
          "title": "Recipe for high IOPS/throughput storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlc7o3/satadom_not_showing_up_on_r730xd/",
          "author": null,
          "description": "I bought a \"02PTHF Dell 64GB SATA 6Gbps SATADOM\" but I can't get it to show up anywhere on my PowerEdge r730xd. It doesn't show in idrac, hardware survey, bios. Even when I boot into gparted, every storage device shows up except the satadom. There are 2 Sata ports in my r730xd and I've tried putting it on both.\n Anyone know how to get this satadom to work? Thank you.\n    submitted by    /u/AwefulUsername  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlc7o3/satadom_not_showing_up_on_r730xd/",
          "publishedOn": "2022-12-14T00:34:06.000Z",
          "wordCount": 14133,
          "title": "Satadom not showing up on R730XD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zlal1w/rack_mount_case_recommendations/",
          "author": null,
          "description": "I want to try and build a custom rack mount server (mainly for Plex). So I’ve been looking for cases/chassis with 8-12 hot swap 3.5 bays, but also fits standard PC motherboard sizes and PSUs. The only one I’ve really found is this Silverstone case, and there don’t seem to be many of reviews of it out there. Are there other cases / companies I should look at? Could I salvage something like an old PowerEdge? Any advice is appreciated!\n    submitted by    /u/SubtleToot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zlal1w/rack_mount_case_recommendations/",
          "publishedOn": "2022-12-13T23:26:30.000Z",
          "wordCount": 16276,
          "title": "Rack mount case recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zla5pj/proxmox_on_the_edge/",
          "author": null,
          "description": "I'm looking move my homelab from an ubuntu server that just happens to serve my house internet to a pfSense instance in Proxmox. Is it was safe to have the modem plugged into the Proxmox machine and connect the ports to virtual networks (the netgate documentation example) or\n is it better to have the modem connected to a PCIe NIC that is passthrough to the pfSense instance, then connect the internal network via bridging.\n    submitted by    /u/t2thev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zla5pj/proxmox_on_the_edge/",
          "publishedOn": "2022-12-13T23:09:34.000Z",
          "wordCount": 14052,
          "title": "Proxmox on the Edge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl9pu8/a_stupid_question_about_dell_servers/",
          "author": null,
          "description": "I'm looking between an r730 and r730xd. The 730 had an optical drive (which I prefer, don't judge me), and enough 3.5\" bays to satisfy my needs, if I can put the OS elsewhere. The 730xd has more drive space than I know what to do with, no optical bay, but has those fancy rear flex bays.\n I'm wondering if I can take a r730xd and swap the front section for the 8x3.5\" from the r730. This way I can have my OS mirror, optical drive, and not feel bad for using 1/3 of the drive space. I don't see anything online about it though, and wanted to check here before I sacrifice my dvd drive.\n    submitted by    /u/thextallxdude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl9pu8/a_stupid_question_about_dell_servers/",
          "publishedOn": "2022-12-13T22:52:29.000Z",
          "wordCount": 14686,
          "title": "A stupid question about Dell servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl9grw/what_to_upgrade_my_lenovo_sa_120_to/",
          "author": null,
          "description": "So when I started my homelab journey I was dumb and went with a data attached storage and have a Lenovo SA120. I want to upgrade it to a NAS as I'm currently running a an R830 as my home server.\n Any input is appreciated.\n    submitted by    /u/GUI-Discharge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl9grw/what_to_upgrade_my_lenovo_sa_120_to/",
          "publishedOn": "2022-12-13T22:42:50.000Z",
          "wordCount": 13791,
          "title": "what to upgrade my Lenovo SA 120 to?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl90t3/sfp_gpon_with_changeable_sn_and_vendorid_working/",
          "author": null,
          "description": "Recently I purchased a SFP module from FS - GPON-ONU-34-20BI. And after ~1h port management and many other functions on UDM SE just stop working. Restart solves it but restarting a router every hour is extremely stupid. Ubiquiti support literally said to me that they don’t care because it isn’t their module. But the problem is that I can’t use theirs module because I need to change GPON SN and VendorID to get internet connection from my ISP. Do you have any SFP modules with changeable SN and VendorID to recommend? Of course it needs to work with UDM SE.\n TLDR: recommend any module that meets requirements in the title.\n    submitted by    /u/_iMordo_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl90t3/sfp_gpon_with_changeable_sn_and_vendorid_working/",
          "publishedOn": "2022-12-13T22:25:40.000Z",
          "wordCount": 14240,
          "title": "SFP GPON with changeable SN and VendorID working with UDM SE",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl8pwv/someone_gave_me_this_and_said_it_was_working_its/",
          "author": null,
          "description": "submitted by    /u/igmyeongui  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl8pwv/someone_gave_me_this_and_said_it_was_working_its/",
          "publishedOn": "2022-12-13T22:13:58.000Z",
          "wordCount": 14393,
          "title": "Someone gave me this and said it was working. It's been a few weeks in his truck and here it's winter outside. Now it doesn't power up, no lights, nothing. I tried both 20 amps and 15 amps and no luck. Any way to troubleshoot/repair these? Thank you!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl82qh/how_to_connectjoin_my_5g_modem_to_my_ax88u/",
          "author": null,
          "description": "I've been using my RT-AX88U as a one-stop-shop router now for about 1 year. However fiber speeds have never got better than 50mbps here.\n So bit the bullet and today got a ZTE MC8020 5G CPE Router. It's arguably the best 5G router on the market (before ZTEs 6Ghz one drops in a few weeks). Without any tweaking I can get 300/50mbps solid with pings as low as 8ms. On my home fiber I was never offered anything better than 50/5mbps for the same price...\n  \nMy question is how to I properly set up both the devices so they work together?\n I have every ethernet port of the AX88U populated. TV, PS5, 2x Gig Homelab, NV Shield, PC, etc. Previously I just connected the WAN port on the AX88U into the wall ethernet socket.\n My ZTE MC8020 5G Router has 2 Ethernet ports only... WAN/LAN1 & LAN2. The ZTE has…",
          "link": "https://www.reddit.com/r/homelab/comments/zl82qh/how_to_connectjoin_my_5g_modem_to_my_ax88u/",
          "publishedOn": "2022-12-13T21:49:29.000Z",
          "wordCount": 15501,
          "title": "How to connect/join my 5G Modem to my AX88U?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl6eu7/internet_keeps_dropping_isp_router_is_at_fault/",
          "author": null,
          "description": "I have a router from my ISP, that I have put into Modem Mode, and have it connected to a OPNSense router. \n Every now and again (4 times today) the internet will drop completely and will stay down until I reboot the ISP router. \n I know it’s the ISP router as I plug an Ethernet cable directly into it, and there’s no internet. \n Frustratingly, this seems to be happening more and more frequently, and the ISP can’t send an engineer until next week, so I’m looking to see if there’s anything anybody can suggest. \n What’s even more odd is when I’m experiencing the issue the IP I get when plugging into the ISP router is not my WAN IP. When the issue isn’t happening, it is. \n So the issue seems to be down to the ISP router doing something weird/wrong. \n It’s driving me fucking crazy and I can’t handle another week before the engineer comes. The last three times I’ve rebooted, the connection has lasted for about 10-20 minutes and then it goes down again. Same issue as I’ve described above. \n Anybody have any fucking idea?!\n    submitted by    /u/drinkmilkandshit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl6eu7/internet_keeps_dropping_isp_router_is_at_fault/",
          "publishedOn": "2022-12-13T20:45:09.000Z",
          "wordCount": 17277,
          "title": "Internet keeps dropping, ISP router is at fault and it’s driving my crazy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl62re/weird_drops_on_10gb_card_in_windows_10/",
          "author": null,
          "description": "Hey all,\n ​\n I've been testing some stuff with the new 10gb network, and I seem to have hit a strange issue. On Windows 10, running iperf to a TrueNAS box with 2 10Gb ports bondeed together, I am getting 6Gb/s on a single thread, which I don't think is too bad.\n ​\n But when I run multiple tests over time, it eventually drops to 2.4 ish....I thought maybe the NIC was overheating, but I ziptied a fan to it and it still seems to be having trouble. The drivers for this card were absolute dogshit to setup, and I'm to the point I\"m probably going to grab an intel 10gb nic instead....\n ​\n Does anyone else have experience with 10gb that could tell me maybe why I'm getting this weirdly sudden and consistent drop in speed? I'm using an HPNC523SFP on both sides of the connection, with a Mikrotik CRS317 running SWOS in the middle here. The NAS Server is running Proxmox with the 2 ports bonded in lacp mode passed to a bridge that a TrueNAS VM is using. The ports are set both in active mode on the switch, and the client is just a plain ass Windows 10 box.\n ​\n I can't think of anything else significant I have configured here...\n    submitted by    /u/QuirkyKirk96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl62re/weird_drops_on_10gb_card_in_windows_10/",
          "publishedOn": "2022-12-13T20:31:58.000Z",
          "wordCount": 16051,
          "title": "Weird drops on 10Gb card in Windows 10",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl4kd3/bought_a_12_bay_unit_have_8_14tb_wd_red_plus_but/",
          "author": null,
          "description": "Should I wait for the 14TB WD Red Plus to go on sale or should I shuck 14 TB easystore drives? \n Thank you!\n    submitted by    /u/KeBlam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl4kd3/bought_a_12_bay_unit_have_8_14tb_wd_red_plus_but/",
          "publishedOn": "2022-12-13T19:32:07.000Z",
          "wordCount": 15932,
          "title": "bought a 12 bay unit, have 8 14TB WD Red Plus, but looking to fill the rest",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zl4fh3/does_anyone_know_where_i_can_find_the_spec_for/",
          "author": null,
          "description": "submitted by    /u/SimplifyAndAddCoffee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zl4fh3/does_anyone_know_where_i_can_find_the_spec_for/",
          "publishedOn": "2022-12-13T19:26:44.000Z",
          "wordCount": 14268,
          "title": "Does anyone know where I can find the spec for this 12 pin power connector on the backplane of a Dell PowerEdge R520?",
          "imageUrl": "https://external-preview.redd.it/Am8ItFZ6bcqpi-JUwVKlJmCCVQfvE8TiI1yWs4mrJH8.jpg?auto=webp&v=enabled&s=9a24c9498b7d9cdfd5c5a604853de6d129ccabe1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkwvef/moved_to_a_new_house_but_brought_something_old/",
          "author": null,
          "description": "submitted by    /u/modelop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkwvef/moved_to_a_new_house_but_brought_something_old/",
          "publishedOn": "2022-12-13T14:19:34.000Z",
          "wordCount": 16935,
          "title": "Moved to a new house, but brought something old.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkufgl/server_and_network_rackcabinetcase/",
          "author": null,
          "description": "Almost done, still missing a few details.\n    submitted by    /u/Pedroxns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkufgl/server_and_network_rackcabinetcase/",
          "publishedOn": "2022-12-13T12:23:04.000Z",
          "wordCount": 16397,
          "title": "Server and network rack/cabinet/case",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zktine/need_help_finding_documentationtips_on_how_to_use/",
          "author": null,
          "description": "submitted by    /u/5y5c0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zktine/need_help_finding_documentationtips_on_how_to_use/",
          "publishedOn": "2022-12-13T11:31:41.000Z",
          "wordCount": 17417,
          "title": "Need help finding documentation/tips on how to use this. Not sure where to start as I haven't been able to find much info on this. Would love to use this as a storage server.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zksilk/my_modest_living_room_homelab/",
          "author": null,
          "description": "I live in a 2 bedroom flat. No basements, or other suitable places for a server cabinet. I also can't run ethernet cables without drilling lots of holes everywhere. The ISP's coax cable enters the flat on the corner of the living room so all the wired stuff has to live within immediate vicinity of it. \n That means I have to be very careful picking equipment - everything has to be quiet and not very hideous. Enter, my homelab:\n Not too ugly, no?\n The loudest piece here is the big NAS. Everything else is completely silent. The NAS has 12 hard disks generating a noticeable, persistent buzzing sound. Thankfully, it's only audible if the room is entirely silent. If there is anything on the TV I can't hear it at all.\n On the wireless side, most devices are on the TP-Link AP. It supports VLANs and has decent coverage. The Netgear AP only exists to deliver as fast a connection as possible to my desktop PC on the other side of the flat. More on that here.\n Overall, this is what the network map looks like:\n https://preview.redd.it/bgqugnty5n5a1.png?width=3284&format=png&auto=webp&s=094de0edad8d30f9e71ba599d499d69596987afe\n I plan on adding 5G cellular backup at some point, but overall I'm pretty happy with this setup!\n    submitted by    /u/callcifer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zksilk/my_modest_living_room_homelab/",
          "publishedOn": "2022-12-13T10:30:27.000Z",
          "wordCount": 14062,
          "title": "My modest living room homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkj6ia/im_beginning_to_think_im_developing_a_problemesp/",
          "author": null,
          "description": "submitted by    /u/AmSoDoneWithThisShit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkj6ia/im_beginning_to_think_im_developing_a_problemesp/",
          "publishedOn": "2022-12-13T02:07:20.000Z",
          "wordCount": 17247,
          "title": "I'm beginning to think I'm developing a problem....(esp knowing that storage will be at 100TB within the week)",
          "imageUrl": "https://preview.redd.it/ywwwmteopk5a1.jpg?auto=webp&v=enabled&s=f1fbbe3dbf0ae3aa0a1b323623dc0fd27269f51e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkipjw/noise/",
          "author": null,
          "description": "This is stupid I know but does anyone else get annoyed when in movies, they are in a datacenter and it’s perfectly quiet?! Like they are either whispering or not raising their voice at all\n    submitted by    /u/cwfrazier1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkipjw/noise/",
          "publishedOn": "2022-12-13T01:46:53.000Z",
          "wordCount": 14814,
          "title": "Noise",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkhsvo/water_cool_a_home_server/",
          "author": null,
          "description": "Hi everyone. I'm having a difficult time finding water cooling parts for my home server. I can't fit a radiator and pump in my server, but a separate chassis to house the radiators and pump sounds like a great solution. Does anyone know of a chassis that would work well as a dedicated water cooler? I plan to cool an Epyc 7402. That thing gets hot while processing ffmpeg. 54°C while at 20% usage. I'm afraid to allocate more cores.\n    submitted by    /u/Intelligent_Soil_442  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkhsvo/water_cool_a_home_server/",
          "publishedOn": "2022-12-13T01:07:22.000Z",
          "wordCount": 1897,
          "title": "Water cool a home server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkhkhs/3d_printed_cooler_master_n400_case_toolless_hdd/",
          "author": null,
          "description": "submitted by    /u/structuralarchitect  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkhkhs/3d_printed_cooler_master_n400_case_toolless_hdd/",
          "publishedOn": "2022-12-13T00:57:37.000Z",
          "wordCount": 15118,
          "title": "3D Printed Cooler Master N400 Case Toolless HDD Bracket",
          "imageUrl": "https://external-preview.redd.it/ue4QBuHj4k0-LDrV5P_fe3M2xEX2MhN2YlDL61ycUyY.jpg?auto=webp&s=13d2cf752a4230962a2df55c862cf52199797810"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkhhkk/dell_vrtx_blade_interoperability/",
          "author": null,
          "description": "So I've got my hands on a very nice Dell VRTX chassis slap full of drives and other shiny stuff. It has 4x M520 blades which have nice specs, but admittedly are a bit older on LGA1356 with DDR3 and I'm looking to replace the blades. I started looking into Dell's technical guidance and found where it lists M520, 620, 630, 640, 820, 830 blades as options. I found some options on ebay which are listed as PowerEdge M630 through their service tags. Looking at my blades service tags they are reported as: PowerEdge M520 (for PE VRTX). \n I don't know a lot about these VRTX Chassis other than they have some special connectivity and PCIe sharing options. That being said, is there a difference between a normal M630 blade (say from a m1000E chassis) and the M520 from the VRTX?\n    submitted by    /u/irngrzzlyadm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkhhkk/dell_vrtx_blade_interoperability/",
          "publishedOn": "2022-12-13T00:54:00.000Z",
          "wordCount": 14236,
          "title": "Dell VRTX Blade Interoperability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkfq26/nic_and_switch_advise/",
          "author": null,
          "description": "Hey guys,\n Planning on making my first homelab and need some advise.\n Got an Fujitsu FUTRO S920 as router due to this video. Got an NAS which will get RTL8125B nic in either 2.5 or 10 gb. But don't know what NIC to get for my router without breaking the bank, and ofc a good switch behind the router to plug all the devices in. My pc asus mobo already got 2.5 but could a RTL8125B nic in there aswell if needed. \n ISP currently delivers 500mbit download so could I cheap out and use 1gb ethernet port on the thinclient? Single nic's are much cheaper and easier to find than double. \n BTW: I'm thinking of running OpenWrt on the thinclouter/router.\n Would appreciate some suggestion and or tips :)\n    submitted by    /u/itz_game_pro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkfq26/nic_and_switch_advise/",
          "publishedOn": "2022-12-12T23:41:10.000Z",
          "wordCount": 14212,
          "title": "NIC and Switch advise",
          "imageUrl": "https://external-preview.redd.it/NVeSSuFiud1Ksr4aFb9TkkZVaRakPwyl9QnnzbXWQD4.jpg?auto=webp&s=8b045f8c14b69704ef9e88d05d9aa58a7ce772d9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkeuek/how_to_set_docker_container_a_static_ip_andor/",
          "author": null,
          "description": "I want to either the docker container to have a separate IP or separate hostname from the server it is running on. Ex. server is server.local/192.169.1.2 and want the container be container.local/192.169.1.3.\n I see that docker allows you to set the ip for docker's internal networks, but is it possible to be done this way? It is similar to Virtualbox/vmware bridged connection compared to NAT.\n    submitted by    /u/Clawkikker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkeuek/how_to_set_docker_container_a_static_ip_andor/",
          "publishedOn": "2022-12-12T23:06:42.000Z",
          "wordCount": 16409,
          "title": "How to set docker container a static IP and/or hostname on host network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkegf2/best_way_to_begin_segmenting_network_into_vlans/",
          "author": null,
          "description": "Kinda title, but I have a entirely flat network today, NVR Cameras have their own device which controls them, but their management is on the same flat network with the addition of the 50 some VMs that live in my env.\n What is the best way to begin segmenting all these items and getting to a point where I have an IOT network, management network etc?\n    submitted by    /u/Anti_Alphabet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkegf2/best_way_to_begin_segmenting_network_into_vlans/",
          "publishedOn": "2022-12-12T22:51:59.000Z",
          "wordCount": 14510,
          "title": "Best way to begin segmenting network into VLANs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkeg2x/idrac_service_module_v4300_for_ubuntu_2204/",
          "author": null,
          "description": "I have a Dell PowerEdge T330 that I am running Ubuntu 22.04 LTS (Jammy) on, and of course Dell in their standard lack of consideration for Linux users by dragging their feet on updating the ISM software to support current versions, so I decided to research and figure out how to get it installed onto the system myself. Versions given in example are current as of when I did the installation. \n And now, on to the instructions!\n  \nDownload & install libssl1.1:\n  \n​\n cd ~ && wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.16_amd64.deb sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2.16_amd64.deb wget https://dl.dell.com/FOLDER08657945M/1/OM-iSM-Dell-Web-LX-4300-2781_A00.tar.gz tar -xvzf OM-iSM-Dell-Web-LX-4300-2781_A00.tar.gz --one-top-level \n  \nEdit the Installation Script:\n  \n​\n nano ./OM-iSM-Dell-Web-LX-4300-2781_A00/setup.sh \n  \nChange setup.sh line 294 from 20 to 22, and save file:\n  \n​\n if [ \"$OS\" == \"Ubuntu\" ] && [ \"$VER\" == \"22\" ]; then \n  \nFinally, run the setup script, I went ahead and selected 10 (install everything):\n  \n​\n sudo bash setup.sh \n Primary sources of my information:\n https://www.dell.com/support/home/en-us/drivers/driversdetails?driverid=2pk7t&oscode=us008&productcode=poweredge-t330\n https://www.reddit.com/r/homelab/comments/gmln6q/idrac_service_module_ubuntu_2004/\n https://ubuntuforums.org/showthread.php?t=2480893\n *Use of this information is at your own risk. I will not be held liable in the event of any issues or problems that may occur. Be sure to do your OWN due diligence before starting on this project, and do not proceed if you do not feel comfortable working on your system!\n **Please note, this requires you to install libssl1.1, which has been depreciated on 22.04 and you must download it from a previous version repository.\n    submitted by    /u/wb6vpm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkeg2x/idrac_service_module_v4300_for_ubuntu_2204/",
          "publishedOn": "2022-12-12T22:51:40.000Z",
          "wordCount": 14310,
          "title": "iDRAC Service Module v4.3.0.0 for Ubuntu 22.04",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zke40j/advice_for_homelab_server_rack_or_standard/",
          "author": null,
          "description": "Hey, I am trying to figure out for weeks what and how I want to start my Homelab Journey.\n What I basically want to do is to setup a Kubernetes Cluster able to manage some services I want to publish online.\n Virtualisation would be preferred because I don't want to setup 3+ Machines to run K3S on it when I can do it on only one physical machine (well my wife probably would kill me if I but 3 more machines)\n If you go for a complete Server Build: what would you recommend? (I will probably Build it from scratch since I don't have the money to buy it at once)\n If it's a consumer build? What CPU and Mainboard do you recommend? (Power Consumption should not be high!)\n    submitted by    /u/ToxicalToast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zke40j/advice_for_homelab_server_rack_or_standard/",
          "publishedOn": "2022-12-12T22:39:18.000Z",
          "wordCount": 16450,
          "title": "Advice for Homelab Server - Rack or Standard Desktop? Consumer or Enterprise Hardware?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkdvkv/lil_guy_is_running_nextcloud_jellyfin_and_a/",
          "author": null,
          "description": "submitted by    /u/Oha_der_erste  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkdvkv/lil_guy_is_running_nextcloud_jellyfin_and_a/",
          "publishedOn": "2022-12-12T22:31:08.000Z",
          "wordCount": 14848,
          "title": "Lil guy is running Nextcloud, Jellyfin and a minecraft Server on Proxmox",
          "imageUrl": "https://preview.redd.it/kz38y9a9nj5a1.jpg?auto=webp&s=8c605f89bf5f2efb8f55b7091eb10e205c278424"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkdm37/can_i_set_asus_4gac68u_ltemodemrouter_into_bridge/",
          "author": null,
          "description": "I have Asus 4G-AC68U LTE modem/router. It's half ok for my needs, but it's PITA to reset/change settings compared to RT-AC68U router with Asuswrt-Merlin firmware. I used to have some Huawei LTE modem in bridge mode for the router, but it died awhile ago.\n So is there any way (that I'm missing) to set Asus 4G-AC68U to bridge mode, so RT-AC68U router sees internet and acts as sole router?\n ​\n Bonus question:\n Having OpenVPN server on router, and connecting from mobile (not in home WLAN) to router via VPN to access LAN from outside, how safe is it taken account that the phone isnt' lost.\n    submitted by    /u/Maximum-Avocado856  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkdm37/can_i_set_asus_4gac68u_ltemodemrouter_into_bridge/",
          "publishedOn": "2022-12-12T22:22:05.000Z",
          "wordCount": 14100,
          "title": "Can I set Asus 4G-AC68U LTE-modem/router into bridge mode for Asus RT-AC68U router?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkdc7t/if_you_thought_about_making_your_own_35_dell/",
          "author": null,
          "description": "My last post was of the Dell NotAPowerEdge R404 hard drive enclosure. It seemed that a good amount of people enjoyed my creation and now I'd like to share it with those who want to make their own. The STL files are now available on thingiverse. https://www.thingiverse.com/thing:5702969/files\n https://preview.redd.it/18s9rnqzjj5a1.png?width=923&format=png&auto=webp&s=4f5c5eed3e28c9bf6c552e02b50c1a7f521e48b4\n    submitted by    /u/ngarret  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkdc7t/if_you_thought_about_making_your_own_35_dell/",
          "publishedOn": "2022-12-12T22:12:56.000Z",
          "wordCount": 14616,
          "title": "If you thought about making your own 3.5\" dell caddy enclosure.",
          "imageUrl": "https://external-preview.redd.it/fmBOOcHShdUiIsvLiAWj5pp_sPyYQRPpiX_ozn9HkZs.jpg?auto=webp&s=9d4fa6b02e908b22bba5f9ab9e70cfc6da77ae7b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkct4t/fist_server_advice_hp_z820_or_dell_pe_r720/",
          "author": null,
          "description": "First time posting, looking for advice on a first serious server build project. I currently run a media server out of an old windows tower but it's just a full desktop that runs the media server on the side. I want to have a true server that does dedicated tasks. In this case run a Plex server and VM sandbox for professional development.\n I picked up an z820 for a deal and initially was looking to upgrade it to work as a media/sandbox learning server but I'm wondering if it's the best long term option.\n These are the stats of the hardware it came with and what I (pie in the sky) imaged to build it to:\n Hardware as I bought:\n  \n CPU Intel Xeon E5-2630 V2 ST1AM 2.60Ghz MALAY J527C615 \n  \n RAM 8 x 8GB PC3-14900R DDR3-1866MHz ECC REDG 240-Pin DIMM, 4 x 4GB PC3-14900R DDR3-1866MHz ECC REDG 240-Pin DIMM \n  Disk Space 2 x 120 GB SSD \n  Motherboard HP Dual LGA2011 16 RAM memory slots, SAS & SATA connections REV: 1.03 \n  Graphics Card NVIDIA Quadro K600 1GB DDR3 \n  PCIe Cards included NVIDIA TESLA K40, Siemens PETLink Stream Buffer Model: 10251412 \n \n ​\n Ideal Build:\n  \n CPU Intel Xeon E5-2697 v2 x2 \n  \n RAM 128GB DDR3 RECC \n  Disk Space 8 x 8TB SAS drive (RAID 10 to maximize performance and fail tolerance) \n  Graphics Card Nvidia GeForce 2080ti \n \n -Ability to extend storage to a JBOD enclosure\n With all that said. I'm wondering if, for the sake of a long term build, I should just sell it for parts and look for an r720/r720xd to fill it in with less overall footprint? Or is there a better option to consider?\n    submitted by    /u/Azrael5W02D  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkct4t/fist_server_advice_hp_z820_or_dell_pe_r720/",
          "publishedOn": "2022-12-12T21:54:00.000Z",
          "wordCount": 14769,
          "title": "Fist server advice: HP z820 or Dell PE r720?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkcbl6/downgrading_home_lab/",
          "author": null,
          "description": "Hi,\n i currently have a DELL T7910 with\n  \nDual Xeon 2640v4 (10c 20t)\n 128Gb ram\n Nvidia M2000\n 4x 512GB Nvme's in a Dell Ultra-Speed Drive Quad NVMe M.2 PCIe card\n 2x 3TB Ironwolfs\n 2x 6TB WD Reds\n  \nas my home server / Lab.\n I am thinking about selling it and change for something that consumes a bit less power then this setup, currently is consuming about 160w idle.\n I was thinking in changing it for a couple of DELL Optiplex 3060 with i5-8500T 32GB ram, both of them would run proxmox, with 4/5 VM's on them.\n One would be more dedicated to media the other more for learning. the VM's that i would run are some linux server, with docker containers and a windows server acting as a Domain controler.\n Do you guys think that it would be a good change or not?\n Thanks in advance.\n    submitted by    /u/supertostaempo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkcbl6/downgrading_home_lab/",
          "publishedOn": "2022-12-12T21:36:42.000Z",
          "wordCount": 15650,
          "title": "Downgrading home lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zkb2is/home_freeradius_lab_cheap_router_with/",
          "author": null,
          "description": "I am trying to set up a RADIUS server on a home lab and am looking for a cheap WPA2-Enterprise capable wireless router. Having WPA3 would be nice as well but it isn't a requirement.\n Does anyone have any recommendations?\n    submitted by    /u/Practical_Bathroom53  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zkb2is/home_freeradius_lab_cheap_router_with/",
          "publishedOn": "2022-12-12T20:51:55.000Z",
          "wordCount": 15503,
          "title": "Home FreeRadius Lab - Cheap Router with WPA2-Enterprise?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zk8pcq/is_hardware_raid_still_a_viable_option_in_2022/",
          "author": null,
          "description": "I have multiple enterprise-grade rack mount servers with SAS RAID controllers (such as PERC H710, and P440). I'm just adding this to emphasize that I already have the hardware, and all controllers have a decent sized BBU-backed cache.\n The vast majority of the data is stored on Kingston DC series SSDs.\n Recently, I have heard multiple opinions saying that using hardware RAID with non-SAS drives has no benefits.\n Reasons in a nutshell:\n  \nSAS drives have(/had?) 520 byte sectors, so that they can store an 8-byte checksum alongside the 512-byte sector, with SSD drives lacking that, the controller doesn't have a reliable way to detect issues\n most controllers don't use SMART data to predict SSD failure\n it's more difficult to monitor drive failures if the controller hides the physical drives from the OS)\n moderately modern CPUs have no difficulty calculating parity, even at high IO load, and high speeds\n  \nWhat do you think? Are there any benefits to using a hard RAID as opposed to switching the controller to HBA mode and configuring soft RAID provided by the OS (be it MD/LVM in Linux, or Windows with the classic, drive-level RAID or Storage Spaces)?\n    submitted by    /u/OstentatiousOpossum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zk8pcq/is_hardware_raid_still_a_viable_option_in_2022/",
          "publishedOn": "2022-12-12T19:26:25.000Z",
          "wordCount": 19091,
          "title": "Is hardware RAID still a viable option in 2022?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zk4mho/my_home_lab_progression/",
          "author": null,
          "description": "submitted by    /u/jacobnoori  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zk4mho/my_home_lab_progression/",
          "publishedOn": "2022-12-12T17:00:55.000Z",
          "wordCount": 14410,
          "title": "My Home Lab Progression",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjzmw8/pc_as_first_homelab_server/",
          "author": null,
          "description": "Hi! I'm at the beginning of my homelab journey. I have Raspberry Pi 3 B+ and I have started with some docker containers there. I would like to make step forward and begin with virtualization (experiment with pfsense, networking, guacamole, AD, docker, maybe build small NAS). We rent small flat with my girlfriend and we don't have enough place for rack mounted server or even tower server (She said that 😅). I have an idea to buy PC and use it as first server, and I look for advice.\n My requirements:\n - small and silent,\n - not expensive in reference to power consumption,\n - able to run about 3-5 virtual machines simultaneously and some docker containers,\n - allow to build NAS with that. \n Options which I found, all of them fulfill requirements of size to my flat (sorted from the cheapest one):\n 1. HP EliteDesk 800 G2 Tiny i7-6700T (4x2,8-3,6GHz / 8 threads / 8MB) 16GB 512GB SSD SATA - only 16GB of RAM and probably need to update from 2x8GB to 2x16GB in the future.\n 2. HP Z240 SFF i7-6700 (4x3,4-4,0GHz / 8 threads / 8MB) 32GB 480GB SSD SATA\n 3. Dell OptiPlex 7040 SFF i7-6700 (4x3,4-4,0GHz / 8 threads / 8MB) 32GB 500GB SSD NVMe <- think that it would be the most suitable, but I could be wrong :)\n 4. DELL PRECISION T3420 Xeon E3-1240 v5 (4x3,6-3,9Ghz / 8 threads / 8MB) 32GB 256GB SSD NVMe Nvidia Quadro K1200 - unnecessary graphic's card - I think, but Xeon on board.\n 5. HP Z2 MINI G3 Xeon E3-1225 v5 (4x3,3-3,7GHz / 4 threads / 8MB) 32GB 256GB SSD PCIe Nvidia Quadro M620 2GB GFX - again, unnecessary graphic's card, but I really like design :) \n Thank you in advance :)\n    submitted by    /u/ddavid09  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjzmw8/pc_as_first_homelab_server/",
          "publishedOn": "2022-12-12T13:49:59.000Z",
          "wordCount": 17985,
          "title": "PC as first homelab server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjsroi/wake_on_lan_works_on_25gbps_moca_to_ethernet/",
          "author": null,
          "description": "submitted by    /u/FamiliarMulberry2992  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjsroi/wake_on_lan_works_on_25gbps_moca_to_ethernet/",
          "publishedOn": "2022-12-12T08:38:06.000Z",
          "wordCount": 16248,
          "title": "Wake on Lan? works on 2.5Gbps MoCA to Ethernet Adapter? Asus MA-25",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjrwwl/update_2_my_first_rack_ever/",
          "author": null,
          "description": "submitted by    /u/johnnybegood320  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjrwwl/update_2_my_first_rack_ever/",
          "publishedOn": "2022-12-12T07:58:09.000Z",
          "wordCount": 16514,
          "title": "UPDATE 2: My first rack ever",
          "imageUrl": "https://preview.redd.it/3h22z3e1tg5a1.jpg?auto=webp&s=23defa2a8c918467e1deb3430ce9bf7f46a4f734"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjj8q5/installing_your_kubernetes_homelab_cluster_in/",
          "author": null,
          "description": "For anyone looking to get Kubernetes going in their homelab, I created a guide at Installing your Kubernetes homelab cluster in minutes with Ansible.\n I tried to take a different approach them other guides out there by focusing more on using config as code practices and automating much of the install using ansible and terraform.\n The previous parts of the series focus on installing vmware vsphere 8 and using terraform to create all the virtual machines that kubernetes gets installed on.\n I have been using this process over the last year or two for my own homelab cluster so figured I'd clean up my notes, create a blog, and see if anyone else finds it helpful.\n Let me know what you think so I can try to make the content better.\n    submitted by    /u/tknp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjj8q5/installing_your_kubernetes_homelab_cluster_in/",
          "publishedOn": "2022-12-12T02:08:45.000Z",
          "wordCount": 15933,
          "title": "Installing your Kubernetes homelab cluster in minutes with Ansible",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zji19r/trying_to_finish_my_new_homes_networking_how_do_i/",
          "author": null,
          "description": "submitted by    /u/lokikaraoke  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zji19r/trying_to_finish_my_new_homes_networking_how_do_i/",
          "publishedOn": "2022-12-12T01:26:31.000Z",
          "wordCount": 14397,
          "title": "Trying to finish my new home's networking, how do I hook up to this thing?",
          "imageUrl": "https://preview.redd.it/8fehuanddd5a1.jpg?auto=webp&s=f6fa678008c7d248139309b42c80ab4f46586c7a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjhzwj/building_first_home_server_and_looking_for_advice/",
          "author": null,
          "description": "Hi all! I'm a college student studying IT, and I'd like to build a home server since I currently just have a laptop I use for school. I haven't completely decided all the things I'd like to host on this server, but I know at the very least I'd like to use it as a 24/7 Jellfyin/multimedia server and NAS, along with the capability to run other VMs and containers. The OS would be Unraid or another Linux distro.\n I also want it to be small and as power efficient as possible. Here's my current parts list for this build:\n  \nCPU: Intel Core i3-12100 ($124)\n CPU Heatsink: Noctua NH-L9i-17xx ($45)\n Mobo: ASRock B660M-ITX/AC ($120)\n Memory: G.SKILL Ripjaws V Series 32GB (2 x 16GB) DDR4 RAM ($80)\n Boot Drive: SAMSUNG 970 EVO PLUS M.2 2280 500GB ($67)\n Storage: 3x WD Red 4TB NAS ($210)\n Case: Fractal Design Node 304 ($99)\n PSU: FSP 450W Mini ITX Solution ($80)\n  \nThis is the first computer I've built as a server (rather than for gaming), so any thoughts/suggestions are greatly appreciated. I'm also not against getting anything pre-built, so I'm happy to hear about any alternatives as well.\n    submitted by    /u/plzwakeupmrwest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjhzwj/building_first_home_server_and_looking_for_advice/",
          "publishedOn": "2022-12-12T01:25:11.000Z",
          "wordCount": 14249,
          "title": "Building First Home Server and Looking For Advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjh6lv/subdomains_with_adguard_home/",
          "author": null,
          "description": "Hey everyone,\n I've playing around with my Raspberry Pi and have AdGuard Home running on it. I also have grafana, portainer, NPM, etc... I've added a DNS Rewrite to server.pi to my internal IP (192.168.1.3), but I wanted to add subdomains, for instance if I search \"grafana.server.pi\" it would redirect to my grafana page. I've already added the proxy host on NPM, but I think the problem is related to AdGuard. Has anyone tried something like this and can point me in the right direction? Thanks :)\n    submitted by    /u/LogRepresentative301  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjh6lv/subdomains_with_adguard_home/",
          "publishedOn": "2022-12-12T00:56:47.000Z",
          "wordCount": 14038,
          "title": "Subdomains with Adguard Home",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjg98x/nic_drivers_for_vmware_esxi_installer/",
          "author": null,
          "description": "submitted by    /u/sudo_96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjg98x/nic_drivers_for_vmware_esxi_installer/",
          "publishedOn": "2022-12-12T00:25:26.000Z",
          "wordCount": 14219,
          "title": "Nic drivers for vmware esxi installer",
          "imageUrl": "https://external-preview.redd.it/aLff-Ur6YOlxf-OEz45e7UEmi6Fm-taEHmHQxXcnpzg.jpg?auto=webp&s=5d091f1b0293d9fe5317c5645c1cf7c98b3c9e22"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjfasu/my_homelab_work_in_progress/",
          "author": null,
          "description": "Here’s a photo of my homelab. She’s a work in progress. Any suggestions? Thanks\n My Homelab\n    submitted by    /u/Bosfit89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjfasu/my_homelab_work_in_progress/",
          "publishedOn": "2022-12-11T23:54:36.000Z",
          "wordCount": 13927,
          "title": "My homelab, work in progress.",
          "imageUrl": "https://external-preview.redd.it/myziqHbAGpuozdGzwfBg94yKvEhaH7yclgnnFFlxIsg.jpg?auto=webp&s=0665d78e793744c9081ac2e6ddb35d4a4c819bd4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjej3d/another_debian_vs_ubuntu_server_decision/",
          "author": null,
          "description": "So, yeah, another \"Debian vs. Ubuntu\" thread. I'm asking because a lot of the threads I'm finding are many years old where I guess Ubuntu peeved some people and they moved away from them to Debian. I also know that people generally think Debian is more stable but, again, those threads were quite old. I don't really know if thats much the case anymore.\n Right now, I have a mix of Debian and Ubuntu containers in Proxmox but I want to standardize on one. I'm leaning towards Ubuntu Server for one reason: I have no idea why, but apt update and apt upgrade on my Debian containers is painfully slow. I mean, REALLY slow. I've tried everything and just can't figure out why.\n Another reason I'm leaning towards Ubuntu is because of commercial support. Obviously, I don't need commercial support at home but if we start migrating some services at work to Linux (which I think we may), I'm sure management would want to go with the distro that offers support. I'd prefer to use at work what I'm familiar with at home.\n Other than that, is there any other reason I should stick with Debian that I'm missing?\n    submitted by    /u/IndyPilot80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjej3d/another_debian_vs_ubuntu_server_decision/",
          "publishedOn": "2022-12-11T23:29:46.000Z",
          "wordCount": 15653,
          "title": "Another \"Debian vs. Ubuntu Server\" Decision",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjb975/looking_for_a_good_cloud_service_that_supports/",
          "author": null,
          "description": "I currently use Dropbox when I need a file to quickly sync and frequently update between devices. Right now, I use CopyQ (a cross platform clipboard manager with sync). The clipboard data is stored on dropbox, which updates between devices pretty quickly. I'm looking for an alternative to Dropbox because it's starting plan is too expensive for my usage ($10 / month). Does anyone know of any reliable cloud services that will sync as frequently as Dropbox?\n    submitted by    /u/Antoniopapp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjb975/looking_for_a_good_cloud_service_that_supports/",
          "publishedOn": "2022-12-11T22:03:38.000Z",
          "wordCount": 14283,
          "title": "Looking for a good cloud service that supports lan sync",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjav0j/completely_new_to_home_lab_in_general/",
          "author": null,
          "description": "Hey everyone, Im trying to do something of the following. ISP -> Modem -> 1a Router -> 2b Routers/separate networks -> 8 port Switchs coming off both \n 1a is going to be my Main router with incoming speeds of 2.5 gigs. Is there any way to maintain network separation and still get 2.5 gigs to the other 2b Routers? I was informed VLANS was one, but I have an ASUS ax5700 Router atm and Im unsure where the options to create vlans in the webgui. \n Any assistance is appreciated, if there are other ways to do this, please let me know. I was also informed OPNsense would do exactly what I am trying to do, but I am unclear on how to setup\n    submitted by    /u/blkguylethal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjav0j/completely_new_to_home_lab_in_general/",
          "publishedOn": "2022-12-11T21:53:38.000Z",
          "wordCount": 14802,
          "title": "Completely new to home lab in general!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjakx7/home_lab_nice_rack_filled_with_a_desktop_system/",
          "author": null,
          "description": "bouough the rack to downsize, got a z440 and a pi4 and a couple desktops for NAS and a pfsense box. Am not normal.... I use less power than the z440 alone\n    submitted by    /u/Due_Adagio_1690  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjakx7/home_lab_nice_rack_filled_with_a_desktop_system/",
          "publishedOn": "2022-12-11T21:46:28.000Z",
          "wordCount": 13962,
          "title": "home lab, nice rack filled with a desktop system and a shelf.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zjabev/best_place_to_get_ups_batteries/",
          "author": null,
          "description": "Hi All,\n It has come time again to get new UPS batteries for my APC & Triplite UPS's\n Where have you guys got good-quality batteries?\n    submitted by    /u/KevinSoutar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zjabev/best_place_to_get_ups_batteries/",
          "publishedOn": "2022-12-11T21:39:48.000Z",
          "wordCount": 14027,
          "title": "Best place to get UPS Batteries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj89xu/new_build_ex_server_or_what/",
          "author": null,
          "description": "Hey\n ​\n I used to have a pentium 6500 ,12GB DDR4, 10TB HDD as my homeserver, sold it and for the last two years I used my gaming PC to complete these tasks;\n Plex, 2x Linux VM running in hyperv.\n ​\n I don't have a problem to be honest with this, apart from that I hate hearing the HDD noise next to me and the 3x ethernet cables it runs out. So I decided, I would like to have a little homeserver , again.\n This time, I looked around and I have seen that I only need Plex to be able to run (no transcoding, everything is in 1080p and my upload is 150mbit/s, only 2 people use it)\n The VMs are: DNS and webserver, both only run very little traffic.\n I would love to listen to suggestions, as Synology is horrible priced, I would like to keep this a super small form factor(HP Prodesk g4??? or mac mini (this would be my favourite tbh, but I don't like the fact that I would need to use USB for the 3.5 HDD) \n Then, I have come across used Proliant gen9 servers. I mean, they seem to be percfect. Apart from that they are outdated, I could probably run proxmox or unraid on them, allocate cores and memory properly and completetly avoid using windows (this would be another big point for me) \n Oh and my budget is maximum £250.(used or new) \n On my previous, I ran Windows and I hated it, Windows for me is only for gaming.\n    submitted by    /u/Bolyki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj89xu/new_build_ex_server_or_what/",
          "publishedOn": "2022-12-11T20:50:39.000Z",
          "wordCount": 14953,
          "title": "New build (ex server or what?)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj54qg/my_rack/",
          "author": null,
          "description": "R410: minecraft host R200: VPN R510: VM host HP DL320e: Kali Linux box R710: back up nas I removed the jbod Dell Poweredge 2900 is my main NAS.\n    submitted by    /u/Pootis_overlord  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj54qg/my_rack/",
          "publishedOn": "2022-12-11T19:29:28.000Z",
          "wordCount": 13960,
          "title": "My Rack",
          "imageUrl": "https://preview.redd.it/j0xutcrg3d5a1.jpg?auto=webp&s=2a5ecb9be3858880952340fce1285b9459b13b61"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj3uma/finally_got_a_rack_now_to_fill_it/",
          "author": null,
          "description": "submitted by    /u/RedTermSession  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj3uma/finally_got_a_rack_now_to_fill_it/",
          "publishedOn": "2022-12-11T18:54:26.000Z",
          "wordCount": 14423,
          "title": "Finally got a rack. Now to fill it.",
          "imageUrl": "https://preview.redd.it/k9f9079jfb5a1.png?auto=webp&s=1d847c78588e08901d78c85402036dad25c439ea"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj3a63/new_rackmountable_ups/",
          "author": null,
          "description": "Finally had my UPS die on me. It was one I got for free many years ago. It worked, but didn't have many features.\n I'd like to replace it with a UPS that I can mount in my rack and monitor/manage from my network/computer. I'd also like to get a top-of-rack power strip that I can monitor/manage from my network/computer.\n What are my options?\n I presently have a Netgear Modem, UDM Pro, Ubiquiti AP, Ubiquiti 8 Port Switch, and Synology NAS in the rack. I plan on getting a server sometime in the future.\n    submitted by    /u/MainStudy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj3a63/new_rackmountable_ups/",
          "publishedOn": "2022-12-11T18:39:14.000Z",
          "wordCount": 14749,
          "title": "New Rackmountable UPS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zj0pk2/thinking_of_switching_to_thin_clients/",
          "author": null,
          "description": "I currently have 5 Raspberry Pis in my rack doing various things (Home Assistant, lighter Docker containers, reverse proxy, vpn, PiHole, etc.) and am thinking about swapping them out to a thin client or two. I want to try my hand with Proxmox as a hypervisor (possibly try my hands as a cluster).\n I have been doing a bit of research and found that the main contenders seem to be Lenovo ThinkCentre/ThinkStation, HP EliteDesk/Prodesk, and Dell Micro. The STH article that is getting passed around is a couple of years old and does not look to be updated with any newer recommended models.\n Do you all think that it would be worth swapping out most of my Raspberry Pis for a couple of thin clients? If so, what models should I be looking for? Mainly looking for a good balance between power and performance while being hopefully on the cheaper side. Again, I will hopefully be playing around with Proxmox as a cluster.\n    submitted by    /u/liltrublmakr56  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zj0pk2/thinking_of_switching_to_thin_clients/",
          "publishedOn": "2022-12-11T17:29:11.000Z",
          "wordCount": 15341,
          "title": "Thinking of switching to thin clients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ziz9j9/nvr_questions/",
          "author": null,
          "description": "So upon reading up on security cameras with dvr and nvr, I really want to go the nvr route.\n I'm looking at either lorex or night owl.\n My question is if I have the nvr base in my rack, do my cameras need t9 connect directly to it or can I utilize existing wall Jack's? I know I'll need poe.\n My goal is an NVr box that can take ip cameras and wireless.\n I'm also open to non wyze suggestions lol.\n    submitted by    /u/eagle6705  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ziz9j9/nvr_questions/",
          "publishedOn": "2022-12-11T16:50:14.000Z",
          "wordCount": 14234,
          "title": "NVR questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zixkqe/powering_on_server_once_a_week_for_truenas/",
          "author": null,
          "description": "I know this topic comes up often but my situation is a little different. I have four servers total running in my rack and two of them are TrueNAS boxes. One is simply being used as a backup (replication) so I was wondering instead of running this server 24/7, why not power it off and have it turn on once a week, replicate and shutdown? Seems reasonable enough. \n Any downsides other than not having replication running more often? At 325w being drawn at 0.33 cents is around $77 a month for me. I know my wattage is rookie numbers considering what others here are running.\n    submitted by    /u/chench0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zixkqe/powering_on_server_once_a_week_for_truenas/",
          "publishedOn": "2022-12-11T16:02:16.000Z",
          "wordCount": 15021,
          "title": "Powering ON server once a week for TrueNAS replication? (to save on electricity)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zixbac/need_help_with_vm_enviorment/",
          "author": null,
          "description": "I recently setup a VM in virtual box, to create a domain controller and run server 2019 on it. I’m using a windows desktop so I am not able to download the iso that’s needed for the client VM to connect to the domain. How would I acquire an iso to attach to the client. It’s only giving me options to upgrade or download the instillation media. For reference I’m watching Josh madakors powershell home lab tutorial and at about the 47 minute mark is where I’m stuck. Where you have to add the iso to the client. Any feedback would be really helpful! video\n    submitted by    /u/Agitated-Tradition81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zixbac/need_help_with_vm_enviorment/",
          "publishedOn": "2022-12-11T15:54:57.000Z",
          "wordCount": 14638,
          "title": "Need help with VM enviorment",
          "imageUrl": "https://external-preview.redd.it/Ns-NZUII343dKLBQO5nOIqyMgyf3vHS9vmb24sl7XY0.jpg?auto=webp&s=d0f45741e925b9c3075cb2a5da7af1cc0ac3ee53"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ziw5w0/i_saw_one_of_yall_in_the_wild_today/",
          "author": null,
          "description": "submitted by    /u/SeldomRomantic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ziw5w0/i_saw_one_of_yall_in_the_wild_today/",
          "publishedOn": "2022-12-11T15:21:34.000Z",
          "wordCount": 14805,
          "title": "I saw one of y’all in the wild today.",
          "imageUrl": "https://external-preview.redd.it/JCjD2xiO-DR8HXqvCEFc94vMvR9YF61tLHWjUX90pS0.jpg?auto=webp&s=caf16288b583c0c57d4da029a1eeb818fd208999"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ziugm8/onpremise_cloud_gaming/",
          "author": null,
          "description": "submitted by    /u/cloudy_gamer_1383  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ziugm8/onpremise_cloud_gaming/",
          "publishedOn": "2022-12-11T14:37:18.000Z",
          "wordCount": 14375,
          "title": "On-premise 'cloud' gaming?",
          "imageUrl": "https://external-preview.redd.it/1LuV12jkRaY5Ws05OrguPGlmy3euDPvK6GZ1vNSENs0.jpg?auto=webp&s=29b0a5ab88111bb6ca47e27f1e2982fdfb92dfee"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zipwbf/total_run_time_1368_years_246_days_world/",
          "author": null,
          "description": "Total run time: 1,368 years 246 days -- World Community Grid Homelab team stats for Sunday, 12/11/2022\n  \nCurrent Members 249 (#33 in the world)\n Total Run Time (y:d:h:m:s) (Rank) 1368:246:17:39:20 (#146)\n Points Generated (Rank) 2,341,198,829 (#127)\n Results Returned (Rank) 3,819,799 (#132)\n  \nHomelabbers who have joined the Homelab team and are processing datasets for World Community Grid are working on the following projects:\n  \n Project Points Generated Results Returned Total Run Time (y:d:h:m:s) \n  \n OpenPandemics - COVID-19 436,172,461 652,605 204:235:10:58:59 \n  Africa Rainfall Project 28,750,573 6,638 15:177:17:28:32 \n  Help Stop TB 2,624,907 1,068 1:237:01:20:12 \n  Mapping Cancer Markers 1,323,628,778 1,847,385 842:072:15:04:52 \n  Beta Testing 588,775 966 0:125:19:17:04 \n  Microbiome Immunity Project 233,228,063 555,814 126:303:09:50:12 \n  OpenZika 56,754,339 148,682 27:023:07:53:07 \n  FightAIDS@Home - Phase 2 75,951,773 100,228 50:357:19:14:52 \n  Outsmart Ebola Together 61,922,110 115,152 29:077:20:37:22 \n  FightAIDS@Home 4,068,979 67,396 2:152:07:48:41 \n  Smash Childhood Cancer 117,508,071 323,865 67:308:08:05:27 \n \n Join the Homelab team here: \n (if you already participate in World Community Grid)\n https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n (if you are new to World Community Grid)\n https://join.worldcommunitygrid.org?teamId=124DTPZ682\n Link to team statistics: https://www.worldcommunitygrid.org/team/viewTeamInfo.do?teamId=124DTPZ682\n    submitted by    /u/homelabber12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zipwbf/total_run_time_1368_years_246_days_world/",
          "publishedOn": "2022-12-11T12:22:46.000Z",
          "wordCount": 18340,
          "title": "Total run time: 1,368 years 246 days -- World Community Grid Homelab team stats for Sunday, 12/11/2022",
          "imageUrl": "https://external-preview.redd.it/wIj6ygk01ih8oIHxFRQ6FPPWByQkwZHSYkhAwFSPi5g.jpg?auto=webp&s=695923a3c1648c33a1135adf2092e5d80a1fa37d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ziord5/really_small_homelab/",
          "author": null,
          "description": "submitted by    /u/diesus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ziord5/really_small_homelab/",
          "publishedOn": "2022-12-11T11:35:18.000Z",
          "wordCount": 14907,
          "title": "Really Small Homelab",
          "imageUrl": "https://preview.redd.it/12povzyuqa5a1.jpg?auto=webp&s=c567021fe9f9a096ef275dc27be23ecfd0e805f1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zia2qg/what_ethernet_nics_are_you_using_on_esxi_8/",
          "author": null,
          "description": "Has anybody upgraded their servers and swapped out for a dual or quad port NIC that works?\n Looking for something I can pickup, doesn't need to be 10GB\n    submitted by    /u/silver565  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zia2qg/what_ethernet_nics_are_you_using_on_esxi_8/",
          "publishedOn": "2022-12-11T01:37:01.000Z",
          "wordCount": 13947,
          "title": "What ethernet NICs are you using on ESXi 8?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi9gan/my_new_home_server_used_for_virtualization/",
          "author": null,
          "description": "submitted by    /u/renegdewolf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi9gan/my_new_home_server_used_for_virtualization/",
          "publishedOn": "2022-12-11T01:10:33.000Z",
          "wordCount": 15292,
          "title": "my new home server used for virtualization testing, studying for certifications and remote work. my new home server/Lab Asus tuf white edition I7 13700 overclocked to 5.4 MSI PRO Z790P Coolermaster Pl360 flux gskill trident 32gb 4800 corsair rm850 crucial bx500 1tb for os Win 11 Pro 2 6tb WD bl",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi9690/cisco_switch_on_isp_modem/",
          "author": null,
          "description": "Hey guys - I've just purchased a gigabit Cisco 3560, I'd like to try and build a homelab in the future whilst also learning Cisco kit. Ideally, I get a pfSense/OPNSense router feeding the switch, but this will have to wait until I can source some well-priced hardware.\n Right now, I only have the router my ISP provided me with. Is it possible to connect a Cisco managed switch to an ISP router? I (at the moment) don't have any other way of providing IP addresses, other than this router which acts as an AP as well as DNS/DHCP server. \n Total newbie - any advice is well received. Thank you.\n    submitted by    /u/Poots0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi9690/cisco_switch_on_isp_modem/",
          "publishedOn": "2022-12-11T00:58:23.000Z",
          "wordCount": 14091,
          "title": "Cisco Switch on ISP modem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi8vd9/power_company_accidentally_cut_my_fiber_line_from/",
          "author": null,
          "description": "submitted by    /u/scd31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi8vd9/power_company_accidentally_cut_my_fiber_line_from/",
          "publishedOn": "2022-12-11T00:44:33.000Z",
          "wordCount": 14292,
          "title": "Power company accidentally cut my fiber line from the road. ISP isn't fixing it until Monday at the earliest. Packed up the important servers and redeployed at my girlfriend's house",
          "imageUrl": "https://external-preview.redd.it/_AQ38GbrVfJ1EI4y4JtHosQZjnA49oQwjL4eJtQUjgU.jpg?auto=webp&s=eff410e22a3cf4ec3eb55881c35b2f4ecc62d069"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi7fge/dell_r720_bootingdisplay_issues/",
          "author": null,
          "description": "I have a dell r720 that I'm having issues setting up/booting.\n The system powers on when the power button is pressed and the front LCD panel says \"System Booting\" but there is no video output on either the front or back VGA ports. I have tested my VGA cable and monitor on my other r720 and it works. I have also done a NVRAM jumper reset to make sure the embedded video controller wasn't disabled. No error codes show on the LCD and their are no error beeps (unless those can be disabled). When the system finishes \"booting\" the front LCD displays the system name and all other menus properly. Not sure what the issue could be so I'm checking here to see if any of you have any ideas.\n ​\n EDIT: This system does not have the enterprise IDRAC license so I cannot confirm boot or enter the system through there.\n    submitted by    /u/LiamColeE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi7fge/dell_r720_bootingdisplay_issues/",
          "publishedOn": "2022-12-10T23:41:15.000Z",
          "wordCount": 14169,
          "title": "Dell R720 Booting/Display Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi6zfe/updating_intel_me_amt_from_linux/",
          "author": null,
          "description": "Hi all,\n Recently I've been moving away from rackmount hardware to SFF machines to reduce my power usage, heat and noise.\n I've had some good success running Proxmox on HP EliteDesk SFF units and have been finding Intel AMT to be a suitable alternative to iLo/iDrac and am currently experimenting with MeshCommander/MeshCentral.\n On the HP site there is a firmware update tool for updating Intel AMT.However the included firmware is quite old and the tool is designed for either DOS/EFI.\n The newer firmware updates appear to be designed for Windows only.\n Is there a way to flash the Intel AMT firmware from within Linux IE Debian/Proxmox?If so, how I determine which firmware I need?\n The download from HP appears to include two bin files, C0_LP and D0_H.\n Thanks in advance for any help/advice.\n EDIT: I've more or less given up on the idea of doing this from within Linux for now and used this method:\n  \nI formatted a USB disk as fat32.\n Created a folder structure /efi/boot\n Placed the tianocore EFI shell in the boot folder named Boot64.efi https://github.com/tianocore/edk2/blob/UDK2018/ShellBinPkg/UefiShell/X64/Shell.efi\n From the HP flash tool download extracted with 7zip, copied the FWUpdLcl.efi and MEInfo.efifiles from the MEFlash and MEInfo directories to the USB disk.\n From the HP firmware download extracted with 7zip, copied both of the .bin files (H and LP) from the ME directory.\n Booted the machine from the USB Disk to get into an EFI shell\n Ran FS0: to change to the root of the USB disk (dir to check I'm in the right place)\n Ran MEInfo.efi to determine what firmware was running. In the output I saw I was running \"H\" rather than \"LP\".\n Ran FWUpdLcl.efi -f ME_11.8_Corporate_D0_H_Production.bin to flash the \"H\" firmware\n Rebooted and verified I was running the new AMT version with MeshCommander.\n  \n​\n    submitted by    /u/Joe_Pineapples  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi6zfe/updating_intel_me_amt_from_linux/",
          "publishedOn": "2022-12-10T23:22:12.000Z",
          "wordCount": 14449,
          "title": "Updating Intel ME / AMT from Linux",
          "imageUrl": "https://external-preview.redd.it/R3LvUNYzYoInUsVttws2Iys7pv7xulPDzt5n0hBxhcA.jpg?auto=webp&s=2bce80bdd1c922360e40a6a784e85eaa5fdc1b1f"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi6rra/supported_hdd_in_a_proliant_ml350/",
          "author": null,
          "description": "Picked up a Proliant ML350 G6 off of marketplace the other day for $50 and this is my first time working with server hardware. I see that there are multiple slots for hot swap SAS drives and a few for SAYA drives but I don't quite understand what type of drive I should be buying. I'm looking online and I see the HDD and sdd's however they don't have a mounting bracket. In my server I see there's a bunch of blanks. Am I supposed to fit the drives inside those? Also it it only SATA or ISCSI or something? Can someone explain this terminology for me? Thanks!\n Pic: \n https://imgur.com/a/cuDG3et\n    submitted by    /u/sarxlives  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi6rra/supported_hdd_in_a_proliant_ml350/",
          "publishedOn": "2022-12-10T23:13:25.000Z",
          "wordCount": 14907,
          "title": "Supported HDD in a Proliant ML350?",
          "imageUrl": "https://external-preview.redd.it/qgchVyCG3GKwAaKo_orU2k8sVgqepZKU_B6X7OlpDQc.jpg?auto=webp&s=7c586d9ceb1cb2e71910a685dcdb5948ff76df20"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi6oos/opinions_on_replacement_tinyminimicro_machines/",
          "author": null,
          "description": "Up until recently I’ve been running: - Synology NAS (Plex and NFS for other devices) - 3x Mac minis (2011) running Proxmox as a playground and to host a few services for the home - 1x Intel NUC (D54250WYKH i5-4250U) as a Home-Assistant box \n This is great as a playground, but with the current cost of energy, I’m kind of wishing I had just ONE tiny/mini/micro system that could run Proxmox and then my same few VMs to replace the bare minimum of what I need.\n I’ve been reading up on the Serve The Home site and their great video series, and I’ve been considering:\n  \nLenovo ThinkCentre M720Q (9th Gen Intel i5 9400T)\n HP EliteDesk 800 G4 \n Optiplex 3070\n Optiplex 7050\n  \nI DID try experimenting with two Raspberry Pi 4s I had, but they are just 2GB RAM models and I quickly ate that!\n So could anyone recommend a good bang-for-pound 😆 machine that I could pickup for around £200 used? Is it worthwhile to punt for the newer generation chipsets for power efficiency?\n    submitted by    /u/HarmlessSaucer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi6oos/opinions_on_replacement_tinyminimicro_machines/",
          "publishedOn": "2022-12-10T23:09:55.000Z",
          "wordCount": 15441,
          "title": "Opinions on replacement tiny/mini/micro machines for Proxmox?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi6d0y/ceph_overhead_using_rook_vs_proxmox/",
          "author": null,
          "description": "Hi, looking to build proxmox server and k8s cluster at home. Since I don’t have too many nodes, I was going to run either Rook or the Proxmox-managed ceph for storage.\n Can anyone speak to the performance of either? I’ve heard that proxmox ceph suffers from high overhead and is borderline unusable. Sadly my node with the most compute power for virtualization is also the one with the most drive bays.\n    submitted by    /u/tamerlein3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi6d0y/ceph_overhead_using_rook_vs_proxmox/",
          "publishedOn": "2022-12-10T22:56:38.000Z",
          "wordCount": 14019,
          "title": "Ceph: overhead using Rook vs Proxmox",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi64np/need_help_with_raid_and_truenas_scale_pools/",
          "author": null,
          "description": "Hiya, entirely new to the networking space so excuse my lack of knowledge--\n I've recently been working on turning my old Desktop into my own home server and so far it's been going great, at least until I got stuck at creating new pools via TrueNAS Scale..\n I've got an 18tb and another 4tb hard drive and planned to use them in 2 pools:\n One Pool for RAID1, so I'd be using the entire 4tb drive and 4tb of the larger drive to create a pool where I keep my most important data and one using the rest of the 18tb drive as a regular data pool.\n ​\n However after creating the RAID1 Pool, I realized that I can no longer select my 18tb drive to add as a data vdev... could someone tell me how I can use the rest of my 18tb drive alongside RAID1 if that's possible?\n    submitted by    /u/FinalPedro360  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi64np/need_help_with_raid_and_truenas_scale_pools/",
          "publishedOn": "2022-12-10T22:47:19.000Z",
          "wordCount": 14177,
          "title": "Need help with RAID and TrueNAS Scale pools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi5lgn/hp_dl20_gen9_nvme_support/",
          "author": null,
          "description": "Hi there, \n I have an HP DL20 Gen9 which currently has two SATA SSDs installed.\n I'd like to upgrade to two NVMe SSDs installed on two PCIe to M.2 adapters like this one.\n The system doesn't seem to support PCIe bifurcation so I guess I should be fine by just using two separate adapters, right? \n The system has one internal PCIe x16 slot which has a PCIe riser which splits that port into two PCIe x8 ports. Can I just install a PCIe to NVMe adapter in each of them? \n Thank you!\n    submitted by    /u/v3ng00  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi5lgn/hp_dl20_gen9_nvme_support/",
          "publishedOn": "2022-12-10T22:25:56.000Z",
          "wordCount": 14889,
          "title": "HP DL20 Gen9 - NVMe Support",
          "imageUrl": "https://external-preview.redd.it/qhoDUHJ4T6lRFVYCY-9LC6_D9Eq2S0cPXdOpKFukm2A.jpg?auto=webp&s=965af572f573b77cc8e751ba8115cec24cb07842"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi431k/14g_bezels_anything_else/",
          "author": null,
          "description": "submitted by    /u/cjchico  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi431k/14g_bezels_anything_else/",
          "publishedOn": "2022-12-10T21:26:59.000Z",
          "wordCount": 14331,
          "title": "14G Bezels > anything else",
          "imageUrl": "https://preview.redd.it/sbhrgkkij65a1.jpg?auto=webp&s=cab6b670036eae547bbbf10fec50bf2c2fbc2997"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi2rtr/my_first_free_score_on_some_equipment/",
          "author": null,
          "description": "Hey all. Recently my mother's workplace has moved buildings. They found a better place, cleaner, where it already had furniture. I decided that, in hopes of finding something that I could use/learn from, I would go to the old place to tear through the remaining stuff in the office. The equipment was never registered properly and I was told there are no problems if I take them because of that. So I did, and I found some pretty interesting stuff. \n I'm pretty new to homelabbing (not entirely new) but these were the first things I would get for free. \n An HP switch, 48 ports, only 4 are GbE (2 RJ45+2 SFP)\n ​\n Cisco 881, FE ports only\n ​\n There's a VPN sticker on it. I suppose it was used for tunneling to the headquarters.\n ​\n 8 Port GbE PoE switch. Pretty neat!\n Haven't booted this yet, unsure about specs, it just says SA4. I'll use this as the host for my CNC router since it has a LPT port on the back.\n This HP Compaq which - as you will see in the photo below - I called \\\"scrapyard\\\". Sorry for the lurking finger.\n ​\n I tried to install BSD but after flashing the USB it just wouldn't boot from the BIOS.\n I also got a lot of cat5e/cat6 wires. And one single mode fiber, too! (~5m)\n Overall I'd say I could find a use for these. Please let me know what you guys think!\n    submitted by    /u/fortlesss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi2rtr/my_first_free_score_on_some_equipment/",
          "publishedOn": "2022-12-10T20:34:55.000Z",
          "wordCount": 14574,
          "title": "My first free score on some equipment!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi0mza/layer_2_security_at_home/",
          "author": null,
          "description": "I just finished reading BRKSEC-2202 - Understanding and Preventing Layer 2 Attacks in IPv4 Network (2013). I learnt about attacks in layer 2 and ways to mitigate them.\n These attacks seems easy to perform, and also easy to mitigate (just enable things like DHCP snooping, Dynamic ARP inspection and IP source guard in your switch).\n Unfortunately, my current smart switch (Zyxel GS1900) does not offer these security features.\n Then again, these attacks require the malicious actor to be inside my network. They have to physically get into my house to do that (they can also brute force my wifi password or trick me to install some malicious software), and if that's the case then they can do much more than these \"layer 2 attacks\".\n Do you have these layer 2 security features at your homelab? Do you think they are essential to a secure homelab?\n    submitted by    /u/regunakyle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi0mza/layer_2_security_at_home/",
          "publishedOn": "2022-12-10T19:09:13.000Z",
          "wordCount": 14951,
          "title": "\"Layer 2 Security\" at home?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi0enj/baby_lab_3_laptop_proxmox_cluster/",
          "author": null,
          "description": "submitted by    /u/bkm9312  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi0enj/baby_lab_3_laptop_proxmox_cluster/",
          "publishedOn": "2022-12-10T19:00:03.000Z",
          "wordCount": 14644,
          "title": "baby lab: 3 laptop proxmox cluster",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zi04mr/3d_printed_a_hot_swap_drive_enclosure_to/",
          "author": null,
          "description": "submitted by    /u/ngarret  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zi04mr/3d_printed_a_hot_swap_drive_enclosure_to/",
          "publishedOn": "2022-12-10T18:48:38.000Z",
          "wordCount": 14994,
          "title": "3d printed a \"hot swap\" drive enclosure to troubleshoot dead drives.",
          "imageUrl": "https://preview.redd.it/rm4yyts9r55a1.jpg?auto=webp&s=bcfc3190545ca0a4d4044b4028167975417cee22"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhyqzc/trying_to_install_proxmox_onto_hp_proliant_ml350/",
          "author": null,
          "description": "submitted by    /u/MagicDartProductions  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhyqzc/trying_to_install_proxmox_onto_hp_proliant_ml350/",
          "publishedOn": "2022-12-10T17:53:14.000Z",
          "wordCount": 17336,
          "title": "Trying to install Proxmox onto HP ProLiant ML350 G6 server and get this screen. More in comments.",
          "imageUrl": "https://preview.redd.it/oiq3rbvdh55a1.jpg?auto=webp&s=2ee1ca69b3f8913be1812f8b99b72d8c26200a76"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhxa48/a_bit_dusty/",
          "author": null,
          "description": "UDM Pro UniFi 24 port POE switch PI Zero for Pi-Hole DNS Pi 4B as web server for custom comic book site Synology NAS for Plex and general storage\n What else would be fun to add? This is a bit addicting.\n    submitted by    /u/DagonFelix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhxa48/a_bit_dusty/",
          "publishedOn": "2022-12-10T16:53:58.000Z",
          "wordCount": 14217,
          "title": "A bit dusty",
          "imageUrl": "https://preview.redd.it/vnn5c36t655a1.jpg?auto=webp&s=865ee9663e9ffcc5b967fba986d8f71cbb4d3e6d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhwdmv/updating_proxmox_is_always_an_adventure/",
          "author": null,
          "description": "submitted by    /u/redstonefreak589  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhwdmv/updating_proxmox_is_always_an_adventure/",
          "publishedOn": "2022-12-10T16:15:21.000Z",
          "wordCount": 14875,
          "title": "Updating Proxmox is always an adventure",
          "imageUrl": "https://preview.redd.it/or3rabe9i35a1.png?auto=webp&s=0cb9ded0c31aa63b52659e74038588a7c57b0c3a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhn45s/first_homelab/",
          "author": null,
          "description": "hey, so I just stared building my first homelab. here is some of the configuration until now:\n  \nAruba AOW4010 as my main gigabit switch\n ZyXEL (idk the model) 100 mbit/s switch as a backup\n Random blank patch panel from amazon\n Fiber optic lc to lc patch panel from a friend\n 3x HP Compaq SFF pc's from school: \n One running Truenas Scale, 1x 160Gb HDD as a boot drive, 500Gb and 8Tb HDDs as my Pool running a few NFS and SMB shares and running my plex, sonarr, radarr, etc... services\n One running Proxmox, with VMs for PiHole, a Minecraft Server, a MySQL database, a simple website, a Signum Plotter and Miner, connected to my mentioned NFS share. MC, DB and PiHole VMs are automatically backed up to my Truenas Box daily.\n The last one running OPNSense. Connecting to it via OpenVPN, because I want to keep my Lab separated from the rest of our network.\n \n  \nI know, cable management, etc... is pretty bad at the moment, but for now, this is just a proof of concept. I've only spent about 80€ so far, 50€ for the rack itself, 20€ for the blank patch panel, and about 10€ for the keystones and cage nuts, I can't really complain. I'm still going to school, so I'm on a pretty tight budget, but I'll do the most out of it.\n ​\n https://preview.redd.it/zi40xei7615a1.jpg?width=1179&format=pjpg&auto=webp&s=bd84ed5fd7042426f7fae1776bccf6cb683c8a43\n    submitted by    /u/Alive-Mulberry2301  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhn45s/first_homelab/",
          "publishedOn": "2022-12-10T08:33:16.000Z",
          "wordCount": 14299,
          "title": "First homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhmwc7/been_looking_for_a_while_not_sure_if_they_ever/",
          "author": null,
          "description": "Would anyone by chance have an idea if there is any manufacturer who does spools of transparent cat5 or cat6? I'm... Going for a certain aesthetic.\n Essentially I'd like to make a homelab network project look like a 90s clear plastic telephone, and well, clear cables wherever I can should cement the gaudy mess when I can get to it.\n I might scrap the whole idea eventually but... It's just one of those things that crawled into my brain and infected it a while back.\n    submitted by    /u/MetaVulture  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhmwc7/been_looking_for_a_while_not_sure_if_they_ever/",
          "publishedOn": "2022-12-10T08:19:34.000Z",
          "wordCount": 14775,
          "title": "Been looking for a while not sure if they ever made transparent cat5 or 6 cables...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhmoge/best_os_for_nas_and_later_on_git_davinci_resolve/",
          "author": null,
          "description": "​\n x399 1920x mellanox 455A\n I almost finished the hardware part of my first NAS and now I need to chose an OS and NAS software. I was wondering what you would chose.\n The requirements are:\n  \nvery little command line, easy to setup and use, easy to expand when I add drives\n RAID0 m.2 for the work drive, auto backup to HDD\n I'd like to get close to the throughput of the mellanox while keeping power consumption lowest possible.\n eventually install a git server and a davinci resolve server, the resolve server has a linux variant\n after I chose which 4x m.2 card I prefer, that'll free up one port for a GPU, then this NAS can be used as a desktop to do work, no gaming\n the client is a windows machine connected directly to it via a twinax cable and the second NIC is linked to the wifi router for desktop access\n if setting it up in RDMA that's be cool to offload the cpu, as long as it's easy to do\n  \nThanks!\n    submitted by    /u/mcdroid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhmoge/best_os_for_nas_and_later_on_git_davinci_resolve/",
          "publishedOn": "2022-12-10T08:06:25.000Z",
          "wordCount": 16385,
          "title": "Best OS for NAS and later on Git + Davinci Resolve server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhkrcn/not_quite_there_yet/",
          "author": null,
          "description": "submitted by    /u/xpingjockey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhkrcn/not_quite_there_yet/",
          "publishedOn": "2022-12-10T06:11:37.000Z",
          "wordCount": 15345,
          "title": "Not quite there yet",
          "imageUrl": "https://preview.redd.it/7exkkcm7025a1.jpg?auto=webp&s=7f10dda2ba5b26c08427ca0c9523b9c9d2bde5f6"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhingh/my_lackrack_lab/",
          "author": null,
          "description": "submitted by    /u/blending-tea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhingh/my_lackrack_lab/",
          "publishedOn": "2022-12-10T04:19:19.000Z",
          "wordCount": 14834,
          "title": "My lack-rack lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhegir/dell_12g_bricked_idrac_emmc_replacement/",
          "author": null,
          "description": "Hey homelabers,\n I’ve seen mixed info on the web about fixing bricked idracs, from chip replacements to live booting over tftp.\n This post is not a guide, it’s more documenting what worked for me to hopefully point anyone in similar situations in the right direction :)\n I don’t have the answers to everything but I do have some good news. I have a Dell r720 which had both a bricked iDrac and a failing emmc with the “failed to write errors” after find this out I bought 2 replacement emmc chips off eBay to try replace the dead flash. Then lost the chips for 6 months… after I had found them again the fun began.\n I have a decent hot air station which definitely helps in doing this, also flux and board preheating helps tremendously otherwise you risk lifting traces. I took the motherboard out of…",
          "link": "https://www.reddit.com/r/homelab/comments/zhegir/dell_12g_bricked_idrac_emmc_replacement/",
          "publishedOn": "2022-12-10T00:59:52.000Z",
          "wordCount": 15158,
          "title": "Dell 12G Bricked iDrac EMMC replacement",
          "imageUrl": "https://external-preview.redd.it/kEWYZyogHxHLweQBr3I1NnA5t6ZX-eSeXMM7jP_KrJs.jpg?auto=webp&s=231fd58dd8b297e7cc682f38287e4d3fa5b3f577"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhefw3/x9srh7tf_bios_upgrade/",
          "author": null,
          "description": "I am looking for BIOS upgrade for X9SRH-7TF so that I can get bifurcation working. Current installed version is from 2015\n    submitted by    /u/BeastMiners  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhefw3/x9srh7tf_bios_upgrade/",
          "publishedOn": "2022-12-10T00:59:02.000Z",
          "wordCount": 14155,
          "title": "X9SRH-7TF - BIOS Upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhe3au/decided_join_the_family_with_a_mini_10in_starter/",
          "author": null,
          "description": "submitted by    /u/carney2134  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhe3au/decided_join_the_family_with_a_mini_10in_starter/",
          "publishedOn": "2022-12-10T00:42:47.000Z",
          "wordCount": 15360,
          "title": "Decided join the family with a mini 10in starter lab",
          "imageUrl": "https://preview.redd.it/o5nav2ajd05a1.jpg?auto=webp&s=926f7da55ccf5daa9d5731f712f3ee077d8cb2b0"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhdqd6/homelab_vpn_access/",
          "author": null,
          "description": "has anyone here setup static ip with Century link to have a static vpn setup for remote access? \n Is it reliable?\n    submitted by    /u/somethots  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhdqd6/homelab_vpn_access/",
          "publishedOn": "2022-12-10T00:26:32.000Z",
          "wordCount": 14040,
          "title": "homelab vpn access",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhaicr/does_the_supermicro_x10srlf_support_pcie/",
          "author": null,
          "description": "Hi, \n im planning to change the mainboard in my NAS and stumbled upon the X10SRL-F from Supermicro. Now my question is: Does the X10SRL-F support PCIe Bifurcation and boot from PCIe nvme/ssd?\n Cheers\n    submitted by    /u/bmtlr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhaicr/does_the_supermicro_x10srlf_support_pcie/",
          "publishedOn": "2022-12-09T22:18:12.000Z",
          "wordCount": 14237,
          "title": "Does the Supermicro X10SRL-F support PCIe Bifurcation and boot from PCIe nvme/ssd?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zhaecp/anyone_familiar_with_the_hp_z620/",
          "author": null,
          "description": "I purchased a z620 on ebay... someone I've purchased from before. It won't boot and they are taking their time responding so I thought in the meantime I'd pick the community's brain.\n I've tested with several CPUs and several sticks of memory both 2 and 4gig. \n I've tried another video card.\n I've re-seated every cable and I've tried it with no CPU and/or no memory in varying combinations.\n With any CPU installed and one or two memory sticks I get a single beep.... And HP's list of beep codes shows 2 beeps and 3 beeps etc.... but NOTHING for a single beep. \n Furthermore even at idle pre-boot the cpu heats up something fierce.... possibly just because the fan isn't spinning yet? \n The led on the motherboard is solid blue and the PSU light is solid green (I think it was green?)\n The bios has been reset several times plus I've flushed the PSU caps by unplugging and holding power.\n I never get a video signal under any of these conditions. The fans ramp up sometimes tho I'm afraid I missed making notes about what combinations of the above result in this.\n Any ideas? Is this just a toast MB? PSU? Is it haunted by the ghost of Nicola Tesla?\n Thanks!\n    submitted by    /u/fliberdygibits  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zhaecp/anyone_familiar_with_the_hp_z620/",
          "publishedOn": "2022-12-09T22:13:43.000Z",
          "wordCount": 14460,
          "title": "Anyone familiar with the HP z620?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh9hui/external_zfs_hba_setup_combability_sata_lsi_9211/",
          "author": null,
          "description": "I bet this question has been answered before but I couldn't find anything definitive.\n I'm looking to expand my general purpose server (Proxmox w/ TrueNAS VM + others) storage. There seem to be several external HBAs (Dell SC220, Dell MD1200, etc.) that are very reasonably priced.\n The server currently has two SAS Cards flashed to LSI 9211 IT mode with direct passthrough to TrueNas and I have a few PCIe slots open. \n Are these SAS HBAs compatible with SATA drives that's friendly to ZFS (i.e. has full access to the drives)? I know I'll need to get the cable converters but anything else I should be looking out for?\n    submitted by    /u/togepi_man  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh9hui/external_zfs_hba_setup_combability_sata_lsi_9211/",
          "publishedOn": "2022-12-09T21:36:38.000Z",
          "wordCount": 14244,
          "title": "External ZFS HBA Setup Combability: SATA + LSI 9211 IT Mode",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh7auo/best_way_to_connect_drives_proxmox_ha_servers/",
          "author": null,
          "description": "Howdy! I just got a second server and want to try out proxmox HA (I already use proxmox standalone). Since I'm going to be making a lot of changes to my setup I was wondering what the best way to connect my hard drives to each servers might be. In my first server I have an LSI 9260-4i RAID card with 4 800GB SSDs, combined into 2 virtual 800GB drives via RAID 1. Am I better off skipping the raid card an connecting the drives directly to the 6Gb/s and 3Gb/s sata ports on to mobo?\n Notes\n 1) The supermicro motherboard I have doesn't have it's own RAID manager, but I think I can setup zfs or ceph in proxmox?\n 2) My servers: SuperServer 5018A-FTN4 , so far the first server was been great for a debian VM, home assisant VM, and a frigate LXC.\n 3) I don't have any type of nas ATM.\n    submitted by    /u/Boss_Waffle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh7auo/best_way_to_connect_drives_proxmox_ha_servers/",
          "publishedOn": "2022-12-09T20:09:02.000Z",
          "wordCount": 15228,
          "title": "Best way to connect drives Proxmox HA Servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh78y9/hp_se1101/",
          "author": null,
          "description": "Hello. This afternoon, I was lucky enough to snag a pair of HP SE1101 rack servers with 1tb hard drives apiece that my organization was discarding. As someone that is quite new to homelabbing and server usage, I was wondering if anyone either knew anything about these servers, or if anyone has any ideas for decent use cases for them. I picked them up purely out of opportunistic fortune, so I had no use case or anything in mind. Thanks!\n    submitted by    /u/kleinkleinkleinklein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh78y9/hp_se1101/",
          "publishedOn": "2022-12-09T20:06:58.000Z",
          "wordCount": 14996,
          "title": "HP SE1101",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh6xby/managed_switch_saves_the_day_again/",
          "author": null,
          "description": "Another day, another problem solved by having a managed switch.\n In one part of the house, video calls, sometimes, drop out a tiny bit here and there—in another part of the house, they are fine. Other Internet usage seems fine in the affected part of the house, so how do you resolve this issue? Well, this can be a bit troublesome to troubleshoot, but, in my case, the managed switch helped track down the culprit pretty fast.\n So, like any good tech guy with a homelab, I SSHed into my trusty switch and looked at the statistics for all the interfaces. Unexpectedly, one of the interfaces was communicating at 100Mbps when it should be 1000Mbps! Since my documentation is good, I quickly noticed that port was one of my Wireless Access Points (WAP). The plot thickens!\n Next, I reviewed the counters for that port and, well, lots of errors and drops on that port! Shouldn’t be happening! So, I proceeded to reseat both ends of the CAT6a cable and returned to my SSH session. Same thing. Still negotiating at a lowly 100Mbps.\n I grab a new CAT6a cable (spare cables are a must for a homelab!), swap the cables out and re-return to my SSH session. 1000Mbps is now correctly being negotiated! After verifying I’m connected to this WAP, I proceed to download a large file. Zero errors and drops on this port! Success! I proceed to have a not too long, but not too short, video call and, well, all is well again!\n Last step is to make absolutely certain the affected cable is in the garbage, so it never gets used again!\n Cheers!\n TL;DR: Invest in a managed switch—you get a lot of advanced functionality and it will save you from future frustrating IT episodes!\n    submitted by    /u/BinkReddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh6xby/managed_switch_saves_the_day_again/",
          "publishedOn": "2022-12-09T19:54:55.000Z",
          "wordCount": 16564,
          "title": "Managed Switch Saves the Day, Again",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh6s7r/dell_servers/",
          "author": null,
          "description": "Anyone familiar with Dell PowerEdge towers, and NIC cards?\n Are those servers picky on the cards, bios version/firmeware of cards you put in them? I'm looking to add a card in 2 servers I'm getting. I need QSFP28 cages, one or two ports. HPEs are notorious for this, I wonder how Dell compares.\n Any known solid cards that I can get for cheap, would be great. thanks!\n    submitted by    /u/JKennex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh6s7r/dell_servers/",
          "publishedOn": "2022-12-09T19:49:01.000Z",
          "wordCount": 14832,
          "title": "Dell servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh68ob/100_year_storage_of_data/",
          "author": null,
          "description": "My Grandfather has recently assigned me an interesting task. He sequenced his GENOME and requested storage of this information for the next 100 years. Grandpa has prepaid for a safety deposit box in Iron Mountain in addition to their long term data storage offering. The question is what methods would you use for this HARD storage? I have already burned the 180GB RAR's to a Blu-ray format, does anyone have a SSD or alternative recommendation ?\n    submitted by    /u/Leblancwork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh68ob/100_year_storage_of_data/",
          "publishedOn": "2022-12-09T19:27:21.000Z",
          "wordCount": 21023,
          "title": "100 Year Storage of Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh68f5/bmc_self_test_status_failed_is_there_anything_i/",
          "author": null,
          "description": "Hi all. Got a new (to me) ASUS server and while I was checking it out I noticed that in the \"Server Mgmt\" tab of the BIOS the field titled \"BMC Self Test Status\" and the value is \"FAILED\".\n https://preview.redd.it/xvs0h0h1bx4a1.jpg?width=3024&format=pjpg&auto=webp&s=9ae1b515a0cf2140f11d8496b222ceb4afd8d13b\n I checked the manual for the server and on page 66 it says there's an LED on the board called \"BMCLED1\" which \"blinks to indicate that the on-board BMC is functional.\" However, mine is just a constant and very, very dim green LED (no blinking).\n On page 126 of the manual it shows more options than I have on the \"Server Mgmt\" tab, including a toggle for \"BMC Support\" (Enabled/Disabled).\n I tried updating the BIOS to the latest one, but no change (not unexpectedly). Is there anything I can do to try and recover the BMC, or is it toast?\n Would appreciate any input, thanks.\n For reference:\n Server: ASUS RS100-E10-PI2\n Motherboard model: ASUS P11C-M/4L\n BIOS version: 4003 (latest)\n    submitted by    /u/amp8888  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh68f5/bmc_self_test_status_failed_is_there_anything_i/",
          "publishedOn": "2022-12-09T19:27:05.000Z",
          "wordCount": 15679,
          "title": "\"BMC Self Test Status FAILED\" <--- Is There Anything I Can Do or Is It Toast?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh5h0n/are_t_series_cpus_worth_the_premium/",
          "author": null,
          "description": "I'm just starting out on the journey of replacing my QNAP NAS with a custom build. I want this computer to be on 24/7 so energy efficiency is probably important. I have used the QNAP for plex and as my personal cloud storage. I would like to use it for more but the j1800 is pretty limiting. I like to tinker so home automation, plex, moonlight, some form of ad blocker, Linux iso collections and virtual machines to play around with are all on the list of goals for this next machine.\n I was looking towards a lga 1700 based build and was thinking about a i3 12100t. I want to rack mount this little guy inside a silverstone RM41-H08.\n I want to start off efficient but I'm not sure that the T series chips will be worth starting with if eventually I build this out with 8+ spinning disks and a dGPU and 10gig NIC and all of these other power hungry parts.\n I try to build to use for a decade or even potentially longer. I'm just not sure that i won't want to upgrade the cpu sooner than later.\n I would love to hear about your experiences as well as opinions! \n Thanks!\n    submitted by    /u/threepoundog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh5h0n/are_t_series_cpus_worth_the_premium/",
          "publishedOn": "2022-12-09T18:57:09.000Z",
          "wordCount": 16500,
          "title": "are \"T\" series CPUs worth the premium?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh4jdg/affordable_10gbe_pcie_nic/",
          "author": null,
          "description": "I figured /r/homelab would know...\n I recently upgraded to 3gbps fibre internet service and wanted to take advantage on my wee homelab so I purchased an ASUS XG-C100C V2 PCIe NIC for $130 CAD. Well I should have done more research because this card has a habit of completely freezing up when under heavy load, requiring a NIC reset to temporarily resolve the issue. There is no updated firmware or drivers available, so I'm returning it and looking for another.\n Any affordable, stable recommendations? The modem/router only has one 10GB Ethernet port. Bonus points for an affordable, stable 10GB switch.\n    submitted by    /u/Dinkadactyl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh4jdg/affordable_10gbe_pcie_nic/",
          "publishedOn": "2022-12-09T18:19:57.000Z",
          "wordCount": 15537,
          "title": "Affordable 10GBE PCIe NIC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh3znp/any_advice_getting_new_used_sas_drives_to_show_up/",
          "author": null,
          "description": "I picked up some used 14TB SAS drives, but I'm having trouble getting them recognized in my R510 with an H200 HBA. \n  \nThe SAS drives are Seagate\n I've been using this server with shucked WD SATA drives for years\n The drives spin up (I can feel them spinning after disconnecting them)\n I pulled a functioning SATA drive out of the exact same slot that the SAS drive is not working in\n The SAS drives don't show anywhere, including in the HBA BIOS. I even tried removing all other disks (even though mixed SATA and SAS should be fine)\n  \nAny ideas on how I can troubleshoot this?\n    submitted by    /u/Fonethree  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zh3znp/any_advice_getting_new_used_sas_drives_to_show_up/",
          "publishedOn": "2022-12-09T18:00:10.000Z",
          "wordCount": 14982,
          "title": "Any advice getting new (used) SAS drives to show up on a R510?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zh2f5u/weekly_rhomelabsales_summary_20221209/",
          "author": null,
          "description": "The last weeks [For Sale] posts in r/homelabsales \n Posts that have not met the rules of HLS or have completed are not shown. \n Bot Feedback? - Checkout the pinned post in my profile\n CAN \n ON\n  \nDell VRTX, 2x M520 Blades, 12x 1tb 7.2k SAS\n  \nQC\n  \n[MTL] Infiniband 40 Gbps Switch, Cables and Cards\n  \n​\n EU-UK \n -ANY-\n  \nDL380p G8, 12xLFF, 256GB RAM, Rails | £250 Collection only London E15\n \nPowerEdge R820, Arista Switches, HP DL360 G8, HP Dl380 G8, Quanta E5 v2 server\n \n UK&EU\n  \nDell PowerEdge R640 2 x 12 Core 2.10GHz Silver 4116 64GB H740P 2 x 750W PSU\n \nDell PowerEdge R730XD 2 x 14 Core 2.00GHz E5-2660 V4 64GB 2 x 300GB 15K SAS H730P\n \n ​\n EU \n ESP\n  \nIntel Xeon E5-2660 V3 (Haswell-EP LGA2011-3), Scalable 1st and 2nd gen (Skylake-SP and Cascade Lake-SP LGA3647), Scalable 3rd gen (Ice La…",
          "link": "https://www.reddit.com/r/homelab/comments/zh2f5u/weekly_rhomelabsales_summary_20221209/",
          "publishedOn": "2022-12-09T17:00:04.000Z",
          "wordCount": 26371,
          "title": "Weekly r/homelabsales Summary - 2022-12-09",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgz58i/intel_optane_ssds_guidance/",
          "author": null,
          "description": "I've read that since intel is shutting down their Optane division you can find some pretty crazy deals now. Problem is there appears to be MANY different types of Optane drives and I'm having difficulty figuring out what's good and what's not.\n Intel OPTANE H10 16GB + 256GB SSD M.2 is selling on eBay for $30; is that good compared to a 500GB WD Blue SN570 NVMe for $40. What advantages to Optane add?\n I posted in HomeLab because I intend to use 2 of these for a mirrored proxmox boot drive, but I do tend to reuse hardware for new projects often so getting a good value, even if it's overkill for this use case, is still good.\n    submitted by    /u/AwefulUsername  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgz58i/intel_optane_ssds_guidance/",
          "publishedOn": "2022-12-09T14:45:13.000Z",
          "wordCount": 16394,
          "title": "Intel Optane SSDs Guidance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgz2qv/a_small_epyc_build/",
          "author": null,
          "description": "submitted by    /u/jaskij  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgz2qv/a_small_epyc_build/",
          "publishedOn": "2022-12-09T14:42:19.000Z",
          "wordCount": 14864,
          "title": "A small EPYC build",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgxu3j/i76700k_gtx1060_esxi_8_apparently_works_nicely/",
          "author": null,
          "description": "submitted by    /u/EpicLPer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgxu3j/i76700k_gtx1060_esxi_8_apparently_works_nicely/",
          "publishedOn": "2022-12-09T13:49:39.000Z",
          "wordCount": 15300,
          "title": "i7-6700K + GTX1060 + ESXi 8 apparently works nicely for Plex and Blue Iris",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgw83r/teamviewer_alternative/",
          "author": null,
          "description": "I have a big problem. I have been using TeamViewer for years to access my headless servers, but yesterday evening it decided to think I was using it for commercial purposes. I called support and filled out the form and everything, but I am basically screwed until they reinstate my free account.\n As soon as they reinstate my free account, the first thing I am doing is switch to another Remote Desktop service. Any recommendations? I have wanted to switch to something selfhosted for a while now, but I avoided it because I need to be able to remote into computers even when the selfhosted VM might now be working. Since a Remote Desktop service is so important to have always working for me, I would really like a cloud service, but I don’t know if any that offer the same features as TeamViewer for free.\n    submitted by    /u/BothConsequence5513  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgw83r/teamviewer_alternative/",
          "publishedOn": "2022-12-09T12:36:34.000Z",
          "wordCount": 17997,
          "title": "TeamViewer Alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgsum7/infrastructure_questions_for_www_accesible/",
          "author": null,
          "description": "Hi homelab community!\n I am planning to move parts of my homelab infrastructure from my local server to a VPS provider (like linode, aws, azure, ...)At least I want move applications that should be accessible from the web.e.g. my private homepage, a small community website, a small application that i created for my business.\n I plan to use NGINX proxy manager to enforce and handle SSL and authelia for 2FA.\n My preferred option would be to separate the infrastructure from the webserver.But with that my question is:\"How to prevent direct access to the webserver and basically skipping nginx and authelai like shown in the picture below for client 3?\"\n Option1\n As i do have full access to the VPS via SSH I could of course also install docker on Virtual Server2 and handle NGINX and Authelia on the same server to make things way easier:\n Option 2\n But I think the solution to keep the infrastructure topics separated from the webserver seems way cleaner to me as i am also planning to futher lockdown with e.g. geoblocking, cloudflare, and so on.\n Any help/thoughts/suggestions or votes for option 1 or 2 would be highly appreciated.\n thanks and have a nice weekend,mike\n    submitted by    /u/mikemaierx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgsum7/infrastructure_questions_for_www_accesible/",
          "publishedOn": "2022-12-09T09:50:36.000Z",
          "wordCount": 16237,
          "title": "Infrastructure questions for www accesible websites",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zglnce/lessons_learned/",
          "author": null,
          "description": "submitted by    /u/DreadPirateR2891  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zglnce/lessons_learned/",
          "publishedOn": "2022-12-09T03:33:48.000Z",
          "wordCount": 16067,
          "title": "Lessons learned!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zghu7y/looking_for_program_to_fix_sd_card_firmware/",
          "author": null,
          "description": "So, short version, I bought some SD cards off of AliExpress aaaaand they're not the 1tb cards I was hoping they'd be. They appear to be 2gb, and therefore clearly tampered with. \n Now, thing is, even a 2gb card wouldn't be *completely* useless to me (I have filed the dispute, but even odds they won't even bother asking me to send them back). But I obviously need to fix the tampering. \n Anyone got any suggestions on software I can use?\n    submitted by    /u/Dragonorb13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zghu7y/looking_for_program_to_fix_sd_card_firmware/",
          "publishedOn": "2022-12-09T00:48:16.000Z",
          "wordCount": 14224,
          "title": "Looking for program to \"fix\" SD card firmware.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgg8ja/inside_of_mah_new_1u_cuz_i_forgot_to_show_before/",
          "author": null,
          "description": "​\n https://preview.redd.it/oqef8kg6hr4a1.png?width=760&format=png&auto=webp&s=0a89816e13ece8b606c1b30013036fc0ec906b89\n    submitted by    /u/ZanesCyno  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgg8ja/inside_of_mah_new_1u_cuz_i_forgot_to_show_before/",
          "publishedOn": "2022-12-08T23:47:47.000Z",
          "wordCount": 13636,
          "title": "inside of mah new 1u (cuz i forgot to show before)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgfugh/issues_getting_x540_nic_to_negotiate_10g_over_23m/",
          "author": null,
          "description": "I've been setting up wired network runs at home, and decided to use CAT6, since it's rated for 10G up to 55m, which is well above what I needed. The main network rack is in the garage, and I ran four CAT6 cables from the \"server closet\" on the second story, each about 75ft/23m.\n I have an old storage server (Supermicro SuperStorage 6048R-E1CR24L) with dual Intel X540 NICs. I patched it through to the Mikrotik CRS312 switch, but it only auto-negotiated at 1G. I saw in Winbox that \"10G\" would flash for a brief moment under the list of peer advertised speeds, but it would never stick.\n My server runs SmartOS, an Illumos/Solaris derivative. I searched around to see if anyone else had issues getting 10G working on X540 NICs, and tried some of the suggestions, but nothing has worked so far. I brought the server down to the garage and connected it with a short CAT6 cable, and voila, it negotiated 10G with no problem. I haven't tried another OS yet to see if that might make it work.\n Long-term, though, I don't want to keep the server in the garage, especially come spring and summer. So, long story short, I'm wondering if anyone else has had issues with X540 NICs not being able to negotiate 10G speeds at distances within the CAT6 spec?\n For contrast, I have a Mac Studio in the room with the \"server closet,\" and it negotiates 10G. I tested the speeds with iperf3 between it and the storage server, and it can get ~9.35G one-way. So I don't think there's any interference that would explain this behavior. Although when I run with --bidir, the bandwidth drops to 7.97G and 5.97G; could this indicate something is wrong with the runs, terminations, etc.?\n    submitted by    /u/devopsdudeinthebay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgfugh/issues_getting_x540_nic_to_negotiate_10g_over_23m/",
          "publishedOn": "2022-12-08T23:33:28.000Z",
          "wordCount": 14478,
          "title": "Issues getting X540 NIC to negotiate 10G over ~23m of CAT6?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgfrjy/replace_nuc_5i5_with_vm_on_proliant_microserver/",
          "author": null,
          "description": "Hello. An old NUC 5i5RYH 1.6GHz w/ 8GB of RAM serves as my main desktop PC running Windows 10 Pro in my study. I really don't expect much from it, just browsing the web and running MS Office-type programs. No games, minimal video. It works as a home computer.\n I have an HPE Proliant Microserver Gen 10 Plus with a Xeon E-2444 3.4GHz w/ 32GB of RAM running Windows Server Standard 2019 with the Windows Server Essentials Experience added. It's basically a file server but I also run a couple of programs remotely using a Remote Desktop app as a poor man's VMWare type arrangement. Other than my internet upload connection being slow when accessing it remotely, it works well.\n I'm considering building a VM with Windows 10 Pro using Hyper-V as replacement for the old NUC. I can add audio support by way of the server's PCIe gen3 x16 slot and dedicate a network port to the VM. Other than the NUC supporting hyperthreading, it seems to me that the VM would be better. It would also get rid of some unnecessary older hardware. Also, since I'm running the server, anyway, it would reduce power consumption.\n When I posted this same question on the s\\intelnuc, I was advised to inquire here.\n Suggestions? Critique? If this would work without constant maintenance (other than normal software updates) can you recommend a video/sound card? The slot is PCI-E 3.0 x16, low profile, mounted horizontally on a daughter board.\n    submitted by    /u/SomebodyInGNV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgfrjy/replace_nuc_5i5_with_vm_on_proliant_microserver/",
          "publishedOn": "2022-12-08T23:30:32.000Z",
          "wordCount": 14307,
          "title": "replace NUC 5i5 with VM on Proliant Microserver Gen 10 plus?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgeo6t/broadwell_vs_haswell_worth_the_difference/",
          "author": null,
          "description": "Hello,\n I am looking to purchase either a system containing an i5-6500T or an i5-4790T. They perform similarly, with around a 20% improvement for the newer chip, however the i5-4790T PC that I can purchase has 1x8gb DDR3, compared to the 1x4gb DDR4 in the i5-6500T PC - giving the older chip PC more upgradability on a budget. \n ​\n The only other reason that I can see for preferring the newer chip is that its integrated graphics can be better passed through to multiple VMs (How useful is GVT-g?), however I am unsure as to how competent the 4th Gen i5 would be for simple video playback in a VM. \n ​\n Which option would be superior?\n    submitted by    /u/throwaway396722  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgeo6t/broadwell_vs_haswell_worth_the_difference/",
          "publishedOn": "2022-12-08T22:52:23.000Z",
          "wordCount": 14465,
          "title": "Broadwell vs Haswell: Worth the difference?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgekfb/looking_for_externally_powered_10gbe_thunderbolt/",
          "author": null,
          "description": "TB3/4 preferably, but 2 is fine, I can use an adapter. But it needs it's own power supply.\n I only find the Sonnet Twin 10G, isn't there anything else, that is hopefully cheaper?\n    submitted by    /u/JKennex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgekfb/looking_for_externally_powered_10gbe_thunderbolt/",
          "publishedOn": "2022-12-08T22:48:42.000Z",
          "wordCount": 13993,
          "title": "looking for externally powered 10GB-E thunderbolt adapter.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgeaz3/dns_meddling_by_endpoint_security_or_just/",
          "author": null,
          "description": "I recently discovered a strange DNS issue with one machine on my home network. From all of my testing in troubleshooting, I am left with the conclusion that the endpoint protection suite (Carbon Black) is tampering with and replacing my DNS results. Let me explain.\n Over the weekend I added pihole to my network in a high availability cluster using keepalived. This essentially creates a virtual IP on my network that can point to any one of 3 machines, depending on their status. On my network, this virtual IP is 192.168.50.30, and I have configured my router to use it for DNS. Testing this on my main Windows 11 machine, and several other Ubuntu and Debian VMs, it works wonderfully without issue.\n My work machine is a different story however. My domain name, lets call it xyz.house is registered with cloudflare. In pihole, I added an A record for pihole.local to 192.168.50.30, and then a CNAME for pihole.internal.xyz.house pointing to pihole.local. When making DNS requests, the local hostname pihole.internal.xyz.house fails to resolve in a very strange way. At least I thought I wasn't resolving because only the hostname was returned; no IP. Then I realized this was only happening hostnames that actually exist externally of pihole. Once I realized this, I tried other domains. Adding google.com as a local A record in pihole, which was likewise ignored. It seemed that my work machine ignores my local DNS results when the hostname is a real hostname registered somewhere else. As if the endpoint protection is trying to avoid DNS spoofing/poisoning. I also realized that the reason I didn't get an IP response, is because there wasn't an A record listed for xyz.house or pihole.internal.xyz.house in cloudflare.\n Has anyone ever heard of this?\n    submitted by    /u/BinaryPatrick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgeaz3/dns_meddling_by_endpoint_security_or_just/",
          "publishedOn": "2022-12-08T22:39:28.000Z",
          "wordCount": 14198,
          "title": "DNS meddling by endpoint security? or just misconfiguration..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgdzl8/is_now_the_right_time_for_me_to_try_learning/",
          "author": null,
          "description": "I currently run a LOT of services, and Because of my that my poor little homelab can’t keep up. Anytime I’m watching a movie and someone else is on a game server I host we go down.\n I have a spare Dell OptiPlex with 32gb to match my existing one. I was going to try and get myself going on the new one with an Arch ecosystem, but it sort of seems like a good time instead to give k8s a go. Is this the right use case, to essentially create a duplicate server and then decide between the two of them what runs what?\n Any guides or advice you could recommend so I can eventually get into a DevOps role with my existing skills would be sick! Thanks so much.\n    submitted by    /u/fossilsforall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgdzl8/is_now_the_right_time_for_me_to_try_learning/",
          "publishedOn": "2022-12-08T22:28:26.000Z",
          "wordCount": 14883,
          "title": "Is now the right time for me to try learning kubernetes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgdkge/how_to_get_bios_control_of_a_remote_physical/",
          "author": null,
          "description": "Hello everyone, I’m trying to build my home-server/private cloud. I can remote into the server but I would like to know if there is a standard way to get control of the entire physical server, incase if I want to reinstall a new OS or update BIOS settings remotely.\n    submitted by    /u/Most-System5498  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgdkge/how_to_get_bios_control_of_a_remote_physical/",
          "publishedOn": "2022-12-08T22:13:41.000Z",
          "wordCount": 15718,
          "title": "How to get BIOS control of a remote physical server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgcq8i/homelab_ambient_temperatures/",
          "author": null,
          "description": "Since moving my DL380P to the shed 2 years ago it seems to be running OK. I've since moved the rest of my home lab into a rack in the shed with it. This morning the inlet ambient temperature was -2C. In the summer just gone, it peaked at 33C. It got me wondering what temperature extremes other homelabbers are running under, bearing in mind that HP say that 10C is the minimum operating temp.\n    submitted by    /u/BirdingSQLDBA  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgcq8i/homelab_ambient_temperatures/",
          "publishedOn": "2022-12-08T21:44:43.000Z",
          "wordCount": 14482,
          "title": "Homelab ambient temperatures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgcoes/proxmox_install_on_hp_gen8/",
          "author": null,
          "description": "I'm trying to get Proxmox running on my gen 8 but having a few issues. First this is an older spec unit with the celeron CPU. I originally wanted to try VMware exsi but wouldn't let me install due to the lower end CPU. So I tried proxmox and got it installed but now cannot connect and believe it's due to lack of drivers for my NIC. How do I install drivers exactly or get this to work?\n    submitted by    /u/Reep881  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgcoes/proxmox_install_on_hp_gen8/",
          "publishedOn": "2022-12-08T21:42:56.000Z",
          "wordCount": 15071,
          "title": "Proxmox install on Hp Gen8",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgbzi1/thank_you_and_by_the_way_the_switch_died_in_the/",
          "author": null,
          "description": "submitted by    /u/ViktorsakYT_alt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgbzi1/thank_you_and_by_the_way_the_switch_died_in_the/",
          "publishedOn": "2022-12-08T21:18:42.000Z",
          "wordCount": 13728,
          "title": "Thank you, and by the way, the switch died in the summer, probably overheated. F for The Switch. Also learned that the meme flair here is... just for the meme. So this time, discuss!",
          "imageUrl": "https://preview.redd.it/dyfw0dv78s4a1.png?auto=webp&s=ad22a6c864218f3cc4d47673bd4aba9f7e3aea6e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zgaccd/how_to_find_and_load_micro_code_for_intel/",
          "author": null,
          "description": "I bought a workstation at auction. Went down the white rabbit hole to get it running and now stuck at how to update some micro code. It is running on Ubuntu now but will hang easily. Any advice?\n https://preview.redd.it/204w0l0hgq4a1.jpg?width=5184&format=pjpg&auto=webp&s=050ed891ad07bbb21f342af17ab91f7f18f94c4c\n https://preview.redd.it/kfo2fs0hgq4a1.jpg?width=5184&format=pjpg&auto=webp&s=ed88f714bf5c0feaa81496f8605a83489b00a841\n https://preview.redd.it/q0618p0hgq4a1.jpg?width=5184&format=pjpg&auto=webp&s=36ada8435eeeba45db561bd97a09e0a03206246a\n    submitted by    /u/Ready-Problem8946  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zgaccd/how_to_find_and_load_micro_code_for_intel/",
          "publishedOn": "2022-12-08T20:21:54.000Z",
          "wordCount": 13923,
          "title": "How to find and load Micro code for Intel Confidential CPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zga7zz/proxmox_ve_cluster_with_dell_optiplex_9020_micro/",
          "author": null,
          "description": "Here is my cluster under Proxmox VE based on Dell Optiplex 9020 Micro in socket 1150 (Intel 4th gen) which are the last models to accept Xeon processors, which makes them more affordable than the following generations.\n The good points are :\n - Power consumption (15-20 watts on average),\n - Intel vt-d instructions to do passthrough with Linux virtual machines (desktop instance, kodi, batocera) or to do transcoding with Plex/Jellyfin,\n - Very quiet,\n - Low power multi-core processors with hyper-threading (score of 5449 for the i7-4785t and 6168 for the E3-1265l v3 on cpubench) that allow to run several virtual machines without flinching,\n Specifications\n - CPU : two models in i7-4785t (4c/8t, 2,2 Ghz, 35 watts) and one in E3-1265l v3 (4c/8t, 2,5 Ghz, 45 watts),\n - Memory: 8 GB DDR3 (up to 16 GB maximum),\n - 256 GB SSD,\n ​\n I got all three for just over 300 euros. At the moment, the E3-1265l v3 is at 33 dollars on Aliexpress (6168 pts on cpubench) so for those who want to make a HomeLab for cheap, the TinyMiniMicro in socket 1150 have the best value for money because above, the Xeon processors do not work anymore and the price is much higher.\n ​\n https://preview.redd.it/v7464p3tfq4a1.jpg?width=640&format=pjpg&auto=webp&s=6dd548239c0936d7d7d42262f95cefd4f426ed3a\n    submitted by    /u/sussudio45  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zga7zz/proxmox_ve_cluster_with_dell_optiplex_9020_micro/",
          "publishedOn": "2022-12-08T20:17:48.000Z",
          "wordCount": 14132,
          "title": "Proxmox VE cluster with Dell Optiplex 9020 Micro",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zg20qp/simpler_tool_for_configuration_management/",
          "author": null,
          "description": "I recently built a new tool to do some devops work in my home lab, which was initially intended to be a more \"advanced\" exec handler for serf so I could more effectively change backend vm's of my custom load balancer among other things. What I quickly realized was that it was way simpler and easier to use than ansible / chef etc, especially for golang apps where I just needed to drop a binary set up a user and create a systemd unit file with a template, then start the service on an lxc container.\n Some of the key things that make it useful for me is to secure bootstrap of new instances (cloud init) or (golden images), as I can dynamically provision based on instance id/hostname/ip which is locked to particular s3 prefix(or minio), which means I don't need any external inbound requests to the server to provision at all and changing install is as simple as just terminating instance / updating s3 config. It does still function well for serf too though as an exec handler and I now use it as both os installer and exec handler, that first sets up nginx but also can take the members in the serf role and quickly update nginx config + HUP nginx with new members as example.\n The templating uses go templates but variable injection can be done either by providing a preset value or by running a command inline, so you can use hostname -f of the live system to feed a template var. Second to that I built in os limits, so in the same file you can run 2 cmd executions but limit one to ubuntu or specifically ubuntu:20.04 and the other for redhat... This was required for things like installing bind tools which has different package names between the OS's \n Right now there is an nginx install example but I might create a simple one for home assistant and magic mirror etc, with module updates.\n Either way would love some feedback: https://github.com/Nitecon/bruce\n    submitted by    /u/WillTheHatt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zg20qp/simpler_tool_for_configuration_management/",
          "publishedOn": "2022-12-08T15:25:04.000Z",
          "wordCount": 17127,
          "title": "Simpler tool for configuration management.",
          "imageUrl": "https://external-preview.redd.it/H8s1zrFJreOLv2ni_kU6WSorEezGaI8tUG9LM283JRo.jpg?auto=webp&s=e1984a3f03ba2648d2a21147bd174b69c0e735ed"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zg0rhu/i_want_to_get_into_networking_opnsense_vlans/",
          "author": null,
          "description": "submitted by    /u/H_Q_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zg0rhu/i_want_to_get_into_networking_opnsense_vlans/",
          "publishedOn": "2022-12-08T14:38:45.000Z",
          "wordCount": 16126,
          "title": "I want to get into networking - OPNSense, vlans, getting yelled at. Is the Intel i350-T4 a good starting point to add to my Proxmox server?",
          "imageUrl": "https://preview.redd.it/rrhcvx7vqo4a1.png?auto=webp&s=0efaf83cb6cee32408c63e0d7deacf88ff8c3722"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfzjo8/upgrading_a_dell_poweredge_t20/",
          "author": null,
          "description": "Hi everyone,\n I've been the happy owner of a PowerEdge T20, that I bought for a bargain price many years ago (2015?).\n It's served me very well, but I'm starting to think it wouldn't hurt to spend a bit of money and get it a bit more up-to-date on the power front. It would be fine for me to keep the body of the thing, but I would've thought I could upgrade the motherboard and chip, possibly power supply. However, I'm not at all a PC build expert, so don't have much of an idea what the best deals are.\n I'd be looking for excellent bang-for-buck, that should be significantly better than what I already have, but for minimal cost. The thing cost me only something like €250 when I got it, after all.\n Specs:\n  \nMotherboard Dell VD5HY: https://www.itcreations.com/product/84192\n CPU: Xeon(R) CPU E3-1225 v3 @ 3.20GHz \n Having Intel QuickSync for Plex seems to be quite desirable?\n \n Currently 16GB ram. Would be nice to be able to increase that, with good value chips\n  \nHope someone with better skills can advise!\n Thanks in advance!\n    submitted by    /u/Fungled  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfzjo8/upgrading_a_dell_poweredge_t20/",
          "publishedOn": "2022-12-08T13:52:51.000Z",
          "wordCount": 15309,
          "title": "Upgrading a Dell PowerEdge T20?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfxo28/open_homelab_case_to_hold_inside_a_drawer_d/",
          "author": null,
          "description": "submitted by    /u/Gempioo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfxo28/open_homelab_case_to_hold_inside_a_drawer_d/",
          "publishedOn": "2022-12-08T12:35:45.000Z",
          "wordCount": 15016,
          "title": "Open Homelab case to hold inside a drawer :D",
          "imageUrl": "https://preview.redd.it/j7a86ycb5o4a1.png?auto=webp&s=66da656d2a8313ae970ec2edcb9c4dce22431bc6"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfoh8a/fyi_shopgoodwillcom_has_a_bunch_of_dell_wyse/",
          "author": null,
          "description": "I just snagged one with 8gb ram for 37 bucks. These go for 100+ on ebay. It's an auction thing so I had to bid at the last minute to get one. Upgrading my raspberry pi 4.\n    submitted by    /u/mattalat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfoh8a/fyi_shopgoodwillcom_has_a_bunch_of_dell_wyse/",
          "publishedOn": "2022-12-08T04:09:18.000Z",
          "wordCount": 17411,
          "title": "FYI: shopgoodwill.com has a bunch of Dell Wyse 5070's (with intel J5005 processors) for cheap",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfnux7/anyone_have_an_ideia_of_the_year_of_this_chassi/",
          "author": null,
          "description": "submitted by    /u/koyo4ever  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfnux7/anyone_have_an_ideia_of_the_year_of_this_chassi/",
          "publishedOn": "2022-12-08T03:41:59.000Z",
          "wordCount": 15543,
          "title": "Anyone have an ideia of the year of this Chassi?",
          "imageUrl": "https://preview.redd.it/m105mhj3il4a1.jpg?auto=webp&s=d61b2126fde98c8799014c5e80e75188314f3fd0"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfkyuj/moving_reverseproxy_from_vps_to_home_behind_cgnat/",
          "author": null,
          "description": "Hi, I got myself NAS to upgrade my HomeLab and want fix problems with current setup. First I'll describe my setup and issues with it because I may be approaching it completely wrong and missing obvious easy solution\n Current setup\n  \nVPS with static public IPv4\n RPI4 with 1x SSD for data\n Synology DS920+ (new, reason why I'm trying to upgrade my setup)\n  \nMy home is behind CGNAT so I have VPS with NPM.. VPS is sending traffic to RPI4 trough ZeroTier to bypass CGNAT\n Problem with current setup\n  \nall traffic to my services like NextCloud is routed trough VPS and is HEAVILY bottle-necked by my slow internet\n  \nnew setup i want to achieve\n  \nbe able to access local services trough domain at local speeds \n I want to add services like Jellyfin and be able to access them trough my domain (jellyfin.example.com) regardless of me being at home or not and when I'm at home not be bottlenecked by my internet.\n \n  \nSolution i thought of\n  \nrun reverse-proxy at home\n use adguard's dns rewrite to send requests to my domain directly to reverse-proxy at home instead to my VPS and be bottlenecked by my internet\n redirect port 80 & 443 from my VPS to server at home\n  \nFirst I wanted to use \"streams\" in NPM but it didn't work for ports 80 & 443 (of course it didn't) Then I tried to achieve this setup with 'socat' but NPM failed to get SSL cert\n If someone doesn't know, NPM is NginxProxyManager\n info that may matter\n  \nI want to learn traefic and upgrade to it after I get this working, using NPM for now because of the ease of setup \n if traefic will make my desired setup easier I'll go for it straight away\n \n  \n   submitted by    /u/AstacSK  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfkyuj/moving_reverseproxy_from_vps_to_home_behind_cgnat/",
          "publishedOn": "2022-12-08T01:37:02.000Z",
          "wordCount": 14113,
          "title": "Moving reverse-proxy from VPS to home (behind CGNAT)",
          "imageUrl": "https://external-preview.redd.it/D1ipV185QY8kZnEpvHBLdmoBFiyoNWRdt5hPye0i1K8.jpg?auto=webp&s=33b5dcfb9a60b21a5535defec326d23f4c72ed49"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfji3k/starting_on_a_new_hypervisor_for_a_whole_home_kvm/",
          "author": null,
          "description": "submitted by    /u/Johnny1070  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfji3k/starting_on_a_new_hypervisor_for_a_whole_home_kvm/",
          "publishedOn": "2022-12-08T00:35:56.000Z",
          "wordCount": 14042,
          "title": "Starting on a new hypervisor for a whole home KVM project. I will have a silent, desktop-less home, with everything self-hosted.",
          "imageUrl": "https://preview.redd.it/t3gvmt2ikk4a1.jpg?auto=webp&s=50ed99682832fdae8d41a7cccf984afa61371a81"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfi7tr/spacelimited_homelab/",
          "author": null,
          "description": "submitted by    /u/Pferdestaerke  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfi7tr/spacelimited_homelab/",
          "publishedOn": "2022-12-07T23:43:38.000Z",
          "wordCount": 14875,
          "title": "Space-Limited Homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfhb2z/finished_my_quiet_nasserver_build/",
          "author": null,
          "description": "submitted by    /u/wyager  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfhb2z/finished_my_quiet_nasserver_build/",
          "publishedOn": "2022-12-07T23:08:28.000Z",
          "wordCount": 14465,
          "title": "Finished my quiet NAS/server build",
          "imageUrl": "https://preview.redd.it/x4lz5d955k4a1.jpg?auto=webp&s=f7ec5d094638d11992b9e53607419c57bc4bd4da"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zff18o/file_deduplication/",
          "author": null,
          "description": "So, since 1997, I've pretty much deleted nothing and have had multiple drive failures & recoveries. Anyway, now I have a file server (Windows Server 2019) that all these files have been dumped onto with no organization whatsoever (since with some of the drive failures, the folder structures were lost).\n I have anywhere between 3-6 copies of the same file as they existed on multiple drives. Is there any file deduplication software that can look through all these files, pick the non-corrupt ones (yes, I have those too) and place them elsewhere? We're talking close to 10+ million files.\n    submitted by    /u/CelticDubstep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zff18o/file_deduplication/",
          "publishedOn": "2022-12-07T21:47:29.000Z",
          "wordCount": 15465,
          "title": "File Deduplication",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfexix/need_help_deciding_on_a_new_apartment_setup/",
          "author": null,
          "description": "Hey, long time reader here, need some advise / critique on my plans.\n I am planning out networking/homeserver stuff for a new apartment, I have quite a bit of freedom and I already know what my use cases are, but want to do it right.\n Right now I have fiber coming into my apartment and I have the below setup working great for me:\n  \ngeneric ASUS router running openWRT\n 1 managed switch (need VLANs)\n 1 intel Nuc with Ubuntu acting as media PC / home server connected to a TV over HDMI.\n  \nThe NUC has some file shares (few TB in external hard drives) to be accessed locally/over VPN, has Steam for streaming games from a PC (once a month max), Kodi (pretty much replaced by Jellyfin now) and a bunch of containers on it:\n  \nJellyfin (Used for streaming to one TV and 1 laptop, single stream 4K tra…",
          "link": "https://www.reddit.com/r/homelab/comments/zfexix/need_help_deciding_on_a_new_apartment_setup/",
          "publishedOn": "2022-12-07T21:43:55.000Z",
          "wordCount": 14583,
          "title": "Need help deciding on a new apartment setup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfdoko/my_first_venture_into_tape_storage_after_years_of/",
          "author": null,
          "description": "submitted by    /u/NWSpitfire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfdoko/my_first_venture_into_tape_storage_after_years_of/",
          "publishedOn": "2022-12-07T21:01:06.000Z",
          "wordCount": 14854,
          "title": "My first venture into Tape storage after years of wanting to try it (LTO-4)",
          "imageUrl": "https://external-preview.redd.it/ggPwpZgB8ZjwYtRlZjd8GPn_pRlRZYfio7x_4ix4Da4.png?format=pjpg&auto=webp&s=97937a2be66de0173ef47f89f34500e77f4b9866"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfd23b/any_easy_and_inexpensive_way_of_uprgading_w10/",
          "author": null,
          "description": "Hi all, \n Not exactly the question for this sub, but you folks know everything AND Dell Optiplex desktops are quite popular among homelab enthusiasts...\n Long story short - I have several Dell Optiplex desktops I bought off DellRefurbished and ebay over the last 3-4 years, ranging from i5-4590 to i5-8500. Most serve some specific purpose (e.g. a BlueIris surveillance server), others just act as a \"regular\" PC I often RDP to on a daily basis from my work laptop. \n Most of the time I would try to buy the desktop with Pro version of the OS (W10 pro, W7 pro), but it looks like I made a mistake once and bought one W10 Home machine. I can live with most limitations, except for the lack of RDP server functionality. \n I tried rdpwrap on that machine and it usually works for a while, but Microsoft …",
          "link": "https://www.reddit.com/r/homelab/comments/zfd23b/any_easy_and_inexpensive_way_of_uprgading_w10/",
          "publishedOn": "2022-12-07T20:40:17.000Z",
          "wordCount": 15900,
          "title": "Any easy and inexpensive way of \"uprgading\" W10 Home to Pro on one of the used Optiplex machines?",
          "imageUrl": "https://external-preview.redd.it/cgFhkanbA9h4cXuQ6MyKNKHfTb_MPIqohJvTe5F42wM.jpg?auto=webp&s=beb4ba800fecbe89060f49d0494f6c46d7747331"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfcxgm/does_this_apc_short_depth_ups_can_be_placed_on_4/",
          "author": null,
          "description": "submitted by    /u/azsarc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfcxgm/does_this_apc_short_depth_ups_can_be_placed_on_4/",
          "publishedOn": "2022-12-07T20:35:19.000Z",
          "wordCount": 14565,
          "title": "Does this APC short depth UPS can be placed on 4 post rack with the given two rails?",
          "imageUrl": "https://preview.redd.it/d9hefuikvk4a1.jpg?auto=webp&s=4a6fb068c2f175174776cb4ee712a4596267402b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfcoq5/my_first_homelab/",
          "author": null,
          "description": "​\n https://preview.redd.it/w75tfxgyaj4a1.jpg?width=1280&format=pjpg&auto=webp&s=9626d065aaab3b457ff04bc22ecb2f8d3c9f6e7b\n Hardware\n  \nWD WD10SPSX 1 TB 2.5\" 64 MB SATA 3 HDD\n 650VA 360W LINE INTERACTIVE UPS \n Raspberry Pi 4-2GB\n Geekworm NASPi V2.0 2.5 inch SATA HDD/SSD NAS Storage Kit for Raspberry Pi 4 Model B\n TP-Link TD-W9970, N300 Mbps Modem\n  \nServices\n  \n OpenVpn\n PiHole\n Gitea\n  \nOS: Arch Linux ARM armv7l \n ​\n What are your thoughts and recommendations? Do you have a self-hosted service that you suggest?\n    submitted by    /u/scroll_down0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfcoq5/my_first_homelab/",
          "publishedOn": "2022-12-07T20:27:02.000Z",
          "wordCount": 14140,
          "title": "My First Homelab!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfc7hb/dell_630_1u/",
          "author": null,
          "description": "What's the power draw on servers like this? Work is throwing away 2 of them with the Xeon E5-2630v4 10c/20T dual CPUs in them. IDK how much RAM is in them though.\n    submitted by    /u/Fruguy01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfc7hb/dell_630_1u/",
          "publishedOn": "2022-12-07T20:10:32.000Z",
          "wordCount": 13901,
          "title": "Dell 630 1U",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfbett/setting_up_vlans/",
          "author": null,
          "description": "I want to setup VLANs on my network and make sure it's correctly configured and secured so that things like for example VLAN Hopping are not possible and so on. I already know the whole concept of VLANs but I'm not quite sure about implementing it which is why I made this post. So, from my research online it shows that I need to:\n For Wireless:\n Create multiple SSIDs with VLAN IDs on them then mark a port as Trunk on the switch with all the VLAN IDs that were assigned to SSIDs. At the end just plug in the Wireless Access Point to that specific trunk port on the switch. Of course, the main appliance that acts as a router\\firewall needs to have set VLANs in its configuration as well.\n For LAN:\n For the LAN I just configure a VLAN ID and a port on the switch itself to which I then plug a RJ45 cable into. Also, the router\\firewall appliance has its own configuration for LAN VLANs.\n Is this how I should go about setting up VLANs or am I missing something here ?\n Thanks\n    submitted by    /u/Tickle_My_Brain  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfbett/setting_up_vlans/",
          "publishedOn": "2022-12-07T19:43:35.000Z",
          "wordCount": 14093,
          "title": "Setting up VLANs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfb8pq/tlsg1016pe_or_juniper_ex220024p4g_24_for_homelab/",
          "author": null,
          "description": "The TP link has more than enough power for my needs , likely less power hungry, newer, and easier to configure but $100 and I'll have to source or make mounting ears. The Juniper can be had for around $60 with ears included, but likely way harder to configure for a n00b like me. My requirements are 16 port (8x PoE+ 30w) gigabit, rack mountable, not crazy power hungry (under 50w not including PoE)\n Are the extra ports and power consumption that I likely won't need worth the cost savings and configuration difficulty? I have only managed switches through GUI before.\n    submitted by    /u/Tomtortoise  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfb8pq/tlsg1016pe_or_juniper_ex220024p4g_24_for_homelab/",
          "publishedOn": "2022-12-07T19:37:46.000Z",
          "wordCount": 14361,
          "title": "TL-SG1016PE or Juniper EX2200-24P-4G 24 for homelab rack",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfb20b/little_help_sourcing_parts/",
          "author": null,
          "description": "Like the title says. I have a 12 bay Dell R510, I am looking for 11 3.5in drive bay caddies. I've looked around on ebay and other similar used sites, but have come up with wildly high prices. Any help would be greatly appreciated. I am using the server for a plex library so I can further cut ties with streaming services.\n Edit I should mention I am in Canada, so the prices are super inflated.\n    submitted by    /u/SuperVDF  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfb20b/little_help_sourcing_parts/",
          "publishedOn": "2022-12-07T19:31:16.000Z",
          "wordCount": 15132,
          "title": "Little help sourcing parts.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zfabos/ssd_storage_server_rack_solution/",
          "author": null,
          "description": "submitted by    /u/Real_Cantaloupe7683  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zfabos/ssd_storage_server_rack_solution/",
          "publishedOn": "2022-12-07T19:06:15.000Z",
          "wordCount": 16100,
          "title": "SSD Storage Server Rack Solution",
          "imageUrl": "https://preview.redd.it/8282lhn1yi4a1.png?auto=webp&s=ea8247684e7ff9bdf57509ff2cebb43c4604cdc7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zf9z9v/mini_pc_as_a_router/",
          "author": null,
          "description": "Hi ! I am kindda lost on all the small form factors PC around. Dell Optiplex, HP elitedesk, lenovo mxxx... \n I'd like to build a simple router on a small PC, obviously it will need at least two NIC. \n Someone from here showed me the Lenovo M720q, which can handle a i350 4x NIC on a PCIe entry. But currently I only find some pricey ones, and the i350 mod also costs a little. Around +300€ in total, not really worth it for a no wifi router (i'll think about getting a wifi access point later on).\n It's hard to say if other brands can do the same, they do have optional rear ports (vga / hdmi / rs232), but i'm not sure those places could host a NIC from there. I'm thinking of some Dell Optiplex, actually I can get a 3070 for a decent price but without this multi NIC capability i'm not motivated to buy it. It does have a empty \"cross\" at the back (if no optional port there) but I really don't know how to profit from it. \n Has some of you used a small factor PC to turn into a multi NIC router ? If yes could you point me some models, tips or anything of help. \n Thanks a lot !\n    submitted by    /u/ShiningPak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zf9z9v/mini_pc_as_a_router/",
          "publishedOn": "2022-12-07T18:54:37.000Z",
          "wordCount": 16808,
          "title": "Mini PC as a router",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zf9v6m/does_anyone_have_a_manual_for_powermust_1000/",
          "author": null,
          "description": "submitted by    /u/mkar3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zf9v6m/does_anyone_have_a_manual_for_powermust_1000/",
          "publishedOn": "2022-12-07T18:50:40.000Z",
          "wordCount": 15597,
          "title": "Does anyone have a manual for powermust 1000 netguard?",
          "imageUrl": "https://preview.redd.it/c8f99ffwck4a1.jpg?auto=webp&s=a6c9b012944eef7d3bbd07252b008a5785542a15"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zf8fb3/newbie_how_important_is_aeration_for_small_nas/",
          "author": null,
          "description": "Dear Reddit friends\n Like announced in the title, I am not an expert in these matters...\n That being said, I have a big house (3 floors) that will need renovating. I wanted to find a spot where to put the incoming fibre connexion, a 4 bay Synology NAS with media and personal backup, probably a second one for video surveillance, and a switch that would be linked to several ethernet plugs in the house (likely 8+).\n There's a small room below the stairs where this could fit well. But apart from a small door, there is of course no window in there.\n Is that a problem? Any recommendations for what I'd like to achieve?\n Thank you very much!\n    submitted by    /u/Neat_Air_4153  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zf8fb3/newbie_how_important_is_aeration_for_small_nas/",
          "publishedOn": "2022-12-07T18:02:42.000Z",
          "wordCount": 14936,
          "title": "Newbie: how important is aeration for small NAS / server room?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zf5h0n/what_do_i_have_here_need_help_identifying_a/",
          "author": null,
          "description": "Back in 2020, I had the opportunity of a lifetime to buy a bunch of hardware left behind in an Intel research facility that closed down. Some of the equipment was labeled with Engineering Sample stickers stating that they could not be sold, so I was able to get some presumably research equipment for free... but I have no idea what these are other than yes, they are motherboards.\n I acquired five of these because I think they'd be cool nerd wall art and make cool gifts, but I'd love to know more about them.\n Pics: https://imgur.com/a/FNkBTdV\n    submitted by    /u/KapnKerk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zf5h0n/what_do_i_have_here_need_help_identifying_a/",
          "publishedOn": "2022-12-07T16:23:23.000Z",
          "wordCount": 14118,
          "title": "What do I have here? Need help identifying a motherboard",
          "imageUrl": "https://external-preview.redd.it/WyGkajAjtIleYx6MTC1g605YjDJHFFpwnCpdAxlTnRo.jpg?auto=webp&s=60f20ee1edafced1d6d36eb1807dbdebc941fab7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zf59io/replacing_unifi_with_omada_or_opnsense/",
          "author": null,
          "description": "I have a pretty old Unifi setup, with a gen 1 USG, and a gen 1 cloud key. They are no longer accepting upgrades, and I’m afraid to even try updating them manually. I work from home and the last time I upgraded them, I had to take PTO due to the firmware being faulty and having to restore to a previous version.\n While I really like the Unifi platform, I’m thinking of switching to Omada’s platform. My wireless is Ruckus Unleashed, and my security system is Reolink. I’ll never use the other features of the DreamMachines. \n However, Omada is still a newer platform. They just released mDNS, which is what I’ve been holding out for. I see they are releasing a 10GB router, which would directly compete with the UDM platform. I’m debating about going into the Omada platform, or built a OPNSense box, and use that. However, at the end day I don’t want to futs with it, I really like my homelab, but the amount of time I dedicated to it is slowly declining, and if the internet goes out not only does it affect my work, but my wife will also not happy with me lol.\n The part I like about OPNSense, is the hardware HA and the ability to load balance two ISP connections which could come in handy \n Any suggestions?\n    submitted by    /u/SubbiesForLife  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zf59io/replacing_unifi_with_omada_or_opnsense/",
          "publishedOn": "2022-12-07T16:16:15.000Z",
          "wordCount": 17395,
          "title": "Replacing Unifi with Omada or OPNSense",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zf3yo5/arm_based_nas_sbc/",
          "author": null,
          "description": "Does something like this exist?\n  \n4 or more ARM cores \n 2 or more SATA\n 16 GB RAM or more\n Gigabit or faster Ethernet\n NVMe (preferable, not required)\n  \n   submitted by    /u/GAGARIN0461  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zf3yo5/arm_based_nas_sbc/",
          "publishedOn": "2022-12-07T15:31:19.000Z",
          "wordCount": 14113,
          "title": "ARM based NAS SBC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zf3gfq/dualport_1_gigabit_network_card_for_fiber_internet/",
          "author": null,
          "description": "I'm finally about to have a fiber optic 1 Gbps Internet (:I ordered a network card with two 1 Gb ports for my (virtualized) pfsense pc before I was planning on switching to fiber internet. Is it gonna do fine or I need something else?\n I'll be using the dual port card like that:\n -The WAN port will be connected to the ONT (essentially a fiber to ethernet adapter)\n -The LAN port of the card will be connected to a switch since this pfsense pc will have more VMS in the future. Nothing demanding, I'm just planning on a Raspberry Pi image VM (for 3D printer interface) and maybe more intresting stuff.\n    submitted by    /u/SpookyHeaD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zf3gfq/dualport_1_gigabit_network_card_for_fiber_internet/",
          "publishedOn": "2022-12-07T15:10:10.000Z",
          "wordCount": 15338,
          "title": "dual-port 1 gigabit network card for fiber internet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zewfml/anyone_use_cheap_50_office_pc_from_ebay_to_use/",
          "author": null,
          "description": "So I’ll first say that a full Desktop PC wasn’t what I was hoping for. But seeing as Raspberry Pi’s are currently very expensive, it’s the next cheapest alternative. Has anyone done this before? It would probably be used to run Linux and mostly just headless usage. A lot of them say they have 8gb of DDR4 Ram and an old Intel i3-i7. Hard drive is usually the thing I’d replace since most of them are HDD. But other than that they seem fine for home labbing. Anyone try this?\n    submitted by    /u/Quinn_Lugh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zewfml/anyone_use_cheap_50_office_pc_from_ebay_to_use/",
          "publishedOn": "2022-12-07T09:02:41.000Z",
          "wordCount": 20425,
          "title": "Anyone use cheap $50 office PC from eBay to use for home lab? Any thoughts on this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zesykx/is_it_okay_to_mount_my_hp_dl380_vertically_like/",
          "author": null,
          "description": "submitted by    /u/purpledrz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zesykx/is_it_okay_to_mount_my_hp_dl380_vertically_like/",
          "publishedOn": "2022-12-07T05:22:21.000Z",
          "wordCount": 17879,
          "title": "Is it okay to mount my HP DL380 vertically like this?",
          "imageUrl": "https://preview.redd.it/17tsw002ve4a1.png?auto=webp&s=f26d834886449bb814e06e6f4565bc729b67a617"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zeoxob/watercooled_dual_xeon_esxi_host/",
          "author": null,
          "description": "submitted by    /u/_Frank-Lucas_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zeoxob/watercooled_dual_xeon_esxi_host/",
          "publishedOn": "2022-12-07T01:56:12.000Z",
          "wordCount": 17838,
          "title": "Watercooled Dual Xeon ESXi Host",
          "imageUrl": "https://preview.redd.it/zmo1nsbaud4a1.jpg?auto=webp&s=5f76729f42ae8d39cee661abd22b2630177f1fbb"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zenx8z/vlan_designsafety_sanity_check/",
          "author": null,
          "description": "I'm considering running DMZ traffic over a VLAN trunk with some other LAN VLANs and was just wanting to confirm some assumptions I'm making in this consideration. I realize the best scenario here is to use a completely separate set of cables and switches for the DMZ network, but I'd like to avoid this if I can for the sake of this consideration.\n As a hypothetical example for the purposes of this question, I have a router, a Layer 2 managed switch, some user PCs, and a server running a publicly-accessible website.\n I have two VLANs I want to use, VLAN2 and VLAN3:\n  \nVLAN2 is the LAN, the user PCs are connected to this. The switch is configured to tag to VLAN2 the incoming untagged packets from user PCs on the VLAN2 ports.\n VLAN3 is the DMZ for WAN traffic the firewall permits through to ac…",
          "link": "https://www.reddit.com/r/homelab/comments/zenx8z/vlan_designsafety_sanity_check/",
          "publishedOn": "2022-12-07T01:07:06.000Z",
          "wordCount": 14525,
          "title": "VLAN design/safety sanity check",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zen0x0/best_method_for_full_iphone_backup_to_my_nas/",
          "author": null,
          "description": "I want to back up my phone similarly to apple’s iCloud service. My main concern is backing up my iMessage and Contacts. I know photos, videos, and files are possible but how do I upload a full backup?\n    submitted by    /u/Choice-Variety-8879  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zen0x0/best_method_for_full_iphone_backup_to_my_nas/",
          "publishedOn": "2022-12-07T00:23:40.000Z",
          "wordCount": 14017,
          "title": "Best method for full iPhone backup to my NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zen0p9/which_are_the_cheapest_high_bandwidth_motherboard/",
          "author": null,
          "description": "I was going the route of the x99 + 2650L v4 but reading more one all the options, I'm not so sure it'll work well because I cannot find out if the various BIOS supports bifurcation.\n The end goal is to push 5GB/s through a mellanox 100gbe.\n Thanks!\n    submitted by    /u/mcdroid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zen0p9/which_are_the_cheapest_high_bandwidth_motherboard/",
          "publishedOn": "2022-12-07T00:23:22.000Z",
          "wordCount": 13774,
          "title": "Which are the cheapest high bandwidth motherboard + cpu?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zemtcb/websitename_hosting_reliable_australian/",
          "author": null,
          "description": "I have been using Servage for 'forever' for my website space, domain names and management. Theyve slowly gotten more and more expensive to not just buy but to manage, while theyre progressively offering less and less.\n Any fellow Aussie Homelabbers out there can recommend a solid host, space, easy reg of new domains (and settings designed for Labbers)?\n Apparently, I need to find something new and swap before Jan 3, 2023 otherwise Ill be charged HEAPS more & be locked into a ridiculous contract even to try save some money.\n Cheers, Capt ZP\n    submitted by    /u/capt_zen_petabyte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zemtcb/websitename_hosting_reliable_australian/",
          "publishedOn": "2022-12-07T00:14:21.000Z",
          "wordCount": 13879,
          "title": "Website/name hosting, reliable & Australian?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zemjbz/case_upgrade_for_homelab_unraid_build/",
          "author": null,
          "description": "Been thinking about upgrading the case for my unRAID server sometime next year. Current specs below\n  \nFractal Design Define 7 XL Black\n MAXIMUS IX HERO w/ i7-7700K, 32GB RAM\n LSI Logic 9201-16i\n 10x 4TB 3.5\" HDD (HBA & SATA)\n 1x 256GB SSD (m.2)\n 1x 1TB 2.5\" SSD (SATA)\n  \nCabling is starting to get cramped, and i don't feel like buying any more 3.5\" drive mounts for the case. I was looking for something similar to the NORCO RPC-4224 but im not sure if NORCO is still in business\n Any recommendations for a server chassis style case with 16+hot-swap bays and support for ATX motherboards that won't break my bank?\n    submitted by    /u/alchemistzim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zemjbz/case_upgrade_for_homelab_unraid_build/",
          "publishedOn": "2022-12-07T00:02:33.000Z",
          "wordCount": 14111,
          "title": "Case Upgrade for HomeLab (unRAID Build)",
          "imageUrl": "https://external-preview.redd.it/ESWR0GD2deBaeMmLFQdBObX2fiWro_gZ0_L98tWM49E.jpg?auto=webp&s=357aa71d3b60db02f0f60a3c98524173c8337b6c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zemeiu/docker_on_bare_metal_or_vm_plex_and/",
          "author": null,
          "description": "Hey Folks,\n So I am working on upgrading my hardware, mostly my TrueNAS and Proxmox servers. I've been running my plex container directly on my TrueNAS server (an old octocore phenom amd cpu) to give it direct access to storage, this has worked well for me, but now I am considering some other options during this upgrade process.\n My new servers will be dual xeons with 22 cores on each CPU. I know this is far overkill for TrueNAS, so I started thinking, maybe I should keep truenas on the octocore and create a VM with access to the storage on the truenas over my back end network. I'm going to be using teamed 4 port gigabit nics on each of the servers I am building to provide good network thruput to my vm hosts from TrueNas where the VM disks will be stored\n If I put the docker container in a VM and host it on proxmox over the network, do you think I will get similar performance over the VM as I would directly on the truenas box?\n Really the question is, do I want to waste(?) all that CPU power on truenas with some docker containers, or host it in a VM and be able to throw as many cores/memory at it as I want and leave the truenas server on the octocore phenom? This will let me use the 2 xeon systems I am building strcitly as proxmox servers and leave the lower end box as just a nas instead of nas and docker.\n I hope this makes sense, my thinking feels a bit scattered, but I think I got my point across\n Any advice would be appreciated!\n Thanks!~Rick\n    submitted by    /u/RickoT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zemeiu/docker_on_bare_metal_or_vm_plex_and/",
          "publishedOn": "2022-12-06T23:57:17.000Z",
          "wordCount": 14429,
          "title": "Docker on Bare Metal or VM? (Plex and Nextcloud/Seafile)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zembxf/workstation_hardware_suggestion_docking_station/",
          "author": null,
          "description": "My current setup: \n an old Mac Air (early 2015) \n a desktop whitebox with a Nvidia something-or-other that drives 4 monitors off 2 outputs (DP mini). It has about 3 boot drives with multiple partitions and a plethora of OSes. \n ​\n I want to transition my daily driver to my Mac Air (soon to be replaced by a new MacPro) while still using my quad-monitor rig, but still retain access to my desktop (I like Linux when I'm just goofing around on the internet, doing CLI-based things, etc) with minimal physical effort (re-configuring cables, etc).\n Therefore, my mind goes to a docking station with a KVM or something, of the sorts. Anyone have any suggestions?\n    submitted by    /u/redraybit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zembxf/workstation_hardware_suggestion_docking_station/",
          "publishedOn": "2022-12-06T23:53:55.000Z",
          "wordCount": 13900,
          "title": "workstation hardware suggestion - docking station or dual KVM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zem8xf/nice_cabinets_with_hidden_it_rack/",
          "author": null,
          "description": "Looking fir a nice finished looking office cabinet that happens to have a built in equipment rack.\n Has anybody seen one or is this basically only a diy type thing?\n    submitted by    /u/Savva135  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zem8xf/nice_cabinets_with_hidden_it_rack/",
          "publishedOn": "2022-12-06T23:50:13.000Z",
          "wordCount": 13701,
          "title": "nice cabinets with hidden IT rack?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zelow5/r730_minimum_fan_31/",
          "author": null,
          "description": "For my ESXi host, I got an R730 to replace an R720 and cannot get the fans to go below 31% so asking for suggestions as it appears to be hardcoded in some way. Wondering if maybe via the idrac settings version, which is 2.40.40.05? \n It is the latest BIOS/IDRAC and I have tried several older versions as well. It came with 2.15.10.10 and is now 2.83.83.83 and BIOS is 2.16.0. Due to habit from the R720s I stepped it up with every major release until current. ie 2.40.40.40 to 2.50.50.50. iDRAC was reset once current.\n running radadm via SSH shows the following and I already did the 3 settings to try and cut it down.\n /admin1-> racadm get system.thermalsettings\n [Key=system.Embedded.1#ThermalSettings.1]\n AirExhaustTemp=70\n #FanSpeedHighOffsetVal=71\n #FanSpeedLowOffsetVal=23\n #FanSpeedMaxOffsetVal=100\n #FanSpeedMediumOffsetVal=48\n FanSpeedOffset=Off\n #MFSMaximumLimit=100\n #MFSMinimumLimit=31\n MinimumFanSpeed=255\n ThermalProfile=Minimum Power\n ThirdPartyPCIFanResponse=Disabled\n Doing F2 then iDRAC then thermal ( think it was) I can set the fan min via a custom but 31 is the lowest it will let me. Via the iDrac web interface it shows that as well\n ​\n https://preview.redd.it/j22d4eik2d4a1.png?width=1656&format=png&auto=webp&s=0dd9581883a61ff5642068807393d52e0bc9e70d\n It is stock except I added a SATA drive (technically mSATA via converter), M.2 in PCIe slot and Mellanox X-3 card.Does have PERC H730 and 1/10GB NIC which as a side note I tried removing them but it would complain during POST so I put them back in. It runs ESXi 7. I was going to remove the storage and just use a USB liveCD to see if it changes due to the third party but per the racadm that's disabled anyway. \n I'd rather not go IPMI route since the ESX can spin up at any second but thinking I may have to. Or go back to the R720.\n Suggestions?\n    submitted by    /u/kevinfason  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zelow5/r730_minimum_fan_31/",
          "publishedOn": "2022-12-06T23:27:38.000Z",
          "wordCount": 14433,
          "title": "R730 Minimum Fan 31%",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zel4vf/does_apple_airport_access_points_support/",
          "author": null,
          "description": "I’m able to get apple airport devices relatively cheaply compared to other wifi access points and just want to use them with WPA2-Enterprise as i have a RADIUS server running on Windows Server 2016 with Network Policy Manager, so i’m just wondering if anyone knows if its possible.\n Most google results are contradictory and from 2011-2013 so if anyone knows that would be really helpful.\n    submitted by    /u/Jackmitchell62  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zel4vf/does_apple_airport_access_points_support/",
          "publishedOn": "2022-12-06T23:06:01.000Z",
          "wordCount": 14557,
          "title": "Does apple airport access points support WPA2-Enterprise?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zekxy5/looking_for_comparable_intel_to_ryzen_5_3600/",
          "author": null,
          "description": "I'm building a new server to replace my R710 and I'm converting it to a backup server that I'll spin up once or twice a week for the backups and maybe to play in virtualization some more (since it's 12 cores and lots of memory)\n My main thing here is a performant server that is still energy efficient enough (I'm fortunate to have relatively inexpensive electricity per watt). I had thought about a ryzen build but I convinced myself that I want a late-gen intel with quicksync and not need a GPU in the server using more wattage. So I want thoughts on comparable intel chips for this setup, it's a NAS but my main service is plex so I want the quicksync for transcoding since I have a few family members offsite that use it from time to time. other than that it runs all *arr libraries, portainer/docker, nextcloud, nginx proxy, and about 10 other docker containers. The R710 is running most of the time under 30% CPU usage but it spikes at times.\n I'm working on not spending a ton of money as I don't need to. Intel i3-9100, I3-10100 and even i5-9600 have been thoughts. I want something that uses energy well, uses cores efficiently, has quicksync, and offers enough cores/bandwidth to do what I need to and then some (I want this to future proof me for a bit)\n Thanks for any thoughts!\n    submitted by    /u/FourTimesRadical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zekxy5/looking_for_comparable_intel_to_ryzen_5_3600/",
          "publishedOn": "2022-12-06T22:58:55.000Z",
          "wordCount": 14600,
          "title": "Looking for comparable intel to Ryzen 5 3600",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zekubn/new_server_build/",
          "author": null,
          "description": "My current servers are sitting on some age and I'm wanting to add some functionality. So I'd like to combine my servers + add a gaming VM running some sort of RTX 3 series. 3070ti most likely.\n currently running a couple VMs with NVR and testers. plex, HA, and a couple other containers. I'm looking at the TRP 5965x + gigabyte WRX80 board.\n I like the threadripper for the cores + PCI lanes + RDIMMs I don't like that it's DDR4. \n I'm hoping this build will last 5 or so years. Will it really matter for a while that I'm going on a DDR4 platform or should I hold off yet again for a DDR5 threadripper (Potentially another year or more)?\n Thanks!\n    submitted by    /u/STGMavrick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zekubn/new_server_build/",
          "publishedOn": "2022-12-06T22:54:59.000Z",
          "wordCount": 13894,
          "title": "New Server Build",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zejw00/am_i_able_to_use_this_slot_for_10gig/",
          "author": null,
          "description": "submitted by    /u/Revirst  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zejw00/am_i_able_to_use_this_slot_for_10gig/",
          "publishedOn": "2022-12-06T22:17:19.000Z",
          "wordCount": 14433,
          "title": "Am i able to use this slot for 10gig?",
          "imageUrl": "https://preview.redd.it/j89gafobrc4a1.jpg?auto=webp&s=aae8b4706b82e9973e2e6fd4e4fff9e78184b58e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zejl3p/looking_for_juniper_ex3400_firmware/",
          "author": null,
          "description": "looking to upgrade switches, anyone have the firmware for this model?\n    submitted by    /u/tier_2_slave  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zejl3p/looking_for_juniper_ex3400_firmware/",
          "publishedOn": "2022-12-06T22:05:02.000Z",
          "wordCount": 13549,
          "title": "looking for juniper EX3400 firmware",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zejkbx/recommended_online_retailer_in_eu/",
          "author": null,
          "description": "Hey folks, Please share your wisdom or recommendation for reputable online retailer in EU, I’m specifically looking for Gen9 i7 9700T or i9 9900T CPU.\n I see some listings in ebay with shipping from china, but thats just questionable game to take.\n Amazon - yeah maybe, but no, crazy prices.\n Any pointers?\n    submitted by    /u/badger707_XXL  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zejkbx/recommended_online_retailer_in_eu/",
          "publishedOn": "2022-12-06T22:04:08.000Z",
          "wordCount": 13764,
          "title": "Recommended online retailer in EU?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zej3ui/are_there_any_network_media_servers_which_connect/",
          "author": null,
          "description": "Is it possible to play media on my TV whilst uploading content via my computer? My TV is wall mounted and using a USB stick is painful.\n    submitted by    /u/spacemarineVIII  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zej3ui/are_there_any_network_media_servers_which_connect/",
          "publishedOn": "2022-12-06T21:46:24.000Z",
          "wordCount": 14569,
          "title": "Are there any network media servers which connect to the TV and my home PC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zej30l/hdd_listed_as_new_return_it_or_no/",
          "author": null,
          "description": "submitted by    /u/Adamsandlersshorts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zej30l/hdd_listed_as_new_return_it_or_no/",
          "publishedOn": "2022-12-06T21:45:29.000Z",
          "wordCount": 14526,
          "title": "HDD listed as new. Return it or no?",
          "imageUrl": "https://external-preview.redd.it/0PFAX-aIH4Dh7ZolxjORgvWW5-1WS22fzauVKWQbQv8.png?auto=webp&s=bef069c540f52d5381ff8058d66815ddcb7ac1d7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zeiz92/move_uraid_build_to_hp_proliant_ml350p_g8/",
          "author": null,
          "description": "I bought this server hoping to move my unraid setup over to it. Not knowing much about enterprise server setup, I see I am running into issues. I am now aware of the raid controls on these servers. It has the Adaptec 5808 hba, which apparently can be flashed into IT mode to passthrough the HDDs. The drives on the onboard raid control can sometimes be seen by unraid but are showing as different drives than what the array was. My question, would it just be easier to just buy a compatable hba card for both of the backplanes? Will it then be just plug and play as if i was just moving the array to another PC? Also, Would any limitations of storage capacity be on the hba card or the backplane end? Most of my HDDs are currently 4tb but looking to upgrade to 6 or 8tb per drive. I am looking for the best way to move drives and be seen by Unraid with no new configuration. I can move the array from one pc to the next no problems. Any help would be appreciated.\n    submitted by    /u/QuaiTheDragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zeiz92/move_uraid_build_to_hp_proliant_ml350p_g8/",
          "publishedOn": "2022-12-06T21:41:23.000Z",
          "wordCount": 14775,
          "title": "Move Uraid build to HP Proliant ML350p G8",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zeigxg/mellanox_is5025/",
          "author": null,
          "description": "Is the mellanox IS5025 any good? It's a 36x 40G switch, and I'm seeing them listed in quite a few places for very very cheap ~$200. What's the catch? Why is a 40g switch 10x cheaper than a 10G?\n I don't really need 40g as I've yet to need 10g in everything apart from a few servers, but I am curious as to why they're so cheap.\n Thanks.\n    submitted by    /u/fatredditor69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zeigxg/mellanox_is5025/",
          "publishedOn": "2022-12-06T21:21:28.000Z",
          "wordCount": 13994,
          "title": "Mellanox IS5025?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zei3pt/m2_drives_in_u2_adapters/",
          "author": null,
          "description": "Hi team!\n I got me an R640, that I am planning to use with NVMe. What is the most reasonable approach to buying the NVMe storage? I don't need large capacities. 1-2-4 TB is more than I would possibly ever need. This will be running on ZFS, I guess as a mirror.\n So the question - what should I pursue? The used DC drives? New ones? Optane? Or may be this is a viable option: https://www.amazon.com/StarTech-com-M-2-U-2-Adapter-SFF-8639/dp/B073W65QX6\n or this: https://www.amazon.com/ICY-DOCK-Tool-Less-SFF-8639-Converter/dp/B07T8LJY23\n An adapter for the M.2. That last option looks tempting, since M.2 drives are getting real cheap. PCIe 3.0 in particular.\n Or am I completely on a wrong track and there is a better way to enjoy the NVMe?\n Thank you.\n    submitted by    /u/sergedubovsky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zei3pt/m2_drives_in_u2_adapters/",
          "publishedOn": "2022-12-06T21:06:57.000Z",
          "wordCount": 14022,
          "title": "M.2 drives in U.2 adapters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zefr0y/older_intel_nuc_projects/",
          "author": null,
          "description": "So I recently came across a deal on some free older Intel Nucs, mainly Nuc5ppyh models but also some Nuc5cpyh models. I have about 65 total (way more than I need) and they have a mix 2/4 gb of ram and 120/240gb of SSD storage. They all run N3700s or N3050s and can only accept one stick of DDR3L.\n ​\n While I have been wanting to find some fun homelab projects to do with them I was not sure if these would be worth my time or if I should find better hardware? Running the steam link app and gaming off my desktop does run smoothly so far.\n ​\n I was going to use a few for things like a portable kodi/plex box with a projector. Would it be possible to manage a NAS through one? or play around with active directory? \n ​\n My current home setup is just a laptop for general use and a Gaming PC for gaming and media storage. I would love to get a rack for home and run a couple servers though. Thanks for any feedback!\n    submitted by    /u/Pack3r7465  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zefr0y/older_intel_nuc_projects/",
          "publishedOn": "2022-12-06T19:35:28.000Z",
          "wordCount": 14836,
          "title": "Older Intel Nuc Projects",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zecsh8/server_in_the_shed_quesstion/",
          "author": null,
          "description": "Hi everyone\n I have a server in my backyward shed that is out there in cold and I believe outside in winter there is a lot of cold and moisture in the air, I think at some point it will affect my erver in some way\n is there any way to prevent this moisture from going into the server inside the shed? \n Thanks in advance\n    submitted by    /u/descended2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zecsh8/server_in_the_shed_quesstion/",
          "publishedOn": "2022-12-06T17:37:33.000Z",
          "wordCount": 16353,
          "title": "Server in the shed quesstion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ze8ygm/advice_needed_a_good_alternative_to_raspberry_pi/",
          "author": null,
          "description": "I want to build a tiny cluster for my work experiments with kubernetes and possibly to host a few my own applications in the future.\n As hardware for the cluster I wanted to use Raspberry Pi 4 CM4 on Turing Pi board, but as many of you know - it's nearly impossible to buy a raspberry right now, so I think I have two possible options:\n - Build a cluster using Raspberry Pi alternative - Orange Pi: 4xOrange Pi 4LTS 4gb or 3xOrange Pi 5 with 8gb ram each.\n - Build a cluster using NUC 5PPYB (around 50$ on Amazon). \n I think it's easy to achieve working k3s cluster with the second option, but I also like an idea to have my own Pi (not Raspberry although) cluster. What I don't like about Orange Pi is a small community and less tutorials and documentation comparing to Raspberry Pi community. Because it'll be my first SBC it could be difficult for me to setup everything. \n What do you think about both options? Maybe I miss something?\n    submitted by    /u/MondayBegins  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ze8ygm/advice_needed_a_good_alternative_to_raspberry_pi/",
          "publishedOn": "2022-12-06T15:01:48.000Z",
          "wordCount": 17820,
          "title": "Advice needed: a good alternative to Raspberry Pi cluster for homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/ze16as/backup_power_supply_for_10_rack_at_home_diy/",
          "author": null,
          "description": "Hi. I have a 10\" rack at home, 12U height. Currently have installed there a PDU, ethernet switch, router and power injector for internet access ODU installed on the roof of my house. On the bottom there is a plastic pipe (that goes under the ground to the street) where fiber would be placed in the future. In near future I plan to install also NVR for cameras and NAS for storage.\n ​\n Since I'm working remotely from home, I need backup power supply in case of power outage, that happens from time to time for couple of minutes. It is a problem when you are providing training online for bunch of people and network goes down :). I was looking for 10\" rack AC UPS, but there are none on the market. I was looking for modular UPS with external battery, but none for 10\" rack.\n ​\n Since all my current and future devices are DC powered I've decided to use buffer switch mode power supply unit. There are sockets for 230V AC input, 12V DC output, connectors for battery. Battery can perfectly fit at the bottom of the shelf where I had a free space (next to this pipe for fiber). PSU fits in standard 10\" rack 1U shelf with extra metal sheet wall in the front (custom build). I've installed also status LEDs that shows status of AC input, DC output, battery charge. I've installed fuse module with 4 outputs, so each of my devices have own fuse. One of devices works only with 9V, so I've installed also DC/DC converter from 12V to 9V. I've selected 12V 9Ah battery and set 1A charging current.\n ​\n Currently my devices consume at most in total 15W, so 9Ah battery is enough for 7h+. After I add planned devices it will increase to 45W, so battery would keep devices on for ~2h 30min. I plan to replace then a battery with bigger one.\n ​\n Here are some photos.\n Power supply for my 10\\\" rack\n ​\n Battery I've used\n ​\n How it looks before installation\n ​\n Houw it looks after installation\n Inside\n ​\n This is how it looks currently, free space is for future devices.\n    submitted by    /u/ThatsMyUsernameDear  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/ze16as/backup_power_supply_for_10_rack_at_home_diy/",
          "publishedOn": "2022-12-06T09:03:41.000Z",
          "wordCount": 16786,
          "title": "Backup power supply for 10\" rack at home - DIY",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdr5e8/helpful_suggestions_for_new_247_performance/",
          "author": null,
          "description": "I've come here before for different suggestions but I'm about to pull the trigger on a specific configuration, want to see if anyone has made similar moves with any tips. For years I've been running a server, first a modded tower server, but for the last 5ish years it's been a dell poweredge R710. Currently it has 6 4TB drives in it, dual L5640 xeon cpu, 24GB ECC memory, 128Gb SSD running openmediavault, and nvme cache drive.\n This runs everything for me. All the 'arr' software, plex (used more than anything, honestly), security cams, ngingx reverse proxy, portainer/docker, nextcloud, minecraft, wordpress, etc.\n I love the setup but I'm running out of space. I thought about getting a disk shelf but it seems a little less efficient than I like, and I also need a new backup solution.\n This m…",
          "link": "https://www.reddit.com/r/homelab/comments/zdr5e8/helpful_suggestions_for_new_247_performance/",
          "publishedOn": "2022-12-06T01:37:11.000Z",
          "wordCount": 14486,
          "title": "Helpful suggestions for new '24/7 performance server' and converting my R710 to a backup?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdqynx/i_built_my_first_actual_server/",
          "author": null,
          "description": "i got a x9drd-it+ motherboard 196gb ecc ddr3 and 2x ev2690v2s my plan was to use it for virtulization but i want to try something i havent done before with a server ive built domain controllers a nas built a pfsence machine and a apache2 server and i dont know what to do next ideas?\n ​\n sorry about spelling and grammar i dont usually talk to people lol\n    submitted by    /u/acedaawsome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdqynx/i_built_my_first_actual_server/",
          "publishedOn": "2022-12-06T01:28:55.000Z",
          "wordCount": 13689,
          "title": "I built my first actual server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdqoyy/equallogic_ps4100_drive_setup_issues/",
          "author": null,
          "description": "submitted by    /u/ACrankyOstrich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdqoyy/equallogic_ps4100_drive_setup_issues/",
          "publishedOn": "2022-12-06T01:16:41.000Z",
          "wordCount": 13651,
          "title": "EqualLogic PS4100 Drive setup issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdps3o/good_deal_for_a_cisco_switch/",
          "author": null,
          "description": "Hi, fellow Homelabbers!\n So, I have been wanting to upgrade my switch on my homelab for a little bit and have found this Cisco switch on eBay:\n https://www.ebay.com.au/itm/153618327472\n It's a Catalyst 3750X with 48 GBe ports. It also comes with a C3KX-NM-10G module installed, which should hopefully give my 10GBe via SFP.\n It's AU$349 (which is around US$234.30)\n Is it a good deal, or should I continue shopping around for something else?\n Thanks for any help in advance! :)\n    submitted by    /u/Trancebrony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdps3o/good_deal_for_a_cisco_switch/",
          "publishedOn": "2022-12-06T00:37:41.000Z",
          "wordCount": 14231,
          "title": "Good deal for a Cisco Switch?",
          "imageUrl": "https://external-preview.redd.it/kUjbJ128pEdVzTkF3zbSH1TF1a187o9GOTC8pdMxKRM.jpg?auto=webp&s=f190188c90ac5d0994b2e0cd122261ac7d9a0f24"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdp82o/hp_microserver_gen_8_cant_boot_ubuntu_cd/",
          "author": null,
          "description": "Hi, I've been trying to set up a home server using a HP Microserver Gen 8 however I can't get to the Ubuntu installer, it presents the grub menu and selecting \"try or install\" goes to a blinking cursor and just hangs there. I'm loading loading he ISO via the ILO web interface and I'm a bit stumped.\n    submitted by    /u/samishal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdp82o/hp_microserver_gen_8_cant_boot_ubuntu_cd/",
          "publishedOn": "2022-12-06T00:14:53.000Z",
          "wordCount": 14399,
          "title": "HP Microserver Gen 8 Can't boot Ubuntu CD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdp0ju/1l_micro_pc_server_os_question/",
          "author": null,
          "description": "First time poster to this Reddit. I have decided to repurpose a seocnd hand 1L micro PC as a home server.\n I plan to run Pihole, PiVPN, Radarr, and a file server. It has a 256GB NVMe SSD which I plan to install the OS on. I also plan to put a 1TB SATA SSD in for storage.\n My question is, for my use case, would it be better to run everything above bare metal with like Debian or Ubuntu Server, or a hypervisor like Proxmox and run all my desired services in VMs?\n    submitted by    /u/ApatheticMoFo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdp0ju/1l_micro_pc_server_os_question/",
          "publishedOn": "2022-12-06T00:06:34.000Z",
          "wordCount": 13741,
          "title": "1L Micro PC Server OS Question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdoo6g/new_1u_build_d/",
          "author": null,
          "description": "Parts List: \n  \nIN-WIN IW-RF100-S315 \n ATX 315W Gold PSU \n AsRock Rack X470D4U Micro ATX Server Motherboard\n AMD Ryzen 9 5900X \n Dynatron A18\n \n CORSAIR Vengeance LPX 128GB (4 x 32GB) 288-Pin PC RAM DDR4 3200\n 10Gb PCI-E NIC Network Card\n  SAMSUNG 970 EVO Plus SSD 1TB NVMe M.2 \n Seagate IronWolf NAS Hard Drive (2 x 8TB)\n  \nhttps://preview.redd.it/55or75zh364a1.png?width=4032&format=png&auto=webp&s=8ed1b558ffbcef4dda32b2114199e977108f5063\n    submitted by    /u/ZanesCyno  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdoo6g/new_1u_build_d/",
          "publishedOn": "2022-12-05T23:53:43.000Z",
          "wordCount": 13898,
          "title": "New 1U Build :D",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdnhv3/getting_started_is_my_ancient_n66u_router_good/",
          "author": null,
          "description": "Presently rocking the default modem/router combination that xfinity provided, just for my two computers, cell phone, and guest's devices.\n I've been wanting to get pi-hole running in my apartment for awhile now. However the markups on rasberry pi's are outrageous right now, and my search for an alternative led me here. Have a used Dell Wyze 5070 (16gb flash, 4gb ram, 1.5ghz quad core Celeron) thin client on the way.\n Assuming I won't be able to customize the xfinity combo modem to work for pihole. So I've pulled out my Asus N66U Black Knight router, planning on placing the xfinity in bridge mode and running that. Newest fw I could find was DD WRT from late 2020.\n Is that fw recent enough or should I be looking for a new router? While I'm sure the router is good enough for my miniscule needs I need it to be secure as possible.\n    submitted by    /u/NoGoodInThisWorld  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdnhv3/getting_started_is_my_ancient_n66u_router_good/",
          "publishedOn": "2022-12-05T23:12:17.000Z",
          "wordCount": 14667,
          "title": "Getting started, is my ancient N66U router good enough for now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdng0o/its_not_amazing_but_its_mine/",
          "author": null,
          "description": "submitted by    /u/toilet-breath  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdng0o/its_not_amazing_but_its_mine/",
          "publishedOn": "2022-12-05T23:10:34.000Z",
          "wordCount": 14517,
          "title": "It’s not amazing, but it’s mine!",
          "imageUrl": "https://preview.redd.it/n1dlxvvfd74a1.jpg?auto=webp&s=efd7ff20e49ac556b255e2b44269f635bfd759e5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdnat4/evolution_of_my_homelab_over_the_past_few_years/",
          "author": null,
          "description": "I live in a flat where my desktop PC (which I use for work) and the ISP router are at the absolute opposite corners, with multiple walls and doors between. Running Ethernet without drilling holes isn't possible due to some unfortunate obstructions.\n I moved here about ~3.5 years ago and, having resigned myself to a wireless existence, decided to get the best possible router and PCI-E WiFi card I could find. At the time, those were the Netgear Nighthawk R9000 and Asus PCE-AC88 respectively. In 2022, there is still nothing better than that Asus for 4x4 MIMO.\n Anyway, it all started very simple. ISP router in modem mode, and the Netgear doing all the heavy lifting:\n https://preview.redd.it/5hman0wpr54a1.png?width=2184&format=png&auto=webp&s=4882c5be0371398146ad3a4f92426df9ffe14782\n This served me well for quite a while and I've been able to achieve ~750Mbps between WAN and my desktop PC. Not quite maxing out the gigabit link, but close enough.\n Recently, I got the itch from this subreddit and decided to take advantage of some Black Friday deals and build my own OPNsense router. It took about a day to set everything up, but it turned out great! (pictures here)\n Around the same time, I also decided to build myself a Kubernetes cluster because 1- why not and 2- I've been meaning to play with it for a while. For that, I grabbed three ThinkCentre M92p Tiny PCs from eBay. These are great little machines with an i5-3470T, 16GB RAM and 128GB SSD. Not bad for £70 each!\n Overall, the network now looks like this:\n https://preview.redd.it/4moa9kekt54a1.png?width=3284&format=png&auto=webp&s=5640a50bc4a4d3cc6bdd299ec60ea1f9be2e9b6c\n I still have a lot to learn and experiment with, but I'm pretty happy with this setup.\n    submitted by    /u/callcifer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdnat4/evolution_of_my_homelab_over_the_past_few_years/",
          "publishedOn": "2022-12-05T23:05:30.000Z",
          "wordCount": 13424,
          "title": "Evolution of my homelab over the past few years",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdmkl4/gpu_passthrough_power_usage_when_vm_is_off/",
          "author": null,
          "description": "I'm wondering what kind of power usage a GPU (say an NVIDIA 3070 Ti) would have when it's passed through to a VM, but the VM is powered off. Would the GPU consume more or less 0 watt? Or would it be similar to a GPU just idling on a Linux machine?\n    submitted by    /u/GAGARIN0461  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdmkl4/gpu_passthrough_power_usage_when_vm_is_off/",
          "publishedOn": "2022-12-05T22:41:29.000Z",
          "wordCount": 14189,
          "title": "GPU passthrough, power usage when VM is off",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdmcgn/reverse_proxy_layer_4/",
          "author": null,
          "description": "Hi folks.. I'm trying to figure out the smartest approach to some sort of gateway/reverse proxy that will shove all requests (along with their ports) for a given server address to an internal address. Primarily since I got the kids domains for christmas, and it would be nice to allow them to have their own minecraft server and the like (probably a web server) attached to that domain. I know it's super easy for http content, but I can't say that I've tried to redirect at a lower level before. Caddy docs say I should be able to do it with their L4 plugin, but I've never used caddy. Suggestions?\n    submitted by    /u/TotallynotJohnSmith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdmcgn/reverse_proxy_layer_4/",
          "publishedOn": "2022-12-05T22:33:47.000Z",
          "wordCount": 14293,
          "title": "Reverse proxy - Layer 4?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdm6it/i_have_built_a_few_desktops_in_the_past_and_have/",
          "author": null,
          "description": "submitted by    /u/zer0logiQ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdm6it/i_have_built_a_few_desktops_in_the_past_and_have/",
          "publishedOn": "2022-12-05T22:28:14.000Z",
          "wordCount": 13659,
          "title": "I have built a few desktops in the past and have found a site like PCPartPicker very helpful for double checking compatibility, etc. Is there a similar site for building servers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdllqg/suspiciously_cheap_servers/",
          "author": null,
          "description": "submitted by    /u/shalamander6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdllqg/suspiciously_cheap_servers/",
          "publishedOn": "2022-12-05T22:08:58.000Z",
          "wordCount": 14151,
          "title": "Suspiciously cheap servers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdlgh3/labeled_rolling_electronics_cabinet_on_my_fb_mp/",
          "author": null,
          "description": "submitted by    /u/xRoguestatus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdlgh3/labeled_rolling_electronics_cabinet_on_my_fb_mp/",
          "publishedOn": "2022-12-05T22:04:07.000Z",
          "wordCount": 14631,
          "title": "Labeled \"Rolling Electronics Cabinet\" on my FB MP for $40. This looks like a server rack. Is it? And can anyone identify this model by looks? Already msg'd em, no response yet.",
          "imageUrl": "https://preview.redd.it/2f6skryqj54a1.jpg?auto=webp&s=bf63c26781e6057861f6e5951db41db291acab95"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdknpv/help_setting_up_lag_between_mikrotik_switches/",
          "author": null,
          "description": "So I have a CRS326-24S+2Q+ and a CSS326-24G-2S+. I am running swOS on both as I don't really need any advanced features (and the CSS won't run routerOS). Anytime I try to setup a LAG between anything the connections start flapping. If I run a single connection everything runs great. \n How I'm setting these up (maybe I'm doing something wrong). On the downstream device (in this case the CSS) I configure I make sure both sfp ports are active, go to the LAG tab and mark both as active and hit apply. Then I do the same on the upstream switch. Connection starts flapping. Reboot both devices. Connection still flapping. Close one of the ports in the LAG and connection is stable. \n ​\n What am I doing wrong? I also have tried setting up a LAG between my pfsense router and the CRS326 with the same results, connection starts flapping. Same results going to my dell server.\n    submitted by    /u/TechDiverRich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdknpv/help_setting_up_lag_between_mikrotik_switches/",
          "publishedOn": "2022-12-05T21:37:58.000Z",
          "wordCount": 14003,
          "title": "Help setting up LAG between mikrotik switches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdkesx/pdf_doc_library/",
          "author": null,
          "description": "I am building a repository of reference materials. 95% of them are in PDF form, but I can covert the rest. I would like the capability to have a \"Shelf Style\" listing of the docs with a front page preview. \n Any suggestions?\n    submitted by    /u/MrHotwire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdkesx/pdf_doc_library/",
          "publishedOn": "2022-12-05T21:29:57.000Z",
          "wordCount": 14317,
          "title": "PDF / DOC Library?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zditqb/dell_omsa_on_proxmox_73/",
          "author": null,
          "description": "Has anyone setup Dell OMSA on Proxmox 7.3 (Debian 11)? I have a Dell T440 with iDrac 9 - Basic Management license. I found this link, but am unsure how well it relates with current versions. I've also hunted Dell's documentation but the farthest I've gotten is their compatibility matrix that goes up to Debian 10.\n    submitted by    /u/tiberiusgv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zditqb/dell_omsa_on_proxmox_73/",
          "publishedOn": "2022-12-05T20:37:10.000Z",
          "wordCount": 13653,
          "title": "Dell OMSA on Proxmox 7.3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdh12a/home_networking_upgrade_10gb_fiber_switch_16_port/",
          "author": null,
          "description": "This weekend I redid the homes network panel. I needed to change so much I just removed all the existing gear and started from scratch. Here is the planned network diagram for this panel that I tried to follow pretty closely.\n the planned network panel diagram\n This is the household demarc from the garage datacenter. \n The end result\n It bridges 2 additional networking centers, an inside the house media closet with a 24 port switch, some 10G MM fiber drops, and one 40Gb connected VM server.\n Adding in 10Gbit switching gear to this panel allows me to span the garage racks and the inside network/media closet in a more planned manner than I had prior. It was OM-1 cable vomit inside this cabinet prior.\n The whatever phase of this network panel\n I also added in the 16 port 1 Gbit TP-link switch…",
          "link": "https://www.reddit.com/r/homelab/comments/zdh12a/home_networking_upgrade_10gb_fiber_switch_16_port/",
          "publishedOn": "2022-12-05T19:36:12.000Z",
          "wordCount": 15811,
          "title": "Home Networking Upgrade - 10Gb Fiber switch, 16 port 1Gb + Lots of Cable Management",
          "imageUrl": "https://external-preview.redd.it/WunfyS0AYhou23enUxJ_m8SO_6Oq8FZiQ7Dd7FQ0K6M.jpg?auto=webp&s=376d8b9bef7d7c178f188e5d2cf9aa9938b71cc5"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdfv8e/add_second_nic_to_dell_micro/",
          "author": null,
          "description": "Would really like to setup a homelab using Dell Micro PCs and run Nutanix on them or even VMWare on them. However I really want to have a second NIC on them for any ISCSI traffic. Has anyone got a good solution?\n    submitted by    /u/georgesmith12021976  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdfv8e/add_second_nic_to_dell_micro/",
          "publishedOn": "2022-12-05T18:56:19.000Z",
          "wordCount": 15177,
          "title": "Add second NIC to Dell Micro",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zdfln5/help_recovering_data_off_old_servers_from_2010/",
          "author": null,
          "description": "submitted by    /u/Liarus_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zdfln5/help_recovering_data_off_old_servers_from_2010/",
          "publishedOn": "2022-12-05T18:47:02.000Z",
          "wordCount": 17283,
          "title": "Help recovering data off old servers from 2010",
          "imageUrl": "https://external-preview.redd.it/KAHhHMj9Y-IeMvGfJaKknDYTMnjqVwUz-IQG08K3YAI.jpg?auto=webp&s=34d4f89ab63178d8716d20844fdb1d1dc9e2fab1"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zddb3e/what_cable_termination_is_this/",
          "author": null,
          "description": "I bought this cable but it's bigger than the entry. I found a name in Amazon for the cable: «bipolar cable», but really I don't know what kind of cable I need. Any idea?\n    submitted by    /u/A-JJF-L  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zddb3e/what_cable_termination_is_this/",
          "publishedOn": "2022-12-05T17:29:59.000Z",
          "wordCount": 14052,
          "title": "What cable termination is this",
          "imageUrl": "https://preview.redd.it/au017bjoo54a1.jpg?auto=webp&s=941a7c11c6f3f13be19fc8542208d3f70015913d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zct0j6/jankiest_homelab_i_have_ever_made/",
          "author": null,
          "description": "submitted by    /u/EvatLore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zct0j6/jankiest_homelab_i_have_ever_made/",
          "publishedOn": "2022-12-05T01:43:44.000Z",
          "wordCount": 18676,
          "title": "Jankiest homelab I have ever made.",
          "imageUrl": "https://preview.redd.it/bbhtj5o3iz3a1.jpg?auto=webp&s=c70b19d50548426b5226ecc06af8f8252ebaef49"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcsud0/e526xx_v4_good_for_unraid_it_would_be_replacing_a/",
          "author": null,
          "description": "Primarily looking for some extra HP to run some vm's and docker services. I already have a 4th gen i7 running proxmox for vms.\n    submitted by    /u/Srslywtfnoob92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcsud0/e526xx_v4_good_for_unraid_it_would_be_replacing_a/",
          "publishedOn": "2022-12-05T01:36:48.000Z",
          "wordCount": 13865,
          "title": "e5-26xx v4 good for unRAID? It would be replacing a 3rd gen i5.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcsq1y/help_with_expired_certificate_on_rv320/",
          "author": null,
          "description": "As the title states, I’m using a Cisco RV320 for a side project. It is running the latest firmware. Part of its function is to act as an OpenVPN server. The issue is the default 10 year certificate in the router has expired therefore preventing a VPN connection. I have attempted to create another self signed certificate and marked it as primary to no avail. Also, the OpenVPN server is setup for password authentication only but I believe the router itself requires a certificate.\n Does anyone have any insight on how to handle this?\n    submitted by    /u/SchmosWorld  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcsq1y/help_with_expired_certificate_on_rv320/",
          "publishedOn": "2022-12-05T01:32:07.000Z",
          "wordCount": 13975,
          "title": "Help with expired certificate on RV320",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcs4an/multiple_cloud_sync_task_only_one_will_run_other/",
          "author": null,
          "description": "submitted by    /u/kylewizerd15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcs4an/multiple_cloud_sync_task_only_one_will_run_other/",
          "publishedOn": "2022-12-05T01:08:09.000Z",
          "wordCount": 14115,
          "title": "Multiple Cloud Sync Task only one will run other says \"Locking local path\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcrtln/stranded_wire_for_home_installation_through_pipes/",
          "author": null,
          "description": "hi people! I'm preparing to move to a new house and i want to run cables from all the rooms from 3 floors. i calculated that up and down i would need 15m cables max from certain rooms. House (located in Europe) has pipes everywhere where i can run easily the cables. Do i really need to put solid cable as it doesn't really pass through walls ? The ideal would be full copper cables/cat6a/23AWG/solid/CMP and Poe++ needed for my various Unifi devices but a proper one from a reputable business vendor with all tests done, etc has around 50 eu. Is it worth it or i could go for a stranded/pure copper/26AWG/poe++/CM from the same vendor with around 15eu per cable ? i know it would cost me probably cheaper to buy a roll and do it myself but i don't really have the time to punch down every single cable and test it separately and i would prefer a ready made solution.\n    submitted by    /u/sessho86  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcrtln/stranded_wire_for_home_installation_through_pipes/",
          "publishedOn": "2022-12-05T00:56:48.000Z",
          "wordCount": 15246,
          "title": "stranded wire for home installation through pipes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcro0m/new_to_homelabsservers_budget_build_questions/",
          "author": null,
          "description": "Questions about storage upgrades\n New to proxmox and servers as a whole. \n I have an old optiplex with an i7-2600s, 32 gigs 1333 ddr3, and a 500gb pny ssd\n I understand I can't store VMs on the boot media and proxmox doesn't like used drives as I have 2 hdds that I had lying around I was going to use to just mess around with, but won't pop up in the interface. \n I was planning to replace the CD drive on the computer with a couple of 2.5\" drive hotswap bay. I should have enough PCI lanes to put 2 PCI controllers for 10 sata cables (1x and 4x) and buy a couple dozen cheap pny 500gb SSDs and a couple of HDDs as backup drives. \n I don't have any important data. I'm just playing around with it now and going for a budget build that pushes the limits of my old hardware. I plan to do these upgrades in waves, buy 1 PCI card, 1 hotswap bay, and 6 SSDs. Then later do it again.\n Questions:\n Is there anything I need to consider? Does proxmox work with generic Newegg PCI sata cards? Do I need dedicated raid controllers? I only have a 500w psu, does it need more juice for mass SSD additions?\n    submitted by    /u/TechManSparrowhawk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcro0m/new_to_homelabsservers_budget_build_questions/",
          "publishedOn": "2022-12-05T00:50:38.000Z",
          "wordCount": 15019,
          "title": "New to Homelabs/Servers Budget build questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcr0au/discord_minecraft_server/",
          "author": null,
          "description": "I feel like I've seen something similar here before, I have set up a Minecraft Server but my public IP is Dynamic. Is there a way to set something up that will poll my Public IP and then send that as a Discord message? Ideally to a Discord that I will make just for this server. The server is on a Linux Ubuntu machine if that matters. I tried to Google this but I'm not seeing anything quite like what I want.\n    submitted by    /u/Diamond_Doge85  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcr0au/discord_minecraft_server/",
          "publishedOn": "2022-12-05T00:24:43.000Z",
          "wordCount": 15912,
          "title": "Discord Minecraft Server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcqn6x/home_lab_for_cicd_nas_recommendations/",
          "author": null,
          "description": "Saw a few people post on the topics of CICD, and wanted to ask if anyone has recommendations for the build (this is my first time building server, I have built a PC for gaming). My main problem is, not sure whether I need higher performance cores for build/compilation (both typescript transpilation, node library build/install, and react native compilation out to android) or more cores with lower clocks to scale test parallelization. Is there a way to have cake and eat it too? Has anyone built/specced anything similar? \n Goals\n  \nSupport self hosted github actions runners with autoscaling, to support nodejs, react, and react native builds + testing. The testing is done with jest, which really likes cores. More cores = more tests that run in parallel.\n \nA centralized way to manage files and folders as a place to back up across various laptop and media devices. Also support future home projects around video storage. I like the idea of a NAS with the additional functionality of general server/compute.\n \nSupport docker containers, devops tooling, and environment to learn all the fun networking items for self hosting webapps.\n \n https://docs.github.com/en/actions/hosting-your-own-runners/about-self-hosted-runners\n    submitted by    /u/cpfowlke  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcqn6x/home_lab_for_cicd_nas_recommendations/",
          "publishedOn": "2022-12-05T00:10:28.000Z",
          "wordCount": 15981,
          "title": "Home Lab for CICD + NAS Recommendations?",
          "imageUrl": "https://external-preview.redd.it/YMPZTYosGtHGXv1uS9w78kPJEjf83SgwfzqnRn2z1ug.jpg?auto=webp&s=42118dbbd4702474126fe588763f8adf0b8be142"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcq4l8/sas_hdds_vs_sata_ssds/",
          "author": null,
          "description": "Okay so I am wondering should I put 4* sas HDDs in my server and/or in NAS, they are 2.5\" 10k sas drives OR should I just buy cheaper new 2.5\" SATA SSDs and put them in my server since server is supporting SATA ofc.\n I currently have sas drives but was thinking maybe I should switch to cheaper SSDs and they are brand new.\n Anyone done that knows what should I do? I know SAS has better performance while being accessed by many users but can SATA SSD perform just like that?\n    submitted by    /u/PestiIy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcq4l8/sas_hdds_vs_sata_ssds/",
          "publishedOn": "2022-12-04T23:50:59.000Z",
          "wordCount": 14935,
          "title": "SAS HDDs vs SATA SSDs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcpxpc/deciding_between_apc_and_eaton/",
          "author": null,
          "description": "I need to get a UPS, but I'm having trouble deciding between Eaton and APC. I've heard good things about APC, but I've also heard that their newer models aren't really all that great. I've heard good things about Eaton, and so far I don't see many people complaining about them. To my knowledge their UPS's are also more common than APC's in enterprises and shit.\n Can y'all help me decide? I don't need something that big since I'll mainly be using it to provide a graceful shutdown for my NAS and keep it running if the power flickers. Both of the UPS's that I'm looking at are in my price range, and my main concern is buying one that has less of a chance of catching on fire.\n    submitted by    /u/Windows_XP2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcpxpc/deciding_between_apc_and_eaton/",
          "publishedOn": "2022-12-04T23:43:33.000Z",
          "wordCount": 15264,
          "title": "Deciding between APC and Eaton",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcphuo/overkill_unraid/",
          "author": null,
          "description": "Dell R820 4x E5-4610 6 cores 12 threads 128gb ram and 9Tb of storage, not much storage but going to upgrade soon ...\n    submitted by    /u/jimbojim28  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcphuo/overkill_unraid/",
          "publishedOn": "2022-12-04T23:26:59.000Z",
          "wordCount": 13911,
          "title": "OverKill Unraid ????",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcorr0/how_many_port_forwarding_rules_can_we_create_in/",
          "author": null,
          "description": "I recently started a rotating 4g mobile proxy business and currently I have a consumer grade router from Tp-Link (TL-WR845N). As you can expect, I need to open a lot of ports so the client can access the proxy modem but I recently discovered a limitation of my router. Port forwarding rules are capped at max 36 rules. This is a big issue that I am trying to solve in priority as it's hindering my progress for deploying more modems and opening more ports.\n I am looking into 2 options here, either I can make an pfsence router myself or get something off the shelf like dream machine pro. I'm from India and getting server hardware here is a big pain in the butt. So I was thinking to go with dream machine pro.\n So does anyone know about how many port forwarding rules can we create in dream machine pro?\n    submitted by    /u/reddit_avinash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcorr0/how_many_port_forwarding_rules_can_we_create_in/",
          "publishedOn": "2022-12-04T22:58:59.000Z",
          "wordCount": 15485,
          "title": "How many port forwarding rules can we create in Dream Machine Pro?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcooi6/sbc_pi_replacement_headless_pihole/",
          "author": null,
          "description": "Hello, thanks for reading -\n I'm in the UK and have been looking at reducing my power usage - I ditched my r710 last year and went back to 2 Gen8 microservers and things have been fine so far.\n I really wanted a Pi just for Pihole/DHCP/VPN etc but the prices and availability just made that a non-starter so I set about a little project.\n Dug out an RK3188 Android box out of a drawer (Chipset：RK3318 Quad-Core 64bit Cortex-A53) (4cpu @ 1.296 GHz) - it no longer functions as an android box as Armbian is installed directly to the eMMC. \n Both Wi-Fi and LAN working (no Bluetooth or audio though but not needed for this use case as a network utility). GPU solid (GUI/Desktop performance more than enough, actually quite good) \n Currently running:\n SSH Server Pi-hole Pi-VPN Samba Sonarr Radarr Docker, and Transmission. \n Once configured for my LAN (used desktop GUI connected to a monitor with keyboard & mouse and a bit of SSH), it only needs the psu connected before logging in via SSH - GUI/Display output still working incase its needed though. \n The power draw/cpu usage while idling are very low and even with all of those services running in the background - ram usage 815mb out of 3973Mb and System load of 5%. The best part for me is the power draw, which sits idle at about 4-5W. \n I have photos of resource usage - neofetch, htop and the info given when logging in to the terminal - I'll make an imgur album if there's enough interest :) \n It's taken me the best part of this weekend to do this - if there is enough interest let me know and I'll get some up on r/homelabsales if that's something that's allowed. \n Thanks for reading 🙏\n    submitted by    /u/CrystalFeeler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcooi6/sbc_pi_replacement_headless_pihole/",
          "publishedOn": "2022-12-04T22:55:33.000Z",
          "wordCount": 14363,
          "title": "SBC Pi replacement / headless pi-hole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcoiyb/new_nas_miniserver/",
          "author": null,
          "description": "Hi everyone,\n UK user.... I currently run an entry level Netgear ReadyNAS which is approaching near 10yrs old and is mainly used for \"cold storage\" and an i3 NUC as my mini-server / media centre, again that's nearing 10 yrs. I've had both from new and they have been brilliant but the media centre is starting to play up and I'm thinking it about time I start thinking about changing both into one combined machine with new drives. \n My needs are not that heavy but ideally I would like to go down the TrueNAS Scale route with a 4U, 4-8HDD hot swap, short server style setup but I'm really struggling to put a decent combination of HW together to match the value for money of the QNAP TS-473A which would also meet my needs. \n Further there is space, noise and consumption challenges with the server compares to the QNAP which further add to the cost to compensate. I don't know if the server style approach is more romantic than reality and if I should just bite the bullet with the QNAP and call it a day (despite my reservations on their poor poor security record). \n My best HW combination so far is as below to keep the NAS under £900 (excl HDDs/SSDs):\n Motherboard: Asrock X570 Pro 4 - £170\n CPU - Ryzen 5 Pro 5650G - £150\n Memory - 32GB ECC - £150\n Server Case - 4U - £190\n PSU - Crosair - 550W - £100\n Various Noctua Fans + Ancilliaries - £120 \n ​\n In comparison the QNAP comes in at £750 + £100 for a RAM upgrade to 32GB ECC. Granted the server is a little more powerful but has other complexities...\n What HW would you go with to justify the server over the QNAP?\n Thanks in advance.\n    submitted by    /u/rediduser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcoiyb/new_nas_miniserver/",
          "publishedOn": "2022-12-04T22:49:32.000Z",
          "wordCount": 14805,
          "title": "New NAS / Mini-Server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcm1l3/wd_16tb_drives_causing_havoc_in_my_r720xds/",
          "author": null,
          "description": "I picked up some shuckable 16TB WD drives (WD160EDGZ) and all seemed well at first. Cleared the drives and rook-ceph started to get to work adding it to the cluster.\n I noticed backfilling to redistribute data to the new drive was going very slow, and after a long search as to why, I noticed the drive was not acting \"normal\" compared to the other 11 drives in this machine. It had partitions that shouldn't have been there, and it seemed to be somehow re-initializing all the time based on seeing the partitions get reported in dmesg frequently. I marked it out of the cluster and began troubleshooting.\n After trying other identical drives in the same machine, trying other slots, and trying these drives in one of the other R720XDs I have with identical config (h710 in IT mode), it seems it's so…",
          "link": "https://www.reddit.com/r/homelab/comments/zcm1l3/wd_16tb_drives_causing_havoc_in_my_r720xds/",
          "publishedOn": "2022-12-04T21:19:17.000Z",
          "wordCount": 15331,
          "title": "WD 16TB drives causing havoc in my R720XDs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcksph/apparently_2_wrongs_do_make_a_right/",
          "author": null,
          "description": "I got an X10DRI-T motherboard of fleabay and IPMI is reporting a high dimm voltage on channels C&D, so I moved all the RAM to other channels.\n I was having stability issues, and 1 ram stick was giving me \"memory signal is too marginal\" errors occasionally, and dropping out.\n So I put the stick with the marginal memory signal into the slot with the too high of voltage and the thing is stable now and that memory is working fine!\n    submitted by    /u/AlphaSparqy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcksph/apparently_2_wrongs_do_make_a_right/",
          "publishedOn": "2022-12-04T20:34:39.000Z",
          "wordCount": 14903,
          "title": "Apparently 2 wrongs do make a right.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcj8ty/gpu_recommendation_for_r730r730xd/",
          "author": null,
          "description": "I’m looking for a GPU for my R730XD. The main purpose is gaming on a windows VM; mostly to stream VR games to my VR headset. I’ll also use it for some movie streaming and encoding.\n I’d prefer Nvidia for the software compatibility but it doesn't have to be. I need it to at least match the gaming performance of an RTX 2070. It also has to fit in a r730xd so it can’t be super massive. I can use server GPUs or consumer GPUs. If it’s a consumer GPU I believe it has to be a blower model (that pushes air out the back).\n I’m having trouble deciphering the nvidia server GPU naming scheme, and there are minimal user benchmarks submitted for server GPUs so I really have no idea what I’m looking at. From other posts I've read it sounds like server GPUs aren't great for gaming. But used parts can be at such large discounts that it may be worth it, I don't know.\n If anyone can recommend me a good GPU that fits in an R730/R730XD I would appreciate it.\n    submitted by    /u/AwefulUsername  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcj8ty/gpu_recommendation_for_r730r730xd/",
          "publishedOn": "2022-12-04T19:37:58.000Z",
          "wordCount": 14990,
          "title": "GPU Recommendation for R730/R730XD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zchvi7/is_an_hp_elitedesk_800_g4_with_an_i58500_not_t/",
          "author": null,
          "description": "Hi ! This computer is available for 250€ and I'd like to know if you'd consider it a good investment for a first proxmox server ? \n I currently own a nas that runs multiple dockers but I'd like to go futher. My raspberry 3b isn't quite adapted lol. \n I'd like use this machine for pfsense, and some other vms / docker images that I still haven't decided about. \n Thanks for your time !\n    submitted by    /u/ShiningPak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zchvi7/is_an_hp_elitedesk_800_g4_with_an_i58500_not_t/",
          "publishedOn": "2022-12-04T18:47:38.000Z",
          "wordCount": 18433,
          "title": "Is an HP EliteDesk 800 G4 with an i5-8500 (not T) and 16Go RAM good for a first proxmox server ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zceggd/need_a_hack_for_hp_nc522sfp_dual_port_10gb_sp/",
          "author": null,
          "description": "I’m trying to change my NIC to a 10GB link but I ignorantly ordered this card on Ebay without checking its compatibility with Exsi 7.0. I have spent a lot of time researching how I can make it work but most of the drivers I got online didn't work. I know this NIC works fine with EXSI 6.7 but I don't want to downgrade my host because of this card. Did anyone get it to work with 7.0?\n    submitted by    /u/Accelonace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zceggd/need_a_hack_for_hp_nc522sfp_dual_port_10gb_sp/",
          "publishedOn": "2022-12-04T16:41:51.000Z",
          "wordCount": 15493,
          "title": "Need a hack for HP NC522SFP Dual Port 10Gb SP+ Ethernet NIC PClex8 Server Adapteron Exsi 7.0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zccxuv/my_overkill_unraid_build_featuring_48tb_intel/",
          "author": null,
          "description": "submitted by    /u/Mellofella  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zccxuv/my_overkill_unraid_build_featuring_48tb_intel/",
          "publishedOn": "2022-12-04T15:43:27.000Z",
          "wordCount": 14915,
          "title": "My overkill Unraid build - featuring 48tb, intel 2176G, ecc stix and gtx1660ti",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcbk2l/accessing_a_selfhosted_website_through_public/",
          "author": null,
          "description": "Hi all,\n Might be a silly question, but I'm not sure how this actually works.\n I currently self-host a Jellyfin that is also publicly exposed (with dense security) for the few cases where I need to use it from outside.\n It is being a domain name and is sent to my home through a VPS (no open port) (so the domain name points to the VPS IP).\n If I access this from my internal network, will the routing be smart enough to not go through the internet and directly re-route to my internal website, or will it still go through the VPS therefore being subject to my internet speeds ups and downs ?\n Thanks\n    submitted by    /u/Bright_Mobile_7400  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcbk2l/accessing_a_selfhosted_website_through_public/",
          "publishedOn": "2022-12-04T14:48:43.000Z",
          "wordCount": 16430,
          "title": "Accessing a self-hosted website through public domain",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zcbh5v/been_reading_about_you_guys_home_lab_here_is_mine/",
          "author": null,
          "description": "Spec in comments I guess..\n    submitted by    /u/IllusionXXI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zcbh5v/been_reading_about_you_guys_home_lab_here_is_mine/",
          "publishedOn": "2022-12-04T14:45:20.000Z",
          "wordCount": 15471,
          "title": "Been reading about you guys' home lab. Here is mine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zc2hdv/last_lab_update_of_2022/",
          "author": null,
          "description": "submitted by    /u/mpjvending  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zc2hdv/last_lab_update_of_2022/",
          "publishedOn": "2022-12-04T06:23:21.000Z",
          "wordCount": 18231,
          "title": "Last lab update of 2022!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zc0nb8/7700x_w_ecc_ddr5_compatibility_update/",
          "author": null,
          "description": "submitted by    /u/nyevv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zc0nb8/7700x_w_ecc_ddr5_compatibility_update/",
          "publishedOn": "2022-12-04T04:42:23.000Z",
          "wordCount": 16805,
          "title": "7700X w/ ECC DDR5 - Compatibility Update",
          "imageUrl": "https://preview.redd.it/0bhipk7y8t3a1.jpg?auto=webp&s=4148d6a727ab5456553f01087269d72e42543386"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbwlk1/server_missing_its_tools/",
          "author": null,
          "description": "submitted by    /u/Lickmysweaty1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbwlk1/server_missing_its_tools/",
          "publishedOn": "2022-12-04T01:21:34.000Z",
          "wordCount": 14507,
          "title": "Server missing its tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbvpkj/announcing_duplicati_dashboard/",
          "author": null,
          "description": "​\n Task view\n The final release has been launched ! After two moths of development, the sotware is finished (for now).\n This version includes this features:\n  \nAdd / delete hosts\n Add / delete tasks\n Modify database connection\n Some graphs for statistics\n A history for every task\n etc.\n  \nYou can always open a new issue to ask for another one ! You can take a look in this repo and try it with Docker.\n    submitted by    /u/MarcOrfila  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbvpkj/announcing_duplicati_dashboard/",
          "publishedOn": "2022-12-04T00:39:23.000Z",
          "wordCount": 14229,
          "title": "Announcing Duplicati Dashboard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbvnt2/few_questions_before_purchase_of_my_new_server/",
          "author": null,
          "description": "Hi, I will be getting a new server (pre-built) in a few weeks and I would like to know a few things before I make that purchase official.\n Server specs:\n  \nForm factor: Tower\n RAM: 32 GB (4x 8GB) DDR4\n PSU: 1x 900W Hot plug, 80 plus gold\n CPU: 2x E5-2650v3 or 2x E5-2690v3\n OS: Ubuntu Server 22.04.1 LTS\n  \nUsage:\n  \nRunning 24/7\n Personal cloud storage for films, videos, photos and other media.\n Running small website.\n Maybe some Minecraft modded server for playing with friends.\n Virtualization for testing but also daily using.\n  \nCost: 601.99$ (2x E5-2650v3) or 759.02$ (2x E5-2690v3)\n - I would like to know how many cores do I need for server? I tried searching the Internet for some charts but didn't find anything useful.\n - Is Intel Xeon E5-2690 v3 better or worse than Intel Xeon E5-2650 v3?\n - Is this configuration good or should I give up on it and find something better?\n    submitted by    /u/Takanashi_Yuri  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbvnt2/few_questions_before_purchase_of_my_new_server/",
          "publishedOn": "2022-12-04T00:37:05.000Z",
          "wordCount": 14901,
          "title": "Few questions before purchase of my new server.",
          "imageUrl": "https://external-preview.redd.it/Hlbf52-zMgk3lZiQPiNlVwXxuQqfSuHNMRFDsvyExVQ.jpg?auto=webp&s=0402e358a1b5b71d7e7e3840908c20761a156712"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbvmmr/best_way_to_secure_dockers_on_a_vps/",
          "author": null,
          "description": "So this is kind of a generic question, but I'm seeking advice for best way to secure a VPS (recently picked up a pretty beefy VPS for cheap on cyber monday). \n So the issue I am running into is that when you install docker and deploy an image with the -p option, it's creating a related rule in nftables (running Debian 11). My original plan was to throw down ufw, forward only 80/443 and reverse proxy things I wanted publicly exposed (very little), and everything else would only accessible via wireguard. \n I setup wireguard, got that working and everything then deployed a syncthing docker (to backup certain files from an on-prem box). I didn't create a rule in ufw for the UI, yet I was able to browse to it and that's when I starting researching and learned that -p option was creating those nft rules. This is not what I want; I want the syncthing UI to only be available to my clients connected to this VPS with wireguard, but I'm not sure how to achieve this. \n Any suggestions? How are you running dockers on a VPS without exposing it all on the internet?\n    submitted by    /u/devianteng  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbvmmr/best_way_to_secure_dockers_on_a_vps/",
          "publishedOn": "2022-12-04T00:35:35.000Z",
          "wordCount": 17291,
          "title": "Best way to secure dockers on a VPS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbuuth/what_kind_of_rack_handles_are_these/",
          "author": null,
          "description": "submitted by    /u/BL1NDX3N0N  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbuuth/what_kind_of_rack_handles_are_these/",
          "publishedOn": "2022-12-04T00:00:36.000Z",
          "wordCount": 14551,
          "title": "What kind of rack handles are these?",
          "imageUrl": "https://preview.redd.it/0y058ofxur3a1.png?auto=webp&s=d19251a3ed42bd042544bd0bbd8cf67ce3e9bd5d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbt0hs/is_this_a_good_idea_used_epycmoboram_from_china/",
          "author": null,
          "description": "Is 1gen epyc any good? \n And would you be confident ordering from this ebay seller? They have lots of modern epyc/xeon combos available.\n    submitted by    /u/OverclockingUnicorn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbt0hs/is_this_a_good_idea_used_epycmoboram_from_china/",
          "publishedOn": "2022-12-03T22:41:07.000Z",
          "wordCount": 15292,
          "title": "Is this a good idea? Used epyc+mobo+ram from China",
          "imageUrl": "https://external-preview.redd.it/ZGgjqTlpjgag5HqTXEfr-pB9fgJBFOjzHh-GuCFzOS4.jpg?auto=webp&s=0d661b8d4d747cb3bbc9684870560a07686de8cd"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbs3nr/aruba_s3500_quieter_psu_options/",
          "author": null,
          "description": "​\n So I got my new to me S3500 switches. They came with a single 1050w power supply. \n That thing is LOUD! I mean, I run older R710s and that noise is ok. Some of you prefer dead silent and that's ok, but I personally don't mind a bit of background white noise. \n But these 1050s are on another level! My first thought was to fan mod it, but with the amount of heat coming out of that thing even with the switch idle makes me think it would overheat rather rapidly. The main fans in the switch slow down considerably after boot and they don't seem too bad. Of course, I can't really tell for sure with the PSU fan blasting away. \n So looking around it looks like Aruba specified both 600w and 1050w power supplies for this switch. I have also seen mention of 350w power supplies in a couple of posts. However they don't appear in the datasheet for the S3500 so my assumption is they don't have enough power output.\n So for those of you that have run S3500s, is the 600w PSU a lot quieter than the 1050?\n    submitted by    /u/Radius118  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbs3nr/aruba_s3500_quieter_psu_options/",
          "publishedOn": "2022-12-03T22:03:29.000Z",
          "wordCount": 14870,
          "title": "Aruba S3500 quieter PSU options?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbrfns/drive_fails_on_truenas_but_smart_data_is_good/",
          "author": null,
          "description": "i have a drive thats been giving me constant failuars as of late. \n the Truenas message is:\n Pool Main state is DEGRADED: One or more devices has been removed by the administrator. Sufficient replicas exist for the pool to continue functioning in a degraded state. The following devices are not healthy: Disk HGST_HUS728T8TALE6L4 VRGBGUHK is REMOVED \n output of zpool status Main\n $zpool status Main pool: Main state: DEGRADED status: One or more devices has been removed by the administrator. Sufficient replicas exist for the pool to continue functioning in a degraded state. action: Online the device using zpool online' or replace the device with 'zpool replace'. scan: scrub in progress since Sat Dec 3 11:40:07 2022 11.5T scanned at 719M/s, 8.64T issued at 543M/s, 11.5T total 0B repaired, 75.4…",
          "link": "https://www.reddit.com/r/homelab/comments/zbrfns/drive_fails_on_truenas_but_smart_data_is_good/",
          "publishedOn": "2022-12-03T21:36:19.000Z",
          "wordCount": 16776,
          "title": "drive fails on truenas but smart data is good.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbq592/noctua_nhl9aam4_1u_server/",
          "author": null,
          "description": "so i recently bought a server case ( inter-tech ipc 1u-k-125l) its a 1u server for mini itx motherboards and its about 4.5 cm tall so i read an article that the noctua cpu cooler is a great price, quet, keeps the cpu fairly cool (im planning to use a ryzen 7 3700x ) but my main issue is the height in the description it says its about 3.7 cm tall so it should fit but i dont know how high it stick out with the motherboard attatched if you guys could help me out that would be awesome , if u got any other cpu cooler reccomendations i would love to hear it :)\n    submitted by    /u/FEAR-op  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbq592/noctua_nhl9aam4_1u_server/",
          "publishedOn": "2022-12-03T20:43:41.000Z",
          "wordCount": 15859,
          "title": "Noctua NH-L9a-AM4 1u server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbq0wg/watchguard_xtm8/",
          "author": null,
          "description": "I was given a Watchguard XTM 8 (no CF card) some time ago, and it’s been collecting dust. Prior to that, I made a pfSense box (working LCD with lcdproc, etc.) on a XTM 5 which I then sold. I was able to flash a custom bios to my XTM 5 which allowed the pfSense install. My hope was to make another pfSense box out of this XTM 8, but I seem to remember some sort of issue with the serial port in doing this. \n My question is this: Is there any practical use for this in my homelab? Is it possible to flash a custom BIOS that would allow me to repurpose this as a Linux box or is it a boat anchor?\n    submitted by    /u/Sparkynerd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbq0wg/watchguard_xtm8/",
          "publishedOn": "2022-12-03T20:38:37.000Z",
          "wordCount": 14530,
          "title": "Watchguard XTM8",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbpjyx/good_wired_routers/",
          "author": null,
          "description": "I currently run an older asus wireless router but it seems to bog down when downloading a lot even on wired connections. There aren't many selections on wired only that I can find. Figured I'd add access point/ points later.\n What I want is low powered, easily configured and gigabit ports. \n I currently don't have gigabit internet but I'm on a 300mb plan. I really don't want to spend money on electricicity running a dedicated computer. \n All I really see are tp-link, ubiquiti and mikrotik? Which I've never heard of.\n Is the tplink er605 or 7206 decent and easy to use?\n Or like an ubiquiti edgerouter X ? \n Nothing crazy expensive as we mainly use internet for heavy streaming and daughter does school work and xbox gaming. And I find stuff to fill up plex lol.\n    submitted by    /u/Expensive-Vanilla-16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbpjyx/good_wired_routers/",
          "publishedOn": "2022-12-03T20:19:08.000Z",
          "wordCount": 15797,
          "title": "Good Wired routers ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbokiy/starting_to_sort_networks/",
          "author": null,
          "description": "Wanted to run an IDS, so added the Netgate box (and support pfSense development). The Topton box (on bottom) is meant to run Proxmox and pfSense and be directly connected to the cable modem, but will live inside until setup and tested. One switch outside, and one switch inside the pfSense firewall. Also outside the picture, a Netgear GSS116E, two workstations, and a passel of the usual devices - meant to be well-isolated.\n Need to spend more time with pfSense and Proxmox.\n Have assorted DIN-mount gadgets and Meanwell power supplies. Also a couple of 3D printers. Might lose the wall-warts, and fabricate DIN mounts for the smaller network gadgets.\n Need to sort the mess of wires, and find a (much!) better mount.\n Again ... just a start. :)\n Network front-end (minus cable modem)\n    submitted by    /u/PrestonBannister  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbokiy/starting_to_sort_networks/",
          "publishedOn": "2022-12-03T19:38:37.000Z",
          "wordCount": 14746,
          "title": "Starting to sort networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbogmg/in_your_homelab_dns_over_tls/",
          "author": null,
          "description": "Figuring most here run pfsense, Just curious do all of you guys run a form of secure DNS?\n    submitted by    /u/jubjubrsx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbogmg/in_your_homelab_dns_over_tls/",
          "publishedOn": "2022-12-03T19:34:05.000Z",
          "wordCount": 15262,
          "title": "In your homelab DNS over TLS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbntbb/should_i_need_both_intake_and_exhaust_fans_for/",
          "author": null,
          "description": "submitted by    /u/Kaluvoya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbntbb/should_i_need_both_intake_and_exhaust_fans_for/",
          "publishedOn": "2022-12-03T19:06:39.000Z",
          "wordCount": 16108,
          "title": "Should I need both Intake and Exhaust fans for 44U NetShelter 4 Post Open Frame Rack?",
          "imageUrl": "https://preview.redd.it/q7ucqgyieq3a1.jpg?auto=webp&s=fd96dc1ca4bd18d176995de69cea4c33c32b8eb9"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbmzqr/linux_installation_on_older_machines_anything/",
          "author": null,
          "description": "EDIT: looks like /u/jaskij got it in one: Optiplex at least was in Legacy boot mode. switching to EFI seems to have worked. Leaving this as evidence of my rusty brain.\n Apologies for what is more of a generic Linux question than a real lab question.\n I've been out of the 'active' homelab game for a couple years after a move which caused me to have to de-commission a Proxmox cluster setup due to lack of space.\n I'm now trying to re-use some of that older hardware for Automatic Ripping Machine (ARM) since we have crates full of CDs and it's either rip them or toss them. ARM has convenient install scripts for Ubuntu so that's where I started. The Problem: installation of a variety of OS distros craps out on all 3 of the machines that I'm trying to re-use. This is NOT a universal failure - ins…",
          "link": "https://www.reddit.com/r/homelab/comments/zbmzqr/linux_installation_on_older_machines_anything/",
          "publishedOn": "2022-12-03T18:31:47.000Z",
          "wordCount": 16188,
          "title": "Linux installation on 'older' machines - anything change recently?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbkq16/getting_ahead_of_the_expansion_addiction/",
          "author": null,
          "description": "Hello, So recently I have up-scaled my homelab from 4 docker containers/VMs to 15, and the expansion is only going to grow. I am having a lot of fun but I am also losing track of configurations and I would love to have some sort of centralized place to edit YAML files with a change history of sorts, to revert changes if I made an error. (currently I copy/paste into a new file, then use that if I need to revert back...)\n The YAML files are mainly on a private share for containers, that I access though my workstation, however I do have other services running outside of docker.\n I have netbox to keep track of IP's/Ports and so on, I have my documentation in order. However I do not have a good way to edit YAML files from a centralized area, and track changes or have a changelog. \n I am very new to code, and code tracking, is there any container/service that I could use for this? Maybe Visual Studio? - I do not know if this will have what I need. \n Thanks!\n    submitted by    /u/Aidz121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbkq16/getting_ahead_of_the_expansion_addiction/",
          "publishedOn": "2022-12-03T16:55:23.000Z",
          "wordCount": 17765,
          "title": "Getting ahead of the expansion addiction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbkn8e/first_homelab/",
          "author": null,
          "description": "Today I fill any got fiber installed at home. It was the last step to finally start my home lab.\n At the moment it's not much but it will get better.\n I got 10G fiber from my ISP with one full IPv4 and a /64 IPv6.\n My goal is to bring back at home my small server that is on a VM at OVH.\n I got 2 sff pc that I'll use for training and hosting.\n My switch is an old 15 year old 16 port Netgear. But I got an Aruba 1930 24 port on its way, so I can use the SFP+ port on my ISP router.\n Then next step will be to replace my hacked up firewall by a 10G capable one.\n    submitted by    /u/DerpF0x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbkn8e/first_homelab/",
          "publishedOn": "2022-12-03T16:51:51.000Z",
          "wordCount": 15466,
          "title": "First homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbkhga/sometimes_less_is_more/",
          "author": null,
          "description": "This is my HP xw6600 Workstation, it's pretty much run 24 hours a day for the last 6 and a half years and survived 3 house moves.\n It has two xeon E5450 CPUs, 6gb DDR2, a 1tb HDD and two 6tb HDDs.\n It runs portainer, Plex, pihole, motioneye (CCTV) and a small Minecraft server.\n We often have multiple TVs watching Plex, and we have 3 of us on Minecraft easily.\n I have a replacement ready just in case, but for now, this little machine has done me proud :)\n HP XW6600 Workstation\n    submitted by    /u/Crosdale  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbkhga/sometimes_less_is_more/",
          "publishedOn": "2022-12-03T16:44:24.000Z",
          "wordCount": 15335,
          "title": "Sometimes less is more?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbkgyg/supermicro_1027gr_fan_controls/",
          "author": null,
          "description": "There were a set of fairly cheap 1U GPU servers (the 1027GR line) on eBay a little while ago, one of which I picked up. I've been tearing my hair out for a few weeks trying to figure out exactly how to control the fans on these things; there's a lot of people out there with instructions on how to generically control fans on SMC servers with ipmitool and some people have details for X9 boards. In particular this STH article/discussion was very helpful indeed.\n ​\n I do think it's worth reading that comment and the original reference guide so I won't go into detail here, but what I did want to add was that the 1027GR seems to have unusual ID's for its zones. Specifically everyone usually says that the CPU zone is 0x00 and any additional cooling zones are 0x01, 0x02, etc. but on this server, (or at least mine) the zones aren't that at all. The zones for controlling the fans on my 1027GR-TR are the following:\n  \n0x10: CPU Zone\n 0x12: Left GPU Zone\n 0x13: Right GPU Zone\n  \nI know it's not the most useful post but I just wanted this to be out there for the next person searching around. Save them a bit of time and maybe keep them from tossing the server they bought because they can't get it quiet enough to use.\n    submitted by    /u/That_One_Fellow_Nils  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbkgyg/supermicro_1027gr_fan_controls/",
          "publishedOn": "2022-12-03T16:43:44.000Z",
          "wordCount": 15642,
          "title": "Supermicro 1027GR fan controls",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbjfyh/thought_i_finally_make_a_post_and_show_off_my/",
          "author": null,
          "description": "​\n https://preview.redd.it/k15co62ggp3a1.jpg?width=668&format=pjpg&auto=webp&s=46d90257792c2252306532f18eda71045007b088\n https://preview.redd.it/3tasz62ggp3a1.jpg?width=501&format=pjpg&auto=webp&s=ca0696489ea54eb652e74dd941e7383c474787db\n https://preview.redd.it/ki9ve32ggp3a1.jpg?width=668&format=pjpg&auto=webp&s=f1d50376577550406dac9e5dbb8f2813ac483e7e\n https://preview.redd.it/5dre862ggp3a1.jpg?width=1213&format=pjpg&auto=webp&s=5c4da5da48810c1d05acaafbc843e4f2eed592d8\n https://preview.redd.it/unhqfnf5lp3a1.png?width=1051&format=png&auto=webp&s=c1abefad08f9b9d3ce908cf9a6d3bcd3e8e0a212\n    submitted by    /u/TheMopMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbjfyh/thought_i_finally_make_a_post_and_show_off_my/",
          "publishedOn": "2022-12-03T15:56:36.000Z",
          "wordCount": 16149,
          "title": "Thought I finally make a post and show off my overkill-homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbh1v1/power_strip_with_socket_metrics_and_api/",
          "author": null,
          "description": "I am looking for a power strip I can interface with to monitor power consumption on a per socket basis. I looked at digital-logger, but it looks like it’s not granular to the socket. I also looked at the Ubiquiti PDU but I am aware of any API or SSH integration I can leverage with it. Any recommendations? \n I am looking for a per socket basis since I want to monitor power draw of each of my devices and create a dashboard. Ultimately my goal is to correlate power consumption to load and determine the best node to send work tasks to, with the aim to minimize power usage.\n    submitted by    /u/ninjakermit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbh1v1/power_strip_with_socket_metrics_and_api/",
          "publishedOn": "2022-12-03T14:05:16.000Z",
          "wordCount": 16396,
          "title": "Power strip with socket metrics and API integration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbh17j/device_management_software_for_family_admin_duties/",
          "author": null,
          "description": "As I'm sure many of you as well, I'm the one all my family (and extended family) members go to whenever they need help with their technology. This often includes setting up new laptops, PCs etc. as well as installing software on those devices.\n After setting up yet another laptop, I've had the idea of creating a small solution to be able to: 1. Install new devices from an image I created 2. Install software remotely 3. Remotely connecting to the devices when my \"users\" need help with anything that requires me to see their screen.\n I'm already pretty set on using AnyDesk for #3, but I haven't yet found a clean, easy (and free/inexpensive) solution for the first two points. I know of OPSI, but from everything I know it's complicated to set up and would require me to implement a VPN for all the client devices.\n Do any of you know of any software that could help me achieve my goal? Any help is greatly appreciated. Thank you!\n    submitted by    /u/InterFelix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbh17j/device_management_software_for_family_admin_duties/",
          "publishedOn": "2022-12-03T14:04:22.000Z",
          "wordCount": 15702,
          "title": "Device management software for family admin duties",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zbfssm/its_christmas_oh_oh_oh/",
          "author": null,
          "description": "Just finished to put this together and wanted to share... Never throw away hardware, you never know when it will be useful... 😅\n    submitted by    /u/Pkillerjd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zbfssm/its_christmas_oh_oh_oh/",
          "publishedOn": "2022-12-03T13:03:33.000Z",
          "wordCount": 14849,
          "title": "It's Christmas!!! Oh Oh Oh",
          "imageUrl": "https://preview.redd.it/vab09n1b3q3a1.jpg?auto=webp&s=cf29649b526e89d55f75989b569595a27a79e431"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zb3tdb/using_a_server_rack_to_capacity_test_a_large/",
          "author": null,
          "description": "submitted by    /u/digimer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zb3tdb/using_a_server_rack_to_capacity_test_a_large/",
          "publishedOn": "2022-12-03T01:16:42.000Z",
          "wordCount": 15040,
          "title": "Using a server rack to capacity test a large battery bank",
          "imageUrl": "https://external-preview.redd.it/EUC2Opp6klyqHjCfeb5zs1AvGSDmt6LbeaXeWePe070.png?auto=webp&s=77153f4dbe31963a304b3a26c674e8b4afb08bf0"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zb37ps/dell_powerconnect_2748_not_connecting_to_network/",
          "author": null,
          "description": "my powerconnect suddenly is unable to reach the network, I had checked to make sure it’s gateway address was set to the address of my router and it was but for some reason it is unable to connect to the network. Additionally when I’m connected to the switch via Ethernet through my laptop, which I have manually set it’s ipv4 address in the 192.168.1.0/24 range, it is able to see all other connections on the switch but unable to see anything connected to the network.\n At the this point, I’m not sure what happened. Any advice is helpful but from what I’ve seen, these devices tend to have this issue.\n Also I did verify the subnet mask and ensured that the static IP I set was in range.\n    submitted by    /u/DiortheGolden  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zb37ps/dell_powerconnect_2748_not_connecting_to_network/",
          "publishedOn": "2022-12-03T00:48:16.000Z",
          "wordCount": 14170,
          "title": "Dell Powerconnect 2748 not connecting to network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zb33pd/ubiquiti_unifi_setup_problems/",
          "author": null,
          "description": "Just bought a Unifi USW-24-POE and a U6 Pro. My original network was [Technicolor modem > Netgear Nighthawk router] and now I would like it to be [modem > switch > AP]. When I do this however, I can't access the switch or AP because I don't have an Ethernet port to route through the switch. It does broadcast an SSID but I have no clue what the password is. To get around this, I setup [Modem > Router > Switch > AP], setup a Unifi Console and got everything working. I then tried to remove the router with the now configured OS console, but when I do this it continues broadcasting the SSID I setup and the password is correct, but it won't let me connect back to the AP unless I have the router plugged in. It just says it's connected, obtaining IP, then disconnects like it was never even trying (Android). Any idea why I can't bypass the router once the new AP is configured?\n    submitted by    /u/Austinitered  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zb33pd/ubiquiti_unifi_setup_problems/",
          "publishedOn": "2022-12-03T00:42:59.000Z",
          "wordCount": 14354,
          "title": "Ubiquiti Unifi Setup Problems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zb1zuw/anyone_use_an_e107_usb_in_their_rack/",
          "author": null,
          "description": "Just got one but a couple of LED switch lights are burned out. It's a shame because it feels like a quality PDU. Any other good blue LED PDUs?\n    submitted by    /u/Austinitered  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zb1zuw/anyone_use_an_e107_usb_in_their_rack/",
          "publishedOn": "2022-12-02T23:51:25.000Z",
          "wordCount": 13980,
          "title": "Anyone use an E107 USB in their rack?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zb1gb0/home_server_build_recommendations/",
          "author": null,
          "description": "Hi Homelab! First time poster, long time reader!\n I am trying to plan out a build for the following function:\n  \nPlex/Jellyfin Server (2x 4K stream at the same time)\n Nextcloud\n Webserver\n Seedbox\n Try to minimize power requirements as much as possible. \n  \nExpecting to run about 50-60 docker containers for various apps and development. \n I already have the following parts:\n  \n2x 1TB SSDs M.2 NVMe for OS (RAID 1)\n 4x 10TB HDD SATA 6 for Media server (RAID 10)\n 4x 8TB HDD SATA 6 for Webserver/Nextcloud/Development/Database (RAID 5/1/10?)\n \nLarge server case with 8 drive bays\n PCPartPicker Part List\n \n  \n Type Item Price \n  \n CPU Intel Core i5-12600K 3.7 GHz 10-Core Processor $249.99 @ B&H \n  CPU Cooler Vetroo V5 52 CFM CPU Cooler $34.99 @ Amazon \n  Motherboard ASRock Z690 Pro RS ATX LGA1700 Motherboard $158.99 @ Newegg \n  Memory Corsair Vengeance LPX 64 GB (2 x 32 GB) DDR4-2400 CL16 Memory $127.99 @ Newegg \n  Power Supply be quiet! Straight Power 11 550 W 80+ Platinum Certified Fully Modular ATX Power Supply $119.90 @ B&H \n  Prices include shipping, taxes, rebates, and discounts   \n  Total $691.86  \n \n ​\n Questions/Concerns:\n  \nPlease let me know your thoughts on this build?\n Should I use RAID 5 for Webserver/Nextcloud or is it better to use RAID 1 or RAID 10\n Does it need a more powerful CPU? more RAM?\n Will I need a video card for the media server?\n Do I need a motherboard with multigig ethernet port or will it be more cost effective/better to just purchase a separate card with 10gbe or SPF+?\n I also have a 1000W power supply that I can use instead of this 550W, but Im not sure if the electricity cost will be more with the 1000W vs the 550W in the table above?\n  \nThank you in advance for any help you can provide!!\n    submitted by    /u/Quick_Parsley_6482  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zb1gb0/home_server_build_recommendations/",
          "publishedOn": "2022-12-02T23:27:03.000Z",
          "wordCount": 14416,
          "title": "Home Server Build Recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zb1eba/wireguard_for_homelab/",
          "author": null,
          "description": "I recently setup wireguard via PiVPN and a Pi4B. It works but speeds are a bit lacking. My home connection is 1000Mbps down and 100Mbps up. I'm getting speeds of about 30Mbps each way when WG is running on the Pi.\n Have tried PiVPN via two proxmox nodes as lxc and VM (J4125 and i5-6500t) and I'm getting about half the bandwidth that the Pi is giving me.\n I've played with MTU and that doesn't help.\n Is there a better way set WG up?\n OpenVPN is an option but most likely yield worse results so hoping WG will pull through.\n Iperf3 results are Gb each way. Have iperfed to an online server too and have got 500 down 80 up from the pi so I'm sure there is room for improvement \n Any ideas / tips for a struggling soul?\n TIA\n    submitted by    /u/Soogs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zb1eba/wireguard_for_homelab/",
          "publishedOn": "2022-12-02T23:24:33.000Z",
          "wordCount": 14260,
          "title": "Wireguard for homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zb18tf/my_home_lab/",
          "author": null,
          "description": "Hardware:2x ProLiant DL380 Gen9 with 2x Intel(R) Xeon(R) CPU E5-2667 v4 @ 3.20GHz / 768 GB RAM with 1 TB NVME + one ESXI host have 8x 600 GB SAS drives\n 1x ProLiant DL380 Gen9 with 2x Intel(R) Xeon(R) CPU E5-2687W v3 @ 3.10GHz / 384 GB RAM with 1 TB NVME\n 1x Dell R820 with 4x Intel(R) Xeon(R) CPU E5-4640 0 @ 2.40GHz / 640 GB DDR3 ram with 3x 1TB NVME\n 1x Fortigate 500D\n 1x Zyxel Switch XGS1250-12\n 1x MikroTik Cloud Router Switch CRS326-24G-2S+RM\n ​\n Cloudline T6 exhaust fan to another room :-) - stable around 25C in the room\n ​\n Only one hp server are online now because of the power price :-(\n Hosting plex/sonarr/radarr and ombi alot of other fun stuff in docker + home assistant\n ​\n vcenter / fortigate are managed almost 100 % by terraform / Gitlab pipelines :-)\n ​\n only 2x server that are added to the vcenter, one G9 with 384 GB RAM are running windows server for hybrid azure testing, the other G9 is not in use yet\n https://preview.redd.it/tnh0xcolik3a1.jpg?width=1800&format=pjpg&auto=webp&s=a49281147a37d3caa45a3396c5295b2e70ffc1d6\n https://preview.redd.it/0s3091plik3a1.jpg?width=1800&format=pjpg&auto=webp&s=0399cd4d85bd4055af600c71f7f73c97d43d065f\n https://preview.redd.it/rfwo73plik3a1.jpg?width=1800&format=pjpg&auto=webp&s=c8cb0bc4a2fccebe230b6355119a7d19b87f0fba\n    submitted by    /u/larsj96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zb18tf/my_home_lab/",
          "publishedOn": "2022-12-02T23:17:51.000Z",
          "wordCount": 14253,
          "title": "My home lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zb0xos/network_monitor_with_web_gui/",
          "author": null,
          "description": "Hey guys, I was wondering is there any kind of network monitor for linux? I have a raspberry pi 4 that acts as a network ad blocker (AdGuard Home) and I tried Grafana + Prometheus combo, but thats a bit too much for me. I also tried some CLI stuff, but that didn't work, I told them to monitor the eth0 but it gave me just like few mbs even when I was downloading few Gigs.\n    submitted by    /u/Ill_Energy7165  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zb0xos/network_monitor_with_web_gui/",
          "publishedOn": "2022-12-02T23:04:35.000Z",
          "wordCount": 14076,
          "title": "Network monitor with web GUI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zaz34w/recommendations_for_a_home_alarm_system/",
          "author": null,
          "description": "I’ve currently got four Hik CCTV cameras, segregated on a VLAN with no internet access, and I’m utilising Frigate with Home Assistant for mobile notifications. This all works great. \n I also have an intruder alarm, with sensors round the house/office/garage, but it’s a traditional alarm that I have to pay £100 to a company to keep it running. \n I’m wondering if there’s a better solution where I can rip out this alarm system and install something else that doesn’t require a company to maintain it.\n For requirements I’d say:\n  \nAbility to arm different zones. With the current system, I can arm the downstairs, upstairs, garage and office independently or altogether. \n Ability to arm/disarm from my phone\n Notifications when the alarm is tripped, whether I’m at home or away. \n  \nAny suggestions?\n Thanks in advance!\n    submitted by    /u/drinkmilkandshit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zaz34w/recommendations_for_a_home_alarm_system/",
          "publishedOn": "2022-12-02T21:56:38.000Z",
          "wordCount": 16146,
          "title": "Recommendations for a Home Alarm system?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zayngo/new_to_self_hosting_i_got_some_questions_about/",
          "author": null,
          "description": "Hej,\n I just build my first home server. I have a lot of experience with Docker and web development, but I got few questions on the architecture I would use on this homelab.\n I'd primarily use it for hosting my personal website (portfolio), use it as a NAS (for video editing and general file sharing - locally and over the internet (maybe nextcloud and something else?)), torrenting, media (probably Jellyfin), deploying dev builds of websites I'm working on and intercepting DNS traffic / ad-tracker-blocking. \n ​\n Hardware:\n CPU: Ryzen 4500; \n RAM: 16G; \n GPU: GTX 10603G; \n Storage: SSD128G, HDD4TB; \n ​\n I'd love to hear your software recommendations and tips, because so far I've got an Ubuntu Server with nothing. What software should I use for my desired use cases, what GUI would you recommend? Niche tips and tricks?\n ​\n Thanks!\n    submitted by    /u/kokolia1070  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zayngo/new_to_self_hosting_i_got_some_questions_about/",
          "publishedOn": "2022-12-02T21:41:05.000Z",
          "wordCount": 14467,
          "title": "New to self hosting. I got some questions about Docker / paravirtualization and NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zaxyep/intel_amt_not_working_properly/",
          "author": null,
          "description": "Hi,\n I have two HP Elitedesk 800 G2 with Intel AMT and i tried to use it but i am not happy how the power control works. Sometime i can't reboot the machine from the AMT. The machine works and i can reboot from Ubuntu but from AMT nothing is happening for example i want to boot into BIOS. I just upgraded AMT to 11.8 and i just installed a Ubuntu server on one of the machines. \n Anyone has constant success with Intel AMT ?\n    submitted by    /u/mihaicph  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zaxyep/intel_amt_not_working_properly/",
          "publishedOn": "2022-12-02T21:17:25.000Z",
          "wordCount": 15415,
          "title": "Intel AMT not working properly",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zaxi6b/wrong_ipv6_route_keeps_reappearing/",
          "author": null,
          "description": "Hi everyone,\n unfortunately I have a strange problem on my Proxmox box (but probably it is not related to Proxmox itself). The system keeps adding a wrong IPv6 route. When I manually remove the route or reconnect the LAN-cable everything is fine for a few minutes. After that the wrong rule appears again and I have no clue what is adding the rule over and over again.\n The wrong route leads to no IPv6 connectivity across VLANs.\n The affected interface is eno1 which is connected to a switch access port that is associated to VLAN10. eno1 gets an IPv6 address as intended (\":d910:\"/\"cc10\" is my marker for: DHCPv6 in VLAN10):\n https://preview.redd.it/4n9v24jlsj3a1.png?width=1338&format=png&auto=webp&s=b95c42c7fa8f76989be23ff88e835c2a6129cdf9\n And here is the wrong route that keeps popping up. The prefix \":d920\" is only handed out in VLAN20. eno1 should never see this! Removing this route leads to working IPv6 connectivity, but the route keeps reappearing.\n https://preview.redd.it/ta0hl7ossj3a1.png?width=1514&format=png&auto=webp&s=c05e1b4c16e59552469d0f13fc13616204189c65\n I also checked with rdisc6 if eno1 does see any wrong router advertisments. But everything seems to be fine (only \":d910:\" appears):\n https://preview.redd.it/wfoby506tj3a1.png?width=924&format=png&auto=webp&s=54f9ac05160de845d7a03e05751b55d9e8244d77\n I'm really desperate as I'm trying to debug this for 1-2 weeks now. I have no clue what I could check next. Any hint/advice is highly appreciated! What keeps adding the route and how can I fix the root cause?\n Thanks for reading!\n    submitted by    /u/schamock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zaxi6b/wrong_ipv6_route_keeps_reappearing/",
          "publishedOn": "2022-12-02T21:01:22.000Z",
          "wordCount": 15633,
          "title": "Wrong IPv6 route keeps reappearing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zawmml/help_feedback_on_upcoming_nasplex_build/",
          "author": null,
          "description": "TL/DR: can you look at my list of components below for a NAS/PleX server for <5 simultaneous streams with hardware encoding to be built in a 4U case with space for 100TB+ of storage and let me know if it all looks good for my use case?\n ---\n Hey everyone!\n I’m looking to build my first NAS/server and I’d love to get some build help. I’ve built computers in the past and have some technical knowledge, but nothing compared to this community. So, here’s what I’m looking to do:\n  \nNAS - I’m a video editor by trade, mostly 4K. I want a 100+ TB NAS to house archive files, and/or working files (if possible). I will hardwire my workstation to the NAS.\n PleX - I have a small-sized (<50) digital blu-ray collection and other digital movies in compressed formats that I’d like to house on my server and give access to close friends and family. <5 streams at once. Yes to hardware encoding.\n Experimentation - As this is my first introduction to all of this, I’d love to experiment with things like Radarr, Sonarr, home automation, Pi-hole, and I’m sure other things in the future.\n  \nThe hardware I've picked out can be found here or outlined below:\n ​\n  \n CPU Intel Core i5-11400 \n  \n Motherboard Gigabyte Z590 AORUS MASTER ATX LGA 1200 \n  Memory G.Skill Aegis 32GB (2x16GB) DDR4-2666 \n  Power Supply Corsair RM550x (2021) 550W 80+ Gold \n  Tiered Cache Storage (2X) TEAMGROUP MP33 1TB M.2 \n  OS Drive Kingston NV2 500GB M.2 \n  Storage Drives Seagate IronWolf Pro 18TB 7200 RPM (or 20TB depending on prices at time of purchase) \n \n    submitted by    /u/Mike-Anto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zawmml/help_feedback_on_upcoming_nasplex_build/",
          "publishedOn": "2022-12-02T20:27:08.000Z",
          "wordCount": 17484,
          "title": "HELP: Feedback on Upcoming NAS/PleX Build",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zavp3c/home_cctv_nvr/",
          "author": null,
          "description": "submitted by    /u/_IceQB_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zavp3c/home_cctv_nvr/",
          "publishedOn": "2022-12-02T19:53:13.000Z",
          "wordCount": 14263,
          "title": "Home CCTV NVR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zav54w/hp_prodesk_400_g4_mini_cpu_upgrade_help/",
          "author": null,
          "description": "Hello,\n I just received my Prodesk (picked one used for 85e in my local area), it currently have a Celeron g4900T. (the exact model is 7HS04EC#ABF)\n Searching on the HP website, i found a pdf listing the differents cpu you can put, I7 8700T, i5 8600T, i5 8500T, i3 xxxxT, and some others GxxxxT (only 35W T).\n I'd like to upgrade to an i5 8500T, but they are pretty rare in my region and quite on the expensive side, I found that the i5 8400T is almost the same performance wise.\n My question is, will a i5 8400T work instead of my G4900T ? both are Coffee Lake S\n Also can I use a non T version of the i5, the power supply is 65W so probably not ?\n Thanks !\n    submitted by    /u/Crepeas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zav54w/hp_prodesk_400_g4_mini_cpu_upgrade_help/",
          "publishedOn": "2022-12-02T19:31:25.000Z",
          "wordCount": 15901,
          "title": "HP Prodesk 400 G4 Mini - CPU upgrade help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zau8ny/i_created_a_guide_showing_how_to_utilize/",
          "author": null,
          "description": "submitted by    /u/Boonigan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zau8ny/i_created_a_guide_showing_how_to_utilize/",
          "publishedOn": "2022-12-02T18:56:24.000Z",
          "wordCount": 15382,
          "title": "I created a guide showing how to utilize Terraform with Proxmox",
          "imageUrl": "https://external-preview.redd.it/ZDMI5xXmyBgH4wnOn1JyXGxj_hV8pZWNCiRKjSqcbQE.jpg?auto=webp&s=43a9b07d9a1550d2e51f01c1094a4f50749f8ab7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zau3ht/what_do_i_replace_my_hp_dl380p_gen8_with/",
          "author": null,
          "description": "I have a HP DL380p Gen8 with dual E5-2650 CPU’s 4x 8TB HDD and 128GB RAM. Currently pulling about 200w 24x7. What could I replace this with without losing storage or processor capacity to reduce the power consumption？\n    submitted by    /u/ReefieUK  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zau3ht/what_do_i_replace_my_hp_dl380p_gen8_with/",
          "publishedOn": "2022-12-02T18:50:46.000Z",
          "wordCount": 15833,
          "title": "What do I replace my HP DL380p Gen8 with?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zat27x/setting_up_certificates_for_my_vmware_homelab/",
          "author": null,
          "description": "Looking to see if someone could point me to any good resources. I'm looking to gain a little bit of PKI experience and thought of starting with my homelab and getting rid of \"certificate not valid\" errors with my lab by creating my own local CA and cutting my own certs for everything. Any good guides or resources people could recommend that would help me figure out all the components and steps needed?\n    submitted by    /u/cylemmulo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zat27x/setting_up_certificates_for_my_vmware_homelab/",
          "publishedOn": "2022-12-02T18:10:43.000Z",
          "wordCount": 18044,
          "title": "Setting up certificates for my Vmware homelab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zasof0/reclaiming_power_outlets/",
          "author": null,
          "description": "I'm less familiar with electrical tom foolery.\n I've got some power adapters for things, like my Netgear Orbi, where they rotated the plug like 90 degrees, resulting in it covering a bunch of other outlets.\n What's a reliable/least likely to cause an electrical fire \"adapter\" that I can use to rotate some plugs 90 degrees to get them \"out of the way\"?\n Was looking at UPSes when it occurred to me I wouldn't need one of not for these stupid plugs.\n    submitted by    /u/Nakatomi2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zasof0/reclaiming_power_outlets/",
          "publishedOn": "2022-12-02T17:55:54.000Z",
          "wordCount": 15389,
          "title": "Reclaiming power outlets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zaqm7u/qbittorrent_plex_vpn_with_homelab_that_uses/",
          "author": null,
          "description": "So i’m really new to home servers and stuff, watched a lot of videos but i’m still pretty confused on how to get started.\n I have an old pc that i want to make into a home lab nas that runs 24/7 and is set up to be able to do the things in the title plus maybe pi hole if that isn’t complicated. I want to be able to remotely control it with my main pc if that’s possible/necessary.\n Is there a guide or video or something that might be able to help? mb if these are dumb questions or if i overlooked something simple\n    submitted by    /u/ThinkTheUnexpected_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zaqm7u/qbittorrent_plex_vpn_with_homelab_that_uses/",
          "publishedOn": "2022-12-02T16:33:05.000Z",
          "wordCount": 17010,
          "title": "Qbittorrent, Plex, VPN with homelab that uses radarrr, etc",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zanq15/pihole_vs/",
          "author": null,
          "description": "so why is is pihole for most of the users? There are other solutions (pfBlockerNG, adguard...) but must uses pihole. Is it the best, or is it just easiest to use?\n    submitted by    /u/flaotte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zanq15/pihole_vs/",
          "publishedOn": "2022-12-02T14:30:22.000Z",
          "wordCount": 15841,
          "title": "pi-hole vs ...?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/zadrgg/mini_homelab_with_windows_linux_and_macos_x86_and/",
          "author": null,
          "description": "submitted by    /u/slimsag  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/zadrgg/mini_homelab_with_windows_linux_and_macos_x86_and/",
          "publishedOn": "2022-12-02T06:22:26.000Z",
          "wordCount": 16422,
          "title": "Mini homelab with Windows, Linux, and macOS - x86 and arm devices for each.",
          "imageUrl": "https://external-preview.redd.it/dGdARWU6ivZiAL4qvEeQDpRxxqA0EjJ1gnZFxhXcrVM.png?format=pjpg&auto=webp&s=aa7e491a0660d81da9f30691ffd17363da556290"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/za752m/should_i_backup_2_drive_into_1_drive_with_2/",
          "author": null,
          "description": "Hi ! I currently have a server with : 1 x 8TB HDD Ironwolf for Data, 1 x 10TB HDD Red for Backup, 1 x 500GB M.2 Crucial for Boot Drive and Linux VM, 2 x 4TB Ironwolf and Red (i still don't know what to do with them for the moment) , 1 x 250GB SSD Sata Kingstone (Old boot drive no use for the moment),\n Now i have my 8TB Backup as sync in my 10TB , 500GB + VM Backup in my 10TB, 4TB Ironwolf backup in my 4TB Red,\n I would like to know if its a good idea to create a partition on the 10TB. With the exact size as my 8TB to backup sync my 8TB in this partition like if i have exactly the same drive and create a partition with the space left to backup my Boot drive and maybe other thing.\n I will probably use the 250GB SSD to put my vm on this one. And backup this ssd with the boot drive backup (inside the 10TB)\n So the goal is to simulate a real drive and be able to see if the sync got the same size, improve the organisation between my 2 backup. Thats not a crucial feature is more a idea i've got recently. Thx for your help\n    submitted by    /u/Bronom213  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/za752m/should_i_backup_2_drive_into_1_drive_with_2/",
          "publishedOn": "2022-12-02T01:36:57.000Z",
          "wordCount": 14729,
          "title": "Should i backup 2 drive into 1 drive with 2 partition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/za6v6j/put_your_server_in_the_basement_they_said_itll_be/",
          "author": null,
          "description": "submitted by    /u/bobbywaz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/za6v6j/put_your_server_in_the_basement_they_said_itll_be/",
          "publishedOn": "2022-12-02T01:25:58.000Z",
          "wordCount": 14595,
          "title": "Put your server in the basement they said, it'll be cool in the summer and provide heat for the pipes in the winter...",
          "imageUrl": "https://external-preview.redd.it/_aAIYXDNB9RKJbGznI5g5y8qOdg_6OiEzt9_yvM_xJc.png?format=pjpg&auto=webp&s=61bdf84513c9d2892236b4c669ed99a5042fe78d"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/za5vtw/generic_ios_app_that_mimics_unifi_ar_feature/",
          "author": null,
          "description": "Is anyone aware of an iOS app that does something similar to the AR feature on the fancy unifi switches? But in a non-vendor-specific way. Like stick a QR code on your rack to create a spatial reference point and then be able to label all the devices and ports in AR and maybe open the web interfaces and see stats?\n    submitted by    /u/Adventurous-Mud-5508  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/za5vtw/generic_ios_app_that_mimics_unifi_ar_feature/",
          "publishedOn": "2022-12-02T00:48:05.000Z",
          "wordCount": 14407,
          "title": "Generic iOS app that mimics Unifi AR feature",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/za4uzv/adopted_a_dell_poweredge_t630_now_to_find_a_use/",
          "author": null,
          "description": "submitted by    /u/redfoxkiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/za4uzv/adopted_a_dell_poweredge_t630_now_to_find_a_use/",
          "publishedOn": "2022-12-02T00:07:48.000Z",
          "wordCount": 14810,
          "title": "Adopted a Dell PowerEdge T630. Now to find a use for it...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/za4emj/keycloak_attempt_to_edit_denied_attribute_error/",
          "author": null,
          "description": "I’m currently trying to setup federation with my AD server and I’m getting an error I’m not sure how to fix. Both on Windows Server.\n 2022-12-01 05:08:50,549 WARN [org.keycloak.userprofile.validator.ReadOnlyAttributeUnchangedValidator] (executor-thread-25) Attempt to edit denied attribute '(?i:^\\QKERBEROS_PRINCIPAL\\E$|^\\QLDAP_ID\\E$|^\\QLDAP_ENTRY_DN\\E$|^\\QCREATED_TIMESTAMP\\E$|^\\QcreateTimestamp\\E$|^\\QmodifyTimestamp\\E$|^\\QuserCertificate\\E$|^\\Qsaml.persistent.name.id.for.\\E.*$|^\\QENABLED\\E$|^\\QEMAIL_VERIFIED\\E$|^\\QdisabledReason\\E$)' of user 'testuser' 2022-12-01 05:08:50,549 WARN [org.keycloak.userprofile.validator.ReadOnlyAttributeUnchangedValidator] (executor-thread-25) Attempt to edit denied attribute '(?i:^\\QKERBEROS_PRINCIPAL\\E$|^\\QLDAP_ID\\E$|^\\QLDAP_ENTRY_DN\\E$|^\\QCREATED_TIMESTAMP\\E$|^\\QcreateTimestamp\\E$|^\\QmodifyTimestamp\\E$|^\\QuserCertificate\\E$|^\\Qsaml.persistent.name.id.for.\\E.*$|^\\QENABLED\\E$|^\\QEMAIL_VERIFIED\\E$|^\\QdisabledReason\\E$)' of user 'testuser' \n Any advice on how to resolve this error would be greatly appreciated!\n    submitted by    /u/forestman11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/za4emj/keycloak_attempt_to_edit_denied_attribute_error/",
          "publishedOn": "2022-12-01T23:50:46.000Z",
          "wordCount": 14437,
          "title": "Keycloak “Attempt to edit denied attribute” error on user registration with Active Directory federation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/za150q/the_first_step_to_getting_my_table_drawers_in/",
          "author": null,
          "description": "submitted by    /u/PhireSide  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/za150q/the_first_step_to_getting_my_table_drawers_in/",
          "publishedOn": "2022-12-01T21:54:02.000Z",
          "wordCount": 14341,
          "title": "The first step to getting my table drawers in better shape. Door shoe holders make awesome cable pockets",
          "imageUrl": "https://external-preview.redd.it/lYZzXE50VyBtMM85WY7rzRt_79BitHAmzr6RMEPuEW8.jpg?auto=webp&s=2566604c8841eb10073855be24d8f0301f42dc70"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/za02uh/question_for_those_of_you_who_have_an_optiplex/",
          "author": null,
          "description": "Hello,\n I was wondering if one of you who have the SFF variant of the OptiPlex 9010 or 7010 could tell me if it uses one of those slim laptop style optical drives, or if it has a full 5.25 bay.\n I'm blind, so I'm unable to see pictures of the unit, and I've found conflicting discussions online. I'm trying to figure out if I could use one of these brackets to install another 3.5 drive, or if I'd be limited to installing an SSD using something like this. If it uses a slim drive, I also need to figure out if I'd need any sort of power adapter to connect an SSD.\n Thanks\n    submitted by    /u/CrunchyTesticle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/za02uh/question_for_those_of_you_who_have_an_optiplex/",
          "publishedOn": "2022-12-01T21:17:14.000Z",
          "wordCount": 15227,
          "title": "Question for those of you who have an OptiPlex 9010 or 7010 SFF",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9zxmp/anyone_can_offer_guidance_on_flashing_coreboot_on/",
          "author": null,
          "description": "Hello fellows, Wonder if anyone succeeded in install Coreboot on those pFsense small computers from Aliexpress.\n I am aware that Protecli sells some small computers that one can configure online and saw that one can choose Coreboot on that unit. Now, supposedly I buy the same exact hardware from Aliexpress, would Protectli Coreboot .img file work on my Chinese small computer? I am weary of any computer with proprietary BIOS without any updates running as main router, thus the question. Anyone?\n    submitted by    /u/LovelyPrankFunk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9zxmp/anyone_can_offer_guidance_on_flashing_coreboot_on/",
          "publishedOn": "2022-12-01T21:12:07.000Z",
          "wordCount": 15063,
          "title": "Anyone can offer guidance on flashing Coreboot on Aliexpress pFsense appliances?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9ye2b/anyone_else_use_lto_in_their_labs/",
          "author": null,
          "description": "submitted by    /u/jackboy1606  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9ye2b/anyone_else_use_lto_in_their_labs/",
          "publishedOn": "2022-12-01T20:15:32.000Z",
          "wordCount": 17545,
          "title": "Anyone else use LTO in their labs ?",
          "imageUrl": "https://preview.redd.it/p8g0x8gkyd3a1.jpg?auto=webp&s=22a0d0f5c7bf59e47c050c9e1f0a9a7abc3b02b4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9xkn3/network_infrastructure_change/",
          "author": null,
          "description": "So i started my journey with homelab and same as many noobie i just bought cheap router turn on DHCP and start playing. Right now all devices are running in same network with only one VLAN. I would like to change it and i bout Fujitsu FUTRO s920 to install on it opnSense but... i completely don't know about it ;/ Sooo i'm here for advice to who should i watched to get basic knowlage about VLANS, NAT, Port forwarding etc. \n I have created graph how my infrastructure looks like. I marked how i imagine vlans with colors of the cables. \n https://preview.redd.it/rnjq55kt9c3a1.png?width=1306&format=png&auto=webp&s=43cd7ed5b6f7b3a06cd7a2c168ad0db71739c5b7\n I want to do it because with OPNsense i'll able to:\n -Isolate Crypto miner from whole network(just in case)\n -Isolate IoT devices in one network and let HomeAssistant be bridge between SFW network\n -Isolate other devices in pools for easier troubleshooting \n AP question\n Do you know AP that can broadcast network(3 networks):\n - 5GHz and 2.4GHz with same SID name\n - 2.4GHz hidden IoT network\n Its running :D \n https://preview.redd.it/nr1eq80hac3a1.png?width=1718&format=png&auto=webp&s=64293a16b9ba42a747a6ff4158db37ac66c5b35b\n Thanks for all in advance!\n    submitted by    /u/menma_ja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9xkn3/network_infrastructure_change/",
          "publishedOn": "2022-12-01T19:45:45.000Z",
          "wordCount": 16404,
          "title": "Network infrastructure change.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9xgsl/adding_a_gpu_to_a_u1_poweredge_r620/",
          "author": null,
          "description": "I recently acquired a dell Poweredge R620. This is my first piece of enterprise gear, so I'm still learning a lot. I would like to add a GPU to the server for gaming. I know I can't add anything too crazy and it has to be under 75W, but after watching a video by Craft Computing talking about the Tesla P4 I thought it would be a perfect fit for this server. Also they are really cheap right now compared to what they were a few months ago. \n Since I'm still new, and this is my first time ever doing anything like this, I wanted some advice before I purchased anything. Is it a good idea to go with the Tesla P4 or should I use something else? Is there anything in addition to the GPU that I would need to purchase? I know I might need a fan for cooling, but is there something I might be forgetting? Also does anyone have this setup? Would it even be possible? Any advice is greatly appreciated.\n    submitted by    /u/General-Monitor-5196  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9xgsl/adding_a_gpu_to_a_u1_poweredge_r620/",
          "publishedOn": "2022-12-01T19:41:50.000Z",
          "wordCount": 17258,
          "title": "Adding a GPU to a U1 Poweredge R620?",
          "imageUrl": "https://external-preview.redd.it/43f5cnvM1vdu66p4aPQ5Z9FJcgLchbQqzGAddqERYKU.jpg?auto=webp&s=7a87c4d89339a462b37596c4b1efb712630bacf2"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9x0qc/mikrotik_switch/",
          "author": null,
          "description": "I am wanting to get a Mikrotik switch and I am wondering how much difference 512 MB of RAM that the CRS326-24G-2S would cause problems? I have read on other posts that less than 1 GB of RAM can cause problems with slow speeds. I won't have a lot of traffic on my network. I am wanting to create some VLAN's to separate IoT devices in my network. I am familiar with Mikrotik eq, I worked for a WISP as a TierII technician that had some Mikrotik switches and radios. I am also looking at a CSS326-24G-2S+RM 24. I don't really need routing, just something more to learn. I am using pfSense as my router and I've out grown my 8 port switch. \n I am not interested in Ubiquity equipment.\n Thanks\n    submitted by    /u/skidoug  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9x0qc/mikrotik_switch/",
          "publishedOn": "2022-12-01T19:25:19.000Z",
          "wordCount": 15392,
          "title": "Mikrotik switch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9wvn6/question_about_dell_poweredge_r520_etc_onboard/",
          "author": null,
          "description": "Real basic question I hope someone can answer for me to save me the buttload of time it would take to find out myself through experimentation...\n If you have a Dell server (e.g. R520) with an on-board RAID controller for the backplane, and the RAID controller does not support non-RAID configurations... \n If you, as a workaround, were to set up each disk as a single RAID0 virtual disk individually, and pass the RAID0 VDs through to the OS, would the Filesystem on the physical disk remain mountable if later removed from the RAID controller?\n In other words: does the RAID controller do anything to the structure of the disk such that it can only be mounted by the RAID controller, or would it be identical to the same disk mounted by a SAS controller without RAID?\n I'm looking to use this workaround to mount disks to pass through to a guest OS, and want to ensure that I am not dependent on the continued operation of the host RAID controller to access and work with the data, so that if/when the host controller dies or is replaced with another device, I can just plug the drives in to another SAS controller and have them be recognized and mounted normally.\n Thanks in advance.\n P.S. if I don't get an answer here I'll need to verify it myself by several passes of formatting and mounting and OSing and swapping 10TB disks between servers so that could take a while.... I'll post the results here if I do though because I'm not a monster.\n    submitted by    /u/SimplifyAndAddCoffee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9wvn6/question_about_dell_poweredge_r520_etc_onboard/",
          "publishedOn": "2022-12-01T19:20:04.000Z",
          "wordCount": 17411,
          "title": "Question about Dell Poweredge R520 etc on-board RAID controllers that don't support non-RAID mode",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9wusu/1u_rack_fan_configuration/",
          "author": null,
          "description": "I've got a 1U IRD and for some reason when replacing the fans, accidentally they were installed reversed, so they are exhausting air instead of intake. \n This resulted in a 5C cooler temperature. The question is, should I continue to keep it this way, or do I have the fans the \"correct\" way at a cost of an increase in 5C?\n    submitted by    /u/darkened_sol  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9wusu/1u_rack_fan_configuration/",
          "publishedOn": "2022-12-01T19:19:14.000Z",
          "wordCount": 14389,
          "title": "1U rack fan configuration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9wqoi/repurposed_ikea_box_as_mini_homelab_station/",
          "author": null,
          "description": "submitted by    /u/faibg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9wqoi/repurposed_ikea_box_as_mini_homelab_station/",
          "publishedOn": "2022-12-01T19:14:54.000Z",
          "wordCount": 15315,
          "title": "Repurposed Ikea box as mini homelab station",
          "imageUrl": "https://preview.redd.it/b9ed0ui66c3a1.jpg?auto=webp&s=e83ff366ab4f39a52d9178e67eb3aa7a135cc1f4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9vj8i/updateadded_some_things_to_my_new_rack/",
          "author": null,
          "description": "submitted by    /u/Stevenyoung2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9vj8i/updateadded_some_things_to_my_new_rack/",
          "publishedOn": "2022-12-01T18:32:03.000Z",
          "wordCount": 15131,
          "title": "Update:Added some things to my new rack",
          "imageUrl": "https://preview.redd.it/wh3ll1u3gd3a1.jpg?auto=webp&s=5d6a8b0d84c1b8f4cb52414a5cdf314d7559de50"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9ukch/uapachd_when_cold_started_with_brocade_poe_switch/",
          "author": null,
          "description": "Hey y'all, posted on /r/Ubiquiti, but I figured y'all might have some experience on the switch side: https://www.reddit.com/r/Ubiquiti/comments/z8y6y7/uapachd_when_cold_started_with_poe_switch/\n I had a weird issue I was hoping someone could help with.\n In my house, I use a Brocade ICX6450 switch, which supports POE (802.3af and 802.3at). Indeed, I had figured out how to make this whole thing work before things broke after a power outage and I had to do my workaround again.\n I have two UAP-AC-HD APs and one UAP-AC-Pro. The Pro has no issues - I connect it to the switch, tell it to turn POE on, and it's immediately detected as 802.3af. Obviously also works fine with an injector. However, both of the HDs - when the AP has been disconnected for a while (e.g. 5 hour power outage), when it's connected to the switch, it's detected as \"non-standard PD\". When I connect it to an 802.3at injector, it turns on fine.\n Here's the strange thing - if I have it on the injector for a little bit of time (~5 minutes or so) then immediately plug it into the switch directly, the switch senses it as 802.3at and feeds it power.\n Has anyone run into this before? Or does this sound familiar to anyone?\n    submitted by    /u/misteryub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9ukch/uapachd_when_cold_started_with_brocade_poe_switch/",
          "publishedOn": "2022-12-01T17:58:30.000Z",
          "wordCount": 16910,
          "title": "UAP-AC-HD - when cold started with Brocade POE switch, detected as non-standard PD, but when cold started with injector, no issuesQuestion (self.Ubiquiti)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9sffd/low_voltage_conduit/",
          "author": null,
          "description": "Building a house. Around 2,200 square feet for the footprint. Will have a full basement. So total square feet is 4,400 plus the garage and porch and so on\n Thinking about maybe putting an 18U server rack in a storage area under the stairs?\n Wondering about how especially on exterior walls, if we add spray foam it will be hard to use old cable to pull new cable for future upgrades.\n Wondering if I should have conduit anywhere I will spray foam? This way if technology is significantly different in 20 years I can pull something else through and leave the spray foam intact? If so, are there key words I can search for to find good info about low voltage conduit?\n Wondering about larger conduit into the server rack are as well.\n I’m pretty ignorant. I mean, I’ve read a lot and think I have a plan but I have very little hands on experience. This may not be a typical question for here but I figured if anyone would know, you guys would.\n Thanks.\n    submitted by    /u/John_Locke76  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9sffd/low_voltage_conduit/",
          "publishedOn": "2022-12-01T16:37:14.000Z",
          "wordCount": 15028,
          "title": "Low voltage conduit?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9s8xn/help_with_a_beginner_devops_homelab_build/",
          "author": null,
          "description": "I want to make my first homelab but I want some help to consider what I should buy.\n Reason:\n  \nto learn and play with technologies.\n to learn about virtualization\n I already know about kubernetes, but I have never provisioned a cluster myself. So the goal is to provision VMs and then make a kubernetes cluster on top of that.\n What will the cluster be running? I don't know exactly, maybe some bots, some self hosting, gitops testing, docker multi-arch building etc.\n  \nImportant factors:\n  \nNoise\n Consumption\n  \nWhat I was thinking was to buy a Deskmini x300 with 64GB ram, 1TB SSD and a 5600g Ryzen. I think it should be enough for 4 VM k8s cluster (one master and 3 nodes) and also some space for other things.\n However, I am considering if it makes sense to buy a Ryzen 5700g instead. Going that way, it is going to be more expensive but I also fear about the two important factors above. I think I would have to buy a Noctua fan and on top of that, I am not even sure the deskmini x300 PSU can handle the CPU.\n I should also add that I want to run it mainly headless with SSH connection from my laptop. I am still not sure if I want to buy a screen, don't have much space in my office.\n    submitted by    /u/YouGuysNeedTalos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9s8xn/help_with_a_beginner_devops_homelab_build/",
          "publishedOn": "2022-12-01T16:29:53.000Z",
          "wordCount": 16513,
          "title": "Help with a beginner devops homelab build.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9oak1/dead_after_4_years_of_service_mainly_without/",
          "author": null,
          "description": "submitted by    /u/manu2107el  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9oak1/dead_after_4_years_of_service_mainly_without/",
          "publishedOn": "2022-12-01T13:46:47.000Z",
          "wordCount": 16132,
          "title": "Dead after 4 years of service mainly without maintenance RIP.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9nvaq/grafana_93_shows_images_on_a_map/",
          "author": null,
          "description": "submitted by    /u/bear007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9nvaq/grafana_93_shows_images_on_a_map/",
          "publishedOn": "2022-12-01T13:27:27.000Z",
          "wordCount": 14630,
          "title": "Grafana 9.3 Shows Images On a Map",
          "imageUrl": "https://external-preview.redd.it/aSsHMoV-e4U6iAIkLRINFl6oisvfTwteyt3D--hd9-A.jpg?auto=webp&s=fdac7f4d8f248886c0120e99b18288ab6658ccec"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9ld76/anything_of_worth/",
          "author": null,
          "description": "submitted by    /u/Jacksy90  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9ld76/anything_of_worth/",
          "publishedOn": "2022-12-01T11:21:40.000Z",
          "wordCount": 15120,
          "title": "Anything of worth?:)",
          "imageUrl": "https://preview.redd.it/c2x6xh89bb3a1.jpg?auto=webp&s=4a3ef500e7a24234990ca52c9e303be4d47f9e78"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9fko5/new_to_homelab_just_picked_up_an_hp_c3000_is/",
          "author": null,
          "description": "submitted by    /u/31899  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9fko5/new_to_homelab_just_picked_up_an_hp_c3000_is/",
          "publishedOn": "2022-12-01T05:29:45.000Z",
          "wordCount": 16594,
          "title": "New to homelab. Just picked up an HP C3000! Is anyone familiar with this system?",
          "imageUrl": "https://preview.redd.it/zpeygwajk93a1.jpg?auto=webp&s=dce3a4d395fed4ab660541033352715d8a5d8b40"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9apdp/switched_from_a_3_server_lab_to_a_1_server_lab/",
          "author": null,
          "description": "So, due to the power cost (our bill last month was over $1K USD), so I built a power efficient server to replace my proxmox server, my Nas and my firewall. \n It’s running a i5-8600K, 32GB DDR4 ram, 1TB NVMe, and 2x14TB HDD’s.\n Thinking of taking some of the 1TB SSD’s from my old server and turning them into a cache drive on my new server but I’m not sure about that yet.\n Compared to my old proxmox server (which used around 2.5KWh daily), this server uses less than 1KWh daily, so I’m happy with the investment\n    submitted by    /u/AustinBZechar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9apdp/switched_from_a_3_server_lab_to_a_1_server_lab/",
          "publishedOn": "2022-12-01T01:57:38.000Z",
          "wordCount": 14734,
          "title": "Switched from a 3 server lab to a 1 server lab due to power costs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z99x2b/new_to_homelabing_network_switch_config/",
          "author": null,
          "description": "Does anyone have experience setting up an FS.com S3900-24T4S managed network switch? When I connect to the switch I can access the web GUI and even SSH into it. I have it connected to a PFsense machine but no matter how I attempted to configure the network switch I cannot seem to get online through it. Does anyone have just a basic setup that I can go off of?\n    submitted by    /u/WorshipingAtheist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z99x2b/new_to_homelabing_network_switch_config/",
          "publishedOn": "2022-12-01T01:24:19.000Z",
          "wordCount": 14652,
          "title": "New to Homelabing - Network Switch Config",
          "imageUrl": "https://external-preview.redd.it/ySsj9_qv7J2PBrUf4BLtCLFKqq0TXwm_XpcXP-x7ND4.jpg?auto=webp&s=0015f2fd5f6802cfc970855e97e566314ded6183"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z99oyz/called_tplink_and_they_cant_tell_me_if_this/",
          "author": null,
          "description": "Hello, I'm building a rack since I now work from home and this is needed. I need good bandwidth while not ruining myself and we all know this can go quite fast in networking and servers.\n On another sub a user told me that if I wanted to max out the SFP+ ports between my server and my computers I needed RDMA. I then found an RDMA daughter card for my r730xd server and Mellanox CX3 cards for my computers.\n I then asked myself, is my switch compliant with RDMA? Another user replied and said that a switch needs to be PFC (Priority Flow Control) so it can do RDMA. For my budget I'm currently looking at the TP-Link TL-SG3428XMP which have 4x SFP+ ports and PoE and is L2+ which does everything I need. At least that's what I though before that unclear stuff about RDMA. I called TP-Link and they told me my question was too complicated and that someone would call me back tomorrow which they did. The man on the phone was really lost and couldn't answer my question and said I would receive an email. I never received an email and it's been dead silent since then.\n TLDR; Can someone tell me if the TP-Link TL-SG3428XMP can do RDMA over 10GB/s between my server and my computers all on SFP+ ports?\n Sorry to ask for a noob question in this sub but I need help and really have to take a decision on the network daughter card before they ship my server.\n    submitted by    /u/igmyeongui  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z99oyz/called_tplink_and_they_cant_tell_me_if_this/",
          "publishedOn": "2022-12-01T01:15:00.000Z",
          "wordCount": 15056,
          "title": "Called TP-Link and they can't tell me if this switch can do RDMA over SFP+ ports",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z99dmm/wanting_to_switch_from_mesh_to_access_point/",
          "author": null,
          "description": "Ok, so I have a nighthawk m60 mesh network set up currently (router and two satellites). My house is wired for cat5e with Ethernet drops in every room. \n Here's where I need advice. I cannot find a access point that will also function as an Ethernet switch, so should I...\n A. Get 3 wifi routers and set two of them up as access point nodes. \n Or\n B. Go from modem to wifi router to managed switches in the rooms that currently have the satellites and replace the satellites with Poe access points.\n Or\n C. Someone who is way smarter than me will give me direction to a better solution.\n    submitted by    /u/frostyf3at  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z99dmm/wanting_to_switch_from_mesh_to_access_point/",
          "publishedOn": "2022-12-01T01:01:20.000Z",
          "wordCount": 15310,
          "title": "Wanting to switch from mesh to access point",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z9982v/anyone_know_of_a_tool_to_sign_for_file_delivery/",
          "author": null,
          "description": "Sign for file delivery\n Am toying with nextcloud have just got setup on my unraid system. But wondering if there is a better tool out there?\n I want to deliver drone video footage to clients.\n I want actionable information about who downloaded data & when.\n I think inviting clients to create an account will be too much trouble.\n Is there a way I can send them a unique link and have them effectively sign for the files by inputing their names, email & phone number & clicking agree?\n Often clients may share the link with others and this is a way of safely sharing the files but also keeping some trail.\n Thanks\n    submitted by    /u/dopeytree  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z9982v/anyone_know_of_a_tool_to_sign_for_file_delivery/",
          "publishedOn": "2022-12-01T00:55:12.000Z",
          "wordCount": 14972,
          "title": "Anyone know of a tool to Sign for file delivery? Like receiving parcels",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z97v41/the_post_formerly_known_as_anything_friday/",
          "author": null,
          "description": "Post anything.\n  \nWant to discuss something?\n Want to have a moan?\n Want to show something off?\n  \nDo it here.\n View all previous megaposts here!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z97v41/the_post_formerly_known_as_anything_friday/",
          "publishedOn": "2022-12-01T00:00:09.000Z",
          "wordCount": 14568,
          "title": "The Post Formerly Known as Anything Friday - December 2022 Edition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z97p2q/lightning_psa/",
          "author": null,
          "description": "Reminder to check your setups for resistance to lightning.\n I thought I was safe as all of my equipment is surge protected. Last night we had a very close lightning strike. \n The surge travelled through the ground. Into an unplugged coax cable outside. Through that cable and into an AP inside. Through that AP and into my Cat5e cables. Through those cables and killed my 24 port managed switch. It may have also damaged the NIC on one of my servers.\n This is my current theory at least.\n It is also a good idea to backup your switch configs to a remote server. Configuring my new switch is going to be a pain.\n    submitted by    /u/jtsfour2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z97p2q/lightning_psa/",
          "publishedOn": "2022-11-30T23:53:16.000Z",
          "wordCount": 16863,
          "title": "Lightning PSA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z97a24/fitting_a_9u_10_rack_and_a_1u_19_space_between/",
          "author": null,
          "description": "submitted by    /u/frambot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z97a24/fitting_a_9u_10_rack_and_a_1u_19_space_between/",
          "publishedOn": "2022-11-30T23:36:11.000Z",
          "wordCount": 15377,
          "title": "Fitting a 9U 10\" rack and a 1U 19\" space between wall studs",
          "imageUrl": "https://external-preview.redd.it/WS74rs33LtlUd_kguh5uGCv6vQhYTenaJma3BBddGxA.jpg?auto=webp&s=8881370e0c3c618c667463eaabdd0045b8047a7e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z93qs8/x10sdv_superdom/",
          "author": null,
          "description": "Hi,\n I got an X10SDV-6C+-TLN4F which I got secondhand (cheap), and I discovered the \"known\" issue with NVME's - so now I'm looking into getting an SM 64GB SuperDOM for boot and / , but wonder how is the lifetime for these things ?\n    submitted by    /u/casperghst42  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z93qs8/x10sdv_superdom/",
          "publishedOn": "2022-11-30T21:24:57.000Z",
          "wordCount": 15075,
          "title": "X10SDV - SuperDOM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z93d59/nas_options/",
          "author": null,
          "description": "I currently am using a Synology DS918+ purely for storage (3x 14TB WD HDDs). I have a mini ASRock PC with an i7-1100K with 2x 1TB NVME SSD's running Unraid for all of my dockers (plex) & VMs. I like Unraid for that.\n ​\n I purchased a 10gbe switch and am evaluating what to do with my setup to use at least 2.5gbe on my NAS and primary workstation.\n ​\n  \nBuild a cheap AMD Ryzen 3 or Ryzen 5 ATX tower and put in my 14TB HDDs (3 are in my DS918+ and I have 2 extra) and 32GB of ECC RAM and run TrueNAS or Xpenology and setup shares. Keep using my little i7 unraid box for VMs & docker (plex). I'd do 3 or 4 HDDS to start in Z1. I can add another array in the future? I'm a TrueNAS noob.\n Use my i7-1100K CPU in a mATX motherboard and a case with more space for drives. Run Unraid for everything. No ECC RAM though with the i7... Sell my DS918+ and my ASRock Mini barebones. Only concern is will I have issues with bitrot on Unraid vs. ZFS or Synology SHR.\n Use my i7-1100K CPU in a mATX motherboard and a case with more space for drives. Run Proxmox and setup TrueNAS as a VM and run my Win & Linux VMs to proxmox. Sell my DS918+ and my ASRock Mini barebones. \n Buy a 5-bay DS1522+ use 4x14TB HDDs, 1x14TB HDD as a hotswap. Add their overpriced 10gbe card. Keep using it as my file shares, use Hyperbackup to other offsite DS220 and cloud backup to GDrive. Keep my mini i7 Unraid box. Sell my DS918+ to recoup some of the expense of new one.\n  \nI do like how easy Synology makes things (love Hyperbackup). I use their quickconnect feature and OpenVPN to access it remotely. For accessing my Unraid remotely I use Tailscale. If I used TrueNAS, what do they offer for easy offsite backups and syncing to google drive?\n ​\n I have a short depth server rack so I can't use any full size servers. An ATX tower I would set on the floor. It's all in a 5x5 closet, no ventilation. So I do have to consider heat. Currently the Synology HDDs run 37-40C.\n ​\n Any feedback appreciated.\n    submitted by    /u/wildmn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z93d59/nas_options/",
          "publishedOn": "2022-11-30T21:11:10.000Z",
          "wordCount": 15946,
          "title": "NAS Options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z90v51/since_you_all_got_be_into_to_this_i_feel_like_a/",
          "author": null,
          "description": "submitted by    /u/UrafuckinNerd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z90v51/since_you_all_got_be_into_to_this_i_feel_like_a/",
          "publishedOn": "2022-11-30T19:36:26.000Z",
          "wordCount": 16625,
          "title": "Since you all got be into to this, I feel like a few of you can help me get this into the basement",
          "imageUrl": "https://preview.redd.it/vepqi29om63a1.jpg?auto=webp&s=fabefa475c81d982bd5bd7cd2a63146ca61f8bbc"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z90c2l/the_start_of_my_homelab_journey/",
          "author": null,
          "description": "submitted by    /u/Pesfreak92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z90c2l/the_start_of_my_homelab_journey/",
          "publishedOn": "2022-11-30T19:17:10.000Z",
          "wordCount": 15006,
          "title": "The start of my homelab journey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z902eu/what_are_these_blue_ethernetsized_clips_from/",
          "author": null,
          "description": "Hey all... What are these?\n I believe it came with a MonoPrice order (with 1U keystone blank panel), and they're in bags of 24.\n The rectangular size is ALMOST exactly the dimensions of an ethernet plug (looking at an Ethernet plug from the \"front\", meaning the smallest dimension). But they don't seem meant for empty sockets as they just fall out..\n I normally label everything I keep precisely to avoid this problem, lol. TYVM.\n https://preview.redd.it/vbxfsxr3z43a1.jpg?width=960&format=pjpg&auto=webp&s=cf748b5f67619113e5f1e440db02d5f56dee3e17\n ​\n EDIT: Added 2nd image to show how it doesn't seem to relate to the 1U keystone plate. These little pieces are 1cm or 5/16 wide.\n    submitted by    /u/Agreeable-Ad4233  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z902eu/what_are_these_blue_ethernetsized_clips_from/",
          "publishedOn": "2022-11-30T19:07:21.000Z",
          "wordCount": 14803,
          "title": "What are these blue Ethernet-sized clips? From MonoPrice..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8y9jp/little_homelab_success_story/",
          "author": null,
          "description": "I was just in a zoom meeting and my (adjoined) neighbors were getting their new solar installation inspected. Of course in the process they shut off the mains to both our units and our power goes out, several times over the course of five minutes or so.\n Finally people on the call are just like,… “did your power go out like 3 times? And how are you still… why didn’t you… what the?”\n Of course all my APs are PoE back to the Ubiquiti Dream Machine SE in the basement, and everything including the Fios ONT is battery backed up by UPS.\n This was the first live test but it worked flawlessly 😎\n Anyone else have success stories that made you pat yourself on the back and think “man I’m glad I did this right.”?\n    submitted by    /u/calinet6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8y9jp/little_homelab_success_story/",
          "publishedOn": "2022-11-30T18:02:22.000Z",
          "wordCount": 15514,
          "title": "Little homelab success story",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8wxrb/best_way_to_handle_wifi_with_a_mini_computer/",
          "author": null,
          "description": "I am moving out of the nest, I am buying a mini computer for opnsense and want to know the best way to handle wifi for a 1bdr apt. Should I just buy antennas for it or just buy an AP?\n    submitted by    /u/Nerdlinger42  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8wxrb/best_way_to_handle_wifi_with_a_mini_computer/",
          "publishedOn": "2022-11-30T17:10:53.000Z",
          "wordCount": 15652,
          "title": "Best way to handle wifi with a mini computer router?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8wvej/the_stack_of_doom/",
          "author": null,
          "description": "submitted by    /u/3tes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8wvej/the_stack_of_doom/",
          "publishedOn": "2022-11-30T17:08:21.000Z",
          "wordCount": 16859,
          "title": "The Stack of Doom",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8w2e9/i_may_have_bit_off_a_bit_more_than_i_can_chew/",
          "author": null,
          "description": "4x dell r730xds, 2x2.5ghz Xeon, 512gb mem, 22x1.2tb sas drives. And a pair of netapp e series storage nodes, each with 50x10tb sas 12gbps drives…… my electric bill is scared….\n    submitted by    /u/ltspeanut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8w2e9/i_may_have_bit_off_a_bit_more_than_i_can_chew/",
          "publishedOn": "2022-11-30T16:36:55.000Z",
          "wordCount": 15135,
          "title": "I may have bit off a bit more than I can chew…",
          "imageUrl": "https://preview.redd.it/40p0wz0nq53a1.jpg?blur=40&format=pjpg&auto=webp&s=bc10e9397cad3514979bed10bd9c2c64c9e64f00"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8vgke/i_added_a_pretty_little_cloud_to_my_setup/",
          "author": null,
          "description": "submitted by    /u/fire-marshmallow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8vgke/i_added_a_pretty_little_cloud_to_my_setup/",
          "publishedOn": "2022-11-30T16:12:49.000Z",
          "wordCount": 16064,
          "title": "I added a pretty little cloud to my setup.",
          "imageUrl": "https://preview.redd.it/w067gu4cm53a1.jpg?auto=webp&s=b93a25270e7ed99d3ec09481f81ebfc182bd56c8"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8o8n3/are_we_ipv6_ready/",
          "author": null,
          "description": "if you would rebuild home network from the scratch, would you go IPv6 only?\n Why is it a bad idea?\n    submitted by    /u/flaotte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8o8n3/are_we_ipv6_ready/",
          "publishedOn": "2022-11-30T10:37:29.000Z",
          "wordCount": 21224,
          "title": "are we IPv6 ready?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8o17n/should_i_worry_about_the_temps_and_humidity_the/",
          "author": null,
          "description": "submitted by    /u/tiernanotoole  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8o17n/should_i_worry_about_the_temps_and_humidity_the/",
          "publishedOn": "2022-11-30T10:25:00.000Z",
          "wordCount": 16788,
          "title": "should I worry about the temps and humidity? The shed converted to a server room... maybe a little too much ventilation?",
          "imageUrl": "https://preview.redd.it/tnj4gmone23a1.png?auto=webp&s=a659897360e29d9237df87fab0b21654bad7554f"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8n139/dumb_question_but_do_you_guys_use_vpns_for/",
          "author": null,
          "description": "View Poll\n    submitted by    /u/dibra4life  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8n139/dumb_question_but_do_you_guys_use_vpns_for/",
          "publishedOn": "2022-11-30T09:27:08.000Z",
          "wordCount": 16558,
          "title": "Dumb question but do you guys use VPNs for torrenting (linux ISOs ofc)? I never see a VPN instance in your dashboards. Do you somehow integrate it within qBitTorrent, system wide or at router level?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8lq8h/this_is_going_to_get_out_of_hand_very_quickly/",
          "author": null,
          "description": "submitted by    /u/4538alex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8lq8h/this_is_going_to_get_out_of_hand_very_quickly/",
          "publishedOn": "2022-11-30T08:10:23.000Z",
          "wordCount": 15956,
          "title": "This is going to get out of hand very quickly…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8kcod/time_for_me_to_jump_on_the_train_my_current_setup/",
          "author": null,
          "description": "TP-Link TL-SG108E switch, Hue Bridge, ThinkCentre M73q Tiny running Proxmox, Synology DS220j NAS with 2x 4 TB (RAID 1), Canon LBP226dw Printer. Not in the photo: TP-Link RE655 for wireless connection to the Fritzbox, TP-Link TL-SG105E at my desk.\n    submitted by    /u/mrln_bllmnn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8kcod/time_for_me_to_jump_on_the_train_my_current_setup/",
          "publishedOn": "2022-11-30T06:58:39.000Z",
          "wordCount": 16205,
          "title": "Time for me to jump on the Train. My current Setup.",
          "imageUrl": "https://preview.redd.it/kjm5eoahv23a1.jpg?auto=webp&s=a19324e1816427f584218ab79b2f1e2cfba0d3e7"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8i6nq/dormlab_update_ended_up_just_going_with_debian/",
          "author": null,
          "description": "submitted by    /u/i_lost_my_bagel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8i6nq/dormlab_update_ended_up_just_going_with_debian/",
          "publishedOn": "2022-11-30T05:12:20.000Z",
          "wordCount": 16270,
          "title": "Dormlab Update: Ended up just going with Debian. Here's what I have setup so far.",
          "imageUrl": "https://preview.redd.it/0z31ewpvu03a1.png?auto=webp&s=307760ad964ad6ca9c06cbdd8f25b7d9e50ffd2b"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8btvd/dual_sfp_module_recommendations/",
          "author": null,
          "description": "I realize this questions gets thrown around a lot, but here I am asking again as I wasn't happy with the specifics per the other posts I came across. Perhaps a sticky/reference list of all the more common SFP+ modules, their release date, compatability with things like ESXi, general performance expecations, costs, ect.\n In my particular case, I've got a new R450 that I'll be using with Hyper-V on a slightly older T440 Hyper-V host. I'd like to setup replication between them and the backups we are creating could also use some wider bandwidth than 1gb NICs (no LAG, avoiding it). The new R450 came with a Broadcom dual SFP+. I'd be using 1 SFP+ via a DAC back to our UniFi Pro switch and I was thinking of creating a direct connection between the two hosts with SFP+ and a DAC cable. Making this purely for replication of our multiple VMs and virtual workstations, preventing this traffic from even having to touch our switches.\n The Intel x520-DA2 all seem long in the tooth and picky about modules, and the newer x710 even more so. Is there another solid option for dual SFP+ modules that play nice with Dell Servers (T440)?\n    submitted by    /u/Pr0t0c01s  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8btvd/dual_sfp_module_recommendations/",
          "publishedOn": "2022-11-30T00:43:54.000Z",
          "wordCount": 15385,
          "title": "Dual SFP+ Module Recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8bnq5/looking_for_a_specific_switch/",
          "author": null,
          "description": "Hi There,\n I've just gone through some of the switch reccomendation threads and Wiki but wasn't able to find something to suit my specific needs. I'm after a switch with the following:\n ​\n  \n24 Ports\n Ability to Create VLANs\n Some (or all) PoE ports\n 10 gb SFP ports would be nice but not necessary\n Relatively Quiet/Low Power (as quiet/low power a switch with these needs could be)\n  \n​\n Thanks\n    submitted by    /u/luigi123mad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8bnq5/looking_for_a_specific_switch/",
          "publishedOn": "2022-11-30T00:37:00.000Z",
          "wordCount": 14908,
          "title": "Looking for a specific Switch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8bif4/my_dell_r720_home_server_journey_so_far_and_where/",
          "author": null,
          "description": "Hi everyone,\n I recently picked up a Dell R720 on trademe (New Zealand website). It's got:\n 2x E5-2630v2, 128GB DDR3, 8x 3.5\", Perc H310 Mini, and an idrac express.\n So, overkill for home use, but hey, why not right!?\n ​\n So first I'm going ot make sure I'm all up do date with the firmware and things. Anything else I should do before getting started (like upgrading to a certain level of firmware and not all the way?)\n ​\n After that is done, on to installing more hardware. So far I've got 2x 8TB Ironwolfs and 6x 2TB Dell Enterprise drives to go in the front. Was thinking I'd make one raidz2 of the 6x 2TB drives for the data storage and home backups (and use something like backblaze or google archive for offsite backup of this) and then for the two 8TB, just leave as two disks for media use for plex (don't mind if i lose media, can always redownload (1GB connection FTW!)).\n ​\n As for the OS and LXCs and VMs, since all the front bay drives will be full, I'm thinking I'll order in 2x Samsung 980 250GB and 2x PCIe nvme adapter cards. Hopefully I can use the clover bootloader method to boot off of a internal USB stick that points to the mirrored nvme cards(?)\n ​\n From there I'm thinking I'll use proxmox as my base OS and have a bunch of LXC and VMs. Currently looking to hadware pass the drives to TrueNAS and have that be the main arbiter of disk space. Any ideas if this is a good way to go? \n ​\n I'll also be installing your usual home media things: Plex, Sonarr, Jackett, Deluge, etc.\n ​\n Along with some things like pihole, are there any other great bits of kit I should be looking at installing? Will look at getting a server nVidia GFX card for transcoding/mining/stable diffusion etc. Any ones I should look for/stay away from?\n    submitted by    /u/Fienx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z8bif4/my_dell_r720_home_server_journey_so_far_and_where/",
          "publishedOn": "2022-11-30T00:31:10.000Z",
          "wordCount": 16369,
          "title": "My Dell R720 Home Server Journey So Far And Where To Go...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z8a4wx/project_idea_but_i_dont_know_where_to_start/",
          "author": null,
          "description": "Hi everyone! I have a project I want to get into but mentioned in the title, I have absolutely nowhere to start. I'm new to hypervisors/vms but I'd love to experiment with it. Any resources would be great!\n I want to turn my entire desktop into a hypervisor. No bare metal installs. My current desktop right now is a regular bare metal Linux install and I use libvirt with a dedicated GPU and NVME drive passed through to run Windows 11 with Looking Glass and I can do a BIOS boot override to run that nvme bare metal for specific games if needed, but I've been itching to learn more about hypervisors and want to pursue the idea of running absolutely everything virtualized. For Windows bare metal I plan to get a fast USB3 portable drive running Ventoy with a Windows 11 VHD in it so that won't be …",
          "link": "https://www.reddit.com/r/homelab/comments/z8a4wx/project_idea_but_i_dont_know_where_to_start/",
          "publishedOn": "2022-11-29T23:37:43.000Z",
          "wordCount": 16313,
          "title": "Project idea but I don't know where to start.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z89l8j/intel_i913900k_24core_pe_cores_and_esxi_homelab/",
          "author": null,
          "description": "Hi, i want to setup a esxi homelab do any one know how esxi will handle scheduling of P and E cores? I guess is like normal cores as esxi dont understand p and e cores. so if a VM has 2 vcpus, some times it will be schedule in 2P cores, others 2E cores and some times 1P and 1E cores? is there any problem with this for the stability of the VM or any other issue apart than when it gets the E cores they will run more slow? what happen with windows server and linux that dont support E cores when they get scheduled with 2 E cores or 1P and 1e?\n    submitted by    /u/Stunning_Art4243  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z89l8j/intel_i913900k_24core_pe_cores_and_esxi_homelab/",
          "publishedOn": "2022-11-29T23:17:12.000Z",
          "wordCount": 15210,
          "title": "Intel i9-13900K 24-core p+E cores and esxi homelab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z89ikb/arubas250048pus_10g_sfp_rj45_80m_compatibility/",
          "author": null,
          "description": "I have an Aruba S2500 switch that I love, and I recently moved and had Cat6A run through the entire house. I'm trying to get 10Gb from my main desktop to my server rack in the basement. I've gone through three 10Gb SFP+ RJ45 transceivers. Brands like Fiber Mall, Ipolex and Hi Fiber. I realized after the Hi Fiber (which works from Server to switch on a 15ft run) that I needed an 80m transceiver. Fiber Mall and Ipolex did not work at all, it didn't even light up the in the spf+ port when I connected my cable from my patch panel to the RJ45 transceiver. The Hi Fiber did light up but it was stuck at 1Gb, not 10Gb. For NICs in my gaming rig I have a TP Link TX401 and I tried the X520-T2 both resulted in just 1Gb.\n ​\n Any help is greatly appreciated.\n    submitted by    /u/RevitXman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z89ikb/arubas250048pus_10g_sfp_rj45_80m_compatibility/",
          "publishedOn": "2022-11-29T23:14:17.000Z",
          "wordCount": 15520,
          "title": "ArubaS2500-48P-US 10G SFP+ RJ45 80m Compatibility",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z89co3/replacing_usg3_can_i_make_use_the_hardware_some/",
          "author": null,
          "description": "This winter, I'll be replacing my USG-3 with a UDM Pro. I'm sure I could sell it, but is there anything I can do with this hardware? Can I run Pi-hole or adguard directly on it? Or is there anything else that might be worth having on a dedicated box? Once I have it's replacement setup, I'll probably do some experimenting anyway, but curious to hear if anyone here has any thoughts?\n    submitted by    /u/autoneub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z89co3/replacing_usg3_can_i_make_use_the_hardware_some/",
          "publishedOn": "2022-11-29T23:07:50.000Z",
          "wordCount": 15350,
          "title": "Replacing USG-3. Can I make use the hardware some other way?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z88pvc/what_are_the_bestaffordable_sfp_10gb_cables_in/",
          "author": null,
          "description": "Amazon, eBay? What to look for? Are there cheap cables that I should be aware of?\n For information my setup is the following:\n  \nI'm using a TP-Link TL-SG3428XMP Ethernet Switch\n Server has Dell 068M95 Quad-Port 10GB SFP+ Network Daughter Card\n I want to equip 2 work computers with Mellanox MCX311A-XCAT ConnectX-3 EN 10G Ethernet 10GbE SFP+ PCIe NIC\n  \nMy goal is to have all these equipment communicate to each other as fast as possible. \n Thank you for helping, this is my first build, any advice is welcome!\n    submitted by    /u/igmyeongui  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z88pvc/what_are_the_bestaffordable_sfp_10gb_cables_in/",
          "publishedOn": "2022-11-29T22:44:07.000Z",
          "wordCount": 15010,
          "title": "What are the Best/Affordable SFP+ 10Gb cables in Canada?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z88in1/iscsi_boot_xcpng/",
          "author": null,
          "description": "Hey all,\n I have a PowerEdge M630 that I'm trying to install and boot XCP-NG from iSCSI on. It looks like XCP-NG doesn't support software iSCSI boot, and I have to use an iSCSI HBA. My M630 has a QLogic converged NIC with BCM57810 which according to this document has \"Offloaded full HBA functionality iSCSI initiator\". To me that means I should be able to mount a target and have it visible to the OS for install. (Maybe I'm wrong here?) I have configured the card in BIOS, and sometimes I can see the card connect to the target, sometimes it doesn't. Anytime it tries it says the connection succeeded though. Does this chipset need drivers installed for it to be visible to XCP-NG? Or should it just work? Furthermore, am I misunderstanding something / going about this incorrectly?\n ​\n Thanks!\n    submitted by    /u/jmarmorato1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z88in1/iscsi_boot_xcpng/",
          "publishedOn": "2022-11-29T22:36:16.000Z",
          "wordCount": 15543,
          "title": "iSCSI boot XCP-NG",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z87sri/shallow_depth_rack_casechassis/",
          "author": null,
          "description": "Apologies in advance if I missed a section in the hardware FAQs -\n I am designing a small home lab on a rack-mount server that supports 10-20 VM workloads (TrueNAS, pfSense, Plex, handful of others, plus some headroom to mess around). I need minimum 8 3.5\" HDD bays for my NAS, though 12 would be ideal. As for the other equipment, I plan to use an unmanaged network switch and a UPS with a maximum depth of about 16 inches.\n When I look around for rack-mount PC cases or chassis, most of them are at least 27 inches deep, which would extend the overall footprint of the rack by quite a bit. I am aiming for low power consumption and don't need a ton of VMs, so I am considering a microATX motherboard or similar small footprint. I see a handful of shallow-depth chassis or cases out there but none of them seem have enough HDD bays.\n My question is: Are there any shallow depth rack cases/chassis out there with at least 8 HDD bays? I don't mind going with a 4U or even taller system if it allows me to arrange the drives vertically above the mobo. My main goal is to reduce the floor footprint. Thanks!\n    submitted by    /u/me-wave  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z87sri/shallow_depth_rack_casechassis/",
          "publishedOn": "2022-11-29T22:08:33.000Z",
          "wordCount": 15394,
          "title": "Shallow depth rack case/chassis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z86o6a/after_a_4_month_wait_finally/",
          "author": null,
          "description": "submitted by    /u/nyevv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z86o6a/after_a_4_month_wait_finally/",
          "publishedOn": "2022-11-29T21:24:41.000Z",
          "wordCount": 15066,
          "title": "After a 4 month wait, finally!",
          "imageUrl": "https://external-preview.redd.it/znHxexCt6-u0DcvFVQ1oMFE2qvNtFZBS-9rHgpLDF3A.jpg?auto=webp&s=304d54a6c2f8c0fdba0d01a034ee5f1cbdee3cd6"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z86mu3/ups_batteries/",
          "author": null,
          "description": "One of my rack 1500 apc is bitching about how the batteries are nearing the end of their lives. Who should I buy replacement batteries from for cheap?\n    submitted by    /u/Squanchy2112  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z86mu3/ups_batteries/",
          "publishedOn": "2022-11-29T21:23:14.000Z",
          "wordCount": 15544,
          "title": "Ups batteries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z862en/nvidia_tesla_m40_24gb_driver_issues/",
          "author": null,
          "description": "Hey, maybe someone can help me here. I've got a Nvidia Tesla M40 24GB Today and tried to install it on a Supermicro X10SLL-F Motherboard.\n Sadly event though the card is detected and as far as I can tell, correctly displayed in lspci the driver cannot initialize it. \n lspci output:\n 00:00.0 Host bridge: Intel Corporation Xeon E3-1200 v3 Processor DRAM Controller (rev 06) 00:01.0 PCI bridge: Intel Corporation Xeon E3-1200 v3/4th Gen Core Processor PCI Express x16 Controller (rev 06) 00:14.0 USB controller: Intel Corporation 8 Series/C220 Series Chipset Family USB xHCI (rev 05) 00:19.0 Ethernet controller: Intel Corporation 82579LM Gigabit Network Connection (Lewisville) (rev 05) 00:1a.0 USB controller: Intel Corporation 8 Series/C220 Series Chipset Family USB EHCI #2 (rev 05) 00:1c.0 PCI br…",
          "link": "https://www.reddit.com/r/homelab/comments/z862en/nvidia_tesla_m40_24gb_driver_issues/",
          "publishedOn": "2022-11-29T21:02:13.000Z",
          "wordCount": 16343,
          "title": "Nvidia TESLA M40 24GB Driver Issues",
          "imageUrl": "https://external-preview.redd.it/gzVOBlNe4Zou1hw9qoEi78Ws5E9-uzQhQNkZViCr4NA.jpg?auto=webp&s=6764945d2258fa0e61c78664eb0ddda326770515"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z859vf/carlab_battery_powered_lab_for_camping/",
          "author": null,
          "description": "I have a small homelab, and am thinking of dropping it at my parents house and remoting in when required. Setting up backups to automate etc. but has anyone every made a CarLab for car camping?\n My guess would be using old laptops? Most of the use would be for TV shows and music for most people, but I also run a business that requires streaming video meetings. I suppose a Starlink would be required, and as it is finally covering most of Australia it has to be an option, esp as 5G is nowhere near ready for proper use yet.\n Any other suggestions or directions towards websites where someone has already tried this?\n Thanks.\n    submitted by    /u/capt_zen_petabyte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z859vf/carlab_battery_powered_lab_for_camping/",
          "publishedOn": "2022-11-29T20:33:57.000Z",
          "wordCount": 15960,
          "title": "Carlab? Battery powered 'lab' for camping?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z820l4/out_with_the_old_and_in_with_the_old_a_boring/",
          "author": null,
          "description": "With my monthly energy cost nearly matching my rent, the weekend just passed was used to completely realign the chi of my home lab;\n ​\n  \nInspect and clean all hardware , some disturbing sights were seen in places I would't have assumed would collect much dust (roof of HDD cages, not in direct air flow... seems this case may have had unknown negative pressure https://i.imgur.com/rsGFTuk.jpg ). Some of these systems have seen 1year+ uptime between reboots.\n To consolidate running services into less physical metal servers to save on 24/7 running costs\n Move on demand software to a dedicated App server\n Move all 24/7 services to a single 24/7 machine\n  \n​\n What was actually achieved :\n  \nRetired server (Intel i7-950 / 32GB DDR3 / 9x 2TB WD Green & 2x 250GB 850evo) ~4units/day https://i.imgur.…",
          "link": "https://www.reddit.com/r/homelab/comments/z820l4/out_with_the_old_and_in_with_the_old_a_boring/",
          "publishedOn": "2022-11-29T18:34:29.000Z",
          "wordCount": 16478,
          "title": "Out with the old and in with the old (a boring post about consolidation due to energy costs in UK)",
          "imageUrl": "https://external-preview.redd.it/kdYX49Q-jY-kN8Ytixk_-Fse2CFWx2nZbAICgcUhmY8.jpg?auto=webp&s=548e0626ff86bf8df03a68cd03d38e79bbdee710"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z81wmj/how_to_reduce_noise_of_an_online_apc_ups/",
          "author": null,
          "description": "I recently got a 2200VA Online APC UPS, SRT2200XLA, and it's loud. I hear the transformer and fan noise, and I assume it's on all the time because it's an online UPS.\n Does anyone have any tips to reduce the noise overall? I assume there is nothing I can do about the transformer screeching, but maybe I can replace the built-in fans with quieter Noctua ones?\n Any help would be appreciated. Thanks!\n    submitted by    /u/MystK  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z81wmj/how_to_reduce_noise_of_an_online_apc_ups/",
          "publishedOn": "2022-11-29T18:30:34.000Z",
          "wordCount": 17218,
          "title": "How to reduce noise of an online APC UPS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7wt5y/needed_a_cabinet_for_my_very_first_server_yup/",
          "author": null,
          "description": "submitted by    /u/Zeravnos-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7wt5y/needed_a_cabinet_for_my_very_first_server_yup/",
          "publishedOn": "2022-11-29T15:16:42.000Z",
          "wordCount": 16526,
          "title": "Needed a cabinet for my very first server. Yup. That'll do.",
          "imageUrl": "https://preview.redd.it/9y41kfqupw2a1.png?auto=webp&s=4e0fc8a2c00626e5fbe619d03ac47d82e0ded60c"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7tz4b/what_to_do_with_6_low_power_blades/",
          "author": null,
          "description": "submitted by    /u/lukepetrovici  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7tz4b/what_to_do_with_6_low_power_blades/",
          "publishedOn": "2022-11-29T13:23:25.000Z",
          "wordCount": 16705,
          "title": "What to do with 6 low power “blades”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7r4xb/the_initial_construction_of_home_lab/",
          "author": null,
          "description": "My english is not very good, first of all sorry for the possible crappy mechanical translation.\n Exterior\n After several months of study, I finally completed the construction of my own homelab, and I can use it to do interesting things. Please allow me to proudly introduce the hardware and some details\n cable\n The cabinet comes from the inventory of the local communication company. There is even an independent air duct inside the cabinet, and the fan module can independently dissipate heat from the upper and lower spaces. (Awesome) \n The cabinet doors come across ground wires, the only downside might be the depthIt’s just that the choice of equipment will be limited in this way, and enterprise-level servers and ultra-deep switches can’t be stuffed in (all in the basement)When deploying the…",
          "link": "https://www.reddit.com/r/homelab/comments/z7r4xb/the_initial_construction_of_home_lab/",
          "publishedOn": "2022-11-29T11:13:13.000Z",
          "wordCount": 16753,
          "title": "The initial construction of home lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7m62o/sharing_setups_seems_to_be_the_cool_thing_around/",
          "author": null,
          "description": "submitted by    /u/Berzerker7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7m62o/sharing_setups_seems_to_be_the_cool_thing_around/",
          "publishedOn": "2022-11-29T06:52:30.000Z",
          "wordCount": 16885,
          "title": "Sharing setups seems to be the cool thing around here",
          "imageUrl": "https://preview.redd.it/yene2fid6u2a1.jpg?auto=webp&s=2b13c5c15ecc4cc025e46e18aef6b01d9cec7e55"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7gix1/my_endgame_for_a_bit_until_i_rip_and_replace/",
          "author": null,
          "description": "submitted by    /u/realcrankysysadmin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7gix1/my_endgame_for_a_bit_until_i_rip_and_replace/",
          "publishedOn": "2022-11-29T02:20:39.000Z",
          "wordCount": 16238,
          "title": "My endgame for a bit until I rip and replace those switches.",
          "imageUrl": "https://external-preview.redd.it/b5pjH9eTliCxBAjOx5KwQmc1KvJu_yKMzRklfAh_fWk.jpg?auto=webp&s=d2972d3ef45dede1f8089f46e201d80fd7ee4316"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7f2w6/advice_about_setting_up_a_network_with_two/",
          "author": null,
          "description": "Hi there. I have had 2 different lab setups I did in the past at home. However I have never really done anything involving switches... it was always tinkering with and connecting up DD-WRT flashed routers and really old computers I had acquired when I was doing computer repair. We have an issue at the small office of 7 employees that I was hoping I could receive some help on. This may not be appropriate to ask here, but /r/networking seemed like it was more of a place for enterprise level stuff, and this subreddit seems to be a place for home networking. My problem falls kinda in between. \n At my new job we have a bit of a mess in terms of a \"network\"... Lots of ethernet cables ran all over the building to offices that aren't used anymore. We have 2 people using USB Wifi Dongles to connect wireless to the router and the rest of the computers are hardwired between two switches. We also have an old server that is not being utilized. Folks that are hardwired to the switches can't Samba share to anyone not hooked up to the same switch. \n I have a network cable tester and tracer coming in the mail Thursday. I figure that is probably step 1 in trying to find out what is going on since nothing is labeled anywhere. What I'm hoping to achieve is to do minimal wire runs and configuration to allow for all of us in the office to be able to communicate via Samba and set up a way for automatic backups to be done on the old server that is not in use.\n It seems to me that connecting the switches together through a simple configuration might would solve these problems. A very basic overview of networking basics seems like where I need to start. I'm hoping to not have to dive too deep and eat up too much time. If anyone has a good link or resource for me, it would be greatly appreciated.\n    submitted by    /u/CountryFriedAlive  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7f2w6/advice_about_setting_up_a_network_with_two/",
          "publishedOn": "2022-11-29T01:17:42.000Z",
          "wordCount": 15614,
          "title": "Advice about setting up a network with two switches and a router.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7f1nh/hunting_for_rails/",
          "author": null,
          "description": "Hey all, trying to source some rails for a HP 5406zl (J8697A). Got it from work a while back and its been gathering dust, finally got it dusted off and updated the firmware on the unit so I figured I would mount it but all the mounting kits for it seem to be several hundred dollars.\n    submitted by    /u/Valius11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7f1nh/hunting_for_rails/",
          "publishedOn": "2022-11-29T01:16:12.000Z",
          "wordCount": 14826,
          "title": "Hunting for rails",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7ey4w/dell_r720_embedded_video_disabled_with_with_an/",
          "author": null,
          "description": "Hello home labbers, I made the mistake of putting my quadro p400 and disabling the embedded video. Is there a way I can reset it with out doing a full factory reset?\n    submitted by    /u/idk12345678998  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7ey4w/dell_r720_embedded_video_disabled_with_with_an/",
          "publishedOn": "2022-11-29T01:11:54.000Z",
          "wordCount": 14806,
          "title": "Dell R720 embedded video disabled with with an incompatible gpu.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7eibg/how_to_monitor_health_of_bios_configured_raid/",
          "author": null,
          "description": "I have an MSI 490i board that I’ve setup a raid 1 via the bios on the board. When I had windows installed on the boot drive, I could install the Intel rapid storage software and it would alert me if one of the discs was dead or dying.\n I’ve switched to TrueNAS and I’m not familiar with how to do this. Is there any similar way or should I be using a different method of setting up a raid?\n    submitted by    /u/Dense-Entertainer-48  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7eibg/how_to_monitor_health_of_bios_configured_raid/",
          "publishedOn": "2022-11-29T00:52:41.000Z",
          "wordCount": 14617,
          "title": "How to monitor health of bios configured raid?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7dsdz/setting_up_a_backup_internet_connection_with/",
          "author": null,
          "description": "submitted by    /u/grumpy-systems  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7dsdz/setting_up_a_backup_internet_connection_with/",
          "publishedOn": "2022-11-29T00:21:48.000Z",
          "wordCount": 14736,
          "title": "Setting Up A Backup Internet Connection With OPNSense",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7d6a8/proxmox_arc_a380_passthrough_jellyfin_hardware/",
          "author": null,
          "description": "Managed to get HW transcoding working for Jellyfin in an Ubuntu VM on Proxmox 7.2.\n My hardware:\n Ryzen 5 2600\n 32GB DDR4-3000 MHz\n ASRock Challenger Arc A380 6GB\n ASRock DeskMeet X300\n ​\n YMMV. This is definitely a hacky solution.\n First time doing anything with hardware acceleration in jellyfin and with the Arc A380 in general, so while I can try to answer questions, I probably don't know much. \n ​\n GPU Passthrough\n First I added the card to the VM following the instructions at https://pve.proxmox.com/wiki/Pci_passthrough\n  \nEnable IOMMU\n nano /etc/default/grub\n \n Find the line GRUB_CMDLINE_LINUX_DEFAULT and add amd_iommu=on or intel_iommu=on for AMD or Intel CPUs respectively\n In my case, this ended up looking like: \n GRUB_CMDLINE_LINUX_DEFAULT=\"quiet amd_iommu=on\" \n Save the changes to…",
          "link": "https://www.reddit.com/r/homelab/comments/z7d6a8/proxmox_arc_a380_passthrough_jellyfin_hardware/",
          "publishedOn": "2022-11-28T23:57:42.000Z",
          "wordCount": 16457,
          "title": "Proxmox Arc A380 Passthrough + Jellyfin Hardware Transcoding",
          "imageUrl": "https://external-preview.redd.it/8W3fiEhGdtr_YQV23-m8BEnPIgaTxqoy5BfvkTM4ggw.jpg?auto=webp&s=1da2aa741cff755d12bc1f270587922f274d4b03"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7cscl/cheap_wifi_doorbell/",
          "author": null,
          "description": "What's the cheapest useable wifi doorbell? I have a garage nextdoor that I want to put a doorbell camera on just to see what's going on if anything. I have a alarm on the door but wouldn't mind having a doorbell camera to see what is going on if anything were to happen.\n    submitted by    /u/Expensive-Vanilla-16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7cscl/cheap_wifi_doorbell/",
          "publishedOn": "2022-11-28T23:42:51.000Z",
          "wordCount": 15038,
          "title": "Cheap wifi doorbell",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7cfce/i_guess_its_sharing_time/",
          "author": null,
          "description": "submitted by    /u/RemarkablePenalty550  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7cfce/i_guess_its_sharing_time/",
          "publishedOn": "2022-11-28T23:28:55.000Z",
          "wordCount": 15385,
          "title": "I guess it's sharing time",
          "imageUrl": "https://preview.redd.it/8kwv7k6ait2a1.jpg?auto=webp&s=991698947fb75af34be94d08b20e02b6f95e3ecf"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z79za8/any_german_home_lab_users_with_vodafone/",
          "author": null,
          "description": "I'm with Vodephone and have the 1gb/s internet wither proprietary sh$$ box.\n After research and many calls with my lovely German wife (who helped translate) we were able to get the Sh$$ box into bridge mode.\n I Currently am running OPNsense on a Fujitsu thin client and love the functionality and security it provides for my homelab.\n My problem is that the internet just sh$$s the bed sometimes, and I'm uncertain whether it's me or Vodafone. Sometime ill have a stable version I get working and then all of a sudden, internet just stops working or drops out.\n We called them, and they says there is nothing they can do and intend to improve my network where I am, but give no time frame. I also get no help configuring some setting that I need from the ISP for my OPNsense and need to find German forums of people who have figured out what setting work for them.\n Now, as tech-savvy as I am, I'm also learning with the whole dualstack configuration. Should I just give up and get this Fritzbox? Will this solve my issues, or is this just a German infrastructure thing that won't fix itself?\n I'm just searching for some advice from people who run home labs and such in Germany, specifically ex unity media customers.\n    submitted by    /u/Ebullient_Dino  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z79za8/any_german_home_lab_users_with_vodafone/",
          "publishedOn": "2022-11-28T21:58:29.000Z",
          "wordCount": 16512,
          "title": "Any German Home Lab users with Vodafone (unitymedia). I'm about to lose my mind.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z79uq1/sfp_pcie_card_vs_sfp_rj45_module/",
          "author": null,
          "description": "Which one would be more desirable? Is there any advantages of one vs the other in terms of price, modularity? I currently only have a 2.5Gbps network card in my server, and I have an unused SFP+ port in my router, so as I see it I have two options:\n Buy an SFP+ PCIe card to go in my server, and connect via DAC cable to the router\n or\n Buy an SFP+ RJ45 1/2.5/5/10 Gbps module, plug it to my server via a regular properly rated ethernet cable. I wouldn't upgrade to a 10 gig nic in this case (not immediately).\n On one side I like the idea of having the DAC connection but have no idea if I actually currently need the bandwidth between the server and my proxmox cluster (4 machines). On the other hand I like the fact that, if I want, I can plug the RJ45 cable to any client that doesn't have the SFP+ module as well.\n Thoughts?\n    submitted by    /u/manjerico  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z79uq1/sfp_pcie_card_vs_sfp_rj45_module/",
          "publishedOn": "2022-11-28T21:53:56.000Z",
          "wordCount": 15109,
          "title": "SFP+ PCIe Card vs. SFP+ RJ45 module",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z79jji/storage_array_chassis_options/",
          "author": null,
          "description": "Hey all,\n I've been running old HDDs for a while now on a Chembro chassis (SAS2-compatible) that can take 24x regular 3.5\" disks. Since it came later, I never bothered with moving my system onto the Chembro, so the chassis is only being used for disks, and a different chassis hosts the system, which is connected to the disks via an external SAS cable. \n Things have been working alright, but now I want to expand. I've been eying a Supermicro SC847 chassis with capacity for 36 disks. I'll likely replace the 24-disk chassis with this one. I could also look into moving the system onto this same chassis, but I'm concerned about heat. If I were to keep the disks separate, is a chassis like the 847 the best solution? Are there any \"disk only\" chassis out there that would allow me to connect my system to this array? What are people using these days?\n Thanks!\n    submitted by    /u/anywhoever  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z79jji/storage_array_chassis_options/",
          "publishedOn": "2022-11-28T21:42:32.000Z",
          "wordCount": 15494,
          "title": "Storage array chassis options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z79aq1/i_need_to_rack_2_gamingstreaming_computers_any/",
          "author": null,
          "description": "submitted by    /u/igmyeongui  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z79aq1/i_need_to_rack_2_gamingstreaming_computers_any/",
          "publishedOn": "2022-11-28T21:33:46.000Z",
          "wordCount": 15038,
          "title": "I need to rack 2 gaming/streaming computers. Any recommendations for an affordable case that isn't crap and must be available in Canada!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z78y03/what_type_of_access_points_are_these_seen_these/",
          "author": null,
          "description": "submitted by    /u/TaskCreepy1661  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z78y03/what_type_of_access_points_are_these_seen_these/",
          "publishedOn": "2022-11-28T21:21:10.000Z",
          "wordCount": 15669,
          "title": "What type of access points are these? Seen these at topgolf. Couldn’t figure out what brand they were. Anyone know?",
          "imageUrl": "https://preview.redd.it/v55y46rjvs2a1.jpg?auto=webp&s=ac1bc02c807a4713e6e5ad3a93c45dde23e0128a"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z78v7r/just_getting_into_homelab/",
          "author": null,
          "description": "submitted by    /u/General_Lab_4475  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z78v7r/just_getting_into_homelab/",
          "publishedOn": "2022-11-28T21:18:30.000Z",
          "wordCount": 15240,
          "title": "Just getting into homelab.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z77ipx/good_switch_recommendations/",
          "author": null,
          "description": "I am looking to move away from Ubiquiti gear for everything except APs. Want to get into some more advanced networking. I'm already setting up OPNSense on a spare dell R210ii I have lying around. I need a good switch to pair with it to go in the rack. Here are my requirements:\n At least 4 SFP+ ports.\n A few GbE ports (Preferrably PoE)\n Ability to configure VLANs.\n Rackmount\n Any good recommendations?\n    submitted by    /u/drakestraid01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z77ipx/good_switch_recommendations/",
          "publishedOn": "2022-11-28T20:30:15.000Z",
          "wordCount": 15252,
          "title": "Good Switch Recommendations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z76j9e/this_is_my_home_network_cabinet_there_are_rack/",
          "author": null,
          "description": "submitted by    /u/GalacticLion7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z76j9e/this_is_my_home_network_cabinet_there_are_rack/",
          "publishedOn": "2022-11-28T19:54:59.000Z",
          "wordCount": 15425,
          "title": "This is my home network cabinet. There are rack rails, but the whole cabinet seems too shallow to fit any rack-mountable switch or server. How do I utilize this space? Sorry for the cable mess; am renovating.",
          "imageUrl": "https://preview.redd.it/2rxuzl75gs2a1.jpg?auto=webp&s=183f035ea3a3bee573011ed959b08125510d3e41"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z7658i/childhood_dream_fulfilled_sorta/",
          "author": null,
          "description": "A computer geek since birth, a dream since childhood has been to own a CRAY SUPERCOMPUTER!(dramatic keyboard strike) While kinda fudging the definition, it is Cray branded equipment. The picture is old, but this post is motivation for me to get the setup photoshoot ready.\n The stack consists of:\n Cray Green blade SR5110 5U blade enclosure with 10 GB512x blades. Each blade has: Motherboard: Intel S2600JF CPU: dual E5-2630L V2 OS: last running oVirt, considering OpenStack next PSU: 2xAC 2x48vdc\n Chassis: SuperMicro SC826E16 2u with 12lff bays + 2sff rear bays Motherboard: X9SRH-7F CPU: Xeon E5-1650 v2 cpu PSU: 1xAC 1x48vdc OS: TrueNAS Scale Storage: 2x1TB sff mirror boot 2x3TB lff mirror 10x5TB lff Raid Z1 40TB useable 58TB raw\n Chassis: SuperMicro CSE-847 4u 36 lff bay Motherboard: Tyan S5512 pulled from a HYVE-CYGNUS-J CPU: Xeon E3-1230 V2 PSU: 1xAC 1x48vdc OS: TrueNAS Scale Storage: whole mess of sata and sas drives\n Mellanox SX6036 36 port infiniband switch in Ethernet mode PSU: 2xAC \n Brocade ICX7250-48 with the PSU chopped out so it runs off 12vdc directly\n 8 Odroid HC2 arm sbc sata drive sleds Running Ubuntu 20.04 as gluster bricks 3x14TB 2x12TB 3x8TB For 90TB total Which all run off 12vdc\n All 12 vdc is fed from an AC power supply and a 48 to 12 vdc converter.\n So why all the DC? I also have a diy solar array and self built 48VDC lithium ion battery packs that directly feed this equipment, no need for an inverter.\n Glad to answer any questions. This post is to motivate me towards cleaning up and better documentation habits.\n    submitted by    /u/0B501337B33F  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z7658i/childhood_dream_fulfilled_sorta/",
          "publishedOn": "2022-11-28T19:40:21.000Z",
          "wordCount": 16183,
          "title": "Childhood dream fulfilled (sorta)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z73jg5/device_to_display_guest_wifi_password/",
          "author": null,
          "description": "Howdy all! I use Unifi as my network infrastructure, and through some libraries I've come up with a nice little web page that allows access to a QR Code for my guest wifi. \n Is anyone aware of an e-ink-based system (similar to rasbperry pi) that I might be able to hack together to always show the guest wifi code? I'd like to randomize it and change it often, but that's difficult in practice without being able to display it readily.\n My initial thought was to try to figure out something with the e-ink price tags at best buy, but they're designed to update by NFC, so I'd need to tap the device to my phone which defeats the purpose.\n Anyway, interested in thoughts...\n    submitted by    /u/JSylvia007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z73jg5/device_to_display_guest_wifi_password/",
          "publishedOn": "2022-11-28T18:06:16.000Z",
          "wordCount": 17426,
          "title": "Device to Display Guest WiFi Password",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6z6r8/ummso_i_watched_this_one_video_that_lead_to/",
          "author": null,
          "description": "Not really a lab but everyone starts somewhere? New to IT/networking and thought redoing my home network would be a great first project! After countless hours of videos and researchIng/learning this is my “rack”. \n Pfsense 2.6 on bare metal i5-7600k, Cisco Catalyst 1000, Cisco 240AV, CyberPower AVRG750U.\n    submitted by    /u/you_wut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6z6r8/ummso_i_watched_this_one_video_that_lead_to/",
          "publishedOn": "2022-11-28T15:19:44.000Z",
          "wordCount": 16138,
          "title": "Umm…so I watched this one video that lead to another..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6un2v/is_this_machine_usefull_for_proxmox/",
          "author": null,
          "description": "Hi all, I found this riverbed steelhead cxa-03070-b010 At work and I was wondering if I could use it for something like proxmox?\n    submitted by    /u/NoodleYankee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6un2v/is_this_machine_usefull_for_proxmox/",
          "publishedOn": "2022-11-28T11:56:31.000Z",
          "wordCount": 17394,
          "title": "Is this machine usefull for proxmox?",
          "imageUrl": "https://preview.redd.it/ftlbzjrs2q2a1.png?auto=webp&s=41339e0fa3b5ca4cfb69aafc2dcf59c227c52d47"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6t3o4/fail2ban_can_i_ban_it_from_router/",
          "author": null,
          "description": "the idea is simple.\n I open dummy ssh on port 22, if someone tries to connect I want to give IP ban on my router (pfSense, I may move to opnSense).\n In this case no other services can be probed. Is it possible to set it up without magic?\n    submitted by    /u/flaotte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6t3o4/fail2ban_can_i_ban_it_from_router/",
          "publishedOn": "2022-11-28T10:27:59.000Z",
          "wordCount": 17001,
          "title": "fail2ban, can I ban it from router?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6jvuo/what_is_this_used_for/",
          "author": null,
          "description": "submitted by    /u/denverblondy1972  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6jvuo/what_is_this_used_for/",
          "publishedOn": "2022-11-28T02:10:02.000Z",
          "wordCount": 16319,
          "title": "what is this used for?",
          "imageUrl": "https://preview.redd.it/rhog3iy56n2a1.jpg?auto=webp&s=5e68c665e1d032a242808c53838382a99d9fffa4"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6jd5p/help_frankensteining_a_cheap_nas/",
          "author": null,
          "description": "Hey homelab, I've recently needed some additional storage and thought it was time to hack together a NAS to last me a few years until I have the budget for something nicer. Digging into my spare parts box, I managed to find four 1 TB HDDs (two internal drives and two old externals that are not in use) as well as a Raspberry Pi 4 (8 GB). \n I was thinking of somehow connecting these together and have the Pi control them. Three of the drives would host media/documents and the fourth would work as a backup of just the most critical files. Should I set these in some sort of RAID array? \n In terms of hardware, I've seen some four-bay HDD enclosures/docks such as these: https://www.amazon.com/dp/B07G2WRB97\n https://www.amazon.com/dp/B08L7PSWV9\n https://www.amazon.com/dp/B00OUSU8MI\n Would this be sufficient for my needs and do I need to purchase anything else? Alternatively I have an old tower with a water-damaged motherboard that I could chuck everything into if that's a better option.\n My other questions were with regards to the OS. I'm really only looking to set up Jellyfin and Vaultwarden via Docker. Is it worth considering a NAS distro such as OMV or TrueNAS? Or should I just go with Raspbian and create a SMB share? It's only me using this and I don't plan to configure anything fancy so I'm leaning towards the latter...\n Appreciate any feedback and advice, thanks in advance!\n    submitted by    /u/AltruisticLoss1078  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6jd5p/help_frankensteining_a_cheap_nas/",
          "publishedOn": "2022-11-28T01:45:58.000Z",
          "wordCount": 14811,
          "title": "Help frankensteining a cheap NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6izgu/power_load_per_socket_uk/",
          "author": null,
          "description": "Hi, homelab newbie here\n I just (finally) decided to build my homelab and my question is about how safe it is to plug everything in the bedroom have allocated for this.\n The room has a total of 4 wall sockets.\n My hardware:\n  \n3 HP Z800 with 2 x 6c/12t, 96Gb, 3 HDD, 1 SSD and 1 x540-t2 card\n 1 HP Z820 with 2 x 8c/16t, 256Gb, 4 HDD, 1 SSD and 1 x540-t2 card\n 1 DELL T7600 with 2 x 8c/16t, 256Gb, 4 HDD, 1 SSD and 1 x540-t2 card\n 1 NAS (DIY) with 4c/8t i7, 32GB, 4 HDD, 1 SSD, 1 NVME and 1 x540-t2 card\n my workstation with 8c/16t, 64Gb, 2 x 1080ti, 1 SSD and 1 x540-t2 card\n 2 x 8 ports 10G-base-t switches\n  \nThis lab with be used a my personal cloud with Openstack, Proxmox, Ceph, OpnSense, Truenas. All this for Kubernetes mostly.\n Is that too much load for 2 sockets? As the other 2 are on the other side of the room or I should spread on the 4 of them? I’m just worried about fire risks.\n    submitted by    /u/anthonyperot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6izgu/power_load_per_socket_uk/",
          "publishedOn": "2022-11-28T01:28:52.000Z",
          "wordCount": 14696,
          "title": "Power load per socket (UK)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6im2i/honeypot_on_home_network_rate_my_security_plan_so/",
          "author": null,
          "description": "I want to run a honeypot on my home network and visualize the logs it collects for a personal project. I understand the risks, so before I open anything up to the internet, I want to come up with a plan that will maximize security given the situation. Here's my plan so far:\n  \nHoneypot is on its own piece of hardware (RPi, NUC, not sure yet)\n Honeypot is in a DMZ (router has an option for this, but from what I've gathered, it'd basically just be a single-firewall DMZ)\n Vulnerable apps/services/etc. would each run in their own Docker container, which would have AppArmor profiles configured for them based on their capabilities\n Instead of running on the honeypot host directly, all Docker containers containing vulnerable things would run in an LXC container (or possibly a VM, not sure which would be better)\n VM/LXC container would have an IDS to detect if anything escaped the Docker containers; host device would have an IDS to detect if anything escaped the VM/LXC container\n  \nWhat do you think of my plan so far? I'm a complete novice, so please let me know what can be improved and what you'd do differently or add.\n ​\n View Poll\n    submitted by    /u/bookooBux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6im2i/honeypot_on_home_network_rate_my_security_plan_so/",
          "publishedOn": "2022-11-28T01:12:09.000Z",
          "wordCount": 14838,
          "title": "Honeypot on home network, rate my security plan so far",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6gfoq/ps5_or_any_other_video_source_in_any_room/",
          "author": null,
          "description": "Ever want to let your kids play their game console in any room in the house? We needed to do this to allow some space flexibly for the family.\n Problem 1: Getting video from the PS5 in their game room to the TV in the livingroom. Pretty easily solved with Monoprice HDMI over IP encoder/decoders. Luckily I ran ethernet everywhere when we remodeled a few years ago. I can add additional decoders to other rooms.\n Problem 2: PlayStation consoles use Bluetooth for controller connectivity. Since these devices were designed to be used in the same room, the range isn’t all that great. This required pulling the case apart to install a pair of external antennas.\n NOTE: You do need hardwired Ethernet at any location where you are installing an encoder/decoder.\n All parts below. Maybe $130 total.\n Monoprice Blackbird H.265 HDMI... https://www.amazon.com/dp/B0BBRGNN1L?ref=ppx_pop_mob_ap_share\n Screwdriver for Playstation 4 &... https://www.amazon.com/dp/B07ZKLCSN5?ref=ppx_pop_mob_ap_share\n Bingfu Dual Band WiFi Antenna... https://www.amazon.com/dp/B099R3GR91?ref=ppx_pop_mob_ap_share\n Amazon Basics High-Speed HDMI... https://www.amazon.com/dp/B014I8SP4W?ref=ppx_pop_mob_ap_share\n Amazon Basics RJ45 Cat-6 Ethernet... https://www.amazon.com/dp/B00N2VISLW?ref=ppx_pop_mob_ap_share\n    submitted by    /u/DadCoachEngineer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6gfoq/ps5_or_any_other_video_source_in_any_room/",
          "publishedOn": "2022-11-27T23:36:41.000Z",
          "wordCount": 15201,
          "title": "PS5 (or any other video source) in any room",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6g70m/sowhat_do_you_use_as_a_hypervisor_in_your_home_lab/",
          "author": null,
          "description": "Me, been cycling through a couple of the usual suspects for years now. But I'm getting tired - been at this for almost 30 years - and am ready to hang up the hat, let the horse loose, and settle on the rocker....in other words, ready to stop tearing down and rebuilding the lab every few months with a new hypervisor. So, I'm kind of curious what you all use at home, and what you use to manage it. So far, been through:\n - ESX (Welcome to a new version! You know all that hardware you carefully curated to work with me? as of this release I now support none of it! Enjoy the upgrade!)\n - Hyper-V Server (You can create virtual machines after you domain join me. Oh...you have no domain? Ok, I can still work, once you set up constrained delegation....and the default client config doesn't work without modifications...and I no longer support the out-of-box cypher suites without several config settings...you sure you don't have a domain?)\n - ProxMox (Wanna buy a license? Wanna buy a license? How about a license? Hey, sexy mama...wanna buy a ProxMox license?)\n - OpenStack (Have you got 14 extra server chassis lying around? Good. Let's begin)\n - and KVM (Welcome to the command line! The default setup does almost but not quite what you, personally want. Enjoy these twenty copy/pasted blog posts and have fun with these command line tools with 400 different settings!)\n That was all fun for awhile, but I'm wanting to use my home lab and not just rebuild it endlessly (and yes, I wanted to rebuild it endlessly....that was part of the fun). So, I'm curious, all of you...what do you use day to day, and how much does the rest of what everyone else's choice suck? :)\n    submitted by    /u/Appropriate_Day2144  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6g70m/sowhat_do_you_use_as_a_hypervisor_in_your_home_lab/",
          "publishedOn": "2022-11-27T23:26:51.000Z",
          "wordCount": 19097,
          "title": "So...what do *you* use as a hypervisor in your home lab?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6fgnm/source_for_half_width_racks/",
          "author": null,
          "description": "Does anyone know where to get half width racks in Canada? Most of the options seem to be in Europe with few even available in the US let alone Canada.\n    submitted by    /u/fuzzynavelsniffer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6fgnm/source_for_half_width_racks/",
          "publishedOn": "2022-11-27T22:57:28.000Z",
          "wordCount": 14950,
          "title": "Source for half width racks?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6f3vh/ive_been_at_this_for_10_years_now_and_i_still/",
          "author": null,
          "description": "submitted by    /u/hardstyle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6f3vh/ive_been_at_this_for_10_years_now_and_i_still/",
          "publishedOn": "2022-11-27T22:43:10.000Z",
          "wordCount": 15252,
          "title": "I've been at this for 10 years now and I still have no idea what i'm doing.",
          "imageUrl": "https://external-preview.redd.it/ARNONy81VMjZwaLbcde7-2XjZ_2mqEnpgYEQUiXYsfU.jpg?auto=webp&s=d5a77c49b679acf29118cc7f604d9634c2527dcd"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6e2ou/backup_solution/",
          "author": null,
          "description": "Hi,\n is the following backup scenario kinda “overkill” for personal usage?\n  \nData is stored on a RAID10 (4 disks)\n Every day a backup gets created of the RAID10 - Backup gets stored on a RAID1 - same location\n Another backup gets created which has a different location. (RAID1)\n  \nDo you think the RAID1 setup is necessary or just “overkill”? \n Note: - RAID10 data pool size is 8TB (4x4TB) - RAID1 setup is also 8TB (2x 8TB) - Hardware price is ~1500€, too expensive? (Seagate IronWolf Pro)\n    submitted by    /u/HeyWatchOutDude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6e2ou/backup_solution/",
          "publishedOn": "2022-11-27T22:02:52.000Z",
          "wordCount": 15654,
          "title": "Backup solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6dp6l/first_time_homelab_setup_and_new_user/",
          "author": null,
          "description": "Hi everyone!\n After a friend recently moved away, and inheriting her homelab I was able to obtain:\n 25u Startech server rack\n Mikrotik CRS-317\n Mikrotik CSS-426\n Rack mounted application hosting server\n Rack mounted 36TB hosted storage\n Rack mounted Gaming PC\n Don't have all the specs written down, but it's a really good start for me.\n Things I'm looking to host:\n Proxmox\n Nginx Proxy Manager\n Heimdall\n Pterodactyl.io(game server host & manager)\n ???\n ------------------\n Any thoughts before I get too deep into trying to set things up?\n Currently using Cloudflare as a proxy for my public IP, and routing for subdomains.\n Will probably have a firewall/router at the front of the network, to route traffic to a public facing network hosting a website, game servers, and other services I plan to offer through a main site on my domain. Separately, my private network with gaming PCs for my roommate and I, and a shared gaming pc on the network rack.\n Part of my network is ready for 10gig, and with AT&T, I can upgrade my 1gig to 5gig at minimal cost.\n Viable to offer online services for game server hosting? I will eventually move to colocation or obtain redundant internet/solar for the rack and connections.\n ​\n https://preview.redd.it/cn1h7olpdk2a1.jpg?width=1280&format=pjpg&auto=webp&s=6b90b1814d1c2f0f57fe59b590edb2b7d9d44b7f\n ​\n https://preview.redd.it/lacupe3tdk2a1.jpg?width=1280&format=pjpg&auto=webp&s=d45b6f8c9bf337835bd9210f923c78c7f5b6f7c2\n    submitted by    /u/UserID10T  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6dp6l/first_time_homelab_setup_and_new_user/",
          "publishedOn": "2022-11-27T21:48:56.000Z",
          "wordCount": 14749,
          "title": "First Time Homelab setup and new user",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6cjjg/hardware_recommendation_for_a_nas/",
          "author": null,
          "description": "I want to plan on building a new NAS with ECC. Currently, I have am using an old gaming desktop I had for a NAS. Just learned about the importance of ECC, for data, and want to start planning on building for it. Can anyone recommend a good combo of hardware that is current? I am planning on using my old desktop case and PSU.\n Budget is preferably under $1k for the whole thing if needing a new case, etc.\n Currently, researching on my own, it seems like possible choices for a motherboard would be either a Asrock b450 (although I don't know what version/model) or a ASRock X470D4U AMD AM4 X470. Not sure what brand/type of memory and CPU I should be using or if there is other motherboard I should consider? Thanks in advance.\n    submitted by    /u/Wooden-Photo-2783  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6cjjg/hardware_recommendation_for_a_nas/",
          "publishedOn": "2022-11-27T21:03:48.000Z",
          "wordCount": 15023,
          "title": "Hardware recommendation for a NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6c3vr/got_these_bois_for_20_in_an_auction_they_seem/",
          "author": null,
          "description": "submitted by    /u/SirIndubitable  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6c3vr/got_these_bois_for_20_in_an_auction_they_seem/",
          "publishedOn": "2022-11-27T20:46:43.000Z",
          "wordCount": 14930,
          "title": "Got these bois for $20 in an auction, they seem good for when they were made. Would you still use them?",
          "imageUrl": "https://external-preview.redd.it/bjfxYpc1kfk2OSo6lxObI5JGNoH1L0I0HVr2IX7rSsA.jpg?auto=webp&s=4a77633b1208912252694b803fd550986f5b575e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6c166/start_to_my_first_home_lab_rack_options/",
          "author": null,
          "description": "A little messy until I get a better rack situation, but here it is!\n  \nDell PowerEdge R610 with 6TB in RAID with OE hot swaps, dual CPU, 128GB of RAM running ESXi 6.5\n TP-Link TL-SG3428\n Windows domain is configured with on-prem AD and Azure Connect to my O365 tenant\n Raspberry Pi 4 with WD MyBook 4TB running open media vault as a NAS\n  \nCurrent project: configuring virtual router for VM network\n Discussion: does anyone have a good, small rack on wheels that will fit this server? I tried to do some research on the rack server form factors but didn’t find anything that would nicely fit this bad larry without a 6’+ rack\n    submitted by    /u/2ndgen360  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6c166/start_to_my_first_home_lab_rack_options/",
          "publishedOn": "2022-11-27T20:43:34.000Z",
          "wordCount": 15335,
          "title": "Start to my first home lab :) Rack options?",
          "imageUrl": "https://preview.redd.it/ifbo8pvwjl2a1.jpg?auto=webp&s=d79154d8bb5c22499f6a6fd7a6d0410f06c86964"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6bszm/bargain_or_trash/",
          "author": null,
          "description": "Been interested in setting up a homelab for a while for home software dev environment and general tinkering (and if im honest i think blinking lights are cool).\n These have come up nearby for <£100. (I cant quite make out what some of this stuff is, undoubtedly many of you will recognise these relics). Wondering if its worth it as a foot in the door or if they're just going to triple my electric bill with no real redeeming benefits?\n    submitted by    /u/SwagBrah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6bszm/bargain_or_trash/",
          "publishedOn": "2022-11-27T20:34:25.000Z",
          "wordCount": 15500,
          "title": "Bargain or trash?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6bisq/creating_a_general_use_server/",
          "author": null,
          "description": "Hello there!\n I have recently gotten a good deal on a cpu, mobo, case, and psu from a friend.\n My plan for the hardware is to turn it into a nas / plex / minecraft server and probably run a discord bot or two.\n But I have a few questions:\n - How big should by boot drive be? would a 32 gb nvme optane drive do?\n - How do I access this server? it'll be at my parents place since I don't want the noise in my living room\n - What os should I run?\n - should I have 16 or 32 gb of ram?\n For the NAS I plan on running 2 8 tb hdd's in raid 1 since that's what my budget allows for, specifically two Seagate Exos 7E8. and then probably a decently sized ssd for the minecraft server so like 500 gb or something. The cpu will be an intel i5 8400 and networking will just be gigabit as both my parents and I have gigabit fiber networking.\n Thank you for your help in advance I hope to post a pic of the final product\n    submitted by    /u/King_of_snow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6bisq/creating_a_general_use_server/",
          "publishedOn": "2022-11-27T20:23:18.000Z",
          "wordCount": 15554,
          "title": "Creating a general use server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6aunt/configuring_windows_server_dhcp_help/",
          "author": null,
          "description": "I'm preparing for a DevOps interview and need to know AD & PowerShell APIs. My apologies if I can't ask here.\n Don't have much to work with, just a Fios G3100 router and Windows Server 2016 running on an Unraid box. My understanding is that Windows Server needs to also run DHCP server to also be a Domain Controller. Won't this conflict with my Fios router or it all depends on where I set up the DHCP server on the Fios router that would be the primary choice when devices connect to the network?\n ​\n  \nIf i had to make the Windows Server the primary router, what would happen if the Windows Server goes offline?\n Or would I be better off making the Fios router range 2-200 and then set the range on WInServer to 202-240? and then manually setting the default Gateway (on the devices that'll be connecting to the domain) to the WinServer? \n Is the right strategy to just put the Windows Server on its own subnet, like what do y'all do? I used to have a Unifi setup but short on space at the moment so I'm familiar with this, but is there any way to have a failover DHCP server?\n  \n   submitted by    /u/electrowiz64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6aunt/configuring_windows_server_dhcp_help/",
          "publishedOn": "2022-11-27T19:57:54.000Z",
          "wordCount": 15316,
          "title": "Configuring Windows Server, DHCP Help?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z6acru/best_switch_with_10gb_rj45_port_switch/",
          "author": null,
          "description": "submitted by    /u/Esophabated  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z6acru/best_switch_with_10gb_rj45_port_switch/",
          "publishedOn": "2022-11-27T19:37:59.000Z",
          "wordCount": 15371,
          "title": "Best Switch with 10gb rj45 port switch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z690vt/is_it_okay_to_put_hdds_flat_on_a_rubber_mat/",
          "author": null,
          "description": "I want to put 4x HDDs on a rubber mat on top of my server. There would be two 140mm fans blowing on them at low speed. Is that sufficient in terms of cooling or do the HDDs overheat \"from beneath\" if they lay flat on the rubber mat?\n    submitted by    /u/JagJag91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z690vt/is_it_okay_to_put_hdds_flat_on_a_rubber_mat/",
          "publishedOn": "2022-11-27T18:46:04.000Z",
          "wordCount": 15360,
          "title": "Is it okay to put HDDs flat on a rubber mat?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z689fz/one_hell_of_nice_and_free_score/",
          "author": null,
          "description": "submitted by    /u/h311m4n000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z689fz/one_hell_of_nice_and_free_score/",
          "publishedOn": "2022-11-27T18:16:03.000Z",
          "wordCount": 16915,
          "title": "One hell of nice (and free) score",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z67z6d/homelab_update/",
          "author": null,
          "description": "submitted by    /u/the_allumny  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z67z6d/homelab_update/",
          "publishedOn": "2022-11-27T18:04:40.000Z",
          "wordCount": 15558,
          "title": "HOMELAB UPDATE!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z64b4e/looking_for_a_network_engineering_apprenticeship/",
          "author": null,
          "description": "Hello! My name is Noah, and I am looking for an apprenticeship in Network Engineering, ideally in the East Midlands, U.K. This would be once I have finished Year 13 in June, so starting around August/September 2023. \n Interested in anything from ISPs, Large Enterprises, and MSPs. Indifferent to vendors as starting afresh - Juniper, Cisco, whatever! I own a little HomeLab, made up of Cisco Routers/Switches, and a WLC. I study L3 BTEC IT, L3 BTEC Business, Geography, and did an AS in Core Maths last year. Predicted grades are excellent. \n If you or your employer can offer me an apprenticeship, or if you have any contacts, I can happily provide my CV and Cover Letter - just send me a DM or email me at hello@nturneruk.com. Thanks! 🙂\n    submitted by    /u/nturneruk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z64b4e/looking_for_a_network_engineering_apprenticeship/",
          "publishedOn": "2022-11-27T15:42:31.000Z",
          "wordCount": 18217,
          "title": "Looking for a Network Engineering Apprenticeship in the East Midlands, UK",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z62jze/my_current_lab_details_in_comments/",
          "author": null,
          "description": "submitted by    /u/jacod1982  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z62jze/my_current_lab_details_in_comments/",
          "publishedOn": "2022-11-27T14:29:00.000Z",
          "wordCount": 15232,
          "title": "My current lab (details in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5rb9c/my_home_lab/",
          "author": null,
          "description": "submitted by    /u/NewYorkApe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5rb9c/my_home_lab/",
          "publishedOn": "2022-11-27T04:17:47.000Z",
          "wordCount": 16823,
          "title": "My home lab.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5o0z5/need_a_new_switch_and_router/",
          "author": null,
          "description": "Bought a new home so I guess its time for a new home lab. Currently have a router from my ISP and just an old Dell 24port switch. Looking to upgrade my networking gear. I love the Unifi UI and easy setup but everything they have seems to be on back order at the moment. I don't mind spending a little extra to get what I want but just looking for something that has an easy to use UI. Any suggestions?\n Also currently I am running Docker on one PC, a few VM's on a different server, and finally I have my plex server on a different device. So 3 main servers in my rack currently.\n    submitted by    /u/saymynamereddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5o0z5/need_a_new_switch_and_router/",
          "publishedOn": "2022-11-27T01:36:21.000Z",
          "wordCount": 14597,
          "title": "Need a new Switch and Router",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5nzhy/google_drive_upload/",
          "author": null,
          "description": "I just got a symmetrical gig internet connection. I finally have the bandwidth to back up all my media files. I have an unlimited Google drive with my business account. I started backing up my qnap nas to drive, however I am running into the 750Gb/ day limit.\n Does anyone know how to bypass this limit or increase it?\n    submitted by    /u/TwistedJackal509  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5nzhy/google_drive_upload/",
          "publishedOn": "2022-11-27T01:34:20.000Z",
          "wordCount": 14471,
          "title": "Google drive upload",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5n83n/how_to_manage_certificates/",
          "author": null,
          "description": "Hey All, I've been labbing for a while now and have just ignored the dreaded untrusted site message as I haven't had a need. Well I decided to rebuild the labs software stack from the ground up, new DC, new OPNsense install, new everything really. As part of this I finally bit the bullet and bought a domain instead of using no-ip. \n So after buying the domain, wasting half a day realizing that Google Domains does not use Google Cloud DNS, converting my nameservers to Cloudflare, building a webserver, and configuring certbot I now have a wildcard cert for my domain. Yay!\n I manually imported the key into OPNsense, and hooray, the secure connection lock is there, I did it! Now what? I have all the *arr's to configure, my Windows domain environment, a bunch of ESXi hosts and vCenter, etc. Is there a way that I'm missing to manage and automate the updating of certs across all these services? Across any of the services? Is it really that once a certificate is issued its your job to apply it to any service you want to use it? \n I feel like I'm missing the whole management after issuing part... help me out here folks.\n    submitted by    /u/darkendvoid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5n83n/how_to_manage_certificates/",
          "publishedOn": "2022-11-27T00:58:25.000Z",
          "wordCount": 15780,
          "title": "How To Manage Certificates?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5mwuv/9px1500rt_found_a_new_home/",
          "author": null,
          "description": "submitted by    /u/RSS83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5mwuv/9px1500rt_found_a_new_home/",
          "publishedOn": "2022-11-27T00:43:26.000Z",
          "wordCount": 14603,
          "title": "9PX1500RT found a new home",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5l3ja/today_i_got_this_24u_rittal_vx_it_for_my_home_lab/",
          "author": null,
          "description": "…for just 280€. It’s practically new and built like a tank. I can’t wait to move my stuff in there.\n    submitted by    /u/bmtlr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5l3ja/today_i_got_this_24u_rittal_vx_it_for_my_home_lab/",
          "publishedOn": "2022-11-26T23:20:54.000Z",
          "wordCount": 14725,
          "title": "Today I got this 24U Rittal VX IT for my home lab…",
          "imageUrl": "https://preview.redd.it/psih78v27f2a1.jpg?auto=webp&s=3d91f14a8c30d68af4e2625927491d8fd8a50fb3"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5kwy3/lightweight_and_affordable_approach_to_thunderbolt/",
          "author": null,
          "description": "submitted by    /u/cuemaxx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5kwy3/lightweight_and_affordable_approach_to_thunderbolt/",
          "publishedOn": "2022-11-26T23:12:59.000Z",
          "wordCount": 15770,
          "title": "Lightweight and affordable approach to Thunderbolt.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5kdfe/minecraft_server/",
          "author": null,
          "description": "Ok im not sure where to post this so mods plz deleted in necessary but point me in the correct direction.\n I'm attempting to build a minecraft server for over 100 users. Now I have an old hp prolient g5 with 2x 4core xeons at 3.2ghz and 32gb ram. Will that be enough? What would you recommed if anything?\n    submitted by    /u/Adorable_Culture  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5kdfe/minecraft_server/",
          "publishedOn": "2022-11-26T22:49:38.000Z",
          "wordCount": 14643,
          "title": "Minecraft server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5iwjq/ram_upgrade_for_hp_microserver_gen8_question/",
          "author": null,
          "description": "Recently got a 2nd hand Microserver Gen8 and want to up the RAM from 4GB. My research is telling me to get 2x8GB non-ECC UDIMM, but before pulling the trigger I would like some confirmation this will work. I don't have much experience buying parts and it's confusing.\n This is what I have picked out: https://www.ebuyer.com/1289675-kingston-ddr4-module-8-gb-dimm-288-pin-ktd-pe426e-8g\n Also, can anyone explain why this RAM is double the price but seems to be the same spec? https://www.ebuyer.com/959562-kingston-technology-ram-memory-ddr4-8gb-dimm-288pin-unbuffered-kth-pl426e-8g\n    submitted by    /u/WouldYouSmashIt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5iwjq/ram_upgrade_for_hp_microserver_gen8_question/",
          "publishedOn": "2022-11-26T21:46:12.000Z",
          "wordCount": 15102,
          "title": "RAM upgrade for HP Microserver Gen8 question",
          "imageUrl": "https://external-preview.redd.it/iH3Cwcu4war_vPm4xYh26rwlRB-Gz1pFYy0oC_PKPWU.jpg?auto=webp&s=9cd93ccaefdcaf47ab0b184ba59a5f44e4e1c3a0"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5ie93/nginx_all_log_is_from_default_gateway_ip_address/",
          "author": null,
          "description": "After being frustrated with the hosting provider I recently started hosting my own blog. I am forwarding the port 80 and 443 from my Mikrotik router to my laptop which serves the website with NGINX on Ubuntu 22.04. Today while checking the access logs I noticed all the requests have the same source IP, my default gateway IP(192.168.1.1)\n Ideally I want to get the IP address of the actual request. What are the things to check for to log the proper IP address?\n    submitted by    /u/cs_antorkhan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5ie93/nginx_all_log_is_from_default_gateway_ip_address/",
          "publishedOn": "2022-11-26T21:24:56.000Z",
          "wordCount": 16135,
          "title": "NGINX - all log is from default gateway IP address",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5hl5i/what_kind_of_port_is_this/",
          "author": null,
          "description": "submitted by    /u/5leepw4lk3r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5hl5i/what_kind_of_port_is_this/",
          "publishedOn": "2022-11-26T20:50:35.000Z",
          "wordCount": 14965,
          "title": "What kind of port is this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5hf2e/almost_finished_my_rack/",
          "author": null,
          "description": "just need to pull a few more network cable's for the future and its done.\n https://preview.redd.it/tp2pwj2hxc2a1.jpg?width=2268&format=pjpg&auto=webp&s=9fe1fd72002a51b9e1a637862427f07a3d1803cf\n ​\n specs :\n  \nUbiquity UDM pro with the 8tb hdd,\n 1u blank. Ubiquity usw 48 port pro switch, 0,5m 10gb DAC cable to UDM and 3 10gb rj45 to SFP+.\n 1u cable manager.\n 1u 24 port keystone panel.\n 2u blank panel.\n HP dl360p g8 2x xeon e5-2680 2.7ghz 8 core 16 threads 384gb ECC HP ram 8x 1tb Samsung ssd's 2x 460w Psu And 4 port 1gb card And 420i raid card with 1gb cache and backup battery.\n 2u rack shelf with my Ikea Smart home hub\n synology rs815+ with 2x 6tb Seagate ironwolf pro drives\n custom 1,5 u rack pc\n eaton bypass strip\n eaton 5px3000 ups with a extra battery pack\n  \n   submitted by    /u/psp1122  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5hf2e/almost_finished_my_rack/",
          "publishedOn": "2022-11-26T20:43:05.000Z",
          "wordCount": 14602,
          "title": "almost finished my rack",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5f9we/best_reverse_proxy_with_ssl/",
          "author": null,
          "description": "Hi all, been doing quite a bit of reading to determine which solution would be best for me to publish my internal web/media servers. I couldn't find a discussion comparing them here in homelab. \n It looks like the big players are: * SWAG - https://docs.linuxserver.io/general/swag * NGINX Proxy Manager - https://nginxproxymanager.com/ * Traefik - https://traefik.io/\n So here I am looking for some reviews and Pros/Cons from the community. What do you use/like and why? \n Me personally, I work in tech, but focus windows side. Limited experience with Linux, Docker, Web, Networking, so not an expert in this realm, but happy to learn. Thanks!\n    submitted by    /u/ChiSox1906  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5f9we/best_reverse_proxy_with_ssl/",
          "publishedOn": "2022-11-26T19:09:56.000Z",
          "wordCount": 15754,
          "title": "Best reverse proxy with SSL?",
          "imageUrl": "https://external-preview.redd.it/_YIweEHhSTA5kxYXzvCDTF-KCaCqzoNXx9cu_aIZbkU.jpg?auto=webp&s=80c60078f83d6de994ec68098bf1770d294f70ae"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5f9td/new_eaton_ups_going_strong_in_its_first_full_week/",
          "author": null,
          "description": "submitted by    /u/TechShocked  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5f9td/new_eaton_ups_going_strong_in_its_first_full_week/",
          "publishedOn": "2022-11-26T19:09:51.000Z",
          "wordCount": 15566,
          "title": "New Eaton UPS going strong in its first full week running!",
          "imageUrl": "https://preview.redd.it/x1g62dingc2a1.jpg?auto=webp&s=e39262e5aec3862732da80e4a6ea2d1606657d5e"
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5e2b9/are_there_any_pdus_that_can_be_timed_to_recycle/",
          "author": null,
          "description": "submitted by    /u/Austinitered  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5e2b9/are_there_any_pdus_that_can_be_timed_to_recycle/",
          "publishedOn": "2022-11-26T18:17:53.000Z",
          "wordCount": 15402,
          "title": "Are there any PDUs that can be timed to recycle my modem/switches?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5djvc/keeping_my_lab_secure_new_labber/",
          "author": null,
          "description": "I've not long started putting together my own little lab and want to ensure I am putting security first as while lurking I've read many horror stories.\n I'm running a small server that I put together myself (I'll post specs in a comment below).\n On this server I am currently running Proxmox with 1 VM and 1 LXC.\n The VM is running Ubuntu Server 22.04 (Minimal Install) and atm is only running Home Assistant via Docker with a couple of other containers that are used within HA.\n The LXC is just a monitoring tool I am running to check the Ubiquiti store as I can never seem to get a G4 Pro Doorbell as scalpers will be scalpers.\n After installing the Ubuntu VM I have a list of tasks I carried out to aid in the security first approach:\n  \nSetup unattended-upgrades\n Configure SSH via keys using ed25519\n Disable password access to SSH\n Install and setup basic rules for UFW and Fail2Ban\n Disable root login.\n  \nThe same steps are applied to the actual Proxmox server where possible (Disable root login wasn't possible).\n ​\n Going forward I am looking to expand and add Plex or Jellyfin that would ideally be accessible externally (I know, not exactly security first here). I hear a lot about using reverse proxies, VPNs etc but its not an area I am familiar with and many YouTube videos seems to explain it differently so I have chickened out for the time being as not to get it wrong.\n Finally I am debating if there is a need to create another Ubuntu VM to installer another instance of Docker for all my other future applications so I can keep Home Assistant and its companion containers segregated.\n ​\n Apologies for the long and boring post.\n TLDR\n Newb labber, using Proxmox, trying to keep secure.\n Using HA, expanding to external access Plex/Jelli.\n Seeking advice on ReverseProxy/VPN and other security tips.\n    submitted by    /u/RedditRotom101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5djvc/keeping_my_lab_secure_new_labber/",
          "publishedOn": "2022-11-26T17:56:38.000Z",
          "wordCount": 15705,
          "title": "Keeping my Lab Secure (New Labber)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5azq9/rackmount_cases/",
          "author": null,
          "description": "Hey all so I'm taking the leap and going to buy a rack. I am looking for two cases, one to transfer my NAS into so it should have a few drive bays I've seen quite a few online and I'm pretty happy with some of them, but I'm also considering putting my PC into the rack as well so that I have ample space on my desk. So I have a couple of questions regarding this:\n  \nThe case, I see a lot of server cases but they all have lots of HDD slots and are kind of overkill from what I can see, maybe I should be looking for a 2U or 3U for a PC case. I would like to make sure I can fit whatever available GPU I have and maybe some things like NIC cards or other pcie devices and don't want to end up restricted. I'd be inserting a regular ATX motherboard.\n \nWill this work? I want to have some kind of small type c device on my desk that will deal with monitors mouse etc connecting back to the server rack (same room not too far) and maybe even type c powered monitors for a very minimal cabling job.\n \n I keep getting caught in a googling loop with type c docking stations when I look for devices that essentially just give me all the ports I'd need over type c so maybe someone has a better idea of what these are called.\n    submitted by    /u/reddddddddddditor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5azq9/rackmount_cases/",
          "publishedOn": "2022-11-26T16:06:46.000Z",
          "wordCount": 17641,
          "title": "Rackmount cases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z5ax6s/adding_sas_drives_to_this_rosewilll_server_chassis/",
          "author": null,
          "description": "I'm thinking of moving my existing R710 server to a more modern configuration (late-gen intel chip with integrated Graphics, etc) and this rosewill case is where I'm wanting to move to: https://www.newegg.com/rosewill-rsv-l4500u-black/p/N82E16811147328\n My issue/question: I have 8 SAS Drives that I'm going to be moving over. I know this case supports 15 3.5\" drives which is fine, but does anyone have experience with using SAS drives in this? I currently have the H200 perc card in my R710 but I'm not sure exactly what I need for this case in order to use the SAS drives properly between the chassis and the MOBO I choose.\n    submitted by    /u/FourTimesRadical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z5ax6s/adding_sas_drives_to_this_rosewilll_server_chassis/",
          "publishedOn": "2022-11-26T16:03:43.000Z",
          "wordCount": 19048,
          "title": "Adding SAS drives to this rosewilll server chassis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/homelab/comments/z58y9n/have_you_ever_removed_fans_from_a_switch/",
          "author": null,
          "description": "I just got a Cisco SF300-24PP and I expected the fan noise but not as much as it is\n So I’m thinking of removing the fans on it. Has anyone ever done this to a switch before? \n If so what was the outcome?\n    submitted by    /u/theguy_win  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/homelab/comments/z58y9n/have_you_ever_removed_fans_from_a_switch/",
          "publishedOn": "2022-11-26T14:34:55.000Z",
          "wordCount": 16004,
          "title": "Have you ever removed fans from a switch?",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "It's A Digital Disease!",
      "feedUrl": "https://www.reddit.com/r/DataHoarder.rss",
      "siteUrl": "https://www.reddit.com/r/DataHoarder",
      "articles": [
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zvaoz0/best_way_to_back_up_images_on_an_apple_device_to/",
          "author": null,
          "description": "First off, hi everyone. I have only today stumbled across your beautiful subreddit and have already spent hours on it. This is a Christmas gift in itself. I am absolutely going to implement this 3-2-1 storage method, but before I do:\n I have had a query (title) for years and it is getting to the stage where my devices are dying and I NEED a solution.\n I have attempted to transfer images and videos from an iPhone to a USB stick via a laptop before in the past but when transferring from an iPhone to a Windows laptop I noticed some videos/images were left out, despite me standing over the transfer for HOURS. Does anybody have a tried and trusted solution for this situation? If it works for this, it will probably work for all my other files stored locally on my laptop too.\n This will be for cold storage. I have read that HDDs perform better than USBs for this, is anybody able to verify that?\n Thank you.\n    submitted by    /u/butterman888  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zvaoz0/best_way_to_back_up_images_on_an_apple_device_to/",
          "publishedOn": "2022-12-26T00:29:26.000Z",
          "wordCount": 17151,
          "title": "Best way to back up images on an Apple device to an external storage device?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv8z0s/transferring_and_backing_up_games_and_mod_folders/",
          "author": null,
          "description": "i've had my gaming laptop for a couple years now. after losing my mod folder for one of my favorite games (~16GB) last year, i began keeping a backup on my second internal ssd. i recently scored a surprisingly cheap pre-built gaming desktop and finally got around to transferring my mods over there.\n a small problem i encountered was my flash drive was slightly too small to move the now 28.6GB folder. i have a second flash drive handy so i just split the folder in half to complete the transfer. this has now lead me down a small rabbit hole of trying to find a convenient way of both keeping the folders on both PCs identical while also having a backup not connected to either. \n i have an old 120GB ssd that i think still works. in the morning i plan to run to best buy and acquire either an enclosure or a sata-usb adapter cable or dock to utilize this ssd as a short term transfer/backup drive. \n moving forward, i'd like a better setup for backing up and transferring all my game files as needed. not overly fond of using a NAS as it seems overly expensive and and honestly overkill for my use case (plus i'd rather not have to keep it powered). i'm leaning towards a few cheap SSDs, possibly setup to be exclusive to specific games or genres.\n both computers have 1.5TB of internal storage (all NVME in the laptop, 500GB NVME and 1TB HDD in the desktop) which is also a limiting factor (steam library is currently closer to 2TB, and i plan on buying a few more large games when i get paid on friday). i'd ideally like to be able to play some of the smaller, less demanding games straight off the external drives (more minecraft and goat simulator, less skyrim and GTA5). \n what do you experienced hoarders recommend?\n    submitted by    /u/moron88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv8z0s/transferring_and_backing_up_games_and_mod_folders/",
          "publishedOn": "2022-12-25T23:00:01.000Z",
          "wordCount": 17266,
          "title": "transferring and backing up games and mod folders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv8rvj/publicbookshelf_will_be_shut_down_123022_is_this/",
          "author": null,
          "description": "https://www.publicbookshelf.com/index.html\n  \nThank you for visiting our website. Due to unforeseen circumstances, our website will be shut down starting 12/30/2022. We appreciate your understanding. For any questions or concerns please reach out to us at: admin@publicbookshelf.com\n  \n   submitted by    /u/InfiniteSpaceIPH  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv8rvj/publicbookshelf_will_be_shut_down_123022_is_this/",
          "publishedOn": "2022-12-25T22:50:04.000Z",
          "wordCount": 17436,
          "title": "PublicBookshelf will be shut down 12/30/22. Is this backed up already?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv73h7/external_usb_drive_bay_vs_dedicated_nas/",
          "author": null,
          "description": "Hello all. If this isn't the right spot for this kind of post, please let me know. Also, sorry for the wall of text. Just wanted to provide some context and background for why I'm asking for help/advice. Let me know if you have any questions or want any additional info about my setup/plans. Thanks! \n  \nA week or so ago, I purchased an ORICO two bay USB 3 external HDD enclosure to house two 8TB WD Red Plus NAS hard drives. I had the drive bay connected to my HP ProDesk 600 G2, and then setup as a RAID 0 array via mdadm. That idea worked fine, and I was pretty happy with things. The ProDesk works perfectly fine for what I want out of a little home server, and I figured connecting some HD's via an external drive bay and creating my own little NAS storage setup would be more interesting and co…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv73h7/external_usb_drive_bay_vs_dedicated_nas/",
          "publishedOn": "2022-12-25T21:26:49.000Z",
          "wordCount": 19205,
          "title": "External USB drive bay vs dedicated NAS suggestions",
          "imageUrl": "https://external-preview.redd.it/jBMt1mKrvAFA0Dfg7IoywvZBJ8rD2ziTvxQevC7g2Jg.jpg?auto=webp&s=00660dbb479c6b72a33dfa36714a50932f8e0913"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv6z8u/whats_the_state_of_usbs_now/",
          "author": null,
          "description": "It seems like USB's are much cheaper than 10 or so years ago which is awesome, $10 for a 64gb on Amazon. I currently have one 32gb USB and for backing up the essentials, it's running low on space.\n I'm hoping to buy on Amazon, probably just 32 or 64 gb. Is there anything I should pay attention to for looking for a new USB? Any types that are maybe a bit faster and reliable without being too expensive?\n    submitted by    /u/viber34  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv6z8u/whats_the_state_of_usbs_now/",
          "publishedOn": "2022-12-25T21:20:51.000Z",
          "wordCount": 16783,
          "title": "What's the state of USBs now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv60ga/looking_for_an_archive_of_the_song_petey_pablo/",
          "author": null,
          "description": "This song is from an album called \" Spike TV Best Of Video Game Music Hits Vol. 1 \" which I can only find on archive.org. However, the full .flac and .mp3 files there are restricted and even after logging in I cannot download them. The only versions I can find online are in very low, compressed quality as they are ripped from a game Need For Speed Underground.\n If anyone has this CD or song in good quality (320 kbp/s mp3 or FLAC) then please send it to me.\n    submitted by    /u/GDShadept  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv60ga/looking_for_an_archive_of_the_song_petey_pablo/",
          "publishedOn": "2022-12-25T20:32:07.000Z",
          "wordCount": 17044,
          "title": "Looking for an archive of the song Petey Pablo – Need For Speed in good quality.",
          "imageUrl": "https://external-preview.redd.it/213OeAYZNyKDf1Co1GVsS8Qr9wrMV8f2HAXfli2Vi-o.jpg?auto=webp&s=f5ee83954be078bff4294f3746c7cb1c2c6feb31"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv5yk3/2x_16tb_segate_exos_489_1530tb/",
          "author": null,
          "description": "submitted by    /u/19wolf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv5yk3/2x_16tb_segate_exos_489_1530tb/",
          "publishedOn": "2022-12-25T20:29:38.000Z",
          "wordCount": 17033,
          "title": "2x 16TB Segate EXOs - $489 ~~ $15.30/TB",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv4u03/what_is_the_best_cloud_based_storageencryption/",
          "author": null,
          "description": "Good afternoon, I've been reading a lot of posts here and want to keep to the 3-2-1 rule, especially as I've had a recent scare trying to hunt down data that was stored on an account that was deleted a while ago. I have 2 forms of local storage (my 1TB Windows 10 laptop and 2TB external WD easy store drive) but am now trying to figure out a good cloud solution.\n I don't have a clear estimate on how much I plan to store online, but I think around 40 GB or more might be a good approximate. I do care about my privacy though, and understand that no cloud based storage can offer me true privacy so I would need to encrypt my files before uploading. I've heard of mega.io , google drive, and tarsnap. I'd like to stay away from drive for obvious reasons.\n My question is, what is a good cloud based service for the (relatively) small amount of data I want to back up that gives me options if I want to scale up in the future, and what encryption programs should I download to encrypt my files before I upload them. Thank you.\n    submitted by    /u/FullAd419  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv4u03/what_is_the_best_cloud_based_storageencryption/",
          "publishedOn": "2022-12-25T19:32:14.000Z",
          "wordCount": 18589,
          "title": "What is the best cloud based storage/encryption for privacy for around 40+ GB of data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv49qy/is_it_worth_to_convert_2tb_data_from_zip_to_7z/",
          "author": null,
          "description": "I have about 400 zips in varying sizes (100MB-100GB) laying on a drive in .zip format.\n I heard 7zip format is much better than zip regarding performance, efficiency and so on.\n So my Quesiton is: Do you think it is worth converting them all to .7z?\n EDIT: I should mention the zips are zipped by the linux-default \"zip\" command and i would use -mx=9 compression on 7zip when recompressing the files.\n    submitted by    /u/Alfagun74  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv49qy/is_it_worth_to_convert_2tb_data_from_zip_to_7z/",
          "publishedOn": "2022-12-25T19:04:29.000Z",
          "wordCount": 16921,
          "title": "Is it worth to convert 2TB data from .zip to .7z?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv40ac/data_hoarding_4tb_drives_at_a_time/",
          "author": null,
          "description": "So I don't really have a NAS Setup, just don't have the funds or knowledge to set it up or the space to really keep anything on my desks and don't want it on the floor.... and don't want to risk losing my data. Eventually when I have more time I Will look into it more and when I have the funds I will try and build something. \n Right Now, I have 2 nas servers in my current PC which I download and organize all my media and when I am done, and have everything set up right, I use my old laptop with 2 docks plugged in with 4 drives. I sync everything over from my internal 4tb to a docked 4tb drive so its one right and one read when transfering the data over. and I just leave it on the dock on my laptop for my Plex server... \n I keep the nas servers internal both are 4tb RED Nas WD drives.. when…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv40ac/data_hoarding_4tb_drives_at_a_time/",
          "publishedOn": "2022-12-25T18:51:15.000Z",
          "wordCount": 18743,
          "title": "Data Hoarding 4tb Drives at a Time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv3z9g/need_help_choosing_ssds_for_my_nas_upgrade/",
          "author": null,
          "description": "I was wondering if 1TB Western Digital SA510 SSD’s would work or should I spend the extra money on SSD’s that are made for NAS use (such as the WD SA500)?\n The WD SA510’s are about 45$ cheaper (here in Canada) than the WD SA500’s. Is the extra cost worth it in the long run? \n I plan to use Raid 10, starting with 6 SSD’s. My NAS has 10G networking, and is mostly used for media storage. \n Thanks in advance!\n    submitted by    /u/Blabliblou22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv3z9g/need_help_choosing_ssds_for_my_nas_upgrade/",
          "publishedOn": "2022-12-25T18:49:53.000Z",
          "wordCount": 16120,
          "title": "Need help choosing SSD’s for my NAS upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv2swv/seatools_what_is_self_test/",
          "author": null,
          "description": "I think It’s a new thing. Self Test?\n ​\n What‘s the difference between Self Test and the Generic Test?\n    submitted by    /u/mainecoon364  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv2swv/seatools_what_is_self_test/",
          "publishedOn": "2022-12-25T17:49:25.000Z",
          "wordCount": 15085,
          "title": "SeaTools - What Is Self Test?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv2nij/whats_the_best_way_to_transfer_my_files_to/",
          "author": null,
          "description": "I just got a new laptop and I plan to move all of my files and apps from my old laptop to the new one\n    submitted by    /u/FlareTDS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv2nij/whats_the_best_way_to_transfer_my_files_to/",
          "publishedOn": "2022-12-25T17:41:33.000Z",
          "wordCount": 16200,
          "title": "What's the best way to transfer my files to another laptop?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv1nte/mdisc_is_really_underrated/",
          "author": null,
          "description": "I'm in my mid 30's so I had my fair share of dealing with CD's back in the day. But In my mind optical media seemed to have become a completely obsolete technology by now. So I was surprised to learn about M-disc when a someone on this sub brought it to my attention as a means to archive data. \n And it turns out that it's the only way to archive data in a way that's legitimately durable long term and immune to bitrot. The second best would be LTO Tape drives. But the drives are really expensive and then the tech is still inherently not immune to bit rot, just less so that hhd and ssd and has a shelf life of about 30 years compared to the 1000 of M-Disc. \n So M-Disc is for anyone that wants to archive data in the most straight forward way. As in put you data on some medium that you can store away and know for a fact that some process of degradation wont be destroying it. No other storage medium can make a claim that comes even close to M-Discs durability and projected life expectancy. M-Disc literally engraves on a rock like layer so not that different from the Assyrian clay tablets that we still have from over 1000 years ago.\n    submitted by    /u/x0y0z0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv1nte/mdisc_is_really_underrated/",
          "publishedOn": "2022-12-25T16:51:03.000Z",
          "wordCount": 21981,
          "title": "M-Disc is really underrated.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv1htu/how_to_auto_organize_and_keep_track_of_movies_and/",
          "author": null,
          "description": "I have a new collection ~2TB but I just got ahold of a 24TB NAS (TrueNAS Scale) and I want to expand my collection and I want to know if there is some software which will re organize my file structure (optional) write all the missing metadata and have some portal where I can look over what I have. Thanks!\n    submitted by    /u/Humehaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv1htu/how_to_auto_organize_and_keep_track_of_movies_and/",
          "publishedOn": "2022-12-25T16:42:06.000Z",
          "wordCount": 16595,
          "title": "How to auto organize and keep track of Movies and TV Shows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zv1dua/spinup_time_of_brand_new_hc560_on_desktop/",
          "author": null,
          "description": "Got it brand new, installed properly into bay, initialized in disk management then did a quick format. Then check the status on crystal disk info and all was ok. But every time i shut the pc down and power it up again, i see the spinup time going lower. It started on 100, then it goes down by 2 every time. Finally ended up on 84 and the worst is 84 as well.\n I know what spinup time is but why does it keep on going down? I havent even begun to populate it with data.\n    submitted by    /u/Adventurous_Wind2947  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zv1dua/spinup_time_of_brand_new_hc560_on_desktop/",
          "publishedOn": "2022-12-25T16:36:10.000Z",
          "wordCount": 16870,
          "title": "spinup time of brand new HC560 on desktop",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuyyyq/14tb_wd_red_plus_cheaper_than_easystore_right_now/",
          "author": null,
          "description": "submitted by    /u/NickLandis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuyyyq/14tb_wd_red_plus_cheaper_than_easystore_right_now/",
          "publishedOn": "2022-12-25T14:20:42.000Z",
          "wordCount": 17046,
          "title": "14TB WD Red Plus cheaper than EasyStore right now: $224.20",
          "imageUrl": "https://external-preview.redd.it/BlvhQdD1xp9qH3AsKthtbIoYhUc5KdbVp44hI9MsY9g.jpg?auto=webp&s=d97691cea494165813a7ac066a7ac67107e35054"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuukia/is_there_an_usb_type_c_powered_35_enclosure/",
          "author": null,
          "description": "Merry Christmas everyone! \n I’ve done some search, but the question and answers are generally a few years old. With Type C being so much more common these days, are there now 3.5” enclosures that are powered via USB C? I’m not keen to have to use a dedicated power adapter.\n    submitted by    /u/baineteo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuukia/is_there_an_usb_type_c_powered_35_enclosure/",
          "publishedOn": "2022-12-25T09:09:52.000Z",
          "wordCount": 15971,
          "title": "Is there an USB Type C powered 3.5” Enclosure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zus9i9/how_does_terabox_provide_1_tb_free_space_for_each/",
          "author": null,
          "description": "I've been looking for a place to stash my hoarded shit and I found Terabox. It looks so unusually good that it's suspicious. What's the catch ? \n For my purpose, I don't really need privacy or security or something. None of what I want to hoard can be considered sensitive/personal content. Is Terabox (free version) a good solution for that ?\n    submitted by    /u/Sadman_Pranto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zus9i9/how_does_terabox_provide_1_tb_free_space_for_each/",
          "publishedOn": "2022-12-25T06:21:34.000Z",
          "wordCount": 16862,
          "title": "How does Terabox provide 1 TB free space for each account when none of their competitors get even close ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zus8tv/randomly_stumbled_upon_this_video_this_evening/",
          "author": null,
          "description": "The whole video is worth watching, but the link starts at the SMR vs CMR chapter.\n https://youtu.be/wtdnatmVdIg?t=733\n    submitted by    /u/wh33t  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zus8tv/randomly_stumbled_upon_this_video_this_evening/",
          "publishedOn": "2022-12-25T06:20:17.000Z",
          "wordCount": 16730,
          "title": "Randomly stumbled upon this video this evening. Thought it was really well done and I love how it finally explained the difference between SMR and CMR to me in a way that makes sense. I wanted to share!",
          "imageUrl": "https://external-preview.redd.it/KPkqWElnz5FD35c5IkEXydsH9DLINcdKie7HqT-JDkI.jpg?auto=webp&s=fff5cf51b80fb6115ee1bf729f63b5535c23aa0b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuo1gz/warhammer_universe_collection_updated_december/",
          "author": null,
          "description": "Welcome to the Warhammer Collection,\n this is the seventh update (December 2022) we're doing on the WH lore and thanks to the feedback received we managed to archive:\n - an improved sorting\n - added new released books\n - replaced/deleted many non-retail\n ALL the books have been renamed with Author's Name Surname - Book title (Series) for an easy search.\n The retail tag means how the book was ripped\n [Retail] - Books that i have bought myself and i have removed the DRM thru calibre\n (Retail) - Books shared by other users whom DRM has been remove correctly thru calibre\n (retail) - Books shared by other users who purchased the books but not drm'ed correctly with calibre\n With this I'm hoping to give the reader a complete collection of WH books in their best available format and somehow well sorted.\n If you enjoyed this and found some issues such as typos, bad scans/conversions, misplaced books and pretty much anything please send me a message.\n Lastly a huge thanks goes to all the people that helped out with this project. Thank you!\n Torrent\n magnet:?xt=urn:btih:ce271c2c106af88f97f7dc2b875f5667131fd5f0\n MEGA\n Will upload an updated link in few days \n ​\n PS: i obviously forgot to add the last short while making the torrent,\n Jude Reid - The Shel'tain Affair (Amendera Kendel) [Retail]\n    submitted by    /u/RedHeadedKhajiit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuo1gz/warhammer_universe_collection_updated_december/",
          "publishedOn": "2022-12-25T01:51:33.000Z",
          "wordCount": 15609,
          "title": "Warhammer Universe Collection [Updated December 2022]",
          "imageUrl": "https://external-preview.redd.it/6g1jVIXhQQNfQR-lwUCo-vxWtwHlKYpV-zg897aZ3yA.jpg?auto=webp&s=0031e2ecd0934f69ff1bc1629201507017ff3448"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuniqw/bibliotheca_alexandrina_a_600_gb_hoard_of_history/",
          "author": null,
          "description": "link to the previous post to make some light on the project \n 2021 Update \n Bibliotheca Alexandrina - 602 GB\n magnet:?xt=urn:btih:5b407389216bb686e7d2f7ecf8aeb1e960f53154 \n Variorum Collected Studies - 116 GB\n magnet:?xt=urn:btih:f9f10ded2a254eacfefa4deeef040d8aa56ed18b \n The series is published by Ashgate and since it was established in 1970, over 1000 volumes have been produced. https://en.wikipedia.org/wiki/Variorum_Collected_Studies \n FAQ\n what's included in these 600GB?\n Classical and medieval academic books, something early modern (1600s), some archeology/prehistory \n what's the difference between this collection and libgen/zlibrary/archive/..?\n quality of the books. Many of my books are tagged as retail, i can vouch for each of them \n why zipped folders?\n all the folders have been z…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuniqw/bibliotheca_alexandrina_a_600_gb_hoard_of_history/",
          "publishedOn": "2022-12-25T01:19:58.000Z",
          "wordCount": 16847,
          "title": "Bibliotheca Alexandrina - a 600 GB+ hoard of history books [December 2022]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zum7je/why_is_my_external_hdd_so_slow/",
          "author": null,
          "description": "I have an external HDD 3.0. When I copy files from the HDD to the PC (NVMe) the speed is 38MB/s. Is it normal? \n And if I copy from PC to HDD, the speed is 130MB/s but after 2 seconds drop down to 34MB/s.\n I searched the internet but nothing seems to improve speed.\n    submitted by    /u/ALE2000XVX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zum7je/why_is_my_external_hdd_so_slow/",
          "publishedOn": "2022-12-25T00:04:14.000Z",
          "wordCount": 16229,
          "title": "Why is my external HDD so slow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zum47k/does_converting_lossy_audio_to_flac_stop/",
          "author": null,
          "description": "I found a bunch of .amr files in one of my archives of past voice mails. After doing some copying and replacing I learned they are a lossy file type. I couldn't find any documentation on .amr files specifically, but I assume they suffer generation loss the same way .mp3s do.\n I know that you can't increase quality by converting a lossy file to a lossless file, but can you prevent it from losing any more quality? These are sentimental files and I'm wondering if they'd be better preserved as .flacs\n    submitted by    /u/fishswimminginatank  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zum47k/does_converting_lossy_audio_to_flac_stop/",
          "publishedOn": "2022-12-24T23:59:41.000Z",
          "wordCount": 15785,
          "title": "Does converting lossy audio to .flac stop generation loss, and quality degradation over time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zulp5s/datahoaders_i_need_help_preserving_about_5tb_of/",
          "author": null,
          "description": "https://www.reddit.com/r/DataHoarder/comments/a6ah2q/so_we_spent_175_usd_to_purchase_a_5tb_drive/\n It's been four years since I made this post, where I acquired a drive holding a 2014 dump of animemusicvdieos.org including an export of it's database. I'm gonna be honest here... It's collected dust since. I've made a few attempts to upload it to Archive.org via FTP but I just get errors. Tried different PCs and FTP clients, I start getting hung transfers and it all goes to hell. This is a huge amount of data so it's not like I can just toss it on Gdrive.\n So I'm looking for other people who can help. People I can send this data too and hopefully they can upload to archive.org and share by other means if they want. This drive won't function forever, I really need to get around to duplicating it's contents and propagating it across the internet and into other individual's collections.\n Ideas?\n    submitted by    /u/AshleyUncia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zulp5s/datahoaders_i_need_help_preserving_about_5tb_of/",
          "publishedOn": "2022-12-24T23:36:31.000Z",
          "wordCount": 15810,
          "title": "Datahoaders, I need help preserving about 5TB of Anime Music Videos and a database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zukpxk/whats_the_rarest_piece_of_data_you_have_preserved/",
          "author": null,
          "description": "Anyone have any stories of lost media or cool pieces of your data stores?\n    submitted by    /u/Dirtrubber  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zukpxk/whats_the_rarest_piece_of_data_you_have_preserved/",
          "publishedOn": "2022-12-24T22:44:49.000Z",
          "wordCount": 16281,
          "title": "What’s the rarest piece of data you have preserved?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zukb60/how_a_coverless_drives_looks_in_operation/",
          "author": null,
          "description": "submitted by    /u/1DonBot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zukb60/how_a_coverless_drives_looks_in_operation/",
          "publishedOn": "2022-12-24T22:23:21.000Z",
          "wordCount": 16256,
          "title": "How a coverless drives looks in operation (surrounded by +180TB drives)",
          "imageUrl": "https://external-preview.redd.it/4-AnQuoO7qlpSyCMx7GRdx_Jbp5J4xn-7U_WhOv5e_4.jpg?auto=webp&s=986731e30b99255e7fb3c0c115752787bd5fa782"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuk6kz/any_way_to_not_upload_duplicates_on_google_drive/",
          "author": null,
          "description": "So, i like to backup files very often from my computer or hard drive to google drive. It would be an absolute pain to go in to every folder and search to see which files have not been uploaded, and upload those files every time. \n I like to just go to google drive and drag all the files into a folder and let them upload. Problem is, there are many. When I do this, google never asks me if I want to replace the files or whatever. It always just reuploads the files that already exist and adds a number to the end of the name.\n Is there any way to stop this so that it does not upload file with the same name?\n    submitted by    /u/AllAboutGadgets  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuk6kz/any_way_to_not_upload_duplicates_on_google_drive/",
          "publishedOn": "2022-12-24T22:16:43.000Z",
          "wordCount": 15213,
          "title": "Any way to not upload duplicates on Google Drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zujv5t/what_systems_do_you_use_to_store_your_data/",
          "author": null,
          "description": "I am using debian+zfs+docker\n    submitted by    /u/kovach_ua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zujv5t/what_systems_do_you_use_to_store_your_data/",
          "publishedOn": "2022-12-24T22:00:32.000Z",
          "wordCount": 16100,
          "title": "What systems do you use to store your data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zufyy1/i_failed/",
          "author": null,
          "description": "Today is my first day home since thanksgiving. Sitting in the garage at my mom’s place when I walked in her garage is my Black Friday order. A 16tb western digital red. Just sitting in a static bag. She reminded me the box was wet so she opened it.\n Plug it into the computer, pull up disc management. \n And promptly formatted the wrong drive. Poof. Around 15tb of movies and tv shows.\n The only backup is a list in meta media manager of the movies. \n Plex should be able to tell me what tv shows I had.\n I should be able to recover everything, but man some of those shows/seasons were low seeded and took forever.\n The best part? The 16tb red drive won’t initialize. And I bought it from newegg.\n 🤷‍♂️ merry Christmas 🎁🎄\n    submitted by    /u/Ok-Professional3832  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zufyy1/i_failed/",
          "publishedOn": "2022-12-24T18:45:33.000Z",
          "wordCount": 16747,
          "title": "I failed.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zufhmp/how_to_archive_a_website_to_host_it/",
          "author": null,
          "description": "there's a forum that i've been a part of since 2011 and there is a high chance that the owner isn't going to continue supporting the site, is there a way to completely archive everything in the website to make it easy to launch another website without losing the content ? \n its literally the one and only active forum in my language.\n    submitted by    /u/sohailoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zufhmp/how_to_archive_a_website_to_host_it/",
          "publishedOn": "2022-12-24T18:21:53.000Z",
          "wordCount": 15732,
          "title": "how to archive a website to host it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zueequ/gallerydl_tweet_ratelimiter_breaking_program/",
          "author": null,
          "description": "While attempting to back up a bunch of twitter accounts, I noticed that for some reason the Rate-Limit Reset error that it gives after ripping a bunch of programs effectively freezes it forever. If I wait out the 15 minutes, it'll give the exact same error again. I haven't seen it get past a rate limit reset. Anyone know how to either slow it down enough that it doesn't trigger the rate limit reset, or how to make it keep ripping after the reset is over?\n    submitted by    /u/SomeHusky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zueequ/gallerydl_tweet_ratelimiter_breaking_program/",
          "publishedOn": "2022-12-24T17:28:38.000Z",
          "wordCount": 15790,
          "title": "Gallery-DL Tweet Rate-Limiter Breaking Program",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zudr4x/download_and_search_your_own_selection_of_books/",
          "author": null,
          "description": "submitted by    /u/TheoGrd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zudr4x/download_and_search_your_own_selection_of_books/",
          "publishedOn": "2022-12-24T16:56:53.000Z",
          "wordCount": 17921,
          "title": "Download and search your own selection of books from libgen with linux",
          "imageUrl": "https://external-preview.redd.it/UsqiQKE_5YkAEqLMx1beyWyipl85naYBEzT9LuUmNOc.jpg?auto=webp&s=bfb2aa514cefbde75d81d86deb33251e320c8faa"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zudm3e/need_help_with_a_seagate_internal_hard_drive_that/",
          "author": null,
          "description": "I have a 500GB Seagate hard drive (ST500DM009) which I have bought around 2 years ago produce this sort of click in random intervals. The first time the drive clicked was when I was freshly installing windows 10 on it for the first time with the media creation tool, At first I thought nothing of it as the installation went without a hitch, However after installing a few games and playing them, The drive suddenly clicked in rapid succession which caused a BSOD, Windows 10 was able to boot again but that's where it all went downhill as the clicking never went away till to this day of me writing this, Sometimes it doesn't click for a day or two but I will ultimately reoccur again, As it clicks most of the time when the drive is in heavy use, I have originally thought that It was the hard drive's APM feature acting up that was causing this issue, That's why I followed this Youtube video guide on how to permanently disable the APM feature within the drive(https://www.youtube.com/watch?v=p4UrnP38T0w) But alas, It's all futile, As the clicking of the drive still persists, The drive is still usable and still in perfect health(surprisingly). What on earth could be causing this?\n Hard drive click audio:https://vocaroo.com/14qXHSyhIHlZ\n Hard disk sentinel status:https://imgur.com/a/QhJj9q5\n    submitted by    /u/borjie_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zudm3e/need_help_with_a_seagate_internal_hard_drive_that/",
          "publishedOn": "2022-12-24T16:49:52.000Z",
          "wordCount": 16705,
          "title": "Need help with a Seagate internal hard drive that clicks randomly then makes a sudden spin up noise",
          "imageUrl": "https://external-preview.redd.it/f42_5FnrwXjfFEh0wjuCD17TMuDKAIuPf0uEE2v7Vzc.jpg?auto=webp&s=3590cd9f797035eac6cca709c796211148eaffc7"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuc8fo/can_someone_help_this_noob/",
          "author": null,
          "description": "I have an 8tb hard drive that I got 5 years ago, but I recently heard hard drives only last 3-5 years and Google seemed to confirm it so I'm panicking on what to do. Do they really just fail over time or maybe that's just for smaller hard drives? I'm not too techy when it comes to computer parts so I don't really know these things. It's made by seagate and it's one that needs to be plugged into the wall. I'm pretty sure it's this one: Seagate Backup Plus Hub 8TB Desktop Hard Drive with Rescue Data Recovery Services https://a.co/d/9YmSkMP\n    submitted by    /u/oharacopter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuc8fo/can_someone_help_this_noob/",
          "publishedOn": "2022-12-24T15:38:55.000Z",
          "wordCount": 15728,
          "title": "Can someone help this noob?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuc0z9/google_enterprise_without_vat_id/",
          "author": null,
          "description": "So, I'm using Google Workspace Enterprise Standard now for storage, ~30TB but I will have to soon close my VAT ID and I understand it is required now. Can I make an account for it without one? Or is there anything similar I could use for a similar price point?\n Is the only solution in my future just a bunch (more) drives for local storage?\n    submitted by    /u/TehBard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuc0z9/google_enterprise_without_vat_id/",
          "publishedOn": "2022-12-24T15:28:06.000Z",
          "wordCount": 15499,
          "title": "Google Enterprise without VAT ID?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zubr9u/wd_easystore_18tb_x_4/",
          "author": null,
          "description": "My GF went to best buy and bought 4 of these for one of her clients who halted the project for their office refresh. They let her keep the external drives and asked if I wanted them. I've shucked a drive before to use in a Linux PC, any reason why these won't work in a ds920+?\n They cannot be returned as they were purchased by her client and setup for her to pickup.\n Wanted to know if anything to look out for before I tear them apart. Otherwise if there's problems I'll have her sell them or just use them as externals with a UnionFS\n    submitted by    /u/blitzblitzblutz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zubr9u/wd_easystore_18tb_x_4/",
          "publishedOn": "2022-12-24T15:14:13.000Z",
          "wordCount": 16214,
          "title": "WD Easystore 18tb x 4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuawmx/i_bought_a_external_hard_drive_but_it_made_noise/",
          "author": null,
          "description": "submitted by    /u/Elliott_The_Chicken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuawmx/i_bought_a_external_hard_drive_but_it_made_noise/",
          "publishedOn": "2022-12-24T14:28:51.000Z",
          "wordCount": 15762,
          "title": "I bought a external hard drive but it made noise so i opened it. This was loose. Does anyone know if it is important or crucial?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zuaql7/lost_access_to_my_servers_files_through_smb/",
          "author": null,
          "description": "i have been using the same windows server (windows 10 pro), with the same drives for 2 years now, and SMB had been working wonderfully.A few days ago i got a new PSU, with more sata connectors, so i added 2 other HDDs to the mix, and made sure that the drive letter for the older ones didn't change.That's really the only major change that happened, besides that all i did was remove my password, so the server would login automatically, and given that i have password protected sharing turned off, it shouldn't have been a problem. Either way after ii noticed all my network drives had been disconected, both from my windows laptop, and my android phone, i tried reverting the passowrd just to be sure, but it didn't work\n https://preview.redd.it/zwsf13h4tu7a1.png?width=650&format=png&auto=webp&s=09383a95c57a8b57969bc4d96ea43efc4c45270d\n https://preview.redd.it/cqj7qua5tu7a1.png?width=745&format=png&auto=webp&s=013123aad4f5ae1590136cb4024b654fe3d37040\n Example of shared drive\n Windows Defender firewall\n All and all, i'm out of ideas,\n i should mention that if i set those same settings on my laptop, and share one of its folders, my server can easily find it in the network, and mount it with no problem, but not the other way around\n any ideas?\n given that a good chunk of the time i'm messing with files on the server, is working with video files, this is really bothersome\n (last note, that same day all of that happened, i opened the computer management app, but i changed absolutely nothing in there, i only clicked on the Users and profiles tab > Users, after that i changed absolutely nothing in said \"users\" folder) \n this will probly turn out to be revelant, so\n https://media.discordapp.net/attachments/589454320005808133/1056224734301388870/image.png\n https://cdn.discordapp.com/attachments/589454320005808133/1056225542963208293/image.png \n    submitted by    /u/peugamerflit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zuaql7/lost_access_to_my_servers_files_through_smb/",
          "publishedOn": "2022-12-24T14:19:24.000Z",
          "wordCount": 16481,
          "title": "lost access to my server's files through SMB network storage, and i don't why. I'm out of ideas",
          "imageUrl": "https://external-preview.redd.it/gobaNcQvAahafY86eih0PYuVpSXb-bvGRxoWhsdPyiA.png?auto=webp&s=3fbfa4d2cb5c53ea6e464a8b421ca7572a663e6e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zu74ma/seagate_expansion_14tb_external_hard_drive_19999/",
          "author": null,
          "description": "submitted by    /u/Viknee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zu74ma/seagate_expansion_14tb_external_hard_drive_19999/",
          "publishedOn": "2022-12-24T10:22:02.000Z",
          "wordCount": 15759,
          "title": "Seagate Expansion 14TB External Hard Drive - $199.99 - $14.28/TB",
          "imageUrl": "https://external-preview.redd.it/nI-Yr1Eb668Ujra70Z2m4G-_R5DY13lMvMbeULO9VPI.jpg?auto=webp&s=689278e484ad9c4c83d4df70e18048e82725e8dc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zu3lqp/i_just_realized_i_am_the_owner_of_a/",
          "author": null,
          "description": "submitted by    /u/wyatt8750  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zu3lqp/i_just_realized_i_am_the_owner_of_a/",
          "publishedOn": "2022-12-24T06:22:37.000Z",
          "wordCount": 16611,
          "title": "I just realized I am the owner of a currently-working IBM 75GXP \"Death Star.\" (It's still Friday somewhere)",
          "imageUrl": "https://preview.redd.it/geurrufahs7a1.jpg?auto=webp&s=a790a3c9180e95f9516117e0ac84d3658d0a30e0"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zu2zng/a_massive_australian_archive_of_newspapers_and/",
          "author": null,
          "description": "submitted by    /u/King_Millez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zu2zng/a_massive_australian_archive_of_newspapers_and/",
          "publishedOn": "2022-12-24T05:45:36.000Z",
          "wordCount": 15413,
          "title": "A massive Australian archive of newspapers and documents at the National Library of Australia's funding runs out in July 2023 – and the National Library is threatening to pull the plug. Can we help?",
          "imageUrl": "https://external-preview.redd.it/Jeycfop4HqZxbuffKYgnG3qQbW3yrlqzPyWWPoIpdZ8.jpg?auto=webp&s=b316a8d27d8e138ab76327e2b6375a72d18fc35d"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zu0qod/how_do_you_easily_accessbrowse_and_organize/",
          "author": null,
          "description": "I have hardware infrastructure in place and have a folder structure I like. All that is fine.\n It would be cool to have an app that made it easier to search and go through content. I'd like to be able to tag similar things instead of relying only on using folders. I'm imagining something like Plex where there is a database of information and you can browse or search.\n I've heard of stash but don't have any experience with it.\n Two additional challenges:\n  \nMost of my content are videos posted online, so these aren't like official released media. There probably isn't an easy database that exists with all the info. I assume I'd have to build that db myself.\n For privacy's sake, I keep all of the data encrypted with VeraCrypt. I am not tied to this solution, but I do want to restrict access, ideally at the file storage layer (but not required). So any solution either has to work directly with some form of encrypted storage, or as part of starting up needs to be able to mount and then access storage otherwise decrypted and made available (maybe something with ZFS?). \n App ideally also requires authentication to access.\n \n  \n   submitted by    /u/DontCryForMeThrowAwa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zu0qod/how_do_you_easily_accessbrowse_and_organize/",
          "publishedOn": "2022-12-24T03:37:01.000Z",
          "wordCount": 16324,
          "title": "How do you easily access/browse and organize stored NSFW content?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztxa59/link_preservation_for_jan_6_report/",
          "author": null,
          "description": "(No political opinion expressed. Please be civil in this venue)\n I was skimming the Jan 6th House report and it concerns me how many links go to web pages. These links can rot very easily. \n Has anyone tried to archive all of the links so it may be persevered?\n    submitted by    /u/jwink3101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztxa59/link_preservation_for_jan_6_report/",
          "publishedOn": "2022-12-24T00:38:20.000Z",
          "wordCount": 16579,
          "title": "Link preservation for Jan 6 report",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztwotw/i_need_help_with_fox35_embedded_video/",
          "author": null,
          "description": "I was trying to get the video from this story: https://www.fox35orlando.com/news/ucf-professor-allegedly-dressed-up-used-accent-during-recorded-video-lessons-students-say.\n However, none of my current tools have Fox35 as a supported website, and the one that did was only allowing me to get the ads.\n Through developer tools I managed to find a link to an .amp version of the page, but I still couldn't get it: https://www.fox35orlando.com/news/ucf-professor-allegedly-dressed-up-used-accent-during-recorded-video-lessons-students-say.amp\n Are there any extentions that have Fox35 as a supported website, or some technique or tool that I'm missing.\n    submitted by    /u/aslfingerspell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztwotw/i_need_help_with_fox35_embedded_video/",
          "publishedOn": "2022-12-24T00:09:27.000Z",
          "wordCount": 17758,
          "title": "I need help with Fox35 embedded video.",
          "imageUrl": "https://external-preview.redd.it/sx47WIAJc9xaRsXlxd7BRZOguEUWWT_KQtiQ0oThR-U.jpg?auto=webp&s=0fe25eddb1f1b744386004e2b001c2f63c6bc5bc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztvxe1/lsi_92118i_vs_92078i/",
          "author": null,
          "description": "I just need more SATA ports for my desktop. I will be using just hard drives with it. Any reason I should go with a 9207 over a 9211?\n    submitted by    /u/al93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztvxe1/lsi_92118i_vs_92078i/",
          "publishedOn": "2022-12-23T23:32:55.000Z",
          "wordCount": 16110,
          "title": "LSI 9211-8i vs 9207-8i",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztudvd/rsync_speeds_around_15_to_17mbs_over_10gb_nic/",
          "author": null,
          "description": "I'm using this rsync command on my new debian/openmediavault server in order to get all data moved from the old one onto this one:\n rsync -hazP --stats -e \"ssh -T -c aes256-gcm@openssh.com -o Compression=no -x\" root@10.10.10.15:/srv/27829c9c-dbc1-4408-a111-56dbcd8f0ec0/media/ /srv/mergerfs/norman_pool2/media\n In both instances, the data is in a unionfs or mergerfs pool. 10.10.10.15 is the IP of the NIC on the source server which should make it communicate over 10Gb only since that port is plugged into the 10Gb NIC on the new server with a DAC cable. The only other interfaces are the main 1GB NICs which each have a line going to my router/switch\n The new server is intel I3 12100 with 32GB ram, the old is Dell R710 with dual xeon L5664 CPUs and 32 GB ram. They both show low CPU utilization and ram utilization during the process, but I'm not seeing more than 15MB/s on larger files, 5-10MB on smaller ones. I think the highest I've seen is 18MB/s which seems insanely slow for a direct 10Gb connection\n Is there anything I'm not thinking of, or anything the command could use to speed things up even more\n    submitted by    /u/FourTimesRadical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztudvd/rsync_speeds_around_15_to_17mbs_over_10gb_nic/",
          "publishedOn": "2022-12-23T22:22:31.000Z",
          "wordCount": 17106,
          "title": "Rsync speeds around 15 to 17MB/s over 10Gb NIC from server to server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztu194/i_have_enjoyed_being_a_statistical_anomaly_far/",
          "author": null,
          "description": "submitted by    /u/bmanalpha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztu194/i_have_enjoyed_being_a_statistical_anomaly_far/",
          "publishedOn": "2022-12-23T22:08:11.000Z",
          "wordCount": 15497,
          "title": "I have enjoyed being a statistical anomaly far too long. Good night sweet prince.",
          "imageUrl": "https://preview.redd.it/uxtjjyxlzp7a1.jpg?auto=webp&s=d197d4ef2e76dad32fa8b70cae8c651cde6a92db"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zttvkg/searching_cloudstorage_testers/",
          "author": null,
          "description": "Searching Cloudstorage Testers\n Hey Guys, might be Offtopic as f***. But hey thats reddit. As the Title is saying iam searching a few people from different Locations around the World that are willing to test a Cloud Storage Service in Terms of Upload/Download Speed / Loading Times and usability.\n Time to test 3 Months. Storagespace to test with: 50GB (able to do more) What you need to do: Just give me a quick Update on how things are working out etc every 2 weeks\n You can keep the Storage after the tests if you want Just reply in here with your Destination and imma get in Touch with you.\n Wish you some nice holidays. Also could someone please tell me what section this post would be? ;)\n    submitted by    /u/No_Dragonfruit_5882  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zttvkg/searching_cloudstorage_testers/",
          "publishedOn": "2022-12-23T22:01:25.000Z",
          "wordCount": 16097,
          "title": "Searching Cloudstorage Testers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zttt6f/seagate_x18_sale/",
          "author": null,
          "description": "submitted by    /u/Mlitz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zttt6f/seagate_x18_sale/",
          "publishedOn": "2022-12-23T21:58:52.000Z",
          "wordCount": 15326,
          "title": "Seagate X18 Sale",
          "imageUrl": "https://preview.redd.it/v2efa282hr7a1.jpg?auto=webp&s=24f742fb09d17e3624cdb0c3c7f44e834340a74e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztsaye/open_source_simple_reddit_post_downloader_that/",
          "author": null,
          "description": "submitted by    /u/turntwice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztsaye/open_source_simple_reddit_post_downloader_that/",
          "publishedOn": "2022-12-23T20:51:13.000Z",
          "wordCount": 15656,
          "title": "Open source simple Reddit post downloader that doesn't require OAUTH. Downloads all post types, converts GIFs to MP4, and enables downloading any subreddit(s) on repeat at set intervals (download new posts every minute, every hour, etc.)",
          "imageUrl": "https://external-preview.redd.it/feGsVmUB-usKVUgg0HSSGzo1Wfbq7Ys5D3f6z9hUgU4.jpg?auto=webp&s=86604eae3cadd87d8ff5ecafd3973ea88f5a4af9"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztrfcn/my_nas_is_ruined_need_help/",
          "author": null,
          "description": "I own a Terramaster f2-221. I'm the guy asking about single disk nas a few days ago.\n Yesterday night, while the nas was turned off, my electricity went away for a few minutes.\n Since this morning, my NAS doesn't work anymore. \n Using tnas the NAS results as Uninitialized, if i try to connect to it's IP via browser it shows me the setup wizard, makes me create a new account and delete all previous data. If i try to connect via file manager, internet explorer, winscp or whatever it always open the setup Wizard or it asays connection refused \n Connecting the add on pc shows several partitions, all healty, but there is no way for my pc to show the contents on the hdd, it only appears in the partition tool of windows \n I try connecting via SSH with Putty (https://forum.terra-master.com/en/viewtopic.php?f=75&t=2350), and it worked...but it said it created a new folder for my admin user (that already existed). The NAS does remember the name i've given to it tho, so i'm confused if the data is there or got partially deleted.\n Anyway, i followed this guide (https://forum.terra-master.com/en/viewtopic.php?f=79&t=2575&p=13904#p13904) but, the results were completely different: no red or any colored text, only white text that more or less looks fine from my very limited knowledge, i coulnd't spot any error message \n I literally don't know what to do apart from wiping my drive, i want to recover the data since there are still important things that i still have to back up elsewhere, and also over a terabyte of hard to find content. \n Can anyone help me?\n    submitted by    /u/TheXade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztrfcn/my_nas_is_ruined_need_help/",
          "publishedOn": "2022-12-23T20:12:01.000Z",
          "wordCount": 16974,
          "title": "My nas is ruined. Need help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztq570/archive_a_youtube_playlist_not_the_videos/",
          "author": null,
          "description": "I have a few YouTube playlists that I've built up over the last few years that I would like to archive off and delete. Some have a 100+ videos in them and it would take days to manually select the video, copy its URL and paste this and the title into a file...\n I do not want to download the videos (most are the copyright of the creators) but would like to create a file with the title, author (channel name) and URL though the channel name could be dropped.\n Searching just seems to give me lots of tool for downloading the videos themselves but not just the playlist...\n    submitted by    /u/ADB-UK  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztq570/archive_a_youtube_playlist_not_the_videos/",
          "publishedOn": "2022-12-23T19:15:38.000Z",
          "wordCount": 16218,
          "title": "Archive a YouTube playlist NOT the videos themselves",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztph8b/how_to_archive_entire_subreddit/",
          "author": null,
          "description": "So we all know that reddit lists are limited to 1000 posts at a time, but push shift archives everything so theoretically you should be able to use that website to get all post submissions from a subreddit.\n Now the real question is, how would you be able to archive an entire subreddit(including the media posted). I have seen things like telegram bots but they will only archive stuff from the date they are added, not useful at all for getting stuff that's already been posted.\n    submitted by    /u/overratedcabbage_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztph8b/how_to_archive_entire_subreddit/",
          "publishedOn": "2022-12-23T18:46:46.000Z",
          "wordCount": 15541,
          "title": "How to Archive Entire Subreddit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztpg7z/is_it_possible_to_clone_a_dying_hdd_to_a_new_one/",
          "author": null,
          "description": "This old HDD has 40k hours on it, has 100% usage all the time (slow as hell), and is \"Caution\" on CrystalDiskInfo. I wonder if it's possible (albeit slow) or the process would just kill the old HDD \n Edit: CDI data https://pastebin.com/EhatQnTS\n    submitted by    /u/lkusen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztpg7z/is_it_possible_to_clone_a_dying_hdd_to_a_new_one/",
          "publishedOn": "2022-12-23T18:45:30.000Z",
          "wordCount": 16060,
          "title": "Is it possible to clone a dying HDD to a new one using Macrium?",
          "imageUrl": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&s=07c121a0180003f7373863af66192b6ff6a937da"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztok6e/resyncing_a_single_bay_synology_nas_with_two/",
          "author": null,
          "description": "Hello,\n I reached out to Synology about this but the tech wasn’t sure how to answer it.\n I use a Synology single-bay NAS and the Cloud Sync application to mirror all of my data (one root folder with all data inside) to both Backblaze B2 and Google Drive. The syncing is up to date, so Backblaze and Google Drive have copies of every piece of data I own, and further, so does a WD 16TB external drive. The really important stuff is further backed up on my PC, laptop, bluray discs, other external drives (one being at a friend’s house), Microsoft OneDrive, and Mega.io, so I’m not concerned about data loss.\n I am wondering, though, if my Synology hard drive fails permanently, is anyone here able to outline the least time consuming workflow it would take to setup a brand new Synology NAS (or new drive in the original Synology tower) to sync up with both Backblaze B2 and Google Drive the way the original Synology drive did, so that anything I add to the root folder will continue being seamlessly backed up to both cloud services as before? Since I have the a WD external drive with the entirety of my data (same exact data as on Backblaze B2 and Google Drive), could I transfer that root folder with all of my data from the WD external to the new Synology NAS, and then can Cloud Sync compare the contents between that folder, Backblaze and Google drive and consider them to be synced up without the need for mass upload / download again?\n Thank you for your time. Please let me know if I may clarify anything I’ve outlined above.\n    submitted by    /u/Arachnatron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztok6e/resyncing_a_single_bay_synology_nas_with_two/",
          "publishedOn": "2022-12-23T18:06:36.000Z",
          "wordCount": 18131,
          "title": "Re-syncing a single bay Synology NAS with two cloud storage providers via Cloud Sync after total disc failure.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zto65b/a_true_story/",
          "author": null,
          "description": "submitted by    /u/AshleyUncia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zto65b/a_true_story/",
          "publishedOn": "2022-12-23T17:49:52.000Z",
          "wordCount": 16913,
          "title": "A True Story",
          "imageUrl": "https://preview.redd.it/5vvromd1ro7a1.jpg?auto=webp&s=960b94026c50417a3d5d7bc508c63d6792b5d0dd"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztnw4x/looking_for_an_18tb_hard_drive/",
          "author": null,
          "description": "I am looking for an 18TB external hard drive for my movie storage for PLEX and am wondering what the best option is. Just asking for opinions. I have been seriously considering the WD Gold as I have one and it is rock solid after 5 years\n    submitted by    /u/kewlncguy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztnw4x/looking_for_an_18tb_hard_drive/",
          "publishedOn": "2022-12-23T17:44:00.000Z",
          "wordCount": 15217,
          "title": "Looking for an 18TB Hard drive.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztnuta/lto_setup_where_are_all_the_drivers/",
          "author": null,
          "description": "I'm trying to set up a Quantum HP LTO-6 drive. Removed it from the chasey and installed in the optical bay. Using a Dell LightPulse (now known as Emulex) PCI-E card. \n Dell has a section for Emulex drivers but can't recognize my PC so it won't give me any drivers. Their assistant tool only works with Dell PCs. \n I've seen some other folks here with similar HP LTO setups. Hopefully someone here encountered this same roadblock and can help!\n    submitted by    /u/Plebsolute  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztnuta/lto_setup_where_are_all_the_drivers/",
          "publishedOn": "2022-12-23T17:43:16.000Z",
          "wordCount": 16310,
          "title": "LTO setup, where are all the drivers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztmnyn/toshiba_website_says_5_years_warranty_for_hdd_but/",
          "author": null,
          "description": "Hello, I'll be buying a couple Toshiba 18TB MG09ACA18TE in Europe. Toshiba's website says this drive has 5 years warranty, while the seller says it has 2 years.\n https://www.toshiba-storage.com/wp-content/uploads/2021/02/MG_Series_Datasheet_B2C_Website.pdf\n Will I get my full 5 year warranty from Toshiba if I buy from this seller?\n    submitted by    /u/jakuri69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztmnyn/toshiba_website_says_5_years_warranty_for_hdd_but/",
          "publishedOn": "2022-12-23T17:10:51.000Z",
          "wordCount": 16511,
          "title": "Toshiba website says 5 years warranty for HDD, but 3rd party seller says 2 years warranty?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztmlcl/would_it_be_possible_to_download_an_entire_tv/",
          "author": null,
          "description": "What I mean is would it be possible to download a TV show's, for instance Nickelodeon, entire run? I realise this would be colossal in GB, but still.\n    submitted by    /u/Voldy256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztmlcl/would_it_be_possible_to_download_an_entire_tv/",
          "publishedOn": "2022-12-23T17:07:50.000Z",
          "wordCount": 15482,
          "title": "Would it be possible to download an entire TV channel?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztjxwc/nvmeof_with_two_clients/",
          "author": null,
          "description": "Hi!\n Has anyone ever created an nvme-of host (target) where two clients connect to it? Is that a supported use case?\n Thank you!\n    submitted by    /u/SnooPaintings709  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztjxwc/nvmeof_with_two_clients/",
          "publishedOn": "2022-12-23T15:47:56.000Z",
          "wordCount": 15742,
          "title": "Nvme-OF with two clients?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ztjglm/the_dream/",
          "author": null,
          "description": "submitted by    /u/DragoniteChamp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ztjglm/the_dream/",
          "publishedOn": "2022-12-23T15:30:51.000Z",
          "wordCount": 17816,
          "title": "The dream 🙏",
          "imageUrl": "https://preview.redd.it/pu1zeq3ujp7a1.jpg?auto=webp&s=85d167af2b15262a706af7cb4ad1c8939c9a1a75"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zth54k/newbie_hard_drive_question/",
          "author": null,
          "description": "I'm thinking of getting my first external hard drive for the purpose of storing stuff I don't necessarily need but don't want to delete, like videos I've recorded that are several gigabytes big. (My computer only has a few gigabytes left to spare out of ~1.1 terabytes of storage which is why I'm doing this, lol) \n I'm considering getting a 6 TB Seagate Expansion Hard Drive, would that be a good for this purpose or are there any better options?\n    submitted by    /u/BeepityBot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zth54k/newbie_hard_drive_question/",
          "publishedOn": "2022-12-23T14:30:51.000Z",
          "wordCount": 17304,
          "title": "Newbie hard drive question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt3sng/looking_for_an_image_sorting_program/",
          "author": null,
          "description": "My Girlfriend has a hard drive with about 250Gbs of pictures, all in a single folder. \n We are working on getting these organized and put onto our NAS.\n Years ago, I had a program that would show you each image, and you would select a number from 1-9, which mapped to a folder, and it was easy to speed through and quickly sort large amounts of photos. \n Has anyone heard of software like this? I can't for the life of me remember what it was called.\n    submitted by    /u/Mofks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt3sng/looking_for_an_image_sorting_program/",
          "publishedOn": "2022-12-23T02:11:52.000Z",
          "wordCount": 15850,
          "title": "Looking for an image sorting program",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt2kfl/can_i_download_all_instagram_reels_at_once_from_a/",
          "author": null,
          "description": "I use WFDownloder and it doesn't download multiple reels\n    submitted by    /u/district999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt2kfl/can_i_download_all_instagram_reels_at_once_from_a/",
          "publishedOn": "2022-12-23T01:10:16.000Z",
          "wordCount": 15669,
          "title": "Can I download all instagram reels at once from a profile?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt2guw/how_should_i_set_my_scan_settings_to_digitize/",
          "author": null,
          "description": "submitted by    /u/lamy1989  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt2guw/how_should_i_set_my_scan_settings_to_digitize/",
          "publishedOn": "2022-12-23T01:05:17.000Z",
          "wordCount": 16350,
          "title": "How should I set my scan settings to digitize over 1,000 photos using Epson Perfection V600? 1200 vs 600 DPI makes a huge difference, but takes up a lot more space.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt1wha/setting_up_a_wd_2_tb_easystore_for_a_complete/",
          "author": null,
          "description": "Hello,\n I am very new to the world of data storage and just bought a 2 TB hard drive after I noticed I was running out of space on my laptop. I bought the external HDD hard drive because I wanted to be able to back up important game projects I've worked on as well as software (everything will dissapear on the internet one day, etc) and have looked through this subreddit.\n I've already deleted the installer that comes with the hard drive but I really am not sure what to do next. I think I need to wipe and partition(?) the HDD and run tests to make sure it's ok but I'm not sure what software I'd need to download for all that. I'd also appreciate any tips to make sure I can keep this alive for long to the best of my ability. Thank you\n    submitted by    /u/FullAd419  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt1wha/setting_up_a_wd_2_tb_easystore_for_a_complete/",
          "publishedOn": "2022-12-23T00:37:29.000Z",
          "wordCount": 16705,
          "title": "Setting up a WD 2 TB Easystore for a complete beginner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zt0n8b/game_faqs_download_txt_bookmarklet/",
          "author": null,
          "description": "in case someone wants do download faqs or have inspiration how to scrape site, you can use this bookmarklet\n just open game's faq list, run bookmarklet, when link turns into red border you can click it and save txt file\n (as is it will work only for txt files, it can be modified to include html files and with more time even with images embedded as data urls)\n javascript:(function(){ [...document.querySelectorAll('.list.guides .content a.bold')] .forEach(a=>get_faq(a.href).then(f=>dl_faq(a,a.parentElement.innerText,f))); function get_faq(url) { return fetch(url) .then(r=>r.text()) .then(t=>t.match(/<pre.*?>(.+)<\\/pre>/s)) .then(m=>m&&m[1]||'') .then(f=>f.replaceAll(/<\\/?pre.*?>/g,'')) .then(f=>f.replaceAll('&lt;','<')) .then(f=>f.replaceAll('&gt;','>')) .then(f=>f.replaceAll('&quot;','\"')) .then(f=>f.replaceAll('&amp;','&')); } function dl_faq(a,name,txt) { a.href = 'data:text/plain;charset=utf-8,'+encodeURIComponent(txt); a.download = name+'.txt'; a.style.border = '1px solid red'; } })() \n [edit] added replacing entities with actual characters, license is public domain\n    submitted by    /u/KHRoN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zt0n8b/game_faqs_download_txt_bookmarklet/",
          "publishedOn": "2022-12-22T23:39:54.000Z",
          "wordCount": 16681,
          "title": "game faqs download txt bookmarklet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zszyrq/the_internet_archive_is_down_for_maintenance/",
          "author": null,
          "description": "Update: it’s back.\n Does anyone have any inside information? I can’t remember the last time that it went completely inaccessible.\n    submitted by    /u/EHypnoThrowWay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zszyrq/the_internet_archive_is_down_for_maintenance/",
          "publishedOn": "2022-12-22T23:17:15.000Z",
          "wordCount": 15865,
          "title": "The Internet Archive is Down For Maintenance (12-22-22, 17:14 CST)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zszjx2/looking_for_an_old_british_tv_show/",
          "author": null,
          "description": "I have the first 2 seasons of Watching (1987) but I cannot find the other 5 anywhere! Is there anywhere I can try that I might not have heard of (or thought of)?\n    submitted by    /u/michaelprstn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zszjx2/looking_for_an_old_british_tv_show/",
          "publishedOn": "2022-12-22T23:00:11.000Z",
          "wordCount": 16634,
          "title": "Looking for an old British TV show",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsyfic/a_storm_is_coming/",
          "author": null,
          "description": "So I'm resilvering my 4th of 4 drives that I'm upgrading in my truenas scale nas. I'm at 60% completed with about 3.3 (of 9) days left to go. I don't have a ups and there's a good chance we'll have a power outage because of the storm headed to my part of the US tonight into tomorrow evening. Can/should I power down the nas now? Will it pickup where it left off when I boot it up again?\n Any insights are appreciated. TIA\n    submitted by    /u/SurenAbraham  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsyfic/a_storm_is_coming/",
          "publishedOn": "2022-12-22T22:12:25.000Z",
          "wordCount": 15801,
          "title": "A storm is coming",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsy7uj/help_me_build_a_server/",
          "author": null,
          "description": "Yeah, the time finally came. My \"gaming PC\" that was converted to a home server isn't enough anymore. I just mounted a hard drive in a cooler slot, and feel terrible about it.\n It's about time that I get a proper server rack and the components inside it.\n My use:\n  \nStorage. I'm now at the 10TB mark, but that's not nearly enough. Not to mention, I do not have backups for everything, just for the really important stuff.\n Jellyfin. Lots of bluray 2160p videos, the server should be capable of streaming at least 3 at a time.\n 2x Minecraft Servers with mods. I noticed this isn't really heavy on my server (besides RAM usage), so I need to have some RAM available for that.\n  \nWhen built, I also want to selfhost Nextcloud, Vaultwarden and archive odd videogame ROMs, besides all of the previously mentioned.\n I cannot have a big server rack. It simply doesn't fit in my home. Maybe in the future, but for now I want something on the smaller side. I'm also not with a lot of money, so if possible, something cheap will be great :P (Used server equipment?)\n So, I need help. What do I need to buy? What do I need to understand? I'm not from the US\n    submitted by    /u/OliveEar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsy7uj/help_me_build_a_server/",
          "publishedOn": "2022-12-22T22:04:01.000Z",
          "wordCount": 17086,
          "title": "Help me build a server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsx8cn/buying_used_hdd_smart_report_interpretation/",
          "author": null,
          "description": "I saw a relatively good deal for 2 HDDs and the seller was kind enough to attach a SMART report. \n Is anyone able to help interpret this data? One thing that has me concerned is the Reallocated sector count. Any help would be greatly appreciated, thanks!\n    submitted by    /u/kaygee420  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsx8cn/buying_used_hdd_smart_report_interpretation/",
          "publishedOn": "2022-12-22T21:22:20.000Z",
          "wordCount": 16159,
          "title": "Buying used HDD SMART report interpretation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zswt4g/thunderbolt_34_nvme_multi_drive_enclosure/",
          "author": null,
          "description": "I’m a video editor and I frequently work with huge files (8K RedRaw or Phantom CineRaw etc). I’m looking for a fast storage solution that I can edit off of. I was looking at the OWC Express 4M2 which allows large capacity storage running at 2.8GBs with four drives running RAID 0. (https://eshop.macsales.com/item/OWC/TB3EX4M2/ )\n I was digging into its specs and it says it requires four drives in RAID 0 because the drives inside are limited to 700MBs due to being a 1-lane PCIe connection. \n There are single drive thunderbolt 3/4 enclosures out there which offer similar speeds but I’m looking for large capacity along with speed. \n Before I pull the trigger, I was wondering if there was anything else out there that could be faster that would better fit my needs?\n (Yes I realize in my hunt for speed this is probably overkill, but I’d like to do my due diligence).\n    submitted by    /u/Canadian__Tired  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zswt4g/thunderbolt_34_nvme_multi_drive_enclosure/",
          "publishedOn": "2022-12-22T21:04:30.000Z",
          "wordCount": 17413,
          "title": "Thunderbolt 3/4 NVMe multi drive enclosure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zswrq5/how_to_pull_files_from_a_txt_file/",
          "author": null,
          "description": "I have a bunch of files listed in a txt file. They are names of photos the clients want. What is the fastest way to find these jpg files and copy to a new folder? I could use Everything but it would take forever. Pls help\n Updated with example: Windows 10 folder A has 5000 photos. File.txt has the file names of about 200 photos we need, also in same folder A. Would be great to auto copy these 200 photos into folder B.\n    submitted by    /u/tungvu256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zswrq5/how_to_pull_files_from_a_txt_file/",
          "publishedOn": "2022-12-22T21:02:49.000Z",
          "wordCount": 17119,
          "title": "how to pull files from a txt file?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsw1hw/where_could_i_find_my_favorite_books_and_shows/",
          "author": null,
          "description": "If this isn't allowed please don't ban me I like y'all. \n I want to be able to get a hold of all my favorite books, shows and movies and I'm not afraid of the high seas but I am a new sailor. Can anyone point me to the right direction or sub. \n Thanks.\n    submitted by    /u/TroothBeToldPodcast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsw1hw/where_could_i_find_my_favorite_books_and_shows/",
          "publishedOn": "2022-12-22T20:31:38.000Z",
          "wordCount": 16207,
          "title": "where could I find my favorite books and shows",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsvta6/rsync_on_debian_nothing_is_copying_but_only/",
          "author": null,
          "description": "I'm copying items from one debian server to another and trying to use Rsync for the process. I had issues getting it working over 10GB lanes but finally fixed that. My issue now is the command is coming back with 'Receiving incremental file list' and then quits but nothing is copied.\n For reference, if I ssh into either one I land in the root folder and have to do cd ../srv/disk/ in order to get into my shares. On the destination server (in the command below) I have an empty directory called Music. The source server has the Music directory full of folders and files and I'm trying to copy all contents into the empty Music folder on the dest.\n The command:\n rsync -ahP --chmod=D777,F666 --address=10.10.10.15:./srv/27829c9c-dbc1-4408-a111-56dbcd8f0ec0/media/Music/ [root@10.10.10.13](mailto:root@10.10.10.13):/srv/27829c9c-dbc1-4408-a111-56dbcd8f0ec0/media/Music\n is coming back with:\n receiving incremental file list\n drwxrwxrwx 4.10K 2022/12/18 13:00:29 Music\n What am I doing wrong?\n    submitted by    /u/FourTimesRadical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsvta6/rsync_on_debian_nothing_is_copying_but_only/",
          "publishedOn": "2022-12-22T20:21:43.000Z",
          "wordCount": 15583,
          "title": "Rsync on debian, nothing is copying but only receiving file list",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsv93m/i_miss_when_vcrs_were_common_and_the_attitude/",
          "author": null,
          "description": "people would just tape shit off TV that they liked or might wanna see later. sports games, films, TV episodes, whatever\n nowadays people seem to willingly kneel to the streaming gods -- you will own nothing, and you will be happy. everything is DRMed, you can't even take a fucking screenshot! \n if you told someone 'i'm gonna record this off hulu' they'd get pissy because you're not meant to do that\n    submitted by    /u/spacewalk__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsv93m/i_miss_when_vcrs_were_common_and_the_attitude/",
          "publishedOn": "2022-12-22T19:57:48.000Z",
          "wordCount": 18949,
          "title": "I miss when VCRs were common, and the attitude they fostered",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsujt0/backup_program_for_windows/",
          "author": null,
          "description": "Hello,\n I recently switched from windows 10 to windows 11 which has made filehistory an even bigger mess to use so I want to look for an alternative that works better. \n What I want to accomplish:\n Incremental back-ups (don't want it to create a full back-up everytime)\n Have it automatically back-up to my NAS\n Able to select which folders to back-up\n A nice to have would also be a filehistory way where I can go back to a version X days ago.\n Anyone have a recommendation for software able to accomplish this (preferably something lightweight)\n    submitted by    /u/StarLines  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsujt0/backup_program_for_windows/",
          "publishedOn": "2022-12-22T19:27:40.000Z",
          "wordCount": 16264,
          "title": "Back-up program for windows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zst0ro/i_made_an_reddit_post_unsaver_bot_that_you_guys/",
          "author": null,
          "description": "submitted by    /u/Wari0-_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zst0ro/i_made_an_reddit_post_unsaver_bot_that_you_guys/",
          "publishedOn": "2022-12-22T18:23:20.000Z",
          "wordCount": 14615,
          "title": "I made an reddit post unsaver bot that you guys can use with a downloader like BDFR to make archiving easier and not have struggle with RedderManager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zssckz/nas_drive_noises_warranty/",
          "author": null,
          "description": "Hey folks, \n bought 2x 4tb seagate ironwolf and now after finding time to build my proxmox homelab with a truenas VM on it I noticed that one of the drives is making interesting noises. I would consider the type of noise \"normal\" for a hard drive but not this frequent. s.m.a.r.t test says everything is fine though. \n They have still warranty but because I'm not an expert I wanted to ask you guys what to do maybe someone here had the same issue and there is a easier way than contacting seagate and sending the drive to them. Or maybe im just paranoid but I don't think that this is normal. \n Many thanks in advance :) \n ​\n https://reddit.com/link/zssckz/video/fpaz5whmmh7a1/player\n    submitted by    /u/beluga030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zssckz/nas_drive_noises_warranty/",
          "publishedOn": "2022-12-22T17:55:56.000Z",
          "wordCount": 15752,
          "title": "NAS Drive noises (warranty?)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zss3cp/downloading_bookmarks_as_individual_html_files/",
          "author": null,
          "description": "I have quite a bit of websites bookmarked and was wondering if there's an efficient way to save those websites for offline viewing? \n I know I can just go through and individually download websites with webcopy or a similar app, but I wanted to ask if there's any way to do it faster.\n If you need to know my browser, I currently use Brave.\n Thank you in advance.\n Edit : forgot to mention, I'm a windows user if that matters.\n    submitted by    /u/noxwolfdog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zss3cp/downloading_bookmarks_as_individual_html_files/",
          "publishedOn": "2022-12-22T17:45:36.000Z",
          "wordCount": 15253,
          "title": "Downloading bookmarks as individual HTML files",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsryk2/wd_elements_desktop_16tb_external_hard_drive/",
          "author": null,
          "description": "submitted by    /u/Viknee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsryk2/wd_elements_desktop_16tb_external_hard_drive/",
          "publishedOn": "2022-12-22T17:40:12.000Z",
          "wordCount": 14685,
          "title": "WD Elements Desktop 16TB External Hard Drive - $239.99 ($15/TB) (US)",
          "imageUrl": "https://external-preview.redd.it/Y0XFFKydAOckP0wTkH_8Taf5Un5j6xMy1vfIV7-7j3A.jpg?auto=webp&s=c7f8368496484ab2fea5fe68384ccf822a3fd5f2"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsoy2p/321_2nd_local_copy_does_this_need_to_be_automated/",
          "author": null,
          "description": "Assuming you have all data centralized and you have an automated offsite backup, would you consider an effective 3-2-1 backup solution to have an automated local backup as well, or would a simple rotated cold storage solution suffice?\n    submitted by    /u/StrongCommission  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsoy2p/321_2nd_local_copy_does_this_need_to_be_automated/",
          "publishedOn": "2022-12-22T15:39:10.000Z",
          "wordCount": 15036,
          "title": "3-2-1: 2nd local copy, does this need to be automated?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsfgt5/why_we_hoard_nintendo_minute_videos_are_being_set/",
          "author": null,
          "description": "submitted by    /u/Brancliff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsfgt5/why_we_hoard_nintendo_minute_videos_are_being_set/",
          "publishedOn": "2022-12-22T07:11:56.000Z",
          "wordCount": 16314,
          "title": "Why We Hoard: Nintendo Minute Videos Are Being Set To Private On Nintendo's YouTube Channel",
          "imageUrl": "https://external-preview.redd.it/I20YQAH3bXT3Qgz9LKnF3lCszWhe5cR_FZuMIc4DPeU.jpg?auto=webp&s=dc6122900e685997b5974f3ecfaae6e00861033b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zsac6s/hdd_prices_too_good_to_be_true_on_facebook/",
          "author": null,
          "description": "There's a Facebook marketplace post near me that claims to have a box of 14TB Western Digital HC530 drives. They're selling them around $100 USD each. The serial numbers shown in the photos return no warranty, but they show up as WD products with the following model number: 0F31156 and description: LEE Drive ASM 14.0TB, 512e, SATA P3_PWDIS_Support, Amazon, Secure Erase.\n Would these be safe to buy? What can I do to check they truly are the capacity they claim they are?\n I would like to do a full check with H2testw, but I've been told it takes a while. What would you do?\n Thanks in advance.\n Edit: they also show crystal disk info screenshots\n Edit 2: there seem to be 2 sellers, one that is a clearance warehouse, and the other that has a physical retail location and offers a 6 month warranty, so I'll add updates as I go\n    submitted by    /u/LNR_Music_Curation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zsac6s/hdd_prices_too_good_to_be_true_on_facebook/",
          "publishedOn": "2022-12-22T03:06:09.000Z",
          "wordCount": 17841,
          "title": "HDD prices too good to be true on Facebook Marketplace",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs837e/syncing_folders_between_hard_drives_on_the_same/",
          "author": null,
          "description": "The right way would probably be to raid 2 drives together and mirror them, but i don't really like the idea of having a backup, but at the same time, said backup is destroyed whenever i accidentally completely delete a file on a hard drive, since it mirrors the action on the other\n also, i don't have 2 equal hard drives, so i'd get the worse writting and the worse reading speeds from both \n either way, i wanna sync a folder every night, so that every change i made to a folder on one drive during the day, gets copied over to the other drive during the night at a specified hour\n New files, Edited files, different files with the same file name, deleted files, all completely mirrored from the drive i used during the day, but only perform the changes at night, or maybe every other day even\n ​\n what program could i use to do that?\n    submitted by    /u/peugamerflit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs837e/syncing_folders_between_hard_drives_on_the_same/",
          "publishedOn": "2022-12-22T01:27:53.000Z",
          "wordCount": 15775,
          "title": "syncing folders between hard drives on the same comuter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs7gpu/i_need_help_gathering_data_on_opinioms_about/",
          "author": null,
          "description": "https://docs.google.com/forms/d/e/1FAIpQLSc-y_AjvI5j2kAczbN57mYqaLiyROa3639qMKzmRjVabom5jw/viewform?usp=sf_link\n It's just 3 questions but any answers are appreciated\n    submitted by    /u/Ok-Thought-3962  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs7gpu/i_need_help_gathering_data_on_opinioms_about/",
          "publishedOn": "2022-12-22T01:01:12.000Z",
          "wordCount": 15345,
          "title": "I need help gathering data on opinioms about digital twin technology",
          "imageUrl": "https://external-preview.redd.it/imz3IIfOe5tS0izphogzvSyXP4XTpjWYWm_HIoM9NNQ.jpg?auto=webp&s=30f69e5f53aabf8d4985b0871d5f04653d855dbd"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs6kb7/data_versioning_between_2_pc_over_network/",
          "author": null,
          "description": "Honestly, not sure if this is even the right sub, but anyways....\n Got 2 pc on local network, both windows 11 pc. Is there a way to do this\n  \npc gets a new file/folder in a monitered directory\n \nProgram checks pc 2 over network to see if that same folder or file is already in pc 2 watched directories\n \nIf new file or folder is not in those watched directories, ask if it wants to move it to a folder on pc 2\n \n I mean even if it's just a batch script that's be cool.\n    submitted by    /u/DR4LUC0N  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs6kb7/data_versioning_between_2_pc_over_network/",
          "publishedOn": "2022-12-22T00:24:31.000Z",
          "wordCount": 15414,
          "title": "Data versioning between 2 pc over network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs6gz8/where_to_find_old_footballnbanfltennis_matches_in/",
          "author": null,
          "description": "I love watching sports, and want to watch classic matches especially for football and tennis. Is there a way to watch and download them?\n    submitted by    /u/godeater123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs6gz8/where_to_find_old_footballnbanfltennis_matches_in/",
          "publishedOn": "2022-12-22T00:20:45.000Z",
          "wordCount": 16287,
          "title": "Where to find old football/nba/nfl/tennis matches in full hd quality?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs3dam/how_to_download_a_video_thats_hosted_on_netutv_i/",
          "author": null,
          "description": "Netu.tv has some serious content protection. There are some videos on a website (nsfw but irrelevant because its only the videos hosted on Netu.tv that are the problem) I'm trying to download that use Netu.tv as their host, and require the user to manually click a play button that shows up somewhere in a rectangular area (random spot so a bot couldn't click the center of the video area) before the video even loads into the site. I can't right click anything in the video player area, opening up developer tools causes the video to disappear without a trace in the \"Elements\" section, disabling JavaScript does nothing to stop the removal of said video once Developer Tools opens. JDownloader picks up nothing because the webpage its on has no video technically, only after the user's manual input does the Netu.tv media appear. Extensions on Google Chrome like CocoNut don't pick it up, even with \"force download\". Certainly someone amongst the data hoarding hivemind can find a way to fetch these videos? Preferably in their raw form and not just via screen-recording?\n    submitted by    /u/GamingDragon27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs3dam/how_to_download_a_video_thats_hosted_on_netutv_i/",
          "publishedOn": "2022-12-21T22:26:51.000Z",
          "wordCount": 15839,
          "title": "How to download a video that's hosted on netu.tv? I see some articles/threads from a while back on successful ways to but they all seem outdated. Jdownloader, developer tools, and browser extensions don't pick it up. Looks as if its truly unhoard-able?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs20nz/djing_usb_stick_maybe_corrupted/",
          "author": null,
          "description": "While I was playing my last track of my DJ set the next dj accidentally bumped into my stick and it got ejected :( the final song even had a weird cut in the end. Should I now directly format it or can I somehow salvage this situation? I really don't want to download all the music manually again and make thousand new playlists aaaa\n Thanks in advance!\n    submitted by    /u/MarionberryEnough658  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs20nz/djing_usb_stick_maybe_corrupted/",
          "publishedOn": "2022-12-21T21:48:54.000Z",
          "wordCount": 16732,
          "title": "DJing USB Stick maybe corrupted?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs1jel/youtube_videos_on_wayback_machine/",
          "author": null,
          "description": "Hey folks.\n This one is annoying me! - There's a historic Youtube video that has been made unavailable for copyright - There are a few other copies on YouTube, but as I recall this was the only one that is in any decent definition.\n https://www.youtube.com/watch?v=w_8dafLxLcI\n On Wayback machine, it goes back to 2008, but those older versions all seem to want Flash and I can't work out how on earth to download them anyway. It's nice of Archive.org to have it archived, but if you can't use it, that's annoying.\n https://web.archive.org/web/20110227200859/http://www.youtube.com/watch?v=w_8dafLxLcI\n Am I just missing something obvious?\n    submitted by    /u/Hacklet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs1jel/youtube_videos_on_wayback_machine/",
          "publishedOn": "2022-12-21T21:30:40.000Z",
          "wordCount": 15637,
          "title": "Youtube videos on Wayback Machine",
          "imageUrl": "https://external-preview.redd.it/e7IUn6nxc_nqwfY-luK-p82DX8uFkO5QSuc7YFZSz4U.jpg?auto=webp&s=1480d38c15d03358efd98d0ced110a122ab840ed"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs1j6p/how_to_clean_up_400gb_data/",
          "author": null,
          "description": "Following a family death I’ve ended up with about 400gb of data pulled from around a dozen mixed drives. I’ve transferred it onto my NAS and stored it in folders by source. (It was easier to harvest it into one location for my wife to pull some family photos from). The storage was chaotic!!! There were recent (i.e newish) drives that had some old stuff, but not all the old stuff, as well as some stuff that appears to be the only copy. Some drives even contained the same data multiple times buried in folders inside folders. 🤯\n I’m running synology DS920+. What’s the easiest way to pull data out by type and remove duplicates? E.g. pull all the photos out into a single folder. I don’t want to lose anything but I don’t need 40 copies of a school nativity from 20 years ago.\n    submitted by    /u/WeirdPerception1984  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs1j6p/how_to_clean_up_400gb_data/",
          "publishedOn": "2022-12-21T21:30:27.000Z",
          "wordCount": 17308,
          "title": "How to clean up 400gb data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs180e/purchasing_a_2_bay_nas_wd_mycloud/",
          "author": null,
          "description": "So the title says it all. I am looking at the WD MyCloud 2bay Expert EX2 NAS. I currently have 2 separate 2tb externals hooked up to my Linux server and my wife directly backs her phones photos to it via the wifi network connection. Plus we stream some media and use it for backup files, etc. I currently run rsync to copy one HD to the other every few months for redundancy. One main feature I want in a NAS is the raid option so I don't have to continue to manually back up the redundancy.\n Is this a good device for me to upgrade to?\n Here is the link for Best Buy. Also, I'd love other suggestion but I need to stay at the $160ish price point. \n https://www.bestbuy.com/site/wd-my-cloud-expert-ex2-ultra-2-bay-0tb-external-network-attached-storage-nas-charcoal/5061402.p?skuId=5061402#anchor=productVariations\n    submitted by    /u/onebasix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs180e/purchasing_a_2_bay_nas_wd_mycloud/",
          "publishedOn": "2022-12-21T21:18:52.000Z",
          "wordCount": 17713,
          "title": "Purchasing a 2 Bay NAS, WD MyCloud?",
          "imageUrl": "https://external-preview.redd.it/mIhJl4qMhF4MpRmW0zdDoIuqLZKEP3kykEatkPxZrUU.jpg?auto=webp&s=91f72b2dd6ba8f7c0eedbd6273c145f0142be761"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zs0ice/how_would_i_download_a_video_from_a_website_that/",
          "author": null,
          "description": "The video stops playing and a notice appears instead basically removing it from the page. I've tried JDownloader and it doesn't pick up the video either.\n    submitted by    /u/GamingDragon27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zs0ice/how_would_i_download_a_video_from_a_website_that/",
          "publishedOn": "2022-12-21T20:52:27.000Z",
          "wordCount": 17444,
          "title": "How would I download a video from a website that doesn't allow opening \"developer tools\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrz9yw/do_you_have_a_lot_of_media_on_your_phone_at_all/",
          "author": null,
          "description": "Movies/music/books/comics/manga? \n What type?\n How much GB?\n    submitted by    /u/warrenmax12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrz9yw/do_you_have_a_lot_of_media_on_your_phone_at_all/",
          "publishedOn": "2022-12-21T20:06:07.000Z",
          "wordCount": 15226,
          "title": "Do you have a lot of media on your phone at all times?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zry24l/is_there_any_software_that_lists_all_files/",
          "author": null,
          "description": "Okay so, I'm found a couple inconsistencies between my two Hard Drives (seems I did a bad job of kerlong them consistent) with docs that were updated in one but not updated accordingly in the other. They were easy fixes but I wanna check for more inconsistencies including file moves. However I don't wanna be checking through so many files one by one.\n I know windows explorer can list all files of a type, showing modification dates for each, but that doesn't include folders and there could be some file types I'm forgetting. Is there a software that would list everything for each hard drive, with the modification dates so I can go through and compare lists for both?\n Bonus points if they can list everything with a number, to make things even easier.\n    submitted by    /u/ToqKaizogou  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zry24l/is_there_any_software_that_lists_all_files/",
          "publishedOn": "2022-12-21T19:20:28.000Z",
          "wordCount": 15954,
          "title": "Is there any software that lists all files, folders and subfolders on a hard drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrxw1m/i_posted_a_couple_of_days_ago_some_smart_errors/",
          "author": null,
          "description": "submitted by    /u/skeptibat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrxw1m/i_posted_a_couple_of_days_ago_some_smart_errors/",
          "publishedOn": "2022-12-21T19:13:58.000Z",
          "wordCount": 16650,
          "title": "I posted a couple of days ago some SMART errors on my drives... I scandisk'd and zero'd and wrote random bits and it seems... a little better?",
          "imageUrl": "https://preview.redd.it/yknxbmq3wa7a1.png?auto=webp&s=d79fef170a961e80ed103f427725b434bd1568cd"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrxoj7/shipping_bdr_discs_in_freezing_temps/",
          "author": null,
          "description": "I just placed an order for a bunch of 50gb and 100gb BD-R discs. Where I'm located the temperatures at this time of the year are below freezing. Should I be concerned about the discs getting damaged during shipping due to the temps?\n    submitted by    /u/HarryMuscle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrxoj7/shipping_bdr_discs_in_freezing_temps/",
          "publishedOn": "2022-12-21T19:06:01.000Z",
          "wordCount": 15452,
          "title": "Shipping BD-R Discs in Freezing Temps?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrx77d/how_do_i_download_this_website_that_only_works_on/",
          "author": null,
          "description": "https://promo.shonenjump.com/jujutsu/shibuya/\n Can’t access it on pc.\n    submitted by    /u/xkilluaaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrx77d/how_do_i_download_this_website_that_only_works_on/",
          "publishedOn": "2022-12-21T18:47:56.000Z",
          "wordCount": 16260,
          "title": "How do I download this website that only works on mobile?",
          "imageUrl": "https://external-preview.redd.it/5J-ylWj9tdrF6T7N3ooMybGtX1JyctCDJP_aOc0PqTQ.jpg?auto=webp&s=c46a9fdb234c092bbf02ccdf8f2bc65d68113713"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrwymq/is_there_a_way_to_searching_multiple_epub_and_pdf/",
          "author": null,
          "description": "So I have recently gotten into hoarding cookbooks. However when I am looking for a recipe for let's say \"apple pie\" it seems that I have open one by one to search. Is there a way to search every index at once? Currently using calibre 64bit.\n ​\n Sorry I am not sure this is right place to ask...\n    submitted by    /u/overimbibe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrwymq/is_there_a_way_to_searching_multiple_epub_and_pdf/",
          "publishedOn": "2022-12-21T18:39:48.000Z",
          "wordCount": 15474,
          "title": "Is there a way to searching multiple epub and pdf?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrvsms/current_situation_about_shucking_wd_elementsmy/",
          "author": null,
          "description": "Hello,\n last time I shucked an external drive years ago, they were pretty much WD Red drives. \n I am planning to have one again as an internal drive.\n How is the situation now? Is it recommended? Does it have any downsides? Are they still red ones? Do I have to tape that one pin for both versions (Elements/My Book)?\n Do you suggest to buy other brands? I was pretty happy about WD Red ones but maybe there are better ones considering price-performance?\n Thanks.\n    submitted by    /u/SleepyTimeNowDreams  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrvsms/current_situation_about_shucking_wd_elementsmy/",
          "publishedOn": "2022-12-21T17:58:50.000Z",
          "wordCount": 18488,
          "title": "Current situation about shucking WD Elements/My Book 8/10/12/14 TB? Reds? Pins?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrv72b/europe_segate_rma_what_the_hell/",
          "author": null,
          "description": "So, here in southern europe the RMA process for segate disks is running poorly or simply replacing the goods with other similar but not technically the same.\n This time the victim was me: Sent them a dead-still-under-warranty Ironwolf 6TB 7200 RPM disk (ST6000VN0033) and received an Ironwolf 6TB 5400 RPM (ST6000VN001). Sent them an email regarding this issue (have the support number), escalated the issue, and nobody replied. It has been now several days.\n Is this even legal? How can i best assure my rights as a consumer?\n Thanks for your help!\n    submitted by    /u/xupetas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrv72b/europe_segate_rma_what_the_hell/",
          "publishedOn": "2022-12-21T17:34:18.000Z",
          "wordCount": 15284,
          "title": "Europe Segate RMA?! What the hell?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrtfr1/should_i_mix_hdd_brandsmodels_raid_5_with_4_hdd/",
          "author": null,
          "description": "Building a 4 bay raid 5 storage for stoeing raw film.\n Choosing between 18TB red pro and ironwolf pro (beat peice per tb, red being slightly more expensive). Should I mix my purchase, 2 of each, to attempt to minimize failure?\n    submitted by    /u/andreifasola  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrtfr1/should_i_mix_hdd_brandsmodels_raid_5_with_4_hdd/",
          "publishedOn": "2022-12-21T16:34:59.000Z",
          "wordCount": 15905,
          "title": "Should I mix HDD brands/models? Raid 5 with 4 HDD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrslu4/pcie_x1_sata_controller/",
          "author": null,
          "description": "hello,\n im looking for a cheap pci e x1 sata controller with as many SATA ports as possible.\n found this one: \n https://www.amazon.de/Syba-SI-PEX40064-PCI-EXPRESS-Controller-Karte/dp/B00AZ9T3OU\n which controller would you recommend\n    submitted by    /u/reicto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrslu4/pcie_x1_sata_controller/",
          "publishedOn": "2022-12-21T16:14:31.000Z",
          "wordCount": 15504,
          "title": "PCI-E x1 SATA Controller",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrqeti/new_rclonebased_backup_tool_i_created_rirb/",
          "author": null,
          "description": "Executive Summary (TL/DR)\n Mimic \n $ rclone sync source: dest:curr --backup-dir dest:back/<date> \n but store the file listing to greatly speed it up. Also automatically store logs, diffs, etc.\n Main Post\n I am a huge fan of using rclone with --backup-dir (docs) for backups.\n It is not the most efficient, most featureful, advanced, sexy, fastest, etc. of the different backup solutions. But it makes up for all of this in a key area: simplicity. \n When it comes to backups, there is a lot to be said for being simple and easy. Easy to understand, easy to restore, easy to verify.\n However, there is a major problem with rclone backups: it needs to list the destination every time which can be very slow. (There are others too but this is the main one).\n So I created rirb: reverse incremental rclone…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrqeti/new_rclonebased_backup_tool_i_created_rirb/",
          "publishedOn": "2022-12-21T15:23:31.000Z",
          "wordCount": 17711,
          "title": "New rclone-based backup tool I created, rirb: reverse incremental rclone backups, which may interest some in this community",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrotd9/its_a_long_shot_but_does_anyone_have_a_copy_of/",
          "author": null,
          "description": "I've been using this for a long time, and I made a backup like any good data hoarder would. Today, however, my USB stick died. I went to load the backup up, and to my horror, it just wouldn't work. This tool (and its backup) are pretty ancient; my copy was from 2015, version 7.4.0.132. \n I'm looking for the USB POS Diagnostics Key. However, they seem to have locked it away since I last used it. \n Anyway, any help would be greatly appreciated.\n    submitted by    /u/libraholes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrotd9/its_a_long_shot_but_does_anyone_have_a_copy_of/",
          "publishedOn": "2022-12-21T14:46:32.000Z",
          "wordCount": 15454,
          "title": "It's a long shot but does anyone have a copy of Toshiba USB POS Diagnostics key?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zrobif/backblazes_hard_drive_stats_are_a_broad_resource/",
          "author": null,
          "description": "submitted by    /u/themadprogramer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zrobif/backblazes_hard_drive_stats_are_a_broad_resource/",
          "publishedOn": "2022-12-21T14:35:19.000Z",
          "wordCount": 22913,
          "title": "Backblaze's Hard Drive Stats are a broad resource for comparing drive stats from industry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zr3xtv/no_one_pirated_this_cnn_christmas_movie/",
          "author": null,
          "description": "submitted by    /u/AshleyUncia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zr3xtv/no_one_pirated_this_cnn_christmas_movie/",
          "publishedOn": "2022-12-20T23:57:30.000Z",
          "wordCount": 15962,
          "title": "No one pirated this CNN Christmas Movie Documentary when it dropped on Nov 27th, so I took matters into my own hands when it re-ran this past weekend.",
          "imageUrl": "https://preview.redd.it/eh5uk5hm557a1.jpg?auto=webp&s=feee18bf372a6f5030a0716b2c438a56567730f7"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zr2gv4/my_file_management_has_gone_absolutely_chaotic_on/",
          "author": null,
          "description": "So I have an unraid server that I used to manage very well with plenty of storage and redundancy but since my situation has changed and I’ve had to take my server offline my desktop PC file management has gone ridiculous. I don’t even know where to begin. Recently bought a bigger SSD because I was desperate and didn’t have time to sift through files so just cloned my drive and now I have some head room and a spare drive. I have program installers, random text file notes, music, films, software, games, files for modifying things, it’s just chaos since not been able to have my server. \n Any tips?\n    submitted by    /u/GiggleStool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zr2gv4/my_file_management_has_gone_absolutely_chaotic_on/",
          "publishedOn": "2022-12-20T22:57:19.000Z",
          "wordCount": 15983,
          "title": "My file management has gone absolutely chaotic on my main desktop PC since I haven’t had my server help and advice needed.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqzwgu/hey_guys_looking_for_suggestions/",
          "author": null,
          "description": "Hi im an aussie that lives in the bush with crappy wifi was originally looking into getting a NAS but i would beleive it would be too slow to load games off it which will be the main purpose so was thinking instead getting an 8 bay hardrive enclosure and installing all my games/media to that instead.going external due to building an itx rig. Any help/reccomendations are welcome thanks in advance\n    submitted by    /u/TIZ_245  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqzwgu/hey_guys_looking_for_suggestions/",
          "publishedOn": "2022-12-20T21:14:57.000Z",
          "wordCount": 15431,
          "title": "Hey guys looking for suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqzi9w/adding_more_bays/",
          "author": null,
          "description": "Context: I own a \"Antec 4U22EPS650 4U Rackmount Case\" with no mobo whatsoever in it I have found a pretty good deal on a Synology DS413 with 4x ironwolf. \n I am aware it is not advised but, Is it possible to gut the DS413, frankenstein it into my rackmount case and effectively \"add more bays\"\n    submitted by    /u/Razial36  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqzi9w/adding_more_bays/",
          "publishedOn": "2022-12-20T20:59:49.000Z",
          "wordCount": 16991,
          "title": "adding more bays?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqyz76/considering_picking_up_from_a_local_seller_what/",
          "author": null,
          "description": "submitted by    /u/RandomDelta06  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqyz76/considering_picking_up_from_a_local_seller_what/",
          "publishedOn": "2022-12-20T20:38:13.000Z",
          "wordCount": 17445,
          "title": "Considering picking up from a local seller, What should I look out for?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqyima/does_nvme_data_overwrite_prevent_recovery/",
          "author": null,
          "description": "When overwriting a NVMe completely with useless files, can the data be recovered? I want to securely erase them.\n  \nI’m planning to sell it and can afford the TBW.\n Don’t have the right mainboard for secure erase\n Don’t have parted magic\n I set the blocks to 0% with tunefs\n  \n   submitted by    /u/Germandude81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqyima/does_nvme_data_overwrite_prevent_recovery/",
          "publishedOn": "2022-12-20T20:19:37.000Z",
          "wordCount": 16204,
          "title": "Does NVMe data overwrite prevent recovery?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqx90b/how_to_convert_epub_to_gitbook/",
          "author": null,
          "description": "hi, I have a lot of e-pub books that i would like to publish on gitbook (or similar) but I can't seem to find a tool (online or otherwise) than can do it. Any idea? \n Thanks!\n    submitted by    /u/pompeii-eo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqx90b/how_to_convert_epub_to_gitbook/",
          "publishedOn": "2022-12-20T19:28:50.000Z",
          "wordCount": 15479,
          "title": "How to convert E-Pub to GitBook?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqwday/great_deal_on_gen4_2tb_nmve_in_canada_how_are/",
          "author": null,
          "description": "Hello,\n I'm in the market for 4x 2tb NVMe Gen4. Going to put them in a PCIe NVMe bay eventually. Do these specs check out? Only think I'm worried about is how drives tend to slow down over time.Not sure how important VNAND is compared to TLD, QLC, cache etc., in regards to speed and longevity.This price and speed seem too good to be true. All these drives are just for storage, OS will be on a Samsung Pro.\n Also, these drives will solely be used for music production and reading, not writing; loading many heavy files/samples simultaneously, if that helps.\n https://www.amazon.ca/dp/B0B2CYTQ1H/ref=as_sl_pc_tf_til?tag=&linkCode=w00&linkId=&creativeASIN=B0B2CYTQ1H\n Thanks!\n    submitted by    /u/MarkGeraz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqwday/great_deal_on_gen4_2tb_nmve_in_canada_how_are/",
          "publishedOn": "2022-12-20T18:54:10.000Z",
          "wordCount": 18745,
          "title": "Great deal on Gen4 2tb NMVe in Canada. How are these specs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqva76/trying_to_open_but_not_break_external_usb_seagate/",
          "author": null,
          "description": "I have an external USB powered drive thats 2TB and I'd like to open the housing to put in a 4TB SSD but I cant figure out how to open it but not break it. Any ideas? I feel like the people in this sub open up drive housings a LOT more than I do so probably have good experience.\n ​\n its this style: Amazon.com: Seagate Ghost-Spider Special Edition FireCuda External Hard Drive 2TB - USB 3.2 Gen 1, customizable LED RGB lighting Pink, with Rescue Services (STKL2000418) : Electronics\n    submitted by    /u/IntegraType-S  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqva76/trying_to_open_but_not_break_external_usb_seagate/",
          "publishedOn": "2022-12-20T18:10:48.000Z",
          "wordCount": 15698,
          "title": "Trying to open but not break external USB Seagate Firecuda housing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqttzv/old_computer_needs_new_storage_how_can_i_safely/",
          "author": null,
          "description": "I have a rather elderly computer from around 2007-08 and it has one 250gb HDD, the drive is almost completely full (pc has been in a basement for about 6 years so not much space was taken up until recently) and I don't know whether simply adding another drive would be effective. I don't use much storage, I figure a terabyte would be more than enough, but should I just add a drive or is there something else I can do? (Windows7 Home Premium, btw) The other specs are okay for what I need, but I want to upgrade the storage and processor. 8gb DDR2 800, GT 730, Athlon x64 Dual Core 4200+ in case this info is useful. Pls ask if you need more info, I'm not particularly experienced regarding storage.\n    submitted by    /u/throwawayaccnt14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqttzv/old_computer_needs_new_storage_how_can_i_safely/",
          "publishedOn": "2022-12-20T17:12:39.000Z",
          "wordCount": 17489,
          "title": "Old computer needs new storage, how can I safely add more?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqt96g/should_a_hard_drive_still_work_after_being/",
          "author": null,
          "description": "I am new to NAS stuff and have an ASUSTOR AS1102T 2 bay NAS. Been using it quite smoothly for the past month. Then I attempted an experiment. After making sure all data is backed up, I powered off the NAS, took out the hard drive, and plugged it into a windows computer. I wanted to see if it’s possible to see the files directly on a desktop (because I intend to use hard drives as Cold Storage as I don’t have much to spend on NAS with many bays). To no avail, windows didn’t recognise it. Also ran a quick health check and all sectors green. I plugged it back into the NAS (another SATA port) and booted up the NAS, but it showed disk errors. I powered off the NAS, and switched the hdd to the original port, and booted it up again, but was met with disk errors again. \n So my questions are: 1) are NAS hdd supposed to be allowed to be plugged out? 2) when they are plugged back in, does port matter? 3) will windows “corrupt/override” the file system that the NAS has written?\n I believe the answer to at least one of these is the reason for the results of my experiment. It would be disappointing if (1) turned out to be “no”, as that was my intended usage. What do you guys think? :)\n Perhaps I need to click on “repair” as mentioned here? https://www.reddit.com/r/synology/comments/ijbac9/disk_drive_order/g3chu61/?utm_source=share&utm_medium=ios_app&utm_name=iossmf&context=3\n    submitted by    /u/tch1001  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqt96g/should_a_hard_drive_still_work_after_being/",
          "publishedOn": "2022-12-20T16:49:44.000Z",
          "wordCount": 16973,
          "title": "Should a hard drive still work after being removed from a NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqsgzg/setting_up_storage/",
          "author": null,
          "description": "Hey!\n I’m fairly new to data hoarding and it’s not something I’ve been able to do much due to Wi-Fi bandwidth caps, but now I’m on a plan with much higher bandwidth with a pretty eh download speed (which is capped to max 50mbps)\n I have a 1 TB ssd, a 1 TB HDD in my laptop (no pc atm), and a 5 TB external HDD. I bought a 2012 Dell OptiPlex 790 earlier this year and have regretted buying it ever since. I can’t sell it since no one would pay for what it cost me. $50 for the machine itself and little over $100 to get it shipped to me, I don’t live in the western world and the OptiPlex came from the US.\n The OptiPlex has a single hard drive bay and seeing as it is from a decade ago, I doubt m.2 ssd is an option. Came with a 4 GB stick and a user here or over in the NAS subreddit recommended that I get either 8 or 16 GB which I’m planning on doing.\n But the main issue at hand is using hard drives. Now, the option that I’ve been considering for a while is using external hard drive dock. Would any of you recommend me going this route or should I count my losses and look for another option?\n    submitted by    /u/Sycrixx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqsgzg/setting_up_storage/",
          "publishedOn": "2022-12-20T16:16:57.000Z",
          "wordCount": 16136,
          "title": "Setting up storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqs8zi/does_anyone_know_a_mirror_possibly_p2p_of_the/",
          "author": null,
          "description": "In short, cygwin is a great niche project but it doesn't keep all the versions online and thus Win systems that go EOL get unsupported.\n That is a shame as one may still want to use old system for vintage projects, fortunately there is one project, the cygwin time machine, that tries to save all the notable releases.\n http://www.crouchingtigerhiddenfruitbat.org/Cygwin/timemachine.html\n The question is, that site may go down (because internet forgets, not immediately, but it does), are there p2p resources to keep mirrors of it alive?\n  \nEdit: a bit surprised by the downvotes. I though the sub was for trying to save things, also (especially?) niche things that are legal to share, rather than mostly \"download a lot of Linux ISOs that at the end are pirated films\". I guess that it mostly dedicated to mainstream data and I expected a bit more.\n    submitted by    /u/pier4r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqs8zi/does_anyone_know_a_mirror_possibly_p2p_of_the/",
          "publishedOn": "2022-12-20T16:07:43.000Z",
          "wordCount": 15604,
          "title": "Does anyone know a mirror (possibly p2p) of the cygwin time machine?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqrwi9/wd_drives_for_nas_20tb/",
          "author": null,
          "description": "Hello,\n Im currently using many 18tb drives in my synology ds1520+, Ds920 and Ds1522+ (still new experience with this one) And happy with the noise levels. Was about to upgrade one nas to 20tb using a wd sale assuming similar experience …however heard some chatter about some noise issues. Either the design of the drive itself isnt the same experience, or i heard theres some new feature around lubrication causing some noise?\n Anyway, anyone with low noise requirements upgrade any of their nas units to 20tb and been happy? If not why?\n    submitted by    /u/Jman5150mib  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqrwi9/wd_drives_for_nas_20tb/",
          "publishedOn": "2022-12-20T15:53:31.000Z",
          "wordCount": 15452,
          "title": "Wd drives for NAS, 20tb?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqrup0/need_some_help_with_a_drive_strategy/",
          "author": null,
          "description": "Ok... so I need some help here.\n I'm planning on upgrading my UNRAID setup.\n Currently I have 24TB total, 10TB free.\n I've got two newer 8TB drives as parity (one shucked, one WD Gold). The rest of the drives are junky sas/sata used drives from ebay 3TB each.\n These drives are all in a Supermicro CSE-846 case, Supermicro X9DR3-F mobo with Dual Xeon E5-2620's 2.00GHz\n I am moving to a single e5-2680v3, probably going to spring for a Fractal Define R5 (unless you have other recommendations?)\n ANYWAYS,\n So I'd like to basically rebuild the whole NAS while I'm at this. What does that mean? Well...\n I'm unhappy with the 3TB drives. They are too noisy and suck up too much power for what they are. I'd like to replace them with a couple 8 TB drives, or maybe even redo my parity setup?\n I really like having dual parity. I know it would be cheaper to just go to single parity but I feel like dual is worth it?\n I guess what I'm wondering is if I should upgrade my parity drives to 12-14TB, and then just buy at least one more 8 TB drive\n OR\n Just get 3 8TB drives and go from there.\n I REALLY won't need all the storage I currently have right away as I plan on reorganizing and starting my linux ISO collection from scratch, so I can slowly acquire drives as needed (outside of parity of course)\n ​\n Recommendations on strategy, specific drives, and cases would be super awesome!\n ​\n Thanks!\n    submitted by    /u/jamalstevens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqrup0/need_some_help_with_a_drive_strategy/",
          "publishedOn": "2022-12-20T15:51:19.000Z",
          "wordCount": 17056,
          "title": "Need some help with a drive strategy.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqrpqi/download_wiki_article_plus_cited_pages/",
          "author": null,
          "description": "So, I know downloading Wikipedia for offline viewing is possible, but is it also possible to download the cited articles/pages/etc? I wasn't sure if there's already a tool out there for this. Ideally macOS/Linux based.\n    submitted by    /u/machone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqrpqi/download_wiki_article_plus_cited_pages/",
          "publishedOn": "2022-12-20T15:45:37.000Z",
          "wordCount": 15790,
          "title": "Download Wiki article PLUS cited pages?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqr6r7/how_are_you_protecting_against_fire_and_water_can/",
          "author": null,
          "description": "Hi All, \n I'll begin by stating that all of my data is backed up off site and in the cloud. \n Now that that is out of the way...I'm wanting to protect what I keep in my office. I have 300+/- tb of data spread across single drives, raid enclosures, etc. I'd like to protect these from fire and water, but am struggling to find the right thing(s). \n As of now I'm looking at a fireproof safe for long guns, and adding shelves inside to stack things. But those are usually waterproof so I'm also looking at placing everything inside of waterproof boxes and then into the safe. \n Are there options I'm overlooking? Thanks for any help, insight, or experience.\n    submitted by    /u/LosinCash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqr6r7/how_are_you_protecting_against_fire_and_water_can/",
          "publishedOn": "2022-12-20T15:23:24.000Z",
          "wordCount": 17440,
          "title": "How are you protecting against fire and water? Can you recommend anything?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqqk80/folder_archiving_best_practices/",
          "author": null,
          "description": "Hi all thanks for reading.\n This is kindof a mixed post asking for some specific answers to get me on my way for this particular project, but also looking for resources to study up for the future. No pressure to run the gauntlet on all these questions, I am just grateful for any help you may offer.\n My lingering questions include:\n  \nIs it worth it to break a large archive into parts, or is it best to leave it as one archive? If its better to break it into parts, what is the best practice volume size all things considered? (I will have this archive backed up on mac, windows and linux machines, online, and will be distributed to a handful of people).\n \nIs there a in depth user level best practices resource on file compression? Something that outlines use cases i.e. best method for speed com…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqqk80/folder_archiving_best_practices/",
          "publishedOn": "2022-12-20T14:56:47.000Z",
          "wordCount": 17590,
          "title": "Folder Archiving Best Practices",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqnbko/why_did_you_start_hoarding_data_in_the_first_place/",
          "author": null,
          "description": "For me it was reducing my pile of 1000 blu rays to a 2.5inch HDD. Digital Storage is way cleaner and easier to handle than physical storage.\n    submitted by    /u/richiethestick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqnbko/why_did_you_start_hoarding_data_in_the_first_place/",
          "publishedOn": "2022-12-20T12:35:41.000Z",
          "wordCount": 19698,
          "title": "Why did you start hoarding data in the first place?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqmtqx/the_smart_dataset_is_a_great_resource_for/",
          "author": null,
          "description": "submitted by    /u/themadprogramer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqmtqx/the_smart_dataset_is_a_great_resource_for/",
          "publishedOn": "2022-12-20T12:12:52.000Z",
          "wordCount": 16134,
          "title": "The SMART dataset is a great resource for comparing device reliability",
          "imageUrl": "https://external-preview.redd.it/yVP3vwhETXXwiTW3Q1OCf1JgmWCic9hdHBizeQazgeE.jpg?auto=webp&s=3c6a322f1f79e7fff3d72ed8779ca3ecfcac0b43"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqm0no/probably_to_keep_track_of_my_archives/",
          "author": null,
          "description": "Hi, I was wondering if there was a program that helped people keep track of where are their backups in multiple places, whether they be high quality original data, or junk data that may be important... someday?\n I'd use Google Sheets and one of the programs that does a full directory search with hashes, but there's an issue.\n I simply don't have the self-discipline to use the peicemeal approach for long before giving up and just throwing things on my drives.\n So I know I need a program that at the very least holds my hand as I archive data, I was wondering if such a useful software might exist?\n    submitted by    /u/ElephantAmore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqm0no/probably_to_keep_track_of_my_archives/",
          "publishedOn": "2022-12-20T11:27:59.000Z",
          "wordCount": 16894,
          "title": "Probably to keep track of my archives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqaax6/how_to_backup_across_multiple_external_usb_devices/",
          "author": null,
          "description": "I have a 32T (total) UnRaid server. Never thought I'd fill up my 12TB USB external device as a backup. Now that its filled up, I would like to purchase another 12+TB external USB, but how do I not backup the already backed up files? \n Ideally, I would write all the backed up files to a text file, then tell 'rsync' to exclude all the files and directories in that file. Certainly I'm not the first one, so curious how others have done this? TIA\n    submitted by    /u/leonj1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqaax6/how_to_backup_across_multiple_external_usb_devices/",
          "publishedOn": "2022-12-20T01:33:07.000Z",
          "wordCount": 16742,
          "title": "How to backup across multiple external USB devices?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqa5al/does_anyone_have_a_iso_of_the_halo_2_i_love_bees/",
          "author": null,
          "description": "I have been looking for it for the past week now and i cannot find it.\n    submitted by    /u/StevenIsCool2004  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqa5al/does_anyone_have_a_iso_of_the_halo_2_i_love_bees/",
          "publishedOn": "2022-12-20T01:27:02.000Z",
          "wordCount": 16626,
          "title": "Does anyone have a ISO of the Halo 2 I love bees disc?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zqa55x/shucked_enclosures/",
          "author": null,
          "description": "Anyone have any shucked enclosures they would like to get rid of? OWC used to sell them, but I can't find them anymore. Looking for 3.5\" USB enclosures.\n    submitted by    /u/shumandoodah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zqa55x/shucked_enclosures/",
          "publishedOn": "2022-12-20T01:26:53.000Z",
          "wordCount": 16667,
          "title": "Shucked Enclosures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq7v1u/is_it_possible_to_compress_videos_for_storage/",
          "author": null,
          "description": "I have about 25 TB of data which I want to store for potential use in the future. The way I see it is I have 2 options, with option 2 being uncertain around its possibility...\n ​\n Option 1: I painstakingly go through all my footage and delete anything I know I will never use.\n Option 2: Put all the footage into a folder and compress it down so that I can store it. With this option, I want to be able to decompress it in the future without losing any video quality whatsoever. \n ​\n Is option 2 possible?\n ​\n Thanks in advance!\n    submitted by    /u/iscottjones  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq7v1u/is_it_possible_to_compress_videos_for_storage/",
          "publishedOn": "2022-12-19T23:54:22.000Z",
          "wordCount": 16570,
          "title": "Is It Possible To Compress Videos For Storage Without Losing Quality When Decompressing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq6g22/external_hard_drive_goes_to_sleep_if_i_do_not/",
          "author": null,
          "description": ".\n    submitted by    /u/nbcs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq6g22/external_hard_drive_goes_to_sleep_if_i_do_not/",
          "publishedOn": "2022-12-19T22:59:05.000Z",
          "wordCount": 17191,
          "title": "External hard drive goes to sleep if I do not access any files within 20s. Is it normal? And if it is normal, then is it healthy for the drive if I have a program that automatically writes an empty file every 10s to prevent it from going to sleep?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq5u2p/im_not_smart_enough_to_know_whatwhere_to_start/",
          "author": null,
          "description": "I know, I'm sorry. I tried looking but frankly I just don't even know what I'm looking for. Sorry. \n I want to have a folder on my computer that my father in a different state can also access and add to. We're trying to share about 2Tbs of STLs and DnD stuff into a single working folder that we can both access. Is this possible? \n I initially tried creating a google drive and sharing it with my dad, but that didn't work out like we had hoped. We'd rather not spend $10 each to share files with each other. \n Again, sorry. I tried looking myself, I searched the internet, but I don't know what to even search to find a solution and I need someone smarter to help point me in the right direction.\n    submitted by    /u/running_in_spite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq5u2p/im_not_smart_enough_to_know_whatwhere_to_start/",
          "publishedOn": "2022-12-19T22:34:32.000Z",
          "wordCount": 18072,
          "title": "I'm not smart enough to know what/where to start looking for answers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq4xjk/what_are_some_good_alternatives_to_cyberduck_on/",
          "author": null,
          "description": "Before everyone starts saying rclone, please read on.\n Currently I use cyberduck along with carotdav to upload files to google drive. I am not looking to mount it as a drive or to setup sync. I want to manually upload different files from different directories at different times manually. I need it to be able to drag and drop to upload multiple files (which I wasn't able to do with rclone browser and I don't want to upload it as a folder, correct me if I'm wrong)\n My current issue with cyberduck is for some reason, it uses much more CPU compared to other programs. The issue with carotDAV is it only upload files one by one even if you dump in a bunch of files, which I cannot max out my connection.\n To what I understand, rclone doesn't fit my needs. If anyone knows how to setup rclone to work like I how I need it, I would happily use rclone. Filezilla Pro doesn't have a trial so I can't test how well it would work for me.\n ​\n Are there any alternative programs on windows for this use case or how do I properly setup rclone for this use case? I'm ready to learn.\n ​\n Thanks.\n    submitted by    /u/chorong761  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq4xjk/what_are_some_good_alternatives_to_cyberduck_on/",
          "publishedOn": "2022-12-19T21:59:55.000Z",
          "wordCount": 17239,
          "title": "What are some good alternatives to Cyberduck (on windows) for uploading to GDrive? (please read before commenting rclone)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq4bv3/efficient_method_to_rip_5000_audio_cds_onsite/",
          "author": null,
          "description": "My dad passed recently, and he left behind a treasured collection of 5,000+ CD's. I'd like to archive it all as I have many fond memories of listening to them; MP3's are sufficient.\n I was originally thinking of setting up something similar to this, with many drives. Problem is my main machine which has the space and processing power is at my own home; moving either the machine or the CD's between my house and my dad's isn't practical, and the work involved in setting it up starts to sound blocking.\n I also considered just cataloguing them and feeding that into a torrent/Usenet/purchasing script, but many of these are old and do not exist online (and are not sorted), so that doesn't sound any faster.\n How do you suggest I go about this? I'm open to jerry-rigging something together, buying a commercial solution, etc, just not sure what's most efficient. My biggest constraint is I don't get much time at his house, so I want a solution with a high CD throughput. Should I just be ripping images, and then transporting those to my own home for transcoding/tagging/etc?\n Thanks all!\n EDIT: As many of you have mentioned, tagging and metadata is a big problem, especially since many of these CD's have no online presence and can't be auto-tagged. Since the CD's aren't sorted (and I don't want to upset the physical state of things too much), retrieving a disc after ripping isn't feasible. So whatever strategy is used needs to record disc data (e.g. photographs of the case) when it's ripped.\n    submitted by    /u/Gatherix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq4bv3/efficient_method_to_rip_5000_audio_cds_onsite/",
          "publishedOn": "2022-12-19T21:36:39.000Z",
          "wordCount": 20481,
          "title": "Efficient method to rip 5,000 audio CD's on-site?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq3k0o/looking_to_move_from_hetzner/",
          "author": null,
          "description": "I currently rent a 40tb box from Hetzner for around 50 euro a month, however the box is located hundreds of miles from my location so over a SMB connection tunnelled over a VPN product i'm only hitting about 4-6mb/s when my home network connection is 120mb/s. The server has about 20TB of data on it at the moment\n ​\n I do have a server locally with Proxmox installed, however the high capacity drives are out of my price range at the moment\n ​\n Is there anything I can do to improve throughput? I thought about getting a cloud storage solution and mounting it via SMB or some other protocol to a Linux machine within my Proxmox however I'm unsure what solutions are available to me apart from buying high capacity drives and then cloning the Hetzner box\n ​\n I would ideally like to stream old game ROMS to emulators and such via the solution\n    submitted by    /u/sadboy2k03  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq3k0o/looking_to_move_from_hetzner/",
          "publishedOn": "2022-12-19T21:06:21.000Z",
          "wordCount": 16887,
          "title": "Looking to move from Hetzner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq3cbe/tips_for_my_bad_drive/",
          "author": null,
          "description": "I finally received a dud drive. Never happened before to me. Sold and shipped by newegg, the 16TB Seagate EXos drive I received wouldn't even spin up. It was packed decently well but I guess not well enough. I have to wait until tomorrow to start the return process. \n Originally I thought it must be a bum external drive dock so tried popping it in my single drive synology to test and it wouldnt show up at all. Glad I didnt jump straight into degrading the pool it is supposed to go into.\n Are there any tips for making sure I get a replacement quickly and efficiently? I am planning on returning the drive to newegg under the replacement option rather than RMA through Seagate.\n    submitted by    /u/haloid2013  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq3cbe/tips_for_my_bad_drive/",
          "publishedOn": "2022-12-19T20:58:27.000Z",
          "wordCount": 16273,
          "title": "Tips for my bad drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq3aej/reddit_archive_simular_to_ihsoyct/",
          "author": null,
          "description": "I don’t particularly enjoy socialgrep and ihsoyct seems to be down. Anyone have an answer lol\n    submitted by    /u/Impressive_Bass_1537  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq3aej/reddit_archive_simular_to_ihsoyct/",
          "publishedOn": "2022-12-19T20:56:18.000Z",
          "wordCount": 16480,
          "title": "Reddit Archive Simular To Ihsoyct?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq2srv/downsides_to_a_renewed_drive_and_a_3rd_party/",
          "author": null,
          "description": "Are there any downsides to using a renewed drive like this and a 3rd party enclosure like this as long as precautions are taken such as running the drive to check for bad sectors and runtime.\n    submitted by    /u/klnadler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq2srv/downsides_to_a_renewed_drive_and_a_3rd_party/",
          "publishedOn": "2022-12-19T20:36:58.000Z",
          "wordCount": 16425,
          "title": "Downsides to a renewed drive and a 3rd party enclosure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq2kaw/external_usb3_case_vantec_inateck_ugreen_or_which/",
          "author": null,
          "description": "Hi everybody,\n have you got some experiences with the kind of items in the title?\n There are tons of models for each vendor and except vantec I dont know others. I've seen some vantec products - I have and old pata nexstar, it's still doing the job when needed), but some amazon clients' online reviews seem to say that old quality has gone (and they cost 3x, compared with other firm).\n I had two sabrent but after a couple year, one after another, stop to work.\n Plus: they should work good with linux and ssd disks, some chip may have trim problems (sob). It seems so complicate build an external 2.5 usb disks (I dont trust the ones sale by wd or seagate or toshiba... there are hdd smr disk; I also prefer to not buy a \"usb ssd\" like Sandisk Extreme, because they are a finished product and I cannot shuck them or change the disk, if needed).\n Some one of you has tested / evaluated these case? Should I evaluate a solution like the FANTEC QB-35US3R. Please note I would not buy a NAS, I have already have enough pc (family says...) and they are too expansive.\n Thanks a lot for reporting you experiences!\n ​\n ----\n edit: added the fantec paragraph.\n    submitted by    /u/wireless82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq2kaw/external_usb3_case_vantec_inateck_ugreen_or_which/",
          "publishedOn": "2022-12-19T20:27:40.000Z",
          "wordCount": 17971,
          "title": "external usb3 case: vantec, inateck, ugreen or... which one? No sabrent please, I've already had bad experiences with them.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq1vy9/these_be_dead_right_dont_use_them_any_more/",
          "author": null,
          "description": "submitted by    /u/skeptibat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq1vy9/these_be_dead_right_dont_use_them_any_more/",
          "publishedOn": "2022-12-19T20:01:10.000Z",
          "wordCount": 16678,
          "title": "These be dead, right? Don't use them any more?",
          "imageUrl": "https://preview.redd.it/f7mmndvtuw6a1.png?auto=webp&s=d161aa9dc58f3b8a269ebf5aacaf460184b3d81c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zq1oer/got_this_lto5_drive_off_ebay_inside_of_it_is/",
          "author": null,
          "description": "How would I go about cleaning this out properly? I figured all this dust cant be good for the tape or the drive\n    submitted by    /u/JustKeKe23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zq1oer/got_this_lto5_drive_off_ebay_inside_of_it_is/",
          "publishedOn": "2022-12-19T19:53:36.000Z",
          "wordCount": 15421,
          "title": "Got this LTO-5 Drive off eBay, inside of it is pretty dusty",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpykxu/are_nas_drives_not_overkill_for_desktop/",
          "author": null,
          "description": "i am quite out of the loop with computer technology, with reliable brands and etc. my computer is from 2011, and will only be ugraded in 2025 when windows 10 dies. but i do need hard drives as i am running out of space.\n i tried searching but could not find a simple and realistic comparrison showing that NAS disk are really better for desktop storage.\n it's mostly for flac and wave music, png, svg and jpg images and mkv, avi and mp4 movies going to migrate to (03) 4tb hard disks , so actually i need to buy 6 for backup reasons, \n i keep hearing i should buy the seagate ironwolf instead of barracuda, and begs the quesiton if its not overkill? with 6 drives i would spend u$ 120 more with ironwolf. from what i read NAS drives are made to run hot and not get affected from vibrations. isn't that because nas drives are all cramped together in a tiny box?\n so in a big server case both vibrations and temperature will not be a concern right?\n my computer runs rather cold, hard disks usually around 30~35 celsius, (a big old server case from the 2000's) \n thanks!\n ps: not raid, just manual backup using software that does incremental copy\n    submitted by    /u/vanderzee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpykxu/are_nas_drives_not_overkill_for_desktop/",
          "publishedOn": "2022-12-19T17:58:59.000Z",
          "wordCount": 16954,
          "title": "are nas drives not overkill for desktop?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpwmt5/gallerydl_twitter_is_there_a_way_to_skip_all/",
          "author": null,
          "description": "I've been using gallery-dl to download media and metadata for a list of people I follow. However, despite using an archive file, it still iterates through their entire tweet history. It does skip downloading old tweets, but I'd rather it just get everything new and then move onto the next URL once it encounters a tweet it already has. That would save me a TON of time (and rate limits).\n All the documentation and suggestions I've found thus far involve skipping downloads, which it's already doing.\n Also, since moving to a new computer and setting things up again, files it already downloaded are displaying as ./gallery-dl/twitter/[user]/? in the terminal output instead of showing the filenames. Not sure why that is happening.\n Config is below. Any suggestions?\n { \"extractor\": { \"twitter\": { \"cookies\": { \"auth_token\": \"[redacted]\" }, \"archive\": \"~/twitter/archive-twitter.sqlite3\", \"postprocessors\": [ { \"name\": \"metadata\", \"event\": \"post\", \"filename\": \"{tweet_id}.json\" } ], \"expand\": false, \"cards\": false, \"quoted\": false, \"retweets\": false, \"text-tweets\": false, \"unique\": true, \"videos\": true, \"timeline\": { \"strategy\": \"media\" } } } } \n I run with the following command: gallery-dl -c ./gallery-dl.no-text.conf -i urls.txt\n    submitted by    /u/turaiel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpwmt5/gallerydl_twitter_is_there_a_way_to_skip_all/",
          "publishedOn": "2022-12-19T16:47:08.000Z",
          "wordCount": 17121,
          "title": "[gallery-dl / Twitter] Is there a way to skip all remaining tweets for a user once everything new has been collected?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zptm0k/wd_mycloud_ex2_ultra_max_capacity/",
          "author": null,
          "description": "Surprisingly few sources on this - officially WD say it's 16 TB, which after some time magically became 20 TB on a 2-bay NAS.\n I don't get what's imposing the limitation though - it's the same controller, same power - what is there to stop me from putting 2x 16 TB drives in there? Or is it just a hard-limit set by WD for whatever reasons and the NAS simply will not boot with such drives?\n One theory is that the \"advertised\" capacity is what it is, going by the maximum available HDD size at that time. I can't confirm that though.\n I'd like to find out if maybe someone's already tried it before I buy the drives. Thoughts ?\n    submitted by    /u/Teacan83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zptm0k/wd_mycloud_ex2_ultra_max_capacity/",
          "publishedOn": "2022-12-19T14:51:09.000Z",
          "wordCount": 16641,
          "title": "WD MyCloud EX2 Ultra - max capacity ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zptksv/is_there_a_way_to_download_tv_tropes_for_offline/",
          "author": null,
          "description": "Hello everyone!\n Recently, I've learned about the Kiwix project that lets you download valuable sites completely in one \".zim\" file that can be browsed offline. I found several interesting zims in the Kiwix library, such as ArchWiki, StackExchange, AllTheTropes. I wonder, is there a way to have a local TV Tropes copy for offline browsing?\n    submitted by    /u/ChrysoliteAzalea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zptksv/is_there_a_way_to_download_tv_tropes_for_offline/",
          "publishedOn": "2022-12-19T14:49:55.000Z",
          "wordCount": 16861,
          "title": "Is there a way to download TV Tropes for offline browsing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zptkha/cloud_storage_wo_install/",
          "author": null,
          "description": "Howdy, fellow hoarders!\n I'm looking for a solution to use to store about 2 TB of data (family photos and videos backup) online that does not require me to install an application to do so.\n I've looked at some of the other posts here and have an idea of the major suppliers already, but not which ones offer an option to just map a drive (open to any protocols sorted by linux).\n Does anyone else have this use case and doing this with a provider, please?\n Ideally I'll go with the cheapest cost/year. I don't want nor need anything fancy, just storage space I can map to have another backip of family photos and videos. \n Thank you in advance.\n Ps- I asked iDrive and tgey responded that I must have their app installed.\n    submitted by    /u/trancekat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zptkha/cloud_storage_wo_install/",
          "publishedOn": "2022-12-19T14:49:33.000Z",
          "wordCount": 16828,
          "title": "Cloud Storage w/o Install",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpt6es/long_term_storage_ssds_vs_hdd/",
          "author": null,
          "description": "I make this post to get an update of current state of the storage technology and also seek to find answer for wheather i should make backups to HDDs vs SSD.\n Current Situation:- I have around 500 gb of Family photos from 2001 on a Seagate external HDD, it lasted for 7 years and data is well and good right now.\n I already have backups on 2 different machines and the external HDD. It's now time again to migrate my external HDD to new Hardware and I am conflicted on what should I choose moving further.\n Until now my photos have been jumping CDs to HDD and I am at a crossroads again weather to switch from HDD to SSD or HDD are still better for cold storage long term.\n I did fair bit of research and I am aware Optical Media would be my best bet, namely M Disk or BD disks. Unfortunately where I live I cannot source them reliably and affordably enough.\n I browsed reddit threads from past few years. Like this from 2 years ago which says SSDs are better.\n I have consistently found a narrative that newer SSDs are better alternative than HDDs.\n My primary concern is not number of read writes in SSDs. Often they are in 100s of TBW which I presume I won't hit because of the nature of my storage needs.\n I fear data corruption and chip failure rather than running out of read writes.\n The disk I chose weather SSD or an HDD will probably be left on shelf with about twice a year plugging into PC to add new photos.\n What do you guys think would be a good choice ?\n Should I keep moving forward with a new HDD or are SSD a smarter choice?\n Whatever I choose I would probably rely on for at least next 4-5 years, with backups of course.\n    submitted by    /u/alsu2launda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpt6es/long_term_storage_ssds_vs_hdd/",
          "publishedOn": "2022-12-19T14:33:25.000Z",
          "wordCount": 20936,
          "title": "Long term storage: SSDs vs HDD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpg3d8/aws_storage_without_egress_chargesan_intended/",
          "author": null,
          "description": "All AWS storage products charge outrageous egress fees, to the extend that backing up to AWS doesn't seem feasible for me. It's like Hotel California: upload is free, storage cost is okay, but you want your data back? Payback!\n For example: s3 glacier us-east-1: $0.0036 per GB + $0.09 per GB egress (for first 10tb).\n https://aws.amazon.com/s3/pricing/\n So if I backup 10 tb to aws and download it back at end of 1 year, it'll cost (0.0036 * 1024 * 10 * 12)+(0.09 * 1024 * 10)=442+921, i.e. 67% of my expense goes to egress. \n I'm like...no f way. Until I saw something else they offered: workdoc! Apparently there's no charge on egress. I reread it trice but yeah. $5 per user with 1tb included. You can allocate more storage per user but that'll cost more than creating a second user, so just create 10 users. That works out to 5 * 10 * 12=$600, less than half of glacier, and you don't have to wait 12 hours. Oh and there's a web gui.\n https://aws.amazon.com/workdocs/pricing/\n Are they doing this to compete with gdrive? I cannot imagine they omitted egress charges by mistake.\n    submitted by    /u/lmux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpg3d8/aws_storage_without_egress_chargesan_intended/",
          "publishedOn": "2022-12-19T03:00:09.000Z",
          "wordCount": 16731,
          "title": "AWS storage without egress charges...an intended loophole?",
          "imageUrl": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?auto=webp&s=8e3eb77ba905bb641af80fcf3efe1de0190ac8c2"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpdnok/looking_for_storage_softwareplatform/",
          "author": null,
          "description": "Just wasted a day messing about with UNRAID to realize it's limited to 30 drives. :-/\n I have a sizable pile of 5TB, 4TB, 3TB and 2TB drives. I live somewhere where power is cheap and cooling is fresh air for 9 out of 12 months. I have JBODs and \"IT\" flashed controllers to run more than I have. All told, it's around .5 PB... someday, I'd like to break the PB barrier, but today is not that day.\n Can someone recommend a single software platform to support various disk sizes, reasonable (N+2) resillency and easy growth/failure replacement?\n UNRAID, too few disks. TrueNAS, would need a seperate pool for each disk size, replacement blows. I know next to nothing about OpenMediaVault but am going to fire that up here soon to poke about. I see people complaining about NFS speeds, but in general, I don't need this to be super fast.\n I run a plex server (I actually won't run that as a plugin, even if the platform supports it) that servers up and transcodes 4K HDR content, a few infrastructure VMs and some game servers, but outside of my plex server being a consumer of large disk, I don't have significant performance needs. My VMs I'll either run local or if I feel the need to go back to multiple VM hosts, I'll come up with something seperate from my bulk storage.\n Thanks for perusing my wall of text. Curious what other folks are using for large drive count systems. \n I'll head off the \"12TB refurbs are cheap\" response with \"there's nothing cheaper than what you already have.\"\n    submitted by    /u/Thranx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpdnok/looking_for_storage_softwareplatform/",
          "publishedOn": "2022-12-19T01:02:33.000Z",
          "wordCount": 16039,
          "title": "Looking for Storage Software/Platform Recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpd7sa/pair_of_shucked_20tb_wd200edgz_wd_elements_drives/",
          "author": null,
          "description": "Just moving my Unraid server across to new hardware based around an ASRock Z790 Pro RS MoBo (have flashed the latest stable BIOS). \n I originally set up Unraid last month on an old/ repurposed Xeon based Thinkserver TS140.\n I moved the drives across (6TB Seagate, 8TB Seagate, 10TB WD, 18TB WD)\n Plus I'd been running the 2 x 20TB WDs unshucked as the parity drives via USB, so I shucked these and put them in the new case as I now have the PSU and drive bays to handle them.\n When I first turned the new PC on, only the Seagates were detected, both in BIOS & Unraid.\n So I tried taping pin 3 on the WD drives. The 10TB & 18TB are now being detected in BIOS & Unraid, but the 20TBs still aren't being detected.\n The Thinkserver was running in Legacy BIOS mode. The ASRock doesn't have a legacy option (that I can find), so is running as UEFI. Would that affect this?\n Any suggestions of something else I can try to get the 20TBs working?\n Are others using these drives with a recent UEFI only motherboard?\n    submitted by    /u/ceestars  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpd7sa/pair_of_shucked_20tb_wd200edgz_wd_elements_drives/",
          "publishedOn": "2022-12-19T00:41:22.000Z",
          "wordCount": 15704,
          "title": "Pair of shucked 20TB WD200EDGZ WD Elements drives not detected with new motherboard, even with pin 3 masked",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpbwmp/should_i_keep_using_this_external_hdd/",
          "author": null,
          "description": "The sequence of events:\n  \nI have this hdd (TOSHIBA HDTB420EK3AA) and i want to use it to backup some internal drives on a desktop. I write a bash script to do this, i mess up, i corrupt the data, and i have to format it. \n Trying to format this thing makes my pc freeze so badly i have to hard reset. I try the same with other machines, and different operating systmes, each one freezing aswell. The winner is an old laptop on lubuntu that manages to successfully format the drive in just over an hour. \n I go back to the first desktop and modify the script, i run it and it kinda works. By looking at rsync output i notice that the average speed is 500 kb/s, reaching 40kb/s at some points. At some point it starts copying an .IPCH file that makes it reach 0 byte/s and then nothing. \n I decide to exclude this file and other folders containing very large amount of small files, since it looks that the speed slows down especially in these cases. For what i know HDDs are ass in this type of operations but this is just ridiculous. \n So i stop the rsync, and everything freezes again. I can't even open the file explorer. I boot windows and use diskpart this time, then i install DiskInfo.\n \n https://preview.redd.it/20pxjo5urq6a1.png?width=670&format=png&auto=webp&s=5f70d06a653ae8e4fda4bbd6e43376a6e578c157\n To me it looks very ok, but in the 20 minutes it took me to write this, diskpart managed to go from 0% to 2% in the process of formatting the disk. \n The disk is almost factory new, but i can't send it back anymore. Any ideas?\n    submitted by    /u/Cute_Rub_9074  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpbwmp/should_i_keep_using_this_external_hdd/",
          "publishedOn": "2022-12-18T23:40:57.000Z",
          "wordCount": 17424,
          "title": "Should i keep using this external hdd?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpapw6/coldonly_storage_solution_with_database_indexing/",
          "author": null,
          "description": "Aloha! Among other things I'm a YouTube archivist on Linux system, with lots of videos to store, lots of HDDs of varying sizes, capacity (80-500GB) and age (several disks with BAD sectors that I wanna use as 3rd data duplicates). Then I have a single gaming PC with 2 HDD hotswap ports free. I'm looking for a hoarding setup solution, some guidance towards tools maybe? How could I improve my operation in relation to my low knowledge levels?\n How I have it running currently, is I have a 1TB inside the PC that acts as \"landing\" for incoming data, which I manually process (rename, move around, compare files, remux), then I connect HDDs that I decide should pick them up. I keep track of all data in LibreOffice Spreadsheet: on HDD arrival I sometimes measure its SMART data and update it in the sp…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpapw6/coldonly_storage_solution_with_database_indexing/",
          "publishedOn": "2022-12-18T22:47:57.000Z",
          "wordCount": 16135,
          "title": "Cold-only storage solution with database indexing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpancs/using_vpn_to_bypass_file_hoster_limits/",
          "author": null,
          "description": "Hello internet,\n I commonly use sites like keep2share to download files and have been using mullvad to bypass data limitations. Some videos are broken into multiple parts and I often pull my phone out to download simultaneously.\n I was wondering if there was a more efficient way to do this from one device and if I could do something like linking different browser windows to different IP addresses. I am constantly downloading files and am perfectly fine with the time investment it may take to set something like this up.\n I thought of Jdownloader but I think that uses proxies versus a VPN correct? \n Sorry for the newbie questions\n    submitted by    /u/ForeignEfficiency401  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpancs/using_vpn_to_bypass_file_hoster_limits/",
          "publishedOn": "2022-12-18T22:44:45.000Z",
          "wordCount": 15736,
          "title": "Using VPN to bypass file hoster limits",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zpafii/this_christmas_i_join_you_15tb_strong/",
          "author": null,
          "description": "Will be building my first server rack using spare parts and new parts with about 10TB new storage in addition to my pc’s original 5TB. Will be using a spare BM450 motherboard, any recommendations for the CPU?\n    submitted by    /u/Op2-0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zpafii/this_christmas_i_join_you_15tb_strong/",
          "publishedOn": "2022-12-18T22:35:06.000Z",
          "wordCount": 16538,
          "title": "This Christmas I join you 15TB strong!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp8uag/i_am_trying_to_view_my_older_youtube_history_from/",
          "author": null,
          "description": "submitted by    /u/Kristiangarzon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp8uag/i_am_trying_to_view_my_older_youtube_history_from/",
          "publishedOn": "2022-12-18T21:24:58.000Z",
          "wordCount": 15598,
          "title": "I am trying to view my older youtube history from 2017, 2018 etc, But it only goes back to August of 2020, Not sure if I paused/deleted my history at all, Is there any solution to fix this and retrieve my old history??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp7foz/fastest_way_to_go_about_calculating_hamming/",
          "author": null,
          "description": "I feel like I'll know what the unfortunate answer is, but the million dollar question is has anyone found a fast way to calculate the hamming distance between a very very very large set of hashes?\n I have a dataset (that will continue to grow) that I'm planning on granting limited access to the public via way of allowing the user upload an item, then the server checks against the database of hashes, and shows information from similar hashes. The issue is that the database of hashes will be over 500 hundred million.\n From my understanding of finding similar/identical content, hamming distance is the fastest approach in calculating the difference between items? The issue I am seeing is that this must be calculated for each query? So the server is checking the 500 hundred million images each and every time someone wants to check?\n Is there any way to speed this process that I'm not seeing in my research? How do things like deduplication software, or reverse/similiar image searches work so fast? What's their secret? Just more compute and they're harnessing a shit ton of compute for each query? TinEye claims to be able to \"search a 57.6 billion web image index in real-time.\" but how?? This must be the KFC's secret herbs and spices or the Coke recipe and I'm just shit out of luck?\n    submitted by    /u/AdamLynch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp7foz/fastest_way_to_go_about_calculating_hamming/",
          "publishedOn": "2022-12-18T20:23:56.000Z",
          "wordCount": 17743,
          "title": "fastest way to go about calculating hamming distance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp6mi6/8tb_disks_unable_to_write_but_both_can_read/",
          "author": null,
          "description": "Hi everyone,\n Background: I have 2 external HDDs (WD My Book) bought from BestBuy. They have both been formatted as MacOS Extended or HFS+. I own both a Windows laptop and a Macbook Pro; I use my Macbook Pro more, which is why I chose an Apple filesystem. I have historically been able to write to both of these disks using both laptops (I use Paragon HFS+ to write to the disk using my Windows laptop; I've done this for 2 years now with various other hard drives). Both hard drives have only been in use for a few months; one is constantly used for file scraping, the other is purely for backup use... the file scraping one only started having problems 2 days ago. The backup hard drive started having problems 2 months ago. (I thought it was only a one-off thing, but seems to be a recurring issue…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp6mi6/8tb_disks_unable_to_write_but_both_can_read/",
          "publishedOn": "2022-12-18T19:48:57.000Z",
          "wordCount": 18022,
          "title": "8TB Disks Unable to Write But Both Can Read, CrystalDiskInfo says Health Status is \"Good\" (no %)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp6fxy/using_aws_s3_glacier_instead_of_building_a_nas/",
          "author": null,
          "description": "Hey all, I'm pretty new to actually organizing my storage. I have loads of stuff that I've collected through the years in several HDDs and SSDs, maybe a dozen or more in total. I was considering getting a NAS so that I can lower the risk of losing anything and also make everything accessible to me easily. \n What I'm most concerned about is availability/reliability. AWS guarantees 99,999999999%. That's not something you can get at home. There are so many ways to just mess up. The cost to scale is also very linear for AWS, compared to a home system.\n I have unlimited Internet already.\n    submitted by    /u/piponwa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp6fxy/using_aws_s3_glacier_instead_of_building_a_nas/",
          "publishedOn": "2022-12-18T19:40:52.000Z",
          "wordCount": 17817,
          "title": "Using AWS S3 Glacier instead of building a NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp6fr4/mediafire_bulk_downloader_site/",
          "author": null,
          "description": "i put a folder on media fire 613 files a while ago and removed it from my computer for some more space i cant redownload it because of the bulk download feture i will go insane please help\n    submitted by    /u/TheEurekaEffect_64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp6fr4/mediafire_bulk_downloader_site/",
          "publishedOn": "2022-12-18T19:40:38.000Z",
          "wordCount": 15449,
          "title": "mediafire bulk downloader site?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp66w9/ratehelp_my_backup_strategy/",
          "author": null,
          "description": "I'm working on trying to solidify my backup strategy. I do think it's fairly solid, but there are a couple things I know that I can do better. \n Current strategy: Centralized storage via Synology NAS (1621+ w/ 32GB ECC RAM) with btrfs. NAS snapshots hourly and maintains snapshot through typical pruning measures. NAS backs up to connected Seagate Backup 8TB drive and Backblaze B2 via Hyper Backup. NUC11 running Windows with read-only user connects to shares and backs up to connected external hard drive via Arq 7. Have rotational cold-storage via Arq as well. \n A couple things I'd like to fix: \n  \nNUC11 running Windows (will likely convert to Hypervisor of some sort, even if just HyperV), was part of a project.\n Potentially move the external drive hanging off of the NUC to an internal 2.5 HDD.\n Add a backup tool that is open source, even if it's just a cold backup. \n Potentially remove NUC11 in general, as I'm running less on it and have a beefy desktop, and far fewer full-time running services than I did. Would move the service or two to run off of the NAS. Though, this would mean trying to incorporate my desktop into initiating a backup process of some sort, potentially manually, which makes it less desirable.\n  \nThe amount of data that I would consider critical is very low, somewhere in between 200-300GB\n Any suggestions on how I could make this more solid?\n    submitted by    /u/StrongCommission  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp66w9/ratehelp_my_backup_strategy/",
          "publishedOn": "2022-12-18T19:29:43.000Z",
          "wordCount": 20651,
          "title": "Rate/Help My Backup Strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp5leo/mount_multiple_mega_accounts_as_drivesremovable/",
          "author": null,
          "description": "Title\n    submitted by    /u/Robotic8040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp5leo/mount_multiple_mega_accounts_as_drivesremovable/",
          "publishedOn": "2022-12-18T19:03:04.000Z",
          "wordCount": 17849,
          "title": "Mount multiple MEGA accounts as drives/removable storage on Windows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp569i/new_tech_job_found_a_box_full_of_hdd_boss_said_i/",
          "author": null,
          "description": "submitted by    /u/wicodly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp569i/new_tech_job_found_a_box_full_of_hdd_boss_said_i/",
          "publishedOn": "2022-12-18T18:44:00.000Z",
          "wordCount": 18062,
          "title": "New Tech Job! Found a box full of HDD. Boss said I can keep them. I’m happy",
          "imageUrl": "https://preview.redd.it/8uf4g6iqtq6a1.jpg?auto=webp&s=742f439986c868c421687ae06390ddd309ff173b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp4h3n/high_tbw_ssds_for_low_power_nas/",
          "author": null,
          "description": "I have a NAS for backup, media server, VMs, etc. It's only serving myself, so I don't like the idea of spinning 6+ spinning up drives up/down when I occasionally need to access a few media files daily when when I reboot for maintenance, testing, or just don't use it for maybe weeks at a time max.\n As I understand, SSDs rarely fail aside from reaching write limit, which is something measurable (and even then, I've heard of people having Samsung SSDs that are nearly twice the TBW that's in the spec). I don't plan on running RAID, since downtime and access to massive amount of data isn't important to me--instead, I prefer frequent incremental backups, occasional full backups, as well as longer life of drives and lower power consumption.\n I will only ever deal with 8-16TB worth of data I want online at the moment, rest is cold storage (combined total of ~100TB hard limit for the foreseeable, I only have 60TB data total). I prefer high TBW because performance is not important for me and backing up constant flow of new large media files is.\n Assuming high TBW SSDs are suitable for such a use case, what high TBW SSDs do you recommend? I was initially looking at Samsung SSDs because they are the gold standard in general, but I've come across Intel DC S3610 as a recommendation that is spec'd ~5x TBW more (10.7PB). I'm not normally one to look for used storage but people seem to have success with used ones from Ebay that are probably pulled from servers after their intended service and they usually a reasonable amount of remaining life at a great price. Unless these somehow fail in other ways, I don't see how they aren't very popular. This model is 7 years old though, so I'm thinking there might be better options (not necessarily price/TB).\n Any thoughts and suggestions are much appreciated.\n    submitted by    /u/rofic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp4h3n/high_tbw_ssds_for_low_power_nas/",
          "publishedOn": "2022-12-18T18:12:10.000Z",
          "wordCount": 17127,
          "title": "High TBW SSDs for low power NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp4gac/is_it_possible_to_transfer_files_from_an_external/",
          "author": null,
          "description": "Title.\n    submitted by    /u/-Sh33ph3rd3r-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp4gac/is_it_possible_to_transfer_files_from_an_external/",
          "publishedOn": "2022-12-18T18:11:04.000Z",
          "wordCount": 15322,
          "title": "Is it possible to transfer files from an external SSD to Google Drive without first having to download them on your PC/smartphone?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp3w62/need_help_reading_an_old_msdos_hdd/",
          "author": null,
          "description": "Hello! I recently got an old Toshiba T1000LE from a relative. Unfortunately I opened it up and there are a lot of bad caps and corrosion on the main board, but the hard disk seems fine (model is JVC JDE2825P30-7, a standard 2.5\" IDE) so I removed it from the machine to recover the files.\n Problem is my w10 computer can't seem to recognize or read anything from this drive. Assuming it's still working (it powers on and spins up) is there a way to recover files on it? Or to make it readable?\n I usually do this procedure for machines that mount more recent os (from w95 on) so I'm not really practical with hard drives this old. Original computer mounts MS-DOS 3.3, it's from 1990, the HDD is 20 mb.\n Thanks a lot in advance!! \n https://preview.redd.it/x7zdvrye0p6a1.jpg?width=1280&format=pjpg&auto=webp&s=357cf72c82ea79c06e142584216efcc84d99373b\n https://preview.redd.it/j47n1vye0p6a1.jpg?width=1280&format=pjpg&auto=webp&s=713c08f17d28faa6f003696c04b2a57c50bbdceb\n https://preview.redd.it/n3tkhtye0p6a1.jpg?width=1126&format=pjpg&auto=webp&s=c0b4c0ce66bd197097ad93e302cbf0e74543e655\n    submitted by    /u/Ska_arj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp3w62/need_help_reading_an_old_msdos_hdd/",
          "publishedOn": "2022-12-18T17:43:05.000Z",
          "wordCount": 16189,
          "title": "Need help reading an old ms-dos hdd",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp3qv8/how_much_does_just_reading_data_from_hddssd/",
          "author": null,
          "description": "I'm seeding torrents and always wondered how this affects lifetime of hard disk?\n    submitted by    /u/Bear_with_a_hammer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp3qv8/how_much_does_just_reading_data_from_hddssd/",
          "publishedOn": "2022-12-18T17:35:19.000Z",
          "wordCount": 17043,
          "title": "How much does just reading data from HDD/SSD affect their life compared to writing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp3oml/trying_to_obtainconvert_files_of_obscure_songs/",
          "author": null,
          "description": "hi! so i have what i think is a pretty obscure question/problem to (hopefully) solve lol. there are some songs i downloaded on apple music earlier this year by a certain artist, and recently (i'm not sure exactly when, but within the last few weeks) that artist removed some of those songs (their earliest releases) from all streaming platforms, rendering me unable to play them on my computer or phone.\n ordinarily, if this happened (and i've certainly had it happen before) i would just find those songs on the internet and download the files to reupload to my apple music library on my computer so i could continue to be able to listen to them normally, but in this case, the artist isn't well known enough for their songs to be on any mp3 sites (trust me, i've checked) or soulseek, and if they w…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp3oml/trying_to_obtainconvert_files_of_obscure_songs/",
          "publishedOn": "2022-12-18T17:32:16.000Z",
          "wordCount": 17490,
          "title": "trying to obtain/convert files of obscure songs removed from streaming (potentially using apple music drm protected m4p files from time machine backup)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp2srs/wife_bought_me_a_10tb_drive_for_christmas_it_was/",
          "author": null,
          "description": "submitted by    /u/joebaes1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp2srs/wife_bought_me_a_10tb_drive_for_christmas_it_was/",
          "publishedOn": "2022-12-18T16:49:35.000Z",
          "wordCount": 16040,
          "title": "wife bought me a 10tb drive for Christmas, it was mislabelled at the factory and it's actually a 12tb drive!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zp02be/how_do_you_name_your_tv_series_folder_and_files/",
          "author": null,
          "description": "Hi, I'm doing it in this way: I create a folder with the TV serie's name, then I create a folder foreach season, and there I put the files with the name of TV serie - episodie number - episodie title\n If the TV series name is for example \"DataHoarder\":\n DataHoarder/Season 1/DataHoarder - 1x01 - Episodie title.ext DataHoarder/Season 2/DataHoarder - 2x01 - Episodie title.ext \n I'm curious, which is your naming convention?\n    submitted by    /u/secon25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zp02be/how_do_you_name_your_tv_series_folder_and_files/",
          "publishedOn": "2022-12-18T14:39:25.000Z",
          "wordCount": 16792,
          "title": "How do you name your TV series folder and files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zopioc/how_books_are_scanned/",
          "author": null,
          "description": "submitted by    /u/ReturnMuch9510  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zopioc/how_books_are_scanned/",
          "publishedOn": "2022-12-18T04:07:39.000Z",
          "wordCount": 17709,
          "title": "How books are scanned.",
          "imageUrl": "https://external-preview.redd.it/SBUKflKHcSRxZnBw0tRv7-cVfcBov5-aEN2jQA3EnO0.jpg?auto=webp&s=453f126fde1ad0e9f21a2cd50134a5a072df752a"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zom4ik/hdd_enclosure_supporting_sata/",
          "author": null,
          "description": "I'm currently building a NAS and have an LSI SAS 9200 to support more storage (my NAS is a SSF optiplex). Are there any options for enclosures that I could connect a SAS-to-SATA cable to?\n    submitted by    /u/Similar_Source5962  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zom4ik/hdd_enclosure_supporting_sata/",
          "publishedOn": "2022-12-18T01:14:14.000Z",
          "wordCount": 15922,
          "title": "HDD enclosure supporting SATA?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zole6m/psa_check_your_new_drives_warranties/",
          "author": null,
          "description": "I ordered a bunch of hard drives over there last month with so many great deals. Some of these came from the WD Store - so I thought they would be okay. But I checked the warranties just to be safe\n Already expired. For two of them.\n I'd have been screwed if I found this out a year from now if they died. Make sure that doesn't happen to you! Test your new drives' warranties!\n    submitted by    /u/ThatFireGuy0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zole6m/psa_check_your_new_drives_warranties/",
          "publishedOn": "2022-12-18T00:43:03.000Z",
          "wordCount": 16374,
          "title": "PSA: Check Your New Drives' Warranties!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoj9z8/strange_problem_with_new_hdd/",
          "author": null,
          "description": "So I just received my new HDD (ULTRASTAR 4TB) It was working just fine and I did transfer some file on it. Then I turned off my pc, when I went to turn it on again it won't boot. It will keep having a black screen and as soon as I disconnect the data cable from my new HDD it will boot.\n I tried many times and I really don't understand what happened. I tried searching online but can't find a fix to my problem.\n Any idea ? \n P.s. I can see it in the bios Edit: I did boot my pc and then connected the sata to the HDD, it took a while but then it showed in disk manager as RAW. I still can't access it and anything I try to do to it takes forever and never gets done.\n Thank you !\n    submitted by    /u/Cris257  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoj9z8/strange_problem_with_new_hdd/",
          "publishedOn": "2022-12-17T23:16:24.000Z",
          "wordCount": 15988,
          "title": "Strange problem with new HDD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoj61l/very_loud_vibrating_hdd_should_i_replace/",
          "author": null,
          "description": "Been using a ST2000DM008 seagate 7200 rpm drive and didnt notice it was the source of the sound until recently.\n It constantly vibrates which creates enough sound alone to be heard from the room next to me. currently I am using cables as a cousion unscrewed as adding foam in between the case and hdd was ineffective but still makes a lot of sound\n Is this expected sound level I need to live with or something not right about it? I have another damages sector hdd but it doesbt vibrate that bad\n    submitted by    /u/Felyne1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoj61l/very_loud_vibrating_hdd_should_i_replace/",
          "publishedOn": "2022-12-17T23:11:25.000Z",
          "wordCount": 15930,
          "title": "Very loud vibrating HDD, should I replace?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoidr3/any_wellwritten_articles_andor_guides_on_a/",
          "author": null,
          "description": "I want a robust set-up for exactly three things:\n - Backing up my computer and lap-top. Right now, I use Acronis to back them both up to the same external hard drive and to the Acronis cloud.\n - Backing up very large (hundreds of GBs, into TBs) of .csv data. These are very large health-care database sets that I use professionally. Right now, I store them on an external hard drive (separate from the computer back-up one) and on Google Cloud Storage.\n - I would like to start a personal PLEX media server.\n I am new to home networking and data-hoarding but my ideal set-up would include some of the following features:\n - As much automation as possible. I have a desktop (hard-wired to network) and a laptop (WiFi). Ideally, my desktop backups will occur on a regularly scheduled basis and my laptop whenever on my home network and/or docked at home.\n - Robust to failure; I think I want on-site, off-site, and remote (cloud) back-ups.\n - The ability to access my storage remotely (i.e., access my PLEX server while traveling for work, etc.).\n I'm prepared to read a lot and make purchases and effort as necessary, I just can't figure out where to start, the sheer amount of information and terms are overwhelming.\n    submitted by    /u/catinyourwall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoidr3/any_wellwritten_articles_andor_guides_on_a/",
          "publishedOn": "2022-12-17T22:37:29.000Z",
          "wordCount": 16931,
          "title": "Any well-written articles and/or guides on a complete home data server set-up?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoi16k/elon_musk_is_trying_to_erase_this_wikipedia/",
          "author": null,
          "description": "submitted by    /u/aladdin_the_vaper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoi16k/elon_musk_is_trying_to_erase_this_wikipedia/",
          "publishedOn": "2022-12-17T22:22:24.000Z",
          "wordCount": 15737,
          "title": "Elon Musk is trying to erase this Wikipedia article from the internet. Join the discussion so the article can stay up",
          "imageUrl": "https://external-preview.redd.it/Od3-uHHgpWBdprrA80Hi-GVnNQZMgcSfL2oE-mBTJEw.jpg?auto=webp&s=0ed1afbd61166f5cf8eaeab98e63e5296174d939"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoi0cx/any_ideas_how_i_can_really_rename_my_flash_drives/",
          "author": null,
          "description": "I have some Sandisk Cruzer Fit usb flashdrives. I want to rename them for my TV. \"video\" \"audio\" \"pictures\" etc. When I rename them, the name still says Cruzer Fit in the properties in my PC and on my TV. \n I can get a new name to show on the computer when looking at my drives, but it's the Cruzer Fit that I am trying to change. \n Any ideas how I could do this?\n    submitted by    /u/synaptic-flow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoi0cx/any_ideas_how_i_can_really_rename_my_flash_drives/",
          "publishedOn": "2022-12-17T22:21:23.000Z",
          "wordCount": 1903,
          "title": "any ideas how I can \"really\" rename my flash drives? it's not working right.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zohn4h/case_suggestions_for_hybrid_build_gaming_pc_plex/",
          "author": null,
          "description": "I'm looking for a case that will hold at least 6 3.5\" drives while simultaneously holding a full gaming PC build. I won't be using liquid cooling so no need of a radiator. I don't want to do a separate build due to power consumption and physical space limitations. I'm the only one that uses the server so I don't need a separate NAS.\n I've been looking at the Fractal Design Define 7 XL but I'm not sure I like the price and the size. I don't really need 18 drives so I could do fine with something smaller but middle-ground options seem to be somewhat limited.\n I would also prefer light tempered glass to dark if possible and I definitely want a side window.\n Any suggestions?\n    submitted by    /u/-CJF-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zohn4h/case_suggestions_for_hybrid_build_gaming_pc_plex/",
          "publishedOn": "2022-12-17T22:05:50.000Z",
          "wordCount": 15627,
          "title": "Case suggestions for hybrid build (Gaming PC + Plex Server)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zohe44/advice_needed/",
          "author": null,
          "description": "TLDR: need help deciding on how to upgrade my system. 1: utilize JBOD W/ UnRaid 2: new server system (specs at bottom)\n Hey guys, I have been hoarding on a system I build last year which is utilizing Linux mint as the OS. It has served me well but I’m running out of space (seems like a common issue here) and only have enough sata connections and power for 2 more drives in the current case and configuration. When I set everything up I basically had no clue what I was doing and everything is all over the place and hard to find/archive my data. After about a year of researching what my needs/wants are I’m wanting to switch to running UnRaid on my system which would mean a complete wipe of everything as far as I understand. I am contemplating buying a second computer and setting everything up and then migrating over to it with the old system used as a back up for my important files. I found a local built NAS for sale for $400 (specs below) or can I utilize Unraid on a small HP computer and add drive via a usb JBOD?\n Processor: AMD FX 4300\n Motherboard: ASUS M6A97 (Supports DDR3 ECC memory)\n RAM: 16 GB (4X4GB) DDR3 ECC 1333Mhz\n Video Card: Nvidia Quadro 510S\n Dell PERC 710 RAID Card (Supports RAID 0,1,5,6,10,50)\n Hard Drives: 2x Samsung 860 EVO 500GB, 6x HGST 4TB HDD, and 1x Western Digital 6TB HDD.\n    submitted by    /u/Randomness54321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zohe44/advice_needed/",
          "publishedOn": "2022-12-17T21:55:18.000Z",
          "wordCount": 16219,
          "title": "Advice needed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoh72f/my_onn_256gb_external_ssd_died/",
          "author": null,
          "description": "I was using it as my SSD for my Ubuntu server and this morning my server was off and there screen was black. I restarted it and I keep getting an error message. I'm asking here because you guys might know how to check if an SSD is dead dead. I can't get any of my machines to read it. Is it dead dead?\n The error was literally \"error\"\n    submitted by    /u/TroothBeToldPodcast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoh72f/my_onn_256gb_external_ssd_died/",
          "publishedOn": "2022-12-17T21:46:50.000Z",
          "wordCount": 15801,
          "title": "My onn 256GB external SSD died",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoh0qa/current_state_of_desktop_use_drives/",
          "author": null,
          "description": "Hello,\n just wanted to ask around a little bit regarding regular home use drives that are currently available.\n I was looking to expand my regular PC storage with something like a 2TB drive. Then I noticed that my current 5y/o WD Blue 1TB did accumulate some bad sectors and image backup failed due to some read errors.So it was time to get a new drive not just to expand but to replace that drive. The use of this drive being as a secondary drive for installing programs and stuff that doesn't need SSD levels of speed, but certainly not just storing data long term.\n Looking into what drives are currently available I quickly came upon the SMR vs CMR debacle and noticed that all WD Blue drives above 1TB use SMR (same for larger seagate barracudas). I did some research on that and really heard so…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoh0qa/current_state_of_desktop_use_drives/",
          "publishedOn": "2022-12-17T21:39:22.000Z",
          "wordCount": 16723,
          "title": "Current state of desktop use drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zofor0/off_site_backup_solution/",
          "author": null,
          "description": "Hi reddit fam,\n ​\n I have a question that I could use some advice. I have a 4 bay Synology Nas with 32TB configured with RAID 5 I think, with 1 drive parity so I have 24TB of usable storage. I have over 20tb backed up to BackBlaze with retention of 14 days. I am paying like $140 a month right now. I also got a T-Mobile promotion which gives me 2TB + Unlimited Google Photos for $15 a month and since I use the 2TB for work, I thought it was a no brainer.\n ​\n I am wanting to change my offsite backup storage. I am thinking of purchasing another 4 bay NAS or building a cheap one, storing at my parent's business, which is a motel, and using that as a backup target over paying for BackBlaze. I was thinking of making it a bit beefier and having more storage so they can store their surveillance footage on the NAS locally and I can use it as a backup target. Curious on pros/cons of getting rid of BackBlaze and taking care of my own offsite backup.\n ​\n I have 2Gig up/down at my home, and my parents business has a 400/40 mbps internet connection.\n    submitted by    /u/Ready-Artist9285  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zofor0/off_site_backup_solution/",
          "publishedOn": "2022-12-17T20:42:29.000Z",
          "wordCount": 16371,
          "title": "Off Site Backup Solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zofj0k/repairing_hard_drives_with_bad_sectors_by/",
          "author": null,
          "description": "I set up a USB TTL connection to the serial port on some Seagate hard drives and managed to 'repair' some that had bad sectors (G-list entries) by issuing a low level format command that tested every sector. \n This process took twice as long as a normal erase or format and any sectors that were deemed unsatisfactory were placed into the 'resident G-list' (which is similar to the factory defect list aka P-list in that the sectors are skipped over rather than reassigned so there is no performance loss).\n One drive had only a handful of bad sectors while the other had a few thousand. I am wondering if these 'refurbished' drives are now 'good as new' or should still be sent to recycling.\n More info on Seagate terminal commands here. warning issuing the wrong command or making a typo could lead to data loss so do not connect to the serial port of a drive containing important data\n Note: this only works on older drives that do not have the serial port locked\n    submitted by    /u/denpa_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zofj0k/repairing_hard_drives_with_bad_sectors_by/",
          "publishedOn": "2022-12-17T20:35:26.000Z",
          "wordCount": 16530,
          "title": "Repairing hard drives with bad sectors by low-level formatting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zofdid/i_got_tds_reply_to_my_fcc_complaint_491gb_is/",
          "author": null,
          "description": "submitted by    /u/TheMonDon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zofdid/i_got_tds_reply_to_my_fcc_complaint_491gb_is/",
          "publishedOn": "2022-12-17T20:28:59.000Z",
          "wordCount": 19488,
          "title": "I got TDS' reply to my FCC complaint. 491GB is normal usage apparently.",
          "imageUrl": "https://preview.redd.it/ji8ql081qi6a1.jpg?auto=webp&s=1190681c8505556a9a4f4c47a6bb18f480e1ff1e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoex02/how_to_download_a_mod_page_off_nexusmodscom/",
          "author": null,
          "description": "I have about 300GBs of fallout 4 mods on my computer. Said mods are organized with the same folder structure thats on nexus. I want to download the mod pages for the mods that I own. How would I do That?\n    submitted by    /u/Coralsix25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoex02/how_to_download_a_mod_page_off_nexusmodscom/",
          "publishedOn": "2022-12-17T20:09:11.000Z",
          "wordCount": 16000,
          "title": "How to download a mod page off Nexusmods.com",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoes5z/gallerydl_is_unable_to_download_from_instagram/",
          "author": null,
          "description": "[instagram][error] HttpError: '401 Unauthorized' for 'https://i.instagram.com/api/v1/users/web_profile_info/' \n I was messing around in my config file trying to add the path to my cookies when I tried to download an Instagram story for testing. It did not work and now I can not download any Instagram page/media at all. What's up?\n    submitted by    /u/doll985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoes5z/gallerydl_is_unable_to_download_from_instagram/",
          "publishedOn": "2022-12-17T20:03:19.000Z",
          "wordCount": 16109,
          "title": "gallery-dl is unable to download from Instagram and prints following error",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zodwu5/do_larger_hdds_have_a_higher_chance_of_failing/",
          "author": null,
          "description": "I'm currently trying to decide between getting two Seagate IronWolf 4TB hard drives for extra pc storage or the 8TB IronWolf. I have heard many times that the larger the hard drive is, the higher chances it has of failing.\n How true is this statement and why is that the case if so? would I be better off buying the 4TB drives to last me the longest? Goal: To download movies/shows, pictures, music and other entertainment\n    submitted by    /u/overratedcabbage_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zodwu5/do_larger_hdds_have_a_higher_chance_of_failing/",
          "publishedOn": "2022-12-17T19:25:14.000Z",
          "wordCount": 17319,
          "title": "Do Larger HDDs have a Higher Chance of Failing ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zodvqm/got_a_used_wd_red_hard_drive_what_can_i_do_to/",
          "author": null,
          "description": "I've searched this question, but not sure what is the best one. I've seen crystal disk info and victoria, etc. Which one do most of you use here? My preference would be something that is open source. This is for a WD Red 8TB drive.\n    submitted by    /u/Wooden-Photo-2783  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zodvqm/got_a_used_wd_red_hard_drive_what_can_i_do_to/",
          "publishedOn": "2022-12-17T19:23:54.000Z",
          "wordCount": 16359,
          "title": "Got a used WD red hard drive, what can I do to make sure it won't fail and/or is in good condition?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zodap1/synology_nas_8x_savings_by_switching_to_glacier/",
          "author": null,
          "description": "Hi all. It's been a while since I've used Glacier, the last time it being such a pain I deleted my account just to get rid of it. It seems its usability has improved with its rework into S3 Glacier Deep Archive and when I just compared the pricing to the Synology C2 service I've been using for years to take care of my few TB of media, it's 8x cheaper! Not considering the hefty but rare to incur retrieval costs, of course.\n So far everything has been going swimmingly, my Synology NAS just configured to use the Glacier Backup app (first time I use it, so far used only Hyper Backup to Syno C2) service with a small test folder into my new AWS account. I know enough to be suspicious of Glacier, so I'd love you people's advice on a few points...\n VERSION CONTROL:\n If I have to full restore from backup, I want to restore to the last daily state I backed up, not every file I've ever had, so I've disabled the following:\n https://preview.redd.it/doxpu31g4i6a1.jpg?width=816&format=pjpg&auto=webp&s=3866059ae4ec6409c40c957d9fefa569f4d9b490\n Is VC something I'd be giving up, with only the last point to restore from unless I choose to never delete from Glacier locally deleted files? That would be a fatally flawed concept for retrieving accidentally deleted files!\n Currently I benefit from version controlled backups in C2, with deduplication making it possible to not pay insane amounts for that.\n MOVING FILES = DUPLICATION?\n When I move a folder around my NAS, does that schedule it for deletion in Glacier then recreate it next time a backup kicks off? If so, it could prove very pricy with Glacier's \"pay 3 months minimum\" storage model...\n Thanks in advance, I appreciate partial answers too, as well as advice about other Gotchas I may not have thought of!\n    submitted by    /u/Lycanka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zodap1/synology_nas_8x_savings_by_switching_to_glacier/",
          "publishedOn": "2022-12-17T18:58:11.000Z",
          "wordCount": 18154,
          "title": "[Synology NAS] 8x savings by switching to Glacier - too good to be true?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoagqo/just_a_reminder_if_you_own_directory_opus_it_has/",
          "author": null,
          "description": "Just wanna mention this cause I almost bought an extra software to do this when it's already in the default file manager I'm using. That said, it's only available in the Pro (paid) version.\n    submitted by    /u/AndalusianGod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoagqo/just_a_reminder_if_you_own_directory_opus_it_has/",
          "publishedOn": "2022-12-17T16:50:47.000Z",
          "wordCount": 18857,
          "title": "Just a reminder: If you own Directory Opus, it has a built-in synchronize function to mirror files between two drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoafd8/hard_drive_sounds_yes_they_sound_like_this_all/",
          "author": null,
          "description": "submitted by    /u/alexkidd4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoafd8/hard_drive_sounds_yes_they_sound_like_this_all/",
          "publishedOn": "2022-12-17T16:49:08.000Z",
          "wordCount": 18679,
          "title": "Hard Drive Sounds - Yes, they sound like this, all the time!! LOL",
          "imageUrl": "https://external-preview.redd.it/mKoApiBrIvG2bsWE3vnhxypnGrKHIwr4jvmnBJg4BHc.png?format=pjpg&auto=webp&s=c0d19d7e3bcd519eab1cc4d6c3c86d514fdc0f87"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zoa8jl/10tb_seagate_exos/",
          "author": null,
          "description": "submitted by    /u/splago  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zoa8jl/10tb_seagate_exos/",
          "publishedOn": "2022-12-17T16:40:28.000Z",
          "wordCount": 16206,
          "title": "10/TB Seagate EXOS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zo88pg/hp_ultrium_920_lto3_scsi_firmware_upgrade/",
          "author": null,
          "description": "Hey Hoarders,\n Recently I've purchased two HP Ultrium 920 tape drives with a single IBM lto-3 ultrium tape. One of those drives accepted my LTO tape, but got fried shortly afterwards (remember kids, modular power supplies can have mirrored 12V-5V if you're not using original cabling~ ) The second one powers up fine, but rejects the tape, basically, ejects it few seconds after inserting it and flashes the \"Tape\" LED.\n I'm thinking that aside from worn out drive it might be the cause of old firmware. I was wondering if anybody has that firmware. HP has the download blocked behind extended support.\n ​\n HP Library and Tape Tools sees the drive as below:\n  \nProduct ID : Ultrium 1-SCSI [HH] \n Drive Technology : LTO \n Mech. Serial Number : HU10927KPF \n Firmware Rev : P61D/Standalone \n Target ID : 3 \n Target LUN : 0 \n OBDR Capability : Supported \n WORM Capability : Not Supported \n Firmware : P61D\n  \n   submitted by    /u/Arszerol  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zo88pg/hp_ultrium_920_lto3_scsi_firmware_upgrade/",
          "publishedOn": "2022-12-17T15:08:56.000Z",
          "wordCount": 16453,
          "title": "HP Ultrium 920 LTO-3 SCSI firmware upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znufp4/google_workspace_storage_dashboard_no_longer/",
          "author": null,
          "description": "Went to check my Workspace storage dashboard out of curiosity to see how much I was using and I noticed that the previous \"5TB Limit\" and the \"xxx% over\" language were gone. It went back to looking at how the dashboard did months ago before the alleged storage limit was put in place. I'm on the Enterprise Plus plan.\n I'm a single-user organization.\n Can anyone else verify that the limit language is gone for them (Enterprise Standard and Enterprise Plus only)?\n https://preview.redd.it/zt0p43gsyc6a1.png?width=2087&format=png&auto=webp&s=65eaa08a79766b0edff231b27a8f3b6c27abfc96\n    submitted by    /u/parker_step  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znufp4/google_workspace_storage_dashboard_no_longer/",
          "publishedOn": "2022-12-17T01:10:23.000Z",
          "wordCount": 15756,
          "title": "Google Workspace Storage Dashboard No Longer Shows Limit (Enterprise Plus)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znu3tx/wd_mycloud_home_1tb_ssd_upgrade_and_repasted/",
          "author": null,
          "description": "submitted by    /u/TrustTheHuman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znu3tx/wd_mycloud_home_1tb_ssd_upgrade_and_repasted/",
          "publishedOn": "2022-12-17T00:53:43.000Z",
          "wordCount": 15742,
          "title": "WD mycloud home 1TB ssd upgrade and repasted.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znqifi/18tb_wd_red_pro_at_319_for_you_muricans_but_569/",
          "author": null,
          "description": "submitted by    /u/Tobarson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znqifi/18tb_wd_red_pro_at_319_for_you_muricans_but_569/",
          "publishedOn": "2022-12-16T22:07:46.000Z",
          "wordCount": 17424,
          "title": "18TB WD Red Pro at $319 for you 'muricans. But €569 for us Euros :/",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znpnjh/datahoarder_discussion/",
          "author": null,
          "description": "Talk about general topics in our Discussion Thread!\n  \nTry out new software that you liked/hated? \n Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n Come show us how much data you lost since you didn't have backups!\n  \nTotally not an attempt to build community rapport.\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znpnjh/datahoarder_discussion/",
          "publishedOn": "2022-12-16T21:30:11.000Z",
          "wordCount": 15662,
          "title": "DataHoarder Discussion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znoj34/critique_my_plans/",
          "author": null,
          "description": "I have one bay unused in my NAS. The other 4 bays are each 3.6 Tb Drives. I am using only 3.55 TB of storage.\n The drives are formatted as SHR 1 in a Synology DS1515+ but I don’t believe they are using BTFRS because the NAS they came from did not support it.\n I am thinking of getting three 10TB Drives and putting one in the open bay then copying the data to that drive, dropping the system from 4 drives to 3 and using the old drives in another NAS that will be offsite. \n If this is a good ideas what are some recommendations on drives\n    submitted by    /u/AnOriginalName2021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znoj34/critique_my_plans/",
          "publishedOn": "2022-12-16T20:41:11.000Z",
          "wordCount": 17674,
          "title": "Critique my plans",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zno9cr/is_this_drive_dead_whenever_i_try_to_do_anything/",
          "author": null,
          "description": "submitted by    /u/750Y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zno9cr/is_this_drive_dead_whenever_i_try_to_do_anything/",
          "publishedOn": "2022-12-16T20:29:55.000Z",
          "wordCount": 17489,
          "title": "Is this drive dead? Whenever i try to do anything with it, it says that it's write protected(even though diskpart says otherwise). The only thing i can do with it is wipe it and create partitions with diskpart, but those partitions remain unwriteable. Sorry for the image quality",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znnibs/are_sata_power_switches_reliable/",
          "author": null,
          "description": "Anyone have experiences with or thoughts on SATA power switches like these (not necessarily that brand)--are they simple and foolproof or considered hacky and not worthy of risking your disks on? I would assume SATA is conducive to this if hotswapping is a thing that can be supported.\n I have external drives for cold storage littered on my workspace and I want to chuck them in my server (Node 304 case). Unfortunately, the USB-SATA logic board on the WD Reds from the Easystores don't fit into the mounting system of the case, hence I'm wondering if the SATA power switch allows me to turn on the drives every few months or so for the occasional access.\n Alternatively I'm thinking of something like this USB-SATA adapter (https://www.amazon.com/Indicators-External-Converter-Computer-Transfer/dp/B017CO5FJM/) (not necessarily this particular brand) and hook up the AC adapter to a power strip with switches for individual outlets to turn the drives on/off. This seems to be the same as the builtin logic boards in functionality but should be drive brand agnostic (e.g. WD logic boards may not necessarily be compatible with Seagate drives, at least without some mods). It is messier and uses USB3, but I should still be able to wire the cables through the PCIe slot and plug in the AC adapters to a power strip with a toggle on/off feature.\n Slight concern is drives not receiving stable power and potentially inducing more wear and tear as a result. \n I should note I am not interested in spinning down the drives--the drives will be used for months at a time and I will be rebooting the system probably biweekly for maintenance and testing, which will inevitably spin up the disks on startup only for them to be spun down again.\n If neither options are suitable then I suppose I just have to live with the drives on top of the server.\n    submitted by    /u/rofic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znnibs/are_sata_power_switches_reliable/",
          "publishedOn": "2022-12-16T19:58:10.000Z",
          "wordCount": 17817,
          "title": "Are SATA power switches reliable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znn5s4/best_approach_for_sync_between_backups/",
          "author": null,
          "description": "Right now when I am keeping media on two separate backups I just run a a rsync script I created for doing a checksum comparison. Are there any tools out there specifically for validating backups? Say you have three stores, at least two of them should have the same checksum for a vmware image. All three should be the same but if one is off the other two match, then I'd have the script refresh it from one of the other two.\n    submitted by    /u/TheIllusioneer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znn5s4/best_approach_for_sync_between_backups/",
          "publishedOn": "2022-12-16T19:42:27.000Z",
          "wordCount": 16936,
          "title": "Best approach for sync between backups?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znl6qx/what_are_some_alternative_to_google_drive/",
          "author": null,
          "description": "Looking for some alternative of drive because Google's privacy policey.Sometimes it deletes on its own.please give me suggestion of some alternative of drive.Tia\n    submitted by    /u/Emad_341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znl6qx/what_are_some_alternative_to_google_drive/",
          "publishedOn": "2022-12-16T18:15:20.000Z",
          "wordCount": 17528,
          "title": "what are some alternative to google drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znl4la/how_to_recover_unplayable_video_or_photo_in/",
          "author": null,
          "description": "I uploaded them and checked they seemed ok after that I deleted from my device.But now it can't play video. It says \"Cannot play this video\". How can I solve this because the raw file is no more\n    submitted by    /u/Emad_341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znl4la/how_to_recover_unplayable_video_or_photo_in/",
          "publishedOn": "2022-12-16T18:12:48.000Z",
          "wordCount": 17886,
          "title": "How to recover unplayable video or photo in google drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znkww3/yall_might_appreciate_this/",
          "author": null,
          "description": "submitted by    /u/ian9921  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znkww3/yall_might_appreciate_this/",
          "publishedOn": "2022-12-16T18:03:35.000Z",
          "wordCount": 17053,
          "title": "yall might appreciate this",
          "imageUrl": "https://preview.redd.it/hzwguhoocc6a1.jpg?auto=webp&s=695b8098fba032cbfc2d005b668d17a28a923ac9"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znkgdg/any_working_methods_for_pluralsight_downloading/",
          "author": null,
          "description": "Hoping to download these Pluralsight courses so that I can watch it later because I am out of time.\n Does YouTube-DLG work?\n Thank you.\n    submitted by    /u/appletreeyum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znkgdg/any_working_methods_for_pluralsight_downloading/",
          "publishedOn": "2022-12-16T17:44:15.000Z",
          "wordCount": 16122,
          "title": "Any working methods for Pluralsight downloading? YouTube-DLG?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znkb10/trying_to_find_solution_to_store_isosroms/",
          "author": null,
          "description": "Hi everyone!\n Been doing a ton of reading/research this morning on the topic, but I can’t seem to get on firm ground for a game storage strategy.\n Currently, I have a desktop PC which I built and use to emulate like 8 consoles worth of games. Many of these games are ISOs or folders that take up a lot of space per game.\n I no longer have access to a free unlimited google drive account which I had about 1.5Tb of data on so I need a migration plan.\n I also plan on adding much more data to emulate some of my PS3 games. I’ll probably ideally love to have upwards of 4-5Tb of storage. But I know the SSD price point sucks there. Open to a hybrid drive like Barracuda. I have an internal Barracuda drive and it’s fast to me!\n I’m not overly concerned about redundancy per se as I have the original discs for many of these games. I can get them all ripped again but it would be annoying. I’m primarily concerned about dependability/longevity with performance second.\n I just ordered a 2Tb 2.5 SATA SSD and a USB 3.0 enclosure for it. My PC does not use USB-C ports. I also have available space internally for another M.2 and another 2.5 drive.\n I’d appreciate some insight. I figured external is the way to go for game storage and continue to store the emulator executables on my system (c) m.2 SSD.\n    submitted by    /u/Nigel-Powers  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znkb10/trying_to_find_solution_to_store_isosroms/",
          "publishedOn": "2022-12-16T17:37:38.000Z",
          "wordCount": 18860,
          "title": "Trying to find solution to store ISOs/ROMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znjgca/just_a_daily_reminder_to_always_have_backups/",
          "author": null,
          "description": "submitted by    /u/_lay4play  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znjgca/just_a_daily_reminder_to_always_have_backups/",
          "publishedOn": "2022-12-16T17:00:53.000Z",
          "wordCount": 16250,
          "title": "Just a daily reminder to always have backups.",
          "imageUrl": "https://preview.redd.it/smy2rquh1c6a1.png?auto=webp&s=bebb8dd5612b22a93cb212176b5ad11517a29f41"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znj0eg/leakedzone_download_method/",
          "author": null,
          "description": "I've tried to download from this site few different ways. JDownloader, firefox download helper, I tried inspecting element but as soon as you do this the site jumps to the main url and the inspector doesn't have the time to load up the data from the original URL. I've tried some online downloaders but they don't seem to work. Yt-dlp + vid link also doesn't work. Is there anything?\n    submitted by    /u/zzzzzzzzzaaaaaaaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znj0eg/leakedzone_download_method/",
          "publishedOn": "2022-12-16T16:41:34.000Z",
          "wordCount": 16242,
          "title": "Leakedzone download method?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znhysj/i_manually_archived_the_entire_free_for_personal/",
          "author": null,
          "description": "submitted by    /u/nashosted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znhysj/i_manually_archived_the_entire_free_for_personal/",
          "publishedOn": "2022-12-16T15:58:02.000Z",
          "wordCount": 16055,
          "title": "I Manually Archived the Entire (free for personal use) Prado Museum Collection - Here's my Journey and Download Link",
          "imageUrl": "https://external-preview.redd.it/EPqg5vhTYzrq0b1dG_hSOBLHypI8--X0zqvQMzFg-Gg.jpg?auto=webp&s=b9d6231be540534c6c7c7592742a535c78378c88"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znhfql/official_december_seagate_ironwolf_giveaway/",
          "author": null,
          "description": "You know the drill, it's giveaway time again! For this one, we are giving away an IronWolf Pro 125 1.92TB SSD to one lucky winner in this thread!\n Happy Holidays! We love participating in the r/DataHoarder community and want to help further someone's data hoarding ways.\n The prize is: one IronWolf Pro 125 1.92GB SSD\n How to enter:\n Just reply to this post once with a comment that includes the terms RunWithIronWolf and Seagate telling us what you're most excited for in 2023.\n Selection process/rules\n One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until December 30th 2022, 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, a…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znhfql/official_december_seagate_ironwolf_giveaway/",
          "publishedOn": "2022-12-16T15:36:08.000Z",
          "wordCount": 19454,
          "title": "Official December Seagate IronWolf Giveaway",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znhebt/not_sure_if_this_is_a_good_deal_but_def_the/",
          "author": null,
          "description": "submitted by    /u/GUI-Discharge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znhebt/not_sure_if_this_is_a_good_deal_but_def_the/",
          "publishedOn": "2022-12-16T15:34:35.000Z",
          "wordCount": 16025,
          "title": "not sure if this is a good deal but def the lowest price on a 14tb drive I've ever seen",
          "imageUrl": "https://external-preview.redd.it/R5G1gmVh3ppMiBmbMMqCoPc6HtSk6Y8rTEXzQdfjtbI.jpg?auto=webp&s=27b34b1277d573c8fa7b384f4080b2d09b7da216"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zngbib/i_really_hate_it/",
          "author": null,
          "description": "submitted by    /u/pinkLizstar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zngbib/i_really_hate_it/",
          "publishedOn": "2022-12-16T14:46:33.000Z",
          "wordCount": 15815,
          "title": "I really hate it",
          "imageUrl": "https://preview.redd.it/if1ybvlzv96a1.jpg?auto=webp&s=dbd1f465cb12c7cc5cd2c2cb2a6e3d1324c5e952"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zng2sr/redoing_zfs_pool_over_holidays_should_i_stay/",
          "author": null,
          "description": "So backstory: I have 2 NAS systems in my house, one is a Synology box that I'm getting close to 8yrs old on, and another TrueNAS custom made using a Rosewill RSV-L4500 case. One of the drives on my Synology started reporting bad sectors, so I decided to take this as an opportunity to move everything over to TrueNAS and sell off the Synology NAS, just to simplify everything to just one device and to finally go full ZFS.\n My current setup on TrueNAS is a striped pool of mirrored vdevs of 2 8 TB drives each, so about ~28TB of usable space. I want to add another 4 drives, which maxes out the case's drive capacity.\n Adding those 4 drives in the same mirrored pool will give me 46TB in usable space, but it got me thinking if I want to use RAIDZ pools instead for this may drives (12 Total).\n Some basic calculations I did were:\n  \nMIRROR 6 Groups of 2 8TB drives: 46TB -- adding to existing pool\n RAIDZ1 3 Groups of 4 8TB drives: 67TB \n RAIDZ1 2 Groups of 6 8TB drives: 74TB \n RAIDZ1 1 Group of 12 8TB drives: 82TB \n RAIDZ2 3 Groups of 4 8TB drives: 44TB\n RAIDZ2 2 Groups of 6 8TB drives: 61TB\n RAIDZ2 1 Group of 12 8TB drives: 70TB\n  \nI understand that mirrored is would be better because rebuilds on failures would be faster than relying on parity etc, but would redoing the pool groups of RAIDZ be better longevity vs usable space? Mostly considering that at this point I can never upgrade this pool again physically (unless I get a different chasis/case but thats a whole other project in itself) but I obviously care about redundancy on failures as well.\n ​\n Does anyone have any recommendations/insights/experiences?\n    submitted by    /u/adamzwakk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zng2sr/redoing_zfs_pool_over_holidays_should_i_stay/",
          "publishedOn": "2022-12-16T14:35:21.000Z",
          "wordCount": 18862,
          "title": "Redoing ZFS pool over holidays, should I stay mirrored or go RAIDZ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znewid/i_took_apart_a_hdd_and_made_a_sticker/",
          "author": null,
          "description": "submitted by    /u/TechSquidTV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znewid/i_took_apart_a_hdd_and_made_a_sticker/",
          "publishedOn": "2022-12-16T13:38:58.000Z",
          "wordCount": 14749,
          "title": "I took apart a HDD and made a sticker",
          "imageUrl": "https://preview.redd.it/56mv2zovj96a1.jpg?auto=webp&s=4251b5798eb9684536fda86590cb1d81eb526be6"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/znbk3f/large_file_set_dup_finders_for_nass/",
          "author": null,
          "description": "I've tried a handful of programs so far and they either won't look at network drives and freeze up part way through (even if I limit the area it is searching), any suggests (i have about 3.5 tb of mixed data) \n i've searched reddit somewhat already and not had any luck yet, linux or windows is fine\n    submitted by    /u/Potential_Ad4240  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/znbk3f/large_file_set_dup_finders_for_nass/",
          "publishedOn": "2022-12-16T10:28:17.000Z",
          "wordCount": 17662,
          "title": "large file set dup finder(s) for NAS's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn92nf/cracking_the_password_on_a_msdos_62_msbackup_set/",
          "author": null,
          "description": "Way back in 1995 I backed up a machine onto a sizeable stack of floppies using MS-DOS 6.2 MSBACKUP.EXE. I've imaged the discs, pulled them into a VM and confirmed that they're readable... so that's cool. The only issue is that I have no idea what password I would have set on them 27 years ago.\n Since the passwords were max 8 characters, I'm presuming if I could put the set through a password cracker it shouldn't take too long to break it. Problem is I have no idea where to start.\n I've looked to see if the file format is well known (it does not appear to be documented). \n I've considered trying to write/build some type of automation that runs on top of the VM to automate the keyboard input/screen reading, but I'm not sure what toolset to start with to build that. I'm reasonably technical enough to string together tools with some code/script if someone could point me in the right direction.\n At this point, I'm more curious than anything else as to what's on those disks and if they're truly recoverable this many years later.\n Any thoughts, direction would be appreciated.\n    submitted by    /u/rollinghunger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn92nf/cracking_the_password_on_a_msdos_62_msbackup_set/",
          "publishedOn": "2022-12-16T07:34:26.000Z",
          "wordCount": 18475,
          "title": "cracking the password on a MS-DOS 6.2 MSBACKUP set",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn6zqt/why_is_there_no_high_capacity_25_hdd_any_more/",
          "author": null,
          "description": "The highest capacity 2.5\" spin-disk HDD I can find is only 5TB at about $290. It really has very little if any advantage over 2.5\" SSD 4TB, which are retailed at $237 the cheapest. The fact is 3.5\" HDD are still growing toward higher capacity, while 2.5in HDD market just silently died.\n I'm thinking about to make an offline backup with a 2.5\" HDD, but it seems this is not a viable path any more.\n    submitted by    /u/--dany--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn6zqt/why_is_there_no_high_capacity_25_hdd_any_more/",
          "publishedOn": "2022-12-16T05:25:23.000Z",
          "wordCount": 17593,
          "title": "Why is there no high capacity 2.5\" hdd any more?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn1ukh/refurbed_seagate_drive_errors_question/",
          "author": null,
          "description": "Recently purchased a refurbed Exos 16TB drive. I cleared the drive, ran stress tests on it, then threw it in my array. SMART data was fine etc.\n 2 Days later, while trying to add another drive to my array, this drive starts throwing out errors every second. I reached out to the vendor who said they'd replace it no problem. Trouble is, the drive has highly sensitive data, and DBAN fails when trying to scrub. How comfortable would you be at that point sending the drive back?\n    submitted by    /u/sIlverbulette  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn1ukh/refurbed_seagate_drive_errors_question/",
          "publishedOn": "2022-12-16T00:56:30.000Z",
          "wordCount": 16869,
          "title": "Refurbed Seagate drive errors, question.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn0yii/homelab_desktop_choices/",
          "author": null,
          "description": "submitted by    /u/MrJwan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn0yii/homelab_desktop_choices/",
          "publishedOn": "2022-12-16T00:14:59.000Z",
          "wordCount": 16948,
          "title": "Homelab Desktop Choices ..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn0wws/tool_for_incremental_backups/",
          "author": null,
          "description": "Which tool, cli or non-cli, do you all suggest for doing incremental backups? Data is about 500gb, and backup will go to an external. deleting and transferring the whole thing doesnt seem a good idea as the size increases lol. Also it should run periodically (every 14 days I'd say?) whenever the external is connected, how can I make sure of that?\n Edit: I'm on Macos\n    submitted by    /u/TetheredToHeaven_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn0wws/tool_for_incremental_backups/",
          "publishedOn": "2022-12-16T00:13:05.000Z",
          "wordCount": 17960,
          "title": "Tool for incremental backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zn02i3/looking_for_a_good_quality_usb_vhs_transfer/",
          "author": null,
          "description": "Hey all, I’ve been looking for a new analog transfer device for a while to transfer hi-8 and VHS tapes. I bought a cheap easy-cap like device, and it sucked. It was causing a lot of artifacting, frame drops, highlight blowout and just something I wouldn’t trust to transfer several hours worth of important footage.\n With Christmas around the corner, I’ve decided to treat myself with a good quality transfer device. Only problem is, I can’t find the right one. Most of the suggestions I’ve found online and on Reddit are extremely dated or way too advanced for my current setup.\n I’ve heard good things about the Hauppage HD PVR, elgato analog capture, and black magic intensity shuttle cards, but so many people have suggested different approaches that I don’t know which one to try. Everything from TBCs, scalers, passthroughs, to PCIs, I don’t even know if I’m getting the right thing.\n I want to get a good quality device that I can use with my laptop and camcorder without having to drop hundreds of bucks and uproot my entire setup. My main goal is to save these videos to a digital format while losing as little of the picture quality as possible. I’d greatly appreciate any suggestions for what I should invest in.\n    submitted by    /u/urnotmydad23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zn02i3/looking_for_a_good_quality_usb_vhs_transfer/",
          "publishedOn": "2022-12-15T23:36:00.000Z",
          "wordCount": 18044,
          "title": "Looking for a good quality USB VHS transfer device, any suggestions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmy0sy/best_way_to_increase_my_data_hoarding/",
          "author": null,
          "description": "I recently decided to up my game and build a NAS. It took a decent amount of convincing, but the biggest thing I used to get my SO on board was that there would be less downtime for our media server. To acquire new material, I need to be connected to a VPN. Is there a way to have my server on a VPN while leaving it accessible to the world outside my network? If not, is it possible to have a directory auto backup to the server, and would this be easier accomplished on windows or Linux?\n    submitted by    /u/Alucard2051  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmy0sy/best_way_to_increase_my_data_hoarding/",
          "publishedOn": "2022-12-15T22:21:31.000Z",
          "wordCount": 17085,
          "title": "Best way to increase my data hoarding?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmxo7l/safe_place_to_store_pirate_library/",
          "author": null,
          "description": "Hey there ! I guess this request is kind of strange but I've been thinking about downloading the whole pirate library (most books from Zlib and Libgen) mirror to have a local copy of almost every books I can think of (around 30TB). I have a safe where I put HDDs with some accounting records and for that matter it has work for years. I know that it isn't the best way to store data that I don't need to access often so what would the alternative be ? Can I put data on Hard Drives and let them unused for years ? Thanks !\n    submitted by    /u/AnyInsurance2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmxo7l/safe_place_to_store_pirate_library/",
          "publishedOn": "2022-12-15T22:09:36.000Z",
          "wordCount": 17677,
          "title": "Safe place to store Pirate Library",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmx7wj/ok_so_not_all_modern_7200_rpm_hdds_got_similar/",
          "author": null,
          "description": "Trying to understand my HDD Read Speeds and why the middle drive is so much slower and the last one so much faster when they are all 7200 RPM. Thank you for input.\n ​\n WDC WD121KRYZ-01W0RB0 12000.1 GB 7200 RPM (Internal SATA)\n Aproximately: 237(MB/s)\n ST18000NM000J-2TV103 18000.2 GB 7200 RPM (Internal SATA))\n Aproximately: 183(MB/s)\n WDC WD201KFGX-68BKJN0 20000.5 GB 7200 RPM (External DAS)\n Aproximately: 276(MB/s)\n    submitted by    /u/nando1969  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmx7wj/ok_so_not_all_modern_7200_rpm_hdds_got_similar/",
          "publishedOn": "2022-12-15T21:52:39.000Z",
          "wordCount": 17052,
          "title": "Ok, so not all modern 7200 RPM HDDs got similar speeds, questions below.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmw281/whats_the_most_reliable_ssd/",
          "author": null,
          "description": "I spent all afternoon trying to get stuff off my old WD drive which is an HDD. I managed to get it spinning and open. But if I’m trying to get everything to a sizable SSD, what should I get?\n    submitted by    /u/quantumcatreflex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmw281/whats_the_most_reliable_ssd/",
          "publishedOn": "2022-12-15T21:04:57.000Z",
          "wordCount": 1860,
          "title": "What’s the most reliable SSD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmw0yi/backup_for_20tb_of_video_footage/",
          "author": null,
          "description": "Hey guys, New at this. I have an archive or video interviews from Holocaust survivors that I need to better secure. Currently, I have them on a few drives but looking for another place to store long term. We don't need to edit or view the footage often it's just a worse-case backup. \n ​\n Any ideas? \n Not looking to spend much. \n Does AWS or some cloud site make sense?\n    submitted by    /u/movingfowards  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmw0yi/backup_for_20tb_of_video_footage/",
          "publishedOn": "2022-12-15T21:03:30.000Z",
          "wordCount": 18535,
          "title": "Backup for 20tb of video footage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmvskq/wd_easystore_bricked/",
          "author": null,
          "description": "Hi everyone, not sure if this is the right place to ask but I'm going to try.\n I have a 14TB WD easystore that's been working for just over a year now. Yesterday, I noticed it was mounting and unmounting rapidly, so I ejected it and restarted the computer. \n When I turned the computer back on it would no longer mount, the discs aren't spinning and there was a slow, white flashing from the LED indicator. I immediately looked up all the troubleshooting guides and did the following. \n  \nSwitched USB cables (used my other easystore's usb)\n plugged into a dedicated wall outlet\n checked windows device manager and un-checked \"allow the computer to turn off this device to save power\" - restarted pc\n opened disc management, where it is not visible and there is no drive letter for it at all\n updated drivers \n allowed hidden items in serial bus drivers\n  \nAfter frustration I stopped everything all together. This morning I plugged it in and there is still no disc spinning activity, and now the LED blinks rapidly. Is this thing bricked? I have 13.9 TBs on it and would really hate to lose it all. I had it propped up on fans and it was well maintained, and of course there is no power or reset button on these things.\n Any suggestions? It's still warrantied for another year. Thanks in advance.\n    submitted by    /u/ryPods  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmvskq/wd_easystore_bricked/",
          "publishedOn": "2022-12-15T20:54:07.000Z",
          "wordCount": 17385,
          "title": "WD Easystore Bricked? :(",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmvovg/help_improveexpand_my_current_backup_setup_please/",
          "author": null,
          "description": "Hi,\n I have personal data (general, plus DSLR and GoPro photos/videos for Lightroom/Final Cut Pro), business data (including lots of big image files, say 1GB per file, 200GB currently), and my computer setup to back up. I don't generally save images/videos on my internal SSD.\n My current setup looks like this:\n  \n2TB external HD for photo/video storage 2.5\"\n 5TB external HD for business data storage 2.5\"\n I also have a 2TB external SSD for temporary photo/video storage for faster editing. This only ever contains duplicates from the 2TB HD\n 4TB external HD for backing up both the 2TB and the 5TB external HDs (yeah, the 4TB was here first, when I had 2x 2TB, but my business 2TB failed so I upgraded that to a 5TB... thus the stupid size relations)\n 1TB time machine external HD for backing up my Mac setup/internal SSD\n iDrive Cloud for backing up my Time Machine, 2TB photo and 5TB business HD.\n  \n​\n Problem: My photo/video 2TB external HD is getting really full, only 10% space left... I started taking more videos, which take up a huge amount of space.\n Now I'm really torn as to how to smartly upgrade my backup setup.\n  \nShould I get a big external HD, maybe 6TB, to replace the current stupid 4TB backup HD, and use the 4TB backup HD for photos and videos instead?(I could even use the 4TB just for videos, leave my photos on the current 2TB photo/video HD). If so, should I get a 2.5\" or 3.5\" for the 6TB? I don't really need to move it, it should stay on my desk, but is there still an advantage to 3.5\" these days at all?\n Or should I rather get a second smallish (2TB) external HD to put the videos on, so that the current photo/video HD only contains photos, and leave the backup 4TB as is for now?\n  \n​\n Trying to save money atm, but also want a sustainable solution...\n Which option do you suggest and why?\n Feel free to also add other sensible options that I'm missing here!\n ​\n Thanks so much!\n ​\n View Poll\n    submitted by    /u/4symmetry  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmvovg/help_improveexpand_my_current_backup_setup_please/",
          "publishedOn": "2022-12-15T20:49:59.000Z",
          "wordCount": 18826,
          "title": "Help improve/expand my current backup setup - please",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmv2yg/is_there_a_calibre_or_stash_like_program_i_can/",
          "author": null,
          "description": "Hi everyone.\n Does anyone know if there are any programs like stash that i can use to acess my downloaded youtube videos from my web browser on my lan in an aesthetically pleasing way?\n I do not want to use plex as while i have that setup and it is good on the tv i would love something a bit more browser focussed for accessing in web browsers on my computers to go along with stash, calibre, kiwix, sonarr, radarr etc.\n    submitted by    /u/therealbabyshell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmv2yg/is_there_a_calibre_or_stash_like_program_i_can/",
          "publishedOn": "2022-12-15T20:24:46.000Z",
          "wordCount": 17632,
          "title": "Is there a Calibre or Stash like Program i can use for videos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmtpnr/photo_deduplication_with_heic_support/",
          "author": null,
          "description": "I'm looking for a photo deduplication app that looks at heic photos also. Platform doesn't really matter as I can work with any. Doing searching for one they seem to be older apps that doesn't support heic. Any suggestions?\n    submitted by    /u/Ryanrk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmtpnr/photo_deduplication_with_heic_support/",
          "publishedOn": "2022-12-15T19:28:29.000Z",
          "wordCount": 16785,
          "title": "Photo Deduplication with heic support?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmqqyo/its_offsite_backup_day/",
          "author": null,
          "description": "submitted by    /u/pizzatreeisland  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmqqyo/its_offsite_backup_day/",
          "publishedOn": "2022-12-15T17:26:25.000Z",
          "wordCount": 17454,
          "title": "it's offsite backup day!",
          "imageUrl": "https://preview.redd.it/bt4vehj5156a1.png?auto=webp&s=da507144b4c15e885db309415e7ee2a15afbd98f"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmqmnz/best_way_to_measure_hdd_vibrations_in_a_server/",
          "author": null,
          "description": "Whats the easiest way to measure the vibration level of hdds in different servers?\n I am currently building multiple diy jbods and want to test which design works best.\n    submitted by    /u/Pommes254  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmqmnz/best_way_to_measure_hdd_vibrations_in_a_server/",
          "publishedOn": "2022-12-15T17:21:46.000Z",
          "wordCount": 17035,
          "title": "Best way to measure hdd vibrations in a server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmqkm9/minecraft_offline/",
          "author": null,
          "description": "Not sure if anyone here archives games, or has experience with Minecraft, but is there any way to have a Minecraft launcher, such as the titan launcher, for offline use? What I mean is, if you use the titan launcher you still have to download any version you might want to play. What I'm looking for is a launcher that already has ALL Minecraft versions built in so I can just play it wherever and whenever and require no internet connection whatsoever. I want this for purposes of archiving the game on an external HDD, since I'm a big data hoarder.\n    submitted by    /u/Voldy256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmqkm9/minecraft_offline/",
          "publishedOn": "2022-12-15T17:19:30.000Z",
          "wordCount": 16998,
          "title": "Minecraft offline.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmpo9h/screen_recorder_software_or_stream_downloader/",
          "author": null,
          "description": "I'm wondering, for the people that have experience with it, whether you prefer to use screen recorder software or something else to save the video stream directly when archiving video from websites? \n I'm specifically looking to archive video from the History channel's website because I can't find it anywhere else and don't want it to just disappear one day.\n    submitted by    /u/PiMan3141592653  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmpo9h/screen_recorder_software_or_stream_downloader/",
          "publishedOn": "2022-12-15T16:43:17.000Z",
          "wordCount": 16830,
          "title": "Screen recorder software or stream downloader?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmo078/ive_started_down_the_path_of_data_hoarding/",
          "author": null,
          "description": "submitted by    /u/NessDan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmo078/ive_started_down_the_path_of_data_hoarding/",
          "publishedOn": "2022-12-15T15:35:37.000Z",
          "wordCount": 17328,
          "title": "I've started down the path of Data Hoarding 😇 Downloaded my data from services, backing up photos and vids from my phone, and archiving my YouTube playlists!",
          "imageUrl": "https://preview.redd.it/ru7po5tiz26a1.png?auto=webp&s=04d976eef515a1d9c361ffc5bf3b992c3c118d4c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmnw7d/advice_on_50_sealed_500gb_hdds/",
          "author": null,
          "description": "I have the opportunity to buy around 50 500GB HDDs still sealed in their original packaging (about USD 4.50 per drive), and was wondering if it would be worth getting any. \n Based on this thread, it seems that the best use would be to just (re)sell the drives or offer upgrade services; and that building something with them would be quite inefficient due to high power requirements relative to the storage space available. Any other ideas on what else could be done with these drives? Or would those two suggestions still be the best advice today? \n Also, these drives are somewhat old (manufactured 2015, ~7 years ago). If the HDDs have been factory sealed all this time, would they still be very likely to work, or would there be some form of degradation?\n    submitted by    /u/drowsy_kitten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmnw7d/advice_on_50_sealed_500gb_hdds/",
          "publishedOn": "2022-12-15T15:31:18.000Z",
          "wordCount": 19057,
          "title": "Advice on 50+ sealed 500GB HDDs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmniue/backblaze_adds_us_east_region/",
          "author": null,
          "description": "https://www.backblaze.com/blog/backblaze-adds-us-east-region-expanding-location-choices-and-cloud-replication-options/\n Also a nice read about behind-the-scenes of the new DC. https://www.backblaze.com/blog/a-behind-the-scenes-look-at-our-us-east-data-center/\n    submitted by    /u/newcbomb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmniue/backblaze_adds_us_east_region/",
          "publishedOn": "2022-12-15T15:16:03.000Z",
          "wordCount": 16652,
          "title": "Backblaze Adds US East Region",
          "imageUrl": "https://external-preview.redd.it/0_QuLEGPgNcIsXFu26NpD73Z3az5ljQOk-aUKXQ-6KI.jpg?auto=webp&s=57c4c18e15c2b569039247fe5cf178606417cbaf"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmf0cu/a_newspaper_vanished_from_the_internet_did/",
          "author": null,
          "description": "submitted by    /u/ChasingTheRush  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmf0cu/a_newspaper_vanished_from_the_internet_did/",
          "publishedOn": "2022-12-15T07:16:08.000Z",
          "wordCount": 29346,
          "title": "A newspaper vanished from the internet. Did someone pay to kill it? | *digs into link rot and the loss of digital archives*",
          "imageUrl": "https://external-preview.redd.it/tGfNHUfJWWvlnVyfRQu2pQGOFrpPN4LQLxUyn6Gcajs.jpg?auto=webp&s=24459ff9106ed4a064443f3f8ea8707194978405"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zmedz1/downloading_all_saved_reddit_media_from_specific/",
          "author": null,
          "description": "GitHub - shadowmoose/RedditDownloader: Scrapes Reddit to download media of your choice. \n can anyone tell me how to use the rmd shadowmoose tool? im looking at the ui, How do I make it download every post i saved from a specific reddit? How do I make it all save in a folder in a specific download location?\n    submitted by    /u/I-am-ocean  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zmedz1/downloading_all_saved_reddit_media_from_specific/",
          "publishedOn": "2022-12-15T06:38:57.000Z",
          "wordCount": 17798,
          "title": "Downloading all saved reddit media from specific subreddit",
          "imageUrl": "https://external-preview.redd.it/vYgR2foukwVDiXH_KtWnPanT3Syjz7NFrQk9zcRI0JM.jpg?auto=webp&s=3cfea73d59cb576f67023b7ccf56ac614f56f05d"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zma47m/my_drive_is_making_weird_grinding_noises_and_50/",
          "author": null,
          "description": "NO, NO IT'S NOT. \n If you care about your data, trash or RMA any drives with ANY errors no matter how small. It will only get worse.\n    submitted by    /u/Royal-Ad-2088  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zma47m/my_drive_is_making_weird_grinding_noises_and_50/",
          "publishedOn": "2022-12-15T02:49:32.000Z",
          "wordCount": 17434,
          "title": "My drive is making weird grinding noises and 50% of the clusters show bad sectors. It’s ok to keep using it though, right?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm7a5d/i_need_help_with_storage/",
          "author": null,
          "description": "Hello Folks, I have an important thing that I figure y'all \n can help me with (please do)\n    submitted by    /u/Mansiontrash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm7a5d/i_need_help_with_storage/",
          "publishedOn": "2022-12-15T00:37:19.000Z",
          "wordCount": 18459,
          "title": "I need help with storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm74yq/what_are_the_best_ways_to_mass_download_safe_for/",
          "author": null,
          "description": "Currently downloading 1 at a time\n    submitted by    /u/wallpapersdance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm74yq/what_are_the_best_ways_to_mass_download_safe_for/",
          "publishedOn": "2022-12-15T00:30:55.000Z",
          "wordCount": 16681,
          "title": "What are the best ways to mass download safe for work pictures of non-nude female fitness pictures from subreddits onto my ipad mini 5?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm6cs0/should_i_replace_this_drive_soon/",
          "author": null,
          "description": "submitted by    /u/aaronwei5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm6cs0/should_i_replace_this_drive_soon/",
          "publishedOn": "2022-12-14T23:56:53.000Z",
          "wordCount": 19319,
          "title": "Should I replace this drive soon?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm6b4b/downloading_large_amount_of_images_from_forums/",
          "author": null,
          "description": "I'm searching for a tool that can download images linked in forum posts. Cyberdrop-dl (python) is quite good, but it has issues with forum posts. If you try to download it by direct link to specific post, it will download a bunch of random images, from that topic, but I can't find any rule how it works.\n    submitted by    /u/Vichex52  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm6b4b/downloading_large_amount_of_images_from_forums/",
          "publishedOn": "2022-12-14T23:54:51.000Z",
          "wordCount": 17098,
          "title": "Downloading large amount of images from forums",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm54b3/what_would_be_the_best_way_to_back_up_a/",
          "author": null,
          "description": "So, I've created a dual-boot PC for myself so I can learn how to use Linux and hopefully transition away from Windows. \n I want to have my PC automatically backup all its data. However, there are a lot of different ways to backup PCs, and I'm not sure which methods/programs would work best for my situation. \n I've looked through the r/DataHoarder Wiki and I have a rough idea of what a backed-up PC should look like, but my problem is that there are a lot of backup tools and programs out there and I don't know which I should use. \"I'm trapped by overchoice.\" \n I also can't seem to find any guides on what can and can't be done when trying to backup a dual-boot PC. Can one operating system backup both itself and the other operating system, or do both operating systems need to have their own backups? \n As to my current situation. I have about 1TB of personal data (I save a lot of movies, music, and images). I currently have all my data saved on a 2TB external USB HDD. My dual-boot PC is set up, but I haven't installed anything on it yet because I want to make sure I have a backup system all set up first. I have a bit of a \"hodgepodge\" of drives. I have:\n  \nTwo 500GB SSDs as my boot drives for Linux and Windows respectfully\n One 500GB HDD I salvaged from my mom's old desktop.\n One 750GB HDD I salvaged from my old Toshiba laptop\n One 2TB HDD that serves as my PC's internal \"bulk storage\" drive for all the music, videos, and images. \n One external USB 2TB HDD that I've been using as my backup drive.\n  \n   submitted by    /u/Alexander-369  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm54b3/what_would_be_the_best_way_to_back_up_a/",
          "publishedOn": "2022-12-14T23:03:57.000Z",
          "wordCount": 17189,
          "title": "What would be the best way to back up a dual-booting Windows and Linux PC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm3yfp/f_for_this_poor_terabyte_i_have_filled_up_with_my/",
          "author": null,
          "description": "submitted by    /u/OfficialXtraG07  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm3yfp/f_for_this_poor_terabyte_i_have_filled_up_with_my/",
          "publishedOn": "2022-12-14T22:16:21.000Z",
          "wordCount": 16612,
          "title": "F for this poor terabyte I have filled up with my childhood dreams.",
          "imageUrl": "https://preview.redd.it/9jkken9gux5a1.jpg?auto=webp&v=enabled&s=f41da4758496a047bf6ba703d073260596c3284b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm3p3f/how_should_i_evaluate_disk_health_given/",
          "author": null,
          "description": "I have a couple dozen drives, all their own volume (virtualized as one via DrivePool) of various sizes and models.\n Following a a power...blip? the other day, StableBit Scanner is reporting a handful of them with unreadable sectors.\n Every single drive where damage was reported is in a single QNAP enclosure.\n Number of sectors unreadable on all affected drives: 1, 1, 1, 8, 61, 44240\n Only two media files were affected (99%+ intact) and were recovered via Scanner. The \"most damaged\" drive amounted to 21MiB in terms of storage.\n Scanner reports all drives as otherwise healthy, and no SMART flags to check\n I manually confirmed that all affected drives are reporting 0 for Reallocated Sectors, Reallocation Events, Pending Sectors, Uncorrectable Sectors (I guess that last one doesn't make sense to me)\n My two questions are:\n Should I treat this as \"the beginning of the end\" for these drives, or not?\n Would a UPS have probably avoided this event?\n    submitted by    /u/TootSweetBeatMeat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm3p3f/how_should_i_evaluate_disk_health_given/",
          "publishedOn": "2022-12-14T22:05:50.000Z",
          "wordCount": 17362,
          "title": "How should I evaluate disk health given unreadable sectors but otherwise healthy SMART?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm3443/the_datahoarder_showoff_thread_december_2022/",
          "author": null,
          "description": "I got my storage start on HardForums storage showoff threads in around 2008 and I miss that format quite a lot so I think it's about time we recreate it here. The basic idea is to post pictures of your setup, detail the spec and tell us what you use your storage for.\n Here's an example post format...\n  \n Amount of total storage (Raw/Formatted/Config)\n Case\n PSU\n CPU\n RAM\n Motherboard\n Controller Cards (if any)\n Drives (include full model numbers)\n Operating System\n A paragraph or two describing what you use your storage for and how you handle backups and organizing and maybe future upgrade plans.\n Gallery of images (use imgur gallery format not separate image links)\n  \n We will run this thread every 6 months or so and update the post to feature the most upvoted, discussed and interesting systems! Have fun!! \n P.S. Some of you may remember where I was when I first joined DH, from this thread and it's about time I post a new one so I'll join you in posting my current setup should this go well.\n    submitted by    /u/-Archivist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm3443/the_datahoarder_showoff_thread_december_2022/",
          "publishedOn": "2022-12-14T21:42:23.000Z",
          "wordCount": 18749,
          "title": "The DataHoarder Showoff Thread | December 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm2431/mediasonic_probox_questions_changing_filesystem/",
          "author": null,
          "description": "I have a Mediasonic Probox that has 3 drives on HFS+ and data on them. File permissions have been ridiculously annoying while on linux and I wanted to change to ext4. I have had success in some ways with hfsplus mounting but I can not share the drives or do anything I really want lol.\n Does the Probox work as ext4 or zfs? I did not want to do NTFS but...I would prefer it to HFS+ at this point. \n If yes to ext4 and/or NTFS: If I format one drive at a time, would that work? Or would I lose/corrupt data on the other 2 drives? I am asking because I was hoping to copy as much data to 2 of the drives, wipe, then transfer data back. Do this for all 3\n Do I manually remove the drive from the enclosure or can I format a drive, one at a (I have no idea how raid really works or if this is actually a raid setup). \n Thank you guys!\n    submitted by    /u/path0l0gy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm2431/mediasonic_probox_questions_changing_filesystem/",
          "publishedOn": "2022-12-14T21:02:08.000Z",
          "wordCount": 16929,
          "title": "MediaSonic Probox Questions (changing filesystem type)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm1zol/what_are_the_pros_and_cons_of_the_file_sync/",
          "author": null,
          "description": "So, I've been looking at the different file backup programs in the r/DataHoarder wiki, and I came across freefilesync.org. This program looked like an ideal file sync program for me. However, I discovered that one of my favorite YouTubers made a nice tutorial about file syncing using a program known as \"Resilio\". I don't know which of these two programs to pick, so I was wondering if anyone here has used Resilio and could give a review of the program, and maybe talk about how it compares to other file sync programs.\n    submitted by    /u/Alexander-369  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm1zol/what_are_the_pros_and_cons_of_the_file_sync/",
          "publishedOn": "2022-12-14T20:57:16.000Z",
          "wordCount": 16520,
          "title": "What are the pros and cons of the file sync program\"Resilio\"?",
          "imageUrl": "https://external-preview.redd.it/bGNkRmqxaDnL61FoZqA4bJpXreeSY-cdeupnwt9qqHU.jpg?auto=webp&v=enabled&s=67ae00d73ee4fdbc8e16a8ed11606e96899675d6"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zm1469/recommendations_on_free_lto4_tape_backup_software/",
          "author": null,
          "description": "I recently got a LTO-4 tape drive and 15 tapes to backup my Plex torrents. I'm waiting for a pcie SAS HBA to be delivered, but in the meantime, does anyone have any suggestions or recommendations for free backup software? I found EaseUS Todo Backup and plan on using it, but maybe there's some better free software out there. \n I'd like to hear if there are some cheaper, paid solutions out there too.\n    submitted by    /u/20cstrothman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zm1469/recommendations_on_free_lto4_tape_backup_software/",
          "publishedOn": "2022-12-14T20:20:02.000Z",
          "wordCount": 17291,
          "title": "Recommendations on free LTO-4 tape backup software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlzzyw/seagate_ironwolf_14tb_60_off_neweggcom/",
          "author": null,
          "description": "submitted by    /u/root54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlzzyw/seagate_ironwolf_14tb_60_off_neweggcom/",
          "publishedOn": "2022-12-14T19:33:34.000Z",
          "wordCount": 17177,
          "title": "Seagate IronWolf 14TB 60% off - Newegg.com",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlzez7/best_place_to_upload_multiple_terabytes_of_twitch/",
          "author": null,
          "description": "I've got multiple terabytes of now-deleted or muted-via-DMCA VODs from Twitch but I have no idea what to do with them. I want them to be accessible to the public, but I'd hate for them to just get DMCA'd somewhere like YouTube. Does the Internet Archive accept stuff like that, and if so, what's the most efficient (CLI preferred) way to upload that much?\n    submitted by    /u/RocketSLC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlzez7/best_place_to_upload_multiple_terabytes_of_twitch/",
          "publishedOn": "2022-12-14T19:08:22.000Z",
          "wordCount": 16980,
          "title": "Best place to upload multiple terabytes of Twitch archives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlyqjo/i_have_2_copies_of_the_same_data_in_separate_hdds/",
          "author": null,
          "description": "I have 2 copies of the same data in 2 HDDs. One of them is 12 years old. Other is 6. I will make one more copy soon. Which copy should I use to create the 3rd one?\n It's all pictures and videos. Is there a way to verify the files to make sure they are still not corrupted?\n    submitted by    /u/streamlinkguy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlyqjo/i_have_2_copies_of_the_same_data_in_separate_hdds/",
          "publishedOn": "2022-12-14T18:40:23.000Z",
          "wordCount": 19494,
          "title": "I have 2 copies of the same data in separate HDDs. Which copy should I use to create the 3rd one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlxvc0/how_can_i_extract_the_3d_model_from_vr_viewer_on/",
          "author": null,
          "description": "I wanted to know if there is a way to download the 3D file from the viewer on a webpage. I feel like this should be possible since I am looking at the model but I don't know how to get to it. I use Google Chrome btw.\n    submitted by    /u/GroundBreakingEye44  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlxvc0/how_can_i_extract_the_3d_model_from_vr_viewer_on/",
          "publishedOn": "2022-12-14T18:06:14.000Z",
          "wordCount": 17106,
          "title": "How can I extract the 3D model from VR viewer on a webpage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlwlcn/rate_my_fugly_storage_setup_raw_288_tb/",
          "author": null,
          "description": "I know y'all will put my head on the pike due to piss poor cable management. Please roast my setup.\n Computer specs -\n  \nAsus WS C621E SAGE\n 2 x Xeon Bronze 3104\n 2 x SK hynix 64GB/4Gx4 DDR4 2400MHz (128 GB total)\n LSI MegaRAID 9271-8i\n Asus 2080 Ti Geforce 11 GB\n IcyDock 3-in-2 (supports 3 hard drives)\n IcyDock 5-in-3 (supports 5 hard drives)\n 18 x 16 TB Exos \n 8 x 16 TB via RAID 0 Array #1 (main boot drive & primary storage)\n 8 x 16 TB via RAID 0 Array #2 (secondary storage)\n 2 x 16 TB via RAID 0 Array #3 (tertiary & temporary storage)\n \n  \nhttps://preview.redd.it/h7gm8rl7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=89a63eafb0c7706ab4389ba0a6c591547c48c2ad\n https://preview.redd.it/wj4xgyl7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=c7d29da0a5819dbd4b19b3674773218f363ca5aa\n https://preview.redd.it/r6b7y0m7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=0aae9f11a52f6704a7a4ed979ac10494a03d9a63\n https://preview.redd.it/l4xx41m7dw5a1.jpg?width=2000&format=pjpg&auto=webp&s=dce2d20a5a2acff95f16a57ce71c8bc2e57d368d\n https://preview.redd.it/p8fwosm7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=2d60d93c7ba751974e912055180a3072be0e374f\n https://preview.redd.it/01wifdm7dw5a1.jpg?width=1500&format=pjpg&auto=webp&s=b95ffe69c15b28f7104ec969d9e1515ae2670d6c\n    submitted by    /u/DeafAccessibility  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlwlcn/rate_my_fugly_storage_setup_raw_288_tb/",
          "publishedOn": "2022-12-14T17:16:39.000Z",
          "wordCount": 17251,
          "title": "Rate my fugly storage setup (raw 288 TB)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlwesd/crystaldisk_info_not_detecting_any_drives/",
          "author": null,
          "description": "Hi everyone, As the title says, suddenly CrystalDisk Info does not detect any drives (not even the C drive). It shows Drive not detected. Could a recent powerloss or a Windows update have caused the issue? All the drives work fine actually.\n    submitted by    /u/terminasitor24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlwesd/crystaldisk_info_not_detecting_any_drives/",
          "publishedOn": "2022-12-14T17:09:30.000Z",
          "wordCount": 15819,
          "title": "CrystalDisk Info not detecting any drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlv7t8/file_naming_for_artwork_kodi_plex_and_jellifin/",
          "author": null,
          "description": "Hello, as far as I know Kodi uses this naming scheme for covers:\n + Name of Movie (YEAR) - Name of Movie (YEAR).mp4 - Name of Movie (YEAR)-poster.jpg \n https://kodi.wiki/view/Movie_artwork#Local_Artwork\n I'm wondering what \"poster\" is. Is it the front cover of the DVD case? like this https://i.ebayimg.com/images/g/e8EAAMXQAx9RN3Lq/s-l500.jpg ? I'm asking because Kodi doesn't use \"cover.jpg.\"\n Also do you prefer the naming scheme above or you just use \"cover.jpg\", like so:\n + Name of Movie (YEAR) - Name of Movie (YEAR).mp4 - cover.jpg \n    submitted by    /u/zoliky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlv7t8/file_naming_for_artwork_kodi_plex_and_jellifin/",
          "publishedOn": "2022-12-14T16:21:17.000Z",
          "wordCount": 18300,
          "title": "File naming for artwork. Kodi, Plex, and Jellifin.",
          "imageUrl": "https://external-preview.redd.it/qVq41jZ9CFuaITfKsY22BNLEY6Eh8ooaHLLzMG8T1Ss.jpg?auto=webp&v=enabled&s=9c2ce1702df42ca5feed11aa3613b99b12d39e5f"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlu1sr/how_to_download_all_files_from_a_website_linux/",
          "author": null,
          "description": "I found a website with a lot of “.pdf.gz” “.py” “.cvs” “.webp” and a lot more different file types That i want to keep offline\n Iknow (a little)$wget $curl $httrack They give me after download an offline webpage mirror were none of the files are downloaded.. just a bluetext that isn’t referring to anything\n How do i, best way, download all this without manually clicking everything\n Also saw kiwix mentioned a view times on this r/ but would like it more to download it myself and so being able to put it on hdd or something\n    submitted by    /u/reditje  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlu1sr/how_to_download_all_files_from_a_website_linux/",
          "publishedOn": "2022-12-14T15:33:55.000Z",
          "wordCount": 16708,
          "title": "How to download all files from a website? (Linux)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zltyb6/need_advice_for_new_nas_drive/",
          "author": null,
          "description": "Hi, I'm looking for a huge drive (12TB+) and came across Seagate Exos which seem to be cheaper than WD Reds, however, I wanted to have 5400 RPM. Currently I have WD Red Plus (4TB) and it's quite silent.\n What's the best drive I can find regarding power consumption + silent and preferably 5400 RPM for 12TB+?\n Thanks!\n    submitted by    /u/RuivoM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zltyb6/need_advice_for_new_nas_drive/",
          "publishedOn": "2022-12-14T15:30:04.000Z",
          "wordCount": 18109,
          "title": "Need advice for new NAS drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlt2ew/trains_and_hard_drives/",
          "author": null,
          "description": "Hey. So I just moved into a new place and I'm close enough to some railroad tracks that the entire house vibrates occasionally when a train goes by. How is this going to affect the two 18TB platter drives in my server?\n Thanks.\n    submitted by    /u/Huecuva  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlt2ew/trains_and_hard_drives/",
          "publishedOn": "2022-12-14T14:55:31.000Z",
          "wordCount": 17780,
          "title": "Trains and hard drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlrw0l/since_2018_the_total_volume_of_data_across_the/",
          "author": null,
          "description": "submitted by    /u/yourdp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlrw0l/since_2018_the_total_volume_of_data_across_the/",
          "publishedOn": "2022-12-14T14:08:47.000Z",
          "wordCount": 17644,
          "title": "Since 2018, the total volume of data across the world has nearly doubled in size every two yrs; it currently sits at ~94T gigabytes and is projected to reach 175T by 2025",
          "imageUrl": "https://external-preview.redd.it/UyPlvt-4ueMd5L2HwRHfpzK_7wzIDZHZzt6HY_ELgnQ.jpg?auto=webp&v=enabled&s=877db3e109f769e922c2cec01a73cbf24c97f6ad"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlc8bz/backblaze_expects_001_per_gb_hds_by_2025/",
          "author": null,
          "description": "https://www.tomshardware.com/news/backblaze-expects-one-cent-per-gb-hdds-by-2025\n ​\n Let's hope inflation, crypto, wars, and mother nature don't interfere with this prediction.\n    submitted by    /u/wbs3333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlc8bz/backblaze_expects_001_per_gb_hds_by_2025/",
          "publishedOn": "2022-12-14T00:34:54.000Z",
          "wordCount": 17874,
          "title": "Backblaze Expects $0.01 per GB HDs by 2025",
          "imageUrl": "https://external-preview.redd.it/BrJKiUC6_NdpNa7rDiEX0UOCCOyac2z4fxB0ZliO5ko.jpg?auto=webp&v=enabled&s=a581ae7e1f8711a67dbed39fec91a03b26d7feca"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlc3qs/apologies_for_any_mistakes_im_quite_new_to_this/",
          "author": null,
          "description": "submitted by    /u/Riley79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlc3qs/apologies_for_any_mistakes_im_quite_new_to_this/",
          "publishedOn": "2022-12-14T00:29:32.000Z",
          "wordCount": 17051,
          "title": "Apologies for any mistakes, im quite new to this, my power went out and when my pc came back on I noticed my hard drive was a lot louder so I checked Crystal Disk Info and saw this, is this something to be concerned about and I should start backing up?",
          "imageUrl": "https://preview.redd.it/evvlk97adr5a1.png?auto=webp&s=8f8e38ed362c5c74086af52495e753d2557c4680"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zlaq5d/mycloud_alternative_remote_access/",
          "author": null,
          "description": "I work for a small business that uses MyCloud for our in-office network; can anyone suggest an alternative for our network that also allows remote access? I'm not especially good with computers or anything like that, so I'm hoping for something that will be relatively easy to implement and that doesn't require me to set up a VPN or anything. Hope this is the right subreddit!\n    submitted by    /u/normopathy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zlaq5d/mycloud_alternative_remote_access/",
          "publishedOn": "2022-12-13T23:32:00.000Z",
          "wordCount": 17282,
          "title": "MyCloud Alternative - remote access?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl9m7h/reliability_in_the_long_run_possibly_a_noob/",
          "author": null,
          "description": "Hey all, long time, first time.\n I built a new NAS a couple of months ago with a i3-10100 CPU @ 3.60GHz (Gigabyte B560M) and a number of WD Red HDDs based on TrueNAS Scale. It's fast and quiet, and really does everything that I could need it for.\n However, I also have a Synology DS920+ on the way from a friend who got a newer 923 from his work. He's only had the 920 for about 6 months. Knowing what I know about Syno, it'll also do the trick.\n My question is this: which one will last longer? Which is a better value proposition for things like Plex, the 'arr suite, and simple Time Machine/cold storage?\n I'm a little worried that what is essentially a gaming motherboard is going to wear out at a certain point, but I'm calling on all of your years experience: go with the DIY solution for the long run, or trust in the Syno, which I've seen people running for 8 years or so?\n    submitted by    /u/chinomage83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl9m7h/reliability_in_the_long_run_possibly_a_noob/",
          "publishedOn": "2022-12-13T22:48:35.000Z",
          "wordCount": 18442,
          "title": "Reliability In The Long Run (possibly a noob question)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl8v24/hosting_a_website_with_dozens_of_terabytes_of/",
          "author": null,
          "description": "I asked this in /r/webdev and they suggested you folks could help me more:\n I have a niche website that currently has about a dozen TB of storage. As the website has started to grow, the data has started to become an issue....the hard drive I use to hold the files is no longer going to be able to hold it all. I'm estimating the storage will be 25-50TB, with about 50-100GB in daily bandwidth, at a minimum. So I need solutions with unlimited traffic.\n I am cheap, so using cloud providers like Azure, AWS is not really an option. I have noticed that Hetzner has cheap servers, with large hard drives (and empty slots for future growth). The issue I now see is the practical question of...how do I merge the hard drives while maintaining some level of protection against disk failure? If I have 3 HD…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl8v24/hosting_a_website_with_dozens_of_terabytes_of/",
          "publishedOn": "2022-12-13T22:19:23.000Z",
          "wordCount": 18215,
          "title": "Hosting a website with dozens of terabytes of storage. how to keep the data safe for cheap. how to pool the multiple disks, or other options available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl8c02/optane_memory_buy_now_for_a_later_zfs_build/",
          "author": null,
          "description": "Intel is discontinuing Optane memory, and there are some good deals to be had on smaller Optane M.2. modules. I saw a YouTube video that says Optane modules are great for ZFS metadata storage.\n I don't have a ZFS server, but plan to build a modest one sometime in the future - so should I grab some Optane modules now before they are gone for good?\n Background: Optane solid state memory is great for write caching because unlike standard SSD storage it really won't wear out in any reasonable amount of time.\n    submitted by    /u/CarlGustav2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl8c02/optane_memory_buy_now_for_a_later_zfs_build/",
          "publishedOn": "2022-12-13T21:59:29.000Z",
          "wordCount": 18153,
          "title": "Optane memory - buy now for a later ZFS build?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl65th/download_all_of_my_icloud_photos_with_metadata/",
          "author": null,
          "description": "Hi all,\n I recently asked about downloading iCloud photos - You can find my post here.\n As I am now using gimme-iphoto for regularly downloading all of my photos, I found that there's certain metadata missing from certain files... What I found missing:\n  \nAny geolocation data - missing from any photo or video\n Date taken - missing from any screenshot or imported picture\n  \nI have also tried using a Mac and exporting the photos (by hand), but this information is also missing, whereas if I look at the photos' info boxes, even screenshots have dates attached to them.\n Is there any solution to download / export the files with this missing data?\n    submitted by    /u/KRider92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl65th/download_all_of_my_icloud_photos_with_metadata/",
          "publishedOn": "2022-12-13T20:35:17.000Z",
          "wordCount": 18734,
          "title": "Download all of my iCloud photos with metadata",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl4dpj/raspi_network_idea/",
          "author": null,
          "description": "Looking for feedback and possible issues with this idea. For this case example there’s 3 raspberry pi all connected to a 1tb ssd with a stable internet connection.\n Mount each raspberry pi onto eachother via an rclone sftp mount.\n on each raspi settup jellyfin to read from the remote raspi drives and their own local drive.\n Now each raspberry pi is connected to eachother and each person with a raspberry pi can play media from it.\n But now let’s say I would want to add a 4th raspi remotely. Since each person lives separately what would be a good way to make it to auto-connect a 4th raspi?\n    submitted by    /u/BitterSweetcandyshop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl4dpj/raspi_network_idea/",
          "publishedOn": "2022-12-13T19:24:45.000Z",
          "wordCount": 17907,
          "title": "Raspi Network Idea",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl31gw/need_help_identifying_the_right_power_cable_to/",
          "author": null,
          "description": "What type of power cable is this? Thanks.\n    submitted by    /u/chufenschmirtz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl31gw/need_help_identifying_the_right_power_cable_to/",
          "publishedOn": "2022-12-13T18:32:10.000Z",
          "wordCount": 18586,
          "title": "Need help identifying the right power cable to buy for a long lost hard drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl2tsh/using_a_pixel_1_for_another_backup_location_of/",
          "author": null,
          "description": "Just wondering if anyone else is using this method. I just got my Pixel 1 in from ebay.\n I plan to keep and host all family videos / photos on my server, and have backups on and off site of that server. \n Planning on using something like syncthing to get pics from our phones to the pixel, and then from the pixel to our \"family\" google account.\n Questions:\n  \nWhat is the best way to get pictures from our phones (android and iphone) to my server? Syncthing? Some other app im not thinking of?\n \nIs it really unlimited full res for the life of the phone? I used the \"reduced quality\" for a long time and was never disappointed with the quality of the pictures saved - should I just use that to not piss google off?\n \nAny other tips to get this to work flawlessly? (auto delete from phone after it uploads to google, etc)\n \n    submitted by    /u/bringo24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl2tsh/using_a_pixel_1_for_another_backup_location_of/",
          "publishedOn": "2022-12-13T18:23:49.000Z",
          "wordCount": 17601,
          "title": "Using a Pixel 1 for another backup location of pictures/videos - advice needed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl1vp5/amazon_hdd_not_packed_very_well_tests_fine/",
          "author": null,
          "description": "So I got one of those BF deals for a big external HDD. Inside the outer Amazon box was the inner manufacturer box, but that was actually loose inside of the outer box. HDD itself seemed well packed / protected inside of the Manufacturer box though. \n I documented the way it arrived and ran the an extended SMART driver test using the Manufacturer's utility. Took a couple of days due to size of the drive, but passed with no issues. Ran a few short tests with the same results. \n So my question for my fellow Datahorders is what would you do? Return the drive and hope replacement is packed better or be satisfied with inner box protection + testing? Just curious.\n    submitted by    /u/robbiejay86  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl1vp5/amazon_hdd_not_packed_very_well_tests_fine/",
          "publishedOn": "2022-12-13T17:47:50.000Z",
          "wordCount": 18132,
          "title": "Amazon HDD not packed very well - tests fine - sketchy or no?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl11q3/same_files_take_up_more_space_on_a_different/",
          "author": null,
          "description": "So this may be really basic stuff to some of you but I'm just trying to wrap my head around this..\n I have a music library that measures 59.7gb on my windows 10 laptop SSD. When I have transferred my library to my android phone it suddenly measures 63.97gb (when viewed via the phone's file explorer) and 59.8gb (when the phone is connected by usb and viewed via windows file explorer).\n ​\n Is this normal? Is it just due to differences in the filesystem or formatting or something? I tried searching around a little but I'm struggling to find a solid answer on this and would appreciate some assistance.\n ​\n thankya\n EDIT: appreciate the answers folks. thankyou!\n    submitted by    /u/layzeelightnin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl11q3/same_files_take_up_more_space_on_a_different/",
          "publishedOn": "2022-12-13T17:15:43.000Z",
          "wordCount": 18422,
          "title": "Same files take up more space on a different device?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl0x1o/how_to_scale_from_a_mitx_8bay_setup_silverstone/",
          "author": null,
          "description": "Hello all.\n ​\n I have a NAS in a SilverStone DS380 (8-hotswap bay) along with some external USB 3.0 disk enclosures, making a total of 12x10TB but the pool is starting to get full and I am thinking of adding 4x20TB in short-term (Q1 2023) getting to 12x20TB in the mid-term (Q4 2024).\n ​\n SilverStone DS380 8-bay\n I do not have space for jumping to a rack solution (which is always on my mind and I will do for sure once i move home) so I need to stick in the meantime with tower-based NAS/DAS solutions. The ideal case would be the 12-bay Synology model of the pic, with the possibility to daisy-chain another 12-bay model to it, but I cannot ID it or find a non-rack alternative.\n ​\n ​\n Synology DS 12-bay\n ​\n Basically, I am trying to find a tower-size 8-bay (minimum) to 12-bay (preferable) DAS (no need to be hot-swap) with USB connection to attach it to my DS380 NAS until I move to a real rack solution (early 2025). \n ​\n I have found some solutions from Orico, Mediasonic, Fantec, OWC, Sabrent... but I read a lot of connectionand cooling issues from this solutions I need to avoid as my system is on 24/7 as a backup and media server to 4 users. Plus I find them too overpriced for just a steel case with trayless bays ($50?), 150w low-efficiency PSU ($30?) and a bunch of SATA to USB adapters ($15?).\n ​\n ​\n Mediasonic 8-bay\n ​\n The best option I manage is another DS380 as a JBOD DAS, with a 300W gold SFX PSU, a pair of SSF-8088 connectors and SFF-8087 cables, but I would need to adress the dual-PSU synchronism with a Supermicro JBOD power control board for example and I would need to buy a JBOD card on my main system with external SSF-8088 connectors.\n ​\n Any thoughts on this? I live in Europe so the available solutions may be reduced.\n ​\n Thanks in advance.\n    submitted by    /u/jfromeo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl0x1o/how_to_scale_from_a_mitx_8bay_setup_silverstone/",
          "publishedOn": "2022-12-13T17:10:48.000Z",
          "wordCount": 18030,
          "title": "How to scale from a mITX 8-bay setup (SilverStone DS380)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zl0acu/telegram_scraper_help/",
          "author": null,
          "description": "Does any one know a tool to scrap users from telegram groups and add them to your preferred group\n    submitted by    /u/Big-Initiative-2030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zl0acu/telegram_scraper_help/",
          "publishedOn": "2022-12-13T16:46:34.000Z",
          "wordCount": 17942,
          "title": "Telegram scraper help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkz6py/is_anyone_else_having_issues_downloading_from/",
          "author": null,
          "description": "Everything is up to date and authorized, cookies and cache has been cleared, etc. \n We get this error - https://i.imgur.com/KVZEwfW.png when getting a .acsm from archive.org and trying to download/view via Adobe Digital Editions. \n Anyone else having this issue?\n    submitted by    /u/QuestPirate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkz6py/is_anyone_else_having_issues_downloading_from/",
          "publishedOn": "2022-12-13T16:03:29.000Z",
          "wordCount": 17027,
          "title": "Is anyone else having issues downloading from archive.org? Since this morning, we've been getting an error in Adobe Digital Editions that prevents download.",
          "imageUrl": "https://external-preview.redd.it/r_T9gs_zFLqBSGoM1rz1nvBsfEYOeONQfkG-8f2IRDQ.png?auto=webp&v=enabled&s=34dea8060d311f4ec5a5de86fb78b28af8af2864"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkz0qj/read_error_rate_is_marked_as_red_and_ive_been/",
          "author": null,
          "description": "submitted by    /u/V0idH3art  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkz0qj/read_error_rate_is_marked_as_red_and_ive_been/",
          "publishedOn": "2022-12-13T15:55:51.000Z",
          "wordCount": 18496,
          "title": "Read Error Rate is marked as Red, and i've been facing difficulty to run operations on this HDD. Any suggestions?",
          "imageUrl": "https://preview.redd.it/7pgy7i0bto5a1.png?auto=webp&s=560a325243b9d2aff11bc020090caa29ef2ab31a"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkw4y6/wd_14tb_easystore_for_19999_1429_tb_at_best_buy/",
          "author": null,
          "description": "submitted by    /u/unsuspectingcueball  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkw4y6/wd_14tb_easystore_for_19999_1429_tb_at_best_buy/",
          "publishedOn": "2022-12-13T13:46:37.000Z",
          "wordCount": 19605,
          "title": "WD 14TB Easystore for 199.99 ($14.29 / TB) at Best Buy and BestBuy eBay Store. Ends 11:59PM Dec 13th",
          "imageUrl": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?auto=webp&v=enabled&s=9b56c069465770cc70354fba8fa2c16490cd485e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkvvsn/plugin_or_tool_to_ping_google_services_affected/",
          "author": null,
          "description": "Hi all,\n As you know Google will start to delete files on in-active accounts starting from January 2023. I was wondering if there is a tool that can login to the account and do some activity so the 2 year policy resets? A simple one to ping the google services like gdrive gmail or other g services so that the inactivity timer resets?\n https://support.google.com/googleone/answer/10214036#activity \n A plugin or a tool that can create and delete a folder on gdrive every 30 days and keeps a track record for example will do the magic I think.\n Thank you\n    submitted by    /u/Jolly-Caramel233  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkvvsn/plugin_or_tool_to_ping_google_services_affected/",
          "publishedOn": "2022-12-13T13:33:50.000Z",
          "wordCount": 17349,
          "title": "Plug-in or tool to ping Google services affected by 2 years inactivity policy by Google.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkvovh/i_want_a_hard_drive_thats_netflix_like_but_does/",
          "author": null,
          "description": "So I was staying at my uncles place, he's in pretty ruff shape was really sick can't leave the house much he's got a shit bag. So he's basically broke but he let us stay at his place for our grandpa's funeral, he doesn't have internet basically has a big stack of DVDs and some Japanese Chanel.\n So basically I want to buy him a hard drive or computer, upload as much as I can fit on it. Then have it set so he can just plug it in, plug an HDMI. If anyone knows what my best route would be I haven't downloaded a torrent in a few years so any tips would help. Thanks\n    submitted by    /u/Pure-Cartographer230  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkvovh/i_want_a_hard_drive_thats_netflix_like_but_does/",
          "publishedOn": "2022-12-13T13:24:41.000Z",
          "wordCount": 19741,
          "title": "I want a hard drive that's Netflix like but does need to be connected to the internet.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkvkik/unreliable_hardware_and_the_false_sense_of/",
          "author": null,
          "description": "Let me spin you a tale as old as time about a man and his data. Hopefully, you can learn that without a solid main setup, even backups cannot save you. \n The story starts in 2016 when I bought my first RAID controller and drives to build my first storage server. Being of young age and with limited means, I opted to cheap out on the controller and buy the (as I later figured out) awful HighPoint Rocketraid 840A, then going for about $300. Compared with an LSI card with 16 ports, that was approximately a third of the price when buying new (Stupid me didn't even consider buying used). Of course, it later turns out that the hardware RAID6 capabilities I bought the card for are not even present, but that is another story for another day. \n So I set up a volume in the card's BIOS, and install so…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkvkik/unreliable_hardware_and_the_false_sense_of/",
          "publishedOn": "2022-12-13T13:18:45.000Z",
          "wordCount": 20792,
          "title": "Unreliable hardware and the false sense of security of backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zktf4k/is_this_normal_92_tb_total_nand_writes_on_a/",
          "author": null,
          "description": "submitted by    /u/Interesting_Sink_254  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zktf4k/is_this_normal_92_tb_total_nand_writes_on_a/",
          "publishedOn": "2022-12-13T11:26:12.000Z",
          "wordCount": 18379,
          "title": "is this normal? 92 TB total NAND writes on a month-old WD Blue SSD",
          "imageUrl": "https://preview.redd.it/7y024rg2zo5a1.png?auto=webp&v=enabled&s=60e62ecde22031a4af4b197504436f74f6ce81b1"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkt9hc/how_to_download_an_entire_wiki/",
          "author": null,
          "description": "I'd like to download the entire SCP wiki so I can browse it offline, but WITHOUT download the comment sections. Is there a software that can do this? How would I limit the software to only download this wiki and any pages closely related to it, without following any possible links to other wikis and downloading those?\n    submitted by    /u/Voldy256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkt9hc/how_to_download_an_entire_wiki/",
          "publishedOn": "2022-12-13T11:17:23.000Z",
          "wordCount": 17603,
          "title": "How to download an entire wiki?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkt3gu/what_nas_to_buy_budget_800/",
          "author": null,
          "description": "Hello all,\n on recommandation of : u/halbzu\n I will post my question here.\n Hello niece and nephews, its testlab01 with a new question and advise needed.\n I want to buy as in the TS says an NAS. a 4bay nas to have it in RAID-5 for fail over. The reason for this is because we are running out of cloud storage on my device as my families devices. Google etc, and when i want to expand the cloud storage i need to pay a lot for something what is not mines. And if i dont pay anymore i still need to store all the files to something local. So in this case an NAS would be the best solution.\n So i know only two brands Synology the number(1) famous NAS brand, and QNAP what is more for professionals i think. My preference self goes to Synology because the software DSM.\n But i am still not really convinced which one to buy. In my shopping cart (eBay) i have added DS920+ and 4x 2tb IronWolf ST4000VN006 in total i will have 12TB of storage with fail over of 1 disk of 4tb.\n In the meantime 923+ came out in November 2022 and is a upgrade compared to the ds920+Pro\"s- 2.5gbps Ethernet port.- upgrade to 16gb ram, not official only upgrade to 8gb with an extra so-dimm 4GB.- new CPU AMD this time (but no GPU processing power, so PLEX will not be the great solution)- now you can have nvme storage pools.\n I am not a big watcher because of work (not that much time) but it would be always good when i have time to watch something without problems.\n My budget is about 800€ less is always better, i have a voucher of 300€ discount so from 966€ will be like 699€ what a good price is for NAS + storage 16GB.\n still to take the 923+ that one is more expensive as well. But getting longer updates as well, or to stay with the 920+ + or even a QNAP to take?\n building a NAS etc, will not be the choice because it will never give you all the bells an whisels what you get with an NAS.\n    submitted by    /u/testlab01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkt3gu/what_nas_to_buy_budget_800/",
          "publishedOn": "2022-12-13T11:07:28.000Z",
          "wordCount": 18686,
          "title": "What NAS to buy? Budget 800€",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkeoig/iso_backups_of_scene_it_discs/",
          "author": null,
          "description": "I used DVDFab to try and backup my Nick scene it dvd and i noticed it ripped extremely quickly. It even says its a large file like a dvd iso should be. Upon booting the iso file the intro screens worked fine but when i select play game it either crashes the video player, or restarts the iso from the start. \n It seems most of the disc doesn’t copy as it should at all, and i cant find any information online on how to fully rip these interactive dvd games. Any ideas?\n    submitted by    /u/Slonkweed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkeoig/iso_backups_of_scene_it_discs/",
          "publishedOn": "2022-12-12T23:00:19.000Z",
          "wordCount": 16427,
          "title": "Iso backups of “scene it?” Discs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zke3o5/western_digital_rma_help_red_pro_nas/",
          "author": null,
          "description": "Hello, I generally lurk and rarely posts here.\n ​\n I saw the Western Digital sale post during Black Friday for the Red Pro NAS drives so I jumped on the chance. Bought 2, and then realized I needed more so bought 2 more. The first 2 drives came perfectly fine, passed SMART and had no problems with stress tests. \n The second batch had huge problems. One, they delivered only ONE drive instead of the two I ordered. Next, the one drive that did arrive was dead on arrival. SMART wasn't even working when I plugged it in. So I tried RMAing it, but that requires registering it. So I tried registering the drive and lo and behold, I get\n \"Sorry! Product registration failed, please try later. (STATCODE108)\" \n Customer support is just running me around the ringer. They keep promising me updates with no updates given after their promised deadline of \"24-48 hours.\" I have gone through both their chat system, garnering me the generic\n (\"Please allow me to inform you that your issue has already been forwarde to our team and they are looking iinto the issue.\")\n and calls - what else can I do? \n I registered the previous 2 drives just fine. All drives were bought directly from the WD online store.\n    submitted by    /u/RockyX123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zke3o5/western_digital_rma_help_red_pro_nas/",
          "publishedOn": "2022-12-12T22:38:57.000Z",
          "wordCount": 2028,
          "title": "Western Digital RMA Help - Red PRO NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkdqq7/a_datahoarding_attempt_that_has_proven_to_be/",
          "author": null,
          "description": "My apologies if this topic does not belong to this group, but I ran out of options and this is my last resource. \n There is in BBC Sounds a podcast called Night Tracks. Each episode is a beautiful collection of classical and rare experimental music. The episodes are only available for certain amount of time and then they are removed from the website. \n I want to collect every single episode but I haven't found any way to download them. I've tried with multiple ad-ons, extensions, and software but it is just imposible. \n Perhaps someone here knows a way. I would deeply appreciate any help.\n    submitted by    /u/Melancholic-Beast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkdqq7/a_datahoarding_attempt_that_has_proven_to_be/",
          "publishedOn": "2022-12-12T22:26:30.000Z",
          "wordCount": 16274,
          "title": "A datahoarding attempt that has proven to be almost impossible",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkcprp/i_cant_copy_a_particular_file_from_dvd/",
          "author": null,
          "description": "first: i didnt grow up with dvds so im a noob.\n i'm trying to rip a video from DVD. but all of the dvd ripping softwares i've tried gave error at exactly 40th minute of the video. i think its becouse VTS_013.VOB file. so i copied other files with DVD Decrypter and skipped VTS_013.VOB to manually copy it with file explorer. but it also gave error. i can run VTS_013.VOB with vlc no issues.\n ​\n ​\n ​\n [00:58:00] hb_init: starting libhb thread # Starting Scan ... [00:58:00] CPU: [00:58:00] - logical processor count: 8 [00:58:00] Intel Quick Sync Video support: no [00:58:00] hb_scan: path=D:\\VIDEO_TS\\VTS_01_3.VOB, title_index=0 udfread ERROR: ECMA 167 Volume Recognition failed src/libbluray/disc/disc.c:333: failed opening UDF image D:\\VIDEO_TS\\VTS_01_3.VOB src/libbluray/disc/disc.c:437: error op…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkcprp/i_cant_copy_a_particular_file_from_dvd/",
          "publishedOn": "2022-12-12T21:50:38.000Z",
          "wordCount": 15902,
          "title": "i cant copy a particular file from DVD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkc7jv/just_accidentally_nuked_90_of_my_video_library/",
          "author": null,
          "description": "submitted by    /u/randombystander3001  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkc7jv/just_accidentally_nuked_90_of_my_video_library/",
          "publishedOn": "2022-12-12T21:32:37.000Z",
          "wordCount": 18144,
          "title": "Just accidentally nuked ~90% of my video library",
          "imageUrl": "https://preview.redd.it/guh9oj5gaj5a1.png?auto=webp&s=8d4162e08a0eb95f5808b839c879287c8e88657b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkbvih/turkish_movies_which_are_hard_to_find_on_torrent/",
          "author": null,
          "description": "submitted by    /u/Sacrer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkbvih/turkish_movies_which_are_hard_to_find_on_torrent/",
          "publishedOn": "2022-12-12T21:20:33.000Z",
          "wordCount": 19521,
          "title": "Turkish movies which are hard to find on torrent are being uploaded with English subtitles to Youtube. Go ahead and back them up.",
          "imageUrl": "https://external-preview.redd.it/ru_AMlstSs-CGi-1_U-UXoek4nQGAg_xK8luucv6hFc.jpg?auto=webp&s=bd24de6703c0cea3f6934e6e3e87ec331933771a"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkbhrv/used_samsung_evo_860_4tb_ssd_buy_or_no/",
          "author": null,
          "description": "I have the opportunity to bulk buy these disks for about $40 a piece. I presume they have been used extensively but have no way to check them before buying. They do guarantee all of them are in working condition. Is this a good deal or is it best to avoid used SSDs like this?\n    submitted by    /u/pain_vin_boursin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkbhrv/used_samsung_evo_860_4tb_ssd_buy_or_no/",
          "publishedOn": "2022-12-12T21:07:02.000Z",
          "wordCount": 16180,
          "title": "Used Samsung EVO 860 4TB SSD - buy or no?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zkaexa/synology_nfs41_netshare_headaches/",
          "author": null,
          "description": "Hello data hoarders please spread some knowledge\n I thought I'd burn all my saved up cash during a recession and got myself a decent starter NAS - DS720+, which had some \"new\", read; suspectedly S.M.A.R.T wiped disks from 2014, included.\n My idea was to run my current linux.iso server with the NAS mounted in NFS4.1 and just smack all the sweet linux iso's right onto there.\n Quickly realized I'm getting bottlenecked bigtime, despite running the newest storage tech in RAID 0 for double the speed etc (I kid, don't hurt me). I know Raid0 is stupid but I'll take any performance wins as this will only host data I don't care about losing - not much of a data hoarder, eh.\n Anyways I'm getting cache overloaded to infinity and beyond.\n With some linux.iso testing I did manage to max my gigabit line …",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zkaexa/synology_nfs41_netshare_headaches/",
          "publishedOn": "2022-12-12T20:28:36.000Z",
          "wordCount": 18995,
          "title": "Synology NFS4.1 NetShare headaches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zka5fj/wdd_max_digital_data_thoughts_on_increasing/",
          "author": null,
          "description": "https://www.amazon.com/dp/B0BGYV6B9V?psc=1\n A non-\"renewed\" disk drive at a reasonable price! I'm completely unfamiliar with the company however, are these bad signs? Do you guys have any thoughts on this company or this disk in particular? Any recommendations for me? I've been looking on diskprices.com and I'm kind of hung up on buying new/renewed, more drives, lower storage OR less drives, higher storage each... I'm looking to increase my storage capacity for my main rig PC, it's only got a 1TB NVME and an external USB HDD with 4TB. My goal is to hoard the entire Z-Library archive (23TB) and to maybe host my own cloud storage, but until then I'll just piece it together one at a time until a drive fills up or my PC runs out of space. inb4 read the wiki thank you thank you\n    submitted by    /u/Goberoberto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zka5fj/wdd_max_digital_data_thoughts_on_increasing/",
          "publishedOn": "2022-12-12T20:18:56.000Z",
          "wordCount": 17483,
          "title": "WDD (Max Digital Data?) Thoughts on increasing storage for main rig PC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zka49j/data_recovery/",
          "author": null,
          "description": "If an SSD has been formatted can data still be covered from the drive and if so what free software can i use to try and retrieve the data ?\n    submitted by    /u/CumsockFinder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zka49j/data_recovery/",
          "publishedOn": "2022-12-12T20:17:41.000Z",
          "wordCount": 13301,
          "title": "Data recovery",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk98yu/simple_and_comprehensive_approach_to_youtube/",
          "author": null,
          "description": "Hey all, apologies for asking a question I know has been asked a million times. In fact I saw what I'm pretty sure was the answer to my Q a couple weeks ago but have searched and searched and unfortunately can't find it again (shoulda archived it, heh.)\n I'm just starting to become a datahoarder and picked up a Synology NAS. My main motivation was the huge collection of tutorials and other knowledge I've saved on YouTube that may up and disappear one day.\n First Goal: I'm looking for really simple no-code (or very low code - I code all day long, and don't want to have to write/maintain a bunch of this stuff too) way to automatically archive anything I add to a specific YouTube playlist to my Synology NAS. I'd ideally like it to save thumbnails and descriptions as well.\n Second Goal: Some sort of easy interface for browsing, searching, and watching those archived videos, so I'm not just using crummy Windows search to try and find a video in the future.\n Does anyone have suggestions that can address 1 or 2, or both?\n Thanks in advance!\n    submitted by    /u/turn-down-for-what  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk98yu/simple_and_comprehensive_approach_to_youtube/",
          "publishedOn": "2022-12-12T19:45:56.000Z",
          "wordCount": 18202,
          "title": "Simple and comprehensive approach to YouTube archiving + browsing/searching?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk7y1j/any_dedicated_pcie_40_nvme_quad_adapters/",
          "author": null,
          "description": "Looking for something dedicated but less expensive like this for my Windows PC, don't need to have Raid:\n https://eshop.macsales.com/item/OWC/SSDACL4M208T/#customer-reviews\n Thanks!\n    submitted by    /u/MarkGeraz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk7y1j/any_dedicated_pcie_40_nvme_quad_adapters/",
          "publishedOn": "2022-12-12T18:59:25.000Z",
          "wordCount": 17240,
          "title": "Any dedicated PCIe 4.0 NVMe quad adapters?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk7un4/quick_way_to_grab_direct_links_for_discord_uploads/",
          "author": null,
          "description": "i've been using a dead discord channel for random occasional file uploads for like a year, and would like to back them up. anybody know how I could extract the direct attachment urls from the entire channel without manual labor?\n thank\n    submitted by    /u/pbdrizz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk7un4/quick_way_to_grab_direct_links_for_discord_uploads/",
          "publishedOn": "2022-12-12T18:55:54.000Z",
          "wordCount": 16244,
          "title": "quick way to grab direct links for discord uploads?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk7hm7/i_need_help_with_my_first_backup_of_everything/",
          "author": null,
          "description": "So I just bought a ULTRASTAR DC HC310 4TB to use for a backup of everything that's important to me and I'm looking for advices and tips on how to store it.\n I did read different opinions... Someone say to store it powered off in an antistatic bag and wrapped in pluriball. Others instead say that having it powered off corrupt faster the data and also the lubricant on the moving parts dries out so that when you power it on again it will put the drive under extreme friction.\n I have not enough knowledge about this to take a decision on my own so I'm here asking for help. \n Also any other advice will be welcome (such as what to choose when formatting it or anything else that I might not know)\n Thank you to everyone who will help me !\n    submitted by    /u/Cris257  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk7hm7/i_need_help_with_my_first_backup_of_everything/",
          "publishedOn": "2022-12-12T18:43:42.000Z",
          "wordCount": 18621,
          "title": "I need help with my first backup of everything that's important to me",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk7aa0/huge_thanks_to_seagate_and_useagate_surfer_for/",
          "author": null,
          "description": "submitted by    /u/Clawz114  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk7aa0/huge_thanks_to_seagate_and_useagate_surfer_for/",
          "publishedOn": "2022-12-12T18:36:49.000Z",
          "wordCount": 16943,
          "title": "Huge thanks to Seagate and u/Seagate_Surfer for running the IronWolf Pro SSD giveaway! It has found a good home and replaced an ancient OCZ relic.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk788r/best_u2_enclosure/",
          "author": null,
          "description": "I am a moron and have some 15.36tb used enterprise ssd's in U.2 format lying around. What's the best case for them? They get kinda hot so I'd like a fan, replaceable ideal so I can swap it with a moctua\n I don't care about throughput that much but I'd like more than 2 drives stored\n    submitted by    /u/Spirited-Guidance-91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk788r/best_u2_enclosure/",
          "publishedOn": "2022-12-12T18:34:42.000Z",
          "wordCount": 16703,
          "title": "Best U.2 enclosure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk77qt/cloud_solution_for_huge_files_that_cannot_be/",
          "author": null,
          "description": "Hi \n I'm trying to find an online backup solution for my veracrypt container that is around 300GB and growing. Ideally, I want a provider that doesn't require you to split the large file in parts. I'm not certain, but my current understanding is that I cannot split up the container into separate parts...\n ​\n I don't need any syncing. I intend on uploading the entire container once per week. \n ​\n Any suggestions would be much appreciated. \n    submitted by    /u/user44566829  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk77qt/cloud_solution_for_huge_files_that_cannot_be/",
          "publishedOn": "2022-12-12T18:34:11.000Z",
          "wordCount": 17056,
          "title": "Cloud solution for huge files that cannot be split up?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk6efk/upgrading_nas/",
          "author": null,
          "description": "Long time lurker first time posting. Also English is not my first Language so please bear with me. I currently have Synology NAS with 2 bays with 2 4TB hard drives. I want to expand because I'm quickly approaching 7TB. I have my previous desktop computer that has about 8 drive bays that I would like to expand over time. I would like to get some opinions from the experts before I begin throwing time and money at this project.\n What OS/software should I use to manage/initialize my NAS? -- so far I have heard of TrueNAS, FreeNAS, ZFS and Unraid. Note:not even sure if I know what i am talking about here or if there are differences i am not aware of.\n Is expanding my \"pools\" for future additional drives going to be an issue? I don't want to be moving around several TB.\n I also read that my drives would have to be matching in size or I won't be able to use the drive to their fullest extent. I was thinking about going to 12-14 TB drives right away but maybe I should by smaller capacity drives to start out? It just seems that in the future my lower capacity drives with hold me back.\n Thoughts about backups - just looking for some suggestions? I read about snapshots but I'm not sure that applies here. I am familiar with the 3-2-1 rule but with the TB amounts of data I have I can't reasonably buy duplicates of all drives just to have 1 to 1 backups (if that makes sense) but maybe there is no way around this.\n I started off my journey with my synology NAS just to see if it would work and now that I have become a little more serious about my data-hoarding I would like a better setup with more storage as well as implement best practices. I see this as the next logical step before I get something that is rack mounted. Let me know all of your thoughts as I am sure I have missed something or have not thought a position through. Thank you for your help!\n    submitted by    /u/TheKingMongo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk6efk/upgrading_nas/",
          "publishedOn": "2022-12-12T18:04:35.000Z",
          "wordCount": 15962,
          "title": "Upgrading NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk6491/made_myself_python_tooling_to_download_threads/",
          "author": null,
          "description": "Hello everyone,\n As I frequently see interesting threads on Reddit, and I want to get them offline to 1) find them again easily, and 2) preserve them in case messages get removed, I made myself some time ago a Python script to \"download\" threads off Reddit.This script does not only download the thread, but generates a nice HTML file, so it can be opened in a browser and the thread navigated around conveniently. Here is an example of such HTML file.\n Recently, I told myself it would be better to have a web frontend for that tooling, since I am sometimes on the go and do not have the script and/or the Python interpreter on my machine.\n This therefore led to RedditArchive, a Flask self-hosted app to archive and download Reddit threads (screenshots available in the README):https://github.com/Ailothaen/RedditArchiver\n You can install it on a small server of yours, such as a Raspberry Pi or a VPS. Installations instructions are provided if you want to try it on.\n If you do not want to deal with the hassle of setting a web server up, worry not! I also made the original script available here:https://github.com/Ailothaen/RedditArchiver-standalone\n Do not hesitate to comment and make suggestions – I have ideas for further features, but that's probably for another time. 🦉\n    submitted by    /u/Ailothaen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk6491/made_myself_python_tooling_to_download_threads/",
          "publishedOn": "2022-12-12T17:55:16.000Z",
          "wordCount": 17527,
          "title": "Made myself Python tooling to download threads off Reddit (available in Web UI and standalone script)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk62zn/who_are_you_by_profession/",
          "author": null,
          "description": "because date hoarding is quite an expensive hobby.\n    submitted by    /u/kovach_ua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk62zn/who_are_you_by_profession/",
          "publishedOn": "2022-12-12T17:54:04.000Z",
          "wordCount": 17753,
          "title": "Who are you by profession?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zk4g75/is_the_write_speed_for_raid_0_normal/",
          "author": null,
          "description": "​\n https://preview.redd.it/57p1d5l0zh5a1.jpg?width=1212&format=pjpg&auto=webp&s=06439c41fe91a67d125fb543db66df7914e6b5fb\n ​\n For background, I am quite new to this. I am a photographer and have been using simple external hard drives to edit and view my photos from. A few months ago, I purchased a 10TB WD Elements desktop hard drive, and the pursuit of having faster read/write speeds (without using SSDs) and joining this subreddit has only heightened that \"passion\" (or addiction?).\n I recently acquired 2x WD Gold 12TB and I have them in the OWC Gemini Dual Thunderbolt 3 enclosure. I have a large amount of photos in which I'd like to use the two drives to store and edit from (I have the appropriate backup system just in case). I would have never thought to go the Raid 0 route but this subred…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zk4g75/is_the_write_speed_for_raid_0_normal/",
          "publishedOn": "2022-12-12T16:54:36.000Z",
          "wordCount": 17433,
          "title": "Is the write speed for Raid 0 normal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjrqpl/new_8tb_wd_easystore_the_drive_seems_to_run_great/",
          "author": null,
          "description": "submitted by    /u/fuckAraZobayan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjrqpl/new_8tb_wd_easystore_the_drive_seems_to_run_great/",
          "publishedOn": "2022-12-12T07:50:00.000Z",
          "wordCount": 18903,
          "title": "New 8TB WD easystore: The drive seems to run great, but what is with this crazy raw value for spin up time?",
          "imageUrl": "https://preview.redd.it/hikmqcl0af5a1.png?auto=webp&s=b7344a0069a08a45d7bc90c303ca545c430b63f5"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjo83r/wd_14tb_elements_desktop_usb_30_external_hard/",
          "author": null,
          "description": "submitted by    /u/buhwhytho  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjo83r/wd_14tb_elements_desktop_usb_30_external_hard/",
          "publishedOn": "2022-12-12T05:18:04.000Z",
          "wordCount": 17431,
          "title": "WD 14TB Elements Desktop USB 3.0 External Hard Drive $209.99 ($379.99-$170.00 for $15/TB",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjhnbn/whats_a_good_standalone_dedicated_nas_to/",
          "author": null,
          "description": "Hi, I am looking for a server that I can use to host and stream <2TB worth of videos, which may later expand to 4TB, but I doubt it may expand over that, these are the types of videos I have want that I want to stream.\n  \none-on-one zoom consultations I've done\n \nripped youtube videos \n \nVideos ripped from online courses I've paid for\n \npersonal recorded videos recorded using my phone\n \n My idea is to have a dedicated media(video) library where I can have it all in one dashboard. Instead of having to open up multiple tabs or files (i.e. youtube, google chrome, etc.). \n I don't want to host these videos on any cloud services (i.e. OneDrive, Google Drive, mega.nz, etc.). For fear thay my files/videos get flagged as copyright and my account suspended.\n I'd also like to have the ability to create embedded video links, to put onto my Personal Knowledge Management System (PKM System), which would most likely be a combination of Notion, OneNote and Nimbus Note.\n I already have a Synology NAS DS218+ that I use for cold storage back-up, but it's not suited to host media. I also don't want to have a NAS were I store sensitive files and at the same time open to the web with media hosting. I want these two things, physically compartmentalized.\n I will be the only dedicated-user of these media files being streamed, so there is no worry of bandwidth, when streaming video files.\n    submitted by    /u/ApolloRising434  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjhnbn/whats_a_good_standalone_dedicated_nas_to/",
          "publishedOn": "2022-12-12T01:12:58.000Z",
          "wordCount": 15893,
          "title": "What's a good stand-alone dedicated NAS to host/stream media?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjhcte/i_am_becoming_a_hoarder/",
          "author": null,
          "description": "submitted by    /u/WhyIsIsTakenTaken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjhcte/i_am_becoming_a_hoarder/",
          "publishedOn": "2022-12-12T01:02:34.000Z",
          "wordCount": 15403,
          "title": "I am becoming a hoarder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjg7g2/sas_drives_not_recognized_in_windows_11/",
          "author": null,
          "description": "A few months ago, I accidentally bought the SAS version of a 16TB Seagate Exos, when I meant to get SATA.\n I knew I was planning a new living room PC soon, and having it double as a NAS, so I kept it. I ordered another 16TB SAS drive and a SAS RAID controller a couple weeks ago to put the new computer together. I want to make a basic RAID 1.\n Windows shows the controller as \"Avago adapter sas3 3008 fury - StorPort\" and says the driver is good, but I don't see any sign of the connected drives, or any UI to set up the controller.\n Are there any good guides for this? Any guides I've found assume SATA drives and either the RAID support on the motherboard or Windows virtual volumes -- and that you can actually see that the drives exist before you get started.\n    submitted by    /u/PstScrpt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjg7g2/sas_drives_not_recognized_in_windows_11/",
          "publishedOn": "2022-12-12T00:23:53.000Z",
          "wordCount": 17620,
          "title": "SAS drives not recognized in Windows 11?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjcsp9/wallhaven_organiser/",
          "author": null,
          "description": "Hi All\n I tend to find myself having weird 'me only' issues when hoarding. Im currently sat at over 1m images, from deviantart, pixiv, pinterest but then i discovered wallhaven.....you can see where this is going.\n Assuming you are using gallery-dl with the '--write-metadata' option to download an ID search or batch of single images it will check the json for the file for the username, create a folder structure and then sort the files for that user to the correct folder.\n it'll then add the user account to a txt file for batch downloading of that users uploads. Eventually, ill no doubt have all the user accounts (if they have uploaded) but i then use this for more downloads.\n As an example, i download all the images tagged for cyberpunk 2077 lets say around 300, this is parsed i then have 90 users ready to go and end up with 100k images after running that list. They state they only have about 1m images themselves so shouldn't take long to get it all then just append to my collection.\n I couldn't find a list of all users, a search all(*) or a list of how many IDs they have. But if you know, let me know. I could have just iterated over IDs in a loop 1 to 999999 but thats possibly a lot of waste.\n Anyway......\n As i say, this fits my need for how i scrape stuff from there but thought id share it should someone want to improve/make use of it. Its powershell btw\n https://pastebin.com/q6JXgTL7\n    submitted by    /u/Obvious-Viking  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjcsp9/wallhaven_organiser/",
          "publishedOn": "2022-12-11T22:39:35.000Z",
          "wordCount": 16248,
          "title": "Wallhaven Organiser",
          "imageUrl": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&s=07c121a0180003f7373863af66192b6ff6a937da"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjbo3e/thinking_of_moving_my_copied_blurays_to_external/",
          "author": null,
          "description": "I have about 250-300 blurays that I have made over time. I do not have originals any longer as I sold them off when Bluray was \"hot\". These are now 5+ years old and worried about bluRay rot.\n 90+% of the blurays are LTH 25gb\n Would a 8TB be good enough to store all them? Since streaming is so abundant now and looks to be for the forseeable future unless something serious happened to the world ( nowadays who can say, would it be better to find them on the net when I want?\n Will an external HD be ok if written to and then only accessed when needed ( once or twice a month) and then shut off? \n I am getting older and plan on retiring in next 10 years. I will have plenty of time to watch all my \"classic\" movies a that time. So I am wanting to store all this until I retire. Then my family can deal with it when I pass.... HAHA dont know what they are in for\n 32TB so far not including blurays\n    submitted by    /u/cmdrmcgarrett  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjbo3e/thinking_of_moving_my_copied_blurays_to_external/",
          "publishedOn": "2022-12-11T22:13:35.000Z",
          "wordCount": 16454,
          "title": "Thinking of moving my copied BluRays to external hard drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjbi2f/advice_for_starting_down_the_path_of_a_hoarder/",
          "author": null,
          "description": "After losing a couple SSD's the pain of losing my files was too great. I started doing some research and bought a TerraMaster D4-300 and two 12Tb HDD. I am unsure what would be the best next steps for backing up my files. \n My initial strategy was to start backing up on one HDD 1 and then set up HDD 2 as a mirrored backup. Now that I have it all plugged in, I am unsure about the best way to do that and looking for advice. I am working from a 4TB Macbook Pro that will go back and forth to work with me and ideally, the TM will be a part of a desk/monitor set up I can just connect laptop to when working from home. \n Something like drivepool seems perfect for what I need but I can see from other posts that's not an option for Mac. Should I just set up a ChronoSync task to mirror HDD 1 to HDD 2 and sync whenever I add files?\n I'm a noob at all this so any advice would be greatly appreciated, thanks!\n    submitted by    /u/DaBeigeMage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjbi2f/advice_for_starting_down_the_path_of_a_hoarder/",
          "publishedOn": "2022-12-11T22:09:30.000Z",
          "wordCount": 16966,
          "title": "Advice for starting down the path of a hoarder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjbah6/any_pixiv_scraper_that_can_target_my_follow_list/",
          "author": null,
          "description": "Every pixiv scraper I can find is purely for scraping tags, but I want to bulk download all my followings, coz I follow over 1k people. Any suggestions?\n    submitted by    /u/MayonnaisalSpray  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjbah6/any_pixiv_scraper_that_can_target_my_follow_list/",
          "publishedOn": "2022-12-11T22:04:33.000Z",
          "wordCount": 16761,
          "title": "Any pixiv scraper that can target my follow list or list of users?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zjavhw/external_enclosure_question/",
          "author": null,
          "description": "Not sure if this is the right place to ask. At the moment just have a small Pi nas running openmediavault with a 4tb 3.5\" hdd in a sabrent powered enclosure. My one issue: the enclosure has a built in power save/sleep function that I cannot disable. Tried going through and making sure APM was disabled, spindown was disabled, etc, but after exhausting all resources I am fairly sure this is a function of the enclosure(even though it is not listed in the product info anywhere I can find). this causes extremely slow load times for Plex initially and can cause temporary hangups browsing files, etc. Anyone know of a good 3.5\" enclosure that does not have a sleep function? I have been looking online and this was the best option that did not list powersave, and ended up having it anyway. Not ready to pull the trigger on an add-on board yet for the Pi. Thanks for any replies!\n    submitted by    /u/dyno241  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zjavhw/external_enclosure_question/",
          "publishedOn": "2022-12-11T21:54:00.000Z",
          "wordCount": 17323,
          "title": "External enclosure question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj9hmh/how_much_space_would_it_take_to_hold_all_of_the/",
          "author": null,
          "description": "Also, would being able to hold this content make it harder for the authorities to deal with book piracy? See here: \n https://join.substack.com/p/copyrights-costs\n  \nAnna’s Archive is active on the normal internet—no need for Tor—and has an “About” page that says: “This website was created by Anna, the person behind the Pirate Library Mirror, which is a backup of the Z-Library shadow library.” And I estimate that people with 300 terabytes of disk space have the ability to personally mirror the totality of the shadow-library material that exists—maybe that’s irrelevant, but the fact that people can personally mirror the totality of the content in question might make it harder to crack down on shadow libraries.\n  \n   submitted by    /u/LinguisticsTurtle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj9hmh/how_much_space_would_it_take_to_hold_all_of_the/",
          "publishedOn": "2022-12-11T21:19:36.000Z",
          "wordCount": 15904,
          "title": "How much space would it take to hold all of the shadow-library content in existence?",
          "imageUrl": "https://external-preview.redd.it/iMgAG5khu2IybQzzkE1u5WD9_vAJy2WSuYo8Ter7P-A.jpg?auto=webp&s=1dac45b95bcde1a6a11afb045a681ba428dc15a4"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj4zl1/found_my_old_yahoo_account_from_2007_and_it_has/",
          "author": null,
          "description": "Is there a way to download the contents of my account in case yahoo goes belly up unexpectedly or something..\n    submitted by    /u/Perfect_Salamander_2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj4zl1/found_my_old_yahoo_account_from_2007_and_it_has/",
          "publishedOn": "2022-12-11T19:25:14.000Z",
          "wordCount": 18100,
          "title": "Found my old yahoo account from 2007 and it has some old emails between my and some family members I'd like to keep.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj4w86/hi_how_to_download_from_internet_archive_using_ia/",
          "author": null,
          "description": "submitted by    /u/mataka54321  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj4w86/hi_how_to_download_from_internet_archive_using_ia/",
          "publishedOn": "2022-12-11T19:22:34.000Z",
          "wordCount": 15659,
          "title": "Hi! How to download from Internet Archive using ia downloader, but files keep their original title and not be renamed by doc file \"identifier\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj4dlx/hdd_sentinel_hates_a_drive/",
          "author": null,
          "description": "I've got an ST18000NE000 and it's passed doing 2 read/write surfaces scans and such but it causes the program to die.\n This is the drive before being scanned. \n And after 2 full read/write scans in HDD Sentinel. \n It seems fine to me?\n    submitted by    /u/Eagle1337  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj4dlx/hdd_sentinel_hates_a_drive/",
          "publishedOn": "2022-12-11T19:08:24.000Z",
          "wordCount": 16109,
          "title": "HDD Sentinel Hates a Drive.",
          "imageUrl": "https://external-preview.redd.it/BJO_olifyouTxfmN4HgPgwVa4Sh3jG0C7lgRdbdkKUY.png?auto=webp&s=9a0693ca263083a1bcce3544afcb15301b65a7bc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj4bsc/hdd_transfer_speeds_question/",
          "author": null,
          "description": "I was a little disappointed when I installed a new external HDD in an enclosure and it maxed out at 50 mb/s copying data from my internal nvme SSD, but accepted it for what it was. I just purchased a second external HDD and am copying between the two and have hit 180+ mbs per second which I was not expecting.\n To add further confusion the new drive is plugged into my slower USB port which (they are both 3.0) ruled so by testing an external drive in each port on opposite sides of the laptop, this slower port gets 15 mb/s when transferring from my internal drive.\n Wondering what the bottleneck could be and if there's anything I can do.\n    submitted by    /u/Artifact-O  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj4bsc/hdd_transfer_speeds_question/",
          "publishedOn": "2022-12-11T19:07:01.000Z",
          "wordCount": 16737,
          "title": "HDD transfer speeds question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zj1in9/how_to_convert_digitize_mini_cds/",
          "author": null,
          "description": "I’m not too sure where to post this but my Aunts birthday is coming up and I wanted to suppose her by digitizing a huge collection of Mini CDs we had from recording in the Sony Handicam. The problem is I have no idea how to accomplish this. Ive been looking online saying I have to finalize the disks but we lost the Camera a long time ago. And the DVD player I have now is too big for the disk and it doesn’t reach the laser for it to be read. i’ve submitted some pictures for context. Links to products I could use and just advice in general would be much appreciated. I thank any and all who answer in advance. \n https://imgur.com/a/XxFOpAU/\n    submitted by    /u/SuperSpirito  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zj1in9/how_to_convert_digitize_mini_cds/",
          "publishedOn": "2022-12-11T17:52:23.000Z",
          "wordCount": 18372,
          "title": "How to Convert / Digitize Mini CDs?",
          "imageUrl": "https://external-preview.redd.it/IFCCfA1gzcM3rYXncct0pGnXMtPEHimLbTZv4SAwghE.jpg?auto=webp&s=2eb91746775e5c5b9d8ae9968bf0cac1d051e989"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziyy34/does_anyone_not_use_raid_in_their_setups/",
          "author": null,
          "description": "I am thinking of buying 30 hard drives because they are so cheap right now, and not doing RAID... maybe backing up on tape or cold storage in the cloud. This is a Plex server for only me and one other family member.\n I'm thinking of assigning each drive to a letter in the alphabet.\n  \nDrive 1 - A [ movies / tv shows / anime ]\n Drive 2 - B [ movies / tv shows / anime ]\n ...\n Drive 26 - Z [...]\n Drive 27 - 0 - 9 [ ... ]\n  \nor\n  \nDrive 1 - A through C [tv shows]\n Drive 2 - ...\n Drive x - A - C [movies] ..\n  \nI have gigabit symmetrical internet and if I ever need to rebuild it's not too painful?\n    submitted by    /u/DigitalSpeed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziyy34/does_anyone_not_use_raid_in_their_setups/",
          "publishedOn": "2022-12-11T16:41:05.000Z",
          "wordCount": 19316,
          "title": "Does anyone not use RAID in their setups?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziyrse/httrack_what_does_happen_if_i_leave_the_scan/",
          "author": null,
          "description": "When I start a new project there are these filters: \n +*.png +*.gif +*.jpg +*.jpeg +*.css +*.js -ad.doubleclick.net/* -mime:application/foobar \n I delete these filters because I am worried that by leaving them then only .png .gif .jpg .jpeg .css .js files will be downloaded and all the other files won't be downloaded, am I correct? \n So I delete the filters and I leave the page blank, but what does happen when the page is left blank? I tried to use the filter +* to see if it is the same thing but then other files are downloaded if I leave the page blank and different files are downloaded if I use the +* filter.\n My question is what is downloaded when no filter is used?\n Another question, what's the difference between this filters:\n +*.png +*.gif +*.jpg +*.jpeg +*.css +*.js -ad.doubleclick.net/* -mime:application/foobar \n and this filters:\n -*\n +*.png +*.gif +*.jpg +*.jpeg +*.css +*.js -ad.doubleclick.net/* -mime:application/foobar\n    submitted by    /u/fjnk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziyrse/httrack_what_does_happen_if_i_leave_the_scan/",
          "publishedOn": "2022-12-11T16:35:56.000Z",
          "wordCount": 16701,
          "title": "HTTrack, what does happen if I leave the Scan Rules (filters) page blank?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziwl8o/psa_to_anyone_who_used_memorex_dvdr_from_2005/",
          "author": null,
          "description": "Pretty sure Memorex isn't a recommended brand anyway, but I figured it can't hurt to put it out there in case someone just didn't know.\n I received a stack of 19 Memorex DVDs from a relative to put them on a flash drive for Christmas. I've gone through 13 so far and 6 have come back with issues.\n In MakeMKV, all but one disc reported:\n Error 'Scsi error - MEDIUM ERROR:L-EC UNCORRECTABLE ERROR' occurred while reading\n The other disc had a different error I don't remember and haven't seen since. Some others were completely unreadable. Some discs were accessible through other means, but any video I could retrieve are severely corrupted so I'll have to copy a bunch of tapes as well to fill in the gaps.\n No discs had any visible damage. No bit rot no scratches. They've been untouched since 2005.\n I'm not asking for any advice, just recording my experience with these discs for others to reference and maybe kick their butt into gear to update their storage situation.\n    submitted by    /u/DeckardTBechard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziwl8o/psa_to_anyone_who_used_memorex_dvdr_from_2005/",
          "publishedOn": "2022-12-11T15:34:03.000Z",
          "wordCount": 18561,
          "title": "PSA to anyone who used Memorex DVD-R from 2005",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziozxs/why_is_it_recommended_to_partition_drives_in_raid/",
          "author": null,
          "description": "I was just reading the arch wiki on setting up RAID and it mentions it's highly recommended to partition the device used for RAID. But it doesn't really explain why. Could someone enlighten me please? Aside from the later suggestion of leaving 100 MiB on the end to make replacement easier is there a reason I should partition the drive before putting it into RAID?\n https://wiki.archlinux.org/title/RAID#Partition_the_devices\n Note: yesterday I did just this but using LVM. So I had 2 18TiB drives, I created 32 partitions about 0.5TiB each and then put them into an LV with total size 18TiB and RAID1 across each device.\n    submitted by    /u/emax-gomax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziozxs/why_is_it_recommended_to_partition_drives_in_raid/",
          "publishedOn": "2022-12-11T11:46:26.000Z",
          "wordCount": 17632,
          "title": "Why is it recommended to partition drives in RAID?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ziognu/how_45_drives_open_source_houston_command_center/",
          "author": null,
          "description": "submitted by    /u/It_Is1-24PM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ziognu/how_45_drives_open_source_houston_command_center/",
          "publishedOn": "2022-12-11T11:21:30.000Z",
          "wordCount": 15497,
          "title": "How 45 Drives Open Source Houston Command Center Makes ZFS On Linux Easy",
          "imageUrl": "https://external-preview.redd.it/QSt43o6FlOwL5od-fJPC1lDVthKeGhjoK068srqkQG4.jpg?auto=webp&s=306b7ddfb448fcc8423057c899d248ff84d6ab0c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zidk9g/the_archive_of_a_vanishing_world_albert_kahn/",
          "author": null,
          "description": "submitted by    /u/kraft-skunk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zidk9g/the_archive_of_a_vanishing_world_albert_kahn/",
          "publishedOn": "2022-12-11T03:41:06.000Z",
          "wordCount": 17550,
          "title": "The Archive Of A Vanishing World | Albert Kahn sought to preserve a world he perceived to be disappearing. A century later, his “Archives de la Planète” connects disparate lands, dying ecosystems and cultures, and a world being utterly transformed by modernity.",
          "imageUrl": "https://external-preview.redd.it/9DHJeuVooPCWGojgtHm0Z1F2uco5p8696ZdBP0CMx-8.jpg?auto=webp&s=7c691a8611e98b99ec097d693c83a7b7a408e5c8"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi8x68/is_there_a_way_to_archivedownload_all_of_someone/",
          "author": null,
          "description": "Pretty self explanatory, just wanna download my deceased Grandpas whole facebook page for photos and videos - any help would be appreciated!\n    submitted by    /u/Hellboymeep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi8x68/is_there_a_way_to_archivedownload_all_of_someone/",
          "publishedOn": "2022-12-11T00:46:45.000Z",
          "wordCount": 16508,
          "title": "Is there a way to archive/download all of someone elses photos & videos from facebook?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi5r9d/archiving_photos_how_to_copy_and_rename_with/",
          "author": null,
          "description": "I have a flatbed scanner and will use CmdTwain so you only have to click the .bat once and it will scan without having to enter anything or do any settings.\n Now cmdtwain overwrites the output file everytime if I dont change the filename before, so my plan is to use the \"running\" bash file to copy the scanned image into a destination folder, and rename it with an incrementing number (like scan00000, scan00001, scan00002,....)\n Is there a not too complex way of doing this?\n    submitted by    /u/PyroRider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi5r9d/archiving_photos_how_to_copy_and_rename_with/",
          "publishedOn": "2022-12-10T22:32:10.000Z",
          "wordCount": 15501,
          "title": "Archiving photos, how to copy and rename with incrementing number one by one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi4hc0/seagate_ironwolf_truenas_showing_lots_of/",
          "author": null,
          "description": "submitted by    /u/SumSnowMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi4hc0/seagate_ironwolf_truenas_showing_lots_of/",
          "publishedOn": "2022-12-10T21:42:10.000Z",
          "wordCount": 16139,
          "title": "Seagate Ironwolf, TrueNAS Showing lots of read/write/checksum errors shows as faulted, but SMART data is good?",
          "imageUrl": "https://preview.redd.it/jjs5f67l455a1.png?auto=webp&s=d672426ef5b4ff3f980c27126a4b3381cbfbd376"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi430s/backing_up_audible_purchases/",
          "author": null,
          "description": "Is there a tool out there that I can use to help backup my Audible purchases in an open audio format?\n    submitted by    /u/Shazzbot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi430s/backing_up_audible_purchases/",
          "publishedOn": "2022-12-10T21:26:57.000Z",
          "wordCount": 15063,
          "title": "Backing up Audible purchases?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi3yla/replacing_3_disk_apfs_fusion_pool_reference_to/",
          "author": null,
          "description": "Thinking about consolidating several spanned AFS Fusion drives “3 disk pool” to a single disk.\n Anyone that understands read times from a sleep state to fully being able to read the entire file system , how should I select a disk if that is my biggest focus to try and resolve without wanting deep enough pockets to go full SSD?\n Are there drives I should be targeting, so when good deals come up I can confidently select a disk?\n    submitted by    /u/rotarypower101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi3yla/replacing_3_disk_apfs_fusion_pool_reference_to/",
          "publishedOn": "2022-12-10T21:22:16.000Z",
          "wordCount": 15372,
          "title": "Replacing 3 disk APFS Fusion Pool, Reference to learn which ~20TB drives to select for wake/fully readable times?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi3fyz/wd_14_tb_wdbwlg0140hbkeesn_shuckable_shuchworthy/",
          "author": null,
          "description": "Found on https://www.amazon.com.tr/gp/product/B07Y3KDVZH , sold by Amazon Turkey itself, wondering if i should shuck it or just use as usb? Anyone has any experience with this particular hdd?\n ​\n official link is https://www.westerndigital.com/en-gb/products/external-drives/wd-elements-desktop-usb-3-0-hdd#WDBWLG0020HBK-EESN\n    submitted by    /u/ares0027  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi3fyz/wd_14_tb_wdbwlg0140hbkeesn_shuckable_shuchworthy/",
          "publishedOn": "2022-12-10T21:02:28.000Z",
          "wordCount": 15504,
          "title": "WD 14 TB WDBWLG0140HBK-EESN Shuckable? Shuch-worthy for 287$/272€?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi36ao/process_to_get_a_shucked_easystore_rmaed/",
          "author": null,
          "description": "Finally had a drive fail. Have like 50 drives running 24/7 so I guess I can’t complain. \n It’s a 14tb WD easystore from bestbuy I bought 12 months ago. I have a bunch of easystore boxes and the housing and stuff, but I don’t know which housing and box matches the one that died. Does that matter? Or can I just put any other housing and box on it?\n    submitted by    /u/sittingmongoose  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi36ao/process_to_get_a_shucked_easystore_rmaed/",
          "publishedOn": "2022-12-10T20:51:36.000Z",
          "wordCount": 15345,
          "title": "Process to get a shucked Easystore rmaed?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi2k60/question_about_potential_bad_drive_in_nas/",
          "author": null,
          "description": "Hello r/DataHoarder, first time long time.\n I have two hard drives I need some quick help with.\n Drive #1\n First is a Western Digital (I know) Red 3TB drive in my PR4100 NAS (I know, I know). Right now the software flags it but does not tell me why. When I check the SMART data via the NAS software, it seems to give me the same info for all 4 drives. (Clicking SMART on 2,3,4 all give the same numbers) This drive is under warranty, so I plan to buy a Seagate and use the RMA WD as a cold backup. But any info on how to get a SMART dump from that individual drive, or figure exactly why it's showing as bad, would be appreciated. This is my second WD drive to die within a year of purchase.\n Drive #2\n Second is a 4TB Western Digital (I know, I know, I know) Blue sitting inside my desktop. This one is giving me an Uncorrectable Sector Count. CrystalDisk just flags it as caution, but I'm not very familiar on the risk here. Also WD's software gives it a cleanbill of health. Should I just replace it, or is it fine for the time being? There is nothing really critical on that drive, so it's not a big problem if it just bites the dust out of the blue. But I would rather avoid it if possible.\n Thanks in advance.\n    submitted by    /u/Jim777PS3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi2k60/question_about_potential_bad_drive_in_nas/",
          "publishedOn": "2022-12-10T20:26:26.000Z",
          "wordCount": 16542,
          "title": "Question about potential bad drive in NAS",
          "imageUrl": "https://external-preview.redd.it/8aLzPI5zMH1z30pQOJ6RR9XvYbvYjQ0BG6U9nkSz9Yg.jpg?auto=webp&s=4a179790006ead8fd186c89a1d4df50d9d32189b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi18rt/question_about_tbw_for_samsung_980_pro/",
          "author": null,
          "description": "I recently installed a 2 TB Samsung Pro 980 M.2 Nvme to use as my boot drive. I cloned my original boot drive which was about 250 GB to the M.2. After a week of computer use, my M.2 states it has 1.2 TB written to it in Samsung magician. Is this normal? I have not installed anything else other than to copy the boot drive to the Nvme.\n    submitted by    /u/Insanity8016  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi18rt/question_about_tbw_for_samsung_980_pro/",
          "publishedOn": "2022-12-10T19:34:32.000Z",
          "wordCount": 16451,
          "title": "Question about TBW for Samsung 980 Pro",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi0pff/are_you_ready_the_cern_released_200_tb_from_the/",
          "author": null,
          "description": "submitted by    /u/sersoniko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi0pff/are_you_ready_the_cern_released_200_tb_from_the/",
          "publishedOn": "2022-12-10T19:11:57.000Z",
          "wordCount": 16246,
          "title": "Are you ready? The CERN released 200 TB from the LHC to the public",
          "imageUrl": "https://external-preview.redd.it/9dMGnerLVSXi5wKf-9Wj9zrx7GZbjxheGslxHFRbli4.jpg?auto=webp&s=a41d07dd00dd16510e84be529836a2c19c715aaa"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zi00j3/has_unas_gone_out_of_business/",
          "author": null,
          "description": "Not hearing back from their sales team at all, their website has said 'will be back in stock Mid-July' since June of this year. Getting more and more discouraged that my hopes for a SFF NAS are shot. The NSC-810 seems one-of-a-kind (cheap knockoffs notwithstanding).\n    submitted by    /u/stempoweredu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zi00j3/has_unas_gone_out_of_business/",
          "publishedOn": "2022-12-10T18:43:57.000Z",
          "wordCount": 15868,
          "title": "Has U-NAS gone out of business?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhyp59/wd_registration_issues/",
          "author": null,
          "description": "submitted by    /u/root54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhyp59/wd_registration_issues/",
          "publishedOn": "2022-12-10T17:51:14.000Z",
          "wordCount": 16514,
          "title": "WD Registration Issues",
          "imageUrl": "https://preview.redd.it/xviaonpez35a1.png?auto=webp&s=1cc51c8acbf4d0d584c1ed83cb8f7f50b97c29b1"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhym9p/wd_red_pro_serial_number_not_found/",
          "author": null,
          "description": "I bought a few 16TB Red Pro drives from the WD store during the WD Black Friday sale. I tried to register them, but 2 drives came back saying invalid S/N. Has anyone run into this lately? \n The drives arrived in good condition, correct packaging and sealed anti-static bags. Unfortunately, one of the bad serial numbers is from a DOA drive that needs to be exchanged. I will call support on Monday. I'm just interested if anyone else has experienced this from WD Store fulfilled drives. Thanks\n    submitted by    /u/GroundWireNeutral  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhym9p/wd_red_pro_serial_number_not_found/",
          "publishedOn": "2022-12-10T17:48:01.000Z",
          "wordCount": 15786,
          "title": "WD Red Pro serial number not found",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhyex1/ig_story_downloading/",
          "author": null,
          "description": "So what’s the latest way to download stories without getting your account locked and temp banned? All the sites I was using the past few years all now trigger the account lock instantly. Anyone have a solution to this?\n    submitted by    /u/haggard929  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhyex1/ig_story_downloading/",
          "publishedOn": "2022-12-10T17:39:43.000Z",
          "wordCount": 15107,
          "title": "IG story downloading",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhxv1x/twitter_to_begin_purging_accounts/",
          "author": null,
          "description": "submitted by    /u/themadprogramer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhxv1x/twitter_to_begin_purging_accounts/",
          "publishedOn": "2022-12-10T17:17:45.000Z",
          "wordCount": 15651,
          "title": "Twitter to begin purging accounts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhxcl1/mechanical_startup_failure_in_gsmartcontrol/",
          "author": null,
          "description": "I bought 20tb WD Elements HDD on Black Friday, run smartctl short & long test and used GSmartControl to view the results. All the stats seemed to be alright and the HDD passed the test. Except in the statistics tab, I found that the HDD had \"Number of Mechanical Start Failures\" value 29. I haven't found much info online and so I contacted WD support and they advised me to replace the HDD, which I did. Yesterday I (finally) received new HDD, and already, after running short test (not sure if I even had to run the test TBH), I am seeing that the NoMSF is 28.\n What the hell, I need to populate my media server!\n Should I replace it again, risk it, repair it (yeah, nah)? Does anyone have any similar experience, or knowledge that can help?\n ​\n Also. I have some crazy RAW values for 2 \"unknown attributes\", but I guess that's some proprietary WD thingie which GSC can't read?\n ​\n ​\n GSC\n GSC \n    submitted by    /u/Zeebedee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhxcl1/mechanical_startup_failure_in_gsmartcontrol/",
          "publishedOn": "2022-12-10T16:57:09.000Z",
          "wordCount": 15336,
          "title": "Mechanical startup failure in GSmartControl",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhxaqb/accidentally_deleted_300_music_sessions_please/",
          "author": null,
          "description": "Hello, in a bit of shock.\n I just noticed I accidentally deleted almost all of my Logic sessions this week.\n To clean up my desktop I put everything in a folder, and by mistake I deleted that folder.\n I have some backups, but not of recent sessions and not of component files like drum kits.\n Please, give me all your suggestions for what I should do to go about recovering my life’s work. I have contacted a local data recovery service about an appointment. NYC area. 2016 MBP OS Catalina.\n This post may be slightly orthogonal to the subreddit but this is devastating to me.\n    submitted by    /u/quick_advert  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhxaqb/accidentally_deleted_300_music_sessions_please/",
          "publishedOn": "2022-12-10T16:54:44.000Z",
          "wordCount": 17717,
          "title": "Accidentally deleted 300 music sessions. Please help.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhx6zw/best_way_to_refresh_data_on_an_ssd_for_long_term/",
          "author": null,
          "description": "I might be mistaken here but is refreshing the charges in SSD NAND as easy as reading the files? Could we not just run something like dd if=/dev/{SSD} of=/dev/null periodically to ensure the data is healthy?\n    submitted by    /u/oeCake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhx6zw/best_way_to_refresh_data_on_an_ssd_for_long_term/",
          "publishedOn": "2022-12-10T16:50:04.000Z",
          "wordCount": 17019,
          "title": "Best way to refresh data on an SSD for long term storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhwimk/made_a_python_script_to_download_your_wattpad/",
          "author": null,
          "description": "submitted by    /u/MRtecno98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhwimk/made_a_python_script_to_download_your_wattpad/",
          "publishedOn": "2022-12-10T16:21:08.000Z",
          "wordCount": 15701,
          "title": "Made a python script to download your Wattpad library in EPUB format",
          "imageUrl": "https://external-preview.redd.it/rGCC9rRPs4fHX-So2Xfsisq-f2R2Aaqbs6efxFmT8lo.jpg?auto=webp&s=c2cb9d755e0645a136c9babedeeb91878a5fa87b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhe54a/slo_mo_guys_with_1pb_tldw_he_puts_60_drives_in/",
          "author": null,
          "description": "submitted by    /u/ArPDent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhe54a/slo_mo_guys_with_1pb_tldw_he_puts_60_drives_in/",
          "publishedOn": "2022-12-10T00:45:12.000Z",
          "wordCount": 16509,
          "title": "Slo Mo Guys with 1PB* - tldw he puts 60 drives in synology DSM on a raid 6",
          "imageUrl": "https://external-preview.redd.it/Embj4lWSoPR6jeH0_pO9ujmL_tebDNK8Dc5bSkRzOg4.jpg?auto=webp&s=756c5b2bdbd7692b5313d5f6daf479bc74a676d6"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhbw2y/does_anyone_know_a_way_to_find_all_the_hidden/",
          "author": null,
          "description": "Last year Youtube made private or deleted videos invisible, but will still show them if you use the \"show unavailable videos\" option in playlist settings. However, when it shows these videos, it doesn't mark them, so I have to go through my 1,700-video-long master music playlist one video in two tabs at a time to see what appears in one but not the other. Does anyone know a better way to manage large playlists?\n    submitted by    /u/Schadenfrueda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhbw2y/does_anyone_know_a_way_to_find_all_the_hidden/",
          "publishedOn": "2022-12-09T23:11:06.000Z",
          "wordCount": 16635,
          "title": "Does anyone know a way to find all the hidden videos in a long Youtube playlist?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhbe3w/im_a_complete_newbie_i_want_to_adapt_this_m2_slot/",
          "author": null,
          "description": "submitted by    /u/Edeinawc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhbe3w/im_a_complete_newbie_i_want_to_adapt_this_m2_slot/",
          "publishedOn": "2022-12-09T22:52:06.000Z",
          "wordCount": 15893,
          "title": "I'm a complete newbie. I want to adapt this M2 slot into a SATA slot. As you can see from the picture there's very little space to work with as half the M2 is under the GPU. Looking up adapaters, I see all these big boards and am overwhelmed due to ignorance. What do I need to make it work?",
          "imageUrl": "https://preview.redd.it/wkpmav77cy4a1.jpg?auto=webp&s=241b37c3375632cd806cf8687ccf24ac61b7eb0f"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zhasrv/software_for_automatically_recordingdownloading/",
          "author": null,
          "description": "No clue if this is the right subreddit for this but here we go i guess.\n Basically i am looking for a program that will automatically record twitch livestreams. Currently i just manually record using browser extensions but i often end op missing big parts of the stream as i dont notice they went live. I tried searching around but i cant find anything that dosent require you to have 20 years of experience in IT to download/use. VODs wont work since they have muted parts or are straight up not uploaded.\n All i would want it to do is automatically detect when a set streamer goes live and record it untill they go offline. Just in case it should also not corrupt the files if the stream crashes or otherwise goes out (on the streamers end).\n Know of anything i could use?\n    submitted by    /u/Crab17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zhasrv/software_for_automatically_recordingdownloading/",
          "publishedOn": "2022-12-09T22:29:18.000Z",
          "wordCount": 16873,
          "title": "Software for automatically recording/downloading twitch livestreams?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh9qbq/where_to_buy_hard_drives/",
          "author": null,
          "description": "I just got a shipment of 3 12TB WD red drives from Amazon. They shipped them loose in a box with a single layer of bubble wrap! Where would you recommend I get some new drives? I immediately initiated a return for the drives. What a waste.\n    submitted by    /u/crittercam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh9qbq/where_to_buy_hard_drives/",
          "publishedOn": "2022-12-09T21:46:32.000Z",
          "wordCount": 15098,
          "title": "Where to buy hard drives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh9fzt/annas_archive_update_fully_open_source_archive/",
          "author": null,
          "description": "submitted by    /u/AnnaArchivist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh9fzt/annas_archive_update_fully_open_source_archive/",
          "publishedOn": "2022-12-09T21:34:33.000Z",
          "wordCount": 16516,
          "title": "Anna’s Archive update: fully open source archive, ElasticSearch, 300GB+ of book covers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh94ff/is_this_a_viable_strat_to_backup_while_still/",
          "author": null,
          "description": "submitted by    /u/fatalskeptic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh94ff/is_this_a_viable_strat_to_backup_while_still/",
          "publishedOn": "2022-12-09T21:21:45.000Z",
          "wordCount": 16679,
          "title": "Is this a viable strat to backup while still having some live access to relevant data?",
          "imageUrl": "https://preview.redd.it/meywgsp1wx4a1.png?auto=webp&s=843fc3afe3540ace13607a9a9b9efdb0f6f3dd1c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh8c12/psu_solution_for_48_bay_jbod_corsair_5v_load/",
          "author": null,
          "description": "I am currently in the process of building my new storage system and planing the power solution.\n After some research (and discovering the fact that psu only provide a fraction of their capacity @ 5v)\n I think i found a solution.\n A year ago corsair officially started offering a 12v to 5v adapters for their psus.\n https://www.corsair.com/uk/en/Categories/Products/Accessories-%7C-Parts/CORSAIR-%2B5V-Load-Balancer/p/CP-8920275\n If i understand correctly each unit takes one 8pin and provides 20A @ 5v (100w according to their website)\n This bundled with a 1500w psu like the HX1500i (with 9 8pin/pcle & also some 5v directly of the psu),\n might be able to power that amount of drives.\n 9 adapter x 20A @ 5v = 180A @ 5v\n + 25A (from psu itselfe) = total of 205A @ 5v.....\n 205A should be more than enough for 48 drives even if all would startup at the same time....\n With delayed spinup this should theoretically be able to support more than double that.\n What do you think of this? Did i make a mistake somewhere?\n    submitted by    /u/Pommes254  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh8c12/psu_solution_for_48_bay_jbod_corsair_5v_load/",
          "publishedOn": "2022-12-09T20:50:07.000Z",
          "wordCount": 16022,
          "title": "PSU Solution for 48 bay JBOD | Corsair 5V Load Balancer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh842m/looking_for_a_gallerytagging_application_for_10k/",
          "author": null,
          "description": "Ideally I would like something that allows me to open a folder with images and it show me images 1 by 1 that I can set tags on if that makes sense. \n Flow like: Select folder —> Select first image —> Type tag —> move to next image\n Does something like this exist?\n    submitted by    /u/SergeantMojo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh842m/looking_for_a_gallerytagging_application_for_10k/",
          "publishedOn": "2022-12-09T20:41:07.000Z",
          "wordCount": 15627,
          "title": "Looking for a gallery/tagging application for ~10k images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh7r97/i_just_got_a_pci_slot_sata_expansion_however_when/",
          "author": null,
          "description": "submitted by    /u/Edeinawc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh7r97/i_just_got_a_pci_slot_sata_expansion_however_when/",
          "publishedOn": "2022-12-09T20:26:52.000Z",
          "wordCount": 16063,
          "title": "I just got a PCI slot SATA expansion. However, when I plug it into the PCI slot, it completely shuts off energy to the computer. It won't even turn on, and if it's on it will shut it down. What could be the problem? Is it bad equipment triggering motherboard short circuit protection?",
          "imageUrl": "https://preview.redd.it/91wr4istlx4a1.jpg?auto=webp&s=0ca9afd3d838da908299d023223f0f04196b3234"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh6wft/supermicro_chassis_question/",
          "author": null,
          "description": "I am about to pull the trigger on a CSE-826BE16-R920LPB with the 920W PSU. \n I've never owned a supermicro chassis before - generally how loud the chassis and PSU fans are at low load? I've got a chenbro case at that is pretty annoying to listen to even on the lowest fan speeds\n Secondly, I see some of these backplanes come with 1 vs 2 expanders - is this purely for redundancy? Will all of the bays work even with just the 1 expander backplane? (SATA drives if it matters)\n    submitted by    /u/siscorskiy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh6wft/supermicro_chassis_question/",
          "publishedOn": "2022-12-09T19:53:50.000Z",
          "wordCount": 16720,
          "title": "Supermicro chassis question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh6vxa/x11spmtpf_flash_lsi_9300_to_it_mode/",
          "author": null,
          "description": "I haven't flashed any of these controllers before. I've always bought from Art of Server on eBay. \n How hard is it to flash the integrated controller on the SM x11spm-tpf board? What are the risks? It is a $500 board, if I mess it up can I brick the whole mobo? Just the lsi controller, or is it an easy process? Would I be better off buying a pcie hba card and leave the integrated controller alone? \n Thanks.\n    submitted by    /u/WrongColorPaint  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh6vxa/x11spmtpf_flash_lsi_9300_to_it_mode/",
          "publishedOn": "2022-12-09T19:53:12.000Z",
          "wordCount": 15770,
          "title": "X11SPM-TPF flash LSI 9300 to IT mode?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh5tri/someone_stole_my_14tb_wd_red_pro_off_my_porch_but/",
          "author": null,
          "description": "I’ve filed a claim with UPS and Western Digital, but I’m not too hopeful of anything coming of it. Has anyone else had a similar experience? We’re you able to get a replacement sent?\n    submitted by    /u/Duffs1597  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh5tri/someone_stole_my_14tb_wd_red_pro_off_my_porch_but/",
          "publishedOn": "2022-12-09T19:10:40.000Z",
          "wordCount": 15503,
          "title": "Someone stole my 14TB WD Red Pro off my porch, but left the open box. I’m so sad",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh5tdm/looking_for_server_build_feedback/",
          "author": null,
          "description": "My budget Is $700 I already have 4 8tb Nas 3.5 drives and 1 250 gb 2.5 ssd drive I want to use docker on this as a media streaming, ebook, audiobook, file Downloader server. \n What would you change? \n My budget Is $700 I already have 4 8tb Nas 3.5 drives and 1 250 gb 2.5 ssd drive I want to use docker on this as a media streaming, ebook, audiobook, file Downloader server. \n What would you change? \n My budget Is $700 I already have 4 8tb Nas 3.5 drives and 1 250 gb 2.5 ssd drive I want to use docker on this as a media streaming, ebook, audiobook, file Downloader server. \n What would you change? \n PCPartPicker Part List\n  \n Type Item Price \n  \n CPU Intel Core i5-12600K 3.7 GHz 10-Core Processor $257.99 @ Newegg \n  CPU Cooler be quiet! Pure Rock 2 Black CPU Cooler $59.27 @ Amazon \n  Motherboard ASRock Z690M Phantom Gaming 4 Micro ATX LGA1700 Motherboard $129.99 @ Newegg \n  Memory G.Skill Ripjaws V 32 GB (2 x 16 GB) DDR4-4000 CL18 Memory $109.99 @ Amazon \n  Power Supply Asus ROG Strix 550 W 80+ Gold Certified Fully Modular ATX Power Supply $89.99 @ B&H \n   Prices include shipping, taxes, rebates, and discounts  \n   Total $647.23 \n   Generated by PCPartPicker 2022-12-09 13:58 EST-0500  \n \n    submitted by    /u/deepdivered  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh5tdm/looking_for_server_build_feedback/",
          "publishedOn": "2022-12-09T19:10:13.000Z",
          "wordCount": 16806,
          "title": "Looking for server build feedback",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh5onq/unsure_what_im_looking_for_regarding_backup/",
          "author": null,
          "description": "Hi all.\n I have a couple of servers racked up at home. I'm looking at using server 2 as a mirror of the data on server 1. I have manually copied all of the data over (about 48tb) manually, but keeping them the same is going to be an impossible task to keep up on manually.\n I'm looking for suggestions on what software would best fit my needs for keeping the data backed up/identical. I have enough horsepower that I can create VM's if needed.\n Not sure I'll be able to hit all of these targets, but here is what I'm hoping for: - Scan server 1 and server 2. Copy any missing files from server 1 to server 2. - Ease of use / intuitive. I'm not much the command line guy, but can be taught. Something that is relatively easy to use would be a bonus. - Incremental vs. Differential - which would best fit my needs? - Anything I'm missing? I don't know what I don't know.\n Any guidance would be amazing. This is a whole new realm for me, so all input is greatly appreciated!\n Cheers!\n    submitted by    /u/TheModfather  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh5onq/unsure_what_im_looking_for_regarding_backup/",
          "publishedOn": "2022-12-09T19:05:04.000Z",
          "wordCount": 18910,
          "title": "Unsure what I'm looking for, regarding backup software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh4i65/yesterday_i_began_archiving_the_free_for_personal/",
          "author": null,
          "description": "Yesterday I started archiving the “free for personal use” art collection of the Prado Museum. Art pieces range from 1100-1980. You can learn more about it by clicking the link.\n So far I am really enjoying the history and and amazing art pieces I have come across. I am only part way through the letter “C” as I write this and have already collected over 600 pieces. I am super excited to do this and can't wait to see what pieces I discover along the way. Each piece can be downloaded by anyone but I thought I would take on the task of doing it so you all can enjoy it in a heaping \"Data Hoarder\" fashion. I am aware you can email the museum, however I really doubt they will send you every file along with the artist bios neatly organized. Plus, I am really enjoying this experience!\n I expect thi…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh4i65/yesterday_i_began_archiving_the_free_for_personal/",
          "publishedOn": "2022-12-09T18:18:41.000Z",
          "wordCount": 15936,
          "title": "Yesterday I began archiving the \"free for personal use\" art collection of the Prado Museum: Here's where I am right now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh40ep/ordered_10x12tb_seagate_drives_received_10x16tb/",
          "author": null,
          "description": "submitted by    /u/Sirelewop14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh40ep/ordered_10x12tb_seagate_drives_received_10x16tb/",
          "publishedOn": "2022-12-09T18:00:37.000Z",
          "wordCount": 17072,
          "title": "Ordered 10x12TB Seagate drives - Received 10x16TB!",
          "imageUrl": "https://external-preview.redd.it/NKKJpdINpJeYIIhucbb7DbksZrFEDqpHcwIp0qWv4go.jpg?auto=webp&s=601e1c5d88124918bd34610ad929964fb8fbb95e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh1zp9/wd_white_label_drive_shucked_from_wd_elements/",
          "author": null,
          "description": "Bear with me a moment, this one's a little complicated, but I'd really appreciate some assistance from anyone more experienced with these drives than myself.\n I bought two 16TB WD Elements drives during a Black Friday sale and subsequently shucked them after testing them via USB. I removed the 3.3v pins (third from the left, etc, done this before on other models) on both, but one of the drives still doesn't want to come alive when plugged in unless I'm using the USB board supplied with the drive enclosure. The drive works, just only when using the enclosure's board.\n The machine I would like to use this drive on is a NAS enclosure with a SATA backplane, so I can't use a molex adapter to get around the usual 3.3v issue. If I'm not able to get anywhere otherwise, I plan to try swapping the drives between machines, but would like to avoid this if possible as it would require (another) array parity rebuild.\n Both drives report as WD160EDGZ-11B2DA0. Any suggestions would be greatly appreciated. Here's a picture of the SATA connector.\n    submitted by    /u/goalcam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh1zp9/wd_white_label_drive_shucked_from_wd_elements/",
          "publishedOn": "2022-12-09T16:42:09.000Z",
          "wordCount": 16523,
          "title": "WD white label drive shucked from WD elements drive, removed 3.3v pin entirely but it still is not coming up",
          "imageUrl": "https://external-preview.redd.it/5KpiMLFPTvbVlnhRI-HUm6VJ5VCfSY5m10fm-dhlND0.png?auto=webp&s=a2e63efe3698aaccf6b8de16512709e266e2de77"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zh0scq/everything_gets_pirated_except_the_stuff_that/",
          "author": null,
          "description": "submitted by    /u/AshleyUncia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zh0scq/everything_gets_pirated_except_the_stuff_that/",
          "publishedOn": "2022-12-09T15:53:35.000Z",
          "wordCount": 17177,
          "title": "Everything gets pirated, except the stuff that doesn't.",
          "imageUrl": "https://preview.redd.it/3dixfacg9w4a1.png?auto=webp&s=c8f68601eeaaf7af433193ad2cf08e0cf5c4a853"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgzjrx/now_when_all_streaming_services_are_stacking_up/",
          "author": null,
          "description": "submitted by    /u/kllssn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgzjrx/now_when_all_streaming_services_are_stacking_up/",
          "publishedOn": "2022-12-09T15:01:51.000Z",
          "wordCount": 17459,
          "title": "Now, when all streaming services are stacking up their prices, I decided also to stack up",
          "imageUrl": "https://external-preview.redd.it/ataZrKVec_W-PU_1GtiwwLRshEz4giV04Olz0ow7xgU.jpg?auto=webp&s=77bfc1b2ea86c447db2989b217c231637edc5641"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgzcx0/need_to_digitize_mr_men_and_anpanman_tapes_but/",
          "author": null,
          "description": "So I have two of the US dub of the 1980s Mr. Men and Little Miss VHS tapes I have since getting into the series back in 2008 and a Anpanman tape that has 3 episodes that aren't on DVD. My brother knows how to record the tapes and digitize them. But there's a few problems. One is that our VCR is a Magnavox VCR/DVD combo GDV228MG9 , and that the tapes can sometimes jump. And if that happens, it messed up the recording.\n My brother researched that we should invest on another VCR player that is S-VHS. But he also told me that we should also look into a VCR with a time base corrector. The major roadblock is that they are too much to buy. And while trying to not spend the money on foolish things is a step, it'll still take a long to achieve that. Not only that, I don't know how long the tapes will last, especially since the Mr. Men ones are in their mid 30s. And I can't just simply buy another copy of the tapes as they aren't on ebay anymore. And I don't know anybody that has the best equipment that can actually digitized the tapes. I did had one friend years ago who helped me with a recorded Thomas tape, but I don't know if he still does it.\n ​\n The Anpanman tape I bought months ago\n ​\n    submitted by    /u/mrnormal94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgzcx0/need_to_digitize_mr_men_and_anpanman_tapes_but/",
          "publishedOn": "2022-12-09T14:54:19.000Z",
          "wordCount": 16361,
          "title": "Need to Digitize Mr. Men and Anpanman tapes, but Time Base Correcters are too expensive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgygl5/advice_he_m43_keeps_telling_me_m2_that_he_doesnt/",
          "author": null,
          "description": "Hi, I'm a 2tb m2 SSD that has been running a bit hot in his computer for a few years now. We had a scare once when I wouldn't mount properly on boot, causing him to think he lost the last 27 years of photos and random internet forum backups that he has stored on me, but one reboot later, he found me again. It gave him a little bit of a scare, so he found another one of me (THE AUDACITY to think he could find another ME) and stuck us together into RAID0. \n Lemme tell you what, this man was ESTATIC to find out that he had double the storage, while still having the protection of RAID. He went on an unhinged downloading spree, grabbing everything he could find online he thought was rare and people might want one day. Random things like old MTV shows, a live action Spirited Away play (ITS ALREADY A MOVIE, WHO NEEDS A PLAY?), and technical manuals for old hardware (?????????).\n Anyways, it was a lot. The heat and pressure to deliver finally was enough for me, and I said 'Peace, Im out'. \n Well, turns out he didn't like that, and started breaking things. I tried to get away, but he grabbed me before I could and said he was going to take me to a 'specialist' to get 'fixed'. Like, I don't need fixing – Ive made my choice. He kept claiming I was so valuable and he needed me, but then decided to treat me like that? Without any backups??? Clearly I wasn't that important to him. Regardless of my decisions, he hauled me down to a data specialist to recover some stuff, but they couldn't do anything. \n So reddit, AITA for dying to teach him about backups and that RAID0 is not a backup?\n    submitted by    /u/XxNerdAtHeartxX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgygl5/advice_he_m43_keeps_telling_me_m2_that_he_doesnt/",
          "publishedOn": "2022-12-09T14:16:12.000Z",
          "wordCount": 15432,
          "title": "[Advice] He (M43) keeps telling me (M2) that he doesn't need to back me up because \"SSD's have fewer moving parts\". AITA for dying on him?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgr1eo/re_noobs_and_their_zipjaz144meg_disks_this_is/",
          "author": null,
          "description": "submitted by    /u/mega_ste  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgr1eo/re_noobs_and_their_zipjaz144meg_disks_this_is/",
          "publishedOn": "2022-12-09T08:11:08.000Z",
          "wordCount": 18368,
          "title": "Re: noobs and their zip/jaz/1.44meg disks, this is what real floppy disks look like :)",
          "imageUrl": "https://external-preview.redd.it/0tjJ-nY0cfxiFHTdvrwhQvtziIA70FG8ceO-p23m7SM.jpg?auto=webp&s=cf5f7dcb1f64c3c700bb8bc719a78ff23808c202"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgjdos/noobs_and_their_16_tb_scamdisksthis_is_what_real/",
          "author": null,
          "description": "submitted by    /u/crashbananacoot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgjdos/noobs_and_their_16_tb_scamdisksthis_is_what_real/",
          "publishedOn": "2022-12-09T01:50:12.000Z",
          "wordCount": 17739,
          "title": "Noobs and their 16 tb Scamdisks…this is what real datahoarding looks like *drops mic*",
          "imageUrl": "https://external-preview.redd.it/lTjaT6PJLCVf4qjfYNEMTH0RCqjhzYUYi8Pn8nEGR8E.jpg?auto=webp&s=b614ff941c6f04485dd3798836c96817ab8d904a"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgj2rz/when_and_if_you_do_manual_backups_which_copying/",
          "author": null,
          "description": "Currently using Windows 11 and I'm copying 6TB worth of data using TeraCopy with Verify setting on and copying speed oscillates between 180-230 MB/s to my DAS.\n I've also used robocopy in the past.\n    submitted by    /u/nando1969  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgj2rz/when_and_if_you_do_manual_backups_which_copying/",
          "publishedOn": "2022-12-09T01:37:33.000Z",
          "wordCount": 17072,
          "title": "When and if you do manual backups which copying method do you use ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zghd8s/life_expectancy_of_samsung_qvo_details_in_comments/",
          "author": null,
          "description": "Long time lurker, first time poster. \n my life is transient. I live out of luggage and my hoarding is manageable. But I'm looking into a dual 2.5\" external enclosure and put in an 8tb Samsung QVO drive. If I'm only writing once to this drive (adding Linux ISO's) what's the life expectancy of this drive? I'm not looking for a forever drive, I know that's impossible. But if these drives fail after 3 years of using them, then Ill find something else. \n Thoughts? Comments? Anyone have this drive that can share insights and/or regrets?\n    submitted by    /u/Peak_Photo1234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zghd8s/life_expectancy_of_samsung_qvo_details_in_comments/",
          "publishedOn": "2022-12-09T00:29:43.000Z",
          "wordCount": 17316,
          "title": "Life expectancy of Samsung QVO, details in comments.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgesqw/bulk_downloading_from_javguru_using_idm_site/",
          "author": null,
          "description": "any advice would be greatly appreciated and im willing to share all my downloads to the world if any1 is interested, got 1g up and down and lots of storage to put to use \n not a programming expert so i cant make my own script, i tried downloading one by one but it takes so much effort anyway to automate this?\n    submitted by    /u/dhendodong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgesqw/bulk_downloading_from_javguru_using_idm_site/",
          "publishedOn": "2022-12-08T22:56:42.000Z",
          "wordCount": 16709,
          "title": "Bulk downloading from jav.guru Using IDM Site Grabber",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgdo3k/how_do_you_backup_software_and_games/",
          "author": null,
          "description": "I am talking about when you move those to new pc. How do you make sure it going to run on new pc? I want save those software and games on case it won't be avalaibe in future. \n The type of games I have are not complex games. Most of them are pixel rpg, visual novesls, puzzle games etc.\n    submitted by    /u/venluxy1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgdo3k/how_do_you_backup_software_and_games/",
          "publishedOn": "2022-12-08T22:17:14.000Z",
          "wordCount": 16638,
          "title": "how do you backup software and games?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgd0qc/brand_new_seagate_barracuda_4tb_making_faint/",
          "author": null,
          "description": "Hey everyone!\n I'm fairly new to datahoarding so if I make any mistakes please let me know.\n I have recently purchased a brand-new 4TB Seagate Barracuda HDD off of Amazon, and it arrived fine. There was no visible damage to the box, and it was firmly strapped onto some sort of carboard frame inside.\n I ran multiple tests on it to check for errors with 2 programs (StableBit Scanner and HD Tune Pro), and both of them showed the drive as completely clean.\n However, I found that it makes a really faint rattling (and sometimes more scratchy) noise. The sound is more common in the first 1.5 billion sectors or so, and gets less common and quieter near the end of the disk. \n Is the disk fine? Should I RMA it immediately?\n (Also, either the SMART data is really weird or I just don't know how to interpret it properly could someone help)\n Link to audio recording (sound amplified): https://drive.google.com/file/d/1YewB1dhB0w64OqlwWx6ne_jidP_JNZCl/view?usp=sharing\n Link to smart data screnshot:\n https://imgur.com/a/Mh4tGvF\n    submitted by    /u/Jaeyoon07031  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgd0qc/brand_new_seagate_barracuda_4tb_making_faint/",
          "publishedOn": "2022-12-08T21:55:01.000Z",
          "wordCount": 17300,
          "title": "Brand new Seagate Barracuda 4TB making faint rattling noises",
          "imageUrl": "https://external-preview.redd.it/7YWbhL82Tavxl53H7SQCRhxuzOk4Abdq3xjs3buWxus.jpg?auto=webp&s=ce583e9ace69660ed718c9314ac248ad4667062b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgbxc1/whats_an_application_thats_missing_in_your/",
          "author": null,
          "description": "Hi all.\n Just finished final exams and have a solid month of nothing to do. I want to spend my free time working on a project. What's a an application you wish you had? What's a program that could make your life easier? \n This could be not just just limited to data hoarding but other hobbies and domains as well. All sorts of ideas welcome!\n    submitted by    /u/crashlevin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgbxc1/whats_an_application_thats_missing_in_your/",
          "publishedOn": "2022-12-08T21:16:33.000Z",
          "wordCount": 17950,
          "title": "What's an application that's missing in your life/could make your workflow easier?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgbch4/successfully_rmaed_western_digital_shucked_drive/",
          "author": null,
          "description": "Just wanted to share a datapoint. Shucked 12tb easy store drive failed in NAS. Created an RMA and sent the drive back without putting it back in the housing. I did remove the little piece of tape though. A few weeks later a 12TB easy store (yes back in the external housing) arrived on my doorstep!\n Wasn’t sure it would work but didn’t know what else to do with a malfunctioning drive.\n    submitted by    /u/ijustwantnsfw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgbch4/successfully_rmaed_western_digital_shucked_drive/",
          "publishedOn": "2022-12-08T20:56:48.000Z",
          "wordCount": 16583,
          "title": "Successfully RMA’ed western digital shucked drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgb7w4/iso_24_25_drive_bay_solution_for_zfs_array/",
          "author": null,
          "description": "I'm looking for something to throw 24 or more 2.5\" drives in. It could be a DAS box, or something from a manufacturer. I used to have a SuperMicro case but I gave it away about two years ago (regretfully).\n I'd either put my own components in, or if it's a DAS box, get a new HBA and build a NAS in a cheap 2U Rosewill case.\n I don't want to use something like a Dell R730xd and do an all in one because of the high fan noise.\n I was thinking a Dell power vault off of FleaBay or something similar, but I'm not sure how loud they are. \n Any suggestions? :)\n    submitted by    /u/-justAnAnon-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgb7w4/iso_24_25_drive_bay_solution_for_zfs_array/",
          "publishedOn": "2022-12-08T20:52:17.000Z",
          "wordCount": 16654,
          "title": "ISO 24+ 2.5\" drive bay solution for ZFS array - suggestions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgan0m/is_it_possible_to_download_your_saved_comments/",
          "author": null,
          "description": "I have a mass of Saved Comments in Reddit < Is it possible to just have a 3rd Party Site send them to me? \n Although it is possible for Reddit to send you what you've saved ~ It only sends *URLs* of what you've saved, tasking me to parse through everything individually to copy+paste into word docs, its just tedious - Is there a way around this? \n    submitted by    /u/PotnaKaboom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgan0m/is_it_possible_to_download_your_saved_comments/",
          "publishedOn": "2022-12-08T20:32:01.000Z",
          "wordCount": 17120,
          "title": "Is It Possible To Download Your Saved Comments?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zgaaey/4tb_drive_in_a_zfs_mirror_is_mostly_dead_what_next/",
          "author": null,
          "description": "Should I get 2x4tb WD HDD's and put it into a raid Z1 with the remaining Ironwolf (less than a year old) or should I get a single 8tb drive?\n Bought Seagate and one died so I'm gonna give WD a shot.\n Yes I have a backup, that is how I would restore if I made a new pool.\n    submitted by    /u/SumSnowMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zgaaey/4tb_drive_in_a_zfs_mirror_is_mostly_dead_what_next/",
          "publishedOn": "2022-12-08T20:20:07.000Z",
          "wordCount": 16561,
          "title": "4TB Drive in a ZFS mirror is mostly dead. What Next?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zga14q/im_so_sick_of_chasing_3rd_parties_to_rip/",
          "author": null,
          "description": "tl;dr Is looking at source code the best way to rip these days?\n I've been using VLC for youtube but many of the instructions on how to do so, are now outdated. Obviously youtube tries to stop this sort of stuff so I've used a couple different versions of this method over the years with moderate success. The other thing I've tried is chrome extensions which again, may work for a period of time but ultimately get blocked. Many of the times, the higher quality versions I've never been able to download. It seems like the VLC method maxed out at 720p/1080p. I'd really like to be able to save content from youtube and others in the max quality possible.\n I think the best way from here is to examine the code which has worked for me in the past (5-10+ years) when code was a little more straightforward, but finding the actual content is \"wrapped\" (sorry I don't code) in java(?). I'd like to learn enough to squirrel this stuff out myself, any suggestions - or does a website's media player query things to an outside source to pull content? \n Right now, I'd like to rip this content and three extensions fail to even find the audio or video. Side rant: anyone come up with a solution to save images as jpeg/png that are displayed as .webp?\n    submitted by    /u/31337420  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zga14q/im_so_sick_of_chasing_3rd_parties_to_rip/",
          "publishedOn": "2022-12-08T20:11:12.000Z",
          "wordCount": 17623,
          "title": "I'm so sick of chasing 3rd parties to rip video/audio",
          "imageUrl": "https://external-preview.redd.it/ix75drDXaEq_YOa050a_5i2ynVU4QuoFPfVe3CZHIfg.jpg?auto=webp&s=602fdadb8437956dfa226de066b53aee965c3db0"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zg7yyy/why_do_people_say_modern_enterprise_drives_are/",
          "author": null,
          "description": "I recently purchased a 14TB Seagate Exos and it's one of the quietest drives I've ever owned. The only quieter drive I've owned was a consumer 4TB 5400 RPM SMR drive which was dead silent.\n I've owned a 150GB WD Raptor that sounded like a sewing machine it was so loud.\n In 2009 I also purchased the first 1TB WD Black drive which wasn't nearly as loud but still noisy. I was expecting the drive to be as loud as that WD Black but it's silent in comparison even after writing several TB to it already. \n At least for Seagate helium filled drives they are silent compared to consumer drives from just a decade ago.\n At first I thought it was louder than it actually was because it was resonating against my case but I simply added some foam pads and it's silent now, I'm amazed. The only time I can tell the drive is on is from the very occasional clicks I consider normal from any spinning hard disk. Am I alone in this?\n    submitted by    /u/Valor_X  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zg7yyy/why_do_people_say_modern_enterprise_drives_are/",
          "publishedOn": "2022-12-08T19:00:55.000Z",
          "wordCount": 17100,
          "title": "Why do people say modern Enterprise drives are loud? (Helium filled)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zg60aq/hard_disks_geometry_in_depth/",
          "author": null,
          "description": "submitted by    /u/Z3t4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zg60aq/hard_disks_geometry_in_depth/",
          "publishedOn": "2022-12-08T17:51:21.000Z",
          "wordCount": 19362,
          "title": "Hard disks geometry in depth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zg3h4a/sas_home_raid_solution/",
          "author": null,
          "description": "I have access to 5 2tb sas SSD hard drives and I was wondering if there was a Nas raid solution that would accommodate the drives?\n    submitted by    /u/01stewartn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zg3h4a/sas_home_raid_solution/",
          "publishedOn": "2022-12-08T16:16:50.000Z",
          "wordCount": 16789,
          "title": "Sas home raid solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfyjhf/why_is_storage_spaces_saying_low_capacity_add/",
          "author": null,
          "description": "submitted by    /u/Laser_Bones  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfyjhf/why_is_storage_spaces_saying_low_capacity_add/",
          "publishedOn": "2022-12-08T13:12:38.000Z",
          "wordCount": 17442,
          "title": "Why is storage Spaces saying \"Low capacity; add drives\" When I have plenty of space?",
          "imageUrl": "https://preview.redd.it/8ttbnnixbo4a1.png?auto=webp&s=e4fed8a1bf8a608d6e3014ddeee97588336f0f63"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfxewl/when_copying_files_to_18tb_windows_freezes_all/",
          "author": null,
          "description": "Windows 10, copying from 1 external device (varying brands & sizes) to another external hard drive (18tb easystore). Usually it locks up & doesn’t recognize any of the usb drives & I have to restart to show the drives again. \n Is there something in the task manager that I can restart to make the usb drive visible again? Or run something else to recognize usb again besides just restarting?\n    submitted by    /u/peanutbluster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfxewl/when_copying_files_to_18tb_windows_freezes_all/",
          "publishedOn": "2022-12-08T12:24:35.000Z",
          "wordCount": 18877,
          "title": "When copying files to 18tb, windows freezes & all usb devices aren’t recognized. What task manager function can I restart to make the usb visible again without restarting the computer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfwzx8/how_interested_in_making_time_capsules_are_you/",
          "author": null,
          "description": "How interested in making time capsules are you?\n Did you think about making a time capsule filled with data ?\n I'm talking in short term like 5 years of USB flash drive holding data. Home environment VS out doors ?\n Also did you ever think about making a time capsule that would hold its data for 100s of years ?\n With all the stuff lost this can be crucial in the future.\n For example the movie Nosferatu was literally ordered to be destroyed because of copyright violations it did.\n WE have it now because some tapes survived and now everything of that time is public domain so it is not a problem and a cultural treasure.\n View Poll\n    submitted by    /u/Ano_9090  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfwzx8/how_interested_in_making_time_capsules_are_you/",
          "publishedOn": "2022-12-08T12:06:16.000Z",
          "wordCount": 17860,
          "title": "How interested in making time capsules are you?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfwmdy/best_cd_drive_under_200/",
          "author": null,
          "description": "I need it to be decently fast and be able to read Blu-rays & DVDs and have a USB-C/Thunderbolt interface. I also need it to burn stuff to Blu-rays, DVDs and if possible, M-Discs.\n Can the Apple USB SuperDrive do any of that?\n    submitted by    /u/kids-ate-my-liver  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfwmdy/best_cd_drive_under_200/",
          "publishedOn": "2022-12-08T11:46:38.000Z",
          "wordCount": 16826,
          "title": "Best CD drive under $200?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfpoi4/where_to_send_old_radio_recordings/",
          "author": null,
          "description": "I literally just came across a box of cassettes in my grandfather's basement , and one contained a local radio broadcast from around 1994-1995. It seems like both sides of the tape were filled, and most of it is callers calling in to talk to Al Stanek, including my uncle who knew him. I'm pretty sure this isn't some \"crazy lost history\" type recording, but are there still archiving groups interested in any recording they can get their hands on? If so, please point me in the right direction.\n    submitted by    /u/Comrade--Banana  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfpoi4/where_to_send_old_radio_recordings/",
          "publishedOn": "2022-12-08T05:05:15.000Z",
          "wordCount": 17243,
          "title": "Where to send old radio recordings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfpeff/managed_to_recover_10k_pictures_from_a_drive_i/",
          "author": null,
          "description": "About a decade I was worried about my not backed up pictures which were on an external drive, so I went to back them up and the drive failed. Or so I thought. Repeated attempts to get the drive to spin up just resulted in a clicking head and nothing. So I put it in a drawer to eventually take to a data recovery service when I could afford it. \n Time passes, and yesterday I was doing some file management of newer pictures which needed to happen (In addition to backing them up) when I got a wild hair to plug the drive in to see what would happen. Low and behold, it spins up....sort of. Same head skipping/stalling issue. The difference this time is I can see the files and am able to copy some, for a few seconds till it freezes. \n Windows file transfer sucks for this so I try TeraCopy, pausing the transfer when it freezes, unplugging the drive, plugging it back in and starting the transfer over. This works...sort of. For whatever reason it only recognized about a third of the files this way. \n So I try again, and this time it works flawlessly without any head issues throughout the entire transfer. I saved about 130GB worth of pictures from a fairly formative time in my life sort of by accident. Now I'm sorting them properly and backing up multiple copies.\n    submitted by    /u/TwoHeadedPanthr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfpeff/managed_to_recover_10k_pictures_from_a_drive_i/",
          "publishedOn": "2022-12-08T04:51:43.000Z",
          "wordCount": 16924,
          "title": "Managed to recover 10k pictures from a drive I thought was toast.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfovzf/if_you_were_curious_about_the_16tb_drive_from/",
          "author": null,
          "description": "submitted by    /u/bricksplus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfovzf/if_you_were_curious_about_the_16tb_drive_from/",
          "publishedOn": "2022-12-08T04:27:24.000Z",
          "wordCount": 18595,
          "title": "If you were curious about the 16TB drive from Black Friday",
          "imageUrl": "https://preview.redd.it/8ik2lbos7n4a1.jpg?blur=40&format=pjpg&auto=webp&s=0f92213f1e2d8c3b0bef54acafe166b6528e8c66"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfjp7i/toshiba_x300_hdwe150_5tb_stoped_being_recognized/",
          "author": null,
          "description": "submitted by    /u/NSG01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfjp7i/toshiba_x300_hdwe150_5tb_stoped_being_recognized/",
          "publishedOn": "2022-12-08T00:44:18.000Z",
          "wordCount": 18251,
          "title": "Toshiba X300 HDWE150 5TB stoped being recognized when tried to install on my server. After bringing it back to my pc and much struggle to initialize, I was surprised by this in hddsentinel. It was perfect when I uninstalled it and I didn't drop or anything. 2,5y old and 2y of warranty.",
          "imageUrl": "https://preview.redd.it/djibg3hwlk4a1.png?auto=webp&s=a44ce9cd3e729f7964e3fd36e959cecc220c7cc3"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfj6of/any_idea_how_to_get_video_from_docuseek/",
          "author": null,
          "description": "I have an assignment to watch a documentary from Docuseek but I can't play the film in 2x to get through it quicker. I wanted to see if anyone knew a way I could rip it or download it somehow so I can speed it up to watch.\n    submitted by    /u/Official_Person  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfj6of/any_idea_how_to_get_video_from_docuseek/",
          "publishedOn": "2022-12-08T00:22:44.000Z",
          "wordCount": 18319,
          "title": "Any idea how to get video from Docuseek?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfixp7/my_parents_dont_stream_tv_but_my_data_hoarding/",
          "author": null,
          "description": "submitted by    /u/AshleyUncia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfixp7/my_parents_dont_stream_tv_but_my_data_hoarding/",
          "publishedOn": "2022-12-08T00:12:47.000Z",
          "wordCount": 19024,
          "title": "My parent's don't stream TV, but my data hoarding and Blu-Ray archival skills mean I can make them nice discs full of MP4's for their Blu-Ray player to get them content they're missing and make it an Xmas gift.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfhzzp/trouble_with_teracopy_copying_files_are_creating/",
          "author": null,
          "description": "I have used teracopy for years now with no problems but last week or so every time I try to copy a file to a folder that contains a space ex. Bob Smith it will create a new folder with the item and that folder will be named just bob. If I remove the space ex. Bobsmith it will copy to that folder fine. I’m at my wits end I’ve reinstalled teracopy about 12 times along with every version and no luck. THIS DOES NOT HAPPEN WHEN HAING EXPLORER to transfer files. Send help.\n    submitted by    /u/Strikeblitz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfhzzp/trouble_with_teracopy_copying_files_are_creating/",
          "publishedOn": "2022-12-07T23:35:00.000Z",
          "wordCount": 18265,
          "title": "Trouble with teracopy copying files are creating new folders.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfg8e2/my_goal_for_2023_3000_terrabytes/",
          "author": null,
          "description": "I just finished setting up my first Asustor as6510t, loaded it with 10 20tb drives. I got the refurbs from Amazon and ran badblocks on them, took nearly 2 weeks to finish four complete block by block write/read's but they all come back clean. So my plan is to buy one each month, so that by end of 2023 I will have 15 of them. three replicas x five 200tb units. So a total of 3PB with one PB of addressable storage. \n As for the individual units, suggestions? I was going to just go with straight Raid-0 or JBOD setting. I am still learning how ADM works but I love how I could use these units to also host docker and they could play host to some container services. \n Other concerns I need to work out are power, brown outs in winter and summer are not uncommon, but also the networking. These units can take up to 10gb for it's primary connector and I'd love to have all 15 for purposes of replication but if it's too pricey I can live with a 1gb switch instead. \n Suggestions?\n    submitted by    /u/TheIllusioneer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfg8e2/my_goal_for_2023_3000_terrabytes/",
          "publishedOn": "2022-12-07T22:28:33.000Z",
          "wordCount": 17901,
          "title": "My goal for 2023 - 3,000 Terrabytes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zffp7h/a_real_site_to_download_high_res_free_use/",
          "author": null,
          "description": "submitted by    /u/RustedBlade7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zffp7h/a_real_site_to_download_high_res_free_use/",
          "publishedOn": "2022-12-07T22:10:12.000Z",
          "wordCount": 18304,
          "title": "A REAL site to download high res, free use, masterpieces. The Prado museum has digitized its entire collection and its available for non commercial use, completely free",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zff3it/in_the_market_for_a_cheap_4u_rackmount_case_that/",
          "author": null,
          "description": "In the market for a cheap 4u rackmount case that will fit a e-atx motherboard and obviously plenty of space to put drives\n    submitted by    /u/Lucky_Reputation5017  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zff3it/in_the_market_for_a_cheap_4u_rackmount_case_that/",
          "publishedOn": "2022-12-07T21:49:41.000Z",
          "wordCount": 18020,
          "title": "In the market for a cheap 4u rackmount case that will fit a e-atx motherboard and obviously plenty of space to put drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfek70/screenshot_multiple_urls_save_pictures_from_urls/",
          "author": null,
          "description": "Hey guys, I am looking for software that is capable of taking screenshots of a large amount of URLs. It would also be nice if it was capable of monitoring URL’s and taking a screenshot if the URL changes. I am also looking for software or an extension that is capable of retrieving images in the original resolution from multiple URLs. Something similar to Image Picka but capable of retaining the original resolution.\n Any information regarding these matters would greatly be appreciated, thanks.\n    submitted by    /u/Humbaba3344  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfek70/screenshot_multiple_urls_save_pictures_from_urls/",
          "publishedOn": "2022-12-07T21:31:11.000Z",
          "wordCount": 18399,
          "title": "Screenshot Multiple URLs & Save Pictures From URLs In Original Resolution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfejpo/this_doesnt_sound_normal_right_seagate_exos_8tb/",
          "author": null,
          "description": "submitted by    /u/Quadrubo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfejpo/this_doesnt_sound_normal_right_seagate_exos_8tb/",
          "publishedOn": "2022-12-07T21:30:45.000Z",
          "wordCount": 18434,
          "title": "This doesnt sound normal right? Seagate exos 8TB drives 7200rpm",
          "imageUrl": "https://external-preview.redd.it/lTRualSxe3nTMFtEIPqRRHamvbQRcyEVeY7DXjWmPJA.png?format=pjpg&auto=webp&s=c34196e4baeaabea2eb616c450cfbb8d20ee3d57"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfdk7b/software_for_scanning_notebooks/",
          "author": null,
          "description": "I have a bunch of A5 notebooks I'm looking to scan into a digital format. I have a scanner thanks to recommendations from here. The question is, what software do I use? \n  \nThe autofeed is about 20 pages; the notebooks, around 168. Each group will need to be merged (along with other potential material (a title sheet describing the notebook, pics of the interior cover, etc.). \n It's all handwritten, so OCR is not a requirement\n Looking to produce an EPUB or PDF format--something generically available. \n Running MacOS\n  \nAny recommendations?\n    submitted by    /u/MrGuilt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfdk7b/software_for_scanning_notebooks/",
          "publishedOn": "2022-12-07T20:57:10.000Z",
          "wordCount": 17434,
          "title": "Software for Scanning Notebooks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfcnao/sata_power_cables/",
          "author": null,
          "description": "Hello! I have to to mount my SSDs on the back of the motherboard tray. Sadly my stock PSU Sata power cables don't fit, due to being \"angled\" (corsair rm850x). \n I have read a lot and come across a term \"molded\" tho I haven't found a clear image to be able to distinguish this confidently myself. \n I have ordered these 3 cables, 2 Y splitters and 2 single extensions. Which would you recommend? Or something else? \n https://www.amazon.de/-/en/Sharkoon-Y-Power-Cable-Y-Cable-Black/dp/B01FMZ6TR0/ref=sr_1_1?crid=1YBGZHOFO96RY&keywords=sharkoon+sata&qid=1670444295&s=industrial&sprefix=sharkoon+sata%2Cindustrial%2C66&sr=1-1 \n https://www.amazon.de/gp/product/B07DXF94K9/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&psc=1 \n https://www.amazon.de/gp/product/B0B18F2J64/ref=ppx_yo_dt_b_asin_title_o05_s00?ie=UTF8&psc=1\n    submitted by    /u/homavfx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfcnao/sata_power_cables/",
          "publishedOn": "2022-12-07T20:25:38.000Z",
          "wordCount": 16805,
          "title": "Sata Power Cables",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfch0a/what_drive_bay_case_is_this/",
          "author": null,
          "description": "Looks to have 4 bays of 5 drives each, asking what case this is? \n https://i.imgur.com/9v1kTcN.png\n    submitted by    /u/X73RN4L  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfch0a/what_drive_bay_case_is_this/",
          "publishedOn": "2022-12-07T20:19:33.000Z",
          "wordCount": 16549,
          "title": "What drive bay case is this?",
          "imageUrl": "https://external-preview.redd.it/0lWEiB3KlNlITlEzox7ySo9eH-hIUGbi9RNcPjHVIjU.png?auto=webp&s=bf6dcf273c84d53dc6af45d17c651ec81ee43166"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zfaj4u/what_turned_you_into_a_data_hoarder/",
          "author": null,
          "description": "Did you watch your favourite YouTube channel get deleted and never come back? Do you refuse to pay for entertainment? Or were you just born this way? I wanna hear your stories.\n    submitted by    /u/bagelsandcupcakes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zfaj4u/what_turned_you_into_a_data_hoarder/",
          "publishedOn": "2022-12-07T19:13:12.000Z",
          "wordCount": 21492,
          "title": "What turned you into a Data Hoarder?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zf9v5u/advice_on_archiving_all_videos_from_a_patreon/",
          "author": null,
          "description": "A Patreon creator I subscribe to has videos going back to 2018 and I would like to archive all these for my future reference. Is there any tool that would allow me to scrape/download all these?\n Thanks!\n    submitted by    /u/OracleDBA  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zf9v5u/advice_on_archiving_all_videos_from_a_patreon/",
          "publishedOn": "2022-12-07T18:50:39.000Z",
          "wordCount": 18253,
          "title": "Advice on archiving all videos from a Patreon creator.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zf9j7c/any_idea_where_can_i_borrow_or_rent_an_open_reel/",
          "author": null,
          "description": "Found some 50 yrs old magnetic tapes (Philips DP8) with family recordings that I'd like to digitize. \n Last choice would be to buy one on ebay or similar, if no other options.\n    submitted by    /u/newbie_01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zf9j7c/any_idea_where_can_i_borrow_or_rent_an_open_reel/",
          "publishedOn": "2022-12-07T18:39:22.000Z",
          "wordCount": 15977,
          "title": "Any idea where can I borrow or rent an open reel tape player in Toronto?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zf98sd/picked_this_up_at_an_auction_i_have_some_questions/",
          "author": null,
          "description": "submitted by    /u/paulyshorewantscrack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zf98sd/picked_this_up_at_an_auction_i_have_some_questions/",
          "publishedOn": "2022-12-07T18:29:39.000Z",
          "wordCount": 17061,
          "title": "Picked this up at an auction, I have some questions.",
          "imageUrl": "https://preview.redd.it/j0xg5xicri4a1.jpg?auto=webp&s=a8dc99e4fa96716c4fabf8f78e6987e7ea6da8d2"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zf7rnq/storage_advice/",
          "author": null,
          "description": "I want to replace my storage setup with one new big boy, please help me decide!\n Current Build:\n Compute:\n  \nDL380 G10 24x SFF, 2x 4114 Xeon, 256GB RAM + iodrives in PCIe Slots\n DL380 G9 12x LFF, 2x 2667v4, 256GB RAM + iodrives in PCIe Slots\n  \nStorage:\n  \nDL380 G9 12x LFF, 2x 2650v4, 192GB RAM (Fully filled with WD Golds)\n MSA 2040 12x LFF filled with some shucked and some wd drives\n  \n​\n currently i run some minor vm's and the main debian zfs vm on the dl380g9(storage)\n i got esxi installed and im passing through the controllers needed to see my disks in the vm directly\n ​\n Current options:\n A: Selfbuild new Server with an SM or Chenbro case (24/36x LFF) and either barebone debian or passthrough with controller again\n B: used SAN like the 3par 8000 and giving it an vm on the compute cluster\n ​\n Main concern is future upgrades and power as im currently at 0,83€ per kw/h also soonish switching from vmware to xen or proxmox whatever fits me better after testing\n ​\n may the hoarding help!\n    submitted by    /u/thalooka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zf7rnq/storage_advice/",
          "publishedOn": "2022-12-07T17:41:02.000Z",
          "wordCount": 18348,
          "title": "Storage advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zf76c7/iphone_photos_to_wd_easystore_through_pc/",
          "author": null,
          "description": "I'm trying to move years of photos from an iphone to a WD Easystore and it just not working. I've tried with two different model iphones and on both, using file explorer every time I copy a folder from the iphone it will be missing more than half the photos. \n Does anyone know how to transfer photos from an iphone to an external hard drive through a pc?\n Many years ago this was easy and quick but now it simply won't work.\n    submitted by    /u/DatasTemporalLobe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zf76c7/iphone_photos_to_wd_easystore_through_pc/",
          "publishedOn": "2022-12-07T17:21:01.000Z",
          "wordCount": 17429,
          "title": "Iphone photos to WD Easystore through PC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zf65fx/ssdhdd_maintenance_questions/",
          "author": null,
          "description": "Hi all. I have Windows 10 and for the longest time I've wanted to know if there's anything I can do differently or better to maintain my drives. I have mixed SATA SSDs, NVMes and HDDs, 12 total.\n I know Windows does TRIM on SSDs, but I don't know...there's something satisfying about running a command or a maintenance cycle that I can see working and see the results of, if you know what I mean.\n Do you run maintenance on your drives regularly? Any recommendations of what I can do to keep them running well? Lastly, do you set Windows to turn off your drives after X amount of minutes in power options, and do you use hibernate? Does hibernate harm SSDs with the writes?\n    submitted by    /u/kingofallnorway  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zf65fx/ssdhdd_maintenance_questions/",
          "publishedOn": "2022-12-07T16:46:34.000Z",
          "wordCount": 19790,
          "title": "SSD/HDD maintenance questions.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zf586c/how_do_i_create_filters_in_downthemall/",
          "author": null,
          "description": "Are there any clear instructions on how to create filters in DownThemAll? (Firefox ver)\n I need to create a filter that selects all urls with this structure: serverXX.sampleurl.net/ With XX being a completely random number between 0 an 999.\n What method is DownThemAll using for filters?, are there any good instructions for it?, and is this possible?\n Thanks in advance!\n    submitted by    /u/mactep66  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zf586c/how_do_i_create_filters_in_downthemall/",
          "publishedOn": "2022-12-07T16:15:02.000Z",
          "wordCount": 17175,
          "title": "How do i create filters in DownThemAll ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zf3yd7/unmanic_starter_setup/",
          "author": null,
          "description": "I used to use Tdarr, but I'm currently trying Unmanic because it seems a bit simpler and easier to configure. However, whilst there are lots of installation write-ups, there isn't any plugin/job/process/test setup tutorials for 'standard' configurations that people might want to use. Anyone got any sources for these?\n I'm basically wanting to set it up to:\n  \nUse the intel quicksync plugin\n Only process files > 5GB\n Transcode to reduce them down using h264, but at a lower bitrate etc so aiming to get about 1GB/hour\n Only run processing/transcoding between certain hours (e.g., 1am => 5am)\n  \nI've added the plugin, a worker, and the filesize test (which I think does #2) but just want to see if somebody else has written up their settings so I can make sure I've got it right before I point it at my library. :)\n Running it on a Synology via Docker, although I don't think that's relevant for this question.\n    submitted by    /u/botterway  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zf3yd7/unmanic_starter_setup/",
          "publishedOn": "2022-12-07T15:31:00.000Z",
          "wordCount": 18139,
          "title": "Unmanic Starter Setup?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zezdld/i_got_a_cheap_crucial_ssd_for_os_about_1_or_2/",
          "author": null,
          "description": "submitted by    /u/samforelli  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zezdld/i_got_a_cheap_crucial_ssd_for_os_about_1_or_2/",
          "publishedOn": "2022-12-07T11:58:39.000Z",
          "wordCount": 18036,
          "title": "I got a cheap Crucial SSD for OS about 1 or 2 years back, and it appears I churned through a lot of it's health in this short time. Any idea how long my SSD would be working for? It's only holding OS for a PC I use as a mass storage unit that stays powered on almost 24/7 (I run VMs there too)",
          "imageUrl": "https://preview.redd.it/cet21u0jsg4a1.png?auto=webp&s=b7c0f724f0db4bace82ead4806ecc9b671d56de8"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zeseu3/nintendo_power_scans_disappeared_from_the/",
          "author": null,
          "description": "submitted by    /u/AbolishDisney  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zeseu3/nintendo_power_scans_disappeared_from_the/",
          "publishedOn": "2022-12-07T04:52:42.000Z",
          "wordCount": 18603,
          "title": "‘Nintendo Power’ Scans Disappeared From The Internet Archive",
          "imageUrl": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?auto=webp&s=e3d2e624576871ac1282ee75a9064e8fd20baa6f"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zenzc4/smart_stats_from_manufacturer_recertified/",
          "author": null,
          "description": "submitted by    /u/george8881  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zenzc4/smart_stats_from_manufacturer_recertified/",
          "publishedOn": "2022-12-07T01:09:57.000Z",
          "wordCount": 18483,
          "title": "SMART stats from manufacturer recertified Ultrastar. Why were these not wiped, and what does this mean?",
          "imageUrl": "https://preview.redd.it/n5u0qcowld4a1.png?auto=webp&s=50bd33b16573493a072e807492b75396a37995a0"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zem53b/follow_up_should_i_just_get_two_hdds_put/",
          "author": null,
          "description": "https://www.reddit.com/r/DataHoarder/comments/zea4ge/what_is_better_for_storage_reliability_for/\n I am building a small home server. Budget it about $700. Its main uses will be Plex, a general file server, a place to hold important data (wedding videos, youtube raw footage) and run a Valheim dedicated server. \n I had originally planned on using one 8TB HDD as the storage drive for Plex movies. I was then going to store important data on two mirrored 1TB SSDs. But following my previous post I feel that these 1TB SSDs are a waste since if I delete a file, the mirrored will also be deleted. I could return them to free up budget for another 8TB HDD (16TB total). \n Should I just get two HDDs, put everything on them, then backup important stuff in cloud storage, and/or an external location? Or stick with the original plan with the 1TB mirrored SSDs/8TB HDD?\n    submitted by    /u/thefreymaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zem53b/follow_up_should_i_just_get_two_hdds_put/",
          "publishedOn": "2022-12-06T23:45:27.000Z",
          "wordCount": 19586,
          "title": "Follow Up: Should I just get two HDDs, put everything on them, then backup important stuff in cloud storage, and/or an external location? Or use 1TB mirrored SSDs/8TB HDD for general storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zelg4f/how_would_you_set_up_4x4tb_4x10tb_on_truenas_core/",
          "author": null,
          "description": "Just wanted you smart folks' opinion. I don't hoard anything super important. The few important things I do store, I have multiple backups of. With that out of the way, how would you set up 8 total drives on TrueNAS? I'm thinking 4x4TB in vdev, and 4x10TB in another vdev, both in the same pool- with raidZ1 setup. I watch the stuff I hoard sometimes, by streaming through jellyfin. I'm relatively new to the scene so very grateful for your input.\n    submitted by    /u/ProximtyCoverageOnly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zelg4f/how_would_you_set_up_4x4tb_4x10tb_on_truenas_core/",
          "publishedOn": "2022-12-06T23:17:49.000Z",
          "wordCount": 18907,
          "title": "How would you set up 4x4TB + 4x10TB on TrueNAS Core?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zeldfq/first_nas_help/",
          "author": null,
          "description": "This is my part list https://au.pcpartpicker.com/list/gMFLxs and I'll be using unraid.\n For plex, do I need a GPU on NAS or can I use NVIDIA Shield Pro. I have no intention on streaming remotely, all will be local.\n Also, if I do need a GPU; is P2000 good card or shall I use RTX 1060 or above?\n    submitted by    /u/2_states  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zeldfq/first_nas_help/",
          "publishedOn": "2022-12-06T23:15:02.000Z",
          "wordCount": 18720,
          "title": "First NAS help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zel3i3/ironwolf_pro_vs_exos/",
          "author": null,
          "description": "Greetings, r/DataHoarder… hoarders.\n I’m currently looking at picking up a new 16 TB drive, either the IronWolf Pro (ST16000NE000) or the Exos (ST16000NM001G).\n The prices are fairly similar, work the IWP being slightly more expensive.\n A couple of years ago the IronWolf Pro was what I thought best, but I’ve not encountered the Exos before. A quick search suggests they’ll be louder, but doesn’t say much otherwise.\n Oh wise hoarders, help me choose a drive? I’d prefer quieter, but I can always get a more soundproof enclosure (plan is to eventually have multiples of the same disk type in a new NAS) — the question is, what’re the real differences, and is there a reason the seemingly newer Exos is cheaper?\n Thanks! 🙏\n    submitted by    /u/allyafterdark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zel3i3/ironwolf_pro_vs_exos/",
          "publishedOn": "2022-12-06T23:04:34.000Z",
          "wordCount": 19180,
          "title": "IronWolf Pro vs. Exos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zekv2x/help_with_moving_files_to_a_folder_while/",
          "author": null,
          "description": "Hi everyone, I've this Powershell script which reads every line containing the full path to a file in file3.txt and removes it.\n What I want is for the script to not remove, but move the files to E:\\Recycle while retaining folder structure. Is that possible and can someone please help me?\n Example\n E:\\testdownload\\download\\hello\\100\\[100] [1961850]\\0001_01.png \n Desired result\n E:\\Recycle\\testdownload\\download\\hello\\100\\[100] [1961850]\\0001_01.png \n Powershell script\n Get-Content -LiteralPath \".\\file3.txt\" | Where-Object { Test-Path -PathType Leaf -LiteralPath $_ } | % { [Management.Automation.WildcardPattern]::Escape($_) } | Get-Item -Force | Remove-Item -Force \n    submitted by    /u/Jungy1eong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zekv2x/help_with_moving_files_to_a_folder_while/",
          "publishedOn": "2022-12-06T22:55:48.000Z",
          "wordCount": 19656,
          "title": "Help with moving files to a folder while retaining folder structure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zejoxg/what_power_connector_is_this_found_this_quantum_8/",
          "author": null,
          "description": "submitted by    /u/Osiris834  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zejoxg/what_power_connector_is_this_found_this_quantum_8/",
          "publishedOn": "2022-12-06T22:09:23.000Z",
          "wordCount": 19077,
          "title": "What power connector is this? Found this Quantum 8 LTO-5 drive at the dump.",
          "imageUrl": "https://preview.redd.it/dg4rzu0xpc4a1.jpg?auto=webp&s=4a058ed9224dd75b2a875ec29d83cb9d52967500"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zejb09/hdd_listed_as_new_return_it_or_no/",
          "author": null,
          "description": "submitted by    /u/Adamsandlersshorts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zejb09/hdd_listed_as_new_return_it_or_no/",
          "publishedOn": "2022-12-06T21:54:15.000Z",
          "wordCount": 19106,
          "title": "HDD listed as new. Return it or no?",
          "imageUrl": "https://external-preview.redd.it/0PFAX-aIH4Dh7ZolxjORgvWW5-1WS22fzauVKWQbQv8.png?auto=webp&s=bef069c540f52d5381ff8058d66815ddcb7ac1d7"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zehu4q/offsite_backup_at_friend_encryption_and_syncing/",
          "author": null,
          "description": "Hi there,\n I have about 12TB of data on my local NAS. Just purchased an 18TB drive to have that data backed up locally. For my third copy, after researching cloud providers (cost, speed, and reliability), I've come to the conclusion that it's best to set up another NAS/server that I will plug in at a friend's place.\n I have two things I would like feedback on:\n  \nEncryption: what do you recommend to encrypt my data off-site? Assuming the server is always connected to the internet when on, is there a way to make it so that when the computer starts up, the encrypted data is not accessible, where I get an email or notification to do somehow remotely unlock the data? What I'm trying to guard against is someone taking the server and accessing my private data. Assuming it gets stolen, I'd like to know that the data is encrypted and not accessible.\n \nSyncing: given this data size (12TB now, 20TB in 5 years), is it best to keep the data in sync using Syncthing? Or would the size cause issues for Syncthing? If so, I would just have a daily Cron job to rsync the data.\n \n Welcome any insights you all are willing to share. Thanks.\n    submitted by    /u/vinhdizzo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zehu4q/offsite_backup_at_friend_encryption_and_syncing/",
          "publishedOn": "2022-12-06T20:56:18.000Z",
          "wordCount": 20338,
          "title": "Off-site backup at friend: encryption and syncing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zee9aq/archiving_official_documents_as_an_act_of_radical/",
          "author": null,
          "description": "submitted by    /u/Crazy-Red-Fox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zee9aq/archiving_official_documents_as_an_act_of_radical/",
          "publishedOn": "2022-12-06T18:36:18.000Z",
          "wordCount": 18944,
          "title": "Archiving official documents as an act of radical journalism - By Maria Bustillos",
          "imageUrl": "https://external-preview.redd.it/c5tgqEUoYNUKkXMl3bPfHUu1g81BANHSaiJC2QEOm8o.jpg?auto=webp&s=68ea02111fddcf53bca5e502969df4a814079fa2"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zedcds/500gb_synced_folder_showing_as_448gb_on_another/",
          "author": null,
          "description": "I have a folder that is approximately 500GB with about 80,000 files in it (mostly PDFs) on a machine which is synced with a service similar to dropbox. In seeking to do routine backups, and remove this data from my main machine eventually, I installed the sync service on another machine, and set it out to 'sync'. \n The new machine now reports the sync is complete, however when I do a rightclick to check properties, the report between the two machines does not match. The file count and storage count differ, by several gigs and thousands of files.\n I can see a couple of possibilities: \n  \nThe two machines count files/space differently, since they are different OS, which seems weird but possible. The reporting does not reflect reality. I am unsure of how I would validate this given it's thousands of files. \n There is some amount of data loss on syncing between machines (this would be very bad). This could be due to some error of transfer I suppose, file incompatibility or corruption?\n  \nI'm not even sure what the correct search term would be for this phenomenon except 'data loss on transfer'\n I can provide exact numbers if helpful, if there is some kind of calculation\n    submitted by    /u/Extra_Negotiation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zedcds/500gb_synced_folder_showing_as_448gb_on_another/",
          "publishedOn": "2022-12-06T18:00:18.000Z",
          "wordCount": 18907,
          "title": "~500GB synced folder showing as ~448GB on another machine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zedb3v/any_better_app_for_a_wd_ex2_ultra_that_tells_me/",
          "author": null,
          "description": "I got a WD EX2 Ultra a few years ago (I didn't do any research; it was a good deal and now I'm stuck with this). My drives are getting full, and I need to swap them with higher capacity, but the challenge is that I can't simply swap them, there are some folders / data that I need on the NAS, so I need to move some data to the new drive. \n Problem is that WD's apps are terrible, and I was wondering if there's any 3rd party app that makes it easy to browse data by \"volume\"\n    submitted by    /u/fatalskeptic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zedb3v/any_better_app_for_a_wd_ex2_ultra_that_tells_me/",
          "publishedOn": "2022-12-06T17:59:10.000Z",
          "wordCount": 18176,
          "title": "Any better app for a WD EX2 Ultra that tells me what's on what volume?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zedadb/looking_for_24port_expander_without_sacrificing/",
          "author": null,
          "description": "Hey all,\n So currently, I've got 14 drives (varying from 8tb to 14tb) in a Fractal XL7 case.\n It's becoming apparent that I'm going to need more space. However, I'd like to stay on my current OS and not replace the CPU/RAM/etc. that I've got.\n It seems to me that an external JBOD SAS is probably my best option, but I'm running into issues due to my lack of experience with these. Most of what I'm finding in the price range I want to spend (less than $500 by the time I add in the cables I'd need) won't do above SATA2. Does anyone have any advice?\n Definitely ok (and expecting) used hardware. Also my ultimate goal here is to buy a bunch of new 16tb drives and stick those in it, create a RAID6 array, copy my other data over, and then add those old drives to the array. \n I'd appreciate any advice here!\n    submitted by    /u/drparton21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zedadb/looking_for_24port_expander_without_sacrificing/",
          "publishedOn": "2022-12-06T17:58:19.000Z",
          "wordCount": 18293,
          "title": "Looking for 24-port expander without sacrificing speed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zeczge/does_moving_and_merging_a_folder_in_mega_keep_1/",
          "author": null,
          "description": ".\n    submitted by    /u/AnonCuriosities  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zeczge/does_moving_and_merging_a_folder_in_mega_keep_1/",
          "publishedOn": "2022-12-06T17:45:32.000Z",
          "wordCount": 18195,
          "title": "Does \"moving and merging\" a folder in Mega keep 1 copy and no duplicates after the merge, and does it keep the oldest file assuming unedited? This is pretty important for me to know due to copyright stuff.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zec3vd/has_anyone_experienced_issues_with_terramaster/",
          "author": null,
          "description": "Long time follower of this subreddit and first time poster. I’m fairly new to DAS.\n I was wondering if anyone else has experience similar issues with their Terramaster D5-300 DAS and shucked WD 20TB WD2000EDGZ drives.\n I’m not using this in RAID, just default single disk mode. \n I recently bought both and have began the install process and powering it on. I’ve noticed the 2x 20TB causes the lights to turn solid orange and repeated beeping. (All drives have been formatted already for Mac OS Extended Journaled ahead of installation.) This happens in any slot I put either 20TB drives in and both when they’re both in. I’ve pulled the drives out and connected the 20TB drives using a USB to SATA cable and they are recognized and works fine.\n However, my 2x 14TB WD140EDGZ drives and 1x 10TB WD100EMAZ can be placed in any slot and are recognized and works as intended. When all 5 drives are in, only the 20TBs exhibit the orange light and beeping from the DAS.\n There isn’t much documentation about this online or on their forums and thought to ask the community if they had similar experiences as I wait for a response from their support. Any insights or advice would be appreciated, thanks in advance.\n    submitted by    /u/RayRCircle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zec3vd/has_anyone_experienced_issues_with_terramaster/",
          "publishedOn": "2022-12-06T17:10:25.000Z",
          "wordCount": 19539,
          "title": "Has anyone experienced issues with Terramaster D5-300 and shucked WD 20TB WD2000EDGZ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zebqda/having_issues_with_lsi_megaraid_sas_2208_disks/",
          "author": null,
          "description": "Update: The specific model is:\n DELL 0HPDKH 9286CV-8e MEGARAID SAS \n I have this LSI MegaRAID SAS 2208 controller that has been working fine. I re-installed ubuntu (I messed up the boot partition on accident) and now am having issues with drives not showing up after reboots. The kernel log shows the board failing to init.\n  \n[ 256.905504] megaraid_sas 0000:41:00.0: Failed to transition controller to ready from megasas_init_fw! \n [ 256.905657] megaraid_sas 0000:41:00.0: Failed from megasas_init_fw 6548\n  \nI went to bed last night after hours of reboots and messing with this thing to wake up this morning with all drives showing up?!\n Fast forward to some updates I did and a required reboot and now again the drives are all missing.\n Does anyone have any ideas why this is happening? I mean I understand that the card is not initialized properly. Just not sure why.\n    submitted by    /u/mak3rdad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zebqda/having_issues_with_lsi_megaraid_sas_2208_disks/",
          "publishedOn": "2022-12-06T16:55:40.000Z",
          "wordCount": 20151,
          "title": "Having issues with LSI MegaRAID SAS 2208 disks not appearing after reboot.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zea4ge/what_is_better_for_storage_reliability_for/",
          "author": null,
          "description": "I'm planning to build my own home server. I had originally planned to put sensitive data (i.e. wedding footage, youtube footage, photos) on two SSDs and mirror them. And then have a HDD for all other junk (i.e. movies), which given my price point I'm not planning to mirror these HDDs. \n Is it a good idea to store my sensitive data on two mirrored SSDs, or should I instead mirror two HDDs and throw all data on them? Thanks.\n    submitted by    /u/thefreymaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zea4ge/what_is_better_for_storage_reliability_for/",
          "publishedOn": "2022-12-06T15:51:52.000Z",
          "wordCount": 20386,
          "title": "What is better for storage reliability for sensitive data, hdd or ssd?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ze9a7w/best_method_to_add_drives_to_ds920/",
          "author": null,
          "description": "Plan to upgrade my DS920+ (4Bays). I currently have this NAS running 3 Drives which are 9,12 & 12 TB WD White and want to remove the 9TB drive and add 2x 20TB WD Pro drives. I am currently using SHR(Synology Hybrid Raid) and running DSM 6.2. Need advice on the best, most efficient and the fastest way to do this. Which would you guys recommend ?\n 1.Add one 20TB drive in 4th bay Use \"Replace Drive\" and let the array build it and then once its complete, remove the 9TB drive and then \"Add Drive\" the next 20TB Drive\n OR\n 2.Pull out all the data from the NAS which is currently 16TB occupied space while keeping the pool intact and then repeat Step 1 ?\n Also, I am currently on DSM 6.2. Do you guys recommend upgrading to DSM 7. Will DSM 6.2 support 20TB drives ?\n    submitted by    /u/Count_pooku  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ze9a7w/best_method_to_add_drives_to_ds920/",
          "publishedOn": "2022-12-06T15:16:02.000Z",
          "wordCount": 19084,
          "title": "Best method to add drives to DS920+",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ze66i9/best_way_to_copy_files_off_of_an_hdd_with_a_lot/",
          "author": null,
          "description": "This drive is 250GB and there is almost 205GB used. I already have it backed up to GDrive (100%) and my main external drive (75%). I would like to make another copy onto another drive of the full contents of the drive which is only on the original and GDrive. My internet is about 50Mbit/s, so I want to avoid downloading from drive. What is the best way to do this?\n    submitted by    /u/donutdoode  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ze66i9/best_way_to_copy_files_off_of_an_hdd_with_a_lot/",
          "publishedOn": "2022-12-06T13:00:57.000Z",
          "wordCount": 18065,
          "title": "Best way to copy files off of an HDD with a lot of hours?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ze5hni/when_you_tryna_shuck/",
          "author": null,
          "description": "submitted by    /u/MINHDOEKOE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ze5hni/when_you_tryna_shuck/",
          "publishedOn": "2022-12-06T12:30:45.000Z",
          "wordCount": 20280,
          "title": "When you tryna shuck",
          "imageUrl": "https://preview.redd.it/6269w8iou94a1.jpg?auto=webp&s=c2e4e6568ed09b0c1411d8ccd58a35fd28bab261"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ze3op9/saw_this_post_on_dpreview_and_wanted_to_share_it/",
          "author": null,
          "description": "https://www.dpreview.com/forums/thread/4686005\n Steve Digicams is no more, hoped someone manage to archive it\n    submitted by    /u/VirtualEffort8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ze3op9/saw_this_post_on_dpreview_and_wanted_to_share_it/",
          "publishedOn": "2022-12-06T11:09:42.000Z",
          "wordCount": 16705,
          "title": "Saw this post on DPreview and wanted to share it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/ze16u7/mini_itx_asrock_died_twice_suggestions_on_an/",
          "author": null,
          "description": "Hi all,\n I have had my unraid server out of commission for a while since the motherboard (ASROCK C2750d4i) died year ago. I sent it off to get fixed under warranty via advice on reddit and was contacted by ASROCK EU team on reddit itself. On return, it worked for a few months before dying again.\n I want to get it back up and running for family photos/4k videos and need a reliable alternative.\n - The mini-itx would need to fit snug, I am using a SilverStone SST-DS380 (20tb x 8 bay enclosure + 1xSSD).\n - Preferably be low powered. If it has a built-in low-powered CPU, that would be a plus. I do have a spare 4770k and i5 from the same generation lying around spare \n - An onboard controller to support 8+ drives.\n I am not looking for anything impressive. It will just need to be running at all times and be used as an accessible network drive around the house and running a plex server to access family media. Nothing more.\n ​\n Any ideas please on what to replace with?\n https://www.silverstonetek.com/en/product/info/server-nas/DS380/\n https://www.asrockrack.com/general/productdetail.asp?Model=C2750D4I#Specifications\n Edit: suggestions of specific boards would be much appreciated\n    submitted by    /u/Kenzo86  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/ze16u7/mini_itx_asrock_died_twice_suggestions_on_an/",
          "publishedOn": "2022-12-06T09:04:30.000Z",
          "wordCount": 17922,
          "title": "Mini ITX ASROCK died twice. Suggestions on an alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdvj26/what_are_your_records_for_failing_drives_that/",
          "author": null,
          "description": "submitted by    /u/vee_lan_cleef  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdvj26/what_are_your_records_for_failing_drives_that/",
          "publishedOn": "2022-12-06T04:39:12.000Z",
          "wordCount": 23212,
          "title": "What are your records for failing drives that lasted far longer than you expeted? Here is my old Seagate 2TB drive with 7.5 years of nonstop usage that has been slowly failing over the last 2 years.",
          "imageUrl": "https://preview.redd.it/og5p45mrh74a1.png?auto=webp&s=ab81842cf378d6c461788cd829a4129708124245"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdreh4/how_to_setup_new_professional_photo_archives/",
          "author": null,
          "description": "Hello all! I’m a professional photographer who makes 8-12TB a year of data. My previous system catastrophically failed on me last month, so I’m back to the drawing boards. \n I’ve already ordered most of what I think I need, but looking for validation that this is a decent idea before I set it all up, fire up the single copy of my current archive data that still exists and start to copy that over to the new system. \n Primary location/archives: Synology 920+, 4x14TB drives, RAID5\n Studio location (offsite): Synology 720+, 2x14TB, RAID1\n Cloud: Google Drive Enterprise\n My plan is to split the main array into 3 folders @ ~14TB/ea. I plan to mirror these folders to the array offsite as a backup to my primary archives. When the offsite backup array gets full, the drives in it will be pulled, put into secure storage, replaced, then mirrored with the next folder. Hopefully that system makes sense? This would hopefully result in me only needing to fuss with this backup array once every 18months or so. \n My plan had initially been to use RAID5 for the on-site system, but upon further research, it seems like people really don’t like this setup? I was hoping to have several years of my most recent archives available locally so I can pull images for proposals, website, etc, and RAID5 would give me 42TB with this set-up. ~in theory~, since I’d have a physical backup of this data, I’d be able to arduously restore the data in the case of a dramatic failure/rebuild failure?\n I’m wondering now if I’d be better off doing RAID10 for my primary archives. I think 28TB would give sufficient access to files id need to access occasionally, and it seems people find this to be a more reliable and trustworthy set-up? \n Both RAID arrays would be for archiving only, and data would very rarely be altered once it was stored. \n Money spent on drives is also not really an issue. Just want reliable, and secure. \n What do you think?\n    submitted by    /u/charliesfinger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdreh4/how_to_setup_new_professional_photo_archives/",
          "publishedOn": "2022-12-06T01:48:25.000Z",
          "wordCount": 20564,
          "title": "How to setup new professional photo archives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdr148/raid_controller_intel_rs2mb044_for_gaming/",
          "author": null,
          "description": "Brand new raid controller given to me by a friend, dumb question but can I use it for gaming? Still sealed with sticker and fully operational\n    submitted by    /u/aceves_7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdr148/raid_controller_intel_rs2mb044_for_gaming/",
          "publishedOn": "2022-12-06T01:31:51.000Z",
          "wordCount": 12746,
          "title": "Raid controller INTEL RS2MB044 for gaming?",
          "imageUrl": "https://preview.redd.it/247sogfn284a1.jpg?auto=webp&s=efc427101c3ef836f91078098f79c8b393fc7e3b"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdql4y/would_you_trust_data_on_this/",
          "author": null,
          "description": "submitted by    /u/Ventilate64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdql4y/would_you_trust_data_on_this/",
          "publishedOn": "2022-12-06T01:11:59.000Z",
          "wordCount": 20630,
          "title": "Would you trust data on this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdq1aa/safe_to_store_somewhat_important_files_on_hdd/",
          "author": null,
          "description": "I know that 76k is a lot of hours, but it would take super long to put everything on an external drive, so I have put it off for a while. Is it safe to keep stuff on this drive or do I finally back it up?\n    submitted by    /u/donutdoode  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdq1aa/safe_to_store_somewhat_important_files_on_hdd/",
          "publishedOn": "2022-12-06T00:48:37.000Z",
          "wordCount": 13024,
          "title": "Safe to store somewhat important files on HDD with 76k hours?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdp0v6/google_takeout_tips_to_extract_or_not_to_exctract/",
          "author": null,
          "description": "Hey everyone,\n I'm doing a google takeout of the tera or so of drive + photos data I have. I have about 20 50G zips downloaded, and i'll be transfering to an external SSD.\n I'm curious, should I unzip all the files before or after dropping them into the SSD, or should I not at all? \n Thank you!\n    submitted by    /u/CroustiBat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdp0v6/google_takeout_tips_to_extract_or_not_to_exctract/",
          "publishedOn": "2022-12-06T00:06:54.000Z",
          "wordCount": 21176,
          "title": "Google Takeout Tips, to extract or not to exctract",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdmfqf/nas_oses_for_a_janky_use_case_unraidtruenasothers/",
          "author": null,
          "description": "I currently have a pretty jank data hoarding setup built in an old tower with 4x4TB HDDs in a software RAID0 that is then combined with 2x16TB drives in a software RAID5, plus two JBOD SSDs for the OS and cache. Currently it's being managed with mdadm via the Cockpit project on CentOS 8 Stream. This has worked fine, but the machine that is handling my storage is also handling all of my other processing; Plex server, various VMs, game servers, etc.\n I've just purchased a new rack and plan to rackmount this machine in a Rosewill RSV-L4500U and grab a few used Dell Poweredge servers to use as ESXi hosts. In the process, I plan to add a few more drives to the array and I'd like to switch to an operating system that's more dedicated to managing storage. I've looked into TrueNAS and Unraid, but both seem to have a pretty major drawback that makes them less than ideal for me; TrueNAS appears to be exceptionally difficult to add drives to after the fact, which means I'd need to buy vastly more HDDs all at once, and Unraid suffers from poor read performance due to its single-spool nature, which isn't ideal for loading VMs off of. I still need to have this machine run the Plex server, as it'll be the only chassis that can fit the GPU for hardware transcoding. \n I might just be misunderstanding the use-cases and features of these operating systems, and if so, please do inform me! What I'm really looking for is a storage-focused OS that makes it simple to manage and monitor traditional RAID, but I'm finding that surprisingly difficult to find! \n Wondering if any of you have experience with any solutions that might fit my needs.\n    submitted by    /u/asphere8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdmfqf/nas_oses_for_a_janky_use_case_unraidtruenasothers/",
          "publishedOn": "2022-12-05T22:36:58.000Z",
          "wordCount": 13607,
          "title": "NAS OSes for a janky use case; Unraid/TrueNAS/others?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdlpvi/how_can_i_downloadconvert_js_javascript_filetype/",
          "author": null,
          "description": "I have a series of podcasts I am trying to download, to transcribe, to use for academic use. An example podcast is here: http://legaldesignpodcast.com/episode-51-joining-the-boring-revolution-with-indy-johar/. Using videodownloader on Firefox, I can generate a .js file which about about 8mb. I'm assuming that's a javascript file that gets downloaded. Normally if I got a .js file, I would think that's just a call for online streaming, but if the file is 8mb...?\n Once I've got it in .mp3 (or AAC, MP3, M4A, WAV, WMA, MOV, MPEG, MP4, WMV), generating a transcript is easy. \n It's been a long time since I've done this, but I feel there must be a simple way to either download from source as MP3 or do a simple conversion. The answer isn't to simply change the extension to .mp3 in this case. \n Another option is to source the podcast from Spotify, but all of the options I've seen are paid downloader apps with so-so reviews. There are no transcripts on either site for the podcast.\n    submitted by    /u/Extra_Negotiation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdlpvi/how_can_i_downloadconvert_js_javascript_filetype/",
          "publishedOn": "2022-12-05T22:12:42.000Z",
          "wordCount": 13263,
          "title": "How can I download/convert .js (javascript?) filetype to MP3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdkn8i/could_you_please_recommend_an_external_hard_drive/",
          "author": null,
          "description": "In my country there's mostly Toshiba and WD. There are different models of WDs in different colors. WD is more expensive. Idk why. Does it live longer ? I can also order from Amazon or Newegg, but shipment fees may make it considerably more expensive. Sorry for my poor English. Thanks in advance !\n    submitted by    /u/ro2ro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdkn8i/could_you_please_recommend_an_external_hard_drive/",
          "publishedOn": "2022-12-05T21:37:30.000Z",
          "wordCount": 12933,
          "title": "Could you please recommend an External Hard Drive of at least 2T?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdk6pp/scanning_tear_sheets_from_magazines/",
          "author": null,
          "description": "I've read what feels like countless discussions on scanners and scanning processes to the point where it makes me slightly nauseous. I'm new to it. I'm buying a scanner in January and finally embarking on my long awaited scanning journey. I intend to digitze my collection of fashion magazines - and the most important aspect of them are the images, of course. It is very important to me to do a great job with the quality of those scans and all my extensive reading brings me to conclusion that destroying my very expensive magazines is the best way to go about it, because it provides a flat scan with minimum shadows and imperfections I can edit out afterwards. I settled on an Epson Perfection V600 scanner. Good, affordable, but fairly small considering how big vintage magazines used to be. But it seems like a good starting point. Any scanning tips from experienced photo scanners would be appreciated. \n However, that is not my main issue. I tried tearing apart my first magazine today and I don't know if I did it right. A lot of the articles mentioned guillotines and specific cutters for something like this, but considering that a lot of the advertisement and editorial images inside fashion magazines tend to be spread across two pages and I don't want any gaps in between them, it seems unwise to use a cutter to cut away the entire spine and most likely several milimeters of each page in the process. So I went and did it manually, page by page. I did it carefuly and very gently and I pulled out pages as close to the spine as it was possible, but the glue or whatever it is that binds the pages together left the edges of my tear sheets quite jagged and messy looking. Is that normal? Surely, I can edit that out in Photoshop, but I would love to know if there's a way of getting cleaner edges on the tear sheets without cutting off any of the picture. I'm providing some images of my tear sheets. All help is greatly appreciated! \n Detail\n Double spread\n    submitted by    /u/cambynes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdk6pp/scanning_tear_sheets_from_magazines/",
          "publishedOn": "2022-12-05T21:22:38.000Z",
          "wordCount": 21561,
          "title": "Scanning Tear Sheets from Magazines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdk233/do_small_home_nass_need_to_care_about_bit_rot/",
          "author": null,
          "description": "Hi, \n Am new here. I've been reading up on bit rot for the last few days and several threads have appeared in this sub-reddit that have given conflicting opinions on this topic. Am curious as to what the current consensus was?\n For reference I currently run a raspberry pi 3 with 2 HDDs attached, both ext4. 1 HDD is exposed via smb which all the family access and then a cron job runs once every 2 weeks to rsync to the other HDD. Another cron job then runs once a month to rclone the content to google-drive. Our data is relatively small ~ 300GB, the vast majority being photos + home videos.\n So yer is bit rot really something I need to be concerned about / pro-actively defend against? Or is it unlikely to ever really be an issue and not worth the hassle?\n    submitted by    /u/coolio9876  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdk233/do_small_home_nass_need_to_care_about_bit_rot/",
          "publishedOn": "2022-12-05T21:18:27.000Z",
          "wordCount": 19978,
          "title": "Do small home NAS's need to care about bit rot?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdjtie/sony_trv280_connection_issues/",
          "author": null,
          "description": "So I followed the guides, installed a FireWire card into my desktop, updated the drivers and the PC recognizes , window 11,the camera in device manager. The problem is when I start to capture using windv it starts capture by hitting play on the camera, everything is good for about 4 seconds then the PC starts connecting and disconnecting the camera. I've tried everything I know to do, hoping someone has a solution.\n    submitted by    /u/nearkcouple4fun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdjtie/sony_trv280_connection_issues/",
          "publishedOn": "2022-12-05T21:10:33.000Z",
          "wordCount": 20847,
          "title": "SONY trv280 connection issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdi27g/drivezfs_weirdness_advice_sought/",
          "author": null,
          "description": "Let me preface this with one statement: replacement drives are already on order, mostly trying to figure things out. \n Been having some odd issues with one of my arrays and seeking an opinion on wtf is going on. \n Kicked off a scrub overnight and came back to emails like this:\n  \nThe number of I/O errors associated with a ZFS device exceeded\n acceptable levels. ZFS has marked the device as faulted.\n impact: Fault tolerance of the pool may be compromised.\n class: statechange\n state: FAULTED\n  \nand this:\n  \nThe number of checksum errors associated with a ZFS device\n exceeded acceptable levels. ZFS has marked the device as\n degraded.\n impact: Fault tolerance of the pool may be compromised.\n class: statechange\n state: DEGRADED\n  \nWith the scrub being basically stopped and the system running a resliver\n Ended up cancelling the scrub and re-running it later that day to similar results.\n Now for the really screwy result:\n Moved the drives (they're in a removable drive cage) from this LSI SAS controller:\n  \nSerial Attached SCSI controller: Broadcom / LSI SAS2008 PCI-Express Fusion-MPT SAS-2 [Falcon] (rev 03)\n  \nto this controller (in the system as a now unused relic of a recent data/drive shuffle)\n  \nSATA controller: Marvell Technology Group Ltd. 88SE9215 PCIe 2.0 x1 4-port SATA 6 Gb/s Controller (rev 11)\n  \nand everything's running fine with another scrub...\n The other drive array on the LSI SAS card completed it's scrub without issues.\n Are my drives failing? not sure what is going on.\n edit: there it goes, borked on the marvell controller, just took quite a bit longer (percentage wise) so it appears my drives are failing...?\n    submitted by    /u/FnordMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdi27g/drivezfs_weirdness_advice_sought/",
          "publishedOn": "2022-12-05T20:11:12.000Z",
          "wordCount": 20749,
          "title": "Drive/ZFS weirdness, advice sought.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdhvhz/starter_questions_for_photo_cataloging/",
          "author": null,
          "description": "Hello I am kinda just starting off trying to save all my family’s photos over the years and I have a few questions to ask you guys. Everything I’ve read on this sub says just to start simple and small and work your way up and to have another location for files. So I have some flash drives I’ve gained over the years some new some old, a brand new 2tb and a hand me down 1tb drive and a photo scanner and I want to do it right so I have a few questions. \n First: Storage. I found a leather zip up case on Amazon to put all the drives in. Are these recommended for storage or is there any way to go wrong with just flash drives and small hard drives? As far as another location goes, my family will all have copies of the photos when I am done and even as I start to save them I’ll keep some drives at my brother’s house. But do you guys recommend cloud saving, and if so what service? \n Second: File saving. I don’t know much about computer files and compression or anything like that. I also have some files coming from Mac devices and don’t know if it will be important for all files to be the same file type when all is said and done? Is this preferred, should i convert all my file types to a certain type like png or jpg or both? And should I keep these files compressed onto flash drives so you have to unzip them to view them or am I overthinking this portion? Any help would be greatly appreciated!\n    submitted by    /u/grantdotyea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdhvhz/starter_questions_for_photo_cataloging/",
          "publishedOn": "2022-12-05T20:05:00.000Z",
          "wordCount": 13715,
          "title": "Starter questions for photo cataloging",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdhtdt/new_to_hdds_and_backups/",
          "author": null,
          "description": "Hi, I am pretty new to hard drives and backups but I know they are required. I bought two HDDs this past Black Friday to have two backups in separate locations. I also understand one cannot just assume that these HDDs arrived in perfect working order and that some preliminary tests should be done. I started by doing a full format, as opposed to a quick one. Which programs should I run afterwards using Windows and what should I be on the lookout for before I proceed to do my backups ? Thanks much for your time.\n    submitted by    /u/LightDarkCloud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdhtdt/new_to_hdds_and_backups/",
          "publishedOn": "2022-12-05T20:02:57.000Z",
          "wordCount": 19750,
          "title": "New to HDDs and Backups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdfc4o/site_to_bulk_download_music_videos_from_the_80s/",
          "author": null,
          "description": "I wanted to start collecting Music Videos from the 80's to 90's and place them in Plex for easy viewing for my parents. Is there any sites where I could download them with the metadata needed for Plex to display them? If there is a better place to ask this question please let them know. thanks, I am also asking this question on the Plex reddit.\n    submitted by    /u/Cool_Friendship9447  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdfc4o/site_to_bulk_download_music_videos_from_the_80s/",
          "publishedOn": "2022-12-05T18:38:13.000Z",
          "wordCount": 12745,
          "title": "site to bulk download music videos from the 80;s with metadata that would be used by Plex",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdc4o7/is_my_external_hdd_dying/",
          "author": null,
          "description": "I have a Seagate External Game Drive Hub, this one specifically, and I am experiencing some abnormalities with it. I have written 4TB of data to it and deleted it after backing up my NAS. Now I use it only for storing Steam Games, so I don't have to ever redownload them in the future.\n  \nOn occasions my Steam games fail to update\n It slows down my computer when connected sometimes, and then my pc is normal when I unplug it\n Sometimes it takes forever to open the drive to see the files\n  \nI've only had this drive for 8 months and it is connected via USB. Should I attempt to shuck it and just connect it via SATA to the MOBO or attempt to get a warranty claim on it?\n    submitted by    /u/NO-LAN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdc4o7/is_my_external_hdd_dying/",
          "publishedOn": "2022-12-05T16:48:57.000Z",
          "wordCount": 20100,
          "title": "Is my External HDD dying?",
          "imageUrl": "https://external-preview.redd.it/aMvDaAllcwNd1DefNGp1DoGz2yvl_NSfPPQA28jTOFE.jpg?auto=webp&s=77beca496bfccea79d423fc0f3bcf7060b997420"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdbpeo/clone_or_copymove/",
          "author": null,
          "description": "For preserving the quality of data, is it better to copy or clone? I'm literally copying from one 16TB drive to a 20TB one. Would cloning be quicker?\n Is Windows copy okay to use? Or should I use something like TeraCopy? I don't plan on verifying so not sure it makes a difference.\n Thank you for your guidance.\n    submitted by    /u/banisheduser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdbpeo/clone_or_copymove/",
          "publishedOn": "2022-12-05T16:34:00.000Z",
          "wordCount": 12980,
          "title": "Clone or Copy/Move?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdasqg/in_case_you_are_wondering_how_western_digital/",
          "author": null,
          "description": "submitted by    /u/nando1969  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdasqg/in_case_you_are_wondering_how_western_digital/",
          "publishedOn": "2022-12-05T16:02:13.000Z",
          "wordCount": 14509,
          "title": "In case you are wondering how Western Digital packs single drive shipments.",
          "imageUrl": "https://preview.redd.it/ulgwa7s0954a1.jpg?auto=webp&s=c4095ab8f2d281b522c4fdf6e29a8e39eb607d46"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zdack1/good_quality_power_strip_with_individual_onoff/",
          "author": null,
          "description": "Okay, this is tangential to data hoarding. I have a lot of external hard drives that I connect to my computer at regular intervals, sometimes up to 6 at the same time. I have a Belkin power strip that has 8 individual power supply outlets but they all have a single on off switch. I bought a couple of power stripes off Amazon with individual on/off switches but they have been less than ideal in quality. Can any fellow data holder please suggest a good quality power strip with individual on/off switches whereby I can connect up to 8 devices at the same time? I am currently living in a non western country so I would appreciate brands that are global.\n    submitted by    /u/lezboyd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zdack1/good_quality_power_strip_with_individual_onoff/",
          "publishedOn": "2022-12-05T15:46:08.000Z",
          "wordCount": 19753,
          "title": "Good Quality Power Strip with individual on/off switches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zd90pp/cmrsmr_toshiba_drives/",
          "author": null,
          "description": "Toshiba N300 8TB NAS HDD/Hard Drive 7200rpm\n Toshiba 16TB 3.5\" Enterprise SATA HDD/Hard Drive ( MG08ACA16TE )\n  \nSecond one is listed at the retailer as CMR. First one, it doesnt say.\n Just wanted to clariy\n a) Extra confirmation both are indeed CMR\n b) Any reason to not use the 8TB in RAID for my nas (raidz1)? 16 TB will be in a NAS as part of SHR (synology hybrid raid)\n Thanks\n :edit - add in model number for 16TB drive\n    submitted by    /u/Maximum-Warning-4186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zd90pp/cmrsmr_toshiba_drives/",
          "publishedOn": "2022-12-05T14:58:37.000Z",
          "wordCount": 12905,
          "title": "CMR/SMR Toshiba Drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zd8vl7/transporting_hdds_just_a_2_hour_car_journey/",
          "author": null,
          "description": "I'm heading to the in-laws for Xmas and need to take my desktop pc, which has an 18tb and an 8tb HDD in it amongst some SSDs. \n The PC will just be bunged safely in the car, but I feel like I remember people giving advice such as taking the harddrives out or something during transport, minimising chances of vibrations etc.\n Any advice? Should I buy particular carry cases? Will the HDDs be fine for the sake of 2 hours?\n I'm backed up of course, but still.\n Thanks in advance\n    submitted by    /u/JiggaRob  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zd8vl7/transporting_hdds_just_a_2_hour_car_journey/",
          "publishedOn": "2022-12-05T14:53:14.000Z",
          "wordCount": 16062,
          "title": "Transporting HDDs just a 2 hour car journey?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zd8b1w/bought_2_5tb_external_hdds_150each_for_backups_is/",
          "author": null,
          "description": "Might not be at the best place to ask, but trying anyways.\n I have 2 hard drives on my pc and one external hard drives for music production and other side hustle.\n What I did is I made folders for each hard drive on my backup 1 drive and backup 2 drive, and I use FreeFileSync to mirror them onto my backup drives.\n I don't own much important documents but my music production stuff is easily 800 GB and I want to future proof it. \n I thought about using a cloud storage backup solution but it would take literally days to download all of it back (tested it).\n So my questions are:\n  \nIs 2 backup drives too much? I feel like I'm going over kill because the average person would only have 1 small cheap backup drive.\n \nShould I backup literally everything (including OS), some things (User files like documents, pictures, etc.) or only important things (ex: my insurance papers)\n \nHow do you manage version control? Let's say I make a monthly backup and one day I modify a file on my computer. But it wont automatically update on the backups too. Is there a way to do this efficiently without having to worry about having the wrong version of my file?\n \n I'm using FreeFileSync to mirror my data, because it would take too long to do a backup from scratch everytime. The one I'm doing right now takes about 16 hours (both backup drives included).\n Thanks.\n    submitted by    /u/Krowplex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zd8b1w/bought_2_5tb_external_hdds_150each_for_backups_is/",
          "publishedOn": "2022-12-05T14:31:41.000Z",
          "wordCount": 13910,
          "title": "Bought 2 5TB external HDDs (150$/each) for backups. Is it too much? Also, do you backup only important files or literally everything? How do you manage version control efficiently?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zd43kp/opinion_on_hetzner_storage_boxes_for_backup/",
          "author": null,
          "description": "I was drawn in by the price, and the fact that it's a unix account (sftp + shell) on a zfs filesystem. So versioning works with zfs snapshots. My wasabi + arq backups were getting a bit expensive. One of the downsides i'm seeing is that concurrent connections seem to be restricted, though it's not exactly clear how many are allowed. Also, the snapshot setup only allows you one type of frequency (you have to choose between daily or weekly, unlike rsync.net where you can have daily, weekly and monthly)\n anyone else using storage boxes for backup ?\n    submitted by    /u/BakGikHung  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zd43kp/opinion_on_hetzner_storage_boxes_for_backup/",
          "publishedOn": "2022-12-05T11:14:23.000Z",
          "wordCount": 14177,
          "title": "Opinion on Hetzner Storage Boxes for backup ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zd06uw/looking_for_least_restriction_cloud_backup/",
          "author": null,
          "description": "Hi All, this is yet another cloud backup question. I've researched a whole bunch, but some of the posts are old so I wanted to know what the current status of the service is from the usual providers.\n How is Backblaze with upload/download speeds for their Personal backup plan? Is the restore process still limited by how you can restore the files, and how fast you can download them?\n Is the Backblase B2 better than the personal plan? Are there fewer restrictions/limits compared to the Personal plan? Does it allow you keep the files on the cloud even if you unplug the hard drive for many days? I think the Personal has a 30 day limit. How easy is the restore process? Does it allow you to select all files and do a backup?\n As for Crashplan, does it also have limitations for upload/download speed and how you can restore the backup? What about iDrive, icedrive, GDrive, DropBox, etc? I know I'm asking a lot but there is not much information on people's experiences with restoring the backups.\n I have about a minimum of 4TB of data I want to backup. In total I have close to 100TB of personal files, ripped CDs, and movies. I was thinking Blackblaze B2, but you have to rely on 3rd apps to use it, which is fine with me. My data is currently on a 8x14TB ZFS NAS machine running Ubuntu. I would like to be able to upload/download as fast as I can. I'm on a symmetric 500mbps fiber line. My main priority is to keep my 4TB of priceless data safe, and be able to restore quickly and not have the cloud provider delete it after the drive being offline for at least 30 days, but 60 days would be better.\n Thanks!\n    submitted by    /u/Aviyan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zd06uw/looking_for_least_restriction_cloud_backup/",
          "publishedOn": "2022-12-05T07:24:39.000Z",
          "wordCount": 14634,
          "title": "Looking for least restriction cloud backup solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcq754/multiple_cloud_sync_task_only_one_will_run_other/",
          "author": null,
          "description": "submitted by    /u/kylewizerd15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcq754/multiple_cloud_sync_task_only_one_will_run_other/",
          "publishedOn": "2022-12-04T23:53:44.000Z",
          "wordCount": 20756,
          "title": "Multiple Cloud Sync Task only one will run other says \"Locking local path\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcq49z/flatbed_scanner_to_capture_image_from_cellphone/",
          "author": null,
          "description": "Customers hand us their insurance cards on their cell phones. Sure, we could have them send us a screenshot and connect it later, but does anyone have a TWAIN/WIA piece of hardware (like a flatbed scanner) that will work? The FI-65f scanner definitely doesn't have the refresh rate necessary.\n    submitted by    /u/spittlbm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcq49z/flatbed_scanner_to_capture_image_from_cellphone/",
          "publishedOn": "2022-12-04T23:50:39.000Z",
          "wordCount": 19360,
          "title": "Flatbed scanner to capture image from cellphone screen",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcpxwn/solution_for_copying_storing_and_hosting_personal/",
          "author": null,
          "description": "I recently aquired a small box of photo disks that have various family (and extended) members on them. I am looking for a solution for copying, storing, and hosting these phtotos. Some of these disks have a folder with the photos, others are from a photo lab and contain some kind of EXE file and a folder with the photos.\n What is the best way to copy these disks? Copy paste the files?then for stoage and hosting what would you recomend ( r/selfhosted is probably the better place to ask this). I was thinking of using photoprism, I am not sure if there is somthing better for this.\n    submitted by    /u/Downtown_Relief810  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcpxwn/solution_for_copying_storing_and_hosting_personal/",
          "publishedOn": "2022-12-04T23:43:48.000Z",
          "wordCount": 20656,
          "title": "Solution for copying, storing, and hosting personal photo disks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcpens/is_anyone_scanning_print_magazines/",
          "author": null,
          "description": "What's your set up, specs, your process and what titles? Curious.\n    submitted by    /u/cdnrtrt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcpens/is_anyone_scanning_print_magazines/",
          "publishedOn": "2022-12-04T23:23:44.000Z",
          "wordCount": 21674,
          "title": "Is anyone scanning print magazines?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcp1ja/seagate_expansion_desktop_5tb_external_hard_drive/",
          "author": null,
          "description": "I was copying files from one drive to the Seagate drive in question (so I don't care about getting the data from that - I just want it working so then I can copy to it again). My computer completely froze (I was doing another copy with 2 other drives at the same time - those ones are fine though, funnily enough) and had no choice but to restart it during the copy.\n The main source drive was fine (thank goodness!) but the Segate 5TB not so much. I don't think it's a mechanical failure (in the platter / read/write head sense) - it spins fine, no beeping or any unusual sounds. But when I plug it in, it disconnects after a few seconds. When opening disk management on windows, it shows \"Unknown Not initialized\" for a split second. Given the circumstances of the failure, faulty cables wouldn't be a thing - although I tried different ones anyway to be doubly sure. So clearly some hardware issue, but I doubt mechanical - so I opened up the ensure (without snapping the clips somehow, lol).\n I put the hard drive inside a spare enclosure. Plugged it in - it didn't disconnect, but it wasn't showing up normally. I go on disk management, and I can see again \"Unknown Not initialized\". Again, I don't care about getting data from this, so I right-clicked on \"initialize\". It says \"The request failed due to a fatal device hardware error.\" So definitely software will not work whatsoever. This leads me to believe I fried the control board / PCB, which provides an interface for the mechanical drive to communicate with the computer. Thus, I can't access the drive.\n The model of the PCB is 100721570 REV E.\n Am I correct in surmising that this is a PCB failure, and that I simply need to buy a replacement (AliExpress seems to be the only place I can buy this)? And apparently I need to copy the BIOS firmware from my original PCB to the replacement - is that true?\n Or is it really a mechanical failure?\n    submitted by    /u/craxing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcp1ja/seagate_expansion_desktop_5tb_external_hard_drive/",
          "publishedOn": "2022-12-04T23:08:52.000Z",
          "wordCount": 20968,
          "title": "Seagate Expansion Desktop 5TB External Hard Drive (ST5000DM000) spins fine, connects but then disconnects",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zclww6/building_a_nas_system_for_the_first_time/",
          "author": null,
          "description": "I am a newbie and I am planning on building a self-hosted NAS system for home use for the first time. After some research, I am thinking of buying a RaspberryPi4 (4GB), attaching an external SSD via USB, and installing OpenMediaVault on it. These are my requirements:\n  \nI need data durability\n I need data encryption\n I need to read/write data from various OSes (Windows, MacOS, Linux)\n  \nWould this setup cover all my points above? I am mostly worried about data durability. I guess I can plug in a secondary SSD and backup my data every now and then. But how do I prevent data corruption/bitrot in the long run? Please also let me know if you would recommend different hardware/software.\n For the sake of completeness: I don’t need to stream movies, I don’t need to store a lot of data (256GB is more than enough), and I don’t need high availability (in fact, I only intend to boot the system every now and then).\n Thanks!\n    submitted by    /u/Responsible-Dig-7540  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zclww6/building_a_nas_system_for_the_first_time/",
          "publishedOn": "2022-12-04T21:14:44.000Z",
          "wordCount": 20091,
          "title": "Building a NAS system for the first time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcku2b/dumb_questions/",
          "author": null,
          "description": "Hey was told to come here for help on YouTube archiving. Was wondering if anyone could help or already archived a specific channel that’s about to whip most of their videos for obvious reasons. WTT . I just want some help archiving this somehow. \n Side question: any website that can hold up a pretty decent amount of storage? Im currently digitally saving all the music I have such as cds and digital copies and using a 36 gig usb to contain everything. As of rn though it’s halfway full and I’m not half way done ripping every cd I got or storing everything. They’re all also just 360k MP3’s not even flacs. Was just curious if any websites other than google drive and megaz can carry about a terabyte\n    submitted by    /u/I_A_M_N_O_B_O_D_Y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcku2b/dumb_questions/",
          "publishedOn": "2022-12-04T20:36:02.000Z",
          "wordCount": 19993,
          "title": "Dumb questions",
          "imageUrl": "https://external-preview.redd.it/LcLRsBy2f4xzshFq9WPZ9rpVSGdE4dtMGxjP8ydXizM.jpg?auto=webp&s=66de85dc9604e602cfb79d997b2a05d3b70fe90e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcknv3/cant_beat_that_value/",
          "author": null,
          "description": "​\n https://preview.redd.it/n316zki2yx3a1.png?width=1139&format=png&auto=webp&s=6b9539dbef78a4f61f32841ebd4b7b974e492d78\n    submitted by    /u/umairshariff23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcknv3/cant_beat_that_value/",
          "publishedOn": "2022-12-04T20:29:54.000Z",
          "wordCount": 20379,
          "title": "Can't beat that value!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zckh9t/used_hgst_drives_6tb_hus726060ala640/",
          "author": null,
          "description": "Anyone bought any used HGST drives? How was your experience?\n A local shop has these used HGST 6TB HUS726060ALA640 drives for $40 a piece. The power on time shows around 2500 days and health 100%.\n The use case would be a TrueNAS server and the drives would be in ZFS RAID 6 or raidz2 (whatever they call it). I would have another backup of the files stored on another machine on 2 larger drives in mirror.\n I am wondering if this is a good deal or if I should stay away? What would you do?\n    submitted by    /u/newpain01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zckh9t/used_hgst_drives_6tb_hus726060ala640/",
          "publishedOn": "2022-12-04T20:23:06.000Z",
          "wordCount": 18636,
          "title": "Used HGST drives - 6TB HUS726060ALA640",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcitfq/how_many_drives_can_be_connected_to_a_dell_perc/",
          "author": null,
          "description": "I work in the electric refurbishment business and found this HBA card. I want to connect it to my NetApp DS2246, but I just cant figure out how many drives this card supportes. When I google it, it shows me the internel sas Version.\n    submitted by    /u/PhantomSlicer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcitfq/how_many_drives_can_be_connected_to_a_dell_perc/",
          "publishedOn": "2022-12-04T19:22:05.000Z",
          "wordCount": 18577,
          "title": "How many Drives can be connected to a Dell Perc h200e 12dnw HBA Card?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcfujb/is_an_ssd_reliable_long_term_storage/",
          "author": null,
          "description": "If I'd like to backup important files to a 2TB external SSD that is stored safely regarding humidity and temperature. Can I expect that drive to remain functional and the data intact for the long term, say 10+ years?\n    submitted by    /u/x0y0z0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcfujb/is_an_ssd_reliable_long_term_storage/",
          "publishedOn": "2022-12-04T17:33:38.000Z",
          "wordCount": 22897,
          "title": "Is an SSD reliable long term storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcdf1r/crashplan_a_couple_questions_about_backup_size/",
          "author": null,
          "description": "Hi, \n I have a crashplan for small business subscription and I need help in understanding the difference in sizes of my backup sets as they are presented in the:\n - Windows App\n - web application\n On windows App I see the \"predefined\" backup set occupying 3.1 TB while on the web application I see the (I guess) overall size at 2.4 TB (with a Selected at 2.9 TB that I don't know the meaning).\n Do you know why?\n ​\n ​\n on windows application\n ​\n ​\n on web application\n ​\n Second question: I bought a new bigger drive since the one where a part of my \"predefined\" backup set of Crashplan is filling up.\n Of course i need to migrate the files without reuploading everything to the cloud.\n May I safely refer to the guide here under the \"Replace a drive\" section?\n https://support.crashplan.com/hc/en-us/articles/8887084769037-Back-up-external-hard-drives-using-CrashPlan-for-Small-Business\n I found it not very clear for such a life critical task.\n Do anyone knows what I have to after connecting the new (empty) drive (a 6TB wd red)?\n Thanks\n    submitted by    /u/frankieta83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcdf1r/crashplan_a_couple_questions_about_backup_size/",
          "publishedOn": "2022-12-04T16:02:14.000Z",
          "wordCount": 20772,
          "title": "Crashplan (a couple questions about backup size and data migration)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zccb5h/this_cloud_is_getting_expensive_but_i_have_some/",
          "author": null,
          "description": "Let's say 10 TB that I have in Azure\n    submitted by    /u/rlopez7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zccb5h/this_cloud_is_getting_expensive_but_i_have_some/",
          "publishedOn": "2022-12-04T15:18:32.000Z",
          "wordCount": 17979,
          "title": "This cloud is getting expensive. But I have some TB that I need to share with my colleagues. Should I move to a NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zcbxrf/how_does_google_drive_mirroring_know_where/",
          "author": null,
          "description": "So I finally installed the new Google Drive app. It's definitely an improvement over the old Backup and Sync, however there's one thing I am unclear on, and I can't find the answer anywhere.\n You have the option to mirror certain folders from your computer. All Google says is that it will keep files and folders the same in both places. What I interpret this to mean is, while syncing is happening, it will keep track of where changes are made and then make the same changes in the other place. If you add a file on your computer, it adds it to the cloud. If you delete a file in the cloud, it deletes it from your computer. It knows where the change is made, and makes the same change in the other place.\n But what if I turn off syncing for 2 months, then I delete 2 files from my computer's folder, then 3 months later I turn on syncing again. How is Google Drive going to know whether files have been deleted from my local storage or added to Drive? Is it going to add the files back to my local storage or is it going to delete them from Drive? What will it use as reference?\n In the old Backup and Sync, there were options where you could tell it what to do in these scenarios. I messed up once and after moving a whole bunch of files from a mirrored folder while it wasn't being synced, I then resubscribed to Drive and it re-added all of those files, and now that folder is a complete mess, 2 years later I still haven't fixed it. I wanna make sure this doesn't happen again, but in the new app there are no settings to set a behavior for when it discovers changes that were made while syncing was off.\n Thanks, any input is appreciated.\n    submitted by    /u/Qbccd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zcbxrf/how_does_google_drive_mirroring_know_where/",
          "publishedOn": "2022-12-04T15:03:43.000Z",
          "wordCount": 19111,
          "title": "How does Google Drive mirroring know where changes have been made when syncing is turned off?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zc9zzq/image_windows_laptop_for_recovery/",
          "author": null,
          "description": "How do I image Windows OS for recovery ? I currently know about macrium reflect but it does not support cloud backup. The laptop has active internet connection but lacks in storage space so I prefer to backup directly to cloud. Restoring won't be an issue as I will use 2nd PC to download the backup prior to restore. Any suggestions ?\n    submitted by    /u/user655362020  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zc9zzq/image_windows_laptop_for_recovery/",
          "publishedOn": "2022-12-04T13:38:10.000Z",
          "wordCount": 20473,
          "title": "Image windows laptop for recovery",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zc9qu7/i_wish_to_make_my_own_webarchive_that_would_store/",
          "author": null,
          "description": "I essentially need a software that would download webpages on my pc in a viewable format, just like The Wayback Machine does, and would also download the embedded videos. I tried out Singlefile, but it saved the webpages in a different format from the originals, while i want to preserve the webpages with their original look and interface.\n    submitted by    /u/BadWi-Fi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zc9qu7/i_wish_to_make_my_own_webarchive_that_would_store/",
          "publishedOn": "2022-12-04T13:24:17.000Z",
          "wordCount": 19508,
          "title": "I wish to make my own webarchive, that would store webpages on my pc. What's the software that i should use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zc4j5h/deal_alert_seagate_exos_x14_12tb_hdd_renewed_for/",
          "author": null,
          "description": "submitted by    /u/willie_style  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zc4j5h/deal_alert_seagate_exos_x14_12tb_hdd_renewed_for/",
          "publishedOn": "2022-12-04T08:35:15.000Z",
          "wordCount": 17666,
          "title": "[Deal Alert] Seagate Exos X14 12TB HDD (Renewed) for $130",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbx5wq/softwarehardware_to_cache_filenames_directories/",
          "author": null,
          "description": "On windows explorer when I go searching through my hdd, theres a long pause on every folder as it scans and builds a directory file tree from scratch every single time. \n These folders haven’t changed in months, maybe years, theres no need to rebuild it so often.\n Is there a software / hardware combo that will place all the filenames and directories on a dedicated NVME for instant browsing? And then do a minor delta update as things change?\n I’m ok with the actual hdd files themselves being slow and taking a while to load.\n Thanks in advance\n    submitted by    /u/freshairproject  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbx5wq/softwarehardware_to_cache_filenames_directories/",
          "publishedOn": "2022-12-04T01:49:21.000Z",
          "wordCount": 19228,
          "title": "Software/hardware to cache filenames & directories for instantaneous windows explorer browsing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbwl8p/how_to_use_a_large_amount_of_m2_drives_for_data/",
          "author": null,
          "description": "A friend of mine picked up several hundred 250gb m.2 SSDs in the wake of a business closing down, and I'm trying to think of potential uses for them. Are there any relatively cheap / efficient ways to connect them in a large storage array, RAID or otherwise?\n    submitted by    /u/atrere  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbwl8p/how_to_use_a_large_amount_of_m2_drives_for_data/",
          "publishedOn": "2022-12-04T01:21:10.000Z",
          "wordCount": 19456,
          "title": "How to use a large amount of m.2 drives for data storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbwgvx/it_aint_much_but_its_my_first_big_boy_storage/",
          "author": null,
          "description": "submitted by    /u/Valor_X  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbwgvx/it_aint_much_but_its_my_first_big_boy_storage/",
          "publishedOn": "2022-12-04T01:15:27.000Z",
          "wordCount": 21246,
          "title": "It ain’t much but it’s my first big boy storage drive. Question: I always run a full error scan on new HDD’s with HD Tune, is this necessary to ensure a full working drive or is it overkill? Should I just check SMART attributes?",
          "imageUrl": "https://preview.redd.it/zw7rk3gwpt3a1.jpg?auto=webp&s=e97b5aafd00bd941ba02381a65fc914e7bc9bf64"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbve3r/pixiv_looks_to_be_wiping_a_lot_of_content_soon/",
          "author": null,
          "description": "I saw that pixiv is changing their content policy and I assume that means a lot of stuff is about to be deleted. If I want a good backup or content rip of the site, what's the best way to do that? Otherwise, if anyone has a recent backup, are you willing to share or explain how you made it?\n    submitted by    /u/th_sth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbve3r/pixiv_looks_to_be_wiping_a_lot_of_content_soon/",
          "publishedOn": "2022-12-04T00:24:41.000Z",
          "wordCount": 21749,
          "title": "Pixiv looks to be wiping a lot of content soon, what's the best way to go about creating a site rip or backup?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbsc58/reminder_to_backup_up_your_data_5_month_old_adata/",
          "author": null,
          "description": "submitted by    /u/hboyd2003  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbsc58/reminder_to_backup_up_your_data_5_month_old_adata/",
          "publishedOn": "2022-12-03T22:13:10.000Z",
          "wordCount": 21443,
          "title": "Reminder to backup up your data! 5 month old ADATA SSD Failure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbqeu6/which_one_of_these_is_the_best_photo_storage/",
          "author": null,
          "description": "I'm a complete beginner when it comes to technology, and I really need your help because I genuinely don't understand specs.\n I'm getting an external hard drive for a laptop that doesn't have room for an internal hard drive. I'm trying to pick the most reliable and best of them.\n  \nBasic Portable Drive 2 TB\n Toshiba Canvio Ready\n Toshiba Canvio Basics\n  \nFinally, I have one more option - buying this docking station to connect one of the internal HDDs (links below) to my laptop - I'm not sure if this is a good alternative or if it's reliable at all. \n  \nToshiba P300 Desktop PC\n WD Blue PC Desktop Hard Drive\n  \nI apologize if this is a stupid and bothersome question, but as a girl (who knows very little about tech and) is looking for a good photo and video storage solution, I hope you won't mind helping me with this.\n    submitted by    /u/the-emotional-emu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbqeu6/which_one_of_these_is_the_best_photo_storage/",
          "publishedOn": "2022-12-03T20:54:56.000Z",
          "wordCount": 20681,
          "title": "Which one of these is the best photo storage solution? Thank you in advance.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbowdf/6_drive_nas_hda_card_question/",
          "author": null,
          "description": "Hi all,\n I'm planning a 6 drive (storage) truenas build + 1 ssd for the OS drive.\n My mobo has 6 sata ports and so consequently, I'm one short. \n To utilise my 6 sata ports for the 6 data drives. I understand there is the option to boot the OS from USB (converted to Sata). Alternatively, I could look to get an HBA card (pci express --> sata) but hear there are compatibility issues via this route. If you know of a good HBA card thats not too expensive, I'd love to hear.\n Any guidance here would be appreciated!\n    submitted by    /u/Maximum-Warning-4186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbowdf/6_drive_nas_hda_card_question/",
          "publishedOn": "2022-12-03T19:52:48.000Z",
          "wordCount": 19808,
          "title": "6 drive nas - HDA card question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbomv1/programprocess_to_sort_a_bunch_of_unsorted_photos/",
          "author": null,
          "description": "Anyone have a process they use to sort 1000s of unsorted photos? Cosplay rip downloaded from a site is like 4000 photos all in one folder. I'd like to get all the photos organized into the character\\shoot\\etc. Other than manually going through and moving to folder anyone have a program, app, script or something they are aware of which can determine similar photos (using AI maybe) and sort them?\n Thanks\n    submitted by    /u/basicallyahurricane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbomv1/programprocess_to_sort_a_bunch_of_unsorted_photos/",
          "publishedOn": "2022-12-03T19:41:23.000Z",
          "wordCount": 19754,
          "title": "Program\\Process to sort a bunch of unsorted photos.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbo7pc/ape_historian_post_i_am_out_of_storage_finally_my/",
          "author": null,
          "description": "submitted by    /u/kukelkan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbo7pc/ape_historian_post_i_am_out_of_storage_finally_my/",
          "publishedOn": "2022-12-03T19:23:28.000Z",
          "wordCount": 19765,
          "title": "Ape historian post | I am out of storage - finally. My new rig with 300tb active storage and tape drives for archival is ordered. Got a few things for free. In theory the setup would store everything until moass (which is on Tuesday). Assembly pron on the way. Backups are still going.",
          "imageUrl": "https://preview.redd.it/t07n1h8kuq3a1.jpg?auto=webp&s=219ed6e2b0d904b60150e18281a21771c24b0317"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbny9t/can_a_raid_array_be_made_from_another_raid_array/",
          "author": null,
          "description": "I was planning on making a raid 5 array from 2 12 tb hdds and and 1 raid 0 array made from 3 4 tb hdds. The 12tb are 7200 rpm while the 3 * 4 hdds are 5400 rpm. Is this possible and more so not stupid? I know raid 10 is basically raid 1 + 0 but I'm not sure if it has to be implemented in a certain way to work. Using mdadm from linux kernel if your wondering. Google wasn't answering my question.\n    submitted by    /u/quantumechanicalhose  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbny9t/can_a_raid_array_be_made_from_another_raid_array/",
          "publishedOn": "2022-12-03T19:12:28.000Z",
          "wordCount": 21485,
          "title": "can a raid array be made from another raid array?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbn1ke/best_software_for_download_youtube_videos_and/",
          "author": null,
          "description": "Hello, I’m trying to download a lot of YouTube videos in huge playlist. I have a really fast internet (5gbit/s), but the softwares that I tried (4K video downloaded and Open Video Downloader) are slow, like 3 MB/s for 4k video download and 1MB/s for Oen video downloader. I founded some online websites with a lot of stupid ads, like https://x2download.app/ , that download at a really fast speed, but they aren’t good for download more than few videos at once. What do you use? I have both windows, Linux and Mac.\n    submitted by    /u/StrengthLocal2543  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbn1ke/best_software_for_download_youtube_videos_and/",
          "publishedOn": "2022-12-03T18:33:58.000Z",
          "wordCount": 20174,
          "title": "Best software for download YouTube videos and playlist in mass",
          "imageUrl": "https://external-preview.redd.it/bBZtnOZdA4YFrPl8m5wpdkUIGtT2JyV2kLHwlKLfkI8.jpg?auto=webp&s=2ed9d33e203acca30d6a9235bb3f536609a105df"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbm58l/is_it_possible_to_use_ai_to_write_scripts_for/",
          "author": null,
          "description": "I’m a code noob.\n Aside from a few simple concepts I can’t script or code. \n I’m wondering if you think it’s feasible to get consistent results with AI generated code.\n It would make my life so much easier. \n This is an example, wdyt?\n Here is an example of a Python script that checks for changes at a URL, and if there are changes, takes a screenshot and saves it to a specific folder:\n    submitted by    /u/badatmathdave  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbm58l/is_it_possible_to_use_ai_to_write_scripts_for/",
          "publishedOn": "2022-12-03T17:56:11.000Z",
          "wordCount": 19478,
          "title": "Is it possible to USE AI to write scripts for data hoarding?",
          "imageUrl": "https://external-preview.redd.it/Gj9D8dnmAuoo3MSs0pjZUPSGgdHz730TfMiL5fbEaQo.jpg?auto=webp&s=bf755b85c339bc6079c1b3a1ae9cc0ce1a5ccc79"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbkp39/append_to_archive_name_based_on_extension_of/",
          "author": null,
          "description": "Hello all,\n I am in the process of backing up a complete music library from a website (+- 10000 albums).\n Here are always 2 options to download a flac and mp3 version. When the files are being downloaded individually they have always the same name whithout knowing if you have downloaded the flac or mp3 version.\n Filename.rar (contains 1 mp3 album)\n Filename.rar (contains 1 flac album)\n by using jdownloader 2 i always download both and append a number\n Filename.rar\n Filename_2.rar\n But i still do not know if the archive contains mp3 or flac.\n Is there any piece of software that can open the archive, see what extensions the songs have and append this to the filename?\n Filename.rar -> Filename_flac.rar\n Filename_2.rar -> Filename_2_mp3.rar\n ​\n Thanks!\n    submitted by    /u/carval444  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbkp39/append_to_archive_name_based_on_extension_of/",
          "publishedOn": "2022-12-03T16:54:13.000Z",
          "wordCount": 19872,
          "title": "Append to archive name based on extension of contents.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbk72l/how_to_download_locked_file_on_hpe_support_center/",
          "author": null,
          "description": "I bought HP LTO-5 Ultrium 3280 FC drive from eBay and have to upgrade firmware. But this file is locked to download and I don't have permission to download it. The URL is; https://support.hpe.com/connect/s/softwaredetails?softwareId=co_154832_1 Does anyone help me? Thanks in advance!\n    submitted by    /u/AMDRadeonHD6950  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbk72l/how_to_download_locked_file_on_hpe_support_center/",
          "publishedOn": "2022-12-03T16:30:46.000Z",
          "wordCount": 19404,
          "title": "How to download locked file on HPE support center?",
          "imageUrl": "https://preview.redd.it/6qfgwoea4r3a1.png?auto=webp&s=56ffe1538c200c8efe74db845f208432839f4867"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbjweh/any_good_way_to_pool_storage_across_2_physical/",
          "author": null,
          "description": "Hello all! I recently filled up my 40tb box that I keep in my local DC (1Gb connection from house to DC) and don’t have room for more drives so I ended up buying another box with the exact same hardware for another 40tb but isn’t in the same rack.\n Does anybody know how to go about making 1 80tb volume? I’d rather not pass the drives directly to the 1st host due to wanting to utilize the second host for processing power along with storage. \n I’m using Windows Server Datacenter 2019 for my host OS (yes yes I know, it’s just so easy to join them to my ADDC and create permissions extremely easy).\n My initial thought was to use iscsi to pass the drives over a dedicated 1Gb link (no connection to the host would be more than 1Gb anyway) and just add them to the pool that way. Unless you guys have a better solution? Was thinking maybe clustering but it seems that you only get mirroring and not striping.\n    submitted by    /u/Kawaiisampler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbjweh/any_good_way_to_pool_storage_across_2_physical/",
          "publishedOn": "2022-12-03T16:16:50.000Z",
          "wordCount": 19630,
          "title": "Any good way to pool storage across 2 physical boxes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbjjh1/zfs_snapshot_replication_without_ecc/",
          "author": null,
          "description": "Hello there!\n First of all, sorry for my bad englisch german native here :) \n I have a question about ZFS-Replication, perhaps someone have some infos.\n I have a Main-Storage System with ZFS and ECC RAM, the Second-Storage-System is running ZFS without ECC.\n In my opinion it's ok to run the second storage system without ECC, because the Main System have.\n The Second System is only for storing zfs-snapshot-replication as Backup\n Since i'm safe against bit root on my main storage after the data are writen to disk there is no chance to transfer corrupted data on my second storage system even without ecc on the second system.\n If i have a bit-root in ram on the second system while replication, zfs would check the different parity and resend it.\n Do I have a flaw in my thinking?\n    submitted by    /u/Vertax1337  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbjjh1/zfs_snapshot_replication_without_ecc/",
          "publishedOn": "2022-12-03T16:00:36.000Z",
          "wordCount": 22010,
          "title": "ZFS Snapshot Replication without ECC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbhy9a/16tb_wd_elements_slow_in_explorer_when_browsing/",
          "author": null,
          "description": "Hello,\n I finally got back into the data hoarding game and got myself a new 16TB WD Element this past Black Friday. I have not shucked it and it is connected via USB 3. Benchmarks and file transfers show performance to be as advertised but I’m having an issue interacting with it in Explorer. I have SABnzbd set to transfer the ISOs after processing and I see the write rate to be > 200 MB/s along with other file transfer actions.\n Whenever I try to right-click and view properties on any folder and file on the drive, it takes > 5 or so seconds before the right-click menu comes up and another > 30 or so seconds before the info window comes up. Browsing is also a touch slower compared to my older and far smaller external drives.\n I tried leaving it as the only connected device, disabling shell menu extensions, Windows Search, services, and startup items and nothing has worked. The only time that the drive and Explorer don’t exhibit this issue is when I boot into Safe Mode. The drive functions as expected with right-clicking and retrieving folder and file properties as instantaneous.\n Other Explorer alternatives like Files doesn’t exhibit the same issue either so it definitely seems like a Windows issue.\n Anyone else has seen this behavior and might have an insight into this?\n    submitted by    /u/Sigvard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbhy9a/16tb_wd_elements_slow_in_explorer_when_browsing/",
          "publishedOn": "2022-12-03T14:48:33.000Z",
          "wordCount": 19259,
          "title": "16TB WD Elements slow in Explorer when browsing, right clicking, and trying to open file and folder properties but file transfers and benchmarks works perfectly and to spec. No issues in Safe Mode however…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbhmth/how_would_i_go_about_copying_around_5tb_worth_of/",
          "author": null,
          "description": "So I have around 5TB worth of data that I want to consolidate into one place and want to know how would I go around and do such a thing.\n Short backstory, I had a system with 2 drives, a 500GB SSD and 2TB HDD. Bought a 1TB HDD during start of the pandemic for recording location of recorded meetings. Year 1 into Pandemic, 2TB HDD has an error and on a \"Caution\" status from CrystalDiskInfo. I was also planning to build a new rig that year so I bought one 1TB NVME SSD(not part of the situation), a 2TB Ironwolf HDD and 4TB Barracuda.\n I didn't want to use my new drives on the PC so I used two 1TB External HDDs to store the data. Then a year later the 1TB I bought at the start of the pandemic was in \"Bad\" condition, so I gave in and plugged my 4TB HDD and transferred my files. For some reason I also plugged in the 2TB HDD. Now all of them are in use. \n So I did a disk analyze using WizTree and found out that I have half of my total storage full, not to mention earlier in the day I got an error that there was not enough space in my boot drive when I was saving stuff into there. \n Now how would I go around completely copying over these files into a whole separate drive/drives, eliminating duplicates and make sure everything is copied properly, so that I can completely wipe my current system and basically start from scratch.\n I would also like to ask on what kind of storage I should use to store this on. I think it will be just a cold storage, with the occasional rummage through, but it might also be another dump place I can continue adding to. I don't want to delete any of the files, more of its a hassle rather than sentimental stuff, but there are stuff that I definitely want to keep there. I would also say that I don't have much money to put towards storing these. So I guess a solution where I can add on over time would be best.\n    submitted by    /u/InfraDelta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbhmth/how_would_i_go_about_copying_around_5tb_worth_of/",
          "publishedOn": "2022-12-03T14:33:16.000Z",
          "wordCount": 22381,
          "title": "How would I go about copying around 5TB worth of data, from multiple drives to a singular drive/drives (Shared Pools/Raid)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbhd7s/working_downloader_for_scribd_books_in_late_2022/",
          "author": null,
          "description": "Hi everyone,\n I've already searched the threads but it looks like the provided links are now out of date.\n I need to download a couple books off Scribd, not documents that are user-uploaded, but ebooks Scribd provides. They are too large to download one page at a time without taking too much time. If you know of any ebook rippers for Scribd I would be grateful.\n Thank you!\n    submitted by    /u/throw_away_bay_bay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbhd7s/working_downloader_for_scribd_books_in_late_2022/",
          "publishedOn": "2022-12-03T14:20:26.000Z",
          "wordCount": 19364,
          "title": "Working downloader for Scribd books in late 2022 (not documents)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbfyvu/debugging_lsi_92408i_in_it_mode/",
          "author": null,
          "description": "Hey Guys,I've recently had a weird failure mode on my unraid box and thought I would consult the hive-mind for ideas & thoughts.\n TLDR:\n I think that somehow port/channel 3 on the first port of my LSI 9240-8i is bad. Swapping breakout cable results in the same sata port being bad.\n Has anyone else ever seen this type of failure mode? Is there a recommended way to test all the channels/ports on it?\n Key system info:\n  \nIt's been up and happy for over a year.\n I'm using a LSI 9240-8i in IT mode as an HBA\n I'm using 3 x 14TB WD drives all attached to a single SAS SFF-8087 to 4x SATA Cable\n 1 x Parity disk and 2 x data disks\n  \nWhat happened:\n  \nWoke up in the morning to a scheduled parity check having failed. Looking at the logs. It failed not long after it started. The second data disk was m…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbfyvu/debugging_lsi_92408i_in_it_mode/",
          "publishedOn": "2022-12-03T13:11:54.000Z",
          "wordCount": 22005,
          "title": "Debugging LSI 9240-8i in IT mode",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbcosn/building_a_new_server_for_my_data_hoarding_needs/",
          "author": null,
          "description": "Hello guys,\n I purchased a Storinator Q30 case and are looking to buy components for it ( CPU, RAM and MB)\n I have 2 * lsi 16i cards and an 10gbe card that will be put into the computer aswell.\n Storage i have 5*10tb and 5*18tb with 20 more slots in the case empty, so a build that can handle all the pcie lanes ( im counting 20 lanes) \n Was thinking to get an ASUS PRIME Z690-P D4 (DDR4) and Intel Core i9-12900 together with 128gb ram but not sure thats the best path to take? read that QSV is favored because of plex and HW transcoding\n The OS im going to be using for this build is going to be Unraid as im going to run some stuff besides plex. nothing that cpu heavy. ( pihole, *arr´s, grafana. etc) and were wondering if you guys could give me suggestions of what path would be the best to take. cost wise, not really any limits.\n ​\n thanks in advice!\n    submitted by    /u/yompe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbcosn/building_a_new_server_for_my_data_hoarding_needs/",
          "publishedOn": "2022-12-03T09:45:47.000Z",
          "wordCount": 20754,
          "title": "Building a new server for my data hoarding needs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zbchcf/bluray_disk_as_data_archival/",
          "author": null,
          "description": "Hi, I've did some research, but rather ask here outright.\n The worry is the availability of a reader 10 years down the line in order to transfer the data onto something newer.\n The issue is I'm on budget and I just can't buy a NAS with data redundancy RAID and stuff right now. About half if not more of my data isn't changing so it might work if I go with write once disks.\n If I do choose this option ... I have lots of HDDs already, I'd like to know some more details about Blu-Ray in terms of reliability, like DVDs would randomly get bad sectors no matter how well you cared about them (or maybe I just had cheap disks?) I would get 1 broken disk per 10 disks in a brand new fresh DVD pack.\n    submitted by    /u/Sloperon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zbchcf/bluray_disk_as_data_archival/",
          "publishedOn": "2022-12-03T09:31:13.000Z",
          "wordCount": 20423,
          "title": "Blu-Ray Disk as Data Archival?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zb6f5a/reusing_old_pc_vs_selling/",
          "author": null,
          "description": "So, I want to finally upgrade from my current system (Z87-G45 motherboard, Intel 4770k, 32GB DDR3) and build a new system. \n I also want to stop paying for Dropbox and have my own NAS that replicates that functionality as well as be a media server to stream my owned content. \n So, I was thinking of just reusing my current system for the NAS, but here are the drawbacks from my understanding: 1 GB Ethernet on motherboard, no built-in WIFI, and no NVME slots (does have MSATA though). \n I could buy a 10G LAN card (100 dollars) as well as an adapter card (15?) to be able to use an NVME drive for caching. Or, I could sell the motherboard, CPU, RAM, and AIO combo and use that money to build the cheapest newish system using a motherboard that has at least a 2.5G LAN port. \n I have never built a server nor have had any kind of network storage before, so this is all a new experience for me. \n What would you do or recommend me do?\n Any advice would be appreciated, including which OS/software system to use!!!\n    submitted by    /u/Junglist4RLife  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zb6f5a/reusing_old_pc_vs_selling/",
          "publishedOn": "2022-12-03T03:27:04.000Z",
          "wordCount": 22570,
          "title": "Reusing Old PC vs Selling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zb2t43/ssd_died_on_me_again_should_i_wait_for_holiday/",
          "author": null,
          "description": "I know Cyber Week was the best time to buy, but my SSD didn't fail until last night. All I want is a 1- or 2-TB external USB-C SSD with at least 1050 MB/s write speed. I want to avoid Samsung due to bad experiences with their products.\n    submitted by    /u/WeCanDoThis74  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zb2t43/ssd_died_on_me_again_should_i_wait_for_holiday/",
          "publishedOn": "2022-12-03T00:28:45.000Z",
          "wordCount": 19121,
          "title": "SSD died on me, AGAIN. Should I wait for holiday sales, or just buy one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zb2h8x/sas_expander_question_do_i_understand_this/",
          "author": null,
          "description": "So i am currently building a new storage system with seagate 6tb 12g sas drives (40 drives) i got from a local datacenter.\n Since one hdd usually only uses 150-200mb/s even with sequential write a 3g connection per drive should be more than enough. So my plan was to just get one 12g 16drive hba (like the lsi 9300-16i) and then use sas expanders/splitters. (Current plan to use them in four 10 disks each raidz2 pools)\n What would be a good option? Most of the ones i found are just 6gb\n Any advice on whats the best/most cost efficient way to achieve this setup when every drive should be able to utilize its full speed? \n Thanks\n    submitted by    /u/Pommes254  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zb2h8x/sas_expander_question_do_i_understand_this/",
          "publishedOn": "2022-12-03T00:13:13.000Z",
          "wordCount": 19309,
          "title": "SAS Expander Question | Do i understand this correctly?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zb2eay/ipfs_for_datahoarder/",
          "author": null,
          "description": "hi,\n I have a question to r/DataHoarder's.\n A lot of people is downloading stuff to 'preserve' it or 'not to be lost'. Why then not use IPFS for storing them ? It seems to be perfect solution for preserving data in a way that is 'not lost' (multiple redundant copies kept by people who want to provide it).\n I know there might be some copyright restrictions that prevent sharing, but a lot of people are keeping 'free' software like Linux ISO etc.\n    submitted by    /u/BigBossYakavetta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zb2eay/ipfs_for_datahoarder/",
          "publishedOn": "2022-12-03T00:09:18.000Z",
          "wordCount": 19756,
          "title": "IPFS for DataHoarder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zb178f/wd_blue_8tb_hard_drive_wd80eazz_5640rpm_cmr_10999/",
          "author": null,
          "description": "I bought one of these at the $109.99 price (about $118 with tax, delivered) to add as an 8th drive on a DS1821+. After Black Friday it is now back up to $119.99:\n https://www.amazon.com/Western-Digital-Blue-Hard-Drive/dp/B09KMGQG5Y\n All other slots are populated with a mix of helium and non-helium 8TB drives, all MyBook and EasyStore shucks. I could not find any information on the Internet regarding whether this drive would honor the disable head parking command. It does.\n The warranty was advertised as 2 years. WD warranty checker lists the warranty as 3 years.\n This WD80EAZZ arrived with idle3-tools reporting head parking at 80 (8 seconds). This drive honors the idle3-tools command to disable head parking. I ran idle3-tools via direct sata connection from an Ubuntu 20.04 server.\n To do this from Ubuntu:\n sudo apt update\n sudo apt install idle3-tools\n sudo fdisk -l (to list what disk label your WD80EAZZ is set at)\n sudo idle3ctl -g /dev/sdX (replace \"X\" with the correct drive label)\n (verify that drive respond to the idle3 command, and lists the parking time as 80)\n sudo idle3ctl -d /dev/sdX (replace \"X\" with the correct drive label)\n (you should get a \"head parking disabled\" message)\n Shutoff the computer. Fully poweroff the drive. Reboot and run\n sudo idle3ctl -g /dev/sdX (replace \"X\" with the correct drive label)\n ...to verify that the head parking disabled setting survived poweroff.\n This drive appears to be mechanically identical to the white label non-helium EasyStore/MyBook drives. But, it does arrive with head parking set to 80.\n This drive seems like a steal at this price. I had 2 4TB Reds fail within the warranty period. Due to the failed Reds, I gave up on Reds and started buying white label 8TB drives. I have had zero white label drives fail so far. I am sure one white will fail tomorrow.\n    submitted by    /u/CottonBambino  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zb178f/wd_blue_8tb_hard_drive_wd80eazz_5640rpm_cmr_10999/",
          "publishedOn": "2022-12-02T23:15:57.000Z",
          "wordCount": 20540,
          "title": "WD Blue 8TB Hard Drive WD80EAZZ 5640RPM CMR $109.99",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zazo3z/rdatahoarder_shitpost_be_like/",
          "author": null,
          "description": "HELP!! I lost 4Pib of data after storing it on floppy disks, i had about 390,937,467 (+-1) disks and after 1 got corrupted i lost all my data. What can I do? I didn't try anything at all, I'm using windows 10 debloated that barely works. \n Thanks for doing the work for me!\n Edit 1: someone said i should try using a neodinium magnet on the floppy disk, my metal chair flew across the room but the floppy disk is still dead\n Edit 2: someone told me to check how the drive sounds when it reads the disk, sounds like vrrrrrrrrrr, skrrrrrrr, krrrrrr then vrrrr again\n Edit 3: someone told me to use cloud to backup my data, i don't know how to reach that cloud whilst carrying all my disks\n Edit 4: someone said i should use DSDD, i don't like DS games, no thanks!\n Edit 5: got told that diskettes sometimes get dirty and i should try licking it, tastes like TV static, 1/10 never trying again.\n    submitted by    /u/GamerKingHD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zazo3z/rdatahoarder_shitpost_be_like/",
          "publishedOn": "2022-12-02T22:17:24.000Z",
          "wordCount": 19747,
          "title": "R/DataHoarder shitpost be like",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zaygnk/how_much_maintenance_over_the_years_required_for/",
          "author": null,
          "description": "Background\n I'm scheduled to move next year to another continent (11hr plane flight away) and would like to keep a backup of my data at a family members house. This is to store my personal data/linux ISOs etc and is purely for my benefit. Unfortunately, there's no one who can maintain the system in my abscence & I dont have a concrete plan on how often I will be back in my home country.\n So, the question is, how much maintenance does a 6disk array Truenas system need with new drives?\n I realise this question is subjective as everyones 'milage may vary' and no guarantee our experiences would be the same.\n My estimates are:\n  \nconsumer nas drives last around 3 years from new\n sometimes more, sometimes less\n system would be running z2 so if a drive fails then Id shut down the system and consider my options.\n Ideally, if scrubbing has issues, SMART detects issues then I'd want to replace the 'bad' drive\n  \nQuestion1. Is it a bad idea to consider having data off-site without anyone to maintain it? Does more drives=more maintenance? \n Qu2: i.e I could 3 larger drives in Z1 or 6smaller drives in Z2, does one option (typically) require more involvement in replacing faulty drives on average? \n I would of course be able to access the drive via ssh/web interface to maintain the nas remotely.\n Qu3: Finally, in the case that one drive has bad sectors in truenas - is there an easy way to work out which drive has the fault? In the case I had to relay this to someone on site - how do we work out which bad drive out of the 6 is the bad one? \n Thanks for your advice.\n    submitted by    /u/Maximum-Warning-4186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zaygnk/how_much_maintenance_over_the_years_required_for/",
          "publishedOn": "2022-12-02T21:34:38.000Z",
          "wordCount": 22211,
          "title": "How much maintenance over the years required for a typical NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zaybxv/datahoarder_discussion/",
          "author": null,
          "description": "Talk about general topics in our Discussion Thread!\n  \nTry out new software that you liked/hated? \n Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n Come show us how much data you lost since you didn't have backups!\n  \nTotally not an attempt to build community rapport.\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zaybxv/datahoarder_discussion/",
          "publishedOn": "2022-12-02T21:30:10.000Z",
          "wordCount": 19431,
          "title": "DataHoarder Discussion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zaxygo/psu_choice_for_running_6_nas_drives/",
          "author": null,
          "description": "Hi all,\n I've rethought my design for my next nas (Truenas scale) and am contemplating using 6 x4TB drives via Raid-Z2. I'd like to re-use a PSU I already have (I need to go inspect it otherwise I'd share with you now) and am wondering the following questions:\n  \nHow much PSU wattage do I need?\n I heard somewhere that molex converters to Sata power is bad. Is this true?\n Is there a 'gold standard' of how to power 6 drives using a typical consumer PSU?\n  \nThanks all for your input.\n    submitted by    /u/Maximum-Warning-4186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zaxygo/psu_choice_for_running_6_nas_drives/",
          "publishedOn": "2022-12-02T21:17:28.000Z",
          "wordCount": 18552,
          "title": "PSU choice for running 6 nas drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zavlak/how_to_backup_drive_to_cloud/",
          "author": null,
          "description": "So I regularly back up my main PC drive to an internal HDD using Macrium Reflect. I just image the full drive and send that image to that HDD. \n However, I’m paranoid about catastrophes such as fires and such, so I’ve been looking for a way to at least save one image on an offshore cloud. \n I tried Macrium Reflect with Microsoft Azure, but my 20mb/s upload speed against a 400GB image file made uploading basically impossible. \n I’m not sure what to do. My other alternative is to occasionally back up a single image to an external HDD, and hide that in a fireproof safe or something, but even that’s not foolproof. \n Ideas? Ideally not expensive ideas lol.\n    submitted by    /u/TheBiggestHorseCock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zavlak/how_to_backup_drive_to_cloud/",
          "publishedOn": "2022-12-02T19:49:04.000Z",
          "wordCount": 18774,
          "title": "How To Backup Drive to Cloud?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zatxqg/is_that_trustworthy_seagate_exos_x16/",
          "author": null,
          "description": "So my WD Red 8TB is dying (just 1 month after warranty expired). Seeking to replace it. Living in Canada.\n Looking at prices on Amazon and newegg and stuff, everything is still quite expensive.\n I managed to find a product that seems to be at like half the price than the rest, bit too good to be true.\n But it's\n  \nRefurbished (what are the chances it have issues?)\n Not sold directly by Amazon (Tech on Tech, high rated)\n Warning about import fees (just $30)?\n The \"enterprise\" branding (I'm an individual, but is that just better?)\n  \nWhat do you guys think?\n https://www.amazon.ca/-/en/Seagate-ST14000NM001G-Disque-interne-donn%C3%A9es/dp/B08FQ3VST4/ref=sr_1_8?__mk_fr_CA=%C3%85M%C3%85%C5%BD%C3%95%C3%91&language=en_CA\n    submitted by    /u/Dunge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zatxqg/is_that_trustworthy_seagate_exos_x16/",
          "publishedOn": "2022-12-02T18:44:47.000Z",
          "wordCount": 19908,
          "title": "Is that trustworthy? Seagate Exos X16 ST14000NM001G at $231,68 cad",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zatvnk/question_lto_for_cold_storage/",
          "author": null,
          "description": "Hi,\n I would appreciate any guidance on best practices for cold storage of content. I generate content for projects which is stored on External WD drives. One drive per project with each project consuming 4-8TB of space. Roughly 2-3 projects per quarter. Consequently, I'm starting to get overwhelmed with the number of external drives living in a closet.\n There was a great video posted recently showing a migration to LTO which caught my interest. The size, weight and longevity of the LTO cartridges is very appealing but, wow, the LTO drive is pricey!\n Is the move to LTO worth the apparent pain and initial cost?\n    submitted by    /u/Obsidian28  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zatvnk/question_lto_for_cold_storage/",
          "publishedOn": "2022-12-02T18:42:36.000Z",
          "wordCount": 20753,
          "title": "Question: LTO for Cold Storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zatuzg/need_advice_on_a_good_photovideodigital_asset/",
          "author": null,
          "description": "Fellow datahoarders! I need your help.\n What programs do you use to sort out photos/videos/media? I’ve been doing a multi-year project where I’m gathering all of my family photos, old and new. I follow the 3-2-1 backup plan to make sure nothing happens in the task of gathering and digitizing old photos, but now I have thousands of pieces of media that I need to comprehensively organize that will make them easy to find and view. I’ve looked online but a lot of the programs don’t seem to be what I specifically need, lacking some feature. \n The key features I want out of the organizing software: \n  \nTagging system (e.g. being able to search for a photo/group of photos by date/person/event/place/source at the same time) \n \nA timeline view (not really needed but would definitely be awesome.)\n \nAbility to mass rename media in an organized way (eg. making a group of photos ‘2021_03_08-baseball-game-pics-cannon_rebel’ \n \nLossless conversion (might just need another program for this one) / lossless viewing after import \n \nSupports ranges of file formats (PNG, JPEG, HEIC, GIF, etc.)\n \n The program doesn’t need cloud options/storage available or built-in photo editing, but if it happens to have it then that’s an added bonus. \n In total when I’m completely done with the project, I’m expecting probably about 200-300gb of media. \n I’m open for both free and paid programs, just let me know a good one, thanks!\n Edit: Currently using Windows 10\n    submitted by    /u/Acharvix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zatuzg/need_advice_on_a_good_photovideodigital_asset/",
          "publishedOn": "2022-12-02T18:41:51.000Z",
          "wordCount": 19036,
          "title": "Need advice on a good photo/video/digital asset organizer!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zas5o7/question_about_ssd_weartear/",
          "author": null,
          "description": "I have a 500GB SSD as my main macOS drive in my Mac Pro. Typically when I download files it goes to the SSD and then I move it to my home servers. \n I know that SSDs have a limited amount of write cycles and that typically larger SSDs usually last longer due to more space for load wear leveling, but I don't really know how much is too much given the size of an SSD. TRIM is also enabled.\n Given the usage my SSD sees in about a week on average (see image), should I move the download location to one of the other internal hard drives and/or get a larger SSD? \n Thanks in advance!\n    submitted by    /u/deutsch-technik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zas5o7/question_about_ssd_weartear/",
          "publishedOn": "2022-12-02T17:34:59.000Z",
          "wordCount": 20859,
          "title": "Question about SSD wear/tear",
          "imageUrl": "https://preview.redd.it/3q3qvlatak3a1.png?auto=webp&s=f72be2794d6f1877b32eff628f6c3c959c353150"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zarryw/cleaning_up_old_hard_drives_but_dont_really_know/",
          "author": null,
          "description": "submitted by    /u/PirateDrragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zarryw/cleaning_up_old_hard_drives_but_dont_really_know/",
          "publishedOn": "2022-12-02T17:20:05.000Z",
          "wordCount": 18206,
          "title": "Cleaning up Old Hard Drives... But don't really know what to check to see if the drives are Still \"Trusted\"",
          "imageUrl": "https://preview.redd.it/dz9y2sujqi3a1.png?auto=webp&s=b73641d02ada29daa8380aae7ffb2733d916b41c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zaqw1v/would_a_smr_drive_be_ok_for_this_use_case/",
          "author": null,
          "description": "I need a drive to transport data. I will be writing big sequential files to this drive (like raw video). Then transfer the files from this drive to my actual bigger storage. Probably filling and dumping 2-4 TBs a week.\n My question is would the write speed of an SMR drive throttle the 1gbps connection I will be using to fill the said drive?\n I can format the drive after each dump. I heard that helps with speed for SMR drives.\n P.S.\n It has to be SMR because I need a 2.5\" drive without an external power supply and a 4TB ssd is just too expensive for me\n    submitted by    /u/lemmeanon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zaqw1v/would_a_smr_drive_be_ok_for_this_use_case/",
          "publishedOn": "2022-12-02T16:44:51.000Z",
          "wordCount": 18956,
          "title": "Would a SMR drive be OK for this use case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zapz8z/migrating_from_windows_to_unraid/",
          "author": null,
          "description": "Hello everyone. As the title suggests, I am trying to migrate to unraid. I'm currently in the process of disassembling my backup from DrivePool, but I need a plan for when I am done.\n Is there any way that I can format these backup disks in Windows such that they will play nicely in unraid, after I wipe my NAS array and rebuild in unraid, in order to move all the files from the backup to the unraid array? NTFS does not seem to be a great option.\n Edit: I realize now I should have mentioned this, but my main problem is that my backup is not a server, but a JBOD with SFF cables hanging out the back that I then plug into the soon-to-be unRAID server. Maybe I should think about migrating my backup to an actual server before performing this migration.\n    submitted by    /u/Mcfloyd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zapz8z/migrating_from_windows_to_unraid/",
          "publishedOn": "2022-12-02T16:06:16.000Z",
          "wordCount": 20000,
          "title": "Migrating from Windows to Unraid",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zapwb6/tube_archivist_v030_now_archiving_comments/",
          "author": null,
          "description": "submitted by    /u/pairofcrocs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zapwb6/tube_archivist_v030_now_archiving_comments/",
          "publishedOn": "2022-12-02T16:02:49.000Z",
          "wordCount": 20184,
          "title": "Tube Archivist v0.3.0 - Now Archiving Comments",
          "imageUrl": "https://external-preview.redd.it/XZ6gf87rBSQtr77em9ls4M7FYvO_At9dPZ-dI4Iwgvg.jpg?auto=webp&s=77f649b6d933c8d25d6c158c0452ed6b927750dc"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zandii/need_advice_building_a_homelab_server/",
          "author": null,
          "description": "I am thinking for hosting my own server with A lot of Services ... Like Nextcloud ;WordPress and Security cameras NVR like Ispy ...and NAS storage at the same time to all my Devices and family phones . And all kind of Dockers haha ..all on Proxmox . And I don't want to So I came across this offer on Alibaba : \n $160/set ---Dual X99 Motherboard With 2011-3 XEON E5 2670 V3*2 With 2pcs X 16GB = 32GB DDR4 3200MHz Memory Combo Kit Not include shipping charge .. I am kinda newbie to Hardware ... So Is it worth it ? Does 2 processors better than 1 ? Cuz I found a Board with one processer with lesser price .\n    submitted by    /u/MrJwan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zandii/need_advice_building_a_homelab_server/",
          "publishedOn": "2022-12-02T14:14:46.000Z",
          "wordCount": 18857,
          "title": "Need Advice Building a homelab server !",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zajj52/how_to_have_a_raid1_accessible_from_both_ubuntu/",
          "author": null,
          "description": "This topic has been discussed many times, but i didn't find anything specific to my situation.\n I would like to create a RAID1 with 2 sata drives (same brand, model,capacity). My objective is to have this raid accessible from both Windows and Ubuntu, wich are located in 2 other separate drives. So i am not trying to boot from the raid, i am just using it for storing data. I know that the easy solution would be to go for a real raid controller card, but im trying to find out if it is really necessary to spend more money. As for the software raid option, for what i've understood you can't do such a thing and make it accessible from both linux and windows, but correct me if im wrong.\n So now i am thinking about doing it using the built-in motherboard controller, but every discussion i've read comes to the conclusion that you shouldn't do it because:\n 1 - If you change motherboard you won't be sure your next hardware is gonna read the data.\n 2 - motherboard implementations of raid usually use CPU resources.\n 3 - motherboard implementations usually dont have powerloss safety features, and this could mess up the data. \n My questions are:\n 1 - Are statements (1) and (3) true also if you have a RAID1 configuration? I am saying this beacuse since it is just a straight copy i would assume the way the data is written isn't that cryptic and i can read it easily if one of the 2 corrupts(or if i change motherboard).\n 2 - Do all motherboards do this \"fake\" raid? In my case on the manufacturer site explicitly says that it supports RAID 0, 1 and 10.\n 3 - Is there a better way to achieve what I am trying to do? \n My motherboard : https://it.msi.com/Motherboard/B450-GAMING-PRO-CARBON-MAX-WIFI/Specification \n Thanks in advance\n    submitted by    /u/Cute_Rub_9074  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zajj52/how_to_have_a_raid1_accessible_from_both_ubuntu/",
          "publishedOn": "2022-12-02T11:29:41.000Z",
          "wordCount": 19199,
          "title": "How to have a RAID1 accessible from both Ubuntu and Windows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zaix5t/sas_controller_for_4kn_hdd/",
          "author": null,
          "description": "Hello, i wondered if anyone could help me with choosing best sas controler? \n I have 3 x 8tb SAS 4kn drives which were removed from servers due to some minor errors, i would like to use them as my private storage in raid 5 configuration. By private storage i mean PC, i have checked already 2 controllers ( adaptec 7805, dell perc h200) which propably dont support 4kn drives, would anybody reccomend something that would be cheap/reliable, for now i have found Dell 9265-8I  that i think supports 4kn and its around 50$ .\n For now these hdd when connected to my controllers show unsupported device and pc doesnt find them - through controller i can see model number and nothing else\n    submitted by    /u/h4ti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zaix5t/sas_controller_for_4kn_hdd/",
          "publishedOn": "2022-12-02T11:01:15.000Z",
          "wordCount": 20060,
          "title": "SAS controller for 4kn hdd ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zai584/i_ordered_a_12tb_drive_and_received_a/",
          "author": null,
          "description": "As the title says, I ordered a WD Elements 12TB model from Amazon, but when I received it today and mounted it on my computer, somehow the drive shows up as 14.5TiB(==16TB) size.\n I am a bit perplexed, and concerned if this could be a faulty product, like actually a 12TB drive with malfunctioning firmware to report itself as 16TB.\n This is my first time buying a large capacity hard drive, so I posted my question here, hoping to get some answers from more experienced people.\n edit: forgot to mention the box front sticker said 16TB while the barcode sticker said it's a 12TB model\n    submitted by    /u/zadpos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zai584/i_ordered_a_12tb_drive_and_received_a/",
          "publishedOn": "2022-12-02T10:24:25.000Z",
          "wordCount": 20593,
          "title": "I ordered a 12TB drive and received a seemingly-16TB model. A lucky accident or a malfunctioning product?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zag3q7/which_drive_should_i_pick_for_an_offsite_backup/",
          "author": null,
          "description": "Hi everyone\n So ive got 2 Drives that could be used for an offsite backup.\n  \nWD red 12tb 5400rpm schucked new - unused\n \nseagate wolf 10tb 7200rpm - daily drive\n \n I want to ask between the two, which one is better to retire aka backup? I wouldn't mind keeping the faster and older one, but if it deteriorates along the way and risks to die, wouldnt it better to retire and leave it alone where it just sits there?\n Here are some SMART facts\n Seagate old\n  SMART Attributes Data Structure revision number: 10 Vendor Specific SMART Attributes with Thresholds: ID# ATTRIBUTE_NAME FLAG VALUE WORST THRESH TYPE UPDATED WHEN_FAILED RAW_VALUE 1 Raw_Read_Error_Rate 0x000f 084 064 044 Pre-fail Always - 226766169 3 Spin_Up_Time 0x0003 087 085 000 Pre-fail Always - 0 4 Start_Stop_Count 0x0032 099 099 020 O…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zag3q7/which_drive_should_i_pick_for_an_offsite_backup/",
          "publishedOn": "2022-12-02T08:32:34.000Z",
          "wordCount": 19719,
          "title": "Which Drive should I pick for an offsite backup?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/zaa34p/local_iso_repository/",
          "author": null,
          "description": "I was wondering if anyone has setup some sort of automatic local mirror for ISO distros.\n I would like to keep a list of some ISOs that I use to be updated and stored locally on my NAS for easier use. If nothing more than, just because. Anyone have any solutions?\n    submitted by    /u/Ironfox2151  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/zaa34p/local_iso_repository/",
          "publishedOn": "2022-12-02T03:33:47.000Z",
          "wordCount": 19302,
          "title": "Local ISO Repository",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/za79si/could_i_have_done_better_this_weekend_with_only_a/",
          "author": null,
          "description": "submitted by    /u/My_Real_Acct  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/za79si/could_i_have_done_better_this_weekend_with_only_a/",
          "publishedOn": "2022-12-02T01:42:05.000Z",
          "wordCount": 19613,
          "title": "Could I have done better this weekend with only a $500 budget for new storage? The deal I got comes to about $13.29/TB. Are these good/reliable drives? Did anyone do any better?",
          "imageUrl": "https://preview.redd.it/yfie5inm1e3a1.png?auto=webp&s=f30ac6b3bbc6cac8e53616caa55f7651bc794500"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/za4e59/quick_question_how_do_you_know_health_of_your_hdd/",
          "author": null,
          "description": "Also I use Defraggler, it only shows health of HDD. Not SSD. Is Defraggler's Health accurate? How do I see SSD health?\n    submitted by    /u/udkudk1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/za4e59/quick_question_how_do_you_know_health_of_your_hdd/",
          "publishedOn": "2022-12-01T23:50:16.000Z",
          "wordCount": 18781,
          "title": "Quick question, how do you know health of your HDD and SSD's? And When to change them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/za38kv/decent_enclosure_to_attach_external_hdds_to/",
          "author": null,
          "description": "Got a great deal on quite few dell minis with i7-7700T and 16 or 32GB of ram that I want to potentially utilize one of them as a NAS. Currently my main PC has two drives passed through to ubuntu VM that are in mirror zfs pool. \n So far I looked at synology, qnap, and terramaster expansion units. Synology being quite expensive and terramaster is too low, is qnap expansion unit a good place to land? I have only two drives right now, but looking at 4+ bay for room to expand.\n    submitted by    /u/jM2me  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/za38kv/decent_enclosure_to_attach_external_hdds_to/",
          "publishedOn": "2022-12-01T23:06:53.000Z",
          "wordCount": 18998,
          "title": "Decent enclosure to attach external HDDs to tiny/mini/micro",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/za36o8/storage_test_data_creation_tools_sources/",
          "author": null,
          "description": "I've been using the HPCreateData for generating windows test data. Its small and versatile but also ancient (2003) any suggestions on a modern replacement. HPCreateData was the enterprise goto tool for test data 10+ years ago.\n For multimedia test data I use the Internet Archive Library, problem there its almost all in the Latin alphabet. Any legal sites like Internet Archive Library where file names are in non-Latin text? To be used for checking backups apps that have GUI and CLI. Downloading from the Youtube is trivial but reports using this data could end up in places you don't have control over.\n The tool is like this....\n https://preview.redd.it/eii7syd49d3a1.jpg?width=574&format=pjpg&auto=webp&s=e5c37a6b550ddfa6e2d0808d64d391c2a0663267\n    submitted by    /u/Jim-JM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/za36o8/storage_test_data_creation_tools_sources/",
          "publishedOn": "2022-12-01T23:05:01.000Z",
          "wordCount": 18901,
          "title": "Storage test data creation tools & sources?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/za0fwr/does_this_drive_look_healthy/",
          "author": null,
          "description": "submitted by    /u/Sansnom99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/za0fwr/does_this_drive_look_healthy/",
          "publishedOn": "2022-12-01T21:29:41.000Z",
          "wordCount": 19347,
          "title": "Does this Drive Look Healthy?",
          "imageUrl": "https://preview.redd.it/uv6xol9tsc3a1.png?auto=webp&s=d134cb72031b8ffcd8a2ce0a4c8d9042b736dfc4"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/za05ol/rkanye_may_potentially_shut_down_in_the_immediate/",
          "author": null,
          "description": "Given the recent events, it appears many users on the sub are calling for it to be closed. Which would be a pretty reasonable thing to do.\n https://old.reddit.com/r/Kanye/comments/z9ykaz/postlivestream_ye_on_infowars/\n    submitted by    /u/raiding_party  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/za05ol/rkanye_may_potentially_shut_down_in_the_immediate/",
          "publishedOn": "2022-12-01T21:19:57.000Z",
          "wordCount": 18570,
          "title": "/r/Kanye may potentially shut down in the immediate future",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9ymra/advice_on_windows_storage_space_with_mixed_drives/",
          "author": null,
          "description": "Hi, I have two shucked drives that I've connected to my main PC. I wanted to enact a two-way mirror with Windows' Storage Spaces. However, as the title says, the two drives are not the same size; one is 6 TB and the other is 10 TB. What I initially thought to do is to create a two partitions on the 10 TB drive: one is the same size as the 6 TB drive and part of the storage space, and the other partition to be an extra general drive for media, game storage, etc.\n So my question is: is this a sensible setup? Should I just set up a storage space with the two drives without creating separate partitions? Is there a third option that I'm not thinking of?\n    submitted by    /u/whyyoutube  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9ymra/advice_on_windows_storage_space_with_mixed_drives/",
          "publishedOn": "2022-12-01T20:24:22.000Z",
          "wordCount": 18959,
          "title": "Advice on Windows Storage Space with mixed drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9yazq/deus_ex_go_to_be_completely_disappeared_with/",
          "author": null,
          "description": "submitted by    /u/AbolishDisney  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9yazq/deus_ex_go_to_be_completely_disappeared_with/",
          "publishedOn": "2022-12-01T20:12:21.000Z",
          "wordCount": 18666,
          "title": "‘Deus Ex Go’ To Be Completely Disappeared With Studio Shutdown",
          "imageUrl": "https://external-preview.redd.it/SN1XpROtvB93NOJjW-GbKE8jFEtMifcFMYK3SbRuekA.jpg?auto=webp&s=e3d2e624576871ac1282ee75a9064e8fd20baa6f"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9wycm/backblaze_vs_deep_glacier/",
          "author": null,
          "description": "I have been using BackBlaze for my emergency cloud backup for just under 5 years. As my data grew and I added larger HDDs to the system it seemed like a very cost efficient emergency plan. The original plan (with 2TB drives) was to back them up using a \"toaster\" drive. I'd keep a copy at work and a copy at the house and BackBlaze was the emergency plan. The \"Toaster\" backup went out the window in 2018 when it began to take hours using \"eSata\" as the drives surpassed 10TB.\n Six months ago it dawn on me (one of those Duh? moments) that I now have 33TB of data on the Backblaze cloud from my six 20TB drives. In the event of a catastrophic failure the only way Backblaze allows restoration is by downloading or a second option of selling you a USB drive that they will fill with your data. You can return up to 5 of these per year for credit.* In short, a complete restoration would take a significant amount of time in 8TB chunks, between mailings.\n I have now purchased a Synology DS1821+, which despite what it says does support Seagate Iron Wolf 20TB drives (I currently have it configured using six with SHR-2 redundancy and 1 hot spare. I'd still like to use a cloud backup but is Glacier any better at a large restoration than BackBlaze was? I'm probably paranoid, but I've lost data in the past and well, you know...\n ​\n *Prior to May of this year it was a 250GB drive.\n    submitted by    /u/Owltiger2057  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9wycm/backblaze_vs_deep_glacier/",
          "publishedOn": "2022-12-01T19:22:51.000Z",
          "wordCount": 19203,
          "title": "BackBlaze vs Deep Glacier",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9u3ad/retaining_user_data_specifically_in_the_area_of/",
          "author": null,
          "description": "For tinder a users data on being rejected/passed over. For match, message requests denied/ignored.\n    submitted by    /u/dwu1977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9u3ad/retaining_user_data_specifically_in_the_area_of/",
          "publishedOn": "2022-12-01T17:41:53.000Z",
          "wordCount": 18271,
          "title": "Retaining user data, specifically in the area of dating apps. How could one see the data on requests accepted/denied ? Ie; % of left swipes on a profile vs right swipes.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9tgiu/sanity_check_before_upgrading_sas_questions/",
          "author": null,
          "description": "Hello!\n I currently have a server setup as my NAS, but I would like to not use the onboard SATA ports anymore.\n I already use some kind of SAS2008 card (flashed to IT mode), with the two SAS ports used up to 8 SATA Hard drives.\n I'm now looking at SAS Expanders because that seems like the right option to add storage connectivity to my server.\n At first I found the Intel RES2SV240 wich has a total of 6 SFF-8087 connectors and external power since my motherboard PCIe are full or too small.\n I also found the cheap 03X3834 IBM LSI 6GB, but I would need a mining riser to power the card. \n Finally, I found the Adaptec AEC-82885T. It has external power connection, but I would need to change my current SFF-8087 to Sata cables for ones that uses SFF-8643. One great advantage are the external ports which will be useful in the future.\n So currently my plan is to buy that Adaptec Card to future-proof my setup.\n Is there anyone with experience with the Adaptec card (or the Intel one?). I plan to use it with a TrueNAS Scale VM on-top of Proxmox (with the HBA pass-thru).\n    submitted by    /u/webtroter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9tgiu/sanity_check_before_upgrading_sas_questions/",
          "publishedOn": "2022-12-01T17:18:13.000Z",
          "wordCount": 19879,
          "title": "Sanity Check before upgrading - SAS Questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9tbm8/how_to_improve_movies_and_tv_shows_sorting/",
          "author": null,
          "description": "I currently have the following structure set up:\n Movies and Shows\n Subcategories: Family movies/shows, grownup movies/shows\n From there: Local language, local language with subtitles, English, English with subtitles\n And that's how I organize everything. Is there a way to automate it somehow?\n    submitted by    /u/cloudhandle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9tbm8/how_to_improve_movies_and_tv_shows_sorting/",
          "publishedOn": "2022-12-01T17:12:56.000Z",
          "wordCount": 18719,
          "title": "How to improve movies and TV shows sorting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9spgr/best_backup_utility_for_my_needs/",
          "author": null,
          "description": "Hi, I'm not sure what the best backup utility would be for what I am looking for.\n My fantasy of backing up files would be placing everything in a single folder and having an automatic scheduled time each week/day for backups to be uploaded to a free and secure cloud storage service.\n The backup would be encrypted first so that if the cloud service becomes compromised my data may still have safety.\n Ideally if a crazy house fire were to occur my data being in the cloud could be restored and decrypted from a different location if my home computer were to melt. If it exists, maybe something similar to how Veracrypt handles encryption where only a password is needed to decrypt files.\n ---\n + Automatic scheduled backups (daily/weekly)\n + Cloud support for arbitrary (free) cloud services such as Mega, Proton Drive, etc.\n + Encryption of data and decryption via passphrase\n + Free or libre\n    submitted by    /u/Equivalent_Play5247  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9spgr/best_backup_utility_for_my_needs/",
          "publishedOn": "2022-12-01T16:48:38.000Z",
          "wordCount": 20281,
          "title": "Best backup utility for my needs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9rv0z/word_of_caution_for_anyone_looking_at_using/",
          "author": null,
          "description": "Last year (August of 2021) I decided I wanted to digitally archive my tapes. I had heard of DigitalFaq and that they had a lot of good information on how to do this, like what VCR's to get and what software to use, etc. I also found that they provide professional digitzing services for VHS tapes. I figured since I only had a crappy VCR/DVD combo unit, I wouldn't mind paying to have them professionally recorded to digital video files.\n I contacted them (that in itself was a bit of a hassle and took a while - this was a red flag and I really shouldn't have persued it after that). Eventually some guy named “K” (turns out this is the owner), responded and I sent him one of my VHS tapes to test out the process.\n Thank goodness this was a tape I had multiple copies of since I NEVER got my tape b…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9rv0z/word_of_caution_for_anyone_looking_at_using/",
          "publishedOn": "2022-12-01T16:14:15.000Z",
          "wordCount": 22068,
          "title": "Word of Caution for Anyone Looking at Using DigitalFaq's Video Archiving Service",
          "imageUrl": "https://external-preview.redd.it/bmmH_g4z-FVRqpGv-GJa1tq49F3UBGXFuzmmXykwmrI.jpg?auto=webp&s=ced94db4981f3c3a16a4e50e147b5c82b9d79c98"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9rbe0/how_do_you_download_videos_from_thotporntv/",
          "author": null,
          "description": "Mfs make it impossible to download with either chrome tools or YT downloader. Jdownloader works 5% of the time.\n    submitted by    /u/fleshymeaty  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9rbe0/how_do_you_download_videos_from_thotporntv/",
          "publishedOn": "2022-12-01T15:52:44.000Z",
          "wordCount": 17072,
          "title": "How do you download videos from thotporn.tv?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9qudy/digitizing_vhs_on_mac_s_video_capture_device_via/",
          "author": null,
          "description": "Are there any high-quality capture devices that work on mac? It would be S-Video coming from my Panasonic AG1980P. \n On that note, what makes a capture card/device good or bad?\n Also, I read that NLEs like Davinci Resolve + Premiere Pro are not ideal for capturing...any Mac-friendly capture software?\n    submitted by    /u/townly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9qudy/digitizing_vhs_on_mac_s_video_capture_device_via/",
          "publishedOn": "2022-12-01T15:33:54.000Z",
          "wordCount": 20459,
          "title": "Digitizing VHS on Mac - S Video Capture Device? via Panasonic AG1980P",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9pncc/home_media_question/",
          "author": null,
          "description": "I’m running kodi on a raspberry pi 4 connected to a western digital external hard drive to watch my old dvd backups on my LG TV via HDMI. It’s worked well so far, but I’m running out of room. I’d love to set up a raid in the event of drive failure, what would you all recommend? \n Was considering getting the Yottamaster 5 Bay RAID External Hard Drive Enclosure from Amazon and a few 14 tb HDD? \n NAS seems excessive given it’s played locally, though it would be nice to stream when I travel.\n    submitted by    /u/JayGeeWise  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9pncc/home_media_question/",
          "publishedOn": "2022-12-01T14:45:18.000Z",
          "wordCount": 18644,
          "title": "Home Media Question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9nme6/file_sharing_website/",
          "author": null,
          "description": "Hi, I have a vague memory from a few years ago of a site like WeTransfer that was hosted on Backblaze servers, the name was like black hole or something similar...\n    submitted by    /u/EdwardTheGamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9nme6/file_sharing_website/",
          "publishedOn": "2022-12-01T13:16:12.000Z",
          "wordCount": 19653,
          "title": "File sharing website",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9n1es/can_i_use_namecheap_stellar_plus_to_potentially/",
          "author": null,
          "description": "The domain registrar Namecheap offers hosting services as well.\n One of those service plans - labeled Stellar Plus (see here: https://www.namecheap.com/hosting/shared/) - allows users an \"Unmetered SSD.\"\n From my research online, there is a limit to the inodes (I believe around 300,000) but if you theoretically compressed / split your files in a few tar archive(s) you could potentially achieve unlimited storage? Paying ~$70/month seems a bargain when it comes to that.\n If I actually considered this, I'd definitely encrypt the files before uploading (they have an FTP option, with unmetered bandwidth)\n So my question is this: did I find a bargain or am I barking up the wrong tree/have no idea what's up?\n Thanks!\n EDIT: I just found this legal page on Namecheap: https://www.namecheap.com/legal/hosting/aup/. From it's section labeled \" Additional Acceptable Use Policy for Virtual accounts\", it seems like the maximum file size would be 10GB based on their text. So, I guess the limit might be 3 petabytes? 10GB * 300,000 inodes (each archive would be 10GB)\n    submitted by    /u/aoa2303  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9n1es/can_i_use_namecheap_stellar_plus_to_potentially/",
          "publishedOn": "2022-12-01T12:49:34.000Z",
          "wordCount": 19096,
          "title": "Can I Use Namecheap Stellar Plus to Potentially Backup Unlimited Files?",
          "imageUrl": "https://external-preview.redd.it/iDD87QPQyDMXkO7xKw14NWFGx5INeoJqreSzMjiFnV4.jpg?auto=webp&s=6ddf025e24c1fd41d910d59e38f9adce87ead5d4"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9lvqy/are_there_any_larger_12tb_quiet_drives_without/",
          "author": null,
          "description": "Currently in my PC case there are 2x 6TB WD Reds (WD60EFRX), each about 5 years old, and they are quiet and fast enough for my needs. But they're getting old and running out of space. \n Now I'd like to upgrade to something like 2x 12/14TB or similar, and when I checked some reviews for the newest WD Reds or Ultrastars, they're filled with people who complain about the clicking/PWL noises in idle. Which is this thump every 5 seconds in idle:\n https://www.youtube.com/watch?v=ksgOgrbRPOo\n That would bother me to no end, since my drives are bolt directly to the case and any vibration would be amplified. I don't mind a bit more noise when the drive is working, but not this constant Chinese torture. So are there any drives that are 12TB+ and still suitable for a PC case? All the \"consumer\" HDDs only go up to about 4-6TB.\n Choices would be: \n  \nWD Red Plus/Pro or WD Ultrastar\n Toshiba Enterprise MG08/MG09 or Toshiba N300\n Seagate Exos X or Seagate Ironwolf\n  \nSo any of these comparable to my old WD Reds 6TB? Obviously them being 5400rpm they are a bit quieter, but I don't think I would mind them being a bit louder when working, as long as they are quiet in idle.\n    submitted by    /u/LeDucky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9lvqy/are_there_any_larger_12tb_quiet_drives_without/",
          "publishedOn": "2022-12-01T11:50:08.000Z",
          "wordCount": 18657,
          "title": "Are there any larger (12TB+) quiet drives (without PWL/clicking) for desktop PC?",
          "imageUrl": "https://external-preview.redd.it/ZtUBNbnrobtS5u5o44AoS5rThv6_bbQ0nx0Muqn8obk.jpg?auto=webp&s=f3b57194c26b19f0d95dd320f5e340e1c4010b89"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9kqsq/using_zfs_snapshots_is_there_a_nice_gui_or_web/",
          "author": null,
          "description": "I have an rsync.net account, and I'm wondering whether there is a GUI or a web app which can show me the following:\n  \ndiffs between two snapshots (files changed, collapsible by directory)\n trends about growth of the data, in which directory\n  \nof course this sort of tool would be fun to build but I'd like to look around see if something exists already.\n    submitted by    /u/BakGikHung  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9kqsq/using_zfs_snapshots_is_there_a_nice_gui_or_web/",
          "publishedOn": "2022-12-01T10:44:48.000Z",
          "wordCount": 18953,
          "title": "using zfs snapshots, is there a nice GUI or web app which shows me diffs ? and usage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9dpqz/is_this_normal_for_an_exos/",
          "author": null,
          "description": "submitted by    /u/root0777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9dpqz/is_this_normal_for_an_exos/",
          "publishedOn": "2022-12-01T04:04:11.000Z",
          "wordCount": 20524,
          "title": "Is this normal for an Exos?",
          "imageUrl": "https://external-preview.redd.it/cNX7t_i5gVJdn4T1ZfgpoN2mccc39Bx-TYI1rDiIUus.png?format=pjpg&auto=webp&s=5e5e1a1dd9acfbbb5d46fe70f3e9d08b99110426"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z9a8a5/new_hard_drive_arrived_from_amazon_not_sure_if_it/",
          "author": null,
          "description": "Hi, I'll start this off with a disclaimer, whilst I'm comfortable taking apart computers and upgrading them etc, I don't know that much about hard drives and storage specifically as, so apologies if I say something Really Ignorant.\n But my 4TB NAS drive just arrived from amazon and it didn't seem adequately packaged: \n https://preview.redd.it/4d062vw8w63a1.jpg?width=4080&format=pjpg&auto=webp&s=abf3a1f524f66e4a404bc192c966f8890663d7d1\n https://preview.redd.it/8a9yhtw8w63a1.jpg?width=3072&format=pjpg&auto=webp&s=babbaf7b746a2ed1520b4fe6f1acee9dadc87079\n After googling it, the box seems to be one of these boxes: https://newsbytes.ph/wp-content/uploads/2020/04/02.jpg\n Which, on it's own did alleviate at least some of my anxiety I felt upon seeing that the outer bag was just a bare paper bag, …",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z9a8a5/new_hard_drive_arrived_from_amazon_not_sure_if_it/",
          "publishedOn": "2022-12-01T01:37:17.000Z",
          "wordCount": 17014,
          "title": "New hard drive arrived from Amazon.... not sure if it was shipped adequately.",
          "imageUrl": "https://external-preview.redd.it/WBpjMId_AhCS8Eqz4hIxifNASivgVw8CG7GeK9UXxcM.jpg?auto=webp&s=0131eccc74521c5e9dc6f54b0110260294496515"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z99po0/finding_hp_lto5_fibre_channels_windows_10_driver/",
          "author": null,
          "description": "I bought HP LTO-5 \"Fibre Channel\"(not SAS) Full-Height drive and I tried to install the LTO driver downloaded in here; https://support.hpe.com/connect/s/softwaredetails?softwareId=MTX_eb39bdd2fa074c218499c52127&language=en_US but when I download and try to install, it installs nothing and finishes. Is this LTO drive does not support this driver? I need your help!\n    submitted by    /u/AMDRadeonHD6950  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z99po0/finding_hp_lto5_fibre_channels_windows_10_driver/",
          "publishedOn": "2022-12-01T01:15:49.000Z",
          "wordCount": 16858,
          "title": "Finding HP LTO-5 Fibre Channel's Windows 10 Driver",
          "imageUrl": "https://preview.redd.it/025z6868b83a1.png?auto=webp&s=1d73f72509dbe4c204f3a818a50f230e4589cf22"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z98m4z/slow_network_transfer_speeds_from_windows_system/",
          "author": null,
          "description": "Howdy folks, looking for a sanity check as google has failed me so far. I have a mini pc (windows 10) with a QNAP TR-004 usb3 attached. Set up a windows share of that drive on my network. That PC is plugged in to my comcast router. The Comcast WiFi sucks though so I have an ASUS mesh network plugged in to that for whole house devices. The windows PC also runs Plex so I can’t put it behind a double nat by plugging it into the ASUS. I’ve got a 5ghz backhaul between the mesh network nodes and my home computer hardwired to one of the mesh nodes.\n Here’s the trouble… copying files between them I get like 30mbps. Using windows copy or Teracopy, doesn’t matter. \n Both computers Speedtest at 500mbps to the internet ( and between the computers using a program to test LAN speed at 600+mbps) so clearly the WiFi backhaul is plenty faster to my home pc. \n Any settings tweaks to speed up windows copies? It feels like those copies aren’t multithreaded… is there a better copy program that will?\n    submitted by    /u/Dopey0121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z98m4z/slow_network_transfer_speeds_from_windows_system/",
          "publishedOn": "2022-12-01T00:29:54.000Z",
          "wordCount": 16260,
          "title": "Slow network transfer speeds from windows system with DAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z98m3m/got_my_drives_in_the_mail_today_one_of_the_4/",
          "author": null,
          "description": "submitted by    /u/tazman3582  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z98m3m/got_my_drives_in_the_mail_today_one_of_the_4/",
          "publishedOn": "2022-12-01T00:29:51.000Z",
          "wordCount": 15922,
          "title": "got my drives in the mail today one of the 4 drives came like this. the box they came in was perfect same with the outer box. this was damaged from factory don't think I should even trust this drive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z973kt/should_i_keep_my_hdd_5tb_wd_connected_to_pc_when/",
          "author": null,
          "description": "Hello guys,\n Sorry I’m asking too after some people already did, I’d like to get a personal recommendation please.\n I’m regular to turn on my PC sometime during the day, at night shutting it down, and in between it enters sleep mode after 15 minutes of no use.\n For the last days I’m having my new HDD connected for some hours a day. I understood that an HDD doesn’t like being plugged out and in, and until now I did that because I haven’t been using it frequently. But now that I am, what is it best to do?\n Should I leave it connected to PC and continue letting it go in a sleep mode and shut it down once a day? Or is sleep mode/shutdown not good for the HDD and I should eject and unplug it?\n And what would be the recommendation if I go back to use it not as much?\n Thanks in advance.\n    submitted by    /u/toktok159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z973kt/should_i_keep_my_hdd_5tb_wd_connected_to_pc_when/",
          "publishedOn": "2022-11-30T23:29:15.000Z",
          "wordCount": 17394,
          "title": "Should I keep my HDD 5TB WD connected to PC when it enters Sleep Mode/shuts down?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z96p9n/using_par2_to_improve_data_backuparchival/",
          "author": null,
          "description": "Hi all\n Someone mentioned recently they always spent 15% of the available space for a par2 data parity file when backup up to CD-R. Clearly back in the day. That idea intrigued me.\n Then someone chimed in that they still do this to this day for backups! Is this prevalent and a thing you are doing?\n I for one do a SHA512 crc of all the files and back up using 3-2-1 where ZFS 128bit, is the cornerstone of my approach. \n However I have not done any more steps to improve the likelihood of recovery success. Maybe this is it?\n    submitted by    /u/espero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z96p9n/using_par2_to_improve_data_backuparchival/",
          "publishedOn": "2022-11-30T23:13:33.000Z",
          "wordCount": 16004,
          "title": "Using par2 to improve data backup/archival resiliency",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z96eec/help_with_finding_imagevideo_archiving_software/",
          "author": null,
          "description": "I've been searching for almost a year for software to meet some of my needs and keep falling short. I have about 50 gb of images and 10 tb of video for a research project that I need to organize, categorize, and have easy access to. My basic needs are:\n - Ability to import metadata for each file (currently in .csv files)\n - Ability to sort quickly between a handful of categories (creating my own hot keys is fine) and add free form tags\n - I would love to use the same app for photos and videos, but I've been operating under the assumption I will not find an app that will do both. \n - Able to access files on a server\n - Accessible by multiple users on both Mac and Windows. Bonus: some ability to work on iOS or Android. \n I'm currently using Devonthink for just images, which works *fine* but is giving me problems importing video via AppleScript and doesn't have Windows options. Anyone have any suggestions of what other options there may be out there to try to handle this?\n    submitted by    /u/hier_ist_kein_warum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z96eec/help_with_finding_imagevideo_archiving_software/",
          "publishedOn": "2022-11-30T23:02:00.000Z",
          "wordCount": 17117,
          "title": "Help with finding image/video archiving software?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z95d8i/just_received_my_new_wd_elements_14tb_is_it_dead/",
          "author": null,
          "description": "submitted by    /u/MINHDOEKOE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z95d8i/just_received_my_new_wd_elements_14tb_is_it_dead/",
          "publishedOn": "2022-11-30T22:23:17.000Z",
          "wordCount": 16984,
          "title": "Just received my new WD Elements 14TB... is it dead? (doesnt show up in File Explorer too)",
          "imageUrl": "https://preview.redd.it/m966pbhuy53a1.png?auto=webp&s=cc73164893670b672eb2b19b7caa48e0dcadfabe"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z94ws7/best_way_to_backup/",
          "author": null,
          "description": "So I want to backup files from Google Drive and OneDrive onto my harddrive. But, I am constantly using and updating the various folders that I'd like to backup.\n What is the best way of doing this as the quickest way I can think of would be to clear my harddrive each time and then re-download the files, as otherwise I'd have to keep track of which files I have already downloaded and or changed in the interim. \n TLDR What's the best way of downloading Google drive files that I keep changing\n    submitted by    /u/-alexn-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z94ws7/best_way_to_backup/",
          "publishedOn": "2022-11-30T22:06:42.000Z",
          "wordCount": 17640,
          "title": "Best way to backup?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z91zbf/synology_c2_storage/",
          "author": null,
          "description": "Does anybody have any experience with Synology C2 Storage? \n I’m looking to back up the movies/TV in my plex server (~12 TB) on my DS 920+ to a cloud provider, since I have external hard drives as local backups. I’ve only had the NAS for a few months but want to make sure I don’t lose my data and adhere to the 3-2-1 rule.\n Synology C2 is an option that I’m considering primarily because it seems like it should integrate well with the NAS, and the cost seems slightly better than what I would have to pay for something like Backblaze (~$800 vs. ~$1000).\n    submitted by    /u/Baker-Decent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z91zbf/synology_c2_storage/",
          "publishedOn": "2022-11-30T20:18:49.000Z",
          "wordCount": 16590,
          "title": "Synology C2 Storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z91sjd/nas_build_sanity_check/",
          "author": null,
          "description": "Hi all. I'm doing my first NAS build, and I'm hoping to get some eyes on my part list to check that everything makes sense before I pull the trigger. I've got the following constraints:\n  \nRack mounted\n Quiet enough that I can sleep in the same room if needed\n ECC memory\n Can run a media server w/ transcoding\n  \nAnd here's my parts list:\n  \n Component Choice Comments/questions \n  \n Case RSV-L4500U 15 bays for 4U isn't much, but I'm hoping it will improve cooling (read: run quieter) \n  Motherboard Supermicro X11SCH-F  \n  CPU Intel Xeon E-2288G  \n  RAM 32GB ECC Is this compatible with both the CPU and mobo? \n  Boot drive 32GB SuperMicro SATADOM  \n  HBA LSI 9211-8i (look on eBay)  \n  Hard drives WD Red I plan to start with a single mirrored pair and add mirrored pairs as needed \n  Cooling Noctua case/cpu fans  \n  PSU Corsair ATX 650W 80 plus gold  \n \n For software I plan to run zfs on TrueNAS CORE. I plan to add mirrored pair vdevs over time as needed.\n Any feedback is appreciated. Thanks!\n    submitted by    /u/4BSa75rz1U639di1NrDf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z91sjd/nas_build_sanity_check/",
          "publishedOn": "2022-11-30T20:11:28.000Z",
          "wordCount": 16380,
          "title": "NAS build sanity check",
          "imageUrl": "https://external-preview.redd.it/VsqSocfeYN5p_7CHfJtnVQRyCAnmkmFvYSN8caCkmOM.jpg?auto=webp&s=be8c7597a3a69701909db544ea52b994fc670a90"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z90n22/overwriting_old_hdds_within_win10/",
          "author": null,
          "description": "What is the best way to overwrite old HDDs Within Win10?\n 1) I do not want a dedicated USB boot/Linux option. Thanks.\n 2) I do not want to destroy HDDs that are perfectly fine. Thanks. \n 3) Currently I just download a bunch of 4K videos from YT, then copy and paste them until the disk is full, then I do a full format from Windows explorer. Is that enough to make previous data permanently inaccessible?\n Thanks!\n    submitted by    /u/real_smoky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z90n22/overwriting_old_hdds_within_win10/",
          "publishedOn": "2022-11-30T19:28:04.000Z",
          "wordCount": 18507,
          "title": "Overwriting old HDDs within Win10",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8zyx4/nas_for_backups_on_all_the_time/",
          "author": null,
          "description": "People who use NAS - do you have the box powered all the time (except when adding / taking out HDDs)?\n I have a whole bunch of HDDs for different backups and every few months, connect them to this caddy and use a comparison tool to drag new / updated files across.\n It's more of a case that I don't continually backup and rarely need to access the backed up data, so electricity costs probably won't be worth keeping a NAS on all the time (although I could combine it with a HTPC, but even that we use less than once a week these days).\n So... people who backup, do you have backups attached through as NAS or what?\n    submitted by    /u/banisheduser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8zyx4/nas_for_backups_on_all_the_time/",
          "publishedOn": "2022-11-30T19:03:54.000Z",
          "wordCount": 21758,
          "title": "NAS for Backups - On all the Time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8zbu3/data_management/",
          "author": null,
          "description": "Hello. I am new to NAS and all this stuff haha, so I could really use some tips and useful information in the proccess.\n ​\n Background information\n ​\n I have 3 main external hard drives:\n ​\n 1. 14 TB for Movies 2. 14 TB for TV Shows 3. 2 TB for Family Photos, Backup of my smartphone photos and other important stuff 4. I will buy hard drives for each one of these external hard drives because I want to have everything with a backup. \n ​\n Movies: 80% is 1080p, 20% is 2160p (90% of them x265)\n TV Shows: 90% is 1080p, 10% is 2160p (all of them x265)\n ​\n I download the media content through Arrs (Sonarr, Radarr and Bazarr) and play it through Plex in all my devices.\n ​\n I would like to have the 3 hard drives always running in the NAS and make the backups for them 4 times a year (with external HDD and keep them in a different location for robberies or fires).\n ​\n Any useful information about the way I would like to manage my NAS and data would be nice!\n    submitted by    /u/Bash348  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8zbu3/data_management/",
          "publishedOn": "2022-11-30T18:41:35.000Z",
          "wordCount": 17091,
          "title": "Data management",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8y2kz/snapraid_elucidate_on_windows_performance_what_do/",
          "author": null,
          "description": "Hi,\n Anyone uses such setup? How easy it is and hows the performance? Read Write especially?\n Is there any option settings to add SSD cache drives?\n    submitted by    /u/-Hexenhammer-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8y2kz/snapraid_elucidate_on_windows_performance_what_do/",
          "publishedOn": "2022-11-30T17:55:14.000Z",
          "wordCount": 18750,
          "title": "SnapRAID + Elucidate on Windows, Performance? What do you think?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8xd9w/i_found_the_backup_and_got_80_of_my_data_back/",
          "author": null,
          "description": "A while ago I made a huge mistake and I lost all my data on my exteenal hard drive, over 2TB of stuff just gone. The expert I talked to said that there was no chances of recovery. However during my Chrisrmas cleaning I found a backup of an older hard-drive that I completely forgot about and I managed to recover 80% of my data. Through my Oblivion and Sims mods are gone as they were only on the destroyed drive, I got most of my audiobooks, ebooks and comics back, as well as personal pictures and data. I feel so relieved. I was fully prepared to have to start from 0 and was grieving my loss and then this. I could dance. From now on I will make regular backups and not put all my eggs in one basket.\n Edit: Story for any mistakes english is not my first language.\n    submitted by    /u/RedRiverValley  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8xd9w/i_found_the_backup_and_got_80_of_my_data_back/",
          "publishedOn": "2022-11-30T17:27:30.000Z",
          "wordCount": 17853,
          "title": "I found the backup and got 80% of my data back",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8xcf6/best_data_storage_solution_for_a_researcher/",
          "author": null,
          "description": "I'm a doctoral student, and while I've been storing copies of my research files (camera trap photos, R code files, some GIS files, etc) on an external drive, I've been thinking about adding a cloud storage service for redundancy. My research files at the moment total just under 100 GB (my system in total takes up under 350 GB, in case a full system backup is what is recommended). I don't expect to access these files often (ideally never) but in case something happens on my machine, or I just do something stupid and delete a file/folder I need, I want to be able to quickly access/retrieve the needed files/folders (so not necessarily retrieving the whole system). It would be nice to encrypt my research files, but I'm not working on anything where I am unduly worried about data theft in any case. I'd say my priorities are: \n  \nReliability \n Cost (of storage primarily, then upload/download)\n Download Speed/accessibility \n Security/Privacy \n Upload speed\n  \nI use a Windows machine from Lenovo if that makes any difference, but could conceivably move to a Macbook down the line. I use File History with my external backup drive.\n I'm posting cus I see so many different recommendations from iDrive to Backblaze to IceDrive to Mega, etc, including in this subreddit, and I figure at this point I'm overthinking it and should seek recs for my specific use case scenario (or maybe for what I want, it doesn't really matter all that much what I choose)\n    submitted by    /u/TigerLeader  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8xcf6/best_data_storage_solution_for_a_researcher/",
          "publishedOn": "2022-11-30T17:26:37.000Z",
          "wordCount": 18286,
          "title": "Best data storage solution for a researcher",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8ug9c/ripping_from_streaming_sites/",
          "author": null,
          "description": "I'm not sure if this is allowed here. Let me also preface this by saying this is for personal use. I also tried to search the sub but mainly came across Bluray and DVD ripping.\n On some sites like Mubi, there are very interesting films which can be hard to come across in other places. I have discovered many rare films this way and when they remove them from the catalog they are very hard to find. I work in film stuff and would love to be able to revisit many of these later on.\n Can anyone point me to how I could do this? Any sites, videos, posts, etc, which explain this would be greatly appreciated.\n Thank you\n    submitted by    /u/Powerful-Employer-20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8ug9c/ripping_from_streaming_sites/",
          "publishedOn": "2022-11-30T15:32:27.000Z",
          "wordCount": 18832,
          "title": "Ripping from streaming sites?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8u78p/coping_with_dataloss/",
          "author": null,
          "description": "Hi, I want to ask the community for some emotional help. I've lurked for a long time but made an account today just for this post(and hope to stop by occasionally).\n I'm not exactly a major datahoarder but I'm definitely a sentimentalist. Recently thanks to some dumb decisions on my part and not paying attention while working on hard drives, and some circumstances that led to me losing my backups, I lost 2TB of super important sentimental data spanning 18 years almost. I feel like an idiot for screwing this up so badly. It's been three weeks and I'm horribly depressed to say the least. I feel like I lost a loved one.\n Those who can share experiences and give advice, please do, I want to stop feeling so much intense grief. Or at least reduce it.\n (Before anyone brings it up, no, data recovery is impossible)\n    submitted by    /u/Scramatic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8u78p/coping_with_dataloss/",
          "publishedOn": "2022-11-30T15:22:13.000Z",
          "wordCount": 19419,
          "title": "Coping with dataloss?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8t4cb/dvd_or_blu_ray_mdisks/",
          "author": null,
          "description": "I want to archive all of my personal data onto M-Disks (around 500gb). I want to get 5 100GB Blu-Ray M-Disks for a long-term cold storage, but I've heard in passing that DVD's are more reliable, but they hold a lot less. Is the difference negligible or for long-term storage is one better than the other?\n    submitted by    /u/PassportNerd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8t4cb/dvd_or_blu_ray_mdisks/",
          "publishedOn": "2022-11-30T14:38:33.000Z",
          "wordCount": 17141,
          "title": "DVD or Blu Ray M-Disks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8rsqx/wd_14tb_hdd_rma_bare_shucked_drive_or_in_enclosure/",
          "author": null,
          "description": "Well it finally happened to me, one of my 14TB's in my Synology failed. It's one of 2 14TB's that I shucked and I kept everything (box, plastic shells, cables, etc) and opened it without breaking any clips; HOWEVER it doesn't look like I marked which internal drive came from which enclosure.\n I read through some threads here and it seems very hit or miss either way (sending bare shucked drive or reassembling). I'm guessing there's no way for us to tell which internal drive belongs in which shell?\n    submitted by    /u/CiViCKiDD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8rsqx/wd_14tb_hdd_rma_bare_shucked_drive_or_in_enclosure/",
          "publishedOn": "2022-11-30T13:41:25.000Z",
          "wordCount": 18302,
          "title": "WD 14TB HDD - RMA bare shucked drive or in enclosure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8qsqv/can_seagate_skyhawk_be_used_for_storage/",
          "author": null,
          "description": "I'm a complete noob when it comes to technology, and I desperately need your help.\n I want a storage solution for family photos and videos kept on over 20 separate CDs and 2-3 USB drives.\n I found this HDD in a local store and was wondering whether it could be used for storage (connected to a docking station) from time to time.\n I read that this is a surveillance HDD that can be used 24/7, so my question is if it can be used occasionally, say once every two months, and then stored somewhere else without power?\n    submitted by    /u/the-emotional-emu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8qsqv/can_seagate_skyhawk_be_used_for_storage/",
          "publishedOn": "2022-11-30T12:55:53.000Z",
          "wordCount": 17359,
          "title": "Can SEAGATE SkyHawk be used for storage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8l12y/best_tools_to_show_the_difference_in_files/",
          "author": null,
          "description": "I bought a new, faster NVMe drive and cloned my Windows system drive onto it using Macrium\n However, there's a small discrepancy in the total files/file sizes.\n Is there a tool to analyze both drives and show me which files it finds that differ between the two?\n Everything seems to be (mostly) in order, but there's a 6GB difference in used space on the two drives.\n (Also worth noting that my taskbar flashes for a few seconds while the desktop loads on the cloned drive, which doesn't happen if I boot from the old drive. I am using an app called TaskbarX, but it isn't working properly since cloning and I don't think that's the issue as the flashing was happening prior to re-configuring that program. In any case, this isn't the proper subreddit for that particular issue)\n    submitted by    /u/MiguelLancaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8l12y/best_tools_to_show_the_difference_in_files/",
          "publishedOn": "2022-11-30T07:32:59.000Z",
          "wordCount": 18465,
          "title": "Best tools to show the difference in files between two cloned drives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8irvw/20tb_satasas_2699930499_or_18tb_sata_18999/",
          "author": null,
          "description": "submitted by    /u/igmyeongui  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8irvw/20tb_satasas_2699930499_or_18tb_sata_18999/",
          "publishedOn": "2022-11-30T05:42:04.000Z",
          "wordCount": 19254,
          "title": "20tb Sata/SAS $269.99-$304.99 -or- 18tb Sata $189.99 Seagate recertified with 2 year warranty, wish I had the money, thought I'd share here!",
          "imageUrl": "https://external-preview.redd.it/Fs6C9svF_Yci9-7roJ3v71orbPpfFyPn329BHhNSQU8.jpg?auto=webp&s=4c1db49fea90382fef14d5213d071fac818998ff"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8c8xl/internet_archive/",
          "author": null,
          "description": "I can't mention any cryptocurrency here but the internet archive's recent partnership has me concerned. If people react to it badly, another burning of the library of alexandria but with the internet archive\n    submitted by    /u/Coolkatisa2511  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8c8xl/internet_archive/",
          "publishedOn": "2022-11-30T01:01:01.000Z",
          "wordCount": 16570,
          "title": "Internet archive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8bnnu/something_like_unraid_but_free/",
          "author": null,
          "description": "So I was working on setting up a new TrueNas Scale, but it doesn't let you just add a disk willy-nilly. UnRaid seems like it does. Unraid costs money. Is there a solution like Unraid, but free? I'd like to just add my drives together and go. I typically used Raidz1, Unraid has a solution so does synology, I assume a freee option exists too?\n    submitted by    /u/Steeler_Train  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8bnnu/something_like_unraid_but_free/",
          "publishedOn": "2022-11-30T00:36:55.000Z",
          "wordCount": 16250,
          "title": "Something Like unRaid but Free",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8a10l/external_ssd_connected_247_in_a_server/",
          "author": null,
          "description": "Is it good to use ssd instead of hhd in a small server 24/7 used to download/upload large files (linux iso LOL)? Are they reliable as a wd gold?\n    submitted by    /u/P0lpett0n3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8a10l/external_ssd_connected_247_in_a_server/",
          "publishedOn": "2022-11-29T23:33:27.000Z",
          "wordCount": 16540,
          "title": "External ssd connected 24/7 in a server",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z86qo5/recovering_data_when_nas_fails_the_actual_nas_not/",
          "author": null,
          "description": "I'm new to this and debating getting a NAS for general backup.\n I understand that if a drive fails you can just swap it out and the NAS will repair/repopulate data from the other drive, but I don't know what would happen if the NAS itself failed? Do you just connect the drives to PC and copy/paste the files inside, or do you have to get another NAS of the same brand and hook the drives up to the new NAS to access those files?\n I'm planning on getting a 2 bay Synology and set up RAID 1.\n    submitted by    /u/khoa-gritson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z86qo5/recovering_data_when_nas_fails_the_actual_nas_not/",
          "publishedOn": "2022-11-29T21:27:22.000Z",
          "wordCount": 16610,
          "title": "Recovering data when NAS fails (the actual NAS not the disks)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z85s5u/which_usb_hub_with_individual_onoff_switches/",
          "author": null,
          "description": "Hey guys, \n I'm having a hard time finding a quality 6+ port USB hub to hook temporarily (4-5 months) six MyBooks (all 14TB) to a mini-PC on a Type-C USB 3.1 Gen 2 port. Typical usage would be copy/move stuff between the internal SSD drive to any one of the six MyBooks (one operation at a time). The important thing is the presence of individual on/off switches, so the drives would only run on demand (I need each one only 2-3 times a week and don't want them spinning up randomly or at boot/shutdown).\n The only semi-legit device I can find is this hub by StarTech, however, most people in the sub have a pretty bad opinion about that brand and the price seems a bit steep, to be honest. That being said, the last thing I want is for my data to become corrupted because of some alphabet soup brand's bad hardware... (speaking of which, any recommendations for a solid USB-B to Type-C data cable are much appreciated!)\n What I like about StarTech's device is the use of actual switches, and not buttons, which usually don't remember the last state after power-cycling...\n Thanks for reading and have a good one!\n    submitted by    /u/kraddock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z85s5u/which_usb_hub_with_individual_onoff_switches/",
          "publishedOn": "2022-11-29T20:52:09.000Z",
          "wordCount": 15407,
          "title": "Which USB hub with individual on/off switches?",
          "imageUrl": "https://external-preview.redd.it/WWUhFm1UH1d76VeFn5Jq1cUqG3TT3n3wMI2Dar76WPY.jpg?auto=webp&s=0d14aa9fae0a561c95e7ee557dceb55abc4fafa9"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z83kas/getting_pending_defects_log_on_brand_new_drives/",
          "author": null,
          "description": "Hi there !\n I just received 4 ironwolf 4TB drives (ST4000VN006) and started checking them for potential damage from shipping.So i did a smart check on all of them (https://file.io/0e2x4hA6sV8m)\n smartctl /dev/sdX -x \n and discovered that one of them (Disk 2) is having \"Pending Defects log (GP Log 0x0c)\" unlike the 3 others.\n Is that something i should be worried about ? Should i send it back for replacement ?I can't seem to find what those infos means.\n I also started a badblocks and a long smart test on all 4 drives, but it's gonna take time.\n badblocks -v /dev/sdX smartctl /dev/sdX -t long \n Thank you in advance.\n    submitted by    /u/UsrnameBetween3and20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z83kas/getting_pending_defects_log_on_brand_new_drives/",
          "publishedOn": "2022-11-29T19:31:50.000Z",
          "wordCount": 14799,
          "title": "Getting \"Pending defects log\" on brand new drives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z8317z/media_server_best_practices_for_video_compression/",
          "author": null,
          "description": "Henlo.\n I've finished ripping the Blu-Rays for Avatar: The Last Airbender. And while I'm very happy with the result, each episode clocks in at around 5.5GB which isn't exactly ideal for streaming.\n I will of course be keeping these original files, but I've recently built a new PC with a 5700x and a 6700xt so I can once again re-encode things (hooray).\n The BD of ATLA is an upscaled version of the original 480p broadcasts (might've been 480i, unsure). I'm looking for \"visually lossless\", which should be easy as many scenes already look not the best. I'd have to apply lots sharpening filters and such to get a better look, something which I don't have experience with.\n Anyhow, using ffmpeg, how do you guys usually re-encode media for smaller sizes? Doom9 mentions a few x265 options specifically, but ofc many clients don't support direct h265 streams.\n Bonus question: blu ray subs are not fun, what's the best way to turn them into actual subtitles?\n    submitted by    /u/General-Stryker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z8317z/media_server_best_practices_for_video_compression/",
          "publishedOn": "2022-11-29T19:11:52.000Z",
          "wordCount": 17977,
          "title": "[Media Server] Best practices for video compression?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z82bni/adding_files_to_already_burnt_mdisk/",
          "author": null,
          "description": "Long story short I'm pretty sure this isn't possible but y'all would know if there's some weird way to do it so I figured I would ask. Basically I have ultra critical stuff on M-disks, but I know there are those 100gb mdisks. Is it possible to burn a few gigs to an M-disk, and then come back later, do a file compare and add more files to the same disk? Keeping everything that's already on the disk just adding more data. Thank you!\n    submitted by    /u/rickyh7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z82bni/adding_files_to_already_burnt_mdisk/",
          "publishedOn": "2022-11-29T18:45:38.000Z",
          "wordCount": 15186,
          "title": "Adding files to already burnt M-Disk?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z825og/help_hoarding_video/",
          "author": null,
          "description": "I'm trying to download some videos from this site - https://www.skatehype.com - most of the browser extensions (in Edge) I've tried haven't been able to detect the video, the one that can is unable to download because it continutally pauses after getting too many errors.\n If I inspect, network, media etc it looks like the video file is https://www.skatehype.com/s/v/12/3/12383.mp4 - but I can find a way of using this to download the video.\n Any pointers in the right directions would be greatly appreciated, thanks.\n    submitted by    /u/gorillabankrolls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z825og/help_hoarding_video/",
          "publishedOn": "2022-11-29T18:39:31.000Z",
          "wordCount": 17942,
          "title": "Help hoarding video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z81uny/what_is_a_good_price_for_samsung_870_evo_4tb_25/",
          "author": null,
          "description": "Thank you for your input. My current SSD just failed on me.\n    submitted by    /u/nando1969  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z81uny/what_is_a_good_price_for_samsung_870_evo_4tb_25/",
          "publishedOn": "2022-11-29T18:28:36.000Z",
          "wordCount": 16083,
          "title": "What is a good price for SAMSUNG 870 EVO 4TB 2.5 that is brand new?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z81oge/idrive_e2_s3compatible_storage_lots_of_errors/",
          "author": null,
          "description": "Hi,\n When I copy files from a source to iDrive e2 using rclone, I am getting a lot of errors from e2:\n \"upload corrupted: Etag differ:\"\n rclone then retries and succeeds.\n Is that normal?\n    submitted by    /u/TedBob99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z81oge/idrive_e2_s3compatible_storage_lots_of_errors/",
          "publishedOn": "2022-11-29T18:22:01.000Z",
          "wordCount": 16019,
          "title": "iDrive e2 (S3-compatible storage): lots of errors \"upload corrupted: Etag differ:\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z80szt/incremental_drive_imaging_solutions_for_linux/",
          "author": null,
          "description": "I'm looking for a solution for cloning images of my drives that works for Linux systems and supports incremental backups. My current solution is Clonezilla. Works really well but requires me to clone the entire drive every time.\n I've combed through the community posts. Many seem to recommend Macrium Reflect. The posts are a bit on the older side, though. Is Macrium still a good option? \n Also, not strictly necessary; but is there an option that allows me to keep using my system as it does the backup? I don't think even Macrium allows that on Linux systems.\n I'd really appreciate any guidance.\n    submitted by    /u/Ushahin_Ceann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z80szt/incremental_drive_imaging_solutions_for_linux/",
          "publishedOn": "2022-11-29T17:49:43.000Z",
          "wordCount": 18160,
          "title": "Incremental drive imaging solutions for Linux.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7vi0k/i_know_i_have_more_files_than_these_is_something/",
          "author": null,
          "description": "submitted by    /u/DeniableW3b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7vi0k/i_know_i_have_more_files_than_these_is_something/",
          "publishedOn": "2022-11-29T14:25:11.000Z",
          "wordCount": 16814,
          "title": "I know I have more files than these? Is something wrong? Details in comments.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7vdem/upgraded_storage_now_this_is_podracing/",
          "author": null,
          "description": "Went from 6x3TB wdred RAID6 (cca 10TB usable) to 5x18TB ironwolfs zfs RAIDZ2 (cca 50TB usable). Is this data hoarding enough? :D\n https://preview.redd.it/rdp5i6aefw2a1.png?width=422&format=png&auto=webp&s=40e887408da64aecaa69a09d0528019c617b433e\n This is my homeserver btw, Im also working on a second NAS in a different location for offsite backups. Not sure how much storage Ill be putting into that, but considering I dont need to backup everything from the main storage (i dont really care that much about losing movies/tv series) itll probably be a bit smaller\n    submitted by    /u/OsaSoft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7vdem/upgraded_storage_now_this_is_podracing/",
          "publishedOn": "2022-11-29T14:20:00.000Z",
          "wordCount": 16760,
          "title": "Upgraded storage. Now this is podracing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7tpg5/isnt_this_kind_of_thing_a_terrible_idea/",
          "author": null,
          "description": "submitted by    /u/themacmeister  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7tpg5/isnt_this_kind_of_thing_a_terrible_idea/",
          "publishedOn": "2022-11-29T13:12:14.000Z",
          "wordCount": 19198,
          "title": "Isn't this kind of thing a terrible idea?",
          "imageUrl": "https://preview.redd.it/lo1gu3tj3w2a1.jpg?auto=webp&s=59c4fe147c6bc8380d04fd3fadac39f8e5dd5002"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7sd5g/wd_elements_slow_transfer_speed_3060mbs_taking/",
          "author": null,
          "description": "submitted by    /u/theseawoof  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7sd5g/wd_elements_slow_transfer_speed_3060mbs_taking/",
          "publishedOn": "2022-11-29T12:12:44.000Z",
          "wordCount": 16021,
          "title": "WD Elements Slow Transfer Speed. 30-60mb/s, taking over a day to transfer a couple of terabytes. is this normal?",
          "imageUrl": "https://preview.redd.it/vyrb5rulax2a1.jpg?auto=webp&s=a950836152682ae4e22e320e953896381aaa213c"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7q0on/is_there_a_way_for_gallerydl_to_download_images/",
          "author": null,
          "description": "I am mass downloading from Pixiv, and it puts all the images into one single folder per artist. I would like each post(each one has ~4-6 images) to have its own folder, named after the title of the post, in the artist folder.\n How would I do this? What would the command for that be?\n    submitted by    /u/GayCumLover  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7q0on/is_there_a_way_for_gallerydl_to_download_images/",
          "publishedOn": "2022-11-29T10:17:07.000Z",
          "wordCount": 16022,
          "title": "Is there a way for Gallery-dl to download images in separate folders in the artist folder instead of just in the artist folder?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7pzcw/any_good_deals_for_14_18_tbs_drives_in_europe/",
          "author": null,
          "description": "Based on the discussions here, there seem to be quite a few nice deals in the US right now. However, I can't find anything worthwhile in Europe. If you see any, please share. I urgently need at least 14 TBs drive within a couple of next days.\n Thank you.\n    submitted by    /u/ExNihilo___  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7pzcw/any_good_deals_for_14_18_tbs_drives_in_europe/",
          "publishedOn": "2022-11-29T10:15:16.000Z",
          "wordCount": 16806,
          "title": "Any good deals for 14 - 18 TBs drives in Europe right now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7pf86/western_digital_seagate_toshiba_drive_lineup/",
          "author": null,
          "description": "I took the time to go through all the Western Digital, Seagate, and Toshiba 3.5\" hard drive lineups and compile this chart. This is for bare 3.5\" drives only, not including externals.\n Columns indicate capacity and nomenclature is C = CMR, S = SMR, 5 = 5400/5640 RPM, 7 = 7200 RPM\n This is specifically for 4Kn drives. All drives 12TB and up are Helium. Some 8TB and 10TB are helium but not clearly defined.\n  Wrkld Drive Brand Type TB/yr Wrnty 500GB 1TB 2TB 3TB 4TB 6TB 8TB 10TB 12TB 14TB 16TB 18TB 20TB 22TB 24TB 26TB ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ WESTERN DIGITAL Blue Consumer < 100 2 yrs C 5 7 C 5 7 S 5 7 S 5 S 5 S 5 C 5 Black Consumer < 100 5 …",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7pf86/western_digital_seagate_toshiba_drive_lineup/",
          "publishedOn": "2022-11-29T09:47:15.000Z",
          "wordCount": 17795,
          "title": "Western Digital, Seagate, Toshiba Drive Lineup Summary",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7ocyw/whats_the_best_storage_per_dollar_25_inch_drive/",
          "author": null,
          "description": "I've been attempting to get my jp server up and running however what used to be a non issue is now becoming an issue as I'm planning on backing up my desktop to the server I'd like to as cost affectively as is reasonable take advantage of it's 25 hard drive bays. It seems that hard drives of that size and at capacities over 1tb are a rarity/mostly exist as external hard drives. I'd ideally like a warranty on the drives as well as opposed to shucking the drives. So far I've just been able to find a Toshiba 4tb drive for 84 dollars. However I have my doubts about it's reliability. I was hoping and wondering if someone would know of a better option than what I've found.. thanks a lot.\n    submitted by    /u/yiseveryusernametkn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7ocyw/whats_the_best_storage_per_dollar_25_inch_drive/",
          "publishedOn": "2022-11-29T08:50:39.000Z",
          "wordCount": 16241,
          "title": "what's the best storage per dollar 2.5 inch drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7k12q/you_guys_are_about_the_only_ones_who_might_be/",
          "author": null,
          "description": "Long story short, I have what I think is a proprietary connector, but I'd like to make sure before I shell out the big bucks on something that is commonly sold under a name I don't know.\n My company just acquired a bunch of busses, all of which included 24/7 Security's \"Zeus\" DVR, the problem is none of them had hard drives in them, go figure. 24/7 sells their hard drives for a cool $400 per, and I'm about to need probably 30+, that's a ton of money for hard drives. \n Here's the info I have:\n  \nThey're a single connector which is 20 pins.\n They are a hybrid style drive with an SSD and HDD inside- the SSD records while the bus is in motion and then transfers it to the HDD once the bus has stopped.\n There's multiple other SD card slots and the like as seen here.\n  \nIs there any sort of alternative to their \"infinity drive\" or am I stuck buying those and-or replacing the whole system? Any and all help is much appreciated.\n    submitted by    /u/stopthemeyham  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7k12q/you_guys_are_about_the_only_ones_who_might_be/",
          "publishedOn": "2022-11-29T05:02:21.000Z",
          "wordCount": 16555,
          "title": "You guys are about the only ones who might be able to help me here: DVRs on Busses.",
          "imageUrl": "https://external-preview.redd.it/y-Ku1Oh7uKkypteI0-aWp0OflV-PkP3vywXKzroTaUE.png?auto=webp&s=efd47622ce35db009c0df91cb323b0b26ceea8c4"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7h51e/over_estimated_christmas_gift_digitizing_all_old/",
          "author": null,
          "description": "My bright idea was to digitize my mom's pre-iphone photo collection...everything pre-2013. Free but meaningful gift for all my siblings & parents and even a few aunts/uncles. BOOM gift buying snuffed out with 1 simple easy idea. We're talking my parents family photos as well going back the 1950s, a few CDs of my grandparents as kids/teens around the 1940s (someone digitized them when CD rom drives were relevant, crap do I need to buy a CD drive?).\n So I am a dumb ass, completely misjudged the numbers. Napkin math, which wasn't even really done, put me around 2-3k photos. Well I've barely made a dent in the first of 3 file boxes and its over 2500+. I'm estimating possible 50,000 photos at this point.\n Plan was to scan, upload to Google Photo and attempt to \"sort\" them using the album face r…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7h51e/over_estimated_christmas_gift_digitizing_all_old/",
          "publishedOn": "2022-11-29T02:47:59.000Z",
          "wordCount": 21295,
          "title": "Over estimated Christmas gift - digitizing all old photos. Any tips before I get too deep?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7f7kt/file_archival_images_and_video/",
          "author": null,
          "description": "What is considered the go-to M-Disc device that is supported by current Macs? I am looking at burning images and videos to disk for long-term storage.\n    submitted by    /u/clorth0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7f7kt/file_archival_images_and_video/",
          "publishedOn": "2022-11-29T01:23:20.000Z",
          "wordCount": 15192,
          "title": "File archival: images and video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7dxp9/18tb_seagate_exos_enterprise_hdd_7200_rpm_26999/",
          "author": null,
          "description": "submitted by    /u/Viknee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7dxp9/18tb_seagate_exos_enterprise_hdd_7200_rpm_26999/",
          "publishedOn": "2022-11-29T00:28:05.000Z",
          "wordCount": 15465,
          "title": "18TB Seagate Exos Enterprise HDD 7200 RPM - $269.99 ($15/TB)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7dwwz/is_there_something_like_antitwin_that_works/",
          "author": null,
          "description": "I have been using anti twin today, which is an older program but works exactly like I need it to. The one thing that is a bit challenging is that if I resolve some of the duplicates without all of them. It \"concludes\" my session and requires me to essentially start over. I was wondering if theres a similar program that allows you to \"recheck found duplicates\" or \"update\" without starting over... Thanks\n    submitted by    /u/deten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7dwwz/is_there_something_like_antitwin_that_works/",
          "publishedOn": "2022-11-29T00:27:06.000Z",
          "wordCount": 17214,
          "title": "Is there something like anti-twin that works pretty much exactly the same but allows you to update the existing \"found duplicates\" without starting a fresh scan?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7dsq4/2tb_usb_portable_sandisk_ssd_cyber_monday_sale/",
          "author": null,
          "description": "I know it's not really NAS related, but it's still a good drive at a good deal.\n Western Digital: https://www.westerndigital.com/products/portable-drives/sandisk-usb-3-2-ssd#SDSSDE30-1T00-G25\n Amazon: https://www.amazon.com/dp/B08RSML1B8\n B&H: https://www.bhphotovideo.com/c/product/1730628-REG\n    submitted by    /u/HTWingNut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7dsq4/2tb_usb_portable_sandisk_ssd_cyber_monday_sale/",
          "publishedOn": "2022-11-29T00:22:11.000Z",
          "wordCount": 15072,
          "title": "2TB USB Portable Sandisk SSD Cyber Monday Sale $119 B&H, $129 WD and Amazon.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7dsku/does_anyone_have_a_source_for_the_osama_bin_laden/",
          "author": null,
          "description": "Download directly from .gov doesn't work anymore and neither does links in Internet Archive.\n    submitted by    /u/-jaqk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7dsku/does_anyone_have_a_source_for_the_osama_bin_laden/",
          "publishedOn": "2022-11-29T00:22:01.000Z",
          "wordCount": 15229,
          "title": "Does anyone have a source for the Osama Bin Laden Files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7dkvx/easystore_8tb_preshuck_is_this_an_smr_drive/",
          "author": null,
          "description": "Bought an Easystore 8TB at Best Buy. Crystaldiskinfo says it has a serial number of WD-CA02J09K drive of 8TB, with 5640 RPM. Is this a slower SMR drive? Was hoping for an ultrastar but guess I better return this one? Edit:\n The title says:\n WDC WD80EMZZ-11B4FB0 8001,5 GB\n    submitted by    /u/Sungofi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7dkvx/easystore_8tb_preshuck_is_this_an_smr_drive/",
          "publishedOn": "2022-11-29T00:13:17.000Z",
          "wordCount": 15172,
          "title": "Easystore 8TB pre-shuck. Is this an SMR drive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7dins/obscure_web_archives/",
          "author": null,
          "description": "I have been trying to find deleted YouTube videos. These videos were uploaded between 2007-2009 and were deleted early 2010. I was wondering if there are any obscure or non-mainstream web archiving services that may be able to help me in my hunt. I have some of the video URL's but I don't know if I can do anything with them. This is my first time posting here so I don't know if this is the right place to post this. Any help would be greatly appreciated.\n    submitted by    /u/Wilsonc22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7dins/obscure_web_archives/",
          "publishedOn": "2022-11-29T00:10:50.000Z",
          "wordCount": 17205,
          "title": "Obscure Web Archives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7chh9/oraclebranded_hgst_drives_unusable_in_ktnstl3/",
          "author": null,
          "description": "Hi all,\n Recently got some 4TB Oracle-Branded HGST drives with the hopes of using them in my storage array, but it appears they must have some kind of custom firmware that prevents them from being used outside of Oracle systems. The drives show up fine on my proxmox host, but cannot be accessed in any way it seems.\n Hardware is a Dell R620 running PVE 7.4, with an LSI 9200-8E card connected to a KTN-STL3 with the\n 303-115-003D interposers (this setup has been working flawlessly with other HGST drives for months).\n Output of lsscsi -sig shows the drives, but without size information:\n sudo lsscsi -sig ... [1:0:5:0] disk HGST H7240AS60SUN4.0T A3A0 /dev/sdh 35000cca07321dee0 /dev/sg7 - [1:0:6:0] disk HGST H7240AS60SUN4.0T A3A0 /dev/sdi 35000cca0734068c8 /dev/sg8 - [1:0:7:0] disk HGST H7240AS6…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7chh9/oraclebranded_hgst_drives_unusable_in_ktnstl3/",
          "publishedOn": "2022-11-28T23:31:05.000Z",
          "wordCount": 15826,
          "title": "Oracle-branded HGST Drives Unusable in KTN-STL3?",
          "imageUrl": "https://external-preview.redd.it/CICHxXLGq68ilw8d2PYBwLJPx8Q7XK2fkdP0tQ3V4zk.jpg?auto=webp&s=edeb780257355018112ac22467f829b77cf12790"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7bymw/best_way_to_transfer_from_s3_buckets_to_truenas/",
          "author": null,
          "description": "I'm currently running a r710 and MD1200 looking to mirror some s3 buckets. I was looking for the best way to do this. Current running idea is to ssh and run rclone. This is my first setup and any advice would be greatly appreciated!\n    submitted by    /u/kylewizerd15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7bymw/best_way_to_transfer_from_s3_buckets_to_truenas/",
          "publishedOn": "2022-11-28T23:11:11.000Z",
          "wordCount": 15426,
          "title": "Best way to transfer from S3 buckets to TrueNAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z79nsk/brand_new_seagate_ext_hardrive_can_you_help_me/",
          "author": null,
          "description": "I bought a brand new 4tb Seagate external hardrive. It works great and wanted to check its health via SMART control. Here are the results:\n Read Error Rate: Value: 3451774; Normalized: 65; Threshold: 6; Worst: 64\n Result: Pre-fail; Assessment: OK\n  \nSpinup Time: Value: n/a ; Normalized: 99; Threshold: 0; Worst: 99\n Result: Pre-fail; Assessment: OK\n  \nStart/Start Count: Value: 6; Normalized: 100; Threshold: 20; Worst: 100\n Result: Old-age; Assessment: OK\n  \nReallocated Sector Count: Value: 0 sectors; Normalized: 100; Threshold: 10; Worst: 100\n Result: Pre-fail; Assessment: OK\n  \nSeek error rate: Value: 102693; Normalized: 100; Threshold: 45; Worst: 253\n Result: Pre-fail; Assessment: OK\n  \nPower on hours: Value: n/a; Normalized: 100; Threshold: 0; Worst: 100\n Result: Old-age; Assessment: OK\n  \nSpinup Retry count: Value: 0; Normalized: 100; Threshold: 97; Worst: 100\n Result: Pre-fail; Assessment: OK\n  \nRun-Time-bad-block-total:** Value: 0; Normalized: 100; Threshold: 0; Worst: 100\n Result: Old-age; Assessment: OK\n  \nPower Cycle Count:** Value: 5; Normalized: 100; Threshold: 20; Worst: 100\n Result: Old-age; Assessment: OK\n  \nEnd to End error: Value: 0; Normalized: 100; Threshold: 99; Worst: 100\n Result: Old-age; Assessment: OK\n ......\n    submitted by    /u/birthdaysuit111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z79nsk/brand_new_seagate_ext_hardrive_can_you_help_me/",
          "publishedOn": "2022-11-28T21:46:55.000Z",
          "wordCount": 15883,
          "title": "Brand New Seagate Ext. Hardrive; can you help me interpret SMART control settings?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z79f9f/howto_dl_archive_of_technical_aesthetics_a/",
          "author": null,
          "description": "Anyway to scrape this page and DL all at once instead of 1 at a time?\n http://tehne.com/library/tehnicheskaya-estetika-byulleten-zhurnal-moskva-1964-1992\n    submitted by    /u/badatmathdave  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z79f9f/howto_dl_archive_of_technical_aesthetics_a/",
          "publishedOn": "2022-11-28T21:38:25.000Z",
          "wordCount": 15776,
          "title": "Howto?: DL archive of Technical Aesthetics, a monthly industrial design magazine published by the Soviet Technical Aesthetics Research Institute from 1964 - 1992.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z79f7b/lga1200_mobo_recommendations/",
          "author": null,
          "description": "Hi! I’m working on building my unraid NAS using a few recycled parts from previous builds. I was getting things ready when I noticed several bent pins in the old mobo I had slated for the build. I have a 10700k and an 11600k for the cause. I know neither is ideal in terms of power draw/heat, but I’d prefer not to sell and replace. With all that in mind, are there any ATX boards with 2.5g LAN that make more sense than others in terms of features and price? Currently, I only need 6 sata ports and a single m.2 gen 3. Any guidance is appreciated! Thanks!\n Edit: based on my own research it looks like the Gigabyte B560 Aorus Pro AX board might do the trick. Eager for your input though!\n    submitted by    /u/SwedishishKSP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z79f7b/lga1200_mobo_recommendations/",
          "publishedOn": "2022-11-28T21:38:21.000Z",
          "wordCount": 16766,
          "title": "Lga1200 mobo recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z77tj5/freefilesync_cannot_see_mounted_nas_share_in/",
          "author": null,
          "description": "Hi all, \n I updated my computer to Fedora 37 and installed FreeFileSync v11.28 from FlatHub. \n I've been using FFS for many years for backing up my files to a NAS Share.\n I do not keep the share permanently mounted in Fedora, I only mount it when I want to do a backup. I'd like to keep this practice. \n In the past, I would first mount the share in Nautilus file manager, then open FFS and it would appear as a destination. Now, even if I have mounted the share in Nautilus, the share does not appear in FFS at all. \n The NAS has the IP address 10.10.10.6 and the share is called \"backup\", so I assume I could enter any of the following and one would work: \n /run/user/1000/gvfs/smb-share:server=10.10.10.6,share=backup \n or \n //10.10.10.6/backup \n or \n smb://10.10.10.6/backup \n but none of these works. \n Has something changed?\n Is there a way to manually add the share's full path to FFS?\n    submitted by    /u/Idiots-R-Invincible  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z77tj5/freefilesync_cannot_see_mounted_nas_share_in/",
          "publishedOn": "2022-11-28T20:41:01.000Z",
          "wordCount": 15308,
          "title": "FreeFileSync cannot see mounted NAS share in Fedora 37",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z77nit/is_it_possible_to_update_firmware_on_an_external/",
          "author": null,
          "description": "Hey there! \n I have an older external 4tb HDD. Listed as the LaCie 4TB F.A. Porsche Designed Desktop Hard Drive.\n I want to install a 14 or 16 TB internal HDD (Western Digital, or Seagate) but when I do, my Macs both state that the HDD is unrecognized and offers me option to format the HDD. I am using the USB connection. I think the controller on the external HDD enclosure does not recognize HDDs of such high capacities. The reason I want do this is for aesthetics. I like the look of the enclosures.\n Is it possible to fix this problem? \n Thanks for any help.\n    submitted by    /u/Mister_Splendid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z77nit/is_it_possible_to_update_firmware_on_an_external/",
          "publishedOn": "2022-11-28T20:35:01.000Z",
          "wordCount": 15752,
          "title": "Is it possible to update firmware on an external HDD enclosure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7756k/is_an_ssd_a_reliable_form_of_longterm_storage_for/",
          "author": null,
          "description": "I've been backing up my PC games from places like Steam, GOG, etc. on 100 GB Blu-ray discs. However, I have a lot of games to back up, and modern games can very easily go over 100 GB per game. I've been throwing around the idea of giving up optical media for my backups, and going with something like a 4TB SSD, especially today on Cyber Monday; putting games onto an SSD would be a lot faster than burning them to a Blu-ray disc, and obviously any SSD that I choose is going to hold more than a single Blu-ray disc, even a triple-layer one. If all I'm using the SSD for is long-term storage, can I expect reliability? I don't even plan on putting it into my PC, I would only plug it in externally whenever I want to add something to it for safekeeping, or if I want to restore/recover something later.\n Or, if I'm looking to save some money, how are mechanical HDDs for the long-term? I assume they're not as good as something with no moving parts.\n Thanks in advance for any insight, I really love the idea of long-term archiving, but I admit that I'm pretty new at this.\n    submitted by    /u/FireCrow1013  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7756k/is_an_ssd_a_reliable_form_of_longterm_storage_for/",
          "publishedOn": "2022-11-28T20:16:33.000Z",
          "wordCount": 16549,
          "title": "Is an SSD a reliable form of long-term storage for backed up files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z7701m/how_do_i_download_all_postsvideos_from_someones/",
          "author": null,
          "description": "There is not really much to say - just looking for a way to download all photos/videos from a users instagram. The account i wanna download it all from has 1598 posts and i simply can't go through downloading all of them at once.\n    submitted by    /u/Hellboymeep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z7701m/how_do_i_download_all_postsvideos_from_someones/",
          "publishedOn": "2022-11-28T20:11:24.000Z",
          "wordCount": 15476,
          "title": "How do i download all posts/videos from someones instagram account?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6z5zl/wd_blue_35_8tb_cmr_5640_rpm_hdd_10999_usa_cyber/",
          "author": null,
          "description": "$13.62/TB\n Amazon: https://www.amazon.com/dp/B09KMGQG5Y\n Western Digital: https://www.westerndigital.com/products/internal-drives/wd-blue-desktop-sata-hdd#WD80EAZZ\n Seems Amazon ships pretty much immediately, WD Store indicates available 3-4 weeks.\n    submitted by    /u/HTWingNut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6z5zl/wd_blue_35_8tb_cmr_5640_rpm_hdd_10999_usa_cyber/",
          "publishedOn": "2022-11-28T15:18:48.000Z",
          "wordCount": 14985,
          "title": "WD Blue 3.5\" 8TB CMR 5640 RPM HDD $109.99 (USA) Cyber Monday Deal (Amazon and WD Store)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6z4xe/wd_elements_12tb_175_after_40_off_promo_code/",
          "author": null,
          "description": "submitted by    /u/Kosofkors  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6z4xe/wd_elements_12tb_175_after_40_off_promo_code/",
          "publishedOn": "2022-11-28T15:17:31.000Z",
          "wordCount": 15809,
          "title": "WD Elements 12TB: $175 after $40 off promo code",
          "imageUrl": "https://preview.redd.it/qet2t0j2lp2a1.png?auto=webp&s=c40c3b7a7ad094899748d2ea343232f8cad7833e"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6yt5j/how_do_you_all_monitor_ambient_temps_for_your/",
          "author": null,
          "description": "submitted by    /u/MzCWzL  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6yt5j/how_do_you_all_monitor_ambient_temps_for_your/",
          "publishedOn": "2022-11-28T15:03:39.000Z",
          "wordCount": 18233,
          "title": "How do you all monitor ambient temps for your drives? Cooking drives is no fun... I think I found a decent solution with these $12 Govee bluetooth thermometers and Home Assistant.",
          "imageUrl": "https://external-preview.redd.it/esDCCiBgxKOkGPVZ0hQfcX_7iiqy7pV0c3iDwBPCZTA.jpg?auto=webp&s=b48a34bccb2954db8eb1e4c65492d55fd53a6469"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6wm22/can_discs_be_removed_from_from_optical_disc/",
          "author": null,
          "description": "If I understand it correctly these contain multiple bdxls, so if I take them out can I write and read them in a regular bdxl compatible drive instead of using the whole cartridge in $10000 readers? It seems cheaper than buying 100 or 128gb bdxls by themselves.\n    submitted by    /u/Voldy256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6wm22/can_discs_be_removed_from_from_optical_disc/",
          "publishedOn": "2022-11-28T13:29:18.000Z",
          "wordCount": 15841,
          "title": "Can discs be removed from from optical disc archival cartridges?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6w06z/web_archive_html_code_dump_of_websites/",
          "author": null,
          "description": "I have seen a website similar to Wayback Machine / archive.org that used to crawl and index HTML code of every webpage / website. I forgot the website. Does anyone know anything similar?\n For example, we could search for some term like \"<h1>twitter</h1>\" and it used to return all webpages that has a twitter inside head tag in their html code.\n Thanks in advance\n    submitted by    /u/karthiksudhan-wild  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6w06z/web_archive_html_code_dump_of_websites/",
          "publishedOn": "2022-11-28T13:01:39.000Z",
          "wordCount": 16431,
          "title": "Web Archive - HTML Code dump of websites",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6vrk8/download_of_google_classroom_materials/",
          "author": null,
          "description": "Good morning everyone. Like most people studying, I got fucked by the pandemic and became part of the Zoom Academy, and most of the materials we used are digital only. I wanted to know if there's a way to download 3 years' worth of documents, assignments, and such on Google Classroom to my computer. My access to these documents is coming close, so I wanted to store them for future use. Is there anything I can do, or should I download everything manually?\n A random guy on Discord said I should come to this sub to search for answers, so sorry if this is not the correct place\n    submitted by    /u/Sanslution  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6vrk8/download_of_google_classroom_materials/",
          "publishedOn": "2022-11-28T12:50:55.000Z",
          "wordCount": 15980,
          "title": "Download of Google Classroom Materials",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6vqqz/download_specific_file_types_from_dropbox/",
          "author": null,
          "description": "Hi reddit,\n ​\n I need to download a specific file type from my dropbox account. In this case only all .mp4-files. Any suggestion how I can do it? \n ​\n It's not possible to use the \"Multi file organize/Custom filters\" to move all the files to a new directory. All directories needs to be kept as they are.\n    submitted by    /u/blowmycool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6vqqz/download_specific_file_types_from_dropbox/",
          "publishedOn": "2022-11-28T12:49:55.000Z",
          "wordCount": 16589,
          "title": "Download specific file types from Dropbox",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6uljs/wd_16tb_elements_external_230_20tb_320/",
          "author": null,
          "description": "submitted by    /u/Anzial  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6uljs/wd_16tb_elements_external_230_20tb_320/",
          "publishedOn": "2022-11-28T11:54:13.000Z",
          "wordCount": 16682,
          "title": "WD 16TB Elements External @ $230, 20tb @$320",
          "imageUrl": "https://external-preview.redd.it/sl-jKLXWfamwYrVvLlNJl8A98qFRYd21LJx1pv0WSeU.jpg?auto=webp&s=d533c09e4e1c69de0bd50bc25ae8da9e7dbafee7"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6ik0v/eac_accurate_rip_results_wont_upload_to_database/",
          "author": null,
          "description": "I have been ripping some cds using exact audio copy with accurate rip setup. I tried to submit my results to the database and it says it successful however when I try to rip the CD again it says tracks not in accurate rip database. I tried disabling my firewall and using another computer but results are the same. Is there anything I could to so that my results get uploaded? No issues with the cds as well all ripped accurately according to cue tools.\n    submitted by    /u/atitann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6ik0v/eac_accurate_rip_results_wont_upload_to_database/",
          "publishedOn": "2022-11-28T01:09:37.000Z",
          "wordCount": 16644,
          "title": "EAC accurate rip results wont upload to database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6hvmm/nas_synology_model_to_start_which_raid_1510etc/",
          "author": null,
          "description": "Simply1- will store family photos and memories , 2- will create locked file to store my photos and my important files no body of my family can see what into file , , 3- I want upload TV Series and movies for adults my father and mother they old don't know how to see by internet , we not like Netflix , and also will upload videos for kids , Spiderman or Cartoon Tom&jerry ..etc\n want my own cloud, I not trust cloud services to store family photos and my important files\n please guide my to right Synology model and which raid\n parents and my brothers and sisters total 8with their children : 5 . total 13+ , to use NAS or server or App ..please guide me to right model and raid , Thanks\n    submitted by    /u/commanderA1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6hvmm/nas_synology_model_to_start_which_raid_1510etc/",
          "publishedOn": "2022-11-28T00:39:13.000Z",
          "wordCount": 17850,
          "title": "NAS Synology model to start ? which Raid ? 1,5,10,etc...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6hu3q/new_cloud_storage_service_requesting_feedback/",
          "author": null,
          "description": "Hi there,\n I'm Tom and I am a DataHoarder :)\n I'm based in Europe and I've just setup a small cloud storage service.\n A short story about my initial thoughts on this project:\n I've been Hoarding Data for over two decades now, going through all phases (losing data, having multiple copies of them, 3-2-1 rules etc), and I've noticed that it is getting very expensive after a while (well, you can notice that very fast nowadays hah).\n All these started when I wanted to grab a couple of extra TBs of online storage to backup some secondary data. There aren't many affordable (mind you, $5-$7/TB might be cheap for some) options out there and all I wanted was to share a box with someone.\n So I've decided to make a little project to \"fix\" this. Maybe there are more people out there who think the same (you never know until you try?). I've had my ups and downs but this is something I was really excited to code. This is also the first project I created after a long time (so please be kind :)). Hopefully it will make me get back to the game.\n I'm basically splitting up the servers, no overselling or anything like that, and you can use (S)FTP, SCP, rsync, Rclone, Duplicati, BorgBackup to create your backups.\n Requesting Feedback:\n I'm offering 100GB Trials for a week for you to play around and provide any kind of feedback so I can improve either the quality of the service or the website itself. I know it requires a signup and email verification but I tried to make it as painless as possible :(\n You can check it out here.\n I'm already working on the next phase (the first one wasn't anything special, just a basic build :)) which I think it can do wonders to decrease the cost of online storage even further. Hopefully it will be ready sometime in Q1 2023. I will let you know :)\n Thank you for your time! \n Tom\n PS: I've got approval from the moderators to post this thread.\n PS2: I've made a similar post on Hacker News earlier today, just a small FYI.\n    submitted by    /u/ExtraLayer_eu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6hu3q/new_cloud_storage_service_requesting_feedback/",
          "publishedOn": "2022-11-28T00:37:17.000Z",
          "wordCount": 17138,
          "title": "New Cloud Storage Service - Requesting Feedback",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6hro4/how_can_you_actually_use_your_facebook/",
          "author": null,
          "description": "You download your information from Facebook, and just thousands of files you need to open one by one. Is there a way to make this actually useful and accessible?\n    submitted by    /u/stackshockprism  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6hro4/how_can_you_actually_use_your_facebook/",
          "publishedOn": "2022-11-28T00:34:13.000Z",
          "wordCount": 16405,
          "title": "How can you actually use your facebook information downloaded?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6g7sy/is_there_a_cheap_but_reliable_2_bay_raid_enclosure/",
          "author": null,
          "description": "Just looking for an enclosure to hold 2 3.5\" drives. They don't even need to be raid, just independent. Just trying to keep them safe. \n It seems like they are all expensive, and it's hard to find one with a cooling fan. \n Do I really need a cooling fan? The data is important and cannot be lost, so longevity and reliability is important. Just not sure if drives can actually get that hot or if it affects reliability. \n Looking to get something for like $80 or less. Seems tough to find. But I can't have something that kills one of my drives. I figured something like a raid enclosure should be relatively simple to manufacture...\n    submitted by    /u/longjohn97410  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6g7sy/is_there_a_cheap_but_reliable_2_bay_raid_enclosure/",
          "publishedOn": "2022-11-27T23:27:44.000Z",
          "wordCount": 17121,
          "title": "Is there a cheap but reliable 2 bay raid enclosure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6ff81/will_a_usb_30_drive_enclosure_work_as_a_good/",
          "author": null,
          "description": "Back in February I picked up an OWC Mercury Elite Pro external enclosure for pretty cheap, as it was open-box. It's a dual drive enclosure with USB 3 and eSATA connections, fairly well built with an aluminum body and fan in the back, and - importantly - has a hardware RAID controller so it can run your 2 disks individually, in Span mode, or in RAID 0 or 1.\n Thanks to Black Friday, I nabbed 2 10TB WD Red Plus drives for a good price, and my intent is to stick them in the OWC, run them in RAID 1 for mirroring, and then connecting the enclosure to a Thin Client PC over USB 3, and then installing Debian to the Thin Client to run everything I need - Plex, backups, maybe some minor game server hosting and file serving.\n The OWC's RAID seems fully featured, if one of the mirrored drives dies, all you need to do is insert a new identical drive and it will automatically rebuild (I would obviously still back up the remaining good drive before initiating the rebuild), I'm just wondering if it sounds like a good idea. On one hand, USB 3 is a very fast standard, but on the other, it feels weird to be running a 10TB mirrored NAS over a single USB cable. Maybe it's a common setup, and I'm just new to this, but I was looking for some reassurance.\n    submitted by    /u/Shadow-Prophet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6ff81/will_a_usb_30_drive_enclosure_work_as_a_good/",
          "publishedOn": "2022-11-27T22:55:47.000Z",
          "wordCount": 18380,
          "title": "Will a USB 3.0 drive enclosure work as a good basic NAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6fb9u/8tb_wd_blue_for_109/",
          "author": null,
          "description": "Newegg\n Amazon\n    submitted by    /u/mattchew1010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6fb9u/8tb_wd_blue_for_109/",
          "publishedOn": "2022-11-27T22:51:18.000Z",
          "wordCount": 16371,
          "title": "8TB WD Blue for $109",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6epad/looking_to_do_a_motherboard_upgrade_and_need/",
          "author": null,
          "description": "Background: So I want to upgrade my SuperMicro board. I would need to get a Intel board (quick sync for plex) and preferably a new 13th gen CPU (delay the need to upgrade). Now I am not opposed to getting a 10G LAN card if that saves me money but I would like to maintain 2x 10GB ports like I have now. I will need to get an HBA card that will give me enough SATA for 15 drives, but there are many posts on this subreddit on which to get, so no issues there. This server will need to handle 8 transcodes simultaneously and at times 4-5 of those will be 4k video's.\n Help: Should I stay with a server board to maintain ECC or is DDR5's sudo ECC enough?\n Help: Are there any boards under $600 with 13th gen support and ECC support?\n Help: Are there even any server boards that support 13th gen?\n Notes: If I am making any wrong assumptions or am crazy with what I am looking for please help me and point in the right direction.\n    submitted by    /u/Networkpro117  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6epad/looking_to_do_a_motherboard_upgrade_and_need/",
          "publishedOn": "2022-11-27T22:27:07.000Z",
          "wordCount": 19542,
          "title": "Looking to do a Motherboard Upgrade and need advice.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6e88z/how_often_have_you_experienced_a_corrupt_files/",
          "author": null,
          "description": "Most here have at least 1TB+ my self included. I’m a Mac user so I haven’t found out how to scan a drive or a folder for corrupt files but so far I haven’t encountered any issues. What are your experiences? \n All my drives are stationary so nothings ever been dropped or exposed to water or anything which helps my case for sure.\n    submitted by    /u/QualitySound96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6e88z/how_often_have_you_experienced_a_corrupt_files/",
          "publishedOn": "2022-11-27T22:08:51.000Z",
          "wordCount": 17693,
          "title": "How often have you experienced a corrupt file(s)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6dd03/18tb_exos_x20_how_many_per_vdev/",
          "author": null,
          "description": "Right now I'm running 10x8TB in a RaidZ2 vdev, but with the increase in size and resilvering times I'm not sure what is recommend to be max number of disks in a z2 vdev.\n I'm thinking 8 at the moment\n    submitted by    /u/MrAlfabet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6dd03/18tb_exos_x20_how_many_per_vdev/",
          "publishedOn": "2022-11-27T21:35:58.000Z",
          "wordCount": 16552,
          "title": "18TB Exos X20 - how many per vdev?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6cj0r/seagate_16tb_exos_x16_not_recognized_on_b550m/",
          "author": null,
          "description": "I can confirm the drive works using an external USB 3.0 SATA disk docking station (Axiom). I can also confirm my SATA cable and PSU cables are good, as they work with a WD 4TB Blue. SATA set to AHCI. But when I plug in the X16 the drive doesn't even spin up on boot.\n Windows 10 Gigabyte B550M Aorus-P (F15d BIOS) I've updated the chipset\n Is there something picky with this drive/mobo combo? Why does it work externally but not plugged into my mobo?\n    submitted by    /u/gban38  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6cj0r/seagate_16tb_exos_x16_not_recognized_on_b550m/",
          "publishedOn": "2022-11-27T21:03:12.000Z",
          "wordCount": 16238,
          "title": "Seagate 16TB Exos X16 not recognized on B550M Aorus-P",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6bdhl/windows_clone_on_usb_drive_usb_to_sata_convertor/",
          "author": null,
          "description": "I'm cloning windows to a USB drive but of course now I'm realizing I probably cannot boot from a USB drive without some specific clean Windows install to the USB drive. And I'm not sure its possible to make another usable clone from a USB drive to SATA drive if the original windows drive was to fail.\n I would expect a USB to SATA connector could potentially fix the problem, but I also don't know (rookie) if I would have to use the USB to SATA connector as I was making the clone, or if I can attach a SATA convertor after making a clone only with the use of a USB connection.\n Im using Macrium Reflect Free.\n If keeping backups of windows isnt considered data-hoarding, my bad.\n    submitted by    /u/tenclowns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6bdhl/windows_clone_on_usb_drive_usb_to_sata_convertor/",
          "publishedOn": "2022-11-27T20:17:31.000Z",
          "wordCount": 17675,
          "title": "Windows clone on USB drive - USB to Sata convertor question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6aglm/60tb_gaming_nas/",
          "author": null,
          "description": "Hello! I have been backing up games for well over a decade now and have something like 60TB including artwork. I know a RAID isn’t a backup and I had a bit of a scare the other day and I’ve decided to get serious about making a backup. I was looking into tape drives and I never realized how expensive they were, but something needs done. So… what do you all recommend? I’ve been looking at an IBM 3592-E08\n Thank you.\n    submitted by    /u/Sasquatters  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6aglm/60tb_gaming_nas/",
          "publishedOn": "2022-11-27T19:42:16.000Z",
          "wordCount": 17160,
          "title": "60+TB Gaming NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6a9nn/archiving_flickr_albums/",
          "author": null,
          "description": "Hey,\n I'm looking for some tool to download images in bulk on Flickr (Albums notably). I've searched on GitHub for some sort of CLI program but haven't been able to get any of them to work.\n Maybe just have to write my own Python script or something.\n ​\n Any help is appreciated!\n    submitted by    /u/Jormunvakur  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6a9nn/archiving_flickr_albums/",
          "publishedOn": "2022-11-27T19:34:32.000Z",
          "wordCount": 17004,
          "title": "Archiving Flickr Albums",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z6a1nd/pdf_library_solution_for_ocr_and_tagging/",
          "author": null,
          "description": "Greetings friends,\n I'm sitting on a pile of PDFs I'd like to organize and searchable. I've come across paperless, but building a NAS or a raspberry pi just to tag and search some PDFs seems overkill, and with 2 young kids and 2 more on the way, I don't have a huge amount of time to fiddle around with tech.\n Currently, all that stuff is handled in Evernote, but if possible, I'd like to leave behind the world of proprietary systems for that task.\n Any advice?\n    submitted by    /u/Gilgeam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z6a1nd/pdf_library_solution_for_ocr_and_tagging/",
          "publishedOn": "2022-11-27T19:25:46.000Z",
          "wordCount": 16636,
          "title": "PDF library: Solution for OCR and tagging",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z68j76/running_weekly_consistency_checks_on_10tb_drives/",
          "author": null,
          "description": "This article on ServeTheHome got me thinking... in a RAID array where periodic \"scrubs\" or consistency checks are recommended to prevent bit rot, the entire disk has to be read. \n I did some quick math for my own array which uses HGST He10 10TB drives with 550TB/yr rated workload and the default MegaRAID settings of weekly consistency check AND patrol read, resulting in\n 10TB * 2 * 52 = 1040TB/yr read\n While doing both of them monthly instead is\n 10TB * 2 * 12 = 240TB/yr read, leaving 310TB/yr for actually using the drives\n I searched to see if anyone else had posted here or on other forums about this concern and couldn't find anything. Should I reduce the frequency to monthly to avoid 'wearing out' the drives, or is a weekly check needed to prevent bit rot on high capacity drives?\n EDIT: thanks for all the data points confirming monthly check is okay! I was going by some old threads like this one which scared me into thinking I needed to keep the weekly default. I've switched mine to monthly now.\n    submitted by    /u/denpa_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z68j76/running_weekly_consistency_checks_on_10tb_drives/",
          "publishedOn": "2022-11-27T18:26:49.000Z",
          "wordCount": 18327,
          "title": "Running weekly consistency checks on 10TB+ drives exceeds the rated annual workload",
          "imageUrl": "https://external-preview.redd.it/BUZXwSx4FYKZmj-VU6fkiJFn3ZbX_w4URhT0fUwD-mg.jpg?auto=webp&s=cb351bd56b93ca009b377beba589db481b6848f8"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z65xk2/how_to_actually_view_read_print_all_texts_and/",
          "author": null,
          "description": "I need to search through all the messages over the past few months to the last year to see what was said and when. It's almost impossible to do and I need an easier way. I need to document things for a custody case, I don't really know a functional way to do it.\n    submitted by    /u/stackshockprism  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z65xk2/how_to_actually_view_read_print_all_texts_and/",
          "publishedOn": "2022-11-27T16:46:28.000Z",
          "wordCount": 17389,
          "title": "How to actually view, read, print, all texts and Facebook messages in a thread?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z65tem/looking_for_a_document_scanner_for_paperlessng/",
          "author": null,
          "description": "I'd like to set up a self hosted paperless instance and digitize all my physical documents. I'd like to get a scanner than can scan a small stack of papers at a time, on both sides, and deposit them vita FTP/NFS/SMB/SMTP to a directory to be consumed by paperless. I've heard there is also some detection feature for accidently scanning two pages stuck together, I probably want that as well. I have no need to run this printer independently of a PC but I don't mind if it does. Has anyone been through this and have a scanner that they like? I'm happy to spend whatever budget to buy it for life and hit that price to performance sweet spot. Better than replacing is down the line when it has problems..\n    submitted by    /u/jswervedizzle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z65tem/looking_for_a_document_scanner_for_paperlessng/",
          "publishedOn": "2022-11-27T16:42:06.000Z",
          "wordCount": 17532,
          "title": "Looking for a document scanner for Paperless-ng",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z64gd0/unsuccessful_cdbackup_with_10mb_loss_i_wonder_why/",
          "author": null,
          "description": "submitted by    /u/alkoka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z64gd0/unsuccessful_cdbackup_with_10mb_loss_i_wonder_why/",
          "publishedOn": "2022-11-27T15:48:15.000Z",
          "wordCount": 17321,
          "title": "Unsuccessful CD-backup with 10mb loss. I wonder why…",
          "imageUrl": "https://preview.redd.it/s4zogvi83k2a1.jpg?auto=webp&s=edbc4691e6896c87fcd34484fe6896ee4e45650d"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z64fxo/do_i_have_to_run_any_tests_on_my_hard_drives/",
          "author": null,
          "description": "I’m going to be using UnRAID. I bought a couple 18tb exos x18 manufacturer recertified drives (1 for data and 1 for parity). Should I test them? If so, how, which tests, and how long will it take? I’m gonna be eager to use them when I get em haha. Thank you!\n    submitted by    /u/v-a-g  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z64fxo/do_i_have_to_run_any_tests_on_my_hard_drives/",
          "publishedOn": "2022-11-27T15:47:46.000Z",
          "wordCount": 17554,
          "title": "Do I have to run any tests on my hard drives before I use them? If so, which tests?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z64ff3/hdd_longevity_when_not_used/",
          "author": null,
          "description": "Hello Redditors,\n I have a novice question. \n Do 3.5\" drives that are used to write once and accessed once every blue moon because they are stored elsewhere have more durability than one inside a system that has daily usage or it does not matter?\n    submitted by    /u/LightDarkCloud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z64ff3/hdd_longevity_when_not_used/",
          "publishedOn": "2022-11-27T15:47:13.000Z",
          "wordCount": 18637,
          "title": "HDD longevity when not used",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z60zax/shucked_drive_enclosures/",
          "author": null,
          "description": "I hope everyone took advantage of Black Friday to fill your storage arrays. For those that bought external drives to shuck, I have a request. I’m trying to help a couple friends get started in data hoarding and self hosting. Since I have a good stock of old spinners and the mini-PC’s that I am using don’t have internal SATA slots, I was hoping to buy some external enclosures for cheap to keep their costs down. I’d recommend that you keep a couple enclosures for Warranty returns but if you have extras let me know. Thanks for your time. If this post violates any rules, I am extremely sorry and will delete it immediately.\n Edit: I was asked to include my location since I am asking if people are willing to ship items. I am located in Florida USA. Thanks for checking out the post.\n    submitted by    /u/NotablyNotABot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z60zax/shucked_drive_enclosures/",
          "publishedOn": "2022-11-27T13:15:43.000Z",
          "wordCount": 17073,
          "title": "Shucked drive enclosures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5wnft/successful_experience_with_seagate_shucked_drive/",
          "author": null,
          "description": "Just thought I would share my experience if it helps others in Australia with a similar experience.\n I shucked a Seagate 5TB Hard Drive I purchased from Amazon Australia on July 2022. It was in my Unraid server and now refuses to power up at all, completely dead. \n I tried to use the return process on the Amazon site, but it doesn't work since its outside of the 30 day return window. Since the drive itself has a 2 year warranty, I contacted chat. They gave me a standard auto reply of \"You need to go back to the manufacturer for the warranty\" which is not how it works in Australia (in Australian consumer law, the retailer cannot refer you to the manufacturer or importer for warranty repairs). I replied with this information, and the chat officer offered to have someone higher up call me on my phone.\n I received the phone call, and the phone support was perfectly fine. I told them I needed to return a drive for warranty, but it was outside of the 30 days, but still has a 2 year warranty, and that I am in Australia, and purchased from Amazon Australia and needed to use them for the warranty. He accepted it straight away, and sent me a brand new 5TB Seagate Drive (he asked if I wanted a refund or replacement, but since I use it I went with replacement).\n All done and dusted, completely swapped under warranty! Not sure how it works in other countries, but in Australia the manufacturer has the burden of proof to show that shucking the drive caused the failure before they can reject a warranty, and retailer are required to work with the consumer to facilitate the warranty process (they cannot refer to manufacturer).\n If you are in Australia and need to refer to the specific detail around manufacturers warranties, just send them this: https://www.accc.gov.au/consumers/problem-with-a-product-or-service-you-bought/repair-replace-refund-cancel\n    submitted by    /u/holastickboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5wnft/successful_experience_with_seagate_shucked_drive/",
          "publishedOn": "2022-11-27T09:17:44.000Z",
          "wordCount": 18707,
          "title": "Successful experience with Seagate shucked drive warranty and Amazon in Australia",
          "imageUrl": "https://external-preview.redd.it/kYgYPJxQHuNfHIehCMFgEP5oTl1c2s2s1ISzqlEBfZw.jpg?auto=webp&s=69946f55186e74bc67d2d710c11f046da13a6ba9"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5o9od/saving_microsoft_store_purchases_as_mp4_or_other/",
          "author": null,
          "description": "So I want to add Manswers to my plex server. I purchased it via the microsoft store, as it's the only way to get season 1. How can I save it as an MP4, rather than be forced to watch it through movies & tv\n    submitted by    /u/TLunchFTW  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5o9od/saving_microsoft_store_purchases_as_mp4_or_other/",
          "publishedOn": "2022-11-27T01:48:03.000Z",
          "wordCount": 16205,
          "title": "Saving Microsoft Store purchases as Mp4 or other non drm files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5o2fn/looking_for_a_scanner_to_scan_thousands_of_family/",
          "author": null,
          "description": "It’s toward the top of my price range, but I like that I can load 60 photos at once and let it do its thing rather than have a flatbed scanner. Does anyone have any experience with this particular scanner or something similar?\n    submitted by    /u/Rra2323  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5o2fn/looking_for_a_scanner_to_scan_thousands_of_family/",
          "publishedOn": "2022-11-27T01:38:25.000Z",
          "wordCount": 16229,
          "title": "Looking for a scanner to scan thousands of family photos. Is the canon imageformula R40 good for this sort of thing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5nvyc/i_checked_hdd_prices_in_china_and_compared_to/",
          "author": null,
          "description": "So we have OEM-ish hc550 16tb priced at 1498¥ (209$), and seems consumer-facing ones at 1619¥ (226$). All are brand new and has warranty in the shop or local agents so it doesn't really matter. Hc570 is 3198¥ or 446$. All are non-discount prices.\n https://imgur.com/a/U0Rz26V\n    submitted by    /u/starryeasternnight  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5nvyc/i_checked_hdd_prices_in_china_and_compared_to/",
          "publishedOn": "2022-11-27T01:29:55.000Z",
          "wordCount": 16105,
          "title": "I checked HDD prices in China and compared to prices in threads in this sub, noticed you guys need to pay a 20% to 100% markup compared",
          "imageUrl": "https://external-preview.redd.it/_TI4yAoMYrUHCzdyZnWhcUDqaN_X32BAmERsEyIGN9E.jpg?auto=webp&s=14833e0af0ba3d58204045daab727fea40e0aa56"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5nd8a/in_case_anyone_was_wondering_about_amazons_hard/",
          "author": null,
          "description": "submitted by    /u/1Autotech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5nd8a/in_case_anyone_was_wondering_about_amazons_hard/",
          "publishedOn": "2022-11-27T01:05:00.000Z",
          "wordCount": 16176,
          "title": "In case anyone was wondering about Amazon's hard drive packaging. Sold, shipped, and delivered by Amazon.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5nakg/cheap_used_desktop_for_a_nasplex_setup/",
          "author": null,
          "description": "I bought a QNAP TS-453D for $400, but reading more, it sounds like I can do a DIY build for comparable cost that will be much more powerful. Looking in eBay, I see a lot of used desktops (i.e. HPs, Dells, that have i3s), but space seems to be the main issue. Are there some popular consumer desktops I should look for that can easily be upgraded for 4 SATA drives?\n    submitted by    /u/BananaBagholder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5nakg/cheap_used_desktop_for_a_nasplex_setup/",
          "publishedOn": "2022-11-27T01:01:19.000Z",
          "wordCount": 16229,
          "title": "Cheap used Desktop for a NAS/Plex setup?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5mskm/tool_that_tallies_video_files/",
          "author": null,
          "description": "Anyone know of a tool that looks at my folder tree and tallies all the hrs of video? I know I have about 15.5TB and growing of TV shows and movies. But I am curious as to how many hrs of video that is. I tried searching by file types (in windows search) and totaling it that way, but Explorer takes way too long to compile it all.\n    submitted by    /u/CoreRipper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5mskm/tool_that_tallies_video_files/",
          "publishedOn": "2022-11-27T00:37:46.000Z",
          "wordCount": 16098,
          "title": "Tool that tallies video files",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5lz0a/windows_explorer_shows_space_free_on_a_storage/",
          "author": null,
          "description": "So, Windows Explorer shows me I still have 1.95TB free out of a 3.62TB storage pool, but it freaks out when I try to copy anything to it saying no room. As you can see, this is what Windows Explorer shows for remaning and total space:\n https://preview.redd.it/y7h93qvxvd2a1.png?width=246&format=png&auto=webp&s=5009163b505e220d19239d579144ca106beeeb4b\n So I thought I'd check my storage space, which reports this:\n https://preview.redd.it/vjzb3rp9wd2a1.jpg?width=580&format=pjpg&auto=webp&s=1e1eab97f292498d3c3fef127e96e9c55e63349c\n What's going on here? CrystalDisk Info says the drive is in good health, so why have I suddenly lost space and what's the warning of reduced resiliancy all about?\n I'm pretty new to this stuff, so I'm quite confused here - any help is appreciated.In the meantime, I'm moving what I can over to another drive that has free space. \n EDIT: Wait no, that last disk doesn't show up in CrystalDisk Info, but the others are.\n I'd try unplugging and replugging it in, but not sure it seems worth the risk here. \n    submitted by    /u/VictoriousSponge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5lz0a/windows_explorer_shows_space_free_on_a_storage/",
          "publishedOn": "2022-11-27T00:00:26.000Z",
          "wordCount": 16447,
          "title": "Windows Explorer shows space free on a storage space, but can't copy files to it as \"no room\", Storage Space showing error, what's going on here?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5lwuv/i_have_both_these_microsd_cards_for_laptop/",
          "author": null,
          "description": "So, I have a SanDisk Extreme Plus 128GB MicroSD from Best Buy (model number: SDSQXBD-128G-CN6MA). Bought it for $30 after taxes. Still a bit of stock left. Limited Lifetime Warranty.\n Also have a SanDisk Ultra Plus 256GB MicroSD from Best Buy (model number: SDSQUBL-256G-CN6IA). Bought for $35 after taxes. Looks super popular since it's already all sold out and only available for backorder at the moment. Looks like it sold out sooner than the Extreme Plus 128GB MicroSD. Limited Lifetime Warranty too.\n My laptop has these specs:\n Asus VivoBook X512DA 15.6\" FHD Ryzen 5 3500U 12GB RAM 512GB SSD Radeon Vega 8 Graphics\n It has a few USB 2.0 ports, one USB 3.0 port, and a MicroSD slot (I'm not sure on the specifics about this MicroSD slot). I can also get my hands on a UGreen USB 3.0 reader as we…",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5lwuv/i_have_both_these_microsd_cards_for_laptop/",
          "publishedOn": "2022-11-26T23:58:00.000Z",
          "wordCount": 17611,
          "title": "I have both these microSD cards for laptop general transfers (small and big files) + storage, but reluctant to open packaging on any of them (would then be unreturnable) to experiment and see if laptop would be able to accommodate their full read and write speeds. Any idea which one better to keep?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5kmvt/western_digital_22_tb_ultrastar_dc_hc570_52285/",
          "author": null,
          "description": "Lowest confirmed price I've seen for this top of the line CMR datacenter HDD1 (Review). AllHDD has it listed at $489 but with the wrong warranty & poor English in the listing. When I called to confirm it was the right HDD yesterday they left me on hold for 15 min while they \"called the warehouse\" so I hung up.\n AAAWAVE accepts both PayPal & Amazon Pay, so those of you with PayPal Credit &/or an Amazon credit card can have 6 - 12 months with no interest to pay off the purchase. \n I own the 18 TB DC HC550 & have had a great experience with it, so I feel confident about the DC HC570. Yes, there are less expensive HDDs out there, but for those of us who have less space than funds & are fairly demanding of our HDDs this is a great way to get massive storage in a small footprint.\n 1 The only other 22+ TB non-SMR HDD on the market is the Western Digital Gold which I have not been able to find for less than its 599.99 USD MSRP anywhere. It appears WD uses the same tech in both, with the exception that the Ultrastar has an SE (Secure Erase) functionality.\n    submitted by    /u/jdrch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5kmvt/western_digital_22_tb_ultrastar_dc_hc570_52285/",
          "publishedOn": "2022-11-26T23:00:52.000Z",
          "wordCount": 16449,
          "title": "Western Digital 22 TB Ultrastar DC HC570 522.85 USD (599.99 USD MSRP) @ AAAWAVE (4.6/5⭐+ 395 reviews on Google Shopping)",
          "imageUrl": "https://external-preview.redd.it/W60BjS3I_ILpI9pT-RJBPrm3KCp1zZpnnrFrskcyShI.jpg?auto=webp&s=8123fe4182489192b2a01e627a6f4fb2abc2f4f4"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5kkq9/finding_deleted_youtube_video_or_at_least_the/",
          "author": null,
          "description": "I have the link https://www.youtube.com/watch?v=TTHWZZ7JAGA . it was a rap instrumental. I just don't remember what it was called or who made it, so I don't know how to find it again. Any ideas? archive.org isn't helping\n    submitted by    /u/stickspike  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5kkq9/finding_deleted_youtube_video_or_at_least_the/",
          "publishedOn": "2022-11-26T22:58:36.000Z",
          "wordCount": 17386,
          "title": "Finding deleted youtube video (or at least the title of it)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5k86s/copying_a_dvd_iso_onto_a_25gb_bluray_disc/",
          "author": null,
          "description": "I have multiple ISO files from old DVD releases that I'm looking to copy and play on my DVD/Blu-Ray player.\n Is there a program I can use to copy that ISO onto my Blu-Ray discs and have it play like a regular DVD on my player?\n Basically is there a way to use my 25GB BluRay discs as an 8.5GB DVD disc for an intents and purposes?\n    submitted by    /u/Apprehensive_Tea4048  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5k86s/copying_a_dvd_iso_onto_a_25gb_bluray_disc/",
          "publishedOn": "2022-11-26T22:43:17.000Z",
          "wordCount": 16270,
          "title": "Copying a DVD iso onto a 25GB Blu-Ray disc",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5k4a1/usb_hdd_enclosure_for_nas/",
          "author": null,
          "description": "Hi, \n I have a \"nuc\" computer running all my containers and such things.\n I need some sort of USB 3.0 USB A / USB 3.1 USB C hard drive enclosure to house 3-4 disks.\n I found this: https://www.amazon.com/Mediasonic-SATA-Hard-Drive-Enclosure/dp/B078YQHWYW\n But they dont claim to have linux support and the reviews for linux are mixed. \n Does anyone have something similar like this to recommend for Linux?\n    submitted by    /u/myhrmans  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5k4a1/usb_hdd_enclosure_for_nas/",
          "publishedOn": "2022-11-26T22:38:34.000Z",
          "wordCount": 16334,
          "title": "USB HDD enclosure for NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5jv6p/usb_enclosure_or_jbod_recommendations_broke_uni/",
          "author": null,
          "description": "Hey everyone, \n I'm trying to cobble together a half functional system using hardware I've obtained for free from businesses and recycling centers, and I'm looking for some advice on how to hook up an odd assortment of hdds to my bizarre server setup and create a half decent NAS.\n So far I have an HP z2 mini g3 (i7 6700, 32GB ram, 256GB SSD) I was given by a friends workplace who didn't need it, and a massive bunch of drives I got from a recycling center (don't worry I tested and scrubbed them all).\n At the moment I'm messing with Ubuntu server on the z2 to learn, but planning to switch over to Truenas Scale and create a nice little ZFS Pool when I start storing data. This is really my only server head option atm as don't have the Budget for a new system\n My main issue is: how tf do I hook up all my drives? I have: 4x 4TB 3x 3TB 2x 2TB ~14x (lol) 1TB\n All 3.5in SATA HDDs\n The z2 has a bunch of 10gbit usb ports but not much else. So far I've looked at using an external USB jbod enclosure such as the sabrent 10 bay one, but am totally open to ideas for how to connect server grade hardware to this thing.\n How would you do it? \n Happy to experiment and put up with a reasonable amount of jank, or to try more complex solutions too!\n Cheers!\n    submitted by    /u/jackygrush  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5jv6p/usb_enclosure_or_jbod_recommendations_broke_uni/",
          "publishedOn": "2022-11-26T22:27:23.000Z",
          "wordCount": 17286,
          "title": "USB Enclosure or JBOD Recommendations - broke uni student cobbling together a NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5jstf/when_the_321_rule_describes_storing_on_different/",
          "author": null,
          "description": "I have 90TB of data that I am in process of backing up to external hard drives. I was going to make duplicate copies of the original data onto external hard drives, but I saw the suggestion of using different media. I do not know how to do anything other than external hard drives and would like some suggestions. Thanks!\n    submitted by    /u/bigcheeks9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5jstf/when_the_321_rule_describes_storing_on_different/",
          "publishedOn": "2022-11-26T22:24:33.000Z",
          "wordCount": 18517,
          "title": "When the 3-2-1 rule describes storing on different media, what are some examples?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5isil/external_hd_help_lacie_and_wd/",
          "author": null,
          "description": "Hello, \n I am looking into purchasing a HD to simply store data and put it away, like photos and videos. But I am unsure what would be the best drive for this situation, as I don’t have too much background with HD, and there is a bunch of HDs to choose from. I came across these two seeing their price and reviews. \n One is the 2TB WD easystore at BB and the other is this Lacie HD at Apple, I was also looking into the Lacie Rugged. I can get this one for 60 because of a discount.\n Any one can recommend any of these, or anything else? I am open to suggestions.\n Thanks!\n    submitted by    /u/A-_-ok  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5isil/external_hd_help_lacie_and_wd/",
          "publishedOn": "2022-11-26T21:41:25.000Z",
          "wordCount": 17325,
          "title": "External HD Help - Lacie and WD",
          "imageUrl": "https://external-preview.redd.it/T3sCj3LLgu1yYPViX8gCtSkG2CCkEGMqIzgZfuUxYoM.jpg?auto=webp&s=eac697b7117aa8fdbda342f8bc19da350a3c54ad"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5iibe/sanityunderstanding_check/",
          "author": null,
          "description": "Hello fellow Denizens of r/DataHoarder\n I just bought 2x14tb WD drives, that I'm adding to my NAS, which is running OMV. It currently only has an 8tb drive in it, on EXT4, which is almost out of space.\n I've been looking into snapraid-btrfs and snapraid-btrfs-runner.\n This and Mergerfs seems to be the perfect combination for my use case of mainly media storage(and maybe a steam cache later) on mixed drive sizes.\n But this is my first time even having enough data/drives to even have to worry about parity/bitrot, so i want to make sure I do it right the first time.\n I have a few things I want to make sure I'm understanding properly.\n 1) So in Snapraid, a 'Sync' is basically creating/updating the parity data on the parity drive. Does updating a parity file go faster if little to nothing has changed on the data drives?\n 2) Snapraid 'Scrubs' periodically check the integrity of a file based off of the Parity data, and timestamp. Still don't exactly get how this one works\n 3) Snapraid Sync will fail if anything is writing to the drives. Snapraid-btrfs gets around this by having Snapraid take a snapshot of btrfs's Read Only snapshots. No idea if that's correct.\n 4) Using Mergerfs and btrfs on my 8tb + 14tb drives, I can fill each drive rather evenly, without striping files. I can use my second 14tb to store the parity file created by Snapraid-btrfs. This should be pretty protected against bitrot, and the rare drive failure, right?(other than files lost between a sync and a failure)\n Sorry this is so long winded. I appreciate any insight :)\n    submitted by    /u/SmolMaeveWolff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5iibe/sanityunderstanding_check/",
          "publishedOn": "2022-11-26T21:29:48.000Z",
          "wordCount": 16706,
          "title": "Sanity/Understanding check",
          "imageUrl": "https://external-preview.redd.it/we4cSDLkpkyreRsxLiZLTPqOyZgN8o60J7U-3yNKOnw.jpg?auto=webp&s=6882c60b5cbaf65b3a08f784317dcdb97eb33010"
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5ierf/any_downside_to_storing_notsofrequently_used_data/",
          "author": null,
          "description": "I am storing some imaging data and they are collectively pretty big. They are lots of tiny files that add up to hundreds of gbs each set. I tried compressing a small 49GB set with 7zip and it compressed to 12GB. These are the RAW files that aren't used too often (they are mostly processed and the processed version is what we used. however, since they are data, we want to keep the raw files too). Is there any downside to compressing the raws, and deleting the raws after to save space? I saw couple of posts but most dealt with low compression ratios and not worth it. But i think saving 60-70% in my case might be. I am just worried about unforseen comsequences i might not be aware of. Like accessing files, likelihood or corruption or whatnot. \n ​\n Thank you!\n    submitted by    /u/behappyftw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5ierf/any_downside_to_storing_notsofrequently_used_data/",
          "publishedOn": "2022-11-26T21:25:30.000Z",
          "wordCount": 16978,
          "title": "Any Downside to storing not-so-frequently used data files in compressed form?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z5i9m9/mirroring_ssd_to_a_part_of_hdd_through_some/",
          "author": null,
          "description": "I am sorry, I am new in all of this and I am not from english speaking country, so I apologize if I say something incorrect.\n I would like to ask you for a advice, because I am bit lost in this scenario:\n In my computer, I have this three drivers, encrypted by BitLocker: \n  \nA: 500GB SSD - Samsung 860 EVO\n B: 1TB HDD - WD 1003FZEX\n C: 10TB HDD - WD 102KRYZ\n  \nOS: Windows 11 Pro\n Motherboard: MSI PRO Z690-A DDR4\n Would it be possible, to mirror the drive A to the drive C through some kind of a software, where if needed, I would create a basic partition on the drive C so it would be the same size with the drive A. The same scenario I would like to use for the drive B to C, same as A to C. But the data on drive A are the most critical for me and I would like them to survive the trial of time with naively ideally no corruption and so on.\n I understand backups are vital in this, but one of the problems at this time is money, so unfortunately right now, something like NAS is out of question for me. (Note: The 102KRYZ. It was a gift from colleague of mine.) Second problem is, if bit rot happens, even with backups, I will have no idea about it and the backups would get overwritten through time, so ideally, the software for the mirroring should check for checksum, if I understand it correctly.\n Space in the PC is basically taken, so adding later another 500GB SSD would be a bit difficult. Thats why I would like to ask about this scenario and how I could utilize the setup I have to the best of capabilities in protecting my data. \n If this scenario is impossible, then maybe, is there a software for just plainly generating checksum and warning the user, if the files gets corrupted, so you could overwrite it from the backup from other drivers? Just a thought.\n I will be very thankful for any idea, answer or anything to my problem. Thank you if you read my post and If I may, I wish you a very nice day.\n    submitted by    /u/_GreyHeart_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z5i9m9/mirroring_ssd_to_a_part_of_hdd_through_some/",
          "publishedOn": "2022-11-26T21:19:31.000Z",
          "wordCount": 19226,
          "title": "Mirroring SSD to a part of HDD through some software for prevention of data rot? Something like RAID1? Looking mainly for redundancy.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/DataHoarder/comments/z58q18/outgrowing_my_setup_and_trying_to_figure_out/",
          "author": null,
          "description": "Hey guys. Currently have a ds920 with 4 16tb exos drives in raid 10. I’m getting close to 20tb storage and am going to need more space. I also sometimes wish transcoding worked a bit faster with my nas on some files so I won’t have buffering. Not a common problem. My question is should I go with a bigger nas, just get an expansion bay, or is it time to go custom? I’ve built many pcs but I’ve never messed with Linux or other nas software. None of the data is critical, but I would like to keep some form of raid in case a drive fails. Anyone have any opinions or tips for me?\n    submitted by    /u/loader963  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/DataHoarder/comments/z58q18/outgrowing_my_setup_and_trying_to_figure_out/",
          "publishedOn": "2022-11-26T14:24:10.000Z",
          "wordCount": 17752,
          "title": "Outgrowing my setup and trying to figure out where to go!",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Hacker News",
      "feedUrl": "https://news.ycombinator.com/rss",
      "siteUrl": "https://news.ycombinator.com/",
      "articles": [
        {
          "id": "http://amasci.com/amateur/holo1.html",
          "author": null,
          "description": "Comments",
          "link": "http://amasci.com/amateur/holo1.html",
          "publishedOn": "2022-12-25T23:58:11.000Z",
          "wordCount": 3047,
          "title": "Holography without Lasers: Hand-drawn Holograms (1999)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/LemonHaze420/DCPopulous",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/LemonHaze420/DCPopulous",
          "publishedOn": "2022-12-25T23:08:48.000Z",
          "wordCount": 574,
          "title": "Source Code for Populous for Windows CE / Dreamcast Released",
          "imageUrl": "https://opengraph.githubassets.com/be2214ccd9be15f1f8816b98cf4aecedd4cbf60310d39073bacfc61d3c7b6bf1/LemonHaze420/DCPopulous"
        },
        {
          "id": "https://spectrum.ieee.org/green-hydrogen",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/green-hydrogen",
          "publishedOn": "2022-12-25T22:56:19.000Z",
          "wordCount": 13016,
          "title": "Green hydrogen is the centerpiece of Australia’s clean-economy growth plan",
          "imageUrl": "https://spectrum.ieee.org/media-library/an-aerial-photo-shows-a-large-solar-photovoltaic-generating-plant.jpg?id=32333508&width=1200&height=600&coordinates=0%2C180%2C0%2C180"
        },
        {
          "id": "https://twitter.com/thefireorg/status/1606010943309336576",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/thefireorg/status/1606010943309336576",
          "publishedOn": "2022-12-25T22:28:18.000Z",
          "wordCount": 470,
          "title": "MIT Faculty Votes for Statement on Freedom of Expression and Academic Freedom",
          "imageUrl": null
        },
        {
          "id": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001918",
          "author": null,
          "description": "Comments",
          "link": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001918",
          "publishedOn": "2022-12-25T21:41:42.000Z",
          "wordCount": 3527,
          "title": "The antimicrobial resistance crisis needs action now",
          "imageUrl": null
        },
        {
          "id": "https://iai.tv/articles/all-knowing-machines-are-a-fantasy-auid-2334",
          "author": null,
          "description": "Comments",
          "link": "https://iai.tv/articles/all-knowing-machines-are-a-fantasy-auid-2334",
          "publishedOn": "2022-12-25T21:31:42.000Z",
          "wordCount": 1546,
          "title": "AI chatbots are not a replacement for search engines",
          "imageUrl": "https://iai.tv/assets/Uploads/_resampled/FillWyI4MDAiLCI1MDAiXQ/All-knowing-machines-are-a-fantasy.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34131436",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34131436",
          "publishedOn": "2022-12-25T21:21:54.000Z",
          "wordCount": 2244,
          "title": "Ask HN: Has anyone successfully recovered photos from a broken Android phone?",
          "imageUrl": null
        },
        {
          "id": "https://www.lockedinspace.com/posts/001.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.lockedinspace.com/posts/001.html",
          "publishedOn": "2022-12-25T21:13:51.000Z",
          "wordCount": 684,
          "title": "General guidance when working as a cloud engineer",
          "imageUrl": null
        },
        {
          "id": "https://onesignal.com/careers/4004532006",
          "author": null,
          "description": "Comments",
          "link": "https://onesignal.com/careers/4004532006",
          "publishedOn": "2022-12-25T21:02:03.000Z",
          "wordCount": 385,
          "title": "OneSignal (YC S11) Is Hiring a Head of Developer Relations",
          "imageUrl": "https://media.onesignal.com/cms/_1200x630_crop_center-center_82_none/onesignal.jpg?mtime=1666043174"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34130767",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34130767",
          "publishedOn": "2022-12-25T20:12:19.000Z",
          "wordCount": 3684,
          "title": "Ask HN: What is your favorite front end state management solution?",
          "imageUrl": null
        },
        {
          "id": "https://kk.org/thetechnium/1000-true-fans/",
          "author": null,
          "description": "Comments",
          "link": "https://kk.org/thetechnium/1000-true-fans/",
          "publishedOn": "2022-12-25T20:06:48.000Z",
          "wordCount": 4722,
          "title": "1k True Fans (2008)",
          "imageUrl": "https://kk.org/wp-content/themes/kkdotorg/inc/images/og_default_1200.png"
        },
        {
          "id": "https://shyim.me/blog/devenv-compose-developer-environment-for-php-with-nix/",
          "author": null,
          "description": "Comments",
          "link": "https://shyim.me/blog/devenv-compose-developer-environment-for-php-with-nix/",
          "publishedOn": "2022-12-25T19:53:19.000Z",
          "wordCount": 3756,
          "title": "Devenv: Compose a Developer Environment Easily for PHP with Nix",
          "imageUrl": "https://avatars.githubusercontent.com/u/6224096?v=4?s=400"
        },
        {
          "id": "https://blog.nuclearsecrecy.com/2022/12/21/oppenheimer-vacated-but-not-vindicated/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.nuclearsecrecy.com/2022/12/21/oppenheimer-vacated-but-not-vindicated/",
          "publishedOn": "2022-12-25T18:46:23.000Z",
          "wordCount": 3861,
          "title": "Oppenheimer: Vacated but Not Vindicated",
          "imageUrl": "https://blog.nuclearsecrecy.com/wp-content/uploads/2022/12/1954-Oppenheimer-TIME-large-face.jpg"
        },
        {
          "id": "https://lwn.net/Articles/917280/",
          "author": null,
          "description": "Comments",
          "link": "https://lwn.net/Articles/917280/",
          "publishedOn": "2022-12-25T17:18:41.000Z",
          "wordCount": 3172,
          "title": "The return of lazy imports for Python",
          "imageUrl": null
        },
        {
          "id": "https://github.com/below/HelloSilicon",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/below/HelloSilicon",
          "publishedOn": "2022-12-25T17:01:10.000Z",
          "wordCount": 4366,
          "title": "HelloSilicon – An introduction to assembly on Apple Silicon Macs",
          "imageUrl": "https://repository-images.githubusercontent.com/276852180/16c87c7a-acc1-4426-8b29-365e4c8f6d6d"
        },
        {
          "id": "https://8bitworkshop.com/docs/posts/2022/happy-holidays-2022.html",
          "author": null,
          "description": "Comments",
          "link": "https://8bitworkshop.com/docs/posts/2022/happy-holidays-2022.html",
          "publishedOn": "2022-12-25T15:42:05.000Z",
          "wordCount": 986,
          "title": "Atari 800 Winter Solstice Celebration Demo 2022",
          "imageUrl": "https://8bitworkshop.com/docs/_static/icon.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=TYJl1EzBs_4",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=TYJl1EzBs_4",
          "publishedOn": "2022-12-25T15:28:36.000Z",
          "wordCount": null,
          "title": "Commodore Christmas Demo (1982) [video]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/apitable/apitable",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/apitable/apitable",
          "publishedOn": "2022-12-25T15:06:22.000Z",
          "wordCount": 1606,
          "title": "APITable: open-source Airtable alternative",
          "imageUrl": "https://opengraph.githubassets.com/1479b72d5134b4f26710c6e2aa5006a8dad619b989c8e82357f378b523045535/apitable/apitable"
        },
        {
          "id": "https://theconversation.com/cats-in-the-middle-ages-what-medieval-manuscripts-teach-us-about-our-ancestors-pets-195389",
          "author": null,
          "description": "Comments",
          "link": "https://theconversation.com/cats-in-the-middle-ages-what-medieval-manuscripts-teach-us-about-our-ancestors-pets-195389",
          "publishedOn": "2022-12-25T14:34:39.000Z",
          "wordCount": 4324,
          "title": "What medieval manuscripts teach us about our ancestors’ pets",
          "imageUrl": "https://images.theconversation.com/files/497695/original/file-20221128-12-umimlg.png?ixlib=rb-1.1.0&rect=4%2C12%2C945%2C471&q=45&auto=format&w=1356&h=668&fit=crop"
        },
        {
          "id": "https://worldsensorium.com/monets-garden-in-giverny/",
          "author": null,
          "description": "Comments",
          "link": "https://worldsensorium.com/monets-garden-in-giverny/",
          "publishedOn": "2022-12-25T13:56:19.000Z",
          "wordCount": 2942,
          "title": "Monet’s Garden in Giverny",
          "imageUrl": "https://worldsensorium.com/wp-content/uploads/2022/11/Nalls-1222-01.jpg"
        },
        {
          "id": "https://danielbmarkham.com/the-overlords-finally-showed-up/",
          "author": null,
          "description": "Comments",
          "link": "https://danielbmarkham.com/the-overlords-finally-showed-up/",
          "publishedOn": "2022-12-25T11:56:18.000Z",
          "wordCount": 2161,
          "title": "The Overlords Finally Showed Up",
          "imageUrl": "https://danielbmarkham.com/content/images/2022/12/dark-ages.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=0itrM7t4l34",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=0itrM7t4l34",
          "publishedOn": "2022-12-25T11:17:17.000Z",
          "wordCount": null,
          "title": "Non-ECC memory corrupted my hard drive image [video]",
          "imageUrl": null
        },
        {
          "id": "https://www.emacswiki.org/emacs/MovingTheCtrlKey",
          "author": null,
          "description": "Comments",
          "link": "https://www.emacswiki.org/emacs/MovingTheCtrlKey",
          "publishedOn": "2022-12-25T10:50:27.000Z",
          "wordCount": 3078,
          "title": "Moving the Ctrl Key",
          "imageUrl": null
        },
        {
          "id": "https://mijailovic.net/2022/12/25/hkpropel/",
          "author": null,
          "description": "Comments",
          "link": "https://mijailovic.net/2022/12/25/hkpropel/",
          "publishedOn": "2022-12-25T10:32:00.000Z",
          "wordCount": 1264,
          "title": "Reverse engineering yet another eBook format",
          "imageUrl": null
        },
        {
          "id": "https://smp.uq.edu.au/pitch-drop-experiment",
          "author": null,
          "description": "Comments",
          "link": "https://smp.uq.edu.au/pitch-drop-experiment",
          "publishedOn": "2022-12-25T09:34:14.000Z",
          "wordCount": 906,
          "title": "Pitch Drop Experiment",
          "imageUrl": "https://smp.uq.edu.au/"
        },
        {
          "id": "https://www.wsj.com/articles/vint-cerf-helped-create-the-internet-on-the-back-of-an-envelope-11671210858",
          "author": null,
          "description": "Comments",
          "link": "https://www.wsj.com/articles/vint-cerf-helped-create-the-internet-on-the-back-of-an-envelope-11671210858",
          "publishedOn": "2022-12-25T05:12:37.000Z",
          "wordCount": 7508,
          "title": "Vint Cerf Helped Create the Internet on the Back of an Envelope",
          "imageUrl": "https://images.wsj.net/im-683799/social"
        },
        {
          "id": "https://www.sainsburywellcome.org/web/research-news/brain-circuit-converts-spatial-goals-escape-actions-discovered",
          "author": null,
          "description": "Comments",
          "link": "https://www.sainsburywellcome.org/web/research-news/brain-circuit-converts-spatial-goals-escape-actions-discovered",
          "publishedOn": "2022-12-25T05:11:55.000Z",
          "wordCount": 1702,
          "title": "Brain circuit that converts spatial goals to escape actions discovered in mice",
          "imageUrl": null
        },
        {
          "id": "https://mastodon.social/@acb/109567809376185861",
          "author": null,
          "description": "Comments",
          "link": "https://mastodon.social/@acb/109567809376185861",
          "publishedOn": "2022-12-25T04:19:03.000Z",
          "wordCount": 111,
          "title": "Interpreting a Sierpinski Triangle Fractal as musical notes sounds good",
          "imageUrl": "https://files.mastodon.social/media_attachments/files/109/567/808/614/600/092/small/e453ebe6673dbc20.png"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34122578",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34122578",
          "publishedOn": "2022-12-25T00:07:19.000Z",
          "wordCount": 1252,
          "title": "Ask HN: Who else is working/on call over Christmas?",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34122118",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34122118",
          "publishedOn": "2022-12-24T23:09:29.000Z",
          "wordCount": 880,
          "title": "Tell HN: Everyone should have a holiday dinner this year",
          "imageUrl": null
        },
        {
          "id": "https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/",
          "author": null,
          "description": "Comments",
          "link": "https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/",
          "publishedOn": "2022-12-24T23:05:12.000Z",
          "wordCount": 2141,
          "title": "The Psychedelic Inspiration for Hypercard (2018)",
          "imageUrl": "https://www.mondo2000.com/wp-content/uploads/2018/06/images-1.jpeg"
        },
        {
          "id": "https://github.com/Droogans/unmaintainable-code",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Droogans/unmaintainable-code",
          "publishedOn": "2022-12-24T22:11:24.000Z",
          "wordCount": 17213,
          "title": "How to write unmantainable code (2015)",
          "imageUrl": "https://opengraph.githubassets.com/d96a518f8def117eab3c75dacebe1207500596d336f20a6037aa61a562d1dd8b/Droogans/unmaintainable-code"
        },
        {
          "id": "https://auerstack.substack.com/p/what-chatgpt-cant-do",
          "author": null,
          "description": "Comments",
          "link": "https://auerstack.substack.com/p/what-chatgpt-cant-do",
          "publishedOn": "2022-12-24T21:46:58.000Z",
          "wordCount": 2825,
          "title": "What ChatGPT can't do",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd539c725-7783-4644-aa25-b785a9bca0e7_795x1014.jpeg"
        },
        {
          "id": "https://www.pagetable.com/?p=1721",
          "author": null,
          "description": "Comments",
          "link": "https://www.pagetable.com/?p=1721",
          "publishedOn": "2022-12-24T21:46:01.000Z",
          "wordCount": 1170,
          "title": "PostScript Cartridge for HP LaserJet",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34121082",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34121082",
          "publishedOn": "2022-12-24T21:06:38.000Z",
          "wordCount": 7738,
          "title": "Merry Christmas, HN",
          "imageUrl": null
        },
        {
          "id": "https://johnhcochrane.blogspot.com/2022/12/stanford-hates-fun.html",
          "author": null,
          "description": "Comments",
          "link": "https://johnhcochrane.blogspot.com/2022/12/stanford-hates-fun.html",
          "publishedOn": "2022-12-24T19:59:05.000Z",
          "wordCount": 6877,
          "title": "Stanford hates fun",
          "imageUrl": "https://lh3.googleusercontent.com/blogger_img_proxy/ANbyha2ZuBmkk5-h515qsZ_69mIBU6Ov5FfbEFTBZ4i2z086ITJ5g7uiiQinaizAeSLcEzQz204neL0GEX-zOc6utBWXO2eeRKmR1LuVYdiTZxZybYDgOk-Tt22gdAtH-4yBFh_TER-OyrWjnMfI=w1200-h630-p-k-no-nu"
        },
        {
          "id": "https://www.axios.com/2022/03/04/the-cold-hard-truth-about-electric-vehicles-in-winter",
          "author": null,
          "description": "Comments",
          "link": "https://www.axios.com/2022/03/04/the-cold-hard-truth-about-electric-vehicles-in-winter",
          "publishedOn": "2022-12-24T19:27:53.000Z",
          "wordCount": 2206,
          "title": "The cold hard truth about electric vehicles in winter",
          "imageUrl": "https://images.axios.com/dlirObIllA2rhztW6nGVX9v1HCw=/0x522:2825x2111/1366x768/2022/03/04/1646391658299.jpg"
        },
        {
          "id": "https://bmcgee.ie/posts/2022/12/setting-up-my-new-laptop-nix-style/",
          "author": null,
          "description": "Comments",
          "link": "https://bmcgee.ie/posts/2022/12/setting-up-my-new-laptop-nix-style/",
          "publishedOn": "2022-12-24T18:53:16.000Z",
          "wordCount": 1710,
          "title": "Setting up my new laptop: Nix style",
          "imageUrl": "https://bmcgee.ie"
        },
        {
          "id": "https://www.os2museum.com/wp/win16-retro-development/",
          "author": null,
          "description": "Comments",
          "link": "https://www.os2museum.com/wp/win16-retro-development/",
          "publishedOn": "2022-12-24T18:37:15.000Z",
          "wordCount": 3623,
          "title": "Win16 Retro Development",
          "imageUrl": null
        },
        {
          "id": "https://github.com/ethereum/pos-evolution/blob/master/pos-evolution.md",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/ethereum/pos-evolution/blob/master/pos-evolution.md",
          "publishedOn": "2022-12-24T17:39:34.000Z",
          "wordCount": 14975,
          "title": "Evolution of the Ethereum proof-of-stake consensus protocol",
          "imageUrl": "https://opengraph.githubassets.com/b026dc7800f313e83e8c87986c8bab860244e43fc9c40c9863fc023543223377/ethereum/pos-evolution"
        },
        {
          "id": "https://www.sacbee.com/news/politics-government/capitol-alert/article270354472.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.sacbee.com/news/politics-government/capitol-alert/article270354472.html",
          "publishedOn": "2022-12-24T16:54:31.000Z",
          "wordCount": 1217,
          "title": "California’s population shrinks for third straight year",
          "imageUrl": "https://www.sacbee.com/latest-news/lnfcmc/picture251009279/alternates/LANDSCAPE_1140/AP21116712044302%20(1).jpg"
        },
        {
          "id": "https://community.secondlife.com/blogs/entry/12081-second-life-on-github/",
          "author": null,
          "description": "Comments",
          "link": "https://community.secondlife.com/blogs/entry/12081-second-life-on-github/",
          "publishedOn": "2022-12-24T16:51:37.000Z",
          "wordCount": 1581,
          "title": "Second Life on GitHub",
          "imageUrl": "https://content.invisioncic.com/Mseclife/monthly_2022_11/image2.jpg.725a20371f8f0350e6007371ae8f89da.jpg"
        },
        {
          "id": "https://austinhenley.com/blog/challengingalgorithms.html",
          "author": null,
          "description": "Comments",
          "link": "https://austinhenley.com/blog/challengingalgorithms.html",
          "publishedOn": "2022-12-24T16:41:19.000Z",
          "wordCount": 883,
          "title": "Challenging algorithms and data structures every programmer should try",
          "imageUrl": "https://austinhenley.com/blog/images/algorithmsbook.jpg"
        },
        {
          "id": "https://www.theguardian.com/books/2022/dec/23/philip-pullman-i-had-to-grow-up-before-i-could-cope-with-middlemarch",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/books/2022/dec/23/philip-pullman-i-had-to-grow-up-before-i-could-cope-with-middlemarch",
          "publishedOn": "2022-12-24T13:13:42.000Z",
          "wordCount": 4866,
          "title": "‘I had to grow up before I could cope with Middlemarch’",
          "imageUrl": "https://i.guim.co.uk/img/media/47a090e17e763e91dca764b995525b10e176ec7f/0_111_683_410/master/683.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=6725bc54a08a4ce601f6b444f32f3eb9"
        },
        {
          "id": "https://www.teslarati.com/califonia-banning-tesla-fsd/",
          "author": null,
          "description": "Comments",
          "link": "https://www.teslarati.com/califonia-banning-tesla-fsd/",
          "publishedOn": "2022-12-24T13:09:54.000Z",
          "wordCount": 2519,
          "title": "California passes law banning Tesla from calling software FSD",
          "imageUrl": "https://www.teslarati.com/wp-content/uploads/2022/12/California-passes-law-banning-Tesla-from-calling-software-FSD.jpeg"
        },
        {
          "id": "https://nautil.us/the-great-forgetting-253223/",
          "author": null,
          "description": "Comments",
          "link": "https://nautil.us/the-great-forgetting-253223/",
          "publishedOn": "2022-12-24T11:55:51.000Z",
          "wordCount": 10137,
          "title": "The Great Forgetting",
          "imageUrl": "https://assets.nautil.us/sites/3/nautilus/Praetorius_HERO.png?auto=compress&fm=png&ixlib=php-3.3.1"
        },
        {
          "id": "https://www.economist.com/christmas-specials/2022/12/20/deadly-dirty-indispensable-the-nitrogen-industry-has-changed-the-world",
          "author": null,
          "description": "Comments",
          "link": "https://www.economist.com/christmas-specials/2022/12/20/deadly-dirty-indispensable-the-nitrogen-industry-has-changed-the-world",
          "publishedOn": "2022-12-24T11:31:49.000Z",
          "wordCount": 36182,
          "title": "Deadly, dirty, indispensable: the nitrogen industry has changed the world",
          "imageUrl": "https://www.economist.com/img/b/1280/720/90/media-assets/image/20221224_XMD114.jpg"
        },
        {
          "id": "https://charperbonaroo.github.io/bls/#0",
          "author": null,
          "description": "Comments",
          "link": "https://charperbonaroo.github.io/bls/#0",
          "publishedOn": "2022-12-24T10:59:06.000Z",
          "wordCount": 33,
          "title": "Bitmap Logic Simulator – Game",
          "imageUrl": null
        },
        {
          "id": "https://squidgeefish.com/projects/rotary-keyboard/",
          "author": null,
          "description": "Comments",
          "link": "https://squidgeefish.com/projects/rotary-keyboard/",
          "publishedOn": "2022-12-24T10:56:32.000Z",
          "wordCount": 1918,
          "title": "Rotary Keyboard",
          "imageUrl": "http://squidgeefish.com/assets/rotary-keyboard/banner.jpg"
        },
        {
          "id": "https://www.hcn.org/articles/wildlife-bringing-back-californias-wild-bees",
          "author": null,
          "description": "Comments",
          "link": "https://www.hcn.org/articles/wildlife-bringing-back-californias-wild-bees",
          "publishedOn": "2022-12-24T05:52:40.000Z",
          "wordCount": 4444,
          "title": "Bringing back California’s wild bees",
          "imageUrl": "https://www.hcn.org/articles/wildlife-bringing-back-californias-wild-bees/bigimage_large"
        },
        {
          "id": "https://www.taptab.dev/",
          "author": null,
          "description": "Comments",
          "link": "https://www.taptab.dev/",
          "publishedOn": "2022-12-24T01:05:20.000Z",
          "wordCount": 529,
          "title": "Show HN: TapTab – Tab switching web extension for Safari",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/cryptopathic/status/1606416137771782151",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/cryptopathic/status/1606416137771782151",
          "publishedOn": "2022-12-23T23:27:39.000Z",
          "wordCount": 470,
          "title": "The situation at LastPass may be worse than they are letting on",
          "imageUrl": null
        },
        {
          "id": "http://blogs.intellique.com/cgi-bin/tech/2022/01/27",
          "author": null,
          "description": "Comments",
          "link": "http://blogs.intellique.com/cgi-bin/tech/2022/01/27",
          "publishedOn": "2022-12-23T22:29:35.000Z",
          "wordCount": 2632,
          "title": "Managing tape drives and libraries with the Unix/Linux CLI",
          "imageUrl": null
        },
        {
          "id": "https://www.science.org/doi/10.1126/sciadv.ade1248",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/doi/10.1126/sciadv.ade1248",
          "publishedOn": "2022-12-23T22:12:06.000Z",
          "wordCount": null,
          "title": "Dating of a large tool assemblage at the Cooper’s Ferry site (Idaho, USA)",
          "imageUrl": null
        },
        {
          "id": "http://whatcolorisit.sumbioun.com/",
          "author": null,
          "description": "Comments",
          "link": "http://whatcolorisit.sumbioun.com/",
          "publishedOn": "2022-12-23T21:57:42.000Z",
          "wordCount": 350,
          "title": "What color is it?",
          "imageUrl": "http://whatcolorisit.sumbioun.com/what-color.jpg"
        },
        {
          "id": "https://pioneerworks.org/broadcast/picture-this-periodic-table",
          "author": null,
          "description": "Comments",
          "link": "https://pioneerworks.org/broadcast/picture-this-periodic-table",
          "publishedOn": "2022-12-23T21:50:07.000Z",
          "wordCount": 15266,
          "title": "Picture This: The Periodic Table",
          "imageUrl": "https://cdn.sanity.io/images/vgvol637/production/1799b148edd4666995b3dfea168dad5ea51ed620-2592x1944.svg?w=800"
        },
        {
          "id": "https://www.science.org/content/article/deadly-sharp-points-found-idaho-could-be-first-american-made-tools",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/content/article/deadly-sharp-points-found-idaho-could-be-first-american-made-tools",
          "publishedOn": "2022-12-23T21:46:37.000Z",
          "wordCount": 3027,
          "title": "Sharp points found in Idaho could be first American-made tools",
          "imageUrl": "https://www.science.org/do/10.1126/science.adg4404/abs/_20221223_on_stemmed_points.jpg"
        },
        {
          "id": "https://www.theguardian.com/business/2022/dec/23/chief-executive-of-ftx-sister-company-pleads-guilty-to-seven-offences",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/business/2022/dec/23/chief-executive-of-ftx-sister-company-pleads-guilty-to-seven-offences",
          "publishedOn": "2022-12-23T21:45:04.000Z",
          "wordCount": 4962,
          "title": "Caroline Ellison, CEO of Alameda Research, pleads guilty to seven offences",
          "imageUrl": "https://i.guim.co.uk/img/media/1be2f27880aeeea8a423433e8bd73f36deb6cd32/0_104_4902_2941/master/4902.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f69e20086dbf622b30d84ce12d7ff014"
        },
        {
          "id": "https://you.com/search?q=what+was+the+recent+breakthrough+in+fusion+research%3F&fromSearchBar=true&tbm=youchat",
          "author": null,
          "description": "Comments",
          "link": "https://you.com/search?q=what+was+the+recent+breakthrough+in+fusion+research%3F&fromSearchBar=true&tbm=youchat",
          "publishedOn": "2022-12-23T21:19:04.000Z",
          "wordCount": null,
          "title": "A new chat feature has been released by You Search",
          "imageUrl": null
        },
        {
          "id": "https://github.com/gabrielsroka/gabrielsroka.github.io/blob/master/getHNFavorites.js",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/gabrielsroka/gabrielsroka.github.io/blob/master/getHNFavorites.js",
          "publishedOn": "2022-12-23T21:07:23.000Z",
          "wordCount": 951,
          "title": "Show HN: Search HN Favorites or Export to CSV/HTML",
          "imageUrl": "https://opengraph.githubassets.com/caa0c293d298022e1a5c47700d6da3a76225808317683d0d0b1a0b0634a9f440/gabrielsroka/gabrielsroka.github.io"
        },
        {
          "id": "https://ossinsight.io/",
          "author": null,
          "description": "Comments",
          "link": "https://ossinsight.io/",
          "publishedOn": "2022-12-23T21:04:34.000Z",
          "wordCount": 1522,
          "title": "GitHub Statistics",
          "imageUrl": "https://ossinsight.io/img/screenshots/homepage.png"
        },
        {
          "id": "https://theprintshop.club/",
          "author": null,
          "description": "Comments",
          "link": "https://theprintshop.club/",
          "publishedOn": "2022-12-23T21:00:05.000Z",
          "wordCount": 440,
          "title": "The Print Shop Club – Create Apple II Print Shop printouts on-line",
          "imageUrl": null
        },
        {
          "id": "https://docs.ruby-lang.org/en/master/NEWS_md.html#label-NEWS+for+Ruby+3.2.0",
          "author": null,
          "description": "Comments",
          "link": "https://docs.ruby-lang.org/en/master/NEWS_md.html#label-NEWS+for+Ruby+3.2.0",
          "publishedOn": "2022-12-23T20:20:23.000Z",
          "wordCount": 2922,
          "title": "News for Ruby 3.2.0",
          "imageUrl": null
        },
        {
          "id": "https://www.lrb.co.uk/the-paper/v45/n01/anne-enright/eyes-that-bite",
          "author": null,
          "description": "Comments",
          "link": "https://www.lrb.co.uk/the-paper/v45/n01/anne-enright/eyes-that-bite",
          "publishedOn": "2022-12-23T20:06:29.000Z",
          "wordCount": 8921,
          "title": "Eyes That Bite",
          "imageUrl": "https://www.lrb.co.uk/storage/social_image/images/3/1/8/0/29050813-1-eng-GB/e780c4508f13-enright_website2.jpg"
        },
        {
          "id": "https://docs.google.com/presentation/d/1sowJrQQfgxnLCErb-CvUV8VGXdtca6SWYWWLRPZgaHI/edit?usp=sharing",
          "author": null,
          "description": "Comments",
          "link": "https://docs.google.com/presentation/d/1sowJrQQfgxnLCErb-CvUV8VGXdtca6SWYWWLRPZgaHI/edit?usp=sharing",
          "publishedOn": "2022-12-23T19:10:07.000Z",
          "wordCount": 6415,
          "title": "I found a secret US Government surveillance program (2019)",
          "imageUrl": "https://lh4.googleusercontent.com/oV3a2QuB7XsN4CSpzbv4bFWL4_BbpNJbExDh5af_20DFwJEzN0m4JKLqPmUN9PWVo99LAnNL9lhRDg=w1200-h630-p"
        },
        {
          "id": "https://www.haiku-os.org/get-haiku/r1beta4/release-notes/",
          "author": null,
          "description": "Comments",
          "link": "https://www.haiku-os.org/get-haiku/r1beta4/release-notes/",
          "publishedOn": "2022-12-23T18:54:10.000Z",
          "wordCount": 2151,
          "title": "Haiku R1/beta4",
          "imageUrl": "https://www.haiku-os.org/images/haiku_600x315.png"
        },
        {
          "id": "https://mesonbuild.com/Release-notes-for-1-0-0.html",
          "author": null,
          "description": "Comments",
          "link": "https://mesonbuild.com/Release-notes-for-1-0-0.html",
          "publishedOn": "2022-12-23T18:41:35.000Z",
          "wordCount": 463,
          "title": "Meson Build System 1.0",
          "imageUrl": null
        },
        {
          "id": "https://bt.ht/suckless/",
          "author": null,
          "description": "Comments",
          "link": "https://bt.ht/suckless/",
          "publishedOn": "2022-12-23T18:26:18.000Z",
          "wordCount": 1227,
          "title": "I want to suckless and you can too",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/zzznah/status/1606294595330940928",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/zzznah/status/1606294595330940928",
          "publishedOn": "2022-12-23T17:58:47.000Z",
          "wordCount": 470,
          "title": "Particle Lenia: Self Organising Particles",
          "imageUrl": null
        },
        {
          "id": "https://www.evanmiller.org/mathematical-hacker.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.evanmiller.org/mathematical-hacker.html",
          "publishedOn": "2022-12-23T17:33:11.000Z",
          "wordCount": 2182,
          "title": "The Mathematical Hacker (2012)",
          "imageUrl": null
        },
        {
          "id": "https://www.macrumors.com/2022/12/23/iphone-14-pro-setback-removed-graphics-processor/",
          "author": null,
          "description": "Comments",
          "link": "https://www.macrumors.com/2022/12/23/iphone-14-pro-setback-removed-graphics-processor/",
          "publishedOn": "2022-12-23T16:11:16.000Z",
          "wordCount": 2911,
          "title": "iPhone 14 Pro faced 'unprecedented' setback leading to removal of new GPU",
          "imageUrl": "https://images.macrumors.com/t/WVnXQ13cuwrE9ZUl4NdNBfTOXr0=/1600x/article-new/2022/10/A16-iPhone-14-Pro.jpeg"
        },
        {
          "id": "https://github.com/vasanthv/talk",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/vasanthv/talk",
          "publishedOn": "2022-12-23T16:04:09.000Z",
          "wordCount": 743,
          "title": "Free, P2P, disposable group video calling app for the web",
          "imageUrl": "https://opengraph.githubassets.com/78545e35550ca5ac66ead96589786f57df8dd1267b564cc2b1ae8095f92f74a5/vasanthv/talk"
        },
        {
          "id": "https://github.com/Immediate-Mode-UI/Nuklear",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Immediate-Mode-UI/Nuklear",
          "publishedOn": "2022-12-23T15:23:33.000Z",
          "wordCount": 1855,
          "title": "Nuklear – A single-header ANSI C immediate mode cross-platform GUI library",
          "imageUrl": "https://opengraph.githubassets.com/54e9c2c98bc187a1ec9c7e381238d92eee3b0e4808e3124dd92e6eff68829802/Immediate-Mode-UI/Nuklear"
        },
        {
          "id": "https://kno.wled.ge/",
          "author": null,
          "description": "Comments",
          "link": "https://kno.wled.ge/",
          "publishedOn": "2022-12-23T13:56:13.000Z",
          "wordCount": 660,
          "title": "WLED Project",
          "imageUrl": null
        },
        {
          "id": "https://craigmod.com/ridgeline/115/",
          "author": null,
          "description": "Comments",
          "link": "https://craigmod.com/ridgeline/115/",
          "publishedOn": "2022-12-23T13:29:56.000Z",
          "wordCount": 753,
          "title": "Walk as Spreadsheet (2021)",
          "imageUrl": "https://craigmod.com/ridgeline/images/115/115.jpg"
        },
        {
          "id": "https://semiengineering.com/risc-v-pushes-into-the-mainstream/",
          "author": null,
          "description": "Comments",
          "link": "https://semiengineering.com/risc-v-pushes-into-the-mainstream/",
          "publishedOn": "2022-12-23T13:27:33.000Z",
          "wordCount": null,
          "title": "RISC-V Pushes into the Mainstream",
          "imageUrl": null
        },
        {
          "id": "https://pcalc.com/mac/thirty.html",
          "author": null,
          "description": "Comments",
          "link": "https://pcalc.com/mac/thirty.html",
          "publishedOn": "2022-12-23T12:42:30.000Z",
          "wordCount": 3112,
          "title": "PCalc, an Origin Story",
          "imageUrl": null
        },
        {
          "id": "https://www.bbc.co.uk/accessibility/forproducts/guides/subtitles/",
          "author": null,
          "description": "Comments",
          "link": "https://www.bbc.co.uk/accessibility/forproducts/guides/subtitles/",
          "publishedOn": "2022-12-23T12:28:10.000Z",
          "wordCount": 31275,
          "title": "BBC Subtitle Guidelines",
          "imageUrl": "https://www.bbc.co.uk/accessibility/forproducts/guides/subtitles/img/EBU-TT-D_illustration1.png"
        },
        {
          "id": "https://www.ringgame.net/riddles.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.ringgame.net/riddles.html",
          "publishedOn": "2022-12-23T12:25:55.000Z",
          "wordCount": 12490,
          "title": "The Hobbit: Riddles in the Dark – The Lost Version (2001)",
          "imageUrl": null
        },
        {
          "id": "https://www.brandonsanderson.com/state-of-the-sanderson-2022/",
          "author": null,
          "description": "Comments",
          "link": "https://www.brandonsanderson.com/state-of-the-sanderson-2022/",
          "publishedOn": "2022-12-23T10:23:16.000Z",
          "wordCount": 11730,
          "title": "State of the Sanderson 2022",
          "imageUrl": "https://www.brandonsanderson.com/wp-content/uploads/2022/12/BS_State-of-Sanderson_BLOG-HEADER_V7-copy.png"
        },
        {
          "id": "https://philip.greenspun.com/materialism/money",
          "author": null,
          "description": "Comments",
          "link": "https://philip.greenspun.com/materialism/money",
          "publishedOn": "2022-12-23T07:16:09.000Z",
          "wordCount": 6249,
          "title": "Money, money, money (and investing) (2015)",
          "imageUrl": null
        },
        {
          "id": "https://tylerneylon.com/a/lsh1/",
          "author": null,
          "description": "Comments",
          "link": "https://tylerneylon.com/a/lsh1/",
          "publishedOn": "2022-12-23T06:30:42.000Z",
          "wordCount": 4689,
          "title": "Introduction to Locality-Sensitive Hashing (2018)",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34101086",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34101086",
          "publishedOn": "2022-12-23T01:00:14.000Z",
          "wordCount": 168,
          "title": "Generally Intelligent (YC S17) Is Hiring Systems Engineers",
          "imageUrl": null
        },
        {
          "id": "https://oscargws.substack.com/p/why-i-gave-up-drinking-in-my-twenties",
          "author": null,
          "description": "Comments",
          "link": "https://oscargws.substack.com/p/why-i-gave-up-drinking-in-my-twenties",
          "publishedOn": "2022-12-23T00:32:04.000Z",
          "wordCount": 3748,
          "title": "On why I gave up drinking in my early twenties",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53dbd9ab-af84-4435-9dcd-9a5b2c62256a_1280x720.png"
        },
        {
          "id": "https://lupyuen.github.io/articles/de3",
          "author": null,
          "description": "Comments",
          "link": "https://lupyuen.github.io/articles/de3",
          "publishedOn": "2022-12-22T23:55:35.000Z",
          "wordCount": 3530,
          "title": "NuttX RTOS for PinePhone: Display Engine",
          "imageUrl": "https://lupyuen.github.io/images/de3-title.jpg"
        },
        {
          "id": "https://interlisp.org/news/2022medleyannualreport/",
          "author": null,
          "description": "Comments",
          "link": "https://interlisp.org/news/2022medleyannualreport/",
          "publishedOn": "2022-12-22T23:53:40.000Z",
          "wordCount": 489,
          "title": "2022 Medley Interlisp Annual Report",
          "imageUrl": null
        },
        {
          "id": "https://handlr.sapico.me/?domain=https%3A%2F%2Fnews.ycombinator.com",
          "author": null,
          "description": "Comments",
          "link": "https://handlr.sapico.me/?domain=https%3A%2F%2Fnews.ycombinator.com",
          "publishedOn": "2022-12-22T23:10:44.000Z",
          "wordCount": 1117,
          "title": "Show HN: My bookmarks of HN and who I'm following",
          "imageUrl": null
        },
        {
          "id": "http://www.acad.bg/ebook/ml/Society%20of%20Mind.pdf",
          "author": null,
          "description": "Comments",
          "link": "http://www.acad.bg/ebook/ml/Society%20of%20Mind.pdf",
          "publishedOn": "2022-12-22T23:01:26.000Z",
          "wordCount": 634532,
          "title": "The Society of Mind (1986) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/elanmart/cbp-translate",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/elanmart/cbp-translate",
          "publishedOn": "2022-12-22T22:20:18.000Z",
          "wordCount": 2760,
          "title": "Serverless Video Transcription inspired by Cyberpunk 2077",
          "imageUrl": "https://opengraph.githubassets.com/8834529f4321ee12a5b0e7112e52bb0b4ebb7af0f9391fa8ace824db0119dd13/elanmart/cbp-translate"
        },
        {
          "id": "https://www.pcmag.com/news/40-years-of-pcmag-an-illustrated-guide",
          "author": null,
          "description": "Comments",
          "link": "https://www.pcmag.com/news/40-years-of-pcmag-an-illustrated-guide",
          "publishedOn": "2022-12-22T22:03:57.000Z",
          "wordCount": 5011,
          "title": "40 Years of PCMag: An Illustrated Guide",
          "imageUrl": "https://i.pcmag.com/imagery/articles/05ItT3UlIrFDJEPH8tt88ii-25.fit_lim.size_1200x630.v1654019873.jpg"
        },
        {
          "id": "https://www.wsj.com/articles/airlines-frequent-flier-status-mileage-run-11671562815",
          "author": null,
          "description": "Comments",
          "link": "https://www.wsj.com/articles/airlines-frequent-flier-status-mileage-run-11671562815",
          "publishedOn": "2022-12-22T22:02:48.000Z",
          "wordCount": 7182,
          "title": "What frequent fliers do for status",
          "imageUrl": "https://images.wsj.net/im-684890/social"
        },
        {
          "id": "https://www.zerodayinitiative.com/advisories/ZDI-22-1690/",
          "author": null,
          "description": "Comments",
          "link": "https://www.zerodayinitiative.com/advisories/ZDI-22-1690/",
          "publishedOn": "2022-12-22T21:15:39.000Z",
          "wordCount": 247,
          "title": "Linux Kernel Ksmbd Use-After-Free Remote Code Execution Vulnerability",
          "imageUrl": "https://zerodayinitiative.com/images/logo-footer.svg"
        },
        {
          "id": "https://www.franzoni.eu/password-requirements-myths-madness/",
          "author": null,
          "description": "Comments",
          "link": "https://www.franzoni.eu/password-requirements-myths-madness/",
          "publishedOn": "2022-12-22T20:42:24.000Z",
          "wordCount": 1624,
          "title": "Password Requirements: Myths and Madness",
          "imageUrl": "https://www.franzoni.eu/content/images/2017/03/cosmic-timetraveler-39766--1-.jpg"
        },
        {
          "id": "https://www.paolomainardi.com/posts/docker-performance-macos/",
          "author": null,
          "description": "Comments",
          "link": "https://www.paolomainardi.com/posts/docker-performance-macos/",
          "publishedOn": "2022-12-22T20:42:12.000Z",
          "wordCount": 3769,
          "title": "Docker on MacOS is slow and how to fix it",
          "imageUrl": "https://www.paolomainardi.com/images/posts/3-docker/docker-dalle-container-macbook.webp"
        },
        {
          "id": "https://www.nngroup.com/articles/optional-registration/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nngroup.com/articles/optional-registration/",
          "publishedOn": "2022-12-22T20:35:10.000Z",
          "wordCount": 2003,
          "title": "Don't force users to register before they can buy (2015)",
          "imageUrl": "https://media.nngroup.com/media/articles/opengraph_images/Slide23articlesoptional-registration.png"
        },
        {
          "id": "https://www.forbes.com/sites/emilybaker-white/2022/12/22/tiktok-tracks-forbes-journalists-bytedance/",
          "author": null,
          "description": "Comments",
          "link": "https://www.forbes.com/sites/emilybaker-white/2022/12/22/tiktok-tracks-forbes-journalists-bytedance/",
          "publishedOn": "2022-12-22T20:22:08.000Z",
          "wordCount": 11646,
          "title": "ByteDance confirmed it used TikTok to monitor journalists’ physical location",
          "imageUrl": "https://imageio.forbes.com/specials-images/imageserve/63a4af573d1eb6def1c8a814/0x0.jpg?format=jpg&width=1200"
        },
        {
          "id": "https://johanpeitz.itch.io/picosynth",
          "author": null,
          "description": "Comments",
          "link": "https://johanpeitz.itch.io/picosynth",
          "publishedOn": "2022-12-22T20:06:52.000Z",
          "wordCount": 515,
          "title": "Pico8 Music Synthesizer",
          "imageUrl": "https://img.itch.zone/aW1nLzEwNzM1ODQ1LnBuZw==/original/1CJm%2Fa.png"
        },
        {
          "id": "http://www.lispworks.com/products/myths_and_legends.html",
          "author": null,
          "description": "Comments",
          "link": "http://www.lispworks.com/products/myths_and_legends.html",
          "publishedOn": "2022-12-22T19:48:24.000Z",
          "wordCount": 5418,
          "title": "Common Lisp – Myths and Legends (2002)",
          "imageUrl": null
        },
        {
          "id": "https://huggingface.co/spaces/bigcode/santacoder-demo",
          "author": null,
          "description": "Comments",
          "link": "https://huggingface.co/spaces/bigcode/santacoder-demo",
          "publishedOn": "2022-12-22T19:45:44.000Z",
          "wordCount": 117,
          "title": "SantaCoder: A new 1.1B code model for generation and infilling",
          "imageUrl": "https://thumbnails.huggingface.co/social-thumbnails/spaces/bigcode/santacoder-demo.png"
        },
        {
          "id": "https://bunny.net/blog/introducing-bunny-optimizer-ai-a-new-way-of-creating-content/",
          "author": null,
          "description": "Comments",
          "link": "https://bunny.net/blog/introducing-bunny-optimizer-ai-a-new-way-of-creating-content/",
          "publishedOn": "2022-12-22T19:22:35.000Z",
          "wordCount": 1381,
          "title": "Bunny AI",
          "imageUrl": "https://bunny.net/blog/content/images/2022/12/bunnynet-introducing-bunny-ai-generate-images-dynamicaly.jpg"
        },
        {
          "id": "https://adamfallon.com/databreach/csv/elasticsearch/2022/12/22/elasticsearch-facebook-data-leak.html",
          "author": null,
          "description": "Comments",
          "link": "https://adamfallon.com/databreach/csv/elasticsearch/2022/12/22/elasticsearch-facebook-data-leak.html",
          "publishedOn": "2022-12-22T19:09:30.000Z",
          "wordCount": 1449,
          "title": "Searching a data breach with ElasticSearch",
          "imageUrl": null
        },
        {
          "id": "https://blog.lastpass.com/2022/12/notice-of-recent-security-incident/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.lastpass.com/2022/12/notice-of-recent-security-incident/",
          "publishedOn": "2022-12-22T19:07:27.000Z",
          "wordCount": 3217,
          "title": "Notice of Recent Security Incident [updated]",
          "imageUrl": "https://blog.lastpass.com/wp-content/uploads/sites/20/2022/08/iStock-621574390-1-scaled.jpg"
        },
        {
          "id": "https://greydanus.github.io/2020/12/01/scaling-down/",
          "author": null,
          "description": "Comments",
          "link": "https://greydanus.github.io/2020/12/01/scaling-down/",
          "publishedOn": "2022-12-22T19:04:39.000Z",
          "wordCount": 3435,
          "title": "Scaling Down Deep Learning",
          "imageUrl": null
        },
        {
          "id": "https://statmodeling.stat.columbia.edu/2022/12/22/do-simpler-machine-learning-models-exist-and-how-can-we-find-them/",
          "author": null,
          "description": "Comments",
          "link": "https://statmodeling.stat.columbia.edu/2022/12/22/do-simpler-machine-learning-models-exist-and-how-can-we-find-them/",
          "publishedOn": "2022-12-22T18:56:34.000Z",
          "wordCount": 3782,
          "title": "Do simpler machine learning models exist and how can we find them?",
          "imageUrl": null
        },
        {
          "id": "https://www.cnbc.com/2022/12/22/ftx-founder-sam-bankman-fried-to-be-released-on-250-million-bail.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.cnbc.com/2022/12/22/ftx-founder-sam-bankman-fried-to-be-released-on-250-million-bail.html",
          "publishedOn": "2022-12-22T18:50:20.000Z",
          "wordCount": 17389,
          "title": "FTX founder Sam Bankman-Fried to be released on $250M bail",
          "imageUrl": "https://image.cnbcfm.com/api/v1/image/107169989-1671666602093-gettyimages-1451152696-029a6648_9afdcfb2-7d82-4df2-ab6f-d8cd93d45c54.jpeg?v=1671734197&w=1920&h=1080"
        },
        {
          "id": "https://evoniuk.github.io/posts/pitfall.html",
          "author": null,
          "description": "Comments",
          "link": "https://evoniuk.github.io/posts/pitfall.html",
          "publishedOn": "2022-12-22T17:30:42.000Z",
          "wordCount": 2989,
          "title": "How Pitfall builds its world (2021)",
          "imageUrl": null
        },
        {
          "id": "https://devos50.github.io/blog/2022/ipod-touch-qemu/",
          "author": null,
          "description": "Comments",
          "link": "https://devos50.github.io/blog/2022/ipod-touch-qemu/",
          "publishedOn": "2022-12-22T17:22:01.000Z",
          "wordCount": 4214,
          "title": "Emulating an iPod Touch 1G and iPhoneOS 1.0 using QEMU (Part I)",
          "imageUrl": null
        },
        {
          "id": "https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/",
          "author": null,
          "description": "Comments",
          "link": "https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/",
          "publishedOn": "2022-12-22T17:17:46.000Z",
          "wordCount": 5759,
          "title": "Don't call yourself a programmer, and other career advice (2011)",
          "imageUrl": null
        },
        {
          "id": "https://randomascii.wordpress.com/2017/07/09/24-core-cpu-and-i-cant-move-my-mouse/",
          "author": null,
          "description": "Comments",
          "link": "https://randomascii.wordpress.com/2017/07/09/24-core-cpu-and-i-cant-move-my-mouse/",
          "publishedOn": "2022-12-22T16:23:49.000Z",
          "wordCount": 14811,
          "title": "24-core CPU and I can’t move my mouse (2017)",
          "imageUrl": "https://randomascii.files.wordpress.com/2017/07/gdi-serialization-fixed.png"
        },
        {
          "id": "https://www.benkuhn.net/abyss/",
          "author": null,
          "description": "Comments",
          "link": "https://www.benkuhn.net/abyss/",
          "publishedOn": "2022-12-22T15:54:24.000Z",
          "wordCount": 3727,
          "title": "Staring into the abyss as a core life skill",
          "imageUrl": null
        },
        {
          "id": "https://f-droid.org/2022/12/18/unifiedpush.html",
          "author": null,
          "description": "Comments",
          "link": "https://f-droid.org/2022/12/18/unifiedpush.html",
          "publishedOn": "2022-12-22T15:45:57.000Z",
          "wordCount": 1730,
          "title": "UnifiedPush: A decentralized, open-source push notification protocol",
          "imageUrl": "https://f-droid.org/assets/fdroid-logo_bfHl7nsLHOUQxzdU8-rGIhn4bAgl6z7k2mA3fWoCyT4=.png"
        },
        {
          "id": "https://spectrum.ieee.org/thin-film-solar-panels",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/thin-film-solar-panels",
          "publishedOn": "2022-12-22T14:08:00.000Z",
          "wordCount": 11502,
          "title": "Paper-Thin Solar Makes Any Surface Photovoltaic",
          "imageUrl": "https://spectrum.ieee.org/media-library/white-glvoed-hands-hold-up-a-green-and-gold-rectangle-of-material.jpg?id=32372942&width=1200&height=600&coordinates=0%2C173%2C0%2C173"
        },
        {
          "id": "https://eandt.theiet.org/content/articles/2022/12/japan-to-invest-on-nuclear-energy-in-major-policy-shift/",
          "author": null,
          "description": "Comments",
          "link": "https://eandt.theiet.org/content/articles/2022/12/japan-to-invest-on-nuclear-energy-in-major-policy-shift/",
          "publishedOn": "2022-12-22T13:18:03.000Z",
          "wordCount": 6968,
          "title": "Japan to invest on nuclear energy in major policy shift",
          "imageUrl": "https://eandt.theiet.org/media/20272/untitled-design-1.jpg?crop=0,0.27416666666666667,0,0.23364583333333328&cropmode=percentage&width=1200&height=450&rnd=133161801130000000"
        },
        {
          "id": "https://www.theguardian.com/artanddesign/2017/may/11/design-museum-california-designing-freedom-tech-design",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/artanddesign/2017/may/11/design-museum-california-designing-freedom-tech-design",
          "publishedOn": "2022-12-22T13:11:30.000Z",
          "wordCount": 5717,
          "title": "Tripping Californians who paved the way to our touchscreen world",
          "imageUrl": "https://i.guim.co.uk/img/media/ff05be3cc9c2cdb92a50ba1910320403fef787bc/14_43_2789_1673/master/2789.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2818de6d5efb50a18eacd9055961b847"
        },
        {
          "id": "https://dalton.substack.com/p/startup-childhood",
          "author": null,
          "description": "Comments",
          "link": "https://dalton.substack.com/p/startup-childhood",
          "publishedOn": "2022-12-22T13:11:24.000Z",
          "wordCount": 2252,
          "title": "Startup childhood – Tiny startups are not Google-in-miniature-form",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F11960689-a421-4f2b-b0c5-3720b4fea9a0_1500x1000.webp"
        },
        {
          "id": "https://www.theguardian.com/global-development/2022/dec/20/africas-biggest-photography-library-opens-in-ghana-accra-dikan-center",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/global-development/2022/dec/20/africas-biggest-photography-library-opens-in-ghana-accra-dikan-center",
          "publishedOn": "2022-12-22T11:02:26.000Z",
          "wordCount": 4918,
          "title": "Africa’s biggest photography library opens in Ghana",
          "imageUrl": "https://i.guim.co.uk/img/media/bf050f7d565f2973e32b7f41f52478f8305cd66e/0_483_7229_4338/master/7229.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=09c5b85fd666856af8160d0b4bfb0f1f"
        },
        {
          "id": "https://lemire.me/blog/2022/05/13/avoid-exception-throwing-in-performance-sensitive-code/",
          "author": null,
          "description": "Comments",
          "link": "https://lemire.me/blog/2022/05/13/avoid-exception-throwing-in-performance-sensitive-code/",
          "publishedOn": "2022-12-22T00:53:51.000Z",
          "wordCount": 4442,
          "title": "Avoid exception throwing in performance-sensitive code",
          "imageUrl": "https://lemire.me/img/portrait2018facebook.jpg"
        },
        {
          "id": "https://peter.sh/experiments/chromium-command-line-switches/",
          "author": null,
          "description": "Comments",
          "link": "https://peter.sh/experiments/chromium-command-line-switches/",
          "publishedOn": "2022-12-21T23:32:05.000Z",
          "wordCount": 29973,
          "title": "All 1,400 Google Chrome CLI flags",
          "imageUrl": null
        },
        {
          "id": "https://www.pixelmator.com/blog/2022/12/21/pixelmator-pro-gets-a-magical-ai-powered-deband-feature/",
          "author": null,
          "description": "Comments",
          "link": "https://www.pixelmator.com/blog/2022/12/21/pixelmator-pro-gets-a-magical-ai-powered-deband-feature/",
          "publishedOn": "2022-12-21T22:08:56.000Z",
          "wordCount": 1216,
          "title": "Pixelmator Pro gets a magical, AI‑powered Deband feature",
          "imageUrl": "https://pixelmator-blog.s3.amazonaws.com/2022-12-21-pixelmator-pro-introduces-a-magical-deband-feature/img_social.png"
        },
        {
          "id": "https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext",
          "author": null,
          "description": "Comments",
          "link": "https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext",
          "publishedOn": "2022-12-21T22:06:01.000Z",
          "wordCount": 2118,
          "title": "The End of Programming",
          "imageUrl": "https://cacm.acm.org/system/assets/0004/4466/121922_CACMpg34_The-End-of2.large.jpg?1671322023&1671322023"
        },
        {
          "id": "https://nim-lang.org/blog/2022/12/21/version-20-rc.html",
          "author": null,
          "description": "Comments",
          "link": "https://nim-lang.org/blog/2022/12/21/version-20-rc.html",
          "publishedOn": "2022-12-21T21:38:38.000Z",
          "wordCount": 4210,
          "title": "Nim version 2.0.0 release candidate",
          "imageUrl": "https://nim-lang.org/assets/img/twitter_banner.png"
        },
        {
          "id": "https://www.pypy.org/posts/2022/07/toy-optimizer.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.pypy.org/posts/2022/07/toy-optimizer.html",
          "publishedOn": "2022-12-21T21:26:59.000Z",
          "wordCount": 4229,
          "title": "Implementing a Toy Optimizer",
          "imageUrl": null
        },
        {
          "id": "https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html",
          "publishedOn": "2022-12-21T21:12:31.000Z",
          "wordCount": 6044,
          "title": "ChatGPT is a ‘code red’ for Google’s search business",
          "imageUrl": "https://static01.nyt.com/images/2022/12/20/business/00google-killer/00google-killer-facebookJumbo.jpg"
        },
        {
          "id": "https://en.wikipedia.org/wiki/All_American_Five",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/All_American_Five",
          "publishedOn": "2022-12-21T21:10:43.000Z",
          "wordCount": 3554,
          "title": "All American Five radio receivers",
          "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Philco_radio_model_PT44_front.jpg/1200px-Philco_radio_model_PT44_front.jpg"
        },
        {
          "id": "https://james.darpinian.com/blog/how-see-a-satellite-tonight-works",
          "author": null,
          "description": "Comments",
          "link": "https://james.darpinian.com/blog/how-see-a-satellite-tonight-works",
          "publishedOn": "2022-12-21T21:08:49.000Z",
          "wordCount": 4015,
          "title": "How “See a Satellite Tonight” Works",
          "imageUrl": "https://james.darpinian.com/blog/headshot.jpg"
        },
        {
          "id": "https://nld-intern.ds.mpg.de/swingratio/",
          "author": null,
          "description": "Comments",
          "link": "https://nld-intern.ds.mpg.de/swingratio/",
          "publishedOn": "2022-12-21T21:03:51.000Z",
          "wordCount": 997,
          "title": "Swing Ratio",
          "imageUrl": null
        },
        {
          "id": "https://www.fivehundredwordsaday.com/beta",
          "author": null,
          "description": "Comments",
          "link": "https://www.fivehundredwordsaday.com/beta",
          "publishedOn": "2022-12-21T20:29:30.000Z",
          "wordCount": 786,
          "title": "Show HN: Write 500 Words a Day",
          "imageUrl": null
        },
        {
          "id": "https://github.com/LMP88959/NTSC-CRT",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/LMP88959/NTSC-CRT",
          "publishedOn": "2022-12-21T20:22:49.000Z",
          "wordCount": 999,
          "title": "NTSC encoding/decoding in C89 using only integers and fixed point math",
          "imageUrl": "https://opengraph.githubassets.com/0dbb8ffb49ee587315f54c1f46ebe27b2c6e440537aa43db601d2d253604142f/LMP88959/NTSC-CRT"
        },
        {
          "id": "https://brev.dev/blog/ai-wont-replace-you-write-bash",
          "author": null,
          "description": "Comments",
          "link": "https://brev.dev/blog/ai-wont-replace-you-write-bash",
          "publishedOn": "2022-12-21T20:22:16.000Z",
          "wordCount": 1415,
          "title": "Using ChatGPT to make Bash palatable",
          "imageUrl": "https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/thumbnail-main.png"
        },
        {
          "id": "https://www.infoq.com/news/2022/12/openjdk-galahad-Dec22/",
          "author": null,
          "description": "Comments",
          "link": "https://www.infoq.com/news/2022/12/openjdk-galahad-Dec22/",
          "publishedOn": "2022-12-21T19:56:22.000Z",
          "wordCount": 7544,
          "title": "OpenJDK Proposes Project Galahad to Merge GraalVM Native Compilation",
          "imageUrl": "https://cdn.infoq.com/statics_s1_20221220065205/styles/static/images/logo/logo-big.jpg"
        },
        {
          "id": "https://www.philipithomas.com/posts/why-i-built-postcard-a-calmer-alternative-to-social-networks",
          "author": null,
          "description": "Comments",
          "link": "https://www.philipithomas.com/posts/why-i-built-postcard-a-calmer-alternative-to-social-networks",
          "publishedOn": "2022-12-21T19:20:16.000Z",
          "wordCount": 594,
          "title": "Personal newsletters as a calmer alternative to social networks",
          "imageUrl": "https://www.philipithomas.com/posts/why-i-built-postcard-a-calmer-alternative-to-social-networks/og/1671725138"
        },
        {
          "id": "https://github.com/microsoft/checkedc",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/microsoft/checkedc",
          "publishedOn": "2022-12-21T18:29:49.000Z",
          "wordCount": 1378,
          "title": "Checked C",
          "imageUrl": "https://opengraph.githubassets.com/4074f767e37b1fc28d0f9770a1f9bffb913740eb8d2862f44780b5bb2583bcc9/microsoft/checkedc"
        },
        {
          "id": "https://github.com/jnsmalm/pixi3d",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/jnsmalm/pixi3d",
          "publishedOn": "2022-12-21T17:49:36.000Z",
          "wordCount": 2430,
          "title": "Pixi3D – 3D rendering library for the web",
          "imageUrl": "https://opengraph.githubassets.com/a29b7ed8bb4c12ed2b6779e755e8ab6105eb889cce2164e3495ea195722c38a2/jnsmalm/pixi3d"
        },
        {
          "id": "https://mprimi.github.io/portable-secret/",
          "author": null,
          "description": "Comments",
          "link": "https://mprimi.github.io/portable-secret/",
          "publishedOn": "2022-12-21T17:10:28.000Z",
          "wordCount": 819,
          "title": "Show HN: Portable Secret – How I store my secrets and communicate privately",
          "imageUrl": null
        },
        {
          "id": "https://www.ycombinator.com/companies/ciro/jobs",
          "author": null,
          "description": "Comments",
          "link": "https://www.ycombinator.com/companies/ciro/jobs",
          "publishedOn": "2022-12-21T17:00:42.000Z",
          "wordCount": 1959,
          "title": "Ciro (YC S22) hiring a founding back end engineer to build an SMB search engine",
          "imageUrl": "https://bookface-images.s3.amazonaws.com/logos/765d253c1131dca038a6ffed081c22c1ad1c92c5.png?1650821484"
        },
        {
          "id": "https://www.economist.com/interactive/christmas-specials/2022/12/20/the-decline-of-the-city-grid",
          "author": null,
          "description": "Comments",
          "link": "https://www.economist.com/interactive/christmas-specials/2022/12/20/the-decline-of-the-city-grid",
          "publishedOn": "2022-12-21T16:30:46.000Z",
          "wordCount": 2292,
          "title": "The Decline of the City Grid",
          "imageUrl": "https://www.economist.com/interactive/christmas-specials/2022/12/20/the-decline-of-the-city-grid/promo.jpg"
        },
        {
          "id": "https://jami.net/",
          "author": null,
          "description": "Comments",
          "link": "https://jami.net/",
          "publishedOn": "2022-12-21T16:24:30.000Z",
          "wordCount": 577,
          "title": "Jami: Share, Message, Call freely and privately",
          "imageUrl": "https://jami.net/assets/images/logo-jami.jpg"
        },
        {
          "id": "https://arxiv.org/abs/2212.09835",
          "author": null,
          "description": "Comments",
          "link": "https://arxiv.org/abs/2212.09835",
          "publishedOn": "2022-12-21T15:36:07.000Z",
          "wordCount": 458,
          "title": "A non-constructive proof of the Four Colour Theorem",
          "imageUrl": null
        },
        {
          "id": "https://www.nbcphiladelphia.com/news/tech/pay-phone-philadelphia/3452775/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nbcphiladelphia.com/news/tech/pay-phone-philadelphia/3452775/",
          "publishedOn": "2022-12-21T15:26:05.000Z",
          "wordCount": 7714,
          "title": "Philadelphia Phreakers installing free payphone",
          "imageUrl": "https://media.nbcphiladelphia.com/2022/12/This-Philly-Guy-Is-Trying-to-Bring-Back-the-Pay-Phone-Without-the-Pay-Part.jpg?quality=85&strip=all&resize=1200%2C675"
        },
        {
          "id": "https://www.scientificamerican.com/article/scientists-created-male-and-female-cells-from-a-single-person/",
          "author": null,
          "description": "Comments",
          "link": "https://www.scientificamerican.com/article/scientists-created-male-and-female-cells-from-a-single-person/",
          "publishedOn": "2022-12-21T13:30:45.000Z",
          "wordCount": 4500,
          "title": "Scientists generate XX and XY cells from a single person",
          "imageUrl": "https://static.scientificamerican.com/sciam/cache/file/B6487D36-289D-4A0C-9FB6802485113611.jpg"
        },
        {
          "id": "https://realizeengineering.blog/2021/01/20/we-are-drowning-in-information-while-starving-for-wisdom/",
          "author": null,
          "description": "Comments",
          "link": "https://realizeengineering.blog/2021/01/20/we-are-drowning-in-information-while-starving-for-wisdom/",
          "publishedOn": "2022-12-21T13:26:46.000Z",
          "wordCount": 3806,
          "title": "We are drowning in information while starving for wisdom (2021)",
          "imageUrl": "https://realizeengineering.files.wordpress.com/2021/01/lake-maggiore.jpg"
        },
        {
          "id": "https://foon.uk/how-flash-2022/",
          "author": null,
          "description": "Comments",
          "link": "https://foon.uk/how-flash-2022/",
          "publishedOn": "2022-12-21T12:01:57.000Z",
          "wordCount": 4232,
          "title": "I still use Flash",
          "imageUrl": "https://foon.uk/how-flash-2022/thumbs/action.png"
        },
        {
          "id": "https://www.cyclist.co.uk/in-depth/11046/bike-frame-stiffness",
          "author": null,
          "description": "Comments",
          "link": "https://www.cyclist.co.uk/in-depth/11046/bike-frame-stiffness",
          "publishedOn": "2022-12-21T11:59:07.000Z",
          "wordCount": 2765,
          "title": "Bike Frame Stiffness",
          "imageUrl": "https://cyclist.b-cdn.net/sites/cyclist/files/2022/12/stiffness_01.jpg"
        },
        {
          "id": "https://www.apple.com/newsroom/2022/12/apple-launches-freeform-a-powerful-new-app-designed-for-creative-collaboration/",
          "author": null,
          "description": "Comments",
          "link": "https://www.apple.com/newsroom/2022/12/apple-launches-freeform-a-powerful-new-app-designed-for-creative-collaboration/",
          "publishedOn": "2022-12-21T10:37:37.000Z",
          "wordCount": 2627,
          "title": "Freeform: a new app designed for creative collaboration",
          "imageUrl": "https://www.apple.com/newsroom/images/product/apps/standard/Apple-Freeform-hero.jpg.og.jpg?202212211312"
        },
        {
          "id": "https://www.youtube.com/watch?v=bfJY0syocfU",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=bfJY0syocfU",
          "publishedOn": "2022-12-21T10:33:57.000Z",
          "wordCount": null,
          "title": "A swarm of robots built this tunnel [video]",
          "imageUrl": null
        },
        {
          "id": "https://but-her-flies.bearblog.dev/mastodon-is-not-a-good-social-network/",
          "author": null,
          "description": "Comments",
          "link": "https://but-her-flies.bearblog.dev/mastodon-is-not-a-good-social-network/",
          "publishedOn": "2022-12-21T09:15:14.000Z",
          "wordCount": 996,
          "title": "Mastodon's federation model encourages specific instances with peculiar rules",
          "imageUrl": null
        },
        {
          "id": "https://www.alexbond.com.au/understanding-large-format-camera-movements/",
          "author": null,
          "description": "Comments",
          "link": "https://www.alexbond.com.au/understanding-large-format-camera-movements/",
          "publishedOn": "2022-12-21T09:04:50.000Z",
          "wordCount": 11164,
          "title": "Large-format camera movements (2020)",
          "imageUrl": "https://www.alexbond.com.au/wp-content/uploads/2020/04/front-tilt_7772.jpg"
        },
        {
          "id": "https://emilymstark.com/2022/12/18/death-to-the-line-of-death.html",
          "author": null,
          "description": "Comments",
          "link": "https://emilymstark.com/2022/12/18/death-to-the-line-of-death.html",
          "publishedOn": "2022-12-21T00:21:34.000Z",
          "wordCount": 1789,
          "title": "The death of the line of death",
          "imageUrl": null
        },
        {
          "id": "https://themacrocompass.substack.com/p/bank-of-japan-surprise",
          "author": null,
          "description": "Comments",
          "link": "https://themacrocompass.substack.com/p/bank-of-japan-surprise",
          "publishedOn": "2022-12-21T00:09:58.000Z",
          "wordCount": 4612,
          "title": "The recent Bank of Japan meeting and its implications for markets",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1ab2c16d-18c1-43cd-8d1c-7ba570893771_1465x1048.jpeg"
        },
        {
          "id": "https://noidea.dog/glue",
          "author": null,
          "description": "Comments",
          "link": "https://noidea.dog/glue",
          "publishedOn": "2022-12-21T00:00:03.000Z",
          "wordCount": 7559,
          "title": "Being Glue (2019)",
          "imageUrl": "http://static1.squarespace.com/static/5a05ececd55b4165f250f032/t/5cc9ed1ec830253749518ae4/1556737311165/boat-1297042_1280+%281%29.png?format=1500w"
        },
        {
          "id": "https://www.nytimes.com/2022/12/19/books/cormac-mccarthy-food-passenger.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/19/books/cormac-mccarthy-food-passenger.html",
          "publishedOn": "2022-12-20T23:01:44.000Z",
          "wordCount": null,
          "title": "Cormac McCarthy loves a good diner",
          "imageUrl": null
        },
        {
          "id": "https://www.jetpack.io/blog/devbox-0-2-0/",
          "author": null,
          "description": "Comments",
          "link": "https://www.jetpack.io/blog/devbox-0-2-0/",
          "publishedOn": "2022-12-20T22:50:34.000Z",
          "wordCount": 1241,
          "title": "Devbox 0.2.0: Automatic Nix installer, plugins, and background services",
          "imageUrl": "https://res-5.cloudinary.com/jetpack-io/image/upload/q_auto/v1/blog/Devbox-0.2.0.png"
        },
        {
          "id": "https://blog.mozilla.org/en/mozilla/mozilla-launch-fediverse-instance-social-media-alternative/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.mozilla.org/en/mozilla/mozilla-launch-fediverse-instance-social-media-alternative/",
          "publishedOn": "2022-12-20T22:45:36.000Z",
          "wordCount": 1497,
          "title": "Mozilla to explore healthy social media alternative",
          "imageUrl": "https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/11/pocket_best_of_special_collections_stories_1200x800-1200x800.jpg"
        },
        {
          "id": "https://www.sparkfun.com/news/5497",
          "author": null,
          "description": "Comments",
          "link": "https://www.sparkfun.com/news/5497",
          "publishedOn": "2022-12-20T22:42:56.000Z",
          "wordCount": null,
          "title": "LoRa: Field Testing Antennas",
          "imageUrl": null
        },
        {
          "id": "https://cacm.acm.org/blogs/blog-cacm/267674-ais-jurassic-park-moment/fulltext",
          "author": null,
          "description": "Comments",
          "link": "https://cacm.acm.org/blogs/blog-cacm/267674-ais-jurassic-park-moment/fulltext",
          "publishedOn": "2022-12-20T22:32:08.000Z",
          "wordCount": 1791,
          "title": "AI's Jurassic Park Moment",
          "imageUrl": "https://cacm.acm.org/system/assets/0004/4410/121222_Gary_Marcus_Marcus.large.jpg?1670874682&1670874682"
        },
        {
          "id": "https://vgel.me/posts/donut/",
          "author": null,
          "description": "Comments",
          "link": "https://vgel.me/posts/donut/",
          "publishedOn": "2022-12-20T22:00:30.000Z",
          "wordCount": 3879,
          "title": "Signed distance functions in 46 lines of Python",
          "imageUrl": null
        },
        {
          "id": "https://slimemoldtimemold.com/2022/12/20/people-took-some-potassium-and-lost-some-weight/",
          "author": null,
          "description": "Comments",
          "link": "https://slimemoldtimemold.com/2022/12/20/people-took-some-potassium-and-lost-some-weight/",
          "publishedOn": "2022-12-20T21:25:02.000Z",
          "wordCount": 17707,
          "title": "People took some potassium and lost some weight",
          "imageUrl": "https://slimemoldtimemold.files.wordpress.com/2022/12/sirkaysturkeylegss_01-copy.jpg"
        },
        {
          "id": "https://www.newstatesman.com/culture/music/2022/11/well-tempered-clavier-bach-300-years-accidental-masterpiece",
          "author": null,
          "description": "Comments",
          "link": "https://www.newstatesman.com/culture/music/2022/11/well-tempered-clavier-bach-300-years-accidental-masterpiece",
          "publishedOn": "2022-12-20T20:54:41.000Z",
          "wordCount": 4730,
          "title": "Bach’s Accidental Masterpiece",
          "imageUrl": "https://www.newstatesman.com/wp-content/uploads/sites/2/2022/11/202249-Bach.jpg"
        },
        {
          "id": "https://technology.doximity.com/articles/ruby-delights-built-into-the-language",
          "author": null,
          "description": "Comments",
          "link": "https://technology.doximity.com/articles/ruby-delights-built-into-the-language",
          "publishedOn": "2022-12-20T20:51:07.000Z",
          "wordCount": 7338,
          "title": "Ruby delights built into the language",
          "imageUrl": "https://res.cloudinary.com/dhttas9u5/image/upload/c_fill,dpr_2,fl_progressive,h_800,q_auto,w_1600/dsfstuyoarbamkbuls2z.jpg"
        },
        {
          "id": "https://web.law.duke.edu/cspd/publicdomainday/2023/",
          "author": null,
          "description": "Comments",
          "link": "https://web.law.duke.edu/cspd/publicdomainday/2023/",
          "publishedOn": "2022-12-20T20:50:50.000Z",
          "wordCount": 9533,
          "title": "January 1, 2023 is Public Domain Day: Works from 1927 are open to all",
          "imageUrl": "https://web.law.duke.edu/sites/default/files/images/centers/cspd/pdd2023/2023-montage.jpg"
        },
        {
          "id": "https://jorzel.github.io/deep-work-essentialism-in-asynchronous-culture/",
          "author": null,
          "description": "Comments",
          "link": "https://jorzel.github.io/deep-work-essentialism-in-asynchronous-culture/",
          "publishedOn": "2022-12-20T20:12:53.000Z",
          "wordCount": 1375,
          "title": "Deep work. Essentialism in asynchronous culture",
          "imageUrl": null
        },
        {
          "id": "https://potassco.org/",
          "author": null,
          "description": "Comments",
          "link": "https://potassco.org/",
          "publishedOn": "2022-12-20T19:40:28.000Z",
          "wordCount": 240,
          "title": "Potassco: The Answer Set Solving Collection",
          "imageUrl": null
        },
        {
          "id": "https://there.oughta.be/a/game-boy-capture-cartridge",
          "author": null,
          "description": "Comments",
          "link": "https://there.oughta.be/a/game-boy-capture-cartridge",
          "publishedOn": "2022-12-20T17:40:21.000Z",
          "wordCount": 4859,
          "title": "There oughta be a Game Boy capture cartridge",
          "imageUrl": "https://there.oughta.be/assets/images/2022-12-20/youtube.jpg"
        },
        {
          "id": "http://blog.presentandcorrect.com/27986-2",
          "author": null,
          "description": "Comments",
          "link": "http://blog.presentandcorrect.com/27986-2",
          "publishedOn": "2022-12-20T17:34:31.000Z",
          "wordCount": 525,
          "title": "A collection of Soviet control rooms",
          "imageUrl": null
        },
        {
          "id": "https://ourworldindata.org/europe-mammal-comeback",
          "author": null,
          "description": "Comments",
          "link": "https://ourworldindata.org/europe-mammal-comeback",
          "publishedOn": "2022-12-20T17:28:17.000Z",
          "wordCount": 2361,
          "title": "Wild mammals are making a comeback in Europe",
          "imageUrl": "https://ourworldindata.org/uploads/2022/05/European-mammals-thumbnail-768x402.png"
        },
        {
          "id": "https://www.ribbonhealth.com/blog/arik-gaisler-ribbons-new-vp-of-engineering-knows-what-makes-a-successful-tech-team",
          "author": null,
          "description": "Comments",
          "link": "https://www.ribbonhealth.com/blog/arik-gaisler-ribbons-new-vp-of-engineering-knows-what-makes-a-successful-tech-team",
          "publishedOn": "2022-12-20T17:00:01.000Z",
          "wordCount": 1604,
          "title": "Ribbon (YC S17) is hiring engineers who want to simplify healthcare",
          "imageUrl": "https://assets.website-files.com/633f1ce35b02f44cbe97afba/639c8ee075bcb403672cb02f_Screen%20Shot%202022-12-16%20at%2010.29.07%20AM.png"
        },
        {
          "id": "https://finance.yahoo.com/news/wells-fargo-reaches-record-3-135449093.html",
          "author": null,
          "description": "Comments",
          "link": "https://finance.yahoo.com/news/wells-fargo-reaches-record-3-135449093.html",
          "publishedOn": "2022-12-20T16:03:54.000Z",
          "wordCount": 14412,
          "title": "Wells Fargo to pay $3.7B for mistreating customers",
          "imageUrl": "https://s.yimg.com/ny/api/res/1.2/coCTgtsJ5spowFFQVs.cRA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/bloomberg_markets_842/821865e0f63580debe413b0776268422"
        },
        {
          "id": "https://grack.com/blog/2022/12/20/deriving-a-bit-twiddling-hack/",
          "author": null,
          "description": "Comments",
          "link": "https://grack.com/blog/2022/12/20/deriving-a-bit-twiddling-hack/",
          "publishedOn": "2022-12-20T15:26:42.000Z",
          "wordCount": 1720,
          "title": "Deriving a Bit-Twiddling Hack: Signed Integer Overflow",
          "imageUrl": null
        },
        {
          "id": "https://paidlink.to/",
          "author": null,
          "description": "Comments",
          "link": "https://paidlink.to/",
          "publishedOn": "2022-12-20T15:23:07.000Z",
          "wordCount": 297,
          "title": "Show HN: Create a paid link to anything",
          "imageUrl": null
        },
        {
          "id": "https://www.nbcnewyork.com/investigations/face-recognition-tech-gets-girl-scout-mom-booted-from-rockettes-show-due-to-her-employer/4004677/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nbcnewyork.com/investigations/face-recognition-tech-gets-girl-scout-mom-booted-from-rockettes-show-due-to-her-employer/4004677/",
          "publishedOn": "2022-12-20T15:13:47.000Z",
          "wordCount": 10702,
          "title": "Facial recognition tech gets woman booted from Rockettes show due to employer",
          "imageUrl": "https://media.nbcnewyork.com/2022/12/Radio-City-music-Hall-w-insets.jpg?quality=85&strip=all&resize=1200%2C675"
        },
        {
          "id": "https://obsidian.md/canvas",
          "author": null,
          "description": "Comments",
          "link": "https://obsidian.md/canvas",
          "publishedOn": "2022-12-20T15:04:48.000Z",
          "wordCount": 841,
          "title": "Show HN: Obsidian Canvas – An infinite space for your ideas",
          "imageUrl": "https://obsidian.md/images/banner.png"
        },
        {
          "id": "https://maskray.me/blog/2022-12-18-control-flow-integrity",
          "author": null,
          "description": "Comments",
          "link": "https://maskray.me/blog/2022-12-18-control-flow-integrity",
          "publishedOn": "2022-12-20T13:43:10.000Z",
          "wordCount": 3114,
          "title": "Control-flow integrity",
          "imageUrl": null
        },
        {
          "id": "https://tafc.space/qna/the-topologists-world-map/",
          "author": null,
          "description": "Comments",
          "link": "https://tafc.space/qna/the-topologists-world-map/",
          "publishedOn": "2022-12-20T12:05:53.000Z",
          "wordCount": 2163,
          "title": "The topologist’s world map (2020)",
          "imageUrl": null
        },
        {
          "id": "https://robertheaton.com/2018/12/17/wavefunction-collapse-algorithm/",
          "author": null,
          "description": "Comments",
          "link": "https://robertheaton.com/2018/12/17/wavefunction-collapse-algorithm/",
          "publishedOn": "2022-12-20T11:54:23.000Z",
          "wordCount": 2869,
          "title": "The “Wavefunction Collapse” generation algorithm explained clearly (2018)",
          "imageUrl": "https://robertheaton.com/images/wfc-terminal.png"
        },
        {
          "id": "https://github.com/openai/point-e",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/openai/point-e",
          "publishedOn": "2022-12-20T11:15:49.000Z",
          "wordCount": 707,
          "title": "Point-E: Point cloud diffusion for 3D model synthesis",
          "imageUrl": "https://opengraph.githubassets.com/39dcd9b5e33bcf9a49b5d302724e7664ba2d92be531be8df4de94e2ab4b67c11/openai/point-e"
        },
        {
          "id": "https://raw.githubusercontent.com/websnarf/bstrlib/master/bstrlib.txt",
          "author": null,
          "description": "Comments",
          "link": "https://raw.githubusercontent.com/websnarf/bstrlib/master/bstrlib.txt",
          "publishedOn": "2022-12-20T10:39:51.000Z",
          "wordCount": 24293,
          "title": "Better String Library (2015)",
          "imageUrl": null
        },
        {
          "id": "https://www.downtowndougbrown.com/2022/12/upgrading-my-old-chumby-8-linux-kernel-part-1-u-boot/",
          "author": null,
          "description": "Comments",
          "link": "https://www.downtowndougbrown.com/2022/12/upgrading-my-old-chumby-8-linux-kernel-part-1-u-boot/",
          "publishedOn": "2022-12-20T10:18:11.000Z",
          "wordCount": 4803,
          "title": "Upgrading my old Chumby 8 Linux kernel",
          "imageUrl": null
        },
        {
          "id": "https://wiki.c2.com/?ExceptionPatterns",
          "author": null,
          "description": "Comments",
          "link": "https://wiki.c2.com/?ExceptionPatterns",
          "publishedOn": "2022-12-20T08:16:23.000Z",
          "wordCount": 780,
          "title": "Exception Patterns (2013)",
          "imageUrl": null
        },
        {
          "id": "https://www.theregister.com/2022/12/19/in_praise_of_midi_techs/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theregister.com/2022/12/19/in_praise_of_midi_techs/",
          "publishedOn": "2022-12-20T08:11:39.000Z",
          "wordCount": 1749,
          "title": "In praise of MIDI",
          "imageUrl": "https://regmedia.co.uk/2022/12/16/shutterstock_midi.jpg"
        },
        {
          "id": "https://www.theguardian.com/world/2022/dec/19/peru-nazca-plain-ancient-art-new-designs-discovered",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/world/2022/dec/19/peru-nazca-plain-ancient-art-new-designs-discovered",
          "publishedOn": "2022-12-20T07:23:43.000Z",
          "wordCount": 4413,
          "title": "More than 100 new designs discovered in Peru’s ancient Nazca plain",
          "imageUrl": "https://i.guim.co.uk/img/media/d76c9a7f98332ea93a6a146c3286e13f9d6d0b46/0_259_3500_2100/master/3500.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=cce953a9c396da79e0183e1e746e63ef"
        },
        {
          "id": "https://github.com/microsoft/WSA/discussions/167",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/microsoft/WSA/discussions/167",
          "publishedOn": "2022-12-20T01:08:02.000Z",
          "wordCount": 1693,
          "title": "The Windows Subsystem for Android now runs Android 13 in beta",
          "imageUrl": "https://opengraph.githubassets.com/5939b20d240d541c07cc6d48f2f18be4115d040db00197f135c89f2a1d788c8a/microsoft/WSA/discussions/167"
        },
        {
          "id": "https://github.com/google-research/frame-interpolation",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/google-research/frame-interpolation",
          "publishedOn": "2022-12-20T00:11:30.000Z",
          "wordCount": 1772,
          "title": "FILM: Frame Interpolation for Large Motion",
          "imageUrl": "https://opengraph.githubassets.com/7469e768e44052f8e7bcacd1b3278324cff437afc72572d1ff8dd0fd1ad8d357/google-research/frame-interpolation"
        },
        {
          "id": "https://www.bloomberg.com/news/articles/2022-12-19/two-charged-with-using-amazon-ring-cameras-in-nationwide-swatting-spree",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/articles/2022-12-19/two-charged-with-using-amazon-ring-cameras-in-nationwide-swatting-spree",
          "publishedOn": "2022-12-19T23:59:22.000Z",
          "wordCount": 576,
          "title": "Amazon Ring cameras used in nationwide ‘swatting’ spree, US Justice Dept. says",
          "imageUrl": null
        },
        {
          "id": "https://theforceengine.github.io/",
          "author": null,
          "description": "Comments",
          "link": "https://theforceengine.github.io/",
          "publishedOn": "2022-12-19T23:54:21.000Z",
          "wordCount": 789,
          "title": "The Force Engine v1.0 Released",
          "imageUrl": null
        },
        {
          "id": "https://lemire.me/blog/2022/12/19/implementing-strlen-using-sve/",
          "author": null,
          "description": "Comments",
          "link": "https://lemire.me/blog/2022/12/19/implementing-strlen-using-sve/",
          "publishedOn": "2022-12-19T22:44:36.000Z",
          "wordCount": 3447,
          "title": "Implementing ‘strlen’ using SVE",
          "imageUrl": "https://lemire.me/img/portrait2018facebook.jpg"
        },
        {
          "id": "https://github.com/facebook/zstd",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/facebook/zstd",
          "publishedOn": "2022-12-19T22:31:47.000Z",
          "wordCount": 2005,
          "title": "Zstandard – Fast real-time compression algorithm",
          "imageUrl": "https://opengraph.githubassets.com/5c85202b23def8995514f646edab958cc264c26fdcfae3e8cfa8cefb4a6604a1/facebook/zstd"
        },
        {
          "id": "https://phys.org/news/2022-12-isotopic-signatures-ryugu-comets-unique.html",
          "author": null,
          "description": "Comments",
          "link": "https://phys.org/news/2022-12-isotopic-signatures-ryugu-comets-unique.html",
          "publishedOn": "2022-12-19T22:30:12.000Z",
          "wordCount": 1880,
          "title": "Ryugu isotopes suggest it formed close to comets along with some unique minerals",
          "imageUrl": "https://scx2.b-cdn.net/gfx/news/hires/2022/isotopic-signatures-in.jpg"
        },
        {
          "id": "https://borretti.me/article/astronomical-calculations-for-hard-sf-common-lisp",
          "author": null,
          "description": "Comments",
          "link": "https://borretti.me/article/astronomical-calculations-for-hard-sf-common-lisp",
          "publishedOn": "2022-12-19T22:27:53.000Z",
          "wordCount": 4941,
          "title": "Astronomical Calculations for Hard SF in Common Lisp",
          "imageUrl": "https://borretti.me/assets/card/astronomical-calculations-hard-sf-common-lisp.jpg"
        },
        {
          "id": "https://www.sigarch.org/fast-memcpy-a-system-design/",
          "author": null,
          "description": "Comments",
          "link": "https://www.sigarch.org/fast-memcpy-a-system-design/",
          "publishedOn": "2022-12-19T22:07:45.000Z",
          "wordCount": 3677,
          "title": "Fast memcpy, A System Design",
          "imageUrl": "https://www.sigarch.org/wp-content/uploads/2022/12/monk_copying_rounded.png"
        },
        {
          "id": "https://jakecoppinger.com/2022/12/sydney-cbd-is-bringing-back-pedestrian-beg-buttons/",
          "author": null,
          "description": "Comments",
          "link": "https://jakecoppinger.com/2022/12/sydney-cbd-is-bringing-back-pedestrian-beg-buttons/",
          "publishedOn": "2022-12-19T21:29:55.000Z",
          "wordCount": 2899,
          "title": "Sydney CBD is bringing back pedestrian “beg buttons”",
          "imageUrl": "https://jakecoppinger.com/wp-content/uploads/2022/12/IMG_0739-1.jpg"
        },
        {
          "id": "https://www.technologyreview.com/2022/12/19/1065306/roomba-irobot-robot-vacuums-artificial-intelligence-training-data-privacy/",
          "author": null,
          "description": "Comments",
          "link": "https://www.technologyreview.com/2022/12/19/1065306/roomba-irobot-robot-vacuums-artificial-intelligence-training-data-privacy/",
          "publishedOn": "2022-12-19T21:04:59.000Z",
          "wordCount": 15549,
          "title": "How did Roomba-recorded photos end up on Facebook?",
          "imageUrl": "https://wp.technologyreview.com/wp-content/uploads/2022/12/A_3-crop.jpg?resize=1200,600"
        },
        {
          "id": "https://bigthink.com/the-future/cryonics-horror-stories/",
          "author": null,
          "description": "Comments",
          "link": "https://bigthink.com/the-future/cryonics-horror-stories/",
          "publishedOn": "2022-12-19T21:02:55.000Z",
          "wordCount": 4345,
          "title": "What happened to the first cryogenically frozen humans?",
          "imageUrl": "https://bigthink.com/wp-content/uploads/2022/08/headfinal2.jpg?resize=1200,630"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34056812",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34056812",
          "publishedOn": "2022-12-19T19:56:52.000Z",
          "wordCount": 7663,
          "title": "Ask HN: What is the cheapest, easiest way to host a cronjob in 2022?",
          "imageUrl": null
        },
        {
          "id": "https://github.com/dariusk/twitter-archiver",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/dariusk/twitter-archiver",
          "publishedOn": "2022-12-19T19:21:55.000Z",
          "wordCount": 681,
          "title": "Twitter archiver: Make your own simple, public, searchable Twitter archive",
          "imageUrl": "https://opengraph.githubassets.com/f62f86b69a7b3bcef86f5613bb85be4fa49697a570087c91d0f76eb1df317541/dariusk/twitter-archiver"
        },
        {
          "id": "https://www.nature.com/articles/s41578-022-00483-4",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/articles/s41578-022-00483-4",
          "publishedOn": "2022-12-19T19:21:26.000Z",
          "wordCount": 17729,
          "title": "Hydrogel interfaces for merging humans and machines",
          "imageUrl": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41578-022-00483-4/MediaObjects/41578_2022_483_Fig1_HTML.png"
        },
        {
          "id": "https://github.com/Spotifyd/spotifyd",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Spotifyd/spotifyd",
          "publishedOn": "2022-12-19T18:56:38.000Z",
          "wordCount": 862,
          "title": "Spotifyd",
          "imageUrl": "https://opengraph.githubassets.com/ef6e6a882febb41bf1340e499969a621665f7a71dc98076b327b78cddbab3fd2/Spotifyd/spotifyd"
        },
        {
          "id": "https://www.helmholtz-berlin.de/pubbin/news_seite?nid=24348&sprache=en&seitenid=1",
          "author": null,
          "description": "Comments",
          "link": "https://www.helmholtz-berlin.de/pubbin/news_seite?nid=24348&sprache=en&seitenid=1",
          "publishedOn": "2022-12-19T18:51:04.000Z",
          "wordCount": 2027,
          "title": "Tandem solar cell achieves 32.5 percent efficiency",
          "imageUrl": "https://www.helmholtz-berlin.de/pubbin/news_datei?modus=DETAIL&did=15063"
        },
        {
          "id": "https://briancallahan.net/blog/20221219.html",
          "author": null,
          "description": "Comments",
          "link": "https://briancallahan.net/blog/20221219.html",
          "publishedOn": "2022-12-19T18:19:08.000Z",
          "wordCount": 1189,
          "title": "GCC now includes Modula-2 and Rust. Do they work on OpenBSD?",
          "imageUrl": null
        },
        {
          "id": "https://github.com/Infisical/infisical",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Infisical/infisical",
          "publishedOn": "2022-12-19T17:52:20.000Z",
          "wordCount": 1440,
          "title": "Show HN: Infisical – open-source secrets manager",
          "imageUrl": "https://repository-images.githubusercontent.com/521655652/7d1fa6af-1799-411b-a127-ae342e934685"
        },
        {
          "id": "https://blog.tempus-ex.com/hello-video-codec/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.tempus-ex.com/hello-video-codec/",
          "publishedOn": "2022-12-19T17:50:34.000Z",
          "wordCount": 2151,
          "title": "Video codec in 100 lines of Rust",
          "imageUrl": "https://blog.tempus-ex.com/content/images/2021/07/tears_of_steel_12130_vis.jpg"
        },
        {
          "id": "https://www.reuters.com/technology/binances-books-are-black-box-filings-show-crypto-giant-tries-rally-confidence-2022-12-19/",
          "author": null,
          "description": "Comments",
          "link": "https://www.reuters.com/technology/binances-books-are-black-box-filings-show-crypto-giant-tries-rally-confidence-2022-12-19/",
          "publishedOn": "2022-12-19T17:48:02.000Z",
          "wordCount": 10508,
          "title": "Binance's books are a black box, filings show, as it tries to rally confidence",
          "imageUrl": "https://www.reuters.com/resizer/-hT9_WQK-v6DeN7BZhcp16_kjb0=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/GDB4YV3UQFNHJMGZVA7FACCKJ4.jpg"
        },
        {
          "id": "https://www.treehugger.com/how-cook-any-whole-grain-popcorn-4858738",
          "author": null,
          "description": "Comments",
          "link": "https://www.treehugger.com/how-cook-any-whole-grain-popcorn-4858738",
          "publishedOn": "2022-12-19T17:22:07.000Z",
          "wordCount": 3519,
          "title": "Cook whole grains like popcorn (2018)",
          "imageUrl": "https://www.treehugger.com/thmb/gumtqbzn5Tdl_vrT7-4X0cLPXfw=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/__opt__aboutcom__coeus__resources__content_migration__treehugger__images__2017__02__popped-buckwheat-fa9e68517fb4462a863437ac17157609.jpg"
        },
        {
          "id": "https://biosrhythm.com/?p=2224",
          "author": null,
          "description": "Comments",
          "link": "https://biosrhythm.com/?p=2224",
          "publishedOn": "2022-12-19T17:10:59.000Z",
          "wordCount": 1568,
          "title": "Commodore PET 2001 repair",
          "imageUrl": null
        },
        {
          "id": "https://www.tomscott.com/corrections/firemarks/",
          "author": null,
          "description": "Comments",
          "link": "https://www.tomscott.com/corrections/firemarks/",
          "publishedOn": "2022-12-19T16:09:33.000Z",
          "wordCount": 6267,
          "title": "Did insurance fire brigades let uninsured buildings burn?",
          "imageUrl": null
        },
        {
          "id": "https://yogthos.net/posts/2022-12-18-StructuringClojureApplications.html",
          "author": null,
          "description": "Comments",
          "link": "https://yogthos.net/posts/2022-12-18-StructuringClojureApplications.html",
          "publishedOn": "2022-12-19T14:16:51.000Z",
          "wordCount": 1714,
          "title": "Structuring Clojure applications",
          "imageUrl": null
        },
        {
          "id": "https://www.australiangeographic.com.au/news/2022/12/discovery-identifies-australia-as-birthplace-of-all-modern-mammals/",
          "author": null,
          "description": "Comments",
          "link": "https://www.australiangeographic.com.au/news/2022/12/discovery-identifies-australia-as-birthplace-of-all-modern-mammals/",
          "publishedOn": "2022-12-19T13:39:34.000Z",
          "wordCount": 2927,
          "title": "Evidence that the evolution of mammals began in the Southern Hemisphere",
          "imageUrl": "https://www.australiangeographic.com.au/wp-content/uploads/2022/12/thumbnail_image001-1.jpg"
        },
        {
          "id": "https://github.com/open-pdf-sign/open-pdf-sign",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/open-pdf-sign/open-pdf-sign",
          "publishedOn": "2022-12-19T13:15:40.000Z",
          "wordCount": 1138,
          "title": "Digitally sign PDF files from your commandline – open-pdf-sign",
          "imageUrl": "https://opengraph.githubassets.com/d8c566214a21fe84ef60ad9f2c7c171f3dd318fcfcafa95171a0a7ee7b27d3cc/open-pdf-sign/open-pdf-sign"
        },
        {
          "id": "https://www.cnbc.com/2022/12/19/dont-want-to-travel-many-in-japan-say-theyll-never-travel-again.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.cnbc.com/2022/12/19/dont-want-to-travel-many-in-japan-say-theyll-never-travel-again.html",
          "publishedOn": "2022-12-19T00:58:22.000Z",
          "wordCount": 22154,
          "title": "35% of Japanese people say they’ll ‘never travel’ again",
          "imageUrl": "https://image.cnbcfm.com/api/v1/image/107166649-1671083587492-gettyimages-1220908117-2404familyeps.jpeg?v=1671404521&w=1920&h=1080"
        },
        {
          "id": "https://github.com/numpy/numpy/releases/tag/v1.24.0",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/numpy/numpy/releases/tag/v1.24.0",
          "publishedOn": "2022-12-19T00:31:09.000Z",
          "wordCount": 2757,
          "title": "NumPy 1.24 Release Notes",
          "imageUrl": "https://opengraph.githubassets.com/629abf17c6c3c961d791b127e7342580c2ce285ac2c5bf5dfcafb17181f18077/numpy/numpy/releases/tag/v1.24.0"
        },
        {
          "id": "https://www.nytimes.com/2022/12/16/us/marion-smith-dead.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/16/us/marion-smith-dead.html",
          "publishedOn": "2022-12-18T23:32:53.000Z",
          "wordCount": null,
          "title": "Marion Smith, the world’s most prolific cave explorer, dies at 80",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/elonmusk/status/1604617643973124097",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/elonmusk/status/1604617643973124097",
          "publishedOn": "2022-12-18T23:21:52.000Z",
          "wordCount": 470,
          "title": "Should I step down as head of Twitter? I will abide by the results of this poll",
          "imageUrl": null
        },
        {
          "id": "https://www.nytimes.com/2022/12/18/business/media/amc-networks-streaming-cable.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/18/business/media/amc-networks-streaming-cable.html",
          "publishedOn": "2022-12-18T22:46:07.000Z",
          "wordCount": null,
          "title": "What AMC’s streaming troubles say about the greater TV industry",
          "imageUrl": null
        },
        {
          "id": "https://www.uber.com/blog/devpod-improving-developer-productivity-at-uber/",
          "author": null,
          "description": "Comments",
          "link": "https://www.uber.com/blog/devpod-improving-developer-productivity-at-uber/",
          "publishedOn": "2022-12-18T22:44:26.000Z",
          "wordCount": 4051,
          "title": "Devpod: Remote development environment at Uber",
          "imageUrl": "https://blogapi.uber.com/wp-content/uploads/2022/12/My-project-1.png"
        },
        {
          "id": "https://twitter.com/paulg/",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/paulg/",
          "publishedOn": "2022-12-18T22:01:58.000Z",
          "wordCount": 470,
          "title": "Twitter suspends pg's account [fixed]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/electronicarts/EAStdC/blob/master/include/EAStdC/EABitTricks.h",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/electronicarts/EAStdC/blob/master/include/EAStdC/EABitTricks.h",
          "publishedOn": "2022-12-18T21:01:53.000Z",
          "wordCount": 8141,
          "title": "EABitTricks.h",
          "imageUrl": "https://opengraph.githubassets.com/3ddb3f8c0a914b02747903ca596eb8a67e3f59545456691120e9f78423d8c90c/electronicarts/EAStdC"
        },
        {
          "id": "https://www.atlasobscura.com/articles/perpetual-broth",
          "author": null,
          "description": "Comments",
          "link": "https://www.atlasobscura.com/articles/perpetual-broth",
          "publishedOn": "2022-12-18T20:47:15.000Z",
          "wordCount": 6587,
          "title": "‘Perpetual broths’ that simmer for decades",
          "imageUrl": "https://img.atlasobscura.com/VK5gLZf7_G890o26kDAi0IfsF8mXcY0qXyUOUZM9wvA/rt:fit/w:600/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy8zMjg4NDcyMy0y/YTE0LTRmMDItODhl/MS1jNGI0ZWU5MmVi/YjMwYWNjYTNiZTJl/NWRhYjgwZjZfYnJv/dGguanBn.jpg"
        },
        {
          "id": "https://news.bloombergtax.com/daily-tax-report/irs-accidentally-releases-112-000-taxpayers-private-data-again",
          "author": null,
          "description": "Comments",
          "link": "https://news.bloombergtax.com/daily-tax-report/irs-accidentally-releases-112-000-taxpayers-private-data-again",
          "publishedOn": "2022-12-18T20:45:57.000Z",
          "wordCount": 10665,
          "title": "IRS accidentally releases taxpayers’ private data again",
          "imageUrl": "https://db0ip7zd23b50.cloudfront.net/dims4/default/8a0cc58/2147483647/legacy_thumbnail/960x369%3E/quality/90/?url=http%3A%2F%2Fbloomberg-bna-brightspot.s3.amazonaws.com%2F6a%2Fdf%2Ff833e8244c958961a11fd6edb99a%2Fbli-irs-abstract-form.png"
        },
        {
          "id": "http://oldvcr.blogspot.com/2022/12/a-minor-memorial-for-leo-laporte-on.html",
          "author": null,
          "description": "Comments",
          "link": "http://oldvcr.blogspot.com/2022/12/a-minor-memorial-for-leo-laporte-on.html",
          "publishedOn": "2022-12-18T20:34:51.000Z",
          "wordCount": 3894,
          "title": "A minor memorial for Leo Laporte on terrestrial AM radio",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXgLPH-lXdjevTnmXNk7P2QQTytZ-4hjgE2BR7lFmxoiXGItZRJgkj9o29JdN7DEGqb7gEgFQuPEGT332sSxDRTif_Wbhjw88K33FPSnag8dxdEgI1-v27yEr3qHemR5HXIPRt6H8QyoKvBnCNISJT0lZE_MME1LdOBUxmbm-NzNO9vxSqIkdIU9sj/w1200-h630-p-k-no-nu/IMG_20110430_100602.jpg"
        },
        {
          "id": "https://github.com/Lartsch/FediAct",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Lartsch/FediAct",
          "publishedOn": "2022-12-18T20:19:20.000Z",
          "wordCount": 1792,
          "title": "Browser extension that lets you follow accounts on foreign Mastodon instances",
          "imageUrl": "https://opengraph.githubassets.com/2bfaca638e36d9a98e9fe1db7bfc136975e32ce30fa4c3f902132aeee1f4cebf/Lartsch/FediAct"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34041962",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34041962",
          "publishedOn": "2022-12-18T19:38:56.000Z",
          "wordCount": 19917,
          "title": "Ask HN: Anyone tired of everything being a subscription now?",
          "imageUrl": null
        },
        {
          "id": "https://dan.bulwinkle.net/blog/government-should-incentivize-green-builders/",
          "author": null,
          "description": "Comments",
          "link": "https://dan.bulwinkle.net/blog/government-should-incentivize-green-builders/",
          "publishedOn": "2022-12-18T19:34:22.000Z",
          "wordCount": 1010,
          "title": "Government should incentivize high performance home builders",
          "imageUrl": null
        },
        {
          "id": "https://www.hillelwayne.com/post/influential-dead-languages/",
          "author": null,
          "description": "Comments",
          "link": "https://www.hillelwayne.com/post/influential-dead-languages/",
          "publishedOn": "2022-12-18T18:04:52.000Z",
          "wordCount": 3727,
          "title": "Ten influential programming languages (2020)",
          "imageUrl": null
        },
        {
          "id": "https://www.theregister.com/2022/12/16/apple_decoy_labor_group/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theregister.com/2022/12/16/apple_decoy_labor_group/",
          "publishedOn": "2022-12-18T18:02:54.000Z",
          "wordCount": 1436,
          "title": "Apple 'created decoy labor group' to derail unionization",
          "imageUrl": "https://regmedia.co.uk/2022/12/16/shutterstock_apple_store.jpg"
        },
        {
          "id": "https://jobs.ashbyhq.com/motion?utm_source=hn",
          "author": null,
          "description": "Comments",
          "link": "https://jobs.ashbyhq.com/motion?utm_source=hn",
          "publishedOn": "2022-12-18T17:03:12.000Z",
          "wordCount": 293,
          "title": "Motion (YC W20) Is Hiring Senior Fullstack Engineers",
          "imageUrl": "https://app.ashbyhq.com/api/images/org-theme-social/fd4042c5-a696-4b26-9058-2ac8131c2d75/fab07bab-a363-44f7-8435-32f76868d3d3.png"
        },
        {
          "id": "https://youtubetranscript.com/",
          "author": null,
          "description": "Comments",
          "link": "https://youtubetranscript.com/",
          "publishedOn": "2022-12-18T16:38:03.000Z",
          "wordCount": 1489,
          "title": "YouTube Transcript – read YouTube videos",
          "imageUrl": null
        },
        {
          "id": "https://www.vulture.com/article/hbo-max-warner-cancelations-disappearing-tv-streaming-future.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.vulture.com/article/hbo-max-warner-cancelations-disappearing-tv-streaming-future.html",
          "publishedOn": "2022-12-18T16:31:33.000Z",
          "wordCount": 28654,
          "title": "TV disappears, but HBO Max removing shows feels different",
          "imageUrl": "https://pyxis.nymag.com/v1/imgs/fac/c79/12120b9eece74f545a774051fd71075f0b-erased.1x.rsocial.w1200.jpg"
        },
        {
          "id": "https://curiositysink.substack.com/p/everything-as-a-service",
          "author": null,
          "description": "Comments",
          "link": "https://curiositysink.substack.com/p/everything-as-a-service",
          "publishedOn": "2022-12-18T16:10:44.000Z",
          "wordCount": 6153,
          "title": "Everything as a Service",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4a032bf0-f180-4cdd-a021-6439f1c6a932_1224x916.png"
        },
        {
          "id": "https://www.retrotechnology.com/dri/howto_cpm.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.retrotechnology.com/dri/howto_cpm.html",
          "publishedOn": "2022-12-18T16:08:44.000Z",
          "wordCount": 7794,
          "title": "How to Start with CP/M",
          "imageUrl": null
        },
        {
          "id": "https://www.youtube.com/watch?v=386p68_lDHA",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=386p68_lDHA",
          "publishedOn": "2022-12-18T16:05:20.000Z",
          "wordCount": null,
          "title": "Investigating Logan Paul's biggest scam [video]",
          "imageUrl": null
        },
        {
          "id": "https://cassandradispatch.org/richard-feynman-on-looking-at-the-world-from-another-point-of-view/",
          "author": null,
          "description": "Comments",
          "link": "https://cassandradispatch.org/richard-feynman-on-looking-at-the-world-from-another-point-of-view/",
          "publishedOn": "2022-12-18T15:51:45.000Z",
          "wordCount": 261,
          "title": "Richard Feynman on looking at the world from another point of view (1973)",
          "imageUrl": null
        },
        {
          "id": "https://fivethirtyeight.com/features/lionel-messi-is-impossible/",
          "author": null,
          "description": "Comments",
          "link": "https://fivethirtyeight.com/features/lionel-messi-is-impossible/",
          "publishedOn": "2022-12-18T15:07:43.000Z",
          "wordCount": 5713,
          "title": "Lionel Messi Is Impossible (2014)",
          "imageUrl": "https://fivethirtyeight.com/wp-content/uploads/2014/06/messi_lede.jpg?w=596"
        },
        {
          "id": "https://www.youtube.com/watch?v=iKmXQAupWzM",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=iKmXQAupWzM",
          "publishedOn": "2022-12-18T14:55:33.000Z",
          "wordCount": null,
          "title": "Zilog Z8000 Coprocessor for the IBM PC by Sweet Micro Systems [video]",
          "imageUrl": null
        },
        {
          "id": "https://slate.com/news-and-politics/2000/06/the-unluckiest-man-in-movie-history.html",
          "author": null,
          "description": "Comments",
          "link": "https://slate.com/news-and-politics/2000/06/the-unluckiest-man-in-movie-history.html",
          "publishedOn": "2022-12-18T08:51:38.000Z",
          "wordCount": 20439,
          "title": "The Unluckiest Man in Movie History (2000)",
          "imageUrl": "https://slate.com/media/sites/slate-com/icon.400x400.png"
        },
        {
          "id": "https://queue.acm.org/detail.cfm?id=3570937",
          "author": null,
          "description": "Comments",
          "link": "https://queue.acm.org/detail.cfm?id=3570937",
          "publishedOn": "2022-12-18T07:45:04.000Z",
          "wordCount": 5755,
          "title": "Reinventing backend subsetting at Google",
          "imageUrl": null
        },
        {
          "id": "https://devblogs.microsoft.com/oldnewthing/20221216-00/?p=107598",
          "author": null,
          "description": "Comments",
          "link": "https://devblogs.microsoft.com/oldnewthing/20221216-00/?p=107598",
          "publishedOn": "2022-12-18T06:28:16.000Z",
          "wordCount": 5574,
          "title": "Why doesn’t Windows use 64-bit virtual address space below 0x00000000`7ffe0000?",
          "imageUrl": "https://devblogs.microsoft.com/oldnewthing/wp-content/uploads/sites/38/2019/02/ShowCover.jpg"
        },
        {
          "id": "https://bolinlang.com/does-it-inline",
          "author": null,
          "description": "Comments",
          "link": "https://bolinlang.com/does-it-inline",
          "publishedOn": "2022-12-17T23:56:51.000Z",
          "wordCount": 980,
          "title": "Does It Inline?",
          "imageUrl": null
        },
        {
          "id": "https://www.nature.com/immersive/d41586-022-03810-5/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/immersive/d41586-022-03810-5/index.html",
          "publishedOn": "2022-12-17T23:33:43.000Z",
          "wordCount": 17704,
          "title": "The human cost of neurotechnology failure",
          "imageUrl": "https://www.nature.com/immersive/d41586-022-03810-5/assets/uTphz5EWeS/2022-12-06_outlook_neurotech_1_bohle-lede_sm-1066x600.jpg"
        },
        {
          "id": "https://www.pointsdevue.com/article/record-high-myopia-solved-alliance-experts-10800-d",
          "author": null,
          "description": "Comments",
          "link": "https://www.pointsdevue.com/article/record-high-myopia-solved-alliance-experts-10800-d",
          "publishedOn": "2022-12-17T23:13:10.000Z",
          "wordCount": 3177,
          "title": "The record-breaking -108.00 diopter myopia lenses (2016)",
          "imageUrl": "https://www.pointsdevue.com/sites/default/files/content-images/article/201606/fig7-lens-mounting-copie.jpg"
        },
        {
          "id": "https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html",
          "author": null,
          "description": "Comments",
          "link": "https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html",
          "publishedOn": "2022-12-17T22:18:36.000Z",
          "wordCount": 2852,
          "title": "Copilot Internals",
          "imageUrl": null
        },
        {
          "id": "https://spectrum.ieee.org/the-golden-age-of-basic",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/the-golden-age-of-basic",
          "publishedOn": "2022-12-17T22:17:26.000Z",
          "wordCount": 13452,
          "title": "The Golden Age of Basic (2014)",
          "imageUrl": "https://spectrum.ieee.org/media-library/kids-try-out-a-commodore-64-in-nuremberg-in-may-1985.jpg?id=25575163&width=1200&height=600&coordinates=0%2C77%2C0%2C78"
        },
        {
          "id": "https://www.youtube.com/watch?v=oeqPrUmVz-o",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=oeqPrUmVz-o",
          "publishedOn": "2022-12-17T21:58:47.000Z",
          "wordCount": null,
          "title": "Steve Jobs Insult Response (1997) [video]",
          "imageUrl": null
        },
        {
          "id": "https://www.useragents.me/",
          "author": null,
          "description": "Comments",
          "link": "https://www.useragents.me/",
          "publishedOn": "2022-12-17T21:50:08.000Z",
          "wordCount": 2673,
          "title": "A self-updating list of the most current useragents",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34032484",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34032484",
          "publishedOn": "2022-12-17T21:35:21.000Z",
          "wordCount": 5299,
          "title": "Tell HN: Google is correlating location data to your IP",
          "imageUrl": null
        },
        {
          "id": "https://worthdoingbadly.com/macdirtycow/",
          "author": null,
          "description": "Comments",
          "link": "https://worthdoingbadly.com/macdirtycow/",
          "publishedOn": "2022-12-17T21:25:35.000Z",
          "wordCount": 813,
          "title": "Get root on macOS 13.0.1 the macOS Dirty Cow bug",
          "imageUrl": null
        },
        {
          "id": "https://www.netwatchglobal.com/solutions/capture-the-flag-using-osint-techniques/",
          "author": null,
          "description": "Comments",
          "link": "https://www.netwatchglobal.com/solutions/capture-the-flag-using-osint-techniques/",
          "publishedOn": "2022-12-17T20:30:32.000Z",
          "wordCount": 482,
          "title": "Capture the flag using OSINT techniques (2019)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/BishopFox/unredacter",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/BishopFox/unredacter",
          "publishedOn": "2022-12-17T19:58:37.000Z",
          "wordCount": 901,
          "title": "Unredacter: Never use pixelation as a redaction technique",
          "imageUrl": "https://opengraph.githubassets.com/2adb8262fbd999e907ed45eb3ebbac3d5dce3a6a89a0257e024e53baa35d79be/BishopFox/unredacter"
        },
        {
          "id": "https://twitter.com/robinberjon/status/1603834995830816769",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/robinberjon/status/1603834995830816769",
          "publishedOn": "2022-12-17T19:33:17.000Z",
          "wordCount": 470,
          "title": "W3C’s transfer from MIT to non-profit going poorly",
          "imageUrl": null
        },
        {
          "id": "https://spritely.institute/news/growing-a-networked-garden-with-spritely-goblins.html",
          "author": null,
          "description": "Comments",
          "link": "https://spritely.institute/news/growing-a-networked-garden-with-spritely-goblins.html",
          "publishedOn": "2022-12-17T19:17:39.000Z",
          "wordCount": 1887,
          "title": "Growing a Networked Garden with Spritely Goblins",
          "imageUrl": "https://spritely.institute/static/images/spritely-institute-logo-300px.png"
        },
        {
          "id": "https://huberman.rile.yt/",
          "author": null,
          "description": "Comments",
          "link": "https://huberman.rile.yt/",
          "publishedOn": "2022-12-17T18:05:04.000Z",
          "wordCount": 144,
          "title": "Show HN: Factual AI Q&A – Answers based on Huberman Lab transcripts",
          "imageUrl": "https://huberman.rile.yt/img/og.png"
        },
        {
          "id": "https://www.theverge.com/2022/11/21/23471306/apple-books-ios-16-page-flip-animation-sucks",
          "author": null,
          "description": "Comments",
          "link": "https://www.theverge.com/2022/11/21/23471306/apple-books-ios-16-page-flip-animation-sucks",
          "publishedOn": "2022-12-17T17:25:16.000Z",
          "wordCount": 8883,
          "title": "Apple changed how reading books works in iOS 16",
          "imageUrl": "https://cdn.vox-cdn.com/thumbor/s1cejsajVEIJSFOH6DjdVSw9KtU=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24020007/226270_iPHONE_14_PHO_akrales_0030.jpg"
        },
        {
          "id": "https://www.archdaily.com/956906/corviale-a-one-kilometer-residential-complex-in-rome",
          "author": null,
          "description": "Comments",
          "link": "https://www.archdaily.com/956906/corviale-a-one-kilometer-residential-complex-in-rome",
          "publishedOn": "2022-12-17T17:15:44.000Z",
          "wordCount": 10975,
          "title": "Corviale, a one-kilometer residential complex in Rome",
          "imageUrl": "https://images.adsttc.com/media/images/601a/9e9e/f91c/8198/f400/030a/large_jpg/40544632165_391d7a9ac4_o.jpg?1612357266"
        },
        {
          "id": "https://www.bigmessowires.com/2022/12/16/avr-gcc-compiler-makes-questionable-code/",
          "author": null,
          "description": "Comments",
          "link": "https://www.bigmessowires.com/2022/12/16/avr-gcc-compiler-makes-questionable-code/",
          "publishedOn": "2022-12-17T17:12:02.000Z",
          "wordCount": 2948,
          "title": "AVR-GCC Compiler Makes Questionable Code",
          "imageUrl": null
        },
        {
          "id": "https://tweedegolf.nl/en/blog/79/sorting-with-simd",
          "author": null,
          "description": "Comments",
          "link": "https://tweedegolf.nl/en/blog/79/sorting-with-simd",
          "publishedOn": "2022-12-17T16:59:07.000Z",
          "wordCount": 8446,
          "title": "Sorting with SIMD",
          "imageUrl": "https://tweedegolf.nl/images/sortingwithsimd3.png"
        },
        {
          "id": "https://github.com/willmcgugan/textual-markdown",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/willmcgugan/textual-markdown",
          "publishedOn": "2022-12-17T15:50:20.000Z",
          "wordCount": 768,
          "title": "Show HN: Textual Markdown – a Markdown “browser” in the terminal",
          "imageUrl": "https://opengraph.githubassets.com/43cd77ad33d495416f7b2894b6e986c31403c9098e80a3fcbbcdfe8e6cc97ecb/willmcgugan/textual-markdown"
        },
        {
          "id": "https://github.com/ax/apk.sh",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/ax/apk.sh",
          "publishedOn": "2022-12-17T15:38:19.000Z",
          "wordCount": 1121,
          "title": "Apk.sh is a Bash script that makes reverse engineering Android apps easier",
          "imageUrl": "https://opengraph.githubassets.com/95854ef892a1abe041d3cacdf518a36d251cd6a2b0b2e53cac0cdb71fd85e1a2/ax/apk.sh"
        },
        {
          "id": "https://www.tfeb.org/fragments/2022/12/16/the-empty-list/",
          "author": null,
          "description": "Comments",
          "link": "https://www.tfeb.org/fragments/2022/12/16/the-empty-list/",
          "publishedOn": "2022-12-17T15:05:28.000Z",
          "wordCount": 892,
          "title": "The empty list",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/tessalau/status/1604018884662951938",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/tessalau/status/1604018884662951938",
          "publishedOn": "2022-12-17T14:28:10.000Z",
          "wordCount": 470,
          "title": "As winter approaches, here's a story about why hardware is hard",
          "imageUrl": null
        },
        {
          "id": "https://www.economist.com/britain/2022/12/12/the-strange-case-of-britains-demise",
          "author": null,
          "description": "Comments",
          "link": "https://www.economist.com/britain/2022/12/12/the-strange-case-of-britains-demise",
          "publishedOn": "2022-12-17T14:17:58.000Z",
          "wordCount": 22137,
          "title": "The strange case of Britain’s demise",
          "imageUrl": "https://www.economist.com/img/b/1280/720/90/media-assets/image/20221217_BRD001.jpg"
        },
        {
          "id": "https://ittavern.com/getting-started-with-nmap/",
          "author": null,
          "description": "Comments",
          "link": "https://ittavern.com/getting-started-with-nmap/",
          "publishedOn": "2022-12-17T10:15:29.000Z",
          "wordCount": 1714,
          "title": "Getting started with nmap",
          "imageUrl": "https://ittavern.com/images/previewimages/nmap.png"
        },
        {
          "id": "https://hackaday.com/2022/12/16/foot-pedal-ups-vim-productivity-brings-ergonomic-benefits/",
          "author": null,
          "description": "Comments",
          "link": "https://hackaday.com/2022/12/16/foot-pedal-ups-vim-productivity-brings-ergonomic-benefits/",
          "publishedOn": "2022-12-17T08:25:08.000Z",
          "wordCount": 4520,
          "title": "Vim Foot Pedal",
          "imageUrl": "https://hackaday.com/wp-content/uploads/2022/12/finished-outside-e1670992799294.jpeg"
        },
        {
          "id": "https://oldvcr.blogspot.com/2022/12/the-strange-case-of-beos-srs-and-silent.html",
          "author": null,
          "description": "Comments",
          "link": "https://oldvcr.blogspot.com/2022/12/the-strange-case-of-beos-srs-and-silent.html",
          "publishedOn": "2022-12-17T04:41:40.000Z",
          "wordCount": 6740,
          "title": "The strange case of BeOS, SRS and the silent Power Mac 6500",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwHBMB16mdbIEk3ztO_P7egsVoTZ8mEBmK7J3NHhGVokIlK6q1C2xhrV_E2XB_wzY2JCXE7eXom6nk-oqEmXbKakh82xQ1jli4gXZ8GX7RjXH_iVemeKNs1C08ujftw55r1kcUz_4SVizTAtMYOVNaBh4uloClrUPPsNjNI5xE2HGoSEWMWHGYTek2/w1200-h630-p-k-no-nu/IMG_20221210_131321.jpg"
        },
        {
          "id": "https://www.newyorker.com/books/under-review/the-man-who-mastered-minor-writing",
          "author": null,
          "description": "Comments",
          "link": "https://www.newyorker.com/books/under-review/the-man-who-mastered-minor-writing",
          "publishedOn": "2022-12-17T03:18:37.000Z",
          "wordCount": 37337,
          "title": "Evan S. Connell mastered minor writing",
          "imageUrl": "https://media.newyorker.com/photos/63974a33c15e2521bb42b8c1/16:9/w_1280,c_limit/Norman_final.jpeg"
        },
        {
          "id": "https://www.circuitvalley.com/2022/06/pensource-usb-c-industrial-camera-c-mount-fpga-imx-mipi-usb-3-crosslinknx.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.circuitvalley.com/2022/06/pensource-usb-c-industrial-camera-c-mount-fpga-imx-mipi-usb-3-crosslinknx.html",
          "publishedOn": "2022-12-17T00:44:00.000Z",
          "wordCount": 9399,
          "title": "Open source USB C camera with C mount lens, MIPI Sensor, Lattice FPGA, USB 3.0",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEineztmEmFegMzFaCr1kmNTqpchNTbrV33iBmQpCceFYxqTpvLPidS6LwYimjdjWfg6ceKlAuNYfntEAkg8j_eB8Th3NTxK_OSKwJvyfmNBU01pzxuJ2HVqMqrk7hXKlHb-7HuoyImV4HrGPNdtk6m6E9Xxt_LXmgnudy48eZPGi56LiLqx_H0bnFxkew/w1200-h630-p-k-no-nu/usb_c_fpga_mipi_camera_c_mount_industrial_lattice_crosslink_fpga_xilinx_zynq%20(4)2.JPG"
        },
        {
          "id": "https://www.facebook.com/100006735798590/posts/i-resigned-from-my-position-as-an-executive-consultant-for-vr-with-meta-my-inter/3467566940144465/",
          "author": null,
          "description": "Comments",
          "link": "https://www.facebook.com/100006735798590/posts/i-resigned-from-my-position-as-an-executive-consultant-for-vr-with-meta-my-inter/3467566940144465/",
          "publishedOn": "2022-12-17T00:10:36.000Z",
          "wordCount": 154,
          "title": "John Carmack Leaves Meta",
          "imageUrl": null
        },
        {
          "id": "https://www.businessinsider.com/john-carmack-meta-consulting-cto-virtual-reality-leaving-2022-12",
          "author": null,
          "description": "Comments",
          "link": "https://www.businessinsider.com/john-carmack-meta-consulting-cto-virtual-reality-leaving-2022-12",
          "publishedOn": "2022-12-17T00:10:36.000Z",
          "wordCount": 3652,
          "title": "John Carmack Leaves Meta",
          "imageUrl": "https://i.insider.com/639cf7e6b5600000185b2e51?width=1200&format=jpeg"
        },
        {
          "id": "https://www.sciencedirect.com/science/article/pii/S0149763422003839",
          "author": null,
          "description": "Comments",
          "link": "https://www.sciencedirect.com/science/article/pii/S0149763422003839",
          "publishedOn": "2022-12-16T23:00:15.000Z",
          "wordCount": 7688,
          "title": "Schizophrenia: The new etiological synthesis",
          "imageUrl": "https://ars.els-cdn.com/content/image/1-s2.0-S0149763422003839-ga1.jpg"
        },
        {
          "id": "https://www.humanesociety.org/news/congress-passes-legislation-end-us-participation-global-shark-fin-trade",
          "author": null,
          "description": "Comments",
          "link": "https://www.humanesociety.org/news/congress-passes-legislation-end-us-participation-global-shark-fin-trade",
          "publishedOn": "2022-12-16T22:25:10.000Z",
          "wordCount": 2027,
          "title": "Congress passes legislation to end US participation in global shark fin trade",
          "imageUrl": "https://www.humanesociety.org/sites/default/files/2018/11/HSUS-logo-share-image.jpg"
        },
        {
          "id": "https://www.monkeon.co.uk/90s-web-humor-button/",
          "author": null,
          "description": "Comments",
          "link": "https://www.monkeon.co.uk/90s-web-humor-button/",
          "publishedOn": "2022-12-16T22:16:38.000Z",
          "wordCount": 839,
          "title": "90s Web \"Humor\" Button",
          "imageUrl": "https://www.monkeon.co.uk/90s-web-humor-button/fb.jpg"
        },
        {
          "id": "https://www.nytimes.com/2022/12/14/arts/thomas-pynchon-huntington-archive.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/14/arts/thomas-pynchon-huntington-archive.html",
          "publishedOn": "2022-12-16T22:15:05.000Z",
          "wordCount": null,
          "title": "Thomas Pynchon, famously private, sells his archive",
          "imageUrl": null
        },
        {
          "id": "https://www.latimes.com/environment/story/2022-12-16/risk-of-dead-pool-looms-at-colorado-river-meeting",
          "author": null,
          "description": "Comments",
          "link": "https://www.latimes.com/environment/story/2022-12-16/risk-of-dead-pool-looms-at-colorado-river-meeting",
          "publishedOn": "2022-12-16T22:13:55.000Z",
          "wordCount": 6281,
          "title": "Fears of ‘dead pool’ on Colorado River as drought threatens Hoover Dam water",
          "imageUrl": "https://ca-times.brightspotcdn.com/dims4/default/8a23f3c/2147483647/strip/true/crop/5472x2873+0+388/resize/1200x630!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Feb%2F1b%2F077149ae4618abfed8c14ac3bfa6%2F1171603-la-na-vegas-drought-lake-mead-28-gmf.jpg"
        },
        {
          "id": "https://hashman.ca/tunnels/",
          "author": null,
          "description": "Comments",
          "link": "https://hashman.ca/tunnels/",
          "publishedOn": "2022-12-16T21:58:38.000Z",
          "wordCount": 161,
          "title": "UWaterloo Steam Tunnels (2016)",
          "imageUrl": "https://hashman.ca/images/tunnels/tunnels_00.jpg"
        },
        {
          "id": "https://github.com/WordPress/performance/pull/547",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/WordPress/performance/pull/547",
          "publishedOn": "2022-12-16T21:36:45.000Z",
          "wordCount": 3676,
          "title": "WordPress testing official SQLite Support",
          "imageUrl": "https://opengraph.githubassets.com/c33f11d7743ecc499235183e20fc3aa4c36ea2c679bf14307c3054c0b2cd8b3f/WordPress/performance/pull/547"
        },
        {
          "id": "https://death.andgravity.com/pwned",
          "author": null,
          "description": "Comments",
          "link": "https://death.andgravity.com/pwned",
          "publishedOn": "2022-12-16T20:42:40.000Z",
          "wordCount": 4579,
          "title": "I almost failed to search a 37 GB text file in under 1 millisecond",
          "imageUrl": null
        },
        {
          "id": "https://github.com/norvig/pytudes/blob/main/ipynb/AlphaCode.ipynb",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/norvig/pytudes/blob/main/ipynb/AlphaCode.ipynb",
          "publishedOn": "2022-12-16T20:38:57.000Z",
          "wordCount": 411,
          "title": "Peter Norvig critically reviews AlphaCode's code quality",
          "imageUrl": "https://opengraph.githubassets.com/d1373329877b78ac968c856e72bb3cd80df80b0b02c724c81f7faabf66aca225/norvig/pytudes"
        },
        {
          "id": "https://legacyupdate.net/",
          "author": null,
          "description": "Comments",
          "link": "https://legacyupdate.net/",
          "publishedOn": "2022-12-16T20:30:42.000Z",
          "wordCount": 690,
          "title": "Legacy Update: Fix Windows Update on Windows XP, Vista, Server 2008, 2003, 2000",
          "imageUrl": "https://legacyupdate.net/banner.png"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34019486",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34019486",
          "publishedOn": "2022-12-16T20:01:08.000Z",
          "wordCount": 11768,
          "title": "Ask HN: How do you protect your children from internet addiction?",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=34017934",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34017934",
          "publishedOn": "2022-12-16T18:07:26.000Z",
          "wordCount": 4128,
          "title": "Ask HN: Anyone using proprietary Unix at work?",
          "imageUrl": null
        },
        {
          "id": "https://retractionwatch.com/2022/12/12/mathematician-withdraws-preprint-24-years-after-initial-submission/",
          "author": null,
          "description": "Comments",
          "link": "https://retractionwatch.com/2022/12/12/mathematician-withdraws-preprint-24-years-after-initial-submission/",
          "publishedOn": "2022-12-16T17:23:42.000Z",
          "wordCount": 2731,
          "title": "Mathematician withdraws preprint 24 years after initial submission",
          "imageUrl": "https://retractionwatch.com/wp-content/uploads/2022/12/arxiv-logo-1-1024x461-1.png"
        },
        {
          "id": "https://www.ycombinator.com/companies/emerge-tools/jobs/5Y3MCJi-senior-mobile-engineer-remote",
          "author": null,
          "description": "Comments",
          "link": "https://www.ycombinator.com/companies/emerge-tools/jobs/5Y3MCJi-senior-mobile-engineer-remote",
          "publishedOn": "2022-12-16T17:00:44.000Z",
          "wordCount": 2841,
          "title": "Emerge (YC W21) is hiring engineers to build the future of mobile development",
          "imageUrl": "https://bookface-images.s3.amazonaws.com/logos/951c5580d5432093d2a1f23a2ba9c548dceb5fe1.png?1633041436"
        },
        {
          "id": "https://github.com/google/osv-scanner",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/google/osv-scanner",
          "publishedOn": "2022-12-16T16:10:24.000Z",
          "wordCount": 1646,
          "title": "Vulnerability scanner written in Go that uses osv.dev data",
          "imageUrl": "https://opengraph.githubassets.com/bc85806b365e0e4ae5e5661926ccbad0d1e4933414e79dab9c4ac0bdcf6f8dc8/google/osv-scanner"
        },
        {
          "id": "https://github.com/google/forma",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/google/forma",
          "publishedOn": "2022-12-16T15:53:49.000Z",
          "wordCount": 1132,
          "title": "Show HN: Forma – An efficient vector-graphics renderer",
          "imageUrl": "https://opengraph.githubassets.com/ec18447e929ea1a88d712c19c3faf78f90563ff1978ca665ff6e764aa5b27bcd/google/forma"
        },
        {
          "id": "https://pv-magazine-usa.com/2022/12/15/california-pulls-the-plug-on-rooftop-solar/",
          "author": null,
          "description": "Comments",
          "link": "https://pv-magazine-usa.com/2022/12/15/california-pulls-the-plug-on-rooftop-solar/",
          "publishedOn": "2022-12-16T15:18:56.000Z",
          "wordCount": 5576,
          "title": "California pulls the plug on rooftop solar",
          "imageUrl": "https://pv-magazine-usa.com/wp-content/uploads/sites/2/2022/01/Solar_installation_technician_on_rooftop_5392894792-1200x675.jpg"
        },
        {
          "id": "https://jackdevanney.substack.com/p/nuclear-power-is-too-slow",
          "author": null,
          "description": "Comments",
          "link": "https://jackdevanney.substack.com/p/nuclear-power-is-too-slow",
          "publishedOn": "2022-12-16T15:07:27.000Z",
          "wordCount": 4047,
          "title": "Nuclear power is too slow",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5e9d80a9-0b15-412d-bed5-d214913a57ac_1000x600.jpeg"
        },
        {
          "id": "https://www.bloomberg.com/news/articles/2022-12-15/focus-on-employees-not-tech-to-build-high-performing-team",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/articles/2022-12-15/focus-on-employees-not-tech-to-build-high-performing-team",
          "publishedOn": "2022-12-16T14:36:00.000Z",
          "wordCount": 576,
          "title": "Humans hold the key to collaboration no matter how good the software tools",
          "imageUrl": null
        },
        {
          "id": "https://arstechnica.com/science/2022/12/scientists-revisit-kepler-findings-learn-two-planets-are-water-worlds/",
          "author": null,
          "description": "Comments",
          "link": "https://arstechnica.com/science/2022/12/scientists-revisit-kepler-findings-learn-two-planets-are-water-worlds/",
          "publishedOn": "2022-12-16T14:30:16.000Z",
          "wordCount": 1685,
          "title": "Scientists may have found the first water worlds",
          "imageUrl": "https://cdn.arstechnica.net/wp-content/uploads/2022/12/STScI-01GGTAPWRG7MWT5D0CZ48FFW3J-760x380.png"
        },
        {
          "id": "https://www.gwern.net/Turing-complete",
          "author": null,
          "description": "Comments",
          "link": "https://www.gwern.net/Turing-complete",
          "publishedOn": "2022-12-16T14:29:31.000Z",
          "wordCount": 16884,
          "title": "Surprisingly Turing-Complete (2021)",
          "imageUrl": "https://www.gwern.net/static/img/logo/logo-whitebg-large-border.png-530px.jpg"
        },
        {
          "id": "https://element.io/blog/bundesmessenger-is-a-milestone-in-germanys-ground-breaking-vision/",
          "author": null,
          "description": "Comments",
          "link": "https://element.io/blog/bundesmessenger-is-a-milestone-in-germanys-ground-breaking-vision/",
          "publishedOn": "2022-12-16T14:01:38.000Z",
          "wordCount": 1834,
          "title": "BundesMessenger, a secure messenger for Germany’s public administration",
          "imageUrl": "https://element.io/blog/content/images/2022/12/BundesMessenger__blog-1.jpg"
        },
        {
          "id": "https://buildwithhubs.co.uk/",
          "author": null,
          "description": "Comments",
          "link": "https://buildwithhubs.co.uk/",
          "publishedOn": "2022-12-16T13:08:39.000Z",
          "wordCount": 248,
          "title": "Geodesic domes made simple",
          "imageUrl": "https://buildwithhubs.co.uk/img/fb/hubs_den.jpg"
        },
        {
          "id": "https://discuss.ocaml.org/t/ocaml-5-0-0-is-out/10974",
          "author": null,
          "description": "Comments",
          "link": "https://discuss.ocaml.org/t/ocaml-5-0-0-is-out/10974",
          "publishedOn": "2022-12-16T12:21:08.000Z",
          "wordCount": 4022,
          "title": "OCaml 5.0 Multicore is out",
          "imageUrl": "https://global.discourse-cdn.com/business7/uploads/ocaml/original/2X/d/d4dc9fe40b17e2bcced034f9fe103917b7999275.svg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=34013643",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=34013643",
          "publishedOn": "2022-12-16T12:04:48.000Z",
          "wordCount": 14415,
          "title": "Ask HN: I have diagnosed ADHD and cannot work with Slack anymore – advice?",
          "imageUrl": null
        },
        {
          "id": "https://fabiensanglard.net/a_linux_evening/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://fabiensanglard.net/a_linux_evening/index.html",
          "publishedOn": "2022-12-16T11:09:24.000Z",
          "wordCount": 1392,
          "title": "A Linux Evening",
          "imageUrl": null
        },
        {
          "id": "https://gmt4.github.io/mpvc/",
          "author": null,
          "description": "Comments",
          "link": "https://gmt4.github.io/mpvc/",
          "publishedOn": "2022-12-16T11:03:17.000Z",
          "wordCount": 998,
          "title": "Show HN: mpvc-tui – A minimal mpc-like CLI and TUI for controlling mpv",
          "imageUrl": "https://github.com/gmt4/mpvc/raw/master/assets/mpvc-tui.png"
        },
        {
          "id": "https://newatlas.com/electronics/water-circuit-switches-thz-faster-semiconductors/",
          "author": null,
          "description": "Comments",
          "link": "https://newatlas.com/electronics/water-circuit-switches-thz-faster-semiconductors/",
          "publishedOn": "2022-12-16T10:56:04.000Z",
          "wordCount": 4740,
          "title": "Water-based circuit concept switches much faster than semiconductors",
          "imageUrl": "https://assets.newatlas.com/dims4/default/bff5caa/2147483647/strip/true/crop/2528x1327+0+179/resize/1200x630!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6b%2F6b%2Fe63c316f4af383e98dcb283b75fb%2Flaser-wasser-adrian-buchmann-beschnitten.jpg&na.image_optimisation=0"
        },
        {
          "id": "https://arstechnica.com/information-technology/2022/12/meet-ghostwriter-a-haunted-ai-powered-typewriter-that-talks-to-you/",
          "author": null,
          "description": "Comments",
          "link": "https://arstechnica.com/information-technology/2022/12/meet-ghostwriter-a-haunted-ai-powered-typewriter-that-talks-to-you/",
          "publishedOn": "2022-12-16T10:54:38.000Z",
          "wordCount": 1720,
          "title": "Ghostwriter, a haunted AI-powered typewriter that talks to you",
          "imageUrl": "https://cdn.arstechnica.net/wp-content/uploads/2022/12/ghostwriter_hero_2-760x380.jpg"
        },
        {
          "id": "https://www.theguardian.com/world/2022/dec/16/huge-cylindrical-aquarium-housing-1500-exotic-fish-bursts-in-berlin",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/world/2022/dec/16/huge-cylindrical-aquarium-housing-1500-exotic-fish-bursts-in-berlin",
          "publishedOn": "2022-12-16T10:43:14.000Z",
          "wordCount": 4898,
          "title": "Cylindrical aquarium housing 1,500 exotic fish bursts in Berlin",
          "imageUrl": "https://i.guim.co.uk/img/media/31cd90d59ab05fbe4adb641d2cceae1b9f1d9ef3/0_208_3500_2100/master/3500.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=7b01d76515731ac381c97cc208cf917e"
        },
        {
          "id": "https://beautiful.software/",
          "author": null,
          "description": "Comments",
          "link": "https://beautiful.software/",
          "publishedOn": "2022-12-16T06:53:20.000Z",
          "wordCount": 1779,
          "title": "Beautiful Software: Christopher Alexander's research initiative on computing",
          "imageUrl": null
        },
        {
          "id": "https://www.printmag.com/advertising/making-the-mac-20-vintage-apple-ads/",
          "author": null,
          "description": "Comments",
          "link": "https://www.printmag.com/advertising/making-the-mac-20-vintage-apple-ads/",
          "publishedOn": "2022-12-16T00:04:53.000Z",
          "wordCount": 2209,
          "title": "Vintage Apple Advertisements",
          "imageUrl": "https://149522020.v2.pressablecdn.com/wp-content/uploads/2020/02/2a34d8_419100b4e44a4b60a3e768e0f4d0f151mv2.jpg"
        },
        {
          "id": "https://github.blog/changelog/2022-12-15-secret-scanning-is-now-available-for-free-on-public-repositories/",
          "author": null,
          "description": "Comments",
          "link": "https://github.blog/changelog/2022-12-15-secret-scanning-is-now-available-for-free-on-public-repositories/",
          "publishedOn": "2022-12-16T00:03:02.000Z",
          "wordCount": 718,
          "title": "Secret scanning is now available for free on public repositories",
          "imageUrl": "https://github.blog/wp-content/uploads/2022/04/Engineering-Security.png?fit=1200%2C630"
        },
        {
          "id": "https://www.atlasobscura.com/articles/what-is-cervois",
          "author": null,
          "description": "Comments",
          "link": "https://www.atlasobscura.com/articles/what-is-cervois",
          "publishedOn": "2022-12-15T23:52:31.000Z",
          "wordCount": 7140,
          "title": "A brewer updating an ancient French beer for modern drinkers",
          "imageUrl": "https://img.atlasobscura.com/7VH2Z4XMcmQc4VzWT2Ei8isEXGkB8n1guP0QZHur62s/rt:fit/w:600/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy9mNjljZWM4Zjhj/MDdiMGM3M2FfSU1H/XzMzODAuSlBH.jpg"
        },
        {
          "id": "https://billwadge.com/2022/12/15/just-how-smart-are-you-chatgpt-i-quiz-chatgpt-about-math/",
          "author": null,
          "description": "Comments",
          "link": "https://billwadge.com/2022/12/15/just-how-smart-are-you-chatgpt-i-quiz-chatgpt-about-math/",
          "publishedOn": "2022-12-15T23:51:59.000Z",
          "wordCount": 4299,
          "title": "I quiz ChatGPT about math",
          "imageUrl": "https://billwadge.files.wordpress.com/2022/12/screenshot-2022-12-16-at-12.41.06-pm.png"
        },
        {
          "id": "https://github.com/IvorySQL/IvorySQL",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/IvorySQL/IvorySQL",
          "publishedOn": "2022-12-15T23:37:42.000Z",
          "wordCount": 1554,
          "title": "IvorySQL: Open-source Oracle-compatible PostgreSQL",
          "imageUrl": "https://repository-images.githubusercontent.com/423810080/a080589b-b9e3-46b4-bb0b-70ba87c815a9"
        },
        {
          "id": "https://webkit.org/blog/13607/help-choose-from-options-for-css-nesting-syntax/",
          "author": null,
          "description": "Comments",
          "link": "https://webkit.org/blog/13607/help-choose-from-options-for-css-nesting-syntax/",
          "publishedOn": "2022-12-15T22:19:18.000Z",
          "wordCount": 2637,
          "title": "Help choose the syntax for CSS Nesting",
          "imageUrl": null
        },
        {
          "id": "https://oschvr.com/posts/what-id-like-as-sre/",
          "author": null,
          "description": "Comments",
          "link": "https://oschvr.com/posts/what-id-like-as-sre/",
          "publishedOn": "2022-12-15T22:04:20.000Z",
          "wordCount": 519,
          "title": "Things I want from Devs as SRE/DevOps",
          "imageUrl": "https://oschvr.s3.us-west-2.amazonaws.com/oldstreet.jpeg"
        },
        {
          "id": "http://incompleteideas.net/IncIdeas/BitterLesson.html",
          "author": null,
          "description": "Comments",
          "link": "http://incompleteideas.net/IncIdeas/BitterLesson.html",
          "publishedOn": "2022-12-15T21:57:34.000Z",
          "wordCount": 1131,
          "title": "The Bitter Lesson (2019)",
          "imageUrl": null
        },
        {
          "id": "https://readwise.io/read",
          "author": null,
          "description": "Comments",
          "link": "https://readwise.io/read",
          "publishedOn": "2022-12-15T21:44:03.000Z",
          "wordCount": 3638,
          "title": "Show HN: Readwise Reader, an all-in-one reading app",
          "imageUrl": "https://readwise-assets.s3.amazonaws.com/static/images/reader/OG-Reader.9fe9ca92418f.jpg"
        },
        {
          "id": "https://groups.google.com/g/net.lang.lisp/c/P7W_1ISJ-sU/m/GAo6w-0B7oQJ",
          "author": null,
          "description": "Comments",
          "link": "https://groups.google.com/g/net.lang.lisp/c/P7W_1ISJ-sU/m/GAo6w-0B7oQJ",
          "publishedOn": "2022-12-15T21:19:18.000Z",
          "wordCount": 15581,
          "title": "Common Lisp (1986)",
          "imageUrl": null
        },
        {
          "id": "https://www.apollographql.com/blog/announcement/ceo-geoff-schmidts-message-to-apollo-employees/",
          "author": null,
          "description": "Comments",
          "link": "https://www.apollographql.com/blog/announcement/ceo-geoff-schmidts-message-to-apollo-employees/",
          "publishedOn": "2022-12-15T21:16:54.000Z",
          "wordCount": 1773,
          "title": "Apollo Layoffs",
          "imageUrl": "/blog/static/Skylark-R-1-d25f1398adc12d53b5404742a0247152.png"
        },
        {
          "id": "https://www.pypy.org/posts/2022/12/jit-bug-finding-smt-fuzzing.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.pypy.org/posts/2022/12/jit-bug-finding-smt-fuzzing.html",
          "publishedOn": "2022-12-15T21:07:30.000Z",
          "wordCount": 4680,
          "title": "Finding JIT Optimizer Bugs Using SMT Solvers and Fuzzing – PyPy",
          "imageUrl": null
        },
        {
          "id": "https://kottke.org/22/12/vintage-map-mandelbrot-set",
          "author": null,
          "description": "Comments",
          "link": "https://kottke.org/22/12/vintage-map-mandelbrot-set",
          "publishedOn": "2022-12-15T20:06:58.000Z",
          "wordCount": 291,
          "title": "Vintage-Style Map of the Mandelbrot Set",
          "imageUrl": "https://kottke.org/plus/misc/images/mandelbrot-map-01.jpg"
        },
        {
          "id": "https://openai.com/blog/new-and-improved-embedding-model/",
          "author": null,
          "description": "Comments",
          "link": "https://openai.com/blog/new-and-improved-embedding-model/",
          "publishedOn": "2022-12-15T18:13:06.000Z",
          "wordCount": 1238,
          "title": "New and Improved Embedding Model for OpenAI",
          "imageUrl": "https://openai.com/content/images/2022/12/new-and-improved-embedding-model-og-1.jpg"
        },
        {
          "id": "https://www.nytimes.com/2022/12/15/books/review/tudors-in-love-sarah-gristwood.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/15/books/review/tudors-in-love-sarah-gristwood.html",
          "publishedOn": "2022-12-15T18:07:33.000Z",
          "wordCount": null,
          "title": "Courtly Love Can Be Deadly",
          "imageUrl": null
        },
        {
          "id": "https://lichess.org/@/thibault/blog/lichess--scala-3/y1sbYzJX",
          "author": null,
          "description": "Comments",
          "link": "https://lichess.org/@/thibault/blog/lichess--scala-3/y1sbYzJX",
          "publishedOn": "2022-12-15T17:07:58.000Z",
          "wordCount": 1475,
          "title": "Lichess gets a big upgrade. It doesn't go as planned",
          "imageUrl": "https://image.lichess1.org/display?h=550&op=thumbnail&path=thibault:ublog:y1sbYzJX:lzBKpBVG.png&w=880&sig=ff30fed332961a1d4d2f3d7581bfa1bddfe89406"
        },
        {
          "id": "https://www.ycombinator.com/blog/rfs-climatetech",
          "author": null,
          "description": "Comments",
          "link": "https://www.ycombinator.com/blog/rfs-climatetech",
          "publishedOn": "2022-12-15T17:07:32.000Z",
          "wordCount": 15296,
          "title": "Request for Startups: Climate Tech",
          "imageUrl": "https://www.ycombinator.com/blog/content/images/2022/12/BlogTwitter-Image-Template1.jpeg"
        },
        {
          "id": "https://brr.fyi/posts/doors-of-mcmurdo",
          "author": null,
          "description": "Comments",
          "link": "https://brr.fyi/posts/doors-of-mcmurdo",
          "publishedOn": "2022-12-15T17:00:15.000Z",
          "wordCount": 1290,
          "title": "Doors of McMurdo",
          "imageUrl": null
        },
        {
          "id": "https://jack.wrenn.fyi/blog/deflect/",
          "author": null,
          "description": "Comments",
          "link": "https://jack.wrenn.fyi/blog/deflect/",
          "publishedOn": "2022-12-15T15:54:48.000Z",
          "wordCount": 1254,
          "title": "Native Reflection in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.nist.gov/news-events/news/2022/12/nist-retires-sha-1-cryptographic-algorithm",
          "author": null,
          "description": "Comments",
          "link": "https://www.nist.gov/news-events/news/2022/12/nist-retires-sha-1-cryptographic-algorithm",
          "publishedOn": "2022-12-15T15:49:12.000Z",
          "wordCount": 2051,
          "title": "NIST is announcing that SHA-1 should be phased out by Dec. 31, 2030",
          "imageUrl": "https://www.nist.gov/sites/default/files/images/2022/12/14/SecureHashAltogirthm23_Released_960x600_v4_A.png"
        },
        {
          "id": "https://medusajs.com/blog/9-best-ecommerce-ux-practices-with-examples",
          "author": null,
          "description": "Comments",
          "link": "https://medusajs.com/blog/9-best-ecommerce-ux-practices-with-examples",
          "publishedOn": "2022-12-15T14:59:37.000Z",
          "wordCount": 18774,
          "title": "Best ecommerce UX practices from mcmaster.com",
          "imageUrl": "https://medusajs.com/images/ux-practices.jpg"
        },
        {
          "id": "https://github.com/obsproject/obs-studio/pull/7926",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/obsproject/obs-studio/pull/7926",
          "publishedOn": "2022-12-15T14:49:52.000Z",
          "wordCount": 2803,
          "title": "Adding WebRTC support to OBS using Rust",
          "imageUrl": "https://opengraph.githubassets.com/90fa3ff622885e846856e91355f0d5891a2c43f4ba4613c160f2f0058e6b4936/obsproject/obs-studio/pull/7926"
        },
        {
          "id": "https://singularityhub.com/2022/12/13/deepminds-alphacode-conquers-coding-performing-as-well-as-humans/",
          "author": null,
          "description": "Comments",
          "link": "https://singularityhub.com/2022/12/13/deepminds-alphacode-conquers-coding-performing-as-well-as-humans/",
          "publishedOn": "2022-12-15T14:43:12.000Z",
          "wordCount": 17519,
          "title": "Deepmind’s alphacode conquers coding, performing as well as humans",
          "imageUrl": "https://singularityhub.com/wp-content/uploads/2022/12/deepmind-alphacode-lines-of-code-purple-blue-pink-1.jpeg"
        },
        {
          "id": "https://link.springer.com/article/10.1007/s00392-022-02129-5",
          "author": null,
          "description": "Comments",
          "link": "https://link.springer.com/article/10.1007/s00392-022-02129-5",
          "publishedOn": "2022-12-15T14:38:52.000Z",
          "wordCount": 6688,
          "title": "Autopsy-based characterization of myocarditis after anti-SARS-CoV-2-vaccination",
          "imageUrl": "https://media.springernature.com/w200/springer-static/cover/journal/392.jpg"
        },
        {
          "id": "https://21sci-tech.com/articles/spring01/Electrodynamics.html",
          "author": null,
          "description": "Comments",
          "link": "https://21sci-tech.com/articles/spring01/Electrodynamics.html",
          "publishedOn": "2022-12-15T14:29:30.000Z",
          "wordCount": 4665,
          "title": "The Suppressed Electrodynamics of Ampère-Gauss-Weber (2001)",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33999296",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33999296",
          "publishedOn": "2022-12-15T13:37:47.000Z",
          "wordCount": 17263,
          "title": "Ask HN: How might HN build a social network together?",
          "imageUrl": null
        },
        {
          "id": "https://www.riffusion.com/about",
          "author": null,
          "description": "Comments",
          "link": "https://www.riffusion.com/about",
          "publishedOn": "2022-12-15T13:26:04.000Z",
          "wordCount": 1489,
          "title": "Riffusion – Stable Diffusion fine-tuned to generate Music",
          "imageUrl": "https://i.imgur.com/fywZpQ7.jpeg"
        },
        {
          "id": "https://www.sydney.edu.au/news-opinion/news/2022/12/07/low-cost-battery-built-with-four-times-the-capacity-of-lithium.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.sydney.edu.au/news-opinion/news/2022/12/07/low-cost-battery-built-with-four-times-the-capacity-of-lithium.html",
          "publishedOn": "2022-12-15T12:07:57.000Z",
          "wordCount": 1173,
          "title": "Na-S Battery: Low-cost with four times the capacity of lithium",
          "imageUrl": "https://www.sydney.edu.au/content/dam/corporate/images/news-and-opinion/news/2022/november/battery.jpg"
        },
        {
          "id": "https://vmst.io/@selzero/109512557990367884",
          "author": null,
          "description": "Comments",
          "link": "https://vmst.io/@selzero/109512557990367884",
          "publishedOn": "2022-12-15T11:49:31.000Z",
          "wordCount": 116,
          "title": "Who knew the first AI battles would be fought by artists?",
          "imageUrl": "https://cdn.vmst.io/media_attachments/files/109/512/541/971/089/323/original/c6caeee2cab72099.png"
        },
        {
          "id": "https://www.oreilly.com/radar/what-does-copyright-say-about-generative-models/",
          "author": null,
          "description": "Comments",
          "link": "https://www.oreilly.com/radar/what-does-copyright-say-about-generative-models/",
          "publishedOn": "2022-12-15T09:00:19.000Z",
          "wordCount": 2807,
          "title": "What does copyright say about generative models?",
          "imageUrl": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/pbthey.lawyer.750pix_crop-5e9abc2396314ea45f97b258fc440487-1.jpg"
        },
        {
          "id": "https://www.quantamagazine.org/how-the-brain-distinguishes-memories-from-perceptions-20221214/",
          "author": null,
          "description": "Comments",
          "link": "https://www.quantamagazine.org/how-the-brain-distinguishes-memories-from-perceptions-20221214/",
          "publishedOn": "2022-12-15T01:32:00.000Z",
          "wordCount": 5745,
          "title": "How the brain distinguishes memories from perceptions",
          "imageUrl": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/12/PerceptionOrMemory-byKristinaArmitage-Social.webp"
        },
        {
          "id": "https://www.coindesk.com/policy/2022/12/13/ftxs-bahamas-liquidators-seek-to-exclude-over-200m-worth-of-luxury-properties-from-liquidation/",
          "author": null,
          "description": "Comments",
          "link": "https://www.coindesk.com/policy/2022/12/13/ftxs-bahamas-liquidators-seek-to-exclude-over-200m-worth-of-luxury-properties-from-liquidation/",
          "publishedOn": "2022-12-15T00:56:30.000Z",
          "wordCount": 21980,
          "title": "FTX's Bahamas Liquidators Seek to Exclude Luxury Properties from Liquidation",
          "imageUrl": "https://www.coindesk.com/resizer/PXigqToo2gdyyUOgvUX9CLRYHiM=/1200x628/center/middle/cloudfront-us-east-1.images.arcpublishing.com/coindesk/CYIY5TNUPRB2VHL2OLGC2IUWHM.jpg"
        },
        {
          "id": "https://www.nytimes.com/2022/12/14/climate/native-plants-lawns-homeowners.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/14/climate/native-plants-lawns-homeowners.html",
          "publishedOn": "2022-12-15T00:16:21.000Z",
          "wordCount": null,
          "title": "Maryland couple fights home owners assoc. and wins ushering in new state law",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/elonjet/status/1603166460746104833",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/elonjet/status/1603166460746104833",
          "publishedOn": "2022-12-14T23:29:41.000Z",
          "wordCount": 470,
          "title": "Twitter restored ElonJet account",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/twittersafety/status/1603165959669354496",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/twittersafety/status/1603165959669354496",
          "publishedOn": "2022-12-14T23:26:43.000Z",
          "wordCount": 470,
          "title": "“We’ve updated our policy to prohibit sharing someone else’s live location.”",
          "imageUrl": null
        },
        {
          "id": "https://www.withdiode.com/projects/62716731-5e1e-4622-86af-90d8e6b5123b",
          "author": null,
          "description": "Comments",
          "link": "https://www.withdiode.com/projects/62716731-5e1e-4622-86af-90d8e6b5123b",
          "publishedOn": "2022-12-14T21:42:28.000Z",
          "wordCount": 324,
          "title": "A circuit simulator that doesn't look like it was made in 2003",
          "imageUrl": "https://withdiode.com/api/og?project=62716731-5e1e-4622-86af-90d8e6b5123b"
        },
        {
          "id": "https://matthewfelgate.wordpress.com/2022/12/14/turn-the-radio-volume-down-for-adverts-and-djs-talking/",
          "author": null,
          "description": "Comments",
          "link": "https://matthewfelgate.wordpress.com/2022/12/14/turn-the-radio-volume-down-for-adverts-and-djs-talking/",
          "publishedOn": "2022-12-14T21:10:25.000Z",
          "wordCount": 3752,
          "title": "Turn the radio volume down for adverts and DJs talking",
          "imageUrl": "https://s0.wp.com/i/blank.jpg"
        },
        {
          "id": "https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1",
          "author": null,
          "description": "Comments",
          "link": "https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1",
          "publishedOn": "2022-12-14T21:07:52.000Z",
          "wordCount": 73,
          "title": "How does GPT obtain its ability? Tracing emergent abilities of language models",
          "imageUrl": "https://www.notion.so/images/meta/default.png"
        },
        {
          "id": "https://musescore.org/en/4.0",
          "author": null,
          "description": "Comments",
          "link": "https://musescore.org/en/4.0",
          "publishedOn": "2022-12-14T21:05:36.000Z",
          "wordCount": 1737,
          "title": "MuseScore 4",
          "imageUrl": "https://musescore.org/sites/musescore.org/files/2022-12/laptop_desktop_2x.png"
        },
        {
          "id": "https://www.easypost.com/careers",
          "author": null,
          "description": "Comments",
          "link": "https://www.easypost.com/careers",
          "publishedOn": "2022-12-14T21:00:16.000Z",
          "wordCount": 510,
          "title": "EasyPost (YC S13) Is Hiring",
          "imageUrl": "https://assets.easypost.com/assets/images/branding/easypost-primary-icon-padded.dc7ae4617154a87e131844bbe208c350.png"
        },
        {
          "id": "https://fuse.wikichip.org/news/7343/iedm-2022-did-we-just-witness-the-death-of-sram/",
          "author": null,
          "description": "Comments",
          "link": "https://fuse.wikichip.org/news/7343/iedm-2022-did-we-just-witness-the-death-of-sram/",
          "publishedOn": "2022-12-14T20:55:17.000Z",
          "wordCount": 4305,
          "title": "The Death of SRAM?",
          "imageUrl": "https://fuse.wikichip.org/wp-content/uploads/2022/09/tsmc-n3e-thumb.png"
        },
        {
          "id": "https://www.theregister.com/2022/12/14/firefox_108/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theregister.com/2022/12/14/firefox_108/",
          "publishedOn": "2022-12-14T20:31:21.000Z",
          "wordCount": 1491,
          "title": "You can hook your MIDI keyboard up to a website with Firefox 108",
          "imageUrl": "https://regmedia.co.uk/2016/03/01/burning_keyboard_teaser.jpg"
        },
        {
          "id": "https://krebsonsecurity.com/2022/12/six-charged-in-mass-takedown-of-ddos-for-hire-sites/",
          "author": null,
          "description": "Comments",
          "link": "https://krebsonsecurity.com/2022/12/six-charged-in-mass-takedown-of-ddos-for-hire-sites/",
          "publishedOn": "2022-12-14T20:01:43.000Z",
          "wordCount": 2221,
          "title": "Six charged in mass takedown of DDoS-for-hire sites",
          "imageUrl": null
        },
        {
          "id": "https://investors.metals.co/news-releases/news-release-details/nori-and-allseas-lift-over-3000-tonnes-polymetallic-nodules/",
          "author": null,
          "description": "Comments",
          "link": "https://investors.metals.co/news-releases/news-release-details/nori-and-allseas-lift-over-3000-tonnes-polymetallic-nodules/",
          "publishedOn": "2022-12-14T19:40:02.000Z",
          "wordCount": 2869,
          "title": "The Metals Company subsidiary lifts over 3000T of nodules to sea surface",
          "imageUrl": null
        },
        {
          "id": "https://www.scanofthemonth.com/scans/nest-thermostat-evolution",
          "author": null,
          "description": "Comments",
          "link": "https://www.scanofthemonth.com/scans/nest-thermostat-evolution",
          "publishedOn": "2022-12-14T18:43:00.000Z",
          "wordCount": 3353,
          "title": "Hidden tech of the Nest Thermostat",
          "imageUrl": "https://assets.website-files.com/6202f89a2c14fae9e9222dc3/6398ee5b5b192d5171c7eece_og-image-nest.png"
        },
        {
          "id": "https://htmx.org/docs/",
          "author": null,
          "description": "Comments",
          "link": "https://htmx.org/docs/",
          "publishedOn": "2022-12-14T18:25:38.000Z",
          "wordCount": 7523,
          "title": "Htmx in a Nutshell",
          "imageUrl": null
        },
        {
          "id": "https://blog.jquery.com/2022/12/13/jquery-3-6-2-released/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.jquery.com/2022/12/13/jquery-3-6-2-released/",
          "publishedOn": "2022-12-14T18:14:16.000Z",
          "wordCount": 1623,
          "title": "jQuery 3.6.2",
          "imageUrl": null
        },
        {
          "id": "https://blog.waymo.com/2022/12/waymos-collision-avoidance-testing.html",
          "author": null,
          "description": "Comments",
          "link": "https://blog.waymo.com/2022/12/waymos-collision-avoidance-testing.html",
          "publishedOn": "2022-12-14T17:56:48.000Z",
          "wordCount": 2507,
          "title": "Waymo's collision avoidance testing",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiloNh_iPC9dOPaXNe1mWtX3yrt11SqMck9RJhNXJ-L1ky4KKKz3UwkT3XyOIowlD7-8FqSVQolTI9MdQVtv4dIPCVx4FtWTUtNnWw7XpP_MNEqtU4uzFMRwGx5jkuqGmh1elLLWlEfKwMarlWP3LK-tHANjBqOcO5SBcs4TL_kEKTMTe5PAMUeglwY/w1200-h630-p-k-no-nu/CAT.gif"
        },
        {
          "id": "https://svelte.dev/blog/announcing-sveltekit-1.0",
          "author": null,
          "description": "Comments",
          "link": "https://svelte.dev/blog/announcing-sveltekit-1.0",
          "publishedOn": "2022-12-14T17:15:27.000Z",
          "wordCount": 2828,
          "title": "SvelteKit 1.0",
          "imageUrl": null
        },
        {
          "id": "https://tailscale.com/blog/tailnet-lock/",
          "author": null,
          "description": "Comments",
          "link": "https://tailscale.com/blog/tailnet-lock/",
          "publishedOn": "2022-12-14T17:07:07.000Z",
          "wordCount": 1406,
          "title": "Tailnet Lock",
          "imageUrl": "https://tailscale.com/blog/tailnet-lock/social.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=TAO1i9Z9GpQ",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=TAO1i9Z9GpQ",
          "publishedOn": "2022-12-14T16:44:16.000Z",
          "wordCount": null,
          "title": "Does glass break faster than a bullet? [video]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/Juice-Labs/Juice-Labs/wiki",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Juice-Labs/Juice-Labs/wiki",
          "publishedOn": "2022-12-14T16:10:49.000Z",
          "wordCount": 898,
          "title": "Show HN: Software for Remote GPU-over-IP",
          "imageUrl": "https://opengraph.githubassets.com/81967fb6bf88cb547469f5f7be34ccdc817b1fc1dd7a7c59bb1cd0c6da407612/Juice-Labs/Juice-Labs"
        },
        {
          "id": "https://www.ft.com/content/741772c0-ee76-4d3d-bfcd-4fabc1fb405d",
          "author": null,
          "description": "Comments",
          "link": "https://www.ft.com/content/741772c0-ee76-4d3d-bfcd-4fabc1fb405d",
          "publishedOn": "2022-12-14T13:06:25.000Z",
          "wordCount": 15256,
          "title": "Female spies of MI6",
          "imageUrl": "https://www.ft.com/__origami/service/image/v2/images/raw/https%3A%2F%2Fd1e00ek4ebabms.cloudfront.net%2Fproduction%2F4725bafd-9c9e-4407-a0c1-ea71bfd27ac3.jpg?source=next-opengraph&fit=scale-down&width=900"
        },
        {
          "id": "https://twitter.com/davisblalock/status/1602600453555961856",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/davisblalock/status/1602600453555961856",
          "publishedOn": "2022-12-14T12:40:24.000Z",
          "wordCount": 470,
          "title": "Ways to get around ChatGPT's safeguards",
          "imageUrl": null
        },
        {
          "id": "https://www.totaltypescript.com/rewriting-typescript-in-rust",
          "author": null,
          "description": "Comments",
          "link": "https://www.totaltypescript.com/rewriting-typescript-in-rust",
          "publishedOn": "2022-12-14T11:56:42.000Z",
          "wordCount": 4519,
          "title": "Rewriting TypeScript in Rust?",
          "imageUrl": "https://www.totaltypescript.com/api/og?title=Rewriting%20TypeScript%20in%20Rust?%20You'd%20have%20to%20be..."
        },
        {
          "id": "https://english.elpais.com/culture/2022-12-12/wendy-carlos-the-brilliant-but-lonely-life-of-an-electronic-music-pioneer.html",
          "author": null,
          "description": "Comments",
          "link": "https://english.elpais.com/culture/2022-12-12/wendy-carlos-the-brilliant-but-lonely-life-of-an-electronic-music-pioneer.html",
          "publishedOn": "2022-12-14T10:20:07.000Z",
          "wordCount": 5942,
          "title": "Wendy Carlos: The brilliant but lonely life of an electronic music pioneer",
          "imageUrl": "https://images.english.elpais.com/resizer/_jDxXwbltG15yrrG-Q3Sp7Br1cU=/1200x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/ZIYYEWM7CNAXLLAYAWFNEHJT7Y.jpg"
        },
        {
          "id": "https://designnotes.blog.gov.uk/2022/12/12/making-the-gov-uk-frontend-typography-scale-more-accessible/",
          "author": null,
          "description": "Comments",
          "link": "https://designnotes.blog.gov.uk/2022/12/12/making-the-gov-uk-frontend-typography-scale-more-accessible/",
          "publishedOn": "2022-12-14T08:04:50.000Z",
          "wordCount": 1660,
          "title": "Making the Gov.uk front end typography scale more accessible",
          "imageUrl": "https://designnotes.blog.gov.uk/wp-content/uploads/sites/53/2022/12/User-looking-at-GOV.UK-on-a-mobile-device.jpg"
        },
        {
          "id": "https://en.wikipedia.org/wiki/Windy_City_Heat",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/Windy_City_Heat",
          "publishedOn": "2022-12-14T06:35:45.000Z",
          "wordCount": 2661,
          "title": "Windy City Heat",
          "imageUrl": "https://upload.wikimedia.org/wikipedia/en/3/31/Windycityheat.jpg"
        },
        {
          "id": "https://skamille.medium.com/okrs-are-hard-b4a6a8491af0",
          "author": null,
          "description": "Comments",
          "link": "https://skamille.medium.com/okrs-are-hard-b4a6a8491af0",
          "publishedOn": "2022-12-14T00:59:26.000Z",
          "wordCount": 3487,
          "title": "OKRs Are Hard",
          "imageUrl": null
        },
        {
          "id": "https://www.getrevue.co/profile/jackjack/issues/a-native-internet-protocol-for-social-media-1503112",
          "author": null,
          "description": "Comments",
          "link": "https://www.getrevue.co/profile/jackjack/issues/a-native-internet-protocol-for-social-media-1503112",
          "publishedOn": "2022-12-13T23:03:29.000Z",
          "wordCount": 2513,
          "title": "A native internet protocol for social media",
          "imageUrl": "https://s3.amazonaws.com/revue/issue_images/images/000/668/283/original/issue_image_1503112.jpg?1670939808"
        },
        {
          "id": "https://old.reddit.com/r/shittychangelog/comments/zl5gaz/here_at_reddit_we_believe_everything_is_better_in/",
          "author": null,
          "description": "Comments",
          "link": "https://old.reddit.com/r/shittychangelog/comments/zl5gaz/here_at_reddit_we_believe_everything_is_better_in/",
          "publishedOn": "2022-12-13T21:45:56.000Z",
          "wordCount": 2611,
          "title": "Reddit's photo albums broke due to Integer overflow of Signed Int32",
          "imageUrl": "https://www.redditstatic.com/new-icon.png"
        },
        {
          "id": "https://www.pcgamer.com/after-spending-20-years-simulating-reality-the-dwarf-fortress-devs-have-to-get-used-to-a-new-one-being-millionaires/",
          "author": null,
          "description": "Comments",
          "link": "https://www.pcgamer.com/after-spending-20-years-simulating-reality-the-dwarf-fortress-devs-have-to-get-used-to-a-new-one-being-millionaires/",
          "publishedOn": "2022-12-13T21:32:57.000Z",
          "wordCount": 12622,
          "title": "After 20 years the Dwarf Fortress devs have to get used to being millionaires",
          "imageUrl": "https://cdn.mos.cms.futurecdn.net/5i5EaBh4eSGR8AJYhpqPUR-1200-80.jpg"
        },
        {
          "id": "https://www.agwa.name/blog/post/domain_pricing_is_very_confusing",
          "author": null,
          "description": "Comments",
          "link": "https://www.agwa.name/blog/post/domain_pricing_is_very_confusing",
          "publishedOn": "2022-12-13T21:27:19.000Z",
          "wordCount": 1917,
          "title": "No, Google did not hike the price of a .dev domain from $12 to $850",
          "imageUrl": null
        },
        {
          "id": "https://www.reuters.com/technology/how-secret-software-change-allowed-ftx-use-client-money-2022-12-13/",
          "author": null,
          "description": "Comments",
          "link": "https://www.reuters.com/technology/how-secret-software-change-allowed-ftx-use-client-money-2022-12-13/",
          "publishedOn": "2022-12-13T21:16:57.000Z",
          "wordCount": 6399,
          "title": "A software change allowed FTX to use client money",
          "imageUrl": "https://www.reuters.com/resizer/8gBJEoCC1GaxZoMG3GaQ4KhbQz4=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/HQEXMEIJYNM3JBMME5F3VPBWVU.jpg"
        },
        {
          "id": "https://www.flickr.org/announcing-the-flickr-foundation/",
          "author": null,
          "description": "Comments",
          "link": "https://www.flickr.org/announcing-the-flickr-foundation/",
          "publishedOn": "2022-12-13T21:02:38.000Z",
          "wordCount": 2518,
          "title": "The Flickr Foundation",
          "imageUrl": "https://www.flickr.org/wp-content/uploads/sites/4/2022/10/flickr_og.jpg"
        },
        {
          "id": "https://jobs.lever.co/mindsdb/5ef21d35-8386-4b1c-941d-77aed16b2c18",
          "author": null,
          "description": "Comments",
          "link": "https://jobs.lever.co/mindsdb/5ef21d35-8386-4b1c-941d-77aed16b2c18",
          "publishedOn": "2022-12-13T21:01:10.000Z",
          "wordCount": 16281,
          "title": "MindsDB (YC W20) Is Hiring a Senior PM",
          "imageUrl": "https://lever-client-logos.s3.us-west-2.amazonaws.com/df2cb049-f236-48be-863e-1c03abaec2e5-1634589438039.png"
        },
        {
          "id": "https://support.apple.com/en-gb/HT213530",
          "author": null,
          "description": "Comments",
          "link": "https://support.apple.com/en-gb/HT213530",
          "publishedOn": "2022-12-13T20:57:04.000Z",
          "wordCount": 2419,
          "title": "About the security content of iOS 16.2 and iPadOS 16.2",
          "imageUrl": null
        },
        {
          "id": "https://tfos.co/p/rebuild-social-media/",
          "author": null,
          "description": "Comments",
          "link": "https://tfos.co/p/rebuild-social-media/",
          "publishedOn": "2022-12-13T20:15:32.000Z",
          "wordCount": 1481,
          "title": "How to rebuild social media on top of RSS",
          "imageUrl": "https://platypub.sfo3.cdn.digitaloceanspaces.com/93206301-493d-43d0-847e-d67a0c70cb7b"
        },
        {
          "id": "https://constructionphysics.substack.com/p/balloon-framing-is-worse-is-better",
          "author": null,
          "description": "Comments",
          "link": "https://constructionphysics.substack.com/p/balloon-framing-is-worse-is-better",
          "publishedOn": "2022-12-13T19:51:21.000Z",
          "wordCount": 5453,
          "title": "Balloon framing is worse-is-better (2021)",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4a7c5b0-3965-4fa1-b4eb-9b71a0480285_548x352.png"
        },
        {
          "id": "https://www.bloomberg.com/news/articles/2022-12-13/will-apple-allow-users-to-install-third-party-app-stores-sideload-in-europe",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/articles/2022-12-13/will-apple-allow-users-to-install-third-party-app-stores-sideload-in-europe",
          "publishedOn": "2022-12-13T19:19:14.000Z",
          "wordCount": 576,
          "title": "Apple to allow outside app stores in overhaul spurred by EU laws",
          "imageUrl": null
        },
        {
          "id": "https://www.newyorker.com/culture/cultural-comment/the-delight-of-edward-hoppers-solitude",
          "author": null,
          "description": "Comments",
          "link": "https://www.newyorker.com/culture/cultural-comment/the-delight-of-edward-hoppers-solitude",
          "publishedOn": "2022-12-13T19:00:31.000Z",
          "wordCount": 37722,
          "title": "The Delight of Edward Hopper’s Solitude",
          "imageUrl": "https://media.newyorker.com/photos/638e75002276ab205c011c87/16:9/w_1280,c_limit/Gopnik-Hopper-1.jpg"
        },
        {
          "id": "https://observablehq.com/@asg017/introducing-sqlite-loadable-rs",
          "author": null,
          "description": "Comments",
          "link": "https://observablehq.com/@asg017/introducing-sqlite-loadable-rs",
          "publishedOn": "2022-12-13T18:54:22.000Z",
          "wordCount": 1826,
          "title": "SQLite-loadable-rs: A framework for building SQLite Extensions in Rust",
          "imageUrl": "https://static.observableusercontent.com/thumbnail/bfc35020b7a962ea51d05982415e9c4fcd4284b6240f7e9bfa64e1e11aa22866.jpg"
        },
        {
          "id": "https://ai.facebook.com/blog/ai-self-supervised-learning-data2vec/",
          "author": null,
          "description": "Comments",
          "link": "https://ai.facebook.com/blog/ai-self-supervised-learning-data2vec/",
          "publishedOn": "2022-12-13T18:03:03.000Z",
          "wordCount": 1191,
          "title": "Data2vec 2.0: Highly efficient self-supervised learning for vision, speech, text",
          "imageUrl": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/318451836_1178090343105940_5457223586182092425_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=ffMH8bGXcV0AX9KtBSg&_nc_oc=AQmXPHZM20ouBRwzgubKz_Fm4_1XFVewy2vIgCdxjJZ2kxWEaz94yziIQh2g8bspnQ8&_nc_ht=scontent-iad3-1.xx&oh=00_AfBEbUaNxxhKpStDW9UjdqKb8KbpBAzmUZePh9gBwMzhQw&oe=639E5F39"
        },
        {
          "id": "https://mars.nasa.gov/explore/mars-now/",
          "author": null,
          "description": "Comments",
          "link": "https://mars.nasa.gov/explore/mars-now/",
          "publishedOn": "2022-12-13T17:35:21.000Z",
          "wordCount": 127,
          "title": "Mars Now",
          "imageUrl": "https://mars.nasa.gov/system/site_config_values/meta_share_images/1_mars-nasa-gov.jpg"
        },
        {
          "id": "https://tailscale.com/blog/throughput-improvements/",
          "author": null,
          "description": "Comments",
          "link": "https://tailscale.com/blog/throughput-improvements/",
          "publishedOn": "2022-12-13T17:25:30.000Z",
          "wordCount": 2926,
          "title": "Userspace isn't slow, some kernel interfaces are",
          "imageUrl": "https://tailscale.com/blog/throughput-improvements/social.png"
        },
        {
          "id": "https://jvns.ca/blog/2022/12/07/tips-for-analyzing-logs/",
          "author": null,
          "description": "Comments",
          "link": "https://jvns.ca/blog/2022/12/07/tips-for-analyzing-logs/",
          "publishedOn": "2022-12-13T16:47:16.000Z",
          "wordCount": 1323,
          "title": "Tips for analyzing logs",
          "imageUrl": null
        },
        {
          "id": "https://www.energy.gov/articles/doe-national-laboratory-makes-history-achieving-fusion-ignition",
          "author": null,
          "description": "Comments",
          "link": "https://www.energy.gov/articles/doe-national-laboratory-makes-history-achieving-fusion-ignition",
          "publishedOn": "2022-12-13T16:44:40.000Z",
          "wordCount": 1792,
          "title": "US Department of Energy: Fusion Ignition Achieved",
          "imageUrl": "https://www.energy.gov/sites/default/files/styles/photo_gallery_509_x_678_/public/2022-06/DOE%20Press%20Release%20Preview%20image.png?itok=tlJni6eS"
        },
        {
          "id": "https://github.com/ponylang/ponyc",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/ponylang/ponyc",
          "publishedOn": "2022-12-13T15:56:04.000Z",
          "wordCount": 1107,
          "title": "Pony Programming Language",
          "imageUrl": "https://repository-images.githubusercontent.com/6667084/a832d300-6128-11e9-8d1a-0773bba1d4c8"
        },
        {
          "id": "https://xethub.com/user/login",
          "author": null,
          "description": "Comments",
          "link": "https://xethub.com/user/login",
          "publishedOn": "2022-12-13T15:14:54.000Z",
          "wordCount": 483,
          "title": "Show HN: We scaled Git to support 1 TB repos",
          "imageUrl": "/assets/img/logo.png"
        },
        {
          "id": "https://www.justice.gov/usao-sdny/press-release/file/1557571/download",
          "author": null,
          "description": "Comments",
          "link": "https://www.justice.gov/usao-sdny/press-release/file/1557571/download",
          "publishedOn": "2022-12-13T15:14:07.000Z",
          "wordCount": 74244,
          "title": "The United States of America vs. Samuel Bankman-Fried Indictment [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/readme/featured/vintage-computing",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/readme/featured/vintage-computing",
          "publishedOn": "2022-12-13T15:12:01.000Z",
          "wordCount": 3141,
          "title": "What we can learn from vintage computing",
          "imageUrl": "https://images.ctfassets.net/s5uo95nf6njh/5VvjzsD4mgUXrfHkk2zXli/7c874faacb9858fe851135a315f8040a/1200x630-ReadMe-Twitter_LI_Post-ImageOnly-Old_Teach_Featured_Article.jpg"
        },
        {
          "id": "https://mifi.no/losslesscut/",
          "author": null,
          "description": "Comments",
          "link": "https://mifi.no/losslesscut/",
          "publishedOn": "2022-12-13T14:44:56.000Z",
          "wordCount": 909,
          "title": "LosslessCut: lossless video/audio editing",
          "imageUrl": null
        },
        {
          "id": "https://mullvad.net/en/blog/2022/12/13/shutting-down-our-unencrypted-public-dns-service/",
          "author": null,
          "description": "Comments",
          "link": "https://mullvad.net/en/blog/2022/12/13/shutting-down-our-unencrypted-public-dns-service/",
          "publishedOn": "2022-12-13T14:41:30.000Z",
          "wordCount": 296,
          "title": "Shutting down our unencrypted public DNS service",
          "imageUrl": "https://mullvad.net/static/press/MullvadVPN_logo_Round_RGB_Color_positive.png"
        },
        {
          "id": "http://blog.fogus.me/2022/12/13/the-best-things-and-stuff-of-2022/",
          "author": null,
          "description": "Comments",
          "link": "http://blog.fogus.me/2022/12/13/the-best-things-and-stuff-of-2022/",
          "publishedOn": "2022-12-13T14:27:28.000Z",
          "wordCount": 3281,
          "title": "The best things and stuff of 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8622869/",
          "author": null,
          "description": "Comments",
          "link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8622869/",
          "publishedOn": "2022-12-13T11:18:59.000Z",
          "wordCount": 12902,
          "title": "Yerba Mate – A Long but Current History (2021)",
          "imageUrl": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-logo-share.png?_=0"
        },
        {
          "id": "https://stratechery.com/2022/consoles-and-competition/",
          "author": null,
          "description": "Comments",
          "link": "https://stratechery.com/2022/consoles-and-competition/",
          "publishedOn": "2022-12-13T09:35:25.000Z",
          "wordCount": 6506,
          "title": "Consoles and competition",
          "imageUrl": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/activision-9.png?fit=1200%2C653&ssl=1"
        },
        {
          "id": "https://github.com/observablehq/plot/blob/main/CHANGELOG.md",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/observablehq/plot/blob/main/CHANGELOG.md",
          "publishedOn": "2022-12-13T08:04:48.000Z",
          "wordCount": 8786,
          "title": "Observable Plot 0.6.1",
          "imageUrl": "https://opengraph.githubassets.com/dee4c7fa8ac767ccaf53457d03275f82b2df180592025b0e77933cfa15425eaa/observablehq/plot"
        },
        {
          "id": "https://www.smashingmagazine.com/2022/09/javascript-api-guide/",
          "author": null,
          "description": "Comments",
          "link": "https://www.smashingmagazine.com/2022/09/javascript-api-guide/",
          "publishedOn": "2022-12-13T06:55:49.000Z",
          "wordCount": 5772,
          "title": "Lesser-known JavaScript APIs",
          "imageUrl": "https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b583db40-b8c0-46c4-9893-5a7ae3d00453/api-page-visibility-web-sharing-broadcast-channel-internationalization.jpg"
        },
        {
          "id": "https://www.historytoday.com/archive/feature/violent-ends",
          "author": null,
          "description": "Comments",
          "link": "https://www.historytoday.com/archive/feature/violent-ends",
          "publishedOn": "2022-12-13T05:04:15.000Z",
          "wordCount": 2569,
          "title": "Violent Ends: Early modern methods of execution",
          "imageUrl": null
        },
        {
          "id": "https://github.com/odnoletkov/advent-of-code-jq",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/odnoletkov/advent-of-code-jq",
          "publishedOn": "2022-12-13T01:29:54.000Z",
          "wordCount": 614,
          "title": "Solving Advent of Code with jq",
          "imageUrl": "https://opengraph.githubassets.com/1f138e621e20f91d4c49c5dae49c822c845445eaa76c84afdcc02562530b761e/odnoletkov/advent-of-code-jq"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33963269",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33963269",
          "publishedOn": "2022-12-13T01:17:50.000Z",
          "wordCount": 933,
          "title": "Ask HN: If I get locked out of everything, please try to help me",
          "imageUrl": null
        },
        {
          "id": "https://www.datocms-assets.com/65181/1667327773-iconiq-analytics-insights-engineering-in-a-hybrid-world.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://www.datocms-assets.com/65181/1667327773-iconiq-analytics-insights-engineering-in-a-hybrid-world.pdf",
          "publishedOn": "2022-12-13T00:08:56.000Z",
          "wordCount": 58290,
          "title": "Data behind high-functioning engineering organizations [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://blog.jakubholy.net/2022/trinity-of-clojure/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.jakubholy.net/2022/trinity-of-clojure/",
          "publishedOn": "2022-12-12T23:39:21.000Z",
          "wordCount": 788,
          "title": "Clojure is a trinity of language, REPL, and structural editor",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/tier10k/status/1602446984090107905",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/tier10k/status/1602446984090107905",
          "publishedOn": "2022-12-12T23:38:53.000Z",
          "wordCount": 470,
          "title": "SBF Arrested by Bahamian Authorities",
          "imageUrl": null
        },
        {
          "id": "https://book.dragonriders.community/",
          "author": null,
          "description": "Comments",
          "link": "https://book.dragonriders.community/",
          "publishedOn": "2022-12-12T23:34:58.000Z",
          "wordCount": 1956,
          "title": "Building Games with DragonRuby – A free book on Ruby game dev",
          "imageUrl": "https://book.dragonriders.community/img/cover.jpg"
        },
        {
          "id": "https://www.slowboring.com/p/why-hasnt-technology-disrupted-higher",
          "author": null,
          "description": "Comments",
          "link": "https://www.slowboring.com/p/why-hasnt-technology-disrupted-higher",
          "publishedOn": "2022-12-12T23:13:51.000Z",
          "wordCount": 3894,
          "title": "Why hasn’t technology disrupted higher education already?",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8ef74a63-a936-4cc2-8a58-563d2f657594_3496x2469.jpeg"
        },
        {
          "id": "https://astralcodexten.substack.com/p/perhaps-it-is-a-bad-thing-that-the",
          "author": null,
          "description": "Comments",
          "link": "https://astralcodexten.substack.com/p/perhaps-it-is-a-bad-thing-that-the",
          "publishedOn": "2022-12-12T22:30:52.000Z",
          "wordCount": 5509,
          "title": "Perhaps it is a bad thing that the leading AI companies cannot control their AIs",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0484a62e-4fb0-4bff-afae-9818b71a58fc_448x271.png"
        },
        {
          "id": "https://jjar.huji.ac.il/sites/default/files/jjar/files/jjar2_art4_lachish_p76-119_2022-10-12_01.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://jjar.huji.ac.il/sites/default/files/jjar/files/jjar2_art4_lachish_p76-119_2022-10-12_01.pdf",
          "publishedOn": "2022-12-12T22:12:08.000Z",
          "wordCount": 149763,
          "title": "A Canaanite’s wish to eradicate lice on an inscribed ivory comb from Lachish [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://www.phoronix.com/news/Linux-6.2-Btrfs-EXT4",
          "author": null,
          "description": "Comments",
          "link": "https://www.phoronix.com/news/Linux-6.2-Btrfs-EXT4",
          "publishedOn": "2022-12-12T22:06:25.000Z",
          "wordCount": 1530,
          "title": "Btrfs in Linux 6.2 brings performance improvements, better RAID 5/6 reliability",
          "imageUrl": null
        },
        {
          "id": "https://unovis.dev/",
          "author": null,
          "description": "Comments",
          "link": "https://unovis.dev/",
          "publishedOn": "2022-12-12T20:13:27.000Z",
          "wordCount": 1436,
          "title": "Unovis: Data visualization for React, Angular, Svelte, TypeScript, JavaScript",
          "imageUrl": "https://unovis.dev/img/unovis-social.png"
        },
        {
          "id": "https://yalereview.org/article/surowiecki-geoff-dyer",
          "author": null,
          "description": "Comments",
          "link": "https://yalereview.org/article/surowiecki-geoff-dyer",
          "publishedOn": "2022-12-12T19:28:32.000Z",
          "wordCount": 3795,
          "title": "Geoff Dyer: The essayist on not having a career James Surowiecki",
          "imageUrl": "https://d181q449nqu6en.cloudfront.net/content/craft/articles/_1200x630_crop_center-center_82_none/Dyer_InterviewAsset-1@2x.png?mtime=20221130105717&focal=none&tmtime=20221130111559"
        },
        {
          "id": "https://www.curbsideclassic.com/trackside-classic/trackside-classic-1955-union-pacific-emd-e9-the-last-of-the-classic-diesel-streamliners/",
          "author": null,
          "description": "Comments",
          "link": "https://www.curbsideclassic.com/trackside-classic/trackside-classic-1955-union-pacific-emd-e9-the-last-of-the-classic-diesel-streamliners/",
          "publishedOn": "2022-12-12T19:02:19.000Z",
          "wordCount": 17240,
          "title": "1955 Union Pacific EMD E9 – The Last of the Classic Diesel Streamliners (2012)",
          "imageUrl": "https://i0.wp.com/www.curbsideclassic.com/wp-content/uploads/2022/07/e9.jpg?fit=112%2C96&ssl=1"
        },
        {
          "id": "https://www.prequel.co/blog/database-drivers-naughty-or-nice",
          "author": null,
          "description": "Comments",
          "link": "https://www.prequel.co/blog/database-drivers-naughty-or-nice",
          "publishedOn": "2022-12-12T15:51:57.000Z",
          "wordCount": 1640,
          "title": "Database drivers: Naughty or nice?",
          "imageUrl": "https://uploads-ssl.webflow.com/632e1440a7cdd10ccb606ffd/639746c0b98a9ad7d61dcbd2_NaughtyOrNice_v2.png"
        },
        {
          "id": "https://thewalrus.ca/bring-back-dinosaurs/",
          "author": null,
          "description": "Comments",
          "link": "https://thewalrus.ca/bring-back-dinosaurs/",
          "publishedOn": "2022-12-12T14:40:00.000Z",
          "wordCount": 4275,
          "title": "What would it take to bring back the dinosaurs?",
          "imageUrl": "https://walrus-assets.s3.amazonaws.com/img/Expert_Jurassic-Park_735.jpg"
        },
        {
          "id": "https://sciencenorway.no/archaeoloy-medieval-history-ships/shipwreck-discovered-at-the-bottom-of-norways-largest-lake-possibly-700-years-old/2110769",
          "author": null,
          "description": "Comments",
          "link": "https://sciencenorway.no/archaeoloy-medieval-history-ships/shipwreck-discovered-at-the-bottom-of-norways-largest-lake-possibly-700-years-old/2110769",
          "publishedOn": "2022-12-12T14:36:10.000Z",
          "wordCount": 9830,
          "title": "Medieval ship found in Norway's biggest lake",
          "imageUrl": "https://image.sciencenorway.no/2110998.jpg?imageId=2110998&panow=100&panoh=100&panox=0&panoy=0&heightw=100&heighth=100&heightx=0&heighty=0&width=1200&height=630"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33954778",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33954778",
          "publishedOn": "2022-12-12T14:13:45.000Z",
          "wordCount": 14498,
          "title": "Ask HN: What's your proudest hack?",
          "imageUrl": null
        },
        {
          "id": "https://www.bloomberg.com/news/articles/2022-12-08/the-hype-around-esports-is-fading-as-investors-and-sponsors-flee",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/articles/2022-12-08/the-hype-around-esports-is-fading-as-investors-and-sponsors-flee",
          "publishedOn": "2022-12-12T14:00:18.000Z",
          "wordCount": 576,
          "title": "The hype around esports is fading as investors and sponsors dry up",
          "imageUrl": null
        },
        {
          "id": "https://www.thediff.co/p/a-solution-in-search-of-a-problem",
          "author": null,
          "description": "Comments",
          "link": "https://www.thediff.co/p/a-solution-in-search-of-a-problem",
          "publishedOn": "2022-12-12T13:57:04.000Z",
          "wordCount": 7775,
          "title": "“A solution in search of a problem” is a low-rates phenomenon",
          "imageUrl": "https://substackcdn.com/image/fetch/w_256,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5b730ae4-aa35-496e-8198-965a187e2e43_600x600.png"
        },
        {
          "id": "https://animationobsessive.substack.com/p/the-complicated-man-who-made-rudolph",
          "author": null,
          "description": "Comments",
          "link": "https://animationobsessive.substack.com/p/the-complicated-man-who-made-rudolph",
          "publishedOn": "2022-12-12T13:52:52.000Z",
          "wordCount": 7296,
          "title": "The complicated man who made 'Rudolph'",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad1343d6-91f8-4d63-9080-92e3065707ac_1454x882.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=BVIN_PJu2rs",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=BVIN_PJu2rs",
          "publishedOn": "2022-12-12T12:58:12.000Z",
          "wordCount": null,
          "title": "What if you delete the “Program Files” folder in Windows? [video]",
          "imageUrl": null
        },
        {
          "id": "https://laion.ai/blog/laion-5b/",
          "author": null,
          "description": "Comments",
          "link": "https://laion.ai/blog/laion-5b/",
          "publishedOn": "2022-12-12T12:18:46.000Z",
          "wordCount": 8178,
          "title": "Laion-5B: A new era of open large-scale multi-modal datasets",
          "imageUrl": "https://laion.ai/images/blog/5b.png"
        },
        {
          "id": "https://www.bloomberg.com/features/2022-carlos-ghosn-escape-japan-freedom/",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/features/2022-carlos-ghosn-escape-japan-freedom/",
          "publishedOn": "2022-12-12T10:23:14.000Z",
          "wordCount": 576,
          "title": "Ghosn’s daring escape cost his extraction crew their freedom",
          "imageUrl": null
        },
        {
          "id": "https://www.youtube.com/watch?v=4LvaX748pVI",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=4LvaX748pVI",
          "publishedOn": "2022-12-12T08:51:56.000Z",
          "wordCount": null,
          "title": "I built a wildlife pond [video]",
          "imageUrl": null
        },
        {
          "id": "https://shkspr.mobi/blog/2022/12/how-much-decentralisation-is-too-much/",
          "author": null,
          "description": "Comments",
          "link": "https://shkspr.mobi/blog/2022/12/how-much-decentralisation-is-too-much/",
          "publishedOn": "2022-12-12T07:30:18.000Z",
          "wordCount": 3452,
          "title": "How much decentralisation is too much?",
          "imageUrl": "https://shkspr.mobi/blog/wp-content/uploads/2022/11/b4ceb19c9c54ec7e.png"
        },
        {
          "id": "https://en.wikipedia.org/wiki/Overlapping_markup",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/Overlapping_markup",
          "publishedOn": "2022-12-12T06:33:36.000Z",
          "wordCount": 4444,
          "title": "Overlapping markup",
          "imageUrl": null
        },
        {
          "id": "https://www.wired.com/story/the-extraordinary-shelf-life-of-the-deep-sea-sandwiches/",
          "author": null,
          "description": "Comments",
          "link": "https://www.wired.com/story/the-extraordinary-shelf-life-of-the-deep-sea-sandwiches/",
          "publishedOn": "2022-12-12T03:11:34.000Z",
          "wordCount": 21892,
          "title": "The extraordinary shelf life of the deep sea sandwiches",
          "imageUrl": "https://media.wired.com/photos/6392312c41224999a9db8bea/191:100/w_1280,c_limit/bologna_sandwich_science_GettyImages-176066417.jpg"
        },
        {
          "id": "https://www.washingtonpost.com/politics/2022/01/13/no-one-reads-terms-service-lawmakers-want-fix-that-with-new-tldr-bill/",
          "author": null,
          "description": "Comments",
          "link": "https://www.washingtonpost.com/politics/2022/01/13/no-one-reads-terms-service-lawmakers-want-fix-that-with-new-tldr-bill/",
          "publishedOn": "2022-12-12T01:17:27.000Z",
          "wordCount": 9662,
          "title": "No one reads the terms of service. Lawmakers want to fix that with 'TLDR' bill",
          "imageUrl": "https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/JVQYRUDT74I6ZITNDQQ4C2Y4SM.jpg&w=1440"
        },
        {
          "id": "https://lwn.net/Articles/917504/",
          "author": null,
          "description": "Comments",
          "link": "https://lwn.net/Articles/917504/",
          "publishedOn": "2022-12-12T01:09:26.000Z",
          "wordCount": 297,
          "title": "The 6.1 kernel is out",
          "imageUrl": null
        },
        {
          "id": "https://www.yannickoswald.com/post/are-you-a-nice-to-have-or-must-have",
          "author": null,
          "description": "Comments",
          "link": "https://www.yannickoswald.com/post/are-you-a-nice-to-have-or-must-have",
          "publishedOn": "2022-12-12T01:03:14.000Z",
          "wordCount": 16120,
          "title": "Are you a nice to have or a must have?",
          "imageUrl": "https://static.wixstatic.com/media/7926ce_e488269507dd403998eb52610bb4b9b2~mv2.png/v1/fit/w_1000%2Ch_987%2Cal_c/file.png"
        },
        {
          "id": "https://onformative.com/work/ai-sculpting/",
          "author": null,
          "description": "Comments",
          "link": "https://onformative.com/work/ai-sculpting/",
          "publishedOn": "2022-12-12T00:24:30.000Z",
          "wordCount": 3533,
          "title": "AI Sculpting",
          "imageUrl": "https://backend.onformative.com/assets/work/ai_sculpting_header.jpg"
        },
        {
          "id": "https://singularityhub.com/2022/12/11/astronomers-just-confirmed-the-most-ancient-galaxies-ever-observed/",
          "author": null,
          "description": "Comments",
          "link": "https://singularityhub.com/2022/12/11/astronomers-just-confirmed-the-most-ancient-galaxies-ever-observed/",
          "publishedOn": "2022-12-12T00:11:21.000Z",
          "wordCount": 16967,
          "title": "Astronomers Just Confirmed the Most Ancient Galaxies Ever Observed",
          "imageUrl": "https://singularityhub.com/wp-content/uploads/2022/12/james_webb_image_deep_field-1.jpeg"
        },
        {
          "id": "https://hackaday.com/2021/10/25/the-longest-ever-flight-was-over-64-days-in-a-cessna-172/",
          "author": null,
          "description": "Comments",
          "link": "https://hackaday.com/2021/10/25/the-longest-ever-flight-was-over-64-days-in-a-cessna-172/",
          "publishedOn": "2022-12-11T23:11:59.000Z",
          "wordCount": 5899,
          "title": "The longest ever flight was 64 days in a Cessna 172 (2021)",
          "imageUrl": "https://hackaday.com/wp-content/uploads/2021/10/LongestFlight.jpg"
        },
        {
          "id": "https://www.businessinsider.com/used-vehicle-retailer-carvana-bankruptcy-car-buyers-inventory-2022-12",
          "author": null,
          "description": "Comments",
          "link": "https://www.businessinsider.com/used-vehicle-retailer-carvana-bankruptcy-car-buyers-inventory-2022-12",
          "publishedOn": "2022-12-11T22:56:56.000Z",
          "wordCount": 3307,
          "title": "Carvana sees 98% of its market value evaporate",
          "imageUrl": "https://i.insider.com/6393589f8580f70019f82ebc?width=1200&format=jpeg"
        },
        {
          "id": "https://www.economist.com/asia/2022/12/08/japanese-manga-are-being-eclipsed-by-korean-webtoons",
          "author": null,
          "description": "Comments",
          "link": "https://www.economist.com/asia/2022/12/08/japanese-manga-are-being-eclipsed-by-korean-webtoons",
          "publishedOn": "2022-12-11T22:24:22.000Z",
          "wordCount": 8087,
          "title": "Japanese Manga are being eclipsed by Korean webtoons",
          "imageUrl": "https://www.economist.com/img/b/1280/720/90/media-assets/image/20221210_ASP003.jpg"
        },
        {
          "id": "https://github.com/RobinKa/jaxga",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/RobinKa/jaxga",
          "publishedOn": "2022-12-11T21:58:07.000Z",
          "wordCount": 1192,
          "title": "Jaxga: Geometric Algebra Library for Jax",
          "imageUrl": "https://opengraph.githubassets.com/3e7700ec55c4c9ee31426e55c6d7c4b7dec39f0cf1dc6dd6aa55a23cd0f0adb3/RobinKa/jaxga"
        },
        {
          "id": "https://kevquirk.com/is-dark-mode-such-a-good-idea/",
          "author": null,
          "description": "Comments",
          "link": "https://kevquirk.com/is-dark-mode-such-a-good-idea/",
          "publishedOn": "2022-12-11T21:36:24.000Z",
          "wordCount": 1559,
          "title": "Is Dark Mode Good for Your Eyes? (2020)",
          "imageUrl": "https://cdn.kevquirk.com/wp-content/uploads/2020/04/night-light-gnome-1024x613.png"
        },
        {
          "id": "https://www.washingtonpost.com/video-games/2022/12/08/diablo-iv-release-date-crunch/",
          "author": null,
          "description": "Comments",
          "link": "https://www.washingtonpost.com/video-games/2022/12/08/diablo-iv-release-date-crunch/",
          "publishedOn": "2022-12-11T21:30:44.000Z",
          "wordCount": 12472,
          "title": "‘Diablo IV’ developers work long hours, bracing for impending release",
          "imageUrl": "https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/NYODU5RN25ADHCHDX5TTTD2NFU.jpeg&w=1440"
        },
        {
          "id": "https://wingolog.org/archives/2022/12/11/we-iterate-so-that-you-can-recurse",
          "author": null,
          "description": "Comments",
          "link": "https://wingolog.org/archives/2022/12/11/we-iterate-so-that-you-can-recurse",
          "publishedOn": "2022-12-11T21:25:34.000Z",
          "wordCount": 1069,
          "title": "We iterate so that you can recurse",
          "imageUrl": null
        },
        {
          "id": "https://jakecoppinger.com/2022/12/creating-aerial-imagery-with-a-bike-helmet-camera-and-opendronemap/",
          "author": null,
          "description": "Comments",
          "link": "https://jakecoppinger.com/2022/12/creating-aerial-imagery-with-a-bike-helmet-camera-and-opendronemap/",
          "publishedOn": "2022-12-11T21:16:45.000Z",
          "wordCount": 3823,
          "title": "Creating aerial imagery with a bike helmet camera (GoPro) and OpenDroneMap",
          "imageUrl": "https://jakecoppinger.com/wp-content/uploads/2022/12/blender-perspective-scaled.jpg"
        },
        {
          "id": "https://onesignal.com/careers/4004540006",
          "author": null,
          "description": "Comments",
          "link": "https://onesignal.com/careers/4004540006",
          "publishedOn": "2022-12-11T21:01:59.000Z",
          "wordCount": 382,
          "title": "OneSignal (YC S11) Is Hiring a Product Engineer",
          "imageUrl": "https://media.onesignal.com/cms/_1200x630_crop_center-center_82_none/onesignal.jpg?mtime=1666043174"
        },
        {
          "id": "https://www.nightcap.guru/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nightcap.guru/",
          "publishedOn": "2022-12-11T20:46:50.000Z",
          "wordCount": 10,
          "title": "Using GPT3 to Interpret Dreams",
          "imageUrl": null
        },
        {
          "id": "https://github.com/KanHarI/gpt-commit-summarizer",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/KanHarI/gpt-commit-summarizer",
          "publishedOn": "2022-12-11T20:24:41.000Z",
          "wordCount": 1352,
          "title": "GPT based tool that writes the commit message for you",
          "imageUrl": "https://opengraph.githubassets.com/8e8d2a8762f881bb137b5591e0df27525e3006a49f2fa8f766eedccb10c0b552/KanHarI/gpt-commit-summarizer"
        },
        {
          "id": "https://simon.peytonjones.org/assets/pdfs/haskell-exchange-22.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://simon.peytonjones.org/assets/pdfs/haskell-exchange-22.pdf",
          "publishedOn": "2022-12-11T20:08:40.000Z",
          "wordCount": 79824,
          "title": "Beyond Functional Programming: The Verse Programming Language [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://www.kianryan.co.uk/2022-11-28-psion-sidecar-ppp-modem-and-terminal/",
          "author": null,
          "description": "Comments",
          "link": "https://www.kianryan.co.uk/2022-11-28-psion-sidecar-ppp-modem-and-terminal/",
          "publishedOn": "2022-12-11T19:54:09.000Z",
          "wordCount": 1891,
          "title": "Getting a Psion 5 palmtop from 1997 online via PPP (and a Raspberry Pi)",
          "imageUrl": "https://www.kianryan.co.uk/assets/images/2022/12/02/sidecar_hamsterdance.png"
        },
        {
          "id": "https://www.rbth.com/lifestyle/332384-video-games-soviet-russian-tetris",
          "author": null,
          "description": "Comments",
          "link": "https://www.rbth.com/lifestyle/332384-video-games-soviet-russian-tetris",
          "publishedOn": "2022-12-11T19:16:39.000Z",
          "wordCount": 2183,
          "title": "Video games made in the USSR",
          "imageUrl": "https://mf.b37mrtl.ru/rbthmedia/images/2020.07/article/5efcf4eb85600a6ece556cdf.jpg"
        },
        {
          "id": "https://dcic-world.org/2022-08-28/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://dcic-world.org/2022-08-28/index.html",
          "publishedOn": "2022-12-11T18:42:40.000Z",
          "wordCount": 1743,
          "title": "A data-centric introduction to computing",
          "imageUrl": null
        },
        {
          "id": "https://www.ft.com/content/4b6f0fab-66ef-4e33-adec-cfc345589dc7",
          "author": null,
          "description": "Comments",
          "link": "https://www.ft.com/content/4b6f0fab-66ef-4e33-adec-cfc345589dc7",
          "publishedOn": "2022-12-11T18:29:26.000Z",
          "wordCount": 1609,
          "title": "Fusion energy breakthrough by Livermore Lab",
          "imageUrl": null
        },
        {
          "id": "https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/",
          "author": null,
          "description": "Comments",
          "link": "https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/",
          "publishedOn": "2022-12-11T18:12:34.000Z",
          "wordCount": 7944,
          "title": "What's wrong with social science and how to fix it (2020)",
          "imageUrl": "https://fantasticanachronism.com/images/skimmed_twitter_card.png"
        },
        {
          "id": "https://elastic.github.io/eui/#/",
          "author": null,
          "description": "Comments",
          "link": "https://elastic.github.io/eui/#/",
          "publishedOn": "2022-12-11T17:28:04.000Z",
          "wordCount": 2,
          "title": "Elastic UI – Component library for data-driven web apps",
          "imageUrl": "https://repository-images.githubusercontent.com/107422373/b6180480-a1d7-11eb-8a3c-902086232aa7"
        },
        {
          "id": "https://www.philipotoole.com/how-i-found-a-bug-in-sqlite/",
          "author": null,
          "description": "Comments",
          "link": "https://www.philipotoole.com/how-i-found-a-bug-in-sqlite/",
          "publishedOn": "2022-12-11T17:18:27.000Z",
          "wordCount": 1977,
          "title": "I found a bug in SQLite",
          "imageUrl": "https://www.philipotoole.com/wp-content/uploads/2022/12/bug.png"
        },
        {
          "id": "https://research.nccgroup.com/2022/12/09/public-report-vpn-by-google-one-security-assessment/",
          "author": null,
          "description": "Comments",
          "link": "https://research.nccgroup.com/2022/12/09/public-report-vpn-by-google-one-security-assessment/",
          "publishedOn": "2022-12-11T16:46:53.000Z",
          "wordCount": 1577,
          "title": "VPN by Google One security assessment",
          "imageUrl": "https://i0.wp.com/research.nccgroup.com/wp-content/uploads/2020/07/cropped-Gwl5Lrim_400x400-1.jpg?fit=512%2C512&ssl=1"
        },
        {
          "id": "https://spectrum.ieee.org/airship",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/airship",
          "publishedOn": "2022-12-11T16:46:22.000Z",
          "wordCount": 10269,
          "title": "LTA Research’s Pathfinder 1",
          "imageUrl": "https://spectrum.ieee.org/media-library/people-are-arranged-around-the-rear-end-of-a-white-cylindrical-airship-above-a-white-floor-and-inside-of-a-large-aircraft-hange.jpg?id=32252504&width=1200&height=600&coordinates=0%2C183%2C0%2C184"
        },
        {
          "id": "https://sigmodrecord.org/publications/sigmodRecord/1906/pdfs/06_Profiles_Hipp.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://sigmodrecord.org/publications/sigmodRecord/1906/pdfs/06_Profiles_Hipp.pdf",
          "publishedOn": "2022-12-11T16:00:00.000Z",
          "wordCount": 84174,
          "title": "Richard Hipp Speaks Out on SQLite (2019) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://dugas.ch/artificial_curiosity/GPT_architecture.html",
          "author": null,
          "description": "Comments",
          "link": "https://dugas.ch/artificial_curiosity/GPT_architecture.html",
          "publishedOn": "2022-12-11T12:29:41.000Z",
          "wordCount": 1992,
          "title": "The GPT Architecture, on a Napkin",
          "imageUrl": null
        },
        {
          "id": "https://www.science.org/content/article/ai-unmasks-anonymous-chess-players-posing-privacy-risks",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/content/article/ai-unmasks-anonymous-chess-players-posing-privacy-risks",
          "publishedOn": "2022-12-11T12:09:46.000Z",
          "wordCount": 2329,
          "title": "AI unmasks anonymous chess players, posing privacy risks",
          "imageUrl": "https://www.science.org/do/10.1126/science.ada0080/abs/_20210114_nid_chess.jpg"
        },
        {
          "id": "https://github.com/oyvindln/vhs-decode",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/oyvindln/vhs-decode",
          "publishedOn": "2022-12-11T12:07:50.000Z",
          "wordCount": 3748,
          "title": "VHS-Decode – Software defined VHS decoder",
          "imageUrl": "https://opengraph.githubassets.com/473589da42d7b239f499790e1b2d55748591d17f1929232e53e5b196f4051d17/oyvindln/vhs-decode"
        },
        {
          "id": "https://crypto.junod.info/posts/recursive-hash/",
          "author": null,
          "description": "Comments",
          "link": "https://crypto.junod.info/posts/recursive-hash/",
          "publishedOn": "2022-12-11T11:32:20.000Z",
          "wordCount": 6659,
          "title": "Hashing Apples, Bananas and Cherries",
          "imageUrl": null
        },
        {
          "id": "https://www.atlasobscura.com/articles/white-olives",
          "author": null,
          "description": "Comments",
          "link": "https://www.atlasobscura.com/articles/white-olives",
          "publishedOn": "2022-12-11T05:10:35.000Z",
          "wordCount": 5616,
          "title": "Rediscovering Calabria’s Mystical White Olives",
          "imageUrl": "https://img.atlasobscura.com/2tDJaHnTs7nFlufv2--P-RkQBqgW0yEGGxbLvqmnqOQ/rt:fit/w:600/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy9iZjQ4ODIxMC02/MzA3LTRmN2ItYWM4/YS1hZDU1MjNhN2Iw/ODM3OGU5MmZiMDc3/ZjczZTU2ZDdfd2hp/dGVfb2xpdmVzLmpw/Zw.jpg"
        },
        {
          "id": "https://www.nytimes.com/2022/12/09/science/puzzles-jigsaw-math.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/12/09/science/puzzles-jigsaw-math.html",
          "publishedOn": "2022-12-11T04:45:43.000Z",
          "wordCount": null,
          "title": "Taking jigsaw puzzles to infinity and beyond",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/zemotion/status/1600529480099196928",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/zemotion/status/1600529480099196928",
          "publishedOn": "2022-12-11T00:43:21.000Z",
          "wordCount": 470,
          "title": "Copyright denied as pose lacks originality",
          "imageUrl": null
        },
        {
          "id": "https://www.cbsnews.com/news/one-pilot-in-cockpit-staffing-shortage-faa-part-121/",
          "author": null,
          "description": "Comments",
          "link": "https://www.cbsnews.com/news/one-pilot-in-cockpit-staffing-shortage-faa-part-121/",
          "publishedOn": "2022-12-10T23:01:02.000Z",
          "wordCount": 1837,
          "title": "Airlines lobbying FAA to have only one pilot in the cockpit",
          "imageUrl": "https://assets2.cbsnewsstatic.com/hub/i/r/2015/11/23/39a3fb9f-cf91-4ad6-86e0-ef7afb500020/thumbnail/1200x630/dbbee551aa6765a80b66fdd40a1b08a9/miracle-on-the-hudson.jpg"
        },
        {
          "id": "https://notesbylex.com/disputing-a-parking-fine-with-chatgpt.html",
          "author": null,
          "description": "Comments",
          "link": "https://notesbylex.com/disputing-a-parking-fine-with-chatgpt.html",
          "publishedOn": "2022-12-10T22:40:10.000Z",
          "wordCount": 343,
          "title": "Disputing a Parking Fine with ChatGPT",
          "imageUrl": "https://notesbylex.com/_media/cover-parking-fine.png"
        },
        {
          "id": "https://www.trains.com/trn/news-reviews/news-wire/amtrak-asks-federal-regulators-to-investigate-union-pacific-handling-of-sunset-limited/",
          "author": null,
          "description": "Comments",
          "link": "https://www.trains.com/trn/news-reviews/news-wire/amtrak-asks-federal-regulators-to-investigate-union-pacific-handling-of-sunset-limited/",
          "publishedOn": "2022-12-10T22:29:59.000Z",
          "wordCount": 31333,
          "title": "Amtrak asks fed regulators to investigate Union Pacific handling of Sunset Ltd",
          "imageUrl": "https://www.trains.com/wp-content/uploads/2022/10/TRN_Sunset_Limited_Johnston.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33936862",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33936862",
          "publishedOn": "2022-12-10T21:13:54.000Z",
          "wordCount": 8730,
          "title": "Tell HN: HP printers force you into agreement",
          "imageUrl": null
        },
        {
          "id": "https://www.cs.yale.edu/publications/techreports/tr1049.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://www.cs.yale.edu/publications/techreports/tr1049.pdf",
          "publishedOn": "2022-12-10T20:14:21.000Z",
          "wordCount": 78053,
          "title": "Haskell, Ada, C++, Awk: An Experiment in Prototyping Productivity (1994) [pdf]",
          "imageUrl": null
        },
        {
          "id": "http://people.uncw.edu/ricanekk/teaching/spring09/csc100/lectures/pattersone/TheMakingOfToyStory.pdf",
          "author": null,
          "description": "Comments",
          "link": "http://people.uncw.edu/ricanekk/teaching/spring09/csc100/lectures/pattersone/TheMakingOfToyStory.pdf",
          "publishedOn": "2022-12-10T20:08:21.000Z",
          "wordCount": 34137,
          "title": "The Making of Toy Story (1996) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://4gravitons.com/2022/12/09/simulated-wormholes-for-my-real-friends-real-wormholes-for-my-simulated-friends/",
          "author": null,
          "description": "Comments",
          "link": "https://4gravitons.com/2022/12/09/simulated-wormholes-for-my-real-friends-real-wormholes-for-my-simulated-friends/",
          "publishedOn": "2022-12-10T20:07:31.000Z",
          "wordCount": 5225,
          "title": "Simulated wormholes for my real friends, real wormholes for my simulated friends",
          "imageUrl": "https://4gravitons.files.wordpress.com/2022/12/quantapreviousheadline.jpg"
        },
        {
          "id": "https://slimvoice.co/login",
          "author": null,
          "description": "Comments",
          "link": "https://slimvoice.co/login",
          "publishedOn": "2022-12-10T19:13:49.000Z",
          "wordCount": 108,
          "title": "Sign in with Google has been removed for your privacy",
          "imageUrl": "https://slimvoice.co/static/img/social_og.png"
        },
        {
          "id": "https://news.yale.edu/2015/09/22/living-artifact-dutch-golden-age-yale-s-367-year-old-water-bond-still-pays-interest",
          "author": null,
          "description": "Comments",
          "link": "https://news.yale.edu/2015/09/22/living-artifact-dutch-golden-age-yale-s-367-year-old-water-bond-still-pays-interest",
          "publishedOn": "2022-12-10T18:56:51.000Z",
          "wordCount": 2169,
          "title": "Yale’s 367-year-old water bond still pays interest (2015)",
          "imageUrl": "https://news.yale.edu/sites/default/files/styles/opengraph_image/public/thumbnail/yale-dutch-water-bond.jpg?itok=FtcU7VR5"
        },
        {
          "id": "https://www.trains.com/trn/news-reviews/news-wire/groundbreaking-marks-start-of-work-on-penn-station-access/",
          "author": null,
          "description": "Comments",
          "link": "https://www.trains.com/trn/news-reviews/news-wire/groundbreaking-marks-start-of-work-on-penn-station-access/",
          "publishedOn": "2022-12-10T18:51:38.000Z",
          "wordCount": 30089,
          "title": "Groundbreaking marks start of work on Penn Station Access",
          "imageUrl": "https://www.trains.com/wp-content/uploads/2022/12/TRN_Penn_Access_groundbreaking.jpg"
        },
        {
          "id": "https://research.american.edu/carbonremoval/2020/09/29/fuel-out-of-thin-air-co2-capture-from-air-and-conversion-to-methanol/",
          "author": null,
          "description": "Comments",
          "link": "https://research.american.edu/carbonremoval/2020/09/29/fuel-out-of-thin-air-co2-capture-from-air-and-conversion-to-methanol/",
          "publishedOn": "2022-12-10T18:34:48.000Z",
          "wordCount": 1984,
          "title": "Fuel out of thin air: CO2 capture from air and conversion to methanol (2020)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/albfan/miraclecast",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/albfan/miraclecast",
          "publishedOn": "2022-12-10T18:23:28.000Z",
          "wordCount": 1560,
          "title": "MiracleCast",
          "imageUrl": "https://opengraph.githubassets.com/fb4b08068c005954b7a2978ba1a3ce2b9a4c6f25af96d43310aadaa8bb768a3f/albfan/miraclecast"
        },
        {
          "id": "https://www.alma.sh/",
          "author": null,
          "description": "Comments",
          "link": "https://www.alma.sh/",
          "publishedOn": "2022-12-10T17:48:38.000Z",
          "wordCount": 9,
          "title": "Alma – Generative Graphics Creator",
          "imageUrl": null
        },
        {
          "id": "https://lab.whitequark.org/notes/2020-04-06/synthesizing-optimal-8051-code/",
          "author": null,
          "description": "Comments",
          "link": "https://lab.whitequark.org/notes/2020-04-06/synthesizing-optimal-8051-code/",
          "publishedOn": "2022-12-10T17:39:06.000Z",
          "wordCount": 2883,
          "title": "Synthesizing optimal 8051 code with an SMT solver (2020)",
          "imageUrl": null
        },
        {
          "id": "http://triskweline.de/unpoly-rugb/#/",
          "author": null,
          "description": "Comments",
          "link": "http://triskweline.de/unpoly-rugb/#/",
          "publishedOn": "2022-12-10T17:35:12.000Z",
          "wordCount": 4098,
          "title": "Breaking up with JavaScript front ends",
          "imageUrl": null
        },
        {
          "id": "https://thebaffler.com/salvos/the-father-of-all-secrets-adler-bell",
          "author": null,
          "description": "Comments",
          "link": "https://thebaffler.com/salvos/the-father-of-all-secrets-adler-bell",
          "publishedOn": "2022-12-10T17:15:12.000Z",
          "wordCount": 6415,
          "title": "The father of all secrets: John le Carré’s daddy issues",
          "imageUrl": "https://thebaffler.com/wp-content/uploads/2022/12/b66-adler-bell-scaled.jpg"
        },
        {
          "id": "https://www.quantamagazine.org/what-causes-alzheimers-scientists-are-rethinking-the-answer-20221208/",
          "author": null,
          "description": "Comments",
          "link": "https://www.quantamagazine.org/what-causes-alzheimers-scientists-are-rethinking-the-answer-20221208/",
          "publishedOn": "2022-12-10T17:02:00.000Z",
          "wordCount": 22140,
          "title": "What causes Alzheimer's? Scientists are rethinking the answer",
          "imageUrl": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/12/Alzheimer-byHarolBustos-Social.webp"
        },
        {
          "id": "https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/",
          "author": null,
          "description": "Comments",
          "link": "https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/",
          "publishedOn": "2022-12-10T16:55:33.000Z",
          "wordCount": 9198,
          "title": "DDD, Hexagonal, Onion, Clean, CQRS, How I put it all together (2017)",
          "imageUrl": "https://herbertograca.files.wordpress.com/2018/11/100-explicit-architecture-svg.png?w=1200"
        },
        {
          "id": "https://www.amazingcto.com/postgres-for-everything/",
          "author": null,
          "description": "Comments",
          "link": "https://www.amazingcto.com/postgres-for-everything/",
          "publishedOn": "2022-12-10T16:52:58.000Z",
          "wordCount": 1321,
          "title": "Just use Postgres for everything",
          "imageUrl": "/Amazing_CTO_Banner.png"
        },
        {
          "id": "https://arxiv.org/abs/2212.03551",
          "author": null,
          "description": "Comments",
          "link": "https://arxiv.org/abs/2212.03551",
          "publishedOn": "2022-12-10T16:12:02.000Z",
          "wordCount": 573,
          "title": "Talking About Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33932594",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33932594",
          "publishedOn": "2022-12-10T13:51:32.000Z",
          "wordCount": 8298,
          "title": "Ask HN: How to get back into AI?",
          "imageUrl": null
        },
        {
          "id": "http://groups.di.unipi.it/~nids/docs/the_plan-9_effect.html",
          "author": null,
          "description": "Comments",
          "link": "http://groups.di.unipi.it/~nids/docs/the_plan-9_effect.html",
          "publishedOn": "2022-12-10T13:05:43.000Z",
          "wordCount": 1707,
          "title": "The Plan-9 Effect or why you should not fix it if it ain't broken (2016)",
          "imageUrl": null
        },
        {
          "id": "https://supabase.com/blog/postgres-crdt",
          "author": null,
          "description": "Comments",
          "link": "https://supabase.com/blog/postgres-crdt",
          "publishedOn": "2022-12-10T12:20:24.000Z",
          "wordCount": 8562,
          "title": "Show HN: Pg_CRDT – an experimental CRDT extension for Postgres",
          "imageUrl": "https://supabase.com/images/blog/crdt/crdt-blog.png"
        },
        {
          "id": "https://tauri.app/blog/2022/12/09/tauri-mobile-alpha/",
          "author": null,
          "description": "Comments",
          "link": "https://tauri.app/blog/2022/12/09/tauri-mobile-alpha/",
          "publishedOn": "2022-12-10T10:22:59.000Z",
          "wordCount": 202,
          "title": "Tauri Mobile Alpha Release",
          "imageUrl": "https://tauri.app/assets/images/header-ae623d29abbe5d2ca2509b55e215d83c.png"
        },
        {
          "id": "https://www.consilium.europa.eu/en/press/press-releases/2022/12/07/anti-money-laundering-council-agrees-its-position-on-a-strengthened-rulebook/",
          "author": null,
          "description": "Comments",
          "link": "https://www.consilium.europa.eu/en/press/press-releases/2022/12/07/anti-money-laundering-council-agrees-its-position-on-a-strengthened-rulebook/",
          "publishedOn": "2022-12-10T10:05:25.000Z",
          "wordCount": 1713,
          "title": "EU-wide maximum limit of €10K for cash payments",
          "imageUrl": "https://www.consilium.europa.eu/media/60608/20221207-anti-money-laundering-press-release.png"
        },
        {
          "id": "http://www.paulgraham.com/identity.html",
          "author": null,
          "description": "Comments",
          "link": "http://www.paulgraham.com/identity.html",
          "publishedOn": "2022-12-10T09:57:08.000Z",
          "wordCount": 1034,
          "title": "Keep Your Identity Small (2009)",
          "imageUrl": null
        },
        {
          "id": "https://hackaday.com/2022/12/07/recreating-the-sounds-of-the-90s-with-a-ym3812-synthesizer/",
          "author": null,
          "description": "Comments",
          "link": "https://hackaday.com/2022/12/07/recreating-the-sounds-of-the-90s-with-a-ym3812-synthesizer/",
          "publishedOn": "2022-12-10T09:46:44.000Z",
          "wordCount": 2565,
          "title": "Recreating the Sounds of the ’90s with a YM3812 Synthesizer",
          "imageUrl": "https://hackaday.com/wp-content/uploads/2022/12/YM3812-Synthesizer.png"
        },
        {
          "id": "https://www.thistothat.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.thistothat.com/",
          "publishedOn": "2022-12-10T07:22:41.000Z",
          "wordCount": 84,
          "title": "This to That",
          "imageUrl": "http://www.thistothat.com/icon/thistothat_big_icon.png"
        },
        {
          "id": "https://en.wikipedia.org/wiki/NEEMO",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/NEEMO",
          "publishedOn": "2022-12-10T04:02:48.000Z",
          "wordCount": 3304,
          "title": "NEEMO",
          "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/e/ef/NEEMO_Program_Seal.png"
        },
        {
          "id": "https://stancarey.wordpress.com/2013/11/27/yan-tan-tethera-pethera-pimp-an-old-system-for-counting-sheep/",
          "author": null,
          "description": "Comments",
          "link": "https://stancarey.wordpress.com/2013/11/27/yan-tan-tethera-pethera-pimp-an-old-system-for-counting-sheep/",
          "publishedOn": "2022-12-10T03:13:51.000Z",
          "wordCount": 5839,
          "title": "Yan tan tethera pethera pimp – an old system for counting sheep (2013)",
          "imageUrl": "https://stancarey.files.wordpress.com/2013/11/stan-carey-herd-of-sheep-in-ireland-spring-2009-yan-tan-tethera.jpg"
        },
        {
          "id": "https://twitter.com/emirkarsiyakali/status/1601373440979525632",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/emirkarsiyakali/status/1601373440979525632",
          "publishedOn": "2022-12-10T00:32:43.000Z",
          "wordCount": 470,
          "title": "$850 USD to renew your own .dev domain which is owned by Google, insane",
          "imageUrl": null
        },
        {
          "id": "https://www.nature.com/articles/ng.3285",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/articles/ng.3285",
          "publishedOn": "2022-12-10T00:30:07.000Z",
          "wordCount": 4605,
          "title": "Analysis of twin studies provide evidence that all human traits are heritable",
          "imageUrl": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fng.3285/MediaObjects/41588_2015_Article_BFng3285_Fig1_HTML.jpg"
        },
        {
          "id": "http://personal.garrettfuller.org/blog/2018/01/19/att-long-lines-a-forgotten-system/",
          "author": null,
          "description": "Comments",
          "link": "http://personal.garrettfuller.org/blog/2018/01/19/att-long-lines-a-forgotten-system/",
          "publishedOn": "2022-12-09T23:20:30.000Z",
          "wordCount": 3404,
          "title": "AT&T Long Lines – A Forgotten System (2018)",
          "imageUrl": null
        },
        {
          "id": "https://www.plai.org/",
          "author": null,
          "description": "Comments",
          "link": "https://www.plai.org/",
          "publishedOn": "2022-12-09T22:08:36.000Z",
          "wordCount": 607,
          "title": "Programming Languages: Application and Interpretation, 3rd Ed",
          "imageUrl": null
        },
        {
          "id": "https://github.com/R9295/panoptisch",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/R9295/panoptisch",
          "publishedOn": "2022-12-09T21:45:50.000Z",
          "wordCount": 1017,
          "title": "Show HN: Panoptisch – A recursive dependency scanner for Python projects",
          "imageUrl": "https://opengraph.githubassets.com/4b3793f8a437dba163eb0af352673bffc1da0905dd5bd79c57e2a2a2bd524882/R9295/panoptisch"
        },
        {
          "id": "https://www.canarymedia.com/articles/solar/a-100mw-solar-farm-in-texas-will-mount-panels-directly-on-the-ground",
          "author": null,
          "description": "Comments",
          "link": "https://www.canarymedia.com/articles/solar/a-100mw-solar-farm-in-texas-will-mount-panels-directly-on-the-ground",
          "publishedOn": "2022-12-09T21:33:46.000Z",
          "wordCount": 1269,
          "title": "A 100MW solar farm in Texas will mount panels directly on the ground",
          "imageUrl": "https://img.canarymedia.com/content/uploads/resized-erthos-solar-ground-mount.jpg?auto=compress,format&crop=focalpoint&fit=crop&fp-x=0.5&fp-y=0.5&h=630&w=1200&s=ebc07fc367f511c18ffdc38f2ed37146"
        },
        {
          "id": "https://www.ft.com/content/8cd27d16-c996-4dc7-86af-ed6f40ff361c",
          "author": null,
          "description": "Comments",
          "link": "https://www.ft.com/content/8cd27d16-c996-4dc7-86af-ed6f40ff361c",
          "publishedOn": "2022-12-09T21:28:20.000Z",
          "wordCount": 1631,
          "title": "Apple to end employee gagging clauses after activist campaign",
          "imageUrl": null
        },
        {
          "id": "https://wiki.xxiivv.com/site/uxn.html",
          "author": null,
          "description": "Comments",
          "link": "https://wiki.xxiivv.com/site/uxn.html",
          "publishedOn": "2022-12-09T21:23:39.000Z",
          "wordCount": 359,
          "title": "Uxn is a virtual machine with 32 instructions",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/torynski/status/1600968583055826944",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/torynski/status/1600968583055826944",
          "publishedOn": "2022-12-09T21:19:32.000Z",
          "wordCount": 470,
          "title": "The Tesla Semi cab from the practical POV of someone who drives trucks",
          "imageUrl": null
        },
        {
          "id": "https://redmonk.com/sogrady/2022/12/09/faster-horse/",
          "author": null,
          "description": "Comments",
          "link": "https://redmonk.com/sogrady/2022/12/09/faster-horse/",
          "publishedOn": "2022-12-09T21:06:01.000Z",
          "wordCount": 3923,
          "title": "A Faster Horse",
          "imageUrl": "http://redmonk.com/sogrady/files/2022/12/2559505386_ff294c80c1_o.jpg"
        },
        {
          "id": "https://github.com/charmbracelet/glow",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/charmbracelet/glow",
          "publishedOn": "2022-12-09T19:53:46.000Z",
          "wordCount": 1608,
          "title": "Glow: Render Markdown on the CLI",
          "imageUrl": "https://repository-images.githubusercontent.com/219616873/fe4a7a80-d35b-11ea-8d24-b5d2c931479a"
        },
        {
          "id": "https://groups.google.com/a/chromium.org/g/chromium-extensions/c/zQ77HkGmK9E",
          "author": null,
          "description": "Comments",
          "link": "https://groups.google.com/a/chromium.org/g/chromium-extensions/c/zQ77HkGmK9E",
          "publishedOn": "2022-12-09T19:53:10.000Z",
          "wordCount": 12204,
          "title": "Pausing Manifest V2 phase-out changes",
          "imageUrl": null
        },
        {
          "id": "https://fireship.io/",
          "author": null,
          "description": "Comments",
          "link": "https://fireship.io/",
          "publishedOn": "2022-12-09T19:04:03.000Z",
          "wordCount": 174,
          "title": "Fireship – Learn to Code Faster",
          "imageUrl": "https://fireship.io/img/default-cover.png"
        },
        {
          "id": "https://matthias-research.github.io/pages/tenMinutePhysics/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://matthias-research.github.io/pages/tenMinutePhysics/index.html",
          "publishedOn": "2022-12-09T18:50:57.000Z",
          "wordCount": 1019,
          "title": "Ten Minute Physics",
          "imageUrl": null
        },
        {
          "id": "https://arxiv.org/abs/2104.12653",
          "author": null,
          "description": "Comments",
          "link": "https://arxiv.org/abs/2104.12653",
          "publishedOn": "2022-12-09T18:43:42.000Z",
          "wordCount": 667,
          "title": "Dark patterns from the end-user perspective",
          "imageUrl": null
        },
        {
          "id": "https://chipsandcheese.com/2022/12/08/knights-landing-atom-with-avx-512/",
          "author": null,
          "description": "Comments",
          "link": "https://chipsandcheese.com/2022/12/08/knights-landing-atom-with-avx-512/",
          "publishedOn": "2022-12-09T18:42:50.000Z",
          "wordCount": 9416,
          "title": "Knight’s Landing: Atom with AVX-512",
          "imageUrl": "https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/knl_dn.jpg?fit=1024%2C675&ssl=1"
        },
        {
          "id": "https://jvns.ca/blog/2018/01/28/mac-freeze/",
          "author": null,
          "description": "Comments",
          "link": "https://jvns.ca/blog/2018/01/28/mac-freeze/",
          "publishedOn": "2022-12-09T18:28:58.000Z",
          "wordCount": 837,
          "title": "I think I found a Mac kernel bug (2018)",
          "imageUrl": null
        },
        {
          "id": "https://www.learngpt.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.learngpt.com/",
          "publishedOn": "2022-12-09T17:21:22.000Z",
          "wordCount": 384,
          "title": "Show HN: LearnGPT – Browse and share ChatGPT examples",
          "imageUrl": "https://www.learngpt.com/assets/thumbnail-aafe18c8b54dc9f0e19fce00705f9c1590fe1956514ac70b3a99791c6b0aefdf.png"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33923137",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33923137",
          "publishedOn": "2022-12-09T16:28:10.000Z",
          "wordCount": 8646,
          "title": "Ask HN: What is the best income stream you have created till date?",
          "imageUrl": null
        },
        {
          "id": "https://github.com/pynecone-io/pynecone",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/pynecone-io/pynecone",
          "publishedOn": "2022-12-09T16:00:32.000Z",
          "wordCount": 1611,
          "title": "Show HN: Pynecone – Web Apps in Pure Python",
          "imageUrl": "https://repository-images.githubusercontent.com/557075997/562346db-fd58-4802-a066-cfd83d846395"
        },
        {
          "id": "https://github.com/eamonnsullivan/backup-scripts",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/eamonnsullivan/backup-scripts",
          "publishedOn": "2022-12-09T15:27:31.000Z",
          "wordCount": 1562,
          "title": "The various scripts I use to back up my home computers using SSH and rsync",
          "imageUrl": "https://opengraph.githubassets.com/e2520c4a17d9bc77fc2adb26c0a421f9644454cb054c29747595b12de4b106b6/eamonnsullivan/backup-scripts"
        },
        {
          "id": "https://github.com/getlago/lago/wiki/Stripe%27s-real-pricing:-a-primer",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/getlago/lago/wiki/Stripe%27s-real-pricing:-a-primer",
          "publishedOn": "2022-12-09T11:01:49.000Z",
          "wordCount": 1310,
          "title": "Stripe’s real pricing: a primer",
          "imageUrl": "https://opengraph.githubassets.com/420f963b3d9a100b2499266a6ee7eab039adadf43f29ccc3440cc09d4b487030/getlago/lago"
        },
        {
          "id": "https://nuitka.net/posts/all-in-with-nuitka.html",
          "author": null,
          "description": "Comments",
          "link": "https://nuitka.net/posts/all-in-with-nuitka.html",
          "publishedOn": "2022-12-09T10:36:03.000Z",
          "wordCount": 1169,
          "title": "All in with Nuitka",
          "imageUrl": null
        },
        {
          "id": "https://scholar.archive.org/",
          "author": null,
          "description": "Comments",
          "link": "https://scholar.archive.org/",
          "publishedOn": "2022-12-09T10:35:25.000Z",
          "wordCount": null,
          "title": "Internet Archive Scholar",
          "imageUrl": null
        },
        {
          "id": "https://retrocomputing.stackexchange.com/questions/2361/why-does-the-commodore-c128-perform-poorly-when-running-cp-m",
          "author": null,
          "description": "Comments",
          "link": "https://retrocomputing.stackexchange.com/questions/2361/why-does-the-commodore-c128-perform-poorly-when-running-cp-m",
          "publishedOn": "2022-12-09T08:14:17.000Z",
          "wordCount": 8785,
          "title": "Why does the Commodore C128 perform poorly when running CP/M?",
          "imageUrl": "https://cdn.sstatic.net/Sites/retrocomputing/Img/apple-touch-icon@2.png?v=6b27f39a6023"
        },
        {
          "id": "https://www.planeandpilotmag.com/news/the-latest/2022/11/30/dallas-midair-tragedy-new-video-shows-startling-change-in-flight-path-of-p-63/",
          "author": null,
          "description": "Comments",
          "link": "https://www.planeandpilotmag.com/news/the-latest/2022/11/30/dallas-midair-tragedy-new-video-shows-startling-change-in-flight-path-of-p-63/",
          "publishedOn": "2022-12-09T00:17:51.000Z",
          "wordCount": null,
          "title": "Dallas midair tragedy: New videos show startling change in flight path of p-63",
          "imageUrl": null
        },
        {
          "id": "https://statmodeling.stat.columbia.edu/2022/12/08/the-cleantech-job-market-every-modeler-is-supposed-to-be-a-great-python-programmer/",
          "author": null,
          "description": "Comments",
          "link": "https://statmodeling.stat.columbia.edu/2022/12/08/the-cleantech-job-market-every-modeler-is-supposed-to-be-a-great-python-programmer/",
          "publishedOn": "2022-12-08T22:13:13.000Z",
          "wordCount": 7209,
          "title": "Every modeler is supposed to be a great Python programmer",
          "imageUrl": null
        },
        {
          "id": "https://www.moma.org/magazine/articles/677",
          "author": null,
          "description": "Comments",
          "link": "https://www.moma.org/magazine/articles/677",
          "publishedOn": "2022-12-08T22:04:52.000Z",
          "wordCount": null,
          "title": "Taking a Walk Across the Internet",
          "imageUrl": null
        },
        {
          "id": "https://alphacode.deepmind.com/",
          "author": null,
          "description": "Comments",
          "link": "https://alphacode.deepmind.com/",
          "publishedOn": "2022-12-08T21:54:26.000Z",
          "wordCount": 4837,
          "title": "AlphaCode Attention Visualization",
          "imageUrl": null
        },
        {
          "id": "https://www.asbestos.com/products/cigarette-filters/",
          "author": null,
          "description": "Comments",
          "link": "https://www.asbestos.com/products/cigarette-filters/",
          "publishedOn": "2022-12-08T21:47:29.000Z",
          "wordCount": 5281,
          "title": "Asbestos Cigarette Filters (2018)",
          "imageUrl": "https://www.asbestos.com/wp-content/uploads/asbestos-cigarette-filter.jpg"
        },
        {
          "id": "https://jameswillia.ms/posts/chatgpt-rot13.html",
          "author": null,
          "description": "Comments",
          "link": "https://jameswillia.ms/posts/chatgpt-rot13.html",
          "publishedOn": "2022-12-08T21:37:13.000Z",
          "wordCount": 428,
          "title": "ChatGPT, Rot13, and Daniel Kahneman",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33913332",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33913332",
          "publishedOn": "2022-12-08T21:00:11.000Z",
          "wordCount": 170,
          "title": "Generally Intelligent (YC S17) is hiring senior software engineers",
          "imageUrl": null
        },
        {
          "id": "https://nymag.com/intelligencer/2017/07/climate-change-earth-too-hot-for-humans.html",
          "author": null,
          "description": "Comments",
          "link": "https://nymag.com/intelligencer/2017/07/climate-change-earth-too-hot-for-humans.html",
          "publishedOn": "2022-12-08T20:56:22.000Z",
          "wordCount": 35804,
          "title": "The Uninhabitable Earth (2017)",
          "imageUrl": "https://pyxis.nymag.com/v1/imgs/dd2/d0d/a46ee9b49786d4798f841d2abcfb39d3d7-07-climate-change-1.1x.rsocial.w1200.jpg"
        },
        {
          "id": "https://lithub.com/napoleonic-conspiracy-theories-unsociable-shabbiness-and-more-occupational-hazards-of-the-second-hand-book-trade/",
          "author": null,
          "description": "Comments",
          "link": "https://lithub.com/napoleonic-conspiracy-theories-unsociable-shabbiness-and-more-occupational-hazards-of-the-second-hand-book-trade/",
          "publishedOn": "2022-12-08T20:53:34.000Z",
          "wordCount": 5597,
          "title": "Occupational Hazards of the Second-Hand Book Trade",
          "imageUrl": "https://s26162.pcdn.co/wp-content/uploads/2021/10/niche-bookstores.png"
        },
        {
          "id": "https://ziglang.org/news/goodbye-cpp/",
          "author": null,
          "description": "Comments",
          "link": "https://ziglang.org/news/goodbye-cpp/",
          "publishedOn": "2022-12-08T20:53:12.000Z",
          "wordCount": 2878,
          "title": "Goodbye to the C++ Implementation of Zig",
          "imageUrl": null
        },
        {
          "id": "https://commonreader.substack.com/p/how-to-write-like-malcolm-gladwell",
          "author": null,
          "description": "Comments",
          "link": "https://commonreader.substack.com/p/how-to-write-like-malcolm-gladwell",
          "publishedOn": "2022-12-08T20:50:47.000Z",
          "wordCount": 6909,
          "title": "How to write like Malcolm Gladwell",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F93e1bbdc-62a5-4c1d-b943-3ce86fecdb57_2818x2850.webp"
        },
        {
          "id": "https://news.livebook.dev/announcing-bumblebee-gpt2-stable-diffusion-and-more-in-elixir-3Op73O",
          "author": null,
          "description": "Comments",
          "link": "https://news.livebook.dev/announcing-bumblebee-gpt2-stable-diffusion-and-more-in-elixir-3Op73O",
          "publishedOn": "2022-12-08T20:49:01.000Z",
          "wordCount": 642,
          "title": "Bumblebee: GPT2, Stable Diffusion, and More in Elixir",
          "imageUrl": "https://img.announcekit.app/d72c14ae799fe88b23e2116fdc9c2097?s=28da628bd20bd9e5c824681ffa3209bd"
        },
        {
          "id": "https://jonathongreen.substack.com/p/stories-of-slang",
          "author": null,
          "description": "Comments",
          "link": "https://jonathongreen.substack.com/p/stories-of-slang",
          "publishedOn": "2022-12-08T20:46:10.000Z",
          "wordCount": 10532,
          "title": "Sailors Beware: Stories of Slang",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F021abbdb-ffaf-4093-91dc-2efa695b2c8b_1083x768.jpeg"
        },
        {
          "id": "https://spectrum.ieee.org/adobe-postscript-code",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/adobe-postscript-code",
          "publishedOn": "2022-12-08T20:21:05.000Z",
          "wordCount": 14375,
          "title": "How PostScript kickstarted desktop publishing",
          "imageUrl": "https://spectrum.ieee.org/media-library/an-illustration-consisting-of-a-spiral-of-calligraphy-style-lettering-that-repeatedly-spells-the-word-infinity.png?id=32309509&width=1200&height=600&coordinates=0%2C130%2C0%2C131"
        },
        {
          "id": "https://www.andrewnile.co.uk/blog/adventures-in-teletext-recovery/",
          "author": null,
          "description": "Comments",
          "link": "https://www.andrewnile.co.uk/blog/adventures-in-teletext-recovery/",
          "publishedOn": "2022-12-08T20:04:54.000Z",
          "wordCount": 1415,
          "title": "Adventures in Teletext Recovery",
          "imageUrl": "https://andrewnile.co.uk/i/banner.png"
        },
        {
          "id": "https://twitter.com/johnmcelhone8/status/1600683623250030593",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/johnmcelhone8/status/1600683623250030593",
          "publishedOn": "2022-12-08T19:53:46.000Z",
          "wordCount": 470,
          "title": "Finding the B-21's hanger location from the stars in its press image",
          "imageUrl": null
        },
        {
          "id": "https://www.ftc.gov/news-events/news/press-releases/2022/12/ftc-seeks-block-microsoft-corps-acquisition-activision-blizzard-inc",
          "author": null,
          "description": "Comments",
          "link": "https://www.ftc.gov/news-events/news/press-releases/2022/12/ftc-seeks-block-microsoft-corps-acquisition-activision-blizzard-inc",
          "publishedOn": "2022-12-08T19:26:58.000Z",
          "wordCount": 1832,
          "title": "FTC seeks to block Microsoft's acquisition of Activision Blizzard",
          "imageUrl": "https://www.ftc.gov/themes/custom/ftc_uswds/img/ftc_social_share_default_en.jpg"
        },
        {
          "id": "https://rez0.blog/hacking/2022/12/02/hacking-on-a-plane.html",
          "author": null,
          "description": "Comments",
          "link": "https://rez0.blog/hacking/2022/12/02/hacking-on-a-plane.html",
          "publishedOn": "2022-12-08T19:01:31.000Z",
          "wordCount": 884,
          "title": "Hacking on a plane: Leaking data of millions and taking over any account",
          "imageUrl": "https://i.imgur.com/6u4iy7e.png"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33910997",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33910997",
          "publishedOn": "2022-12-08T18:05:19.000Z",
          "wordCount": 2523,
          "title": "Show HN: Wasp – DSL/framework for building full-stack web apps – now in beta",
          "imageUrl": null
        },
        {
          "id": "https://www.meter.com/mac-osx-awdl-psa",
          "author": null,
          "description": "Comments",
          "link": "https://www.meter.com/mac-osx-awdl-psa",
          "publishedOn": "2022-12-08T17:59:48.000Z",
          "wordCount": 2597,
          "title": "Recent Apple updates leading to WiFi issues?",
          "imageUrl": "https://assets-global.website-files.com/62700af41da70b605419982b/639212bbf9d0050020714efa_meter-appleupdates.png"
        },
        {
          "id": "https://beta.sayhello.so/",
          "author": null,
          "description": "Comments",
          "link": "https://beta.sayhello.so/",
          "publishedOn": "2022-12-08T17:53:53.000Z",
          "wordCount": null,
          "title": "Show HN: Web search using a ChatGPT-like model that can cite its sources",
          "imageUrl": null
        },
        {
          "id": "https://authzed.com/blog/annotated-zanzibar-launch/",
          "author": null,
          "description": "Comments",
          "link": "https://authzed.com/blog/annotated-zanzibar-launch/",
          "publishedOn": "2022-12-08T17:37:49.000Z",
          "wordCount": 769,
          "title": "Google Zanzibar Through Our Eyes",
          "imageUrl": "https://authzed.com"
        },
        {
          "id": "https://magoo.medium.com/a-blameless-post-mortem-of-usa-v-joseph-sullivan-a137162f7fc9",
          "author": null,
          "description": "Comments",
          "link": "https://magoo.medium.com/a-blameless-post-mortem-of-usa-v-joseph-sullivan-a137162f7fc9",
          "publishedOn": "2022-12-08T17:31:29.000Z",
          "wordCount": 16923,
          "title": "A blameless post-mortem of USA vs. Joseph Sullivan",
          "imageUrl": "https://miro.medium.com/max/1024/1*sa9K-gHJqNdPqpCNeVJMpQ.png"
        },
        {
          "id": "https://arxiv.org/abs/2209.11142",
          "author": null,
          "description": "Comments",
          "link": "https://arxiv.org/abs/2209.11142",
          "publishedOn": "2022-12-08T17:26:27.000Z",
          "wordCount": 706,
          "title": "A Generalist Neural Algorithmic Learner",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/graalvm/babashka-how-graalvm-helped-create-a-fast-starting-scripting-environment-for-clojure-b0fcc38b0746",
          "author": null,
          "description": "Comments",
          "link": "https://medium.com/graalvm/babashka-how-graalvm-helped-create-a-fast-starting-scripting-environment-for-clojure-b0fcc38b0746",
          "publishedOn": "2022-12-08T15:54:55.000Z",
          "wordCount": 6310,
          "title": "Babashka is a fast-starting scripting environment for Clojure",
          "imageUrl": "https://miro.medium.com/max/1200/1*oWvJ_k7bxO1BFM6MLt5Xkw.png"
        },
        {
          "id": "https://github.com/exaloop/codon",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/exaloop/codon",
          "publishedOn": "2022-12-08T15:05:45.000Z",
          "wordCount": 1307,
          "title": "Codon: A high-performance Python-like compiler using LLVM",
          "imageUrl": "https://opengraph.githubassets.com/012486b763a8295fb9987ef3137fec0fd53e5ca908d09fa4497e4d370b1ce2f3/exaloop/codon"
        },
        {
          "id": "https://www.aps.org/publications/apsnews/199801/heisenberg.cfm",
          "author": null,
          "description": "Comments",
          "link": "https://www.aps.org/publications/apsnews/199801/heisenberg.cfm",
          "publishedOn": "2022-12-08T14:38:08.000Z",
          "wordCount": 1589,
          "title": "The sad story of Heisenberg's doctoral oral exam (1998)",
          "imageUrl": "http://www.aps.org/images/aps-social.png"
        },
        {
          "id": "https://github.com/qbists/studyq/tree/main/aoc/2022",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/qbists/studyq/tree/main/aoc/2022",
          "publishedOn": "2022-12-08T14:15:34.000Z",
          "wordCount": 511,
          "title": "Advent of q 2022",
          "imageUrl": "https://opengraph.githubassets.com/d31fbe7f74a31eeb37d9f6c60966734d9319991ca81ff0d748232216d576e66b/qbists/studyq"
        },
        {
          "id": "https://www.wsj.com/articles/google-combines-maps-and-waze-teams-in-restructuring-move-11670462301",
          "author": null,
          "description": "Comments",
          "link": "https://www.wsj.com/articles/google-combines-maps-and-waze-teams-in-restructuring-move-11670462301",
          "publishedOn": "2022-12-08T01:42:57.000Z",
          "wordCount": 7358,
          "title": "Google combines Maps and Waze teams in restructuring move",
          "imageUrl": "https://images.wsj.net/im-681483/social"
        },
        {
          "id": "https://www.science.org/content/article/paleontologist-accused-faking-data-dino-killing-asteroid-paper",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/content/article/paleontologist-accused-faking-data-dino-killing-asteroid-paper",
          "publishedOn": "2022-12-08T00:44:18.000Z",
          "wordCount": 3881,
          "title": "Paleontologist accused of faking data in dino-killing asteroid paper",
          "imageUrl": "https://www.science.org/do/10.1126/science.adg1716/abs/_20221206_on_tanis_robert_depalma.jpg"
        },
        {
          "id": "https://asia.nikkei.com/Business/Tech/Semiconductors/TSMC-founder-Morris-Chang-says-globalization-almost-dead",
          "author": null,
          "description": "Comments",
          "link": "https://asia.nikkei.com/Business/Tech/Semiconductors/TSMC-founder-Morris-Chang-says-globalization-almost-dead",
          "publishedOn": "2022-12-08T00:26:22.000Z",
          "wordCount": 2372,
          "title": "TSMC founder Morris Chang says globalization 'almost dead'",
          "imageUrl": "https://www.ft.com/__origami/service/image/v2/images/raw/https%253A%252F%252Fs3-ap-northeast-1.amazonaws.com%252Fpsh-ex-ftnikkei-3937bb4%252Fimages%252F1%252F0%252F4%252F8%252F43408401-3-eng-GB%252FIMG_7972%2520%25281%2529.jpg?width=1260&height=630&fit=cover&gravity=faces&source=nar-cms"
        },
        {
          "id": "https://www.nature.com/articles/s41467-022-35149-w",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/articles/s41467-022-35149-w",
          "publishedOn": "2022-12-08T00:19:30.000Z",
          "wordCount": 8710,
          "title": "Precise atom manipulation through deep reinforcement learning",
          "imageUrl": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41467-022-35149-w/MediaObjects/41467_2022_35149_Fig1_HTML.png"
        },
        {
          "id": "https://novalis.org/blog/2022-12-05-i-am-frustrated-with-stable-diffusion.html",
          "author": null,
          "description": "Comments",
          "link": "https://novalis.org/blog/2022-12-05-i-am-frustrated-with-stable-diffusion.html",
          "publishedOn": "2022-12-08T00:06:17.000Z",
          "wordCount": 566,
          "title": "I am frustrated with Stable Diffusion",
          "imageUrl": null
        },
        {
          "id": "http://minborgsjavapot.blogspot.com/2022/12/java-20-sneak-peek-on-panama-ffm-api.html",
          "author": null,
          "description": "Comments",
          "link": "http://minborgsjavapot.blogspot.com/2022/12/java-20-sneak-peek-on-panama-ffm-api.html",
          "publishedOn": "2022-12-07T22:44:51.000Z",
          "wordCount": 3720,
          "title": "Java 20: A Sneak Peek on the Panama FFM API",
          "imageUrl": "https://lh4.googleusercontent.com/-3M4OpV6qYhiDGrjzvdEEP3pyN-jaA0C7fierfKazeA3EcfRCSUaITSs5aFDpEluiMjg1DUzoR6IRLc8C4TV38O61izgZK4VBZ9bWCUNm4mXtaOL2SgkwgWRqtNePcZvZi1yZNrNAOYLIiFVPlHM5ORx_g2A-Rg8Y6xmBJbUU0KTvRWf7TnjpB8SK9-R1A=w1200-h630-p-k-no-nu"
        },
        {
          "id": "https://beebo.org/haycorn/2015-04-20_tabs-and-makefiles.html",
          "author": null,
          "description": "Comments",
          "link": "https://beebo.org/haycorn/2015-04-20_tabs-and-makefiles.html",
          "publishedOn": "2022-12-07T22:03:14.000Z",
          "wordCount": 2470,
          "title": "Tabs and Makefile (2015)",
          "imageUrl": null
        },
        {
          "id": "https://circleci.com/blog/ceo-jim-rose-email-to-circleci-employees/",
          "author": null,
          "description": "Comments",
          "link": "https://circleci.com/blog/ceo-jim-rose-email-to-circleci-employees/",
          "publishedOn": "2022-12-07T21:23:33.000Z",
          "wordCount": 2299,
          "title": "CircleCI Layoffs",
          "imageUrl": "https://circleci.com/blog/media/2022-12-07-email-background.png"
        },
        {
          "id": "https://viralinstruction.com/posts/goodjulia/",
          "author": null,
          "description": "Comments",
          "link": "https://viralinstruction.com/posts/goodjulia/",
          "publishedOn": "2022-12-07T20:57:57.000Z",
          "wordCount": 4718,
          "title": "What's Great about Julia?",
          "imageUrl": null
        },
        {
          "id": "https://www.allaboutcircuits.com/news/how-one-startups-cooling-chip-may-surge-processor-power/",
          "author": null,
          "description": "Comments",
          "link": "https://www.allaboutcircuits.com/news/how-one-startups-cooling-chip-may-surge-processor-power/",
          "publishedOn": "2022-12-07T19:57:41.000Z",
          "wordCount": null,
          "title": "A startup’s cooling chip may surge processor power",
          "imageUrl": null
        },
        {
          "id": "https://www.nature.com/articles/s41586-022-05499-y",
          "author": null,
          "description": "Comments",
          "link": "https://www.nature.com/articles/s41586-022-05499-y",
          "publishedOn": "2022-12-07T19:39:02.000Z",
          "wordCount": 18104,
          "title": "Engineered photosynthesis demonstrated in animals in vivo via synthetic biology",
          "imageUrl": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41586-022-05499-y/MediaObjects/41586_2022_5499_Fig1_HTML.png"
        },
        {
          "id": "https://scottaaronson.blog/?p=6871",
          "author": null,
          "description": "Comments",
          "link": "https://scottaaronson.blog/?p=6871",
          "publishedOn": "2022-12-07T19:13:44.000Z",
          "wordCount": 21423,
          "title": "Publicity Stunt Fallout",
          "imageUrl": "https://149663533.v2.pressablecdn.com/wp-content/uploads/2021/10/cropped-Jacket.gif"
        },
        {
          "id": "https://www.wired.com/story/apple-photo-scanning-csam-communication-safety-messages/",
          "author": null,
          "description": "Comments",
          "link": "https://www.wired.com/story/apple-photo-scanning-csam-communication-safety-messages/",
          "publishedOn": "2022-12-07T18:32:08.000Z",
          "wordCount": 20372,
          "title": "Apple kills plans to scan for CSAM in iCloud",
          "imageUrl": "https://media.wired.com/photos/639000b143ab6f113787af35/191:100/w_1280,c_limit/security-apple-encryption-photos.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/communications-system-achieves-fastest-laser-link-space-yet-1130",
          "author": null,
          "description": "Comments",
          "link": "https://news.mit.edu/2022/communications-system-achieves-fastest-laser-link-space-yet-1130",
          "publishedOn": "2022-12-07T18:26:54.000Z",
          "wordCount": 3081,
          "title": "100 Gbps achieved from space to Earth",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202211/TBIRD-communications-payload.png"
        },
        {
          "id": "https://support.apple.com/en-us/HT202303#advanced",
          "author": null,
          "description": "Comments",
          "link": "https://support.apple.com/en-us/HT202303#advanced",
          "publishedOn": "2022-12-07T18:06:58.000Z",
          "wordCount": 2369,
          "title": "Apple introduces end-to-end encryption for backups",
          "imageUrl": null
        },
        {
          "id": "https://blog.torproject.org/new-release-tor-browser-120/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.torproject.org/new-release-tor-browser-120/",
          "publishedOn": "2022-12-07T17:03:00.000Z",
          "wordCount": null,
          "title": "Tor Browser 12.0",
          "imageUrl": null
        },
        {
          "id": "https://lithub.com/ian-fleming-explains-how-to-write-a-thriller/",
          "author": null,
          "description": "Comments",
          "link": "https://lithub.com/ian-fleming-explains-how-to-write-a-thriller/",
          "publishedOn": "2022-12-07T16:52:21.000Z",
          "wordCount": 6315,
          "title": "Ian Fleming explains how to write a thriller (2019)",
          "imageUrl": "https://s26162.pcdn.co/wp-content/uploads/2019/05/bondegg.jpg"
        },
        {
          "id": "https://git.herrbischoff.com/awesome-macos-command-line/about/",
          "author": null,
          "description": "Comments",
          "link": "https://git.herrbischoff.com/awesome-macos-command-line/about/",
          "publishedOn": "2022-12-07T16:39:36.000Z",
          "wordCount": 11129,
          "title": "macOS Command Line",
          "imageUrl": null
        },
        {
          "id": "https://specbranch.com/posts/expensive-abstraction/",
          "author": null,
          "description": "Comments",
          "link": "https://specbranch.com/posts/expensive-abstraction/",
          "publishedOn": "2022-12-07T15:10:25.000Z",
          "wordCount": 2273,
          "title": "Abstraction is expensive",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33894933",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33894933",
          "publishedOn": "2022-12-07T14:51:09.000Z",
          "wordCount": 24758,
          "title": "Tell HN: IPv6-only still pretty much unusable",
          "imageUrl": null
        },
        {
          "id": "https://www.nplusonemag.com/issue-44/the-intellectual-situation/why-is-everything-so-ugly/",
          "author": null,
          "description": "Comments",
          "link": "https://www.nplusonemag.com/issue-44/the-intellectual-situation/why-is-everything-so-ugly/",
          "publishedOn": "2022-12-07T14:28:59.000Z",
          "wordCount": null,
          "title": "The mid in fake midcentury modern",
          "imageUrl": null
        },
        {
          "id": "https://english.elpais.com/science-tech/2022-12-07/a-compendium-of-historic-surgeries-as-told-by-a-surgeon.html",
          "author": null,
          "description": "Comments",
          "link": "https://english.elpais.com/science-tech/2022-12-07/a-compendium-of-historic-surgeries-as-told-by-a-surgeon.html",
          "publishedOn": "2022-12-07T14:13:09.000Z",
          "wordCount": 3617,
          "title": "A compendium of historic surgeries",
          "imageUrl": "https://images.english.elpais.com/resizer/gUoOXyocbi8fZmTZqrRoIzZIsWg=/1200x0/filters:focal(1503x294:1513x304)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/M7UCWCJP4FE3RFCUJ5LGFFQPTA.jpg"
        },
        {
          "id": "https://lawrencecpaulson.github.io//2022/12/07/Memories_first_exposure.html",
          "author": null,
          "description": "Comments",
          "link": "https://lawrencecpaulson.github.io//2022/12/07/Memories_first_exposure.html",
          "publishedOn": "2022-12-07T14:09:13.000Z",
          "wordCount": 1393,
          "title": "Memories: First exposure to computers",
          "imageUrl": null
        },
        {
          "id": "https://dev.yorhel.nl/ncdu",
          "author": null,
          "description": "Comments",
          "link": "https://dev.yorhel.nl/ncdu",
          "publishedOn": "2022-12-07T12:57:58.000Z",
          "wordCount": 643,
          "title": "Ncdu – NCurses Disk Usage",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/flavorjones/status/1600436490885947393",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/flavorjones/status/1600436490885947393",
          "publishedOn": "2022-12-07T11:20:59.000Z",
          "wordCount": 470,
          "title": "Chris Seaton has died",
          "imageUrl": null
        },
        {
          "id": "https://www.palladiummag.com/2022/11/04/i-do-not-want-to-be-an-internet-person/",
          "author": null,
          "description": "Comments",
          "link": "https://www.palladiummag.com/2022/11/04/i-do-not-want-to-be-an-internet-person/",
          "publishedOn": "2022-12-07T10:22:03.000Z",
          "wordCount": 5671,
          "title": "I don’t want to be an internet person",
          "imageUrl": "https://pdmedia.b-cdn.net/2022/11/aleksandr-popov-3yt_0_PnR0A-unsplash-1-scaled.jpg"
        },
        {
          "id": "https://medium.com/@petefison/a-crash-course-in-python-comprehensions-and-generators-f069c8f8ca38",
          "author": null,
          "description": "Comments",
          "link": "https://medium.com/@petefison/a-crash-course-in-python-comprehensions-and-generators-f069c8f8ca38",
          "publishedOn": "2022-12-07T08:30:59.000Z",
          "wordCount": 4250,
          "title": "A crash course in Python “comprehensions” and “generators”",
          "imageUrl": "https://miro.medium.com/max/1200/0*om4Yiv5DJomt52ly"
        },
        {
          "id": "https://www.raspberrypi.com/news/electronic-music-icon-korg-makes-music-with-raspberry-pi/",
          "author": null,
          "description": "Comments",
          "link": "https://www.raspberrypi.com/news/electronic-music-icon-korg-makes-music-with-raspberry-pi/",
          "publishedOn": "2022-12-07T08:29:57.000Z",
          "wordCount": 2312,
          "title": "Korg makes music with Raspberry Pi",
          "imageUrl": "https://www.raspberrypi.com/app/uploads/2022/12/wavestate_snap7-1536x1024-1-500x333.jpeg"
        },
        {
          "id": "https://alt.msdos.narkive.com/5Z8FVmvc/alt-enter-doesn-t-window-dos-graphics-in-xp-used-to-work-in-nt-w2k",
          "author": null,
          "description": "Comments",
          "link": "https://alt.msdos.narkive.com/5Z8FVmvc/alt-enter-doesn-t-window-dos-graphics-in-xp-used-to-work-in-nt-w2k",
          "publishedOn": "2022-12-07T05:40:01.000Z",
          "wordCount": 10773,
          "title": "Alt-Enter Doesn't Window DOS Graphics in XP (Used to Work in NT and W2K) (2006)",
          "imageUrl": null
        },
        {
          "id": "https://wizeus.de/teardown-of-the-uni-t-pro-uti690b-thermal-camera/",
          "author": null,
          "description": "Comments",
          "link": "https://wizeus.de/teardown-of-the-uni-t-pro-uti690b-thermal-camera/",
          "publishedOn": "2022-12-07T03:20:13.000Z",
          "wordCount": 2900,
          "title": "Teardown of the UNI-T PRO UTi690B thermal camera",
          "imageUrl": "https://wizeus.de/wp-content/uploads/2022/06/uti690B_specs-503x1024.webp"
        },
        {
          "id": "https://www.catphones.com/en-us/cat-s62-pro-smartphone/",
          "author": null,
          "description": "Comments",
          "link": "https://www.catphones.com/en-us/cat-s62-pro-smartphone/",
          "publishedOn": "2022-12-07T01:05:14.000Z",
          "wordCount": 5947,
          "title": "Caterpillar offers phone with built-in FLIR camera",
          "imageUrl": "https://www.catphones.com/wp-content/uploads/2020/12/Cat-S62-Pro-Feature-Image-2-1-10.png"
        },
        {
          "id": "https://www.vice.com/en/article/n7zmvd/beware-of-the-perfect-gentleman",
          "author": null,
          "description": "Comments",
          "link": "https://www.vice.com/en/article/n7zmvd/beware-of-the-perfect-gentleman",
          "publishedOn": "2022-12-07T01:04:03.000Z",
          "wordCount": 29470,
          "title": "Beware of the Perfect Gentleman",
          "imageUrl": "https://video-images.vice.com/articles/637d2a2685c21dde6ec46cdf/lede/1669150357954-stacygougoulisromancescammerslede.jpeg?image-resize-opts=Y3JvcD0xeHc6MXhoO2NlbnRlcixjZW50ZXImcmVzaXplPTEyMDA6KiZyZXNpemU9MTIwMDoq"
        },
        {
          "id": "https://stuartritchie.substack.com/p/identical-twins-arent-that-identical",
          "author": null,
          "description": "Comments",
          "link": "https://stuartritchie.substack.com/p/identical-twins-arent-that-identical",
          "publishedOn": "2022-12-07T00:52:13.000Z",
          "wordCount": 6966,
          "title": "Identical twins aren't that identical",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc7f7d56-3b27-4273-869c-13aa32bddb2d_1549x1936.jpeg"
        },
        {
          "id": "https://emacsconf.org/2022/talks/rms/",
          "author": null,
          "description": "Comments",
          "link": "https://emacsconf.org/2022/talks/rms/",
          "publishedOn": "2022-12-07T00:12:27.000Z",
          "wordCount": 3339,
          "title": "What I'd like to see in Emacs",
          "imageUrl": null
        },
        {
          "id": "https://www.noemamag.com/how-to-speak-honeybee/",
          "author": null,
          "description": "Comments",
          "link": "https://www.noemamag.com/how-to-speak-honeybee/",
          "publishedOn": "2022-12-06T23:19:20.000Z",
          "wordCount": 5557,
          "title": "How to Speak Honeybee",
          "imageUrl": "https://noemamag.imgix.net/2022/11/STILLS-7-tw.jpeg?fm=pjpg&focalpoint=focalpoint&fp-x=0.2481520591341077&fp-y=0.3500447591145833&ixlib=php-3.3.0&s=73ae426e92076967f306cbfd2ef0c690"
        },
        {
          "id": "https://inference-review.com/article/the-chinese-civil-examinations",
          "author": null,
          "description": "Comments",
          "link": "https://inference-review.com/article/the-chinese-civil-examinations",
          "publishedOn": "2022-12-06T23:08:39.000Z",
          "wordCount": 5626,
          "title": "The Chinese Civil Examinations",
          "imageUrl": "http://inference-review.com/assets/img/meta/the-chinese-civil-examinations-1.jpg"
        },
        {
          "id": "https://thereader.mitpress.mit.edu/finding-language-in-the-brain/",
          "author": null,
          "description": "Comments",
          "link": "https://thereader.mitpress.mit.edu/finding-language-in-the-brain/",
          "publishedOn": "2022-12-06T23:08:23.000Z",
          "wordCount": 2310,
          "title": "Finding Language in the Brain",
          "imageUrl": "https://thereader.mitpress.mit.edu/wp-content/uploads/2022/08/language-in-the-brain-lead.jpg"
        },
        {
          "id": "https://aphyr.com/posts/360-loopr-a-loop-reduction-macro-for-clojure",
          "author": null,
          "description": "Comments",
          "link": "https://aphyr.com/posts/360-loopr-a-loop-reduction-macro-for-clojure",
          "publishedOn": "2022-12-06T22:08:15.000Z",
          "wordCount": 2883,
          "title": "Loopr: A Loop/Reduction Macro for Clojure",
          "imageUrl": null
        },
        {
          "id": "https://thegrayzone.com/2022/12/06/files-anomaly-6-firm-spyware/",
          "author": null,
          "description": "Comments",
          "link": "https://thegrayzone.com/2022/12/06/files-anomaly-6-firm-spyware/",
          "publishedOn": "2022-12-06T22:05:03.000Z",
          "wordCount": 4739,
          "title": "Anomaly 6: Private spying firm targets global population with illegal spyware",
          "imageUrl": "https://thegrayzone.com/wp-content/uploads/2022/12/Screen-Shot-2022-12-06-at-12.53.41-AM.png"
        },
        {
          "id": "https://www.newyorker.com/science/elements/the-science-of-christmas-trees",
          "author": null,
          "description": "Comments",
          "link": "https://www.newyorker.com/science/elements/the-science-of-christmas-trees",
          "publishedOn": "2022-12-06T21:55:02.000Z",
          "wordCount": 28685,
          "title": "The Science of Christmas Trees",
          "imageUrl": "https://media.newyorker.com/photos/638e53b74d4403fc45f9171f/16:9/w_1280,c_limit/Galchen_Christmas_Tree.png"
        },
        {
          "id": "https://www.abc.net.au/news/2022-12-07/fossil-discovery-queensland-museum-townsville-plesiosaur/101735306",
          "author": null,
          "description": "Comments",
          "link": "https://www.abc.net.au/news/2022-12-07/fossil-discovery-queensland-museum-townsville-plesiosaur/101735306",
          "publishedOn": "2022-12-06T21:38:19.000Z",
          "wordCount": 3880,
          "title": "Australia's first complete plesiosaur fossil discovered in outback Queensland",
          "imageUrl": "https://live-production.wcms.abc-cdn.net.au/07d8e6c93514b4238836380bf9bf6f90?impolicy=wcms_crop_resize&cropH=461&cropW=820&xPos=71&yPos=94&width=862&height=485"
        },
        {
          "id": "https://medium.com/mcdonalds-technical-blog/behind-the-scenes-mcdonalds-event-driven-architecture-51a6542c0d86",
          "author": null,
          "description": "Comments",
          "link": "https://medium.com/mcdonalds-technical-blog/behind-the-scenes-mcdonalds-event-driven-architecture-51a6542c0d86",
          "publishedOn": "2022-12-06T21:16:31.000Z",
          "wordCount": 2636,
          "title": "McDonalds Event Driven Architecture",
          "imageUrl": "https://miro.medium.com/max/1200/1*GVWWFlBJ9S_9wTvZUjM_DA.jpeg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33886973",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33886973",
          "publishedOn": "2022-12-06T21:01:00.000Z",
          "wordCount": 236,
          "title": "Odiggo (YC S21), a hardware startup, is looking for a tech co-founder",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/airbnb-engineering/announcing-lottie-4-0-for-ios-d4d226862a54",
          "author": null,
          "description": "Comments",
          "link": "https://medium.com/airbnb-engineering/announcing-lottie-4-0-for-ios-d4d226862a54",
          "publishedOn": "2022-12-06T20:37:33.000Z",
          "wordCount": 2893,
          "title": "Lottie 4.0 for iOS: new render engine with significant performance improvements",
          "imageUrl": "https://miro.medium.com/max/1200/1*Y4aQ-u0Mnh0S5b71sKr-Fg.jpeg"
        },
        {
          "id": "https://www.radpowerbikes.com/products/radtrike-electric-tricycle",
          "author": null,
          "description": "Comments",
          "link": "https://www.radpowerbikes.com/products/radtrike-electric-tricycle",
          "publishedOn": "2022-12-06T19:40:06.000Z",
          "wordCount": 24175,
          "title": "RadTrike Electric Tricycle",
          "imageUrl": "http://cdn.shopify.com/s/files/1/0799/9645/products/RadTrike_rightside1_1.png?v=1669745967"
        },
        {
          "id": "https://www.popularmechanics.com/science/a32209316/quantum-steampunk-physics/",
          "author": null,
          "description": "Comments",
          "link": "https://www.popularmechanics.com/science/a32209316/quantum-steampunk-physics/",
          "publishedOn": "2022-12-06T19:07:05.000Z",
          "wordCount": 8344,
          "title": "Quantum steampunk, a retrofuturistic field of physics",
          "imageUrl": "https://hips.hearstapps.com/hmg-prod/images/steampunk-future-vision-girl-royalty-free-image-1587485262.jpg?crop=0.987xw:0.740xh;0.00160xw,0.173xh&resize=1200:*"
        },
        {
          "id": "https://maximumeffort.substack.com/p/i-taught-chatgpt-to-invent-a-language",
          "author": null,
          "description": "Comments",
          "link": "https://maximumeffort.substack.com/p/i-taught-chatgpt-to-invent-a-language",
          "publishedOn": "2022-12-06T18:53:01.000Z",
          "wordCount": 11918,
          "title": "I Taught ChatGPT to Invent a Language",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F703253f6-654c-44e1-925f-66d7a5401e22_1274x1146.png"
        },
        {
          "id": "https://github.com/openai/whisper/commit/4179ed2475cc84cba66868b516232ef1b74dacdf",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/openai/whisper/commit/4179ed2475cc84cba66868b516232ef1b74dacdf",
          "publishedOn": "2022-12-06T18:24:34.000Z",
          "wordCount": 512,
          "title": "OpenAI quietly launched Whisper V2 in a GitHub commit",
          "imageUrl": "https://opengraph.githubassets.com/24094f4142c0922cc7fb15423ebc0c56b079ff55c6d5b8b4c5125d7b86304fbb/openai/whisper/commit/4179ed2475cc84cba66868b516232ef1b74dacdf"
        },
        {
          "id": "https://9to5mac.com/2022/12/06/app-store-pricing-changes-developers/",
          "author": null,
          "description": "Comments",
          "link": "https://9to5mac.com/2022/12/06/app-store-pricing-changes-developers/",
          "publishedOn": "2022-12-06T18:06:03.000Z",
          "wordCount": 4276,
          "title": "Apple announces ‘upgrade’ to App Store pricing, adding 700 new price points",
          "imageUrl": "https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2022/12/app-store-money.jpg?resize=1200%2C628&quality=82&strip=all&ssl=1"
        },
        {
          "id": "https://github.com/step-security/wait-for-secrets",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/step-security/wait-for-secrets",
          "publishedOn": "2022-12-06T18:05:00.000Z",
          "wordCount": 1474,
          "title": "Show HN: Publish from GitHub Actions using multi-factor authentication",
          "imageUrl": "https://opengraph.githubassets.com/298316413d7bce95aa1ab5541ccde107ee89b6827036f964330da1ca3cdbbeb4/step-security/wait-for-secrets"
        },
        {
          "id": "https://probablydance.com/2022/12/05/fine-grained-locking-with-two-bit-mutexes/",
          "author": null,
          "description": "Comments",
          "link": "https://probablydance.com/2022/12/05/fine-grained-locking-with-two-bit-mutexes/",
          "publishedOn": "2022-12-06T16:41:50.000Z",
          "wordCount": 3892,
          "title": "Fine-grained locking with two-bit mutexes",
          "imageUrl": "https://s0.wp.com/i/blank.jpg"
        },
        {
          "id": "https://lemire.me/blog/2022/12/06/optimizing-compilers-reload-vector-constants-needlessly/",
          "author": null,
          "description": "Comments",
          "link": "https://lemire.me/blog/2022/12/06/optimizing-compilers-reload-vector-constants-needlessly/",
          "publishedOn": "2022-12-06T16:41:24.000Z",
          "wordCount": 4348,
          "title": "Optimizing compilers reload vector constants needlessly",
          "imageUrl": "https://lemire.me/img/portrait2018facebook.jpg"
        },
        {
          "id": "https://www.dolthub.com/blog/2022-12-02-open-source-hospital-price-transparency/",
          "author": null,
          "description": "Comments",
          "link": "https://www.dolthub.com/blog/2022-12-02-open-source-hospital-price-transparency/",
          "publishedOn": "2022-12-06T16:20:34.000Z",
          "wordCount": 1682,
          "title": "Open-source hospital price transparency",
          "imageUrl": "https://www.dolthub.com/blog/static/4f1b08dde6eef5e9001331341b301ab7/db2c0/sl-140062-cdm-sample-highlighted.png"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33882497",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33882497",
          "publishedOn": "2022-12-06T16:20:02.000Z",
          "wordCount": 5338,
          "title": "Show HN: Domain Name Search with AI",
          "imageUrl": null
        },
        {
          "id": "https://statmodeling.stat.columbia.edu/2022/12/06/a-homework-question-in-someones-11th-grade-statistics-class/",
          "author": null,
          "description": "Comments",
          "link": "https://statmodeling.stat.columbia.edu/2022/12/06/a-homework-question-in-someones-11th-grade-statistics-class/",
          "publishedOn": "2022-12-06T14:33:29.000Z",
          "wordCount": 5074,
          "title": "A homework question in someone’s 11th grade statistics class",
          "imageUrl": null
        },
        {
          "id": "https://emanote.srid.ca/",
          "author": null,
          "description": "Comments",
          "link": "https://emanote.srid.ca/",
          "publishedOn": "2022-12-06T14:20:53.000Z",
          "wordCount": 427,
          "title": "Emanote – Haskell-powered structured view of your plain-text notes",
          "imageUrl": ""
        },
        {
          "id": "https://www.blackbirdspyplane.com/p/why-do-new-cars-look-like-this",
          "author": null,
          "description": "Comments",
          "link": "https://www.blackbirdspyplane.com/p/why-do-new-cars-look-like-this",
          "publishedOn": "2022-12-06T14:10:40.000Z",
          "wordCount": 4125,
          "title": "Why do new cars look like wet putty?",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4783e79d-ea62-49f5-8ba6-ce3fd5ebf983_1713x3616.jpeg"
        },
        {
          "id": "https://www.cnbc.com/2022/12/06/tsmc-to-up-arizona-investment-to-40-billion-with-second-semiconductor-chip-plant.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.cnbc.com/2022/12/06/tsmc-to-up-arizona-investment-to-40-billion-with-second-semiconductor-chip-plant.html",
          "publishedOn": "2022-12-06T13:35:50.000Z",
          "wordCount": 19074,
          "title": "TSMC ups Arizona investment from $12B to $40B with second semi fab",
          "imageUrl": "https://image.cnbcfm.com/api/v1/image/107116242-1662742462700-gettyimages-1243072680-AFP_32J298K.jpeg?v=1670320801&w=1920&h=1080"
        },
        {
          "id": "https://arstechnica.com/gaming/2022/12/dwarf-fortresss-graphical-upgrade-provides-a-new-way-into-a-wildly-wonky-game/",
          "author": null,
          "description": "Comments",
          "link": "https://arstechnica.com/gaming/2022/12/dwarf-fortresss-graphical-upgrade-provides-a-new-way-into-a-wildly-wonky-game/",
          "publishedOn": "2022-12-06T13:15:22.000Z",
          "wordCount": 2102,
          "title": "Dwarf Fortress’ graphical upgrade provides a new way into a wildly wonky game",
          "imageUrl": "https://cdn.arstechnica.net/wp-content/uploads/2022/12/df_header_better-760x380.png"
        },
        {
          "id": "https://academic.oup.com/brain/article/145/2/476/6356504",
          "author": null,
          "description": "Comments",
          "link": "https://academic.oup.com/brain/article/145/2/476/6356504",
          "publishedOn": "2022-12-06T11:21:58.000Z",
          "wordCount": 5968,
          "title": "It’s not Tourette’s but a new type of mass sociogenic illness",
          "imageUrl": "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/brain/145/2/10.1093_brain_awab316/1/m_awab316_toc.jpeg?Expires=1733377704&Signature=guPCy11ASlJPhvbCwlc3PKh51NZRfhsU7PKfGpiu9o-XhVbzrjnPfxONpLmuGMapWW91RJmoMzUwKTiC7Ri-iRnxpnyMPJh613gcsEBc5rRvrz7JXSYtzxDEMgHnx7cp3Upe~D~U1IHPM0iNVyjpydTu~oowQD3Z4BklLY8S~GolHbGacCTpoHYneDqOXSVBjjn7gCk9GCXwLorlwhtmcDqYCH6LMpmDl0Z9YV25wmi-0nvdhpc7xNS812xCye-NL~HJeQbNqJV-s-W4SJQ1A5xRrrk2Rhv1iN023WrRHCBzoUW-V47UooWIbL6n6DmlQrWAXgE0zf3VkN4~Xs~wXg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"
        },
        {
          "id": "https://vickiboykis.com/2022/12/05/the-cloudy-layers-of-modern-day-programming/",
          "author": null,
          "description": "Comments",
          "link": "https://vickiboykis.com/2022/12/05/the-cloudy-layers-of-modern-day-programming/",
          "publishedOn": "2022-12-06T10:36:54.000Z",
          "wordCount": 4144,
          "title": "The cloudy layers of modern-day programming",
          "imageUrl": "https://veekaybee.github.io/images/logo.png"
        },
        {
          "id": "https://www.washingtonpost.com/science/2022/12/05/homo-naledi-fire-evolution/",
          "author": null,
          "description": "Comments",
          "link": "https://www.washingtonpost.com/science/2022/12/05/homo-naledi-fire-evolution/",
          "publishedOn": "2022-12-06T04:18:20.000Z",
          "wordCount": 9302,
          "title": "Ancient human relative used fire, discoveries suggest",
          "imageUrl": "https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/NJSKWLB5PEI6ZPLP3I3W6RZQJY.jpg&w=1440"
        },
        {
          "id": "https://ethw.org/Ancient_Computers",
          "author": null,
          "description": "Comments",
          "link": "https://ethw.org/Ancient_Computers",
          "publishedOn": "2022-12-06T00:32:41.000Z",
          "wordCount": 12801,
          "title": "Ancient Computers (2015)",
          "imageUrl": "https://ethw.org/w/logo.png"
        },
        {
          "id": "https://www.bloomberg.com/news/articles/2022-12-05/spacs-collapse-as-11-billion-of-deals-are-called-off-within-an-hour",
          "author": null,
          "description": "Comments",
          "link": "https://www.bloomberg.com/news/articles/2022-12-05/spacs-collapse-as-11-billion-of-deals-are-called-off-within-an-hour",
          "publishedOn": "2022-12-05T23:24:07.000Z",
          "wordCount": 549,
          "title": "SPACs collapse as $11B of deals are called off within an hour",
          "imageUrl": null
        },
        {
          "id": "https://inkscape.org/release/inkscape-1.2.2/",
          "author": null,
          "description": "Comments",
          "link": "https://inkscape.org/release/inkscape-1.2.2/",
          "publishedOn": "2022-12-05T23:14:04.000Z",
          "wordCount": 381,
          "title": "Inkscape 1.2.2",
          "imageUrl": "https://media.inkscape.org/static/images/inkscape-og-image.png"
        },
        {
          "id": "https://www.reuters.com/technology/musks-neuralink-faces-federal-probe-employee-backlash-over-animal-tests-2022-12-05/",
          "author": null,
          "description": "Comments",
          "link": "https://www.reuters.com/technology/musks-neuralink-faces-federal-probe-employee-backlash-over-animal-tests-2022-12-05/",
          "publishedOn": "2022-12-05T22:42:50.000Z",
          "wordCount": 9046,
          "title": "Neuralink faces federal probe, employee backlash over animal tests",
          "imageUrl": "https://www.reuters.com/resizer/G8bnnDrNpTfktRuO5NACfC8vsh0=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/KSBNFLBBGROW5JWGI3XY42UZWA.jpg"
        },
        {
          "id": "https://letsencrypt.org/2022/12/05/ed-letter-2022.html",
          "author": null,
          "description": "Comments",
          "link": "https://letsencrypt.org/2022/12/05/ed-letter-2022.html",
          "publishedOn": "2022-12-05T22:28:26.000Z",
          "wordCount": 898,
          "title": "A Year-End Letter from our Executive Director",
          "imageUrl": null
        },
        {
          "id": "https://www.caltech.edu/about/news/new-process-allows-3-d-printing-of-microscale-metallic-parts",
          "author": null,
          "description": "Comments",
          "link": "https://www.caltech.edu/about/news/new-process-allows-3-d-printing-of-microscale-metallic-parts",
          "publishedOn": "2022-12-05T22:16:06.000Z",
          "wordCount": 1499,
          "title": "New process allows 3-D printing of microscale metallic parts",
          "imageUrl": "https://caltech-prod.s3.amazonaws.com/main/images/Screen_Shot_2022-11-30_at_9.41.07_AM.width-600.png"
        },
        {
          "id": "https://worksinprogress.substack.com/p/a-tale-of-two-particles",
          "author": null,
          "description": "Comments",
          "link": "https://worksinprogress.substack.com/p/a-tale-of-two-particles",
          "publishedOn": "2022-12-05T21:44:58.000Z",
          "wordCount": 5091,
          "title": "A tale of two particles: Not all radioactivity is risky or harmful",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2f1bbd7f-ee2f-4de1-8337-8151c447d4b7_600x464.jpeg"
        },
        {
          "id": "https://sifted.eu/articles/vc-scout-programme-problems/",
          "author": null,
          "description": "Comments",
          "link": "https://sifted.eu/articles/vc-scout-programme-problems/",
          "publishedOn": "2022-12-05T21:00:38.000Z",
          "wordCount": 3967,
          "title": "VCs using scouts means founders get the short end of the stick (2021)",
          "imageUrl": "https://images.sifted.eu/wp-content/uploads/2021/09/13110424/Profile-Pic_AnhTho-Chuong_1-1-scaled-e1653917110196.jpeg?w=2048&h=1039&q=75&fit=crop&auto=compress,format"
        },
        {
          "id": "https://neal.fun/asteroid-launcher/",
          "author": null,
          "description": "Comments",
          "link": "https://neal.fun/asteroid-launcher/",
          "publishedOn": "2022-12-05T19:30:38.000Z",
          "wordCount": 164,
          "title": "Simulate Asteroid Impacts on Earth",
          "imageUrl": "https://neal.fun/share-cards/asteroid-launcher.png"
        },
        {
          "id": "https://alula.github.io/SpaceCadetPinball/",
          "author": null,
          "description": "Comments",
          "link": "https://alula.github.io/SpaceCadetPinball/",
          "publishedOn": "2022-12-05T19:13:13.000Z",
          "wordCount": 194,
          "title": "Play Windows Pinball (Space Cadet) on the Web",
          "imageUrl": null
        },
        {
          "id": "https://www.lrb.co.uk/the-paper/v44/n24/laleh-khalili/in-clover",
          "author": null,
          "description": "Comments",
          "link": "https://www.lrb.co.uk/the-paper/v44/n24/laleh-khalili/in-clover",
          "publishedOn": "2022-12-05T18:40:35.000Z",
          "wordCount": 10027,
          "title": "When McKinsey comes to town",
          "imageUrl": "https://www.lrb.co.uk/storage/social_image/images/6/9/2/3/29013296-1-eng-GB/e77f9797746d-khalili-website.jpg"
        },
        {
          "id": "https://buildlist.org/",
          "author": null,
          "description": "Comments",
          "link": "https://buildlist.org/",
          "publishedOn": "2022-12-05T18:40:19.000Z",
          "wordCount": 841,
          "title": "Build List: A directory of on-demand manufacturers for your creative projects",
          "imageUrl": null
        },
        {
          "id": "http://users.ics.aalto.fi/tho/stes/step96/hyotyniemi1/",
          "author": null,
          "description": "Comments",
          "link": "http://users.ics.aalto.fi/tho/stes/step96/hyotyniemi1/",
          "publishedOn": "2022-12-05T18:24:35.000Z",
          "wordCount": 2862,
          "title": "Turing Machines Are Recurrent Neural Networks (1996)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/clmnin/summarize.site",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/clmnin/summarize.site",
          "publishedOn": "2022-12-05T18:05:47.000Z",
          "wordCount": 672,
          "title": "Show HN: Chrome extension to summarize blogs and articles using ChatGPT",
          "imageUrl": "https://opengraph.githubassets.com/85fd8c72c645168fdccdad0af7462087bb49c708b6aa2b4a5494487393123e90/clmnin/summarize.site"
        },
        {
          "id": "https://www.nlrb.gov/news-outreach/news-story/nlrb-region-29-wins-federal-court-order-requiring-amazon-to-cease-and",
          "author": null,
          "description": "Comments",
          "link": "https://www.nlrb.gov/news-outreach/news-story/nlrb-region-29-wins-federal-court-order-requiring-amazon-to-cease-and",
          "publishedOn": "2022-12-05T18:03:25.000Z",
          "wordCount": 119,
          "title": "Federal court requires Amazon to stop firing employees for protected activities",
          "imageUrl": null
        },
        {
          "id": "https://bitwarden.com/blog/passwordless-authentication-access-your-bitwarden-web-vault-without-a-password/",
          "author": null,
          "description": "Comments",
          "link": "https://bitwarden.com/blog/passwordless-authentication-access-your-bitwarden-web-vault-without-a-password/",
          "publishedOn": "2022-12-05T17:08:03.000Z",
          "wordCount": 6527,
          "title": "Passwordless Authentication – Access Your Bitwarden Web Vault Without a Password",
          "imageUrl": null
        },
        {
          "id": "https://macos9.app/",
          "author": null,
          "description": "Comments",
          "link": "https://macos9.app/",
          "publishedOn": "2022-12-05T17:00:07.000Z",
          "wordCount": 45,
          "title": "Mac OS 9",
          "imageUrl": null
        },
        {
          "id": "https://blog.thunderbird.net/2022/12/thunderbird-for-android-preview-modern-message-redesign/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.thunderbird.net/2022/12/thunderbird-for-android-preview-modern-message-redesign/",
          "publishedOn": "2022-12-05T16:56:14.000Z",
          "wordCount": 1223,
          "title": "Thunderbird for Android preview: Modern message redesign",
          "imageUrl": "https://blog.thunderbird.net/files/2022/12/K-9-Mail-becomes-Thunderbird-Android.png"
        },
        {
          "id": "https://educatedguesswork.org/posts/nuclear-weapon-disposal/",
          "author": null,
          "description": "Comments",
          "link": "https://educatedguesswork.org/posts/nuclear-weapon-disposal/",
          "publishedOn": "2022-12-05T16:35:13.000Z",
          "wordCount": 5823,
          "title": "One does not simply destroy a nuclear weapon",
          "imageUrl": "https://educatedguesswork.org/img/boromir-nukes.jpg"
        },
        {
          "id": "https://hakaimagazine.com/features/is-sausage-the-missing-link-in-the-great-bait-debate/",
          "author": null,
          "description": "Comments",
          "link": "https://hakaimagazine.com/features/is-sausage-the-missing-link-in-the-great-bait-debate/",
          "publishedOn": "2022-12-05T16:25:35.000Z",
          "wordCount": 4762,
          "title": "Lobster and snow crab fisheries search for alternative baits",
          "imageUrl": "https://hakaimagazine.com/wp-content/uploads/facebook-bait.jpg"
        },
        {
          "id": "https://github.com/jgm/djot",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/jgm/djot",
          "publishedOn": "2022-12-05T16:24:31.000Z",
          "wordCount": 2902,
          "title": "Djot: A light markup language by the creator of Pandoc and CommonMark",
          "imageUrl": "https://opengraph.githubassets.com/762c7fb8353340b7d60385d3bac9b14d458ad77b8e6b80068e3c92de4f7d95f7/jgm/djot"
        },
        {
          "id": "https://stratechery.com/2022/ai-homework/",
          "author": null,
          "description": "Comments",
          "link": "https://stratechery.com/2022/ai-homework/",
          "publishedOn": "2022-12-05T15:41:28.000Z",
          "wordCount": 5407,
          "title": "AI Homework",
          "imageUrl": "https://i0.wp.com/stratechery.com/wp-content/uploads/2020/03/Stratechery-2020-03-11-23.03.59.png?fit=1200%2C811&ssl=1"
        },
        {
          "id": "https://phys.org/news/2022-11-mysteriously-bright-black-hole-jet.html",
          "author": null,
          "description": "Comments",
          "link": "https://phys.org/news/2022-11-mysteriously-bright-black-hole-jet.html",
          "publishedOn": "2022-12-05T15:33:18.000Z",
          "wordCount": 2374,
          "title": "Bright flash is a black hole jet pointing at Earth, astronomers say",
          "imageUrl": "https://scx2.b-cdn.net/gfx/news/hires/2022/mysteriously-bright-fl.jpg"
        },
        {
          "id": "https://bricks.stackexchange.com/questions/17587/can-lego-city-powered-up-trains-be-automated",
          "author": null,
          "description": "Comments",
          "link": "https://bricks.stackexchange.com/questions/17587/can-lego-city-powered-up-trains-be-automated",
          "publishedOn": "2022-12-05T14:46:11.000Z",
          "wordCount": 3142,
          "title": "Can Lego City Powered Up trains be automated?",
          "imageUrl": "https://cdn.sstatic.net/Sites/bricks/Img/apple-touch-icon@2.png?v=95a6163f4789"
        },
        {
          "id": "https://lichess.org/@/thibault/blog/lichess-on-scala3-help-needed/2bpotLb0",
          "author": null,
          "description": "Comments",
          "link": "https://lichess.org/@/thibault/blog/lichess-on-scala3-help-needed/2bpotLb0",
          "publishedOn": "2022-12-05T14:18:56.000Z",
          "wordCount": 839,
          "title": "Lichess on Scala3 – Help needed",
          "imageUrl": "https://image.lichess1.org/display?h=550&op=thumbnail&path=thibault:ublog:2bpotLb0:aXp2Ab4B.jpg&w=880&sig=c6b4533604d27320f1b7ea257e562c1a2177eb33"
        },
        {
          "id": "https://driftingin.space/posts/you-might-not-need-a-crdt",
          "author": null,
          "description": "Comments",
          "link": "https://driftingin.space/posts/you-might-not-need-a-crdt",
          "publishedOn": "2022-12-05T13:57:46.000Z",
          "wordCount": 1715,
          "title": "You might not need a CRDT",
          "imageUrl": "https://driftingin.space/images/og-nocrdt-fb.png"
        },
        {
          "id": "https://mrjamesbell.com/if-you-unscrew-your-belly-button-your-bottom-will-fall-off-and-other-things-my-dad-taught-me/",
          "author": null,
          "description": "Comments",
          "link": "https://mrjamesbell.com/if-you-unscrew-your-belly-button-your-bottom-will-fall-off-and-other-things-my-dad-taught-me/",
          "publishedOn": "2022-12-05T11:00:56.000Z",
          "wordCount": 1552,
          "title": "If you unscrew your belly button, your bottom will fall off",
          "imageUrl": "https://mrjamesbell.com/wp-content/uploads/2022/12/55A9A504-9E79-4A70-9778-B052A1BC46AC.jpeg"
        },
        {
          "id": "http://www.npr.org/templates/story/story.php?storyId=92483237",
          "author": null,
          "description": "Comments",
          "link": "http://www.npr.org/templates/story/story.php?storyId=92483237",
          "publishedOn": "2022-12-05T02:28:57.000Z",
          "wordCount": 3277,
          "title": "A mediocre Dutch artist cast 'the forger's spell' (2008)",
          "imageUrl": "https://media.npr.org/include/images/facebook-default-wide-s1400-c100.jpg"
        },
        {
          "id": "https://www.theparisreview.org/blog/2015/10/20/rimbaud-ascends-the-alps/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theparisreview.org/blog/2015/10/20/rimbaud-ascends-the-alps/",
          "publishedOn": "2022-12-05T02:18:47.000Z",
          "wordCount": 1902,
          "title": "Rimbaud in the Alps (1878)",
          "imageUrl": "https://www.theparisreview.org/blog/wp-content/uploads/2015/10/gotthard_winterreise-copy.jpg"
        },
        {
          "id": "https://blog.mikeswanson.com/post/702753924034297856/activisions-faulty-anti-cheat-software",
          "author": null,
          "description": "Comments",
          "link": "https://blog.mikeswanson.com/post/702753924034297856/activisions-faulty-anti-cheat-software",
          "publishedOn": "2022-12-05T00:28:51.000Z",
          "wordCount": 2108,
          "title": "Activision’s Faulty Anti-Cheat Software",
          "imageUrl": null
        },
        {
          "id": "https://github.com/emilk/egui/commit/e1f348e4b24c2fa83d25c6a7ddfd9b38b85de161",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/emilk/egui/commit/e1f348e4b24c2fa83d25c6a7ddfd9b38b85de161",
          "publishedOn": "2022-12-05T00:21:32.000Z",
          "wordCount": 1346,
          "title": "Egui commit: Implement accessibility APIs via AccessKit",
          "imageUrl": "https://opengraph.githubassets.com/50015c3f0f88b660059a3051135840f9773bc36f1c252b60329395dcfe9f6007/emilk/egui/commit/e1f348e4b24c2fa83d25c6a7ddfd9b38b85de161"
        },
        {
          "id": "https://jackiebavaro.substack.com/p/hot-take-google-has-a-company-strategy",
          "author": null,
          "description": "Comments",
          "link": "https://jackiebavaro.substack.com/p/hot-take-google-has-a-company-strategy",
          "publishedOn": "2022-12-04T23:55:17.000Z",
          "wordCount": 4222,
          "title": "Google has a company strategy, not a product strategy",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F806b6d9d-9aff-4d27-85e1-3d49f742d37c_6000x4000.jpeg"
        },
        {
          "id": "https://www.thepilot.com/news/emergency-declared-and-curfew-ordered-following-moore-power-grid-attack/article_b3b19780-7370-11ed-865d-c78d0de5d921.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.thepilot.com/news/emergency-declared-and-curfew-ordered-following-moore-power-grid-attack/article_b3b19780-7370-11ed-865d-c78d0de5d921.html",
          "publishedOn": "2022-12-04T23:27:58.000Z",
          "wordCount": 13678,
          "title": "Emergency declared and curfew imposed following North Carolina power grid attack",
          "imageUrl": "https://bloximages.newyork1.vip.townnews.com/thepilot.com/content/tncms/assets/v3/editorial/5/c0/5c0cce58-741c-11ed-8859-cfb375a52f6b/638d1415a26c3.image.jpg?crop=1000%2C525%2C0%2C37&resize=1000%2C525&order=crop%2Cresize"
        },
        {
          "id": "https://web.stanford.edu/class/cs343/resources/purify.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://web.stanford.edu/class/cs343/resources/purify.pdf",
          "publishedOn": "2022-12-04T23:21:03.000Z",
          "wordCount": 96611,
          "title": "Memory leaks detection paper co-authored by Netflix CEO Reed Hastings in 1992 [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://news.artnet.com/art-world/archaeologists-graham-hancocks-ancient-apocalypse-fiction-2222060",
          "author": null,
          "description": "Comments",
          "link": "https://news.artnet.com/art-world/archaeologists-graham-hancocks-ancient-apocalypse-fiction-2222060",
          "publishedOn": "2022-12-04T22:58:19.000Z",
          "wordCount": 3669,
          "title": "Archaeologists ask Netflix to reclassify Graham Hancock’s docuseries as fiction",
          "imageUrl": "https://p-news-uploads.storage.googleapis.com/2022/12/GettyImages-563611513.jpg"
        },
        {
          "id": "https://gist.github.com/Gaelan/cf5ae4a1e9d8d64cb0b732cf3a38e04a",
          "author": null,
          "description": "Comments",
          "link": "https://gist.github.com/Gaelan/cf5ae4a1e9d8d64cb0b732cf3a38e04a",
          "publishedOn": "2022-12-04T22:47:24.000Z",
          "wordCount": 1332,
          "title": "ChatGPT passes the 2022 AP Computer Science A free response section",
          "imageUrl": "https://github.githubassets.com/images/modules/gists/gist-og-image.png"
        },
        {
          "id": "https://github.com/eoin-barr/weatherme",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/eoin-barr/weatherme",
          "publishedOn": "2022-12-04T22:38:32.000Z",
          "wordCount": 634,
          "title": "Weather CLI Tool",
          "imageUrl": "https://opengraph.githubassets.com/7c3aabd3b32afeec942f1f24f1e3d383bf1d0ab096078e4eaf102492eb5b0e8d/eoin-barr/weatherme"
        },
        {
          "id": "https://blog.plover.com/2022/12/04/#crap-warning-signs-2",
          "author": null,
          "description": "Comments",
          "link": "https://blog.plover.com/2022/12/04/#crap-warning-signs-2",
          "publishedOn": "2022-12-04T20:45:56.000Z",
          "wordCount": 1451,
          "title": "Software horror show: SAP Concur",
          "imageUrl": "https://pic.blog.plover.com/prog/crap-warning-signs-2/concur.png"
        },
        {
          "id": "https://corecursive.com/doomed-to-fail-with-burger-becky/",
          "author": null,
          "description": "Comments",
          "link": "https://corecursive.com/doomed-to-fail-with-burger-becky/",
          "publishedOn": "2022-12-04T19:44:04.000Z",
          "wordCount": 9655,
          "title": "Porting Doom to the 3D0 Console",
          "imageUrl": "https://corecursive.com/assets/images/083/wide.png"
        },
        {
          "id": "https://www.jamesgmartin.center/2022/11/administrators-have-seized-the-ivory-tower/",
          "author": null,
          "description": "Comments",
          "link": "https://www.jamesgmartin.center/2022/11/administrators-have-seized-the-ivory-tower/",
          "publishedOn": "2022-12-04T19:09:43.000Z",
          "wordCount": 3229,
          "title": "Administrators Have Seized the Ivory Tower",
          "imageUrl": "https://www.jamesgmartin.center/wp-content/uploads/2022/11/AdobeStock_46696567-scaled.jpeg"
        },
        {
          "id": "https://oldoperatingtheatre.com/step-into-the-role-of-a-surgeon-in-our-interactive-game/",
          "author": null,
          "description": "Comments",
          "link": "https://oldoperatingtheatre.com/step-into-the-role-of-a-surgeon-in-our-interactive-game/",
          "publishedOn": "2022-12-04T18:35:50.000Z",
          "wordCount": 1756,
          "title": "Interactive text game of surgery in early 1800s",
          "imageUrl": "https://oldoperatingtheatre.com/wp-content/uploads/2022/06/Table-surgery-kit.jpg"
        },
        {
          "id": "https://www.cyclingnews.com/news/pfc-bans-are-going-to-change-the-face-of-all-waterproof-garments/",
          "author": null,
          "description": "Comments",
          "link": "https://www.cyclingnews.com/news/pfc-bans-are-going-to-change-the-face-of-all-waterproof-garments/",
          "publishedOn": "2022-12-04T18:03:06.000Z",
          "wordCount": 30239,
          "title": "PFC bans are going to change waterproof garments",
          "imageUrl": "https://cdn.mos.cms.futurecdn.net/qBtoFJ5Twui3gAbKkxQJnW-1200-80.jpg"
        },
        {
          "id": "https://invisible-characters.com/",
          "author": null,
          "description": "Comments",
          "link": "https://invisible-characters.com/",
          "publishedOn": "2022-12-04T17:58:48.000Z",
          "wordCount": 498,
          "title": "Invisible Characters",
          "imageUrl": null
        },
        {
          "id": "https://www.chemistryworld.com/features/the-terahertz-gap-into-the-dead-zone/3004857.article",
          "author": null,
          "description": "Comments",
          "link": "https://www.chemistryworld.com/features/the-terahertz-gap-into-the-dead-zone/3004857.article",
          "publishedOn": "2022-12-04T17:14:50.000Z",
          "wordCount": 13703,
          "title": "The terahertz gap: into the dead zone (2007)",
          "imageUrl": "https://d2cbg94ubxgsnp.cloudfront.net/Pictures/1024x536/6/1/1/127611_feature-p52-terahertz-390_tcm18-78971.jpg"
        },
        {
          "id": "https://jobs.ashbyhq.com/motion/dfe19251-9d97-4e6b-b9ac-04422a697f57?utm_source=hn",
          "author": null,
          "description": "Comments",
          "link": "https://jobs.ashbyhq.com/motion/dfe19251-9d97-4e6b-b9ac-04422a697f57?utm_source=hn",
          "publishedOn": "2022-12-04T17:02:10.000Z",
          "wordCount": 1041,
          "title": "Motion (YC W20) Is Hiring a Senior SRE",
          "imageUrl": "https://app.ashbyhq.com/api/images/org-theme-social/fd4042c5-a696-4b26-9058-2ac8131c2d75/fab07bab-a363-44f7-8435-32f76868d3d3.png"
        },
        {
          "id": "https://en.wikibooks.org/wiki/Haskell/Zippers",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikibooks.org/wiki/Haskell/Zippers",
          "publishedOn": "2022-12-04T16:45:08.000Z",
          "wordCount": 6369,
          "title": "Theseus and the Zipper",
          "imageUrl": null
        },
        {
          "id": "http://www.os2museum.com/wp/undocumented-8086-opcodes-part-i/",
          "author": null,
          "description": "Comments",
          "link": "http://www.os2museum.com/wp/undocumented-8086-opcodes-part-i/",
          "publishedOn": "2022-12-04T16:16:31.000Z",
          "wordCount": 3301,
          "title": "Undocumented 8086 Opcodes part 1 (2017)",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33854815",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33854815",
          "publishedOn": "2022-12-04T16:03:19.000Z",
          "wordCount": 6560,
          "title": "Ask HN: Reading material on how to be a better software engineer?",
          "imageUrl": null
        },
        {
          "id": "https://csclub.uwaterloo.ca/resources/tech-talks/cory-doctorow-the-war-on-general-purpose-computing/",
          "author": null,
          "description": "Comments",
          "link": "https://csclub.uwaterloo.ca/resources/tech-talks/cory-doctorow-the-war-on-general-purpose-computing/",
          "publishedOn": "2022-12-04T14:54:57.000Z",
          "wordCount": 546,
          "title": "The War on General Purpose Computing (2015) [video]",
          "imageUrl": null
        },
        {
          "id": "https://github.com/wong2/chat-gpt-google-extension",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/wong2/chat-gpt-google-extension",
          "publishedOn": "2022-12-04T14:01:45.000Z",
          "wordCount": 683,
          "title": "Show HN: Chrome extension to display ChatGPT response besides Google Search",
          "imageUrl": "https://opengraph.githubassets.com/9005406f8df5499726ee7325400f46b208ef2c99a1d8bc88ea16b76400cf7078/wong2/chat-gpt-google-extension"
        },
        {
          "id": "https://garagehq.deuxfleurs.fr/",
          "author": null,
          "description": "Comments",
          "link": "https://garagehq.deuxfleurs.fr/",
          "publishedOn": "2022-12-04T13:30:27.000Z",
          "wordCount": 353,
          "title": "Garage: An open-source distributed object storage service",
          "imageUrl": null
        },
        {
          "id": "https://en.wikipedia.org/wiki/Digital_mobile_radio",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/Digital_mobile_radio",
          "publishedOn": "2022-12-04T13:22:48.000Z",
          "wordCount": 2213,
          "title": "Digital Mobile Radio",
          "imageUrl": null
        },
        {
          "id": "https://susam.net/blog/x86-quine.html",
          "author": null,
          "description": "Comments",
          "link": "https://susam.net/blog/x86-quine.html",
          "publishedOn": "2022-12-04T11:55:24.000Z",
          "wordCount": 3458,
          "title": "x86 Quine: These 12 Bytes of Machine Code Print Themselves (2005)",
          "imageUrl": null
        },
        {
          "id": "https://boxingpythagoras.com/2018/12/01/the-axiom-of-infinity/",
          "author": null,
          "description": "Comments",
          "link": "https://boxingpythagoras.com/2018/12/01/the-axiom-of-infinity/",
          "publishedOn": "2022-12-04T11:43:42.000Z",
          "wordCount": 5048,
          "title": "The Axiom of Infinity (2018)",
          "imageUrl": "https://boxingpythagoras.files.wordpress.com/2018/12/eulers_infinity_sign-svg.png?w=1200"
        },
        {
          "id": "https://goughlui.com/2022/12/04/qsl-cards-ghosts-in-the-air-glow-g1taeg-high-frequency-active-auroral-research-program-haarp/",
          "author": null,
          "description": "Comments",
          "link": "https://goughlui.com/2022/12/04/qsl-cards-ghosts-in-the-air-glow-g1taeg-high-frequency-active-auroral-research-program-haarp/",
          "publishedOn": "2022-12-04T07:59:56.000Z",
          "wordCount": 4156,
          "title": "QSL Cards: Ghosts in the Air Glow and High-Freq Active Auroral Research (HAARP)",
          "imageUrl": "https://goughlui.com/wp-content/uploads/2022/12/gitag-qsl-envelope-1024x446.jpg"
        },
        {
          "id": "https://pubchem.ncbi.nlm.nih.gov/patent/US-6506148-B2",
          "author": null,
          "description": "Comments",
          "link": "https://pubchem.ncbi.nlm.nih.gov/patent/US-6506148-B2",
          "publishedOn": "2022-12-04T05:29:48.000Z",
          "wordCount": 952,
          "title": "Nervous system manipulation by electromagnetic fields from monitors",
          "imageUrl": null
        },
        {
          "id": "https://emacsconf.org/2022/talks/wayland/",
          "author": null,
          "description": "Comments",
          "link": "https://emacsconf.org/2022/talks/wayland/",
          "publishedOn": "2022-12-04T01:27:38.000Z",
          "wordCount": 1297,
          "title": "Emacs should become a Wayland compositor",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33849267",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33849267",
          "publishedOn": "2022-12-04T00:49:57.000Z",
          "wordCount": 504,
          "title": "Ask HN: Best books read in 2022",
          "imageUrl": null
        },
        {
          "id": "https://debugger.medium.com/its-time-for-maximum-viable-product-eec9d5211156",
          "author": null,
          "description": "Comments",
          "link": "https://debugger.medium.com/its-time-for-maximum-viable-product-eec9d5211156",
          "publishedOn": "2022-12-04T00:24:11.000Z",
          "wordCount": 1400,
          "title": "It’s Time for ‘Maximum Viable Product’",
          "imageUrl": "https://miro.medium.com/max/810/0*UNWlizv-gJ4WBlon.jpg"
        },
        {
          "id": "https://fosshost.org/",
          "author": null,
          "description": "Comments",
          "link": "https://fosshost.org/",
          "publishedOn": "2022-12-03T23:18:46.000Z",
          "wordCount": 184,
          "title": "Fosshost Is Shutting Down",
          "imageUrl": null
        },
        {
          "id": "https://www.medievalists.net/2022/11/medieval-paitings-st-albans-cathedral/",
          "author": null,
          "description": "Comments",
          "link": "https://www.medievalists.net/2022/11/medieval-paitings-st-albans-cathedral/",
          "publishedOn": "2022-12-03T22:08:57.000Z",
          "wordCount": 4714,
          "title": "Recreating Medieval Paintings with Light at St Albans Cathedral",
          "imageUrl": "https://www.medievalists.net/wp-content/uploads/2022/11/mnet22113001.jpg"
        },
        {
          "id": "https://robertheaton.com/gameboy-doctor/",
          "author": null,
          "description": "Comments",
          "link": "https://robertheaton.com/gameboy-doctor/",
          "publishedOn": "2022-12-03T22:05:39.000Z",
          "wordCount": 1004,
          "title": "Gameboy Doctor: debug and fix your gameboy emulator",
          "imageUrl": "https://robertheaton.com/images/nintendo-upside-down.png"
        },
        {
          "id": "https://ericchiang.github.io/post/tpm-keys/",
          "author": null,
          "description": "Comments",
          "link": "https://ericchiang.github.io/post/tpm-keys/",
          "publishedOn": "2022-12-03T22:02:12.000Z",
          "wordCount": 3412,
          "title": "The Trusted Platform Module Key Hierarchy",
          "imageUrl": null
        },
        {
          "id": "https://www.engraved.blog/building-a-virtual-machine-inside/",
          "author": null,
          "description": "Comments",
          "link": "https://www.engraved.blog/building-a-virtual-machine-inside/",
          "publishedOn": "2022-12-03T21:19:45.000Z",
          "wordCount": 943,
          "title": "Building a Virtual Machine Inside ChatGPT",
          "imageUrl": "https://www.engraved.blog/content/images/2022/12/deepmind-mbq0qL3ynMs-unsplash.jpg"
        },
        {
          "id": "https://www.theverge.com/2022/11/30/23486753/anker-eufy-security-camera-cloud-private-encryption-authentication-storage",
          "author": null,
          "description": "Comments",
          "link": "https://www.theverge.com/2022/11/30/23486753/anker-eufy-security-camera-cloud-private-encryption-authentication-storage",
          "publishedOn": "2022-12-03T20:50:16.000Z",
          "wordCount": 9796,
          "title": "Anker’s Eufy lied to us about the security of its security cameras",
          "imageUrl": "https://cdn.vox-cdn.com/thumbor/uC-XCcXp6Rc26IZkwBYINhPNiWo=/776x6:1920x660/1200x628/filters:focal(1353x281:1354x282)/cdn.vox-cdn.com/uploads/chorus_asset/file/22525965/191106_165716_9.png"
        },
        {
          "id": "https://futurism.com/msn-is-publishing-more-fake-news",
          "author": null,
          "description": "Comments",
          "link": "https://futurism.com/msn-is-publishing-more-fake-news",
          "publishedOn": "2022-12-03T20:00:25.000Z",
          "wordCount": 4641,
          "title": "MSN replaced journalists with AI publishing fake news about mermaids and Bigfoot",
          "imageUrl": "https://wp-assets.futurism.com/2022/12/bigfoot.jpg"
        },
        {
          "id": "https://www.rfi.fr/en/france/20221201-how-france-is-preparing-to-avoid-a-major-blackout-this-winter",
          "author": null,
          "description": "Comments",
          "link": "https://www.rfi.fr/en/france/20221201-how-france-is-preparing-to-avoid-a-major-blackout-this-winter",
          "publishedOn": "2022-12-03T19:58:35.000Z",
          "wordCount": 7005,
          "title": "France prepares for possibility of electricity blackouts during winter months",
          "imageUrl": "https://s.rfi.fr/media/display/be140cfe-118e-11ea-baee-005056a99247/w:1280/p:16x9/2012-02-09T003731Z_132270829_GM1E8290O6001_RTRMADP_2_FRANCE-ELECTRICITY.JPG"
        },
        {
          "id": "https://davedelong.com/blog/2022/12/03/adventures-in-advent-of-code/",
          "author": null,
          "description": "Comments",
          "link": "https://davedelong.com/blog/2022/12/03/adventures-in-advent-of-code/",
          "publishedOn": "2022-12-03T19:36:15.000Z",
          "wordCount": 1401,
          "title": "Adventures in Advent of Code",
          "imageUrl": null
        },
        {
          "id": "https://github.com/samyk/magspoof",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/samyk/magspoof",
          "publishedOn": "2022-12-03T19:35:47.000Z",
          "wordCount": 2556,
          "title": "MagSpoof: Wireless Magstrip Spoofer",
          "imageUrl": "https://opengraph.githubassets.com/a33647a07a0808525086e42e524f269309dc08cb44a0697b79a6b80c3b1f8155/samyk/magspoof"
        },
        {
          "id": "https://austingil.com/px-or-rem-in-css/",
          "author": null,
          "description": "Comments",
          "link": "https://austingil.com/px-or-rem-in-css/",
          "publishedOn": "2022-12-03T19:35:06.000Z",
          "wordCount": 4253,
          "title": "PX or REM in CSS? Just Use REM",
          "imageUrl": "https://cdn.statically.io/img/austingil.com/f=auto%2Cq=70/wp-content/uploads/CSS%20Blog%20Cover.png"
        },
        {
          "id": "https://www.youtube.com/watch?v=OHKKcd3sx2c",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=OHKKcd3sx2c",
          "publishedOn": "2022-12-03T19:27:00.000Z",
          "wordCount": null,
          "title": "Microsoft Is Forcing Me to Buy MacBooks – Windows Modern Standby",
          "imageUrl": null
        },
        {
          "id": "https://studio.ribbonfarm.com/p/the-dawn-of-mediocre-computing",
          "author": null,
          "description": "Comments",
          "link": "https://studio.ribbonfarm.com/p/the-dawn-of-mediocre-computing",
          "publishedOn": "2022-12-03T18:45:29.000Z",
          "wordCount": 7848,
          "title": "The Dawn of Mediocre Computing",
          "imageUrl": "https://substackcdn.com/image/fetch/w_256,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff139bf53-f5dc-4d6a-a159-4478fe7cd529_1280x1280.png"
        },
        {
          "id": "https://www.righto.com/2022/11/how-8086-processors-microcode-engine.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.righto.com/2022/11/how-8086-processors-microcode-engine.html",
          "publishedOn": "2022-12-03T18:29:31.000Z",
          "wordCount": 8925,
          "title": "How the 8086 processor's microcode engine works",
          "imageUrl": "https://lh3.googleusercontent.com/blogger_img_proxy/ANbyha00BXi3rG1G9LR9M1AXf-uzS8a_GN_6R6DcIdwH5GyYLonh-Y7WLpe4ktAVWaNV1XotZfz0hUIMnOuPggJpM6qTm_mngmpyoYlgeOuQdgMvgLshqjy_hhab4-JflYQPiL-0WPvVrBF5rYY=w1200-h630-p-k-no-nu"
        },
        {
          "id": "https://danielmangum.com/categories/risc-v-bytes/",
          "author": null,
          "description": "Comments",
          "link": "https://danielmangum.com/categories/risc-v-bytes/",
          "publishedOn": "2022-12-03T18:11:38.000Z",
          "wordCount": 106,
          "title": "RISC-V Bytes",
          "imageUrl": null
        },
        {
          "id": "https://www.blockbench.net/",
          "author": null,
          "description": "Comments",
          "link": "https://www.blockbench.net/",
          "publishedOn": "2022-12-03T17:36:21.000Z",
          "wordCount": 483,
          "title": "Blockbench – A low-poly 3D model editor",
          "imageUrl": "https://blockbench.net/logo_banner.png"
        },
        {
          "id": "https://thetinycto.com/gpt-game",
          "author": null,
          "description": "Comments",
          "link": "https://thetinycto.com/gpt-game",
          "publishedOn": "2022-12-03T16:20:27.000Z",
          "wordCount": 47,
          "title": "An Elixir/LiveView game written entirely by ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.youtube.com/watch?v=b--l_0eMbo8",
          "author": null,
          "description": "Comments",
          "link": "https://www.youtube.com/watch?v=b--l_0eMbo8",
          "publishedOn": "2022-12-03T15:31:53.000Z",
          "wordCount": null,
          "title": "One of France's oldest butter producers makes 380 tons per year [video]",
          "imageUrl": null
        },
        {
          "id": "https://knightcolumbia.org/blog/why-were-suing-nso-group?_preview_=7bd805e6dc",
          "author": null,
          "description": "Comments",
          "link": "https://knightcolumbia.org/blog/why-were-suing-nso-group?_preview_=7bd805e6dc",
          "publishedOn": "2022-12-03T14:43:23.000Z",
          "wordCount": 999,
          "title": "Why We’re Suing NSO",
          "imageUrl": "https://s3.amazonaws.com/kfai-documents/images/67d004928d/a3229s1437--1-_webres.jpg"
        },
        {
          "id": "http://videocortex.io/2018/Affine-Space-Types/",
          "author": null,
          "description": "Comments",
          "link": "http://videocortex.io/2018/Affine-Space-Types/",
          "publishedOn": "2022-12-03T13:03:12.000Z",
          "wordCount": 4570,
          "title": "Affine Space Types (2018)",
          "imageUrl": "/images/favicons/favicon-194x194.png"
        },
        {
          "id": "https://github.com/bettercap/bettercap",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/bettercap/bettercap",
          "publishedOn": "2022-12-03T12:59:43.000Z",
          "wordCount": 1133,
          "title": "Bettercap – Swiss Army Knife for 802.11, BLE, IPv4 and IPv6 networks",
          "imageUrl": "https://opengraph.githubassets.com/472ec4430076061291276f1b4582e2658174cf9384f9b324058207bb1695b331/bettercap/bettercap"
        },
        {
          "id": "https://www.synthtopia.com/content/2022/12/02/moog-dancers-prove-that-tv-was-a-lot-more-adventurous-in-the-70s/",
          "author": null,
          "description": "Comments",
          "link": "https://www.synthtopia.com/content/2022/12/02/moog-dancers-prove-that-tv-was-a-lot-more-adventurous-in-the-70s/",
          "publishedOn": "2022-12-03T12:45:07.000Z",
          "wordCount": 1925,
          "title": "Moog dancers prove that TV was more adventurous in the 70s",
          "imageUrl": "https://www.synthtopia.com/wp-content/uploads/2022/12/70s-moog-dancers.jpg"
        },
        {
          "id": "https://silverbullet.md/",
          "author": null,
          "description": "Comments",
          "link": "https://silverbullet.md/",
          "publishedOn": "2022-12-03T12:35:18.000Z",
          "wordCount": 51,
          "title": "Silver Bullet: Markdown-based extensible open source personal knowledge platform",
          "imageUrl": null
        },
        {
          "id": "https://thewalrus.ca/why-the-future-is-analog/",
          "author": null,
          "description": "Comments",
          "link": "https://thewalrus.ca/why-the-future-is-analog/",
          "publishedOn": "2022-12-03T12:19:17.000Z",
          "wordCount": 6207,
          "title": "The future is analog: How to create a more human world",
          "imageUrl": "https://walrus-assets.s3.amazonaws.com/img/Sax_Analog_cg_1800.jpg"
        },
        {
          "id": "https://hedgehogreview.com/issues/hope-itself/articles/the-impotence-of-being-clever",
          "author": null,
          "description": "Comments",
          "link": "https://hedgehogreview.com/issues/hope-itself/articles/the-impotence-of-being-clever",
          "publishedOn": "2022-12-03T11:21:44.000Z",
          "wordCount": 2578,
          "title": "The impotence of being clever",
          "imageUrl": "https://s3.amazonaws.com/thr-prod/images/3805bf66fdc8023d80c5710cd836e860.1500.jpg"
        },
        {
          "id": "https://github.com/mattkrick/trebuchet-client",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/mattkrick/trebuchet-client",
          "publishedOn": "2022-12-03T10:09:35.000Z",
          "wordCount": 1174,
          "title": "Trebuchet-client: Communication through tough firewalls and bad mobile networks",
          "imageUrl": "https://opengraph.githubassets.com/cd3e015cdfeb396bd0eb72093c0523767330e509a66ca3697c07bced2bc7b79c/mattkrick/trebuchet-client"
        },
        {
          "id": "https://www.fastcompany.com/90817765/adobe-at-40-the-past-present-and-future-of-creativity-softwares-enduring-giant",
          "author": null,
          "description": "Comments",
          "link": "https://www.fastcompany.com/90817765/adobe-at-40-the-past-present-and-future-of-creativity-softwares-enduring-giant",
          "publishedOn": "2022-12-03T07:17:56.000Z",
          "wordCount": null,
          "title": "Adobe at 40",
          "imageUrl": null
        },
        {
          "id": "https://blog.hansenpartnership.com/paying-maintainers-isnt-a-magic-bullet/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.hansenpartnership.com/paying-maintainers-isnt-a-magic-bullet/",
          "publishedOn": "2022-12-03T07:02:51.000Z",
          "wordCount": null,
          "title": "Paying Maintainers Isn’t a Magic Bullet",
          "imageUrl": null
        },
        {
          "id": "https://www.ouraynews.com/feature-coverage/magpies-smart-witty-birds",
          "author": null,
          "description": "Comments",
          "link": "https://www.ouraynews.com/feature-coverage/magpies-smart-witty-birds",
          "publishedOn": "2022-12-03T03:54:02.000Z",
          "wordCount": 1065,
          "title": "Magpies – Smart, witty birds",
          "imageUrl": "https://www.ouraynews.com/sites/ouraynews.etypegoogle7.com/files/7d3e98070e_Ar02001010.jpg"
        },
        {
          "id": "https://www.spacex.com/starshield/",
          "author": null,
          "description": "Comments",
          "link": "https://www.spacex.com/starshield/",
          "publishedOn": "2022-12-02T23:53:57.000Z",
          "wordCount": 420,
          "title": "Starshield: Secured satellite network for government entities",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/mtaibbi/status/1598822959866683394",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/mtaibbi/status/1598822959866683394",
          "publishedOn": "2022-12-02T23:49:25.000Z",
          "wordCount": 470,
          "title": "The Twitter Files",
          "imageUrl": null
        },
        {
          "id": "https://mako.cc/copyrighteous/the-financial-times-has-been-printing-an-obvious-error-on-its-market-data-page-for-18-months-and-nobody-else-seems-to-have-noticed",
          "author": null,
          "description": "Comments",
          "link": "https://mako.cc/copyrighteous/the-financial-times-has-been-printing-an-obvious-error-on-its-market-data-page-for-18-months-and-nobody-else-seems-to-have-noticed",
          "publishedOn": "2022-12-02T23:39:59.000Z",
          "wordCount": 1788,
          "title": "The Financial Times has had an error on its “Market Data” page for 18 months",
          "imageUrl": "https://mako.cc/copyrighteous/wp-content/uploads/2022/11/ft-20210505-closeup-hl.png"
        },
        {
          "id": "https://simonwillison.net/2022/Dec/2/datasette-write-api/",
          "author": null,
          "description": "Comments",
          "link": "https://simonwillison.net/2022/Dec/2/datasette-write-api/",
          "publishedOn": "2022-12-02T23:23:15.000Z",
          "wordCount": 2256,
          "title": "Datasette’s new JSON write API: The first alpha of Datasette 1.0",
          "imageUrl": "https://static.simonwillison.net/static/2022/api-explorer.jpg"
        },
        {
          "id": "https://puter.com/",
          "author": null,
          "description": "Comments",
          "link": "https://puter.com/",
          "publishedOn": "2022-12-02T23:05:09.000Z",
          "wordCount": 17201,
          "title": "Puter",
          "imageUrl": "https://puter.com/assets/img/screenshot.png"
        },
        {
          "id": "https://itservices.wp.st-andrews.ac.uk/2019/06/06/the-clever-reason-scammers-cant-spell/",
          "author": null,
          "description": "Comments",
          "link": "https://itservices.wp.st-andrews.ac.uk/2019/06/06/the-clever-reason-scammers-cant-spell/",
          "publishedOn": "2022-12-02T22:41:10.000Z",
          "wordCount": 7044,
          "title": "The clever reason scammers can’t spell (2019)",
          "imageUrl": "https://itservices.wp.st-andrews.ac.uk/files/2019/06/phishing.png"
        },
        {
          "id": "https://twitter.com/id_aa_carmack/status/1598792396191375361",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/id_aa_carmack/status/1598792396191375361",
          "publishedOn": "2022-12-02T21:49:10.000Z",
          "wordCount": 470,
          "title": "Carmack on star fields in VR",
          "imageUrl": null
        },
        {
          "id": "https://gizmodo.com/tiktok-china-south-dakota-ban-bytedance-1849836201",
          "author": null,
          "description": "Comments",
          "link": "https://gizmodo.com/tiktok-china-south-dakota-ban-bytedance-1849836201",
          "publishedOn": "2022-12-02T20:48:22.000Z",
          "wordCount": 5295,
          "title": "South Dakota first to ban TikTok on state-owned devices",
          "imageUrl": "https://i.kinja-img.com/gawker-media/image/upload/c_fill,f_auto,fl_progressive,g_center,h_675,pg_1,q_80,w_1200/4eda4758e16350e3164c5c704dbe4dad.jpg"
        },
        {
          "id": "https://blog.meain.io/2022/terminal-drag-and-drop/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.meain.io/2022/terminal-drag-and-drop/",
          "publishedOn": "2022-12-02T20:19:02.000Z",
          "wordCount": 788,
          "title": "Drag and Drop from Terminal",
          "imageUrl": null
        },
        {
          "id": "http://www.backyard-ballistics.com/",
          "author": null,
          "description": "Comments",
          "link": "http://www.backyard-ballistics.com/",
          "publishedOn": "2022-12-02T20:12:27.000Z",
          "wordCount": 138,
          "title": "Backyard Ballistics",
          "imageUrl": null
        },
        {
          "id": "https://arstechnica.com/tech-policy/2022/12/starlink-speeds-in-us-dropped-from-105mbps-to-53mbps-in-the-past-year/",
          "author": null,
          "description": "Comments",
          "link": "https://arstechnica.com/tech-policy/2022/12/starlink-speeds-in-us-dropped-from-105mbps-to-53mbps-in-the-past-year/",
          "publishedOn": "2022-12-02T20:04:07.000Z",
          "wordCount": 1711,
          "title": "Starlink speeds in US dropped from 105Mbps to 53Mbps in the past year",
          "imageUrl": "https://cdn.arstechnica.net/wp-content/uploads/2022/12/starlink-antenna-760x380.jpg"
        },
        {
          "id": "https://mattstoller.substack.com/p/why-is-booz-allen-renting-us-back",
          "author": null,
          "description": "Comments",
          "link": "https://mattstoller.substack.com/p/why-is-booz-allen-renting-us-back",
          "publishedOn": "2022-12-02T19:46:19.000Z",
          "wordCount": 8747,
          "title": "Why is Booz Allen renting us back our own national parks?",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7b4f255a-c0a6-4f6f-98bd-e93cf37851fa_801x525.png"
        },
        {
          "id": "https://smaller.fish/posts/snap_updates",
          "author": null,
          "description": "Comments",
          "link": "https://smaller.fish/posts/snap_updates",
          "publishedOn": "2022-12-02T18:58:25.000Z",
          "wordCount": 2025,
          "title": "Snap updates happen without user consent",
          "imageUrl": null
        },
        {
          "id": "https://www.fcc.gov/document/fcc-partially-grants-spacex-gen2-broadband-satellite-application",
          "author": null,
          "description": "Comments",
          "link": "https://www.fcc.gov/document/fcc-partially-grants-spacex-gen2-broadband-satellite-application",
          "publishedOn": "2022-12-02T18:13:35.000Z",
          "wordCount": 556,
          "title": "FCC partially grants SpaceX Gen2 broadband satellite application",
          "imageUrl": "https://www.fcc.gov/sites/default/files/social-media-sharing-fcc-logo.jpg"
        },
        {
          "id": "https://github.blog/2022-12-02-introducing-mona-sans-and-hubot-sans/",
          "author": null,
          "description": "Comments",
          "link": "https://github.blog/2022-12-02-introducing-mona-sans-and-hubot-sans/",
          "publishedOn": "2022-12-02T17:59:56.000Z",
          "wordCount": 1685,
          "title": "Mona Sans and Hubot Sans",
          "imageUrl": "https://github.blog/wp-content/uploads/2022/11/image1.jpg"
        },
        {
          "id": "https://sqlfordevs.com/ebook",
          "author": null,
          "description": "Comments",
          "link": "https://sqlfordevs.com/ebook",
          "publishedOn": "2022-12-02T17:43:10.000Z",
          "wordCount": 688,
          "title": "Show HN: I wrote a free eBook about many lesser-known/secret database tricks",
          "imageUrl": "https://sqlfordevs.com/build/assets/opengraph_ebook.d54f5063.png"
        },
        {
          "id": "https://wasmer.io/posts/wasmer-takes-webassembly-libraries-manistream-with-wai",
          "author": null,
          "description": "Comments",
          "link": "https://wasmer.io/posts/wasmer-takes-webassembly-libraries-manistream-with-wai",
          "publishedOn": "2022-12-02T17:42:30.000Z",
          "wordCount": 1657,
          "title": "Wasmer takes WebAssembly libraries mainstream with WAI",
          "imageUrl": "https://wasmer.io/images/og-image.png"
        },
        {
          "id": "https://www.reuters.com/business/logistics-startup-flexport-plans-hiring-spree-double-engineers-2023-2022-11-02/",
          "author": null,
          "description": "Comments",
          "link": "https://www.reuters.com/business/logistics-startup-flexport-plans-hiring-spree-double-engineers-2023-2022-11-02/",
          "publishedOn": "2022-12-02T17:00:15.000Z",
          "wordCount": 4325,
          "title": "Flexport (YC W14) Is Hiring Software Engineers",
          "imageUrl": "https://www.reuters.com/resizer/PnbRZhC_S6ZWXEiQYA0w1QvHKI0=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/UU5XOQCHKBMBRNKF5EFL3BHZKA.jpg"
        },
        {
          "id": "https://acoup.blog/2022/12/02/collections-why-roman-egypt-was-such-a-strange-province/",
          "author": null,
          "description": "Comments",
          "link": "https://acoup.blog/2022/12/02/collections-why-roman-egypt-was-such-a-strange-province/",
          "publishedOn": "2022-12-02T16:46:22.000Z",
          "wordCount": 9822,
          "title": "Roman Egypt was a strange province",
          "imageUrl": "https://i0.wp.com/acoup.blog/wp-content/uploads/2022/12/image-2.png?fit=700%2C550&ssl=1"
        },
        {
          "id": "https://pytorch.org/get-started/pytorch-2.0/",
          "author": null,
          "description": "Comments",
          "link": "https://pytorch.org/get-started/pytorch-2.0/",
          "publishedOn": "2022-12-02T16:17:32.000Z",
          "wordCount": 6216,
          "title": "PyTorch 2.0",
          "imageUrl": "https://pytorch.org/assets/images/featured-img-pytorch-2.png"
        },
        {
          "id": "https://twitter.com/carnage4life/status/1598332648723976193",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/carnage4life/status/1598332648723976193",
          "publishedOn": "2022-12-02T16:08:13.000Z",
          "wordCount": 470,
          "title": "People tricking ChatGPT “like watching an Asimov novel come to life”",
          "imageUrl": null
        },
        {
          "id": "https://prabros.com/chat-ui-ideas/",
          "author": null,
          "description": "Comments",
          "link": "https://prabros.com/chat-ui-ideas/",
          "publishedOn": "2022-12-02T16:06:05.000Z",
          "wordCount": 1337,
          "title": "Interface Ideas for Chat Apps",
          "imageUrl": "https://prabros.com/chat-ui-ideas/resources/website-card.png"
        },
        {
          "id": "https://jam.dev/blog/how-to-move-fast-and-not-break-things/",
          "author": null,
          "description": "Comments",
          "link": "https://jam.dev/blog/how-to-move-fast-and-not-break-things/",
          "publishedOn": "2022-12-02T14:55:00.000Z",
          "wordCount": 1381,
          "title": "How to move fast and not break things as a remote company",
          "imageUrl": "https://strawberryjam.ghost.io/content/images/2022/12/Screen-Shot-2022-11-30-at-12.20.09-PM-copy-2.png"
        },
        {
          "id": "https://twitter.com/samwcyo/status/1597792097175674880",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/samwcyo/status/1597792097175674880",
          "publishedOn": "2022-12-02T14:48:57.000Z",
          "wordCount": 470,
          "title": "Remotely unlock/start/locate any remotely connected Honda/Nissan [resolved]",
          "imageUrl": null
        },
        {
          "id": "https://kerouacsquest.wordpress.com/",
          "author": null,
          "description": "Comments",
          "link": "https://kerouacsquest.wordpress.com/",
          "publishedOn": "2022-12-02T14:44:16.000Z",
          "wordCount": 2134,
          "title": "Kerouac's Quest",
          "imageUrl": "https://secure.gravatar.com/blavatar/035de320759e11c8bb76d8a66407f40c?s=200&ts=1670031037"
        },
        {
          "id": "https://github.com/aaronjanse/dns-over-wikipedia",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/aaronjanse/dns-over-wikipedia",
          "publishedOn": "2022-12-02T14:25:04.000Z",
          "wordCount": 689,
          "title": "DNS over Wikipedia",
          "imageUrl": "https://opengraph.githubassets.com/1ef7f36f2bb80f4667acd2b324bc2f30cac9699aa8d7ec16bd9bcc72b9dc2d82/aaronjanse/dns-over-wikipedia"
        },
        {
          "id": "https://blog.logrocket.com/exploring-competitive-features-node-js-v18-v19/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.logrocket.com/exploring-competitive-features-node-js-v18-v19/",
          "publishedOn": "2022-12-02T14:19:02.000Z",
          "wordCount": 11398,
          "title": "Exploring competitive features in Node.js v18 and v19",
          "imageUrl": "https://blog.logrocket.com/wp-content/uploads/2022/11/exploring-competitive-features-node-js-18-19.png"
        },
        {
          "id": "https://gizmodo.com/mars-megatsunami-asteroid-impact-1849840566",
          "author": null,
          "description": "Comments",
          "link": "https://gizmodo.com/mars-megatsunami-asteroid-impact-1849840566",
          "publishedOn": "2022-12-02T14:13:38.000Z",
          "wordCount": 5602,
          "title": "Evidence of an oceanic impact and megatsunami on Mars",
          "imageUrl": "https://i.kinja-img.com/gawker-media/image/upload/c_fill,f_auto,fl_progressive,g_center,h_675,pg_1,q_80,w_1200/b662b3853b6b1d7e19124482ca445347.png"
        },
        {
          "id": "https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction",
          "author": null,
          "description": "Comments",
          "link": "https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction",
          "publishedOn": "2022-12-02T13:34:19.000Z",
          "wordCount": 1823,
          "title": "How to JIT – An Introduction",
          "imageUrl": null
        },
        {
          "id": "https://www.embeddedrelated.com/showarticle/1033.php",
          "author": null,
          "description": "Comments",
          "link": "https://www.embeddedrelated.com/showarticle/1033.php",
          "publishedOn": "2022-12-02T12:44:46.000Z",
          "wordCount": 10979,
          "title": "Zebras hate you for no reason: Why Amdahl's law is misleading (2017)",
          "imageUrl": null
        },
        {
          "id": "https://www.oranlooney.com/post/encabulation/",
          "author": null,
          "description": "Comments",
          "link": "https://www.oranlooney.com/post/encabulation/",
          "publishedOn": "2022-12-02T12:12:06.000Z",
          "wordCount": 2559,
          "title": "A History of Encabulation",
          "imageUrl": null
        },
        {
          "id": "https://www.bbc.com/future/article/20221130-the-polar-dinosaurs-revealing-ancient-secrets",
          "author": null,
          "description": "Comments",
          "link": "https://www.bbc.com/future/article/20221130-the-polar-dinosaurs-revealing-ancient-secrets",
          "publishedOn": "2022-12-02T11:45:36.000Z",
          "wordCount": 11031,
          "title": "The polar dinosaurs revealing ancient secrets",
          "imageUrl": "https://ychef.files.bbci.co.uk/live/624x351/p0dkwn0d.jpg"
        },
        {
          "id": "https://www.theatlantic.com/technology/archive/2022/12/world-cup-microsoft-excel/672320/",
          "author": null,
          "description": "Comments",
          "link": "https://www.theatlantic.com/technology/archive/2022/12/world-cup-microsoft-excel/672320/",
          "publishedOn": "2022-12-02T11:18:39.000Z",
          "wordCount": 2755,
          "title": "The World Cup of Microsoft Excel",
          "imageUrl": "https://cdn.theatlantic.com/thumbor/M6UpEWzEfQVEh8lH1IccDyHzZC0=/2x21:1077x585/960x504/media/img/mt/2022/12/microsoft_excel_3/original.gif"
        },
        {
          "id": "https://github.com/bvschaik/julius",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/bvschaik/julius",
          "publishedOn": "2022-12-02T08:48:13.000Z",
          "wordCount": 1146,
          "title": "Julius: An open source re-implementation of Caesar III",
          "imageUrl": "https://repository-images.githubusercontent.com/100820555/c8cc1080-50de-11ea-8ede-1e00d73663ce"
        },
        {
          "id": "https://github.com/magma",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/magma",
          "publishedOn": "2022-12-02T07:13:44.000Z",
          "wordCount": 523,
          "title": "Magma: Open-source carrier-grade wireless networking platform for rural areas",
          "imageUrl": "https://avatars.githubusercontent.com/u/66266171?s=280&v=4"
        },
        {
          "id": "https://www.bti360.com/what-ive-learned-in-45-years-in-the-software-industry/",
          "author": null,
          "description": "Comments",
          "link": "https://www.bti360.com/what-ive-learned-in-45-years-in-the-software-industry/",
          "publishedOn": "2022-12-02T06:18:26.000Z",
          "wordCount": 2162,
          "title": "What I’ve Learned in 45 Years in the Software Industry (2021)",
          "imageUrl": null
        },
        {
          "id": "https://spectrum.ieee.org/robot-gift-guide-2022",
          "author": null,
          "description": "Comments",
          "link": "https://spectrum.ieee.org/robot-gift-guide-2022",
          "publishedOn": "2022-12-02T06:17:31.000Z",
          "wordCount": 10750,
          "title": "Robot Gift Guide 2022",
          "imageUrl": "https://spectrum.ieee.org/media-library/a-collage-of-9-photos-of-robots-including-quadrupeds-robots-wheeled-robots-and-drones.jpg?id=32177402&width=1200&height=600&coordinates=0%2C5%2C0%2C6"
        },
        {
          "id": "https://en.wikipedia.org/wiki/Libro_de_los_Juegos",
          "author": null,
          "description": "Comments",
          "link": "https://en.wikipedia.org/wiki/Libro_de_los_Juegos",
          "publishedOn": "2022-12-02T05:07:41.000Z",
          "wordCount": 4298,
          "title": "Libro de Los Juegos",
          "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Alfonso_LJ_97V.jpg/1200px-Alfonso_LJ_97V.jpg"
        },
        {
          "id": "https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html",
          "publishedOn": "2022-12-01T23:20:48.000Z",
          "wordCount": 145760,
          "title": "Accelerando (2005)",
          "imageUrl": null
        },
        {
          "id": "https://bugs.chromium.org/p/apvi/issues/detail?id=100",
          "author": null,
          "description": "Comments",
          "link": "https://bugs.chromium.org/p/apvi/issues/detail?id=100",
          "publishedOn": "2022-12-01T22:35:30.000Z",
          "wordCount": 186,
          "title": "Android platform signing key compromised",
          "imageUrl": null
        },
        {
          "id": "https://jakespracher.medium.com/machines-and-chaos-9f0e87eebe86",
          "author": null,
          "description": "Comments",
          "link": "https://jakespracher.medium.com/machines-and-chaos-9f0e87eebe86",
          "publishedOn": "2022-12-01T21:56:04.000Z",
          "wordCount": 5287,
          "title": "Machines and Chaos",
          "imageUrl": "https://miro.medium.com/max/800/1*w03-SmFh7kq4VBNXmZ23wA.jpeg"
        },
        {
          "id": "https://lessons.nihongo-app.com/",
          "author": null,
          "description": "Comments",
          "link": "https://lessons.nihongo-app.com/",
          "publishedOn": "2022-12-01T21:21:00.000Z",
          "wordCount": 383,
          "title": "Show HN: A Japanese learning app focused on efficient vocab/grammar acquisition",
          "imageUrl": "http://lessons.nihongo-app.com/assets/img/social-card.png"
        },
        {
          "id": "https://cacm.acm.org/blogs/blog-cacm/267236-the-legacy-of-peer-to-peer-systems/fulltext",
          "author": null,
          "description": "Comments",
          "link": "https://cacm.acm.org/blogs/blog-cacm/267236-the-legacy-of-peer-to-peer-systems/fulltext",
          "publishedOn": "2022-12-01T20:25:40.000Z",
          "wordCount": 1974,
          "title": "The Legacy of Peer-to-Peer Systems",
          "imageUrl": "https://cacm.acm.org/system/assets/0004/1069/092021_Baquero_CarlosBaquero.large.jpeg?1632156829&1632156829"
        },
        {
          "id": "https://machinelearning.apple.com/research/stable-diffusion-coreml-apple-silicon",
          "author": null,
          "description": "Comments",
          "link": "https://machinelearning.apple.com/research/stable-diffusion-coreml-apple-silicon",
          "publishedOn": "2022-12-01T20:21:53.000Z",
          "wordCount": 5413,
          "title": "Stable Diffusion with Core ML on Apple Silicon",
          "imageUrl": "https://mlr.cdn-apple.com/media/open_Graph_d53fcef327.jpg"
        },
        {
          "id": "https://www.jacionline.org/article/S0091-6749(22)01477-4/fulltext",
          "author": null,
          "description": "Comments",
          "link": "https://www.jacionline.org/article/S0091-6749(22)01477-4/fulltext",
          "publishedOn": "2022-12-01T20:21:08.000Z",
          "wordCount": 470,
          "title": "Gut epithelial barrier damage caused by dishwasher detergents and rinse aids",
          "imageUrl": null
        },
        {
          "id": "https://www.deepmind.com/blog/mastering-stratego-the-classic-game-of-imperfect-information",
          "author": null,
          "description": "Comments",
          "link": "https://www.deepmind.com/blog/mastering-stratego-the-classic-game-of-imperfect-information",
          "publishedOn": "2022-12-01T20:20:37.000Z",
          "wordCount": 2128,
          "title": "Mastering Stratego",
          "imageUrl": "https://assets-global.website-files.com/621e749a546b7592125f38ed/6388ce129963208649083b0e_Stratego_header_02_hd.png"
        },
        {
          "id": "https://twitter.com/id_aa_carmack/status/1598391619673358342",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/id_aa_carmack/status/1598391619673358342",
          "publishedOn": "2022-12-01T20:06:43.000Z",
          "wordCount": 470,
          "title": "Trying to get a bunch of GPUs on Google Cloud",
          "imageUrl": null
        },
        {
          "id": "https://zed.dev/blog/crdts",
          "author": null,
          "description": "Comments",
          "link": "https://zed.dev/blog/crdts",
          "publishedOn": "2022-12-01T19:03:51.000Z",
          "wordCount": 8405,
          "title": "Using CRDTs for multiplayer text editing",
          "imageUrl": "https://zed.dev/seo/og-image.png"
        },
        {
          "id": "https://discord.com/creators",
          "author": null,
          "description": "Comments",
          "link": "https://discord.com/creators",
          "publishedOn": "2022-12-01T19:01:47.000Z",
          "wordCount": 1528,
          "title": "Discord’s Creator Portal",
          "imageUrl": "https://assets-global.website-files.com/6257adef93867e50d84d30e2/635a8ef575825f77a50d2ecf_Rebrand_LinkEmbeds_Landing.png"
        },
        {
          "id": "https://twitter.com/coinbasewallet/status/1598354819735031809",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/coinbasewallet/status/1598354819735031809",
          "publishedOn": "2022-12-01T18:39:29.000Z",
          "wordCount": 470,
          "title": "Apple blocks Coinbase Wallet",
          "imageUrl": null
        },
        {
          "id": "https://stripe.com/blog/crypto-onramp",
          "author": null,
          "description": "Comments",
          "link": "https://stripe.com/blog/crypto-onramp",
          "publishedOn": "2022-12-01T17:57:38.000Z",
          "wordCount": 1542,
          "title": "An embeddable and customizable fiat-to-crypto onramp",
          "imageUrl": "https://images.ctfassets.net/fzn2n1nzq965/20KoxcW3mQezUH1iL10ajJ/106fdedf2fd5bcb0026c9d666be60317/Fiat-to-crypto-onramp-social.png?q=80"
        },
        {
          "id": "https://a002-oom03.nyc.gov/IRM/Handlers/Campaign/Attachments.ashx?attachmentId=78646d83-e510-4769-945c-4d557c9080bc",
          "author": null,
          "description": "Comments",
          "link": "https://a002-oom03.nyc.gov/IRM/Handlers/Campaign/Attachments.ashx?attachmentId=78646d83-e510-4769-945c-4d557c9080bc",
          "publishedOn": "2022-12-01T17:53:46.000Z",
          "wordCount": 12129,
          "title": "New York City hiring top rat killer",
          "imageUrl": null
        },
        {
          "id": "https://observablehq.com/@winkjs/how-to-visualize-timeline-of-a-wiki-article",
          "author": null,
          "description": "Comments",
          "link": "https://observablehq.com/@winkjs/how-to-visualize-timeline-of-a-wiki-article",
          "publishedOn": "2022-12-01T17:48:15.000Z",
          "wordCount": 1196,
          "title": "Show HN: Transform any Wikipedia article into a graphical timeline",
          "imageUrl": "https://static.observableusercontent.com/thumbnail/c88f505571e3a18d5a892cd04fbdb5ff0921813db4e8d6b54d40b1bbe8de4d12.jpg"
        },
        {
          "id": "https://security.googleblog.com/2022/12/memory-safe-languages-in-android-13.html",
          "author": null,
          "description": "Comments",
          "link": "https://security.googleblog.com/2022/12/memory-safe-languages-in-android-13.html",
          "publishedOn": "2022-12-01T17:39:14.000Z",
          "wordCount": 7770,
          "title": "Memory Safe Languages in Android 13",
          "imageUrl": "http://2.bp.blogspot.com/-7bZ5EziliZQ/VynIS9F7OAI/AAAAAAAASQ0/BJFntXCAntstZe6hQuo5KTrhi5Dyz9yHgCK4B/s1600/googlelogo_color_200x200.png"
        },
        {
          "id": "https://brave.com/private-search-ads/",
          "author": null,
          "description": "Comments",
          "link": "https://brave.com/private-search-ads/",
          "publishedOn": "2022-12-01T17:05:13.000Z",
          "wordCount": 1693,
          "title": "Brave launches private search ads",
          "imageUrl": null
        },
        {
          "id": "https://angel.co/company/hive/jobs/2435822-senior-full-stack-software-developer",
          "author": null,
          "description": "Comments",
          "link": "https://angel.co/company/hive/jobs/2435822-senior-full-stack-software-developer",
          "publishedOn": "2022-12-01T17:01:10.000Z",
          "wordCount": null,
          "title": "Hive (YC S14) is hiring engineers #3, 4 and 5 (100% Remote in Canada)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/Nixtla/statsforecast/tree/main/experiments/m3",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/Nixtla/statsforecast/tree/main/experiments/m3",
          "publishedOn": "2022-12-01T16:29:25.000Z",
          "wordCount": 1642,
          "title": "Statistical vs. Deep Learning forecasting methods",
          "imageUrl": "https://opengraph.githubassets.com/f80e5213eb7b7e2cb9e0bb7de6aaaa05c0584215d09c5bce66f388b653be2b84/Nixtla/statsforecast"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33818183",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33818183",
          "publishedOn": "2022-12-01T16:08:20.000Z",
          "wordCount": 4125,
          "title": "Launch HN: JumpWire (YC W22) – Easily encrypt customer data in your databases",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33818037",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33818037",
          "publishedOn": "2022-12-01T16:00:59.000Z",
          "wordCount": 41429,
          "title": "Ask HN: Who is hiring? (December 2022)",
          "imageUrl": null
        },
        {
          "id": "https://extism.org/blog/announcing-extism/",
          "author": null,
          "description": "Comments",
          "link": "https://extism.org/blog/announcing-extism/",
          "publishedOn": "2022-12-01T13:53:04.000Z",
          "wordCount": 1330,
          "title": "Extism: Make all software programmable with WebAssembly",
          "imageUrl": null
        },
        {
          "id": "https://kennedn.com/blog/posts/snowdon/",
          "author": null,
          "description": "Comments",
          "link": "https://kennedn.com/blog/posts/snowdon/",
          "publishedOn": "2022-12-01T13:18:50.000Z",
          "wordCount": 5018,
          "title": "Hijacking infrared to make a dumb device smart",
          "imageUrl": null
        },
        {
          "id": "https://eclecticlight.co/2022/11/30/an-a-to-z-of-keys-and-keyboards-startup-and-login/",
          "author": null,
          "description": "Comments",
          "link": "https://eclecticlight.co/2022/11/30/an-a-to-z-of-keys-and-keyboards-startup-and-login/",
          "publishedOn": "2022-12-01T10:51:58.000Z",
          "wordCount": 4325,
          "title": "An A to Z of keys and keyboards: (macOS) Startup and login",
          "imageUrl": "https://eclecticlightdotcom.files.wordpress.com/2022/11/intelmacbootmodes2.jpg"
        },
        {
          "id": "https://humanchess.abcd.party/",
          "author": null,
          "description": "Comments",
          "link": "https://humanchess.abcd.party/",
          "publishedOn": "2022-12-01T10:49:06.000Z",
          "wordCount": 762,
          "title": "Human Chess is a chess variant where playing the top engine move is forbidden",
          "imageUrl": null
        },
        {
          "id": "https://www.slynyrd.com/blog/2022/11/28/pixelblog-41-isometric-pixel-art",
          "author": null,
          "description": "Comments",
          "link": "https://www.slynyrd.com/blog/2022/11/28/pixelblog-41-isometric-pixel-art",
          "publishedOn": "2022-12-01T10:37:06.000Z",
          "wordCount": 1648,
          "title": "Isometric Pixel Art",
          "imageUrl": "http://static1.squarespace.com/static/551a19f8e4b0e8322a93850a/551b22f6e4b071275ffb699e/6384e4128e20d3406ac33293/1669926068880/Mockup_1.png?format=1500w"
        },
        {
          "id": "http://www.zimmers.net/cbmpics/c128ds.html",
          "author": null,
          "description": "Comments",
          "link": "http://www.zimmers.net/cbmpics/c128ds.html",
          "publishedOn": "2022-12-01T03:46:56.000Z",
          "wordCount": 608,
          "title": "Commodore 128D Computer (2001)",
          "imageUrl": null
        },
        {
          "id": "https://training.kalzumeus.com/newsletters/archive/do-not-end-the-week-with-nothing",
          "author": null,
          "description": "Comments",
          "link": "https://training.kalzumeus.com/newsletters/archive/do-not-end-the-week-with-nothing",
          "publishedOn": "2022-12-01T01:32:01.000Z",
          "wordCount": 4442,
          "title": "Don't End the Week with Nothing",
          "imageUrl": null
        },
        {
          "id": "https://med.stanford.edu/news/all-news/2022/11/children-mobile-phone-age.html",
          "author": null,
          "description": "Comments",
          "link": "https://med.stanford.edu/news/all-news/2022/11/children-mobile-phone-age.html",
          "publishedOn": "2022-12-01T01:03:52.000Z",
          "wordCount": 2537,
          "title": "Age that kids acquire mobile phones not linked to well-being: study",
          "imageUrl": "http://med.stanford.edu/content/dam/sm-news/images/2022/11/kids-on-phones.jpg"
        },
        {
          "id": "https://electricliterature.com/eating-well-is-a-portal-into-prousts-in-search-of-lost-time/",
          "author": null,
          "description": "Comments",
          "link": "https://electricliterature.com/eating-well-is-a-portal-into-prousts-in-search-of-lost-time/",
          "publishedOn": "2022-12-01T00:22:50.000Z",
          "wordCount": 3943,
          "title": "Eating well is a portal into Proust’s “In Search of Lost Time”",
          "imageUrl": "https://149349728.v2.pressablecdn.com/wp-content/uploads/2022/11/jonathan-pielmayer-ecbZ5gEE-60-unsplash.jpg"
        },
        {
          "id": "https://github.com/chr15m/bugout",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/chr15m/bugout",
          "publishedOn": "2022-11-30T23:06:31.000Z",
          "wordCount": 1318,
          "title": "Bugout: Browser-to-browser networking built on WebTorrent",
          "imageUrl": "https://repository-images.githubusercontent.com/144239267/4d985700-74db-11e9-9238-c7461ba9ef20"
        },
        {
          "id": "https://www.gimp.org/news/2022/11/21/gimp-27-birthday/",
          "author": null,
          "description": "Comments",
          "link": "https://www.gimp.org/news/2022/11/21/gimp-27-birthday/",
          "publishedOn": "2022-11-30T21:59:46.000Z",
          "wordCount": 615,
          "title": "GIMP Turns 27",
          "imageUrl": "https://www.gimp.org/news/2022/11/21/gimp-27-birthday//gimp-27th-birthday.jpg"
        },
        {
          "id": "https://zerforschung.org/posts/hive-en/",
          "author": null,
          "description": "Comments",
          "link": "https://zerforschung.org/posts/hive-en/",
          "publishedOn": "2022-11-30T21:47:56.000Z",
          "wordCount": 568,
          "title": "We found critical vulnerabilities in Hive Social",
          "imageUrl": "https://zerforschung.org/p/hive/hive-header.jpg"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33807621",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33807621",
          "publishedOn": "2022-11-30T21:01:22.000Z",
          "wordCount": 582,
          "title": "Meticulous (YC S21) Is Hiring #3 Founding Engineer in London",
          "imageUrl": null
        },
        {
          "id": "https://www.coindesk.com/layer2/2022/11/30/ftxs-collapse-was-a-crime-not-an-accident/",
          "author": null,
          "description": "Comments",
          "link": "https://www.coindesk.com/layer2/2022/11/30/ftxs-collapse-was-a-crime-not-an-accident/",
          "publishedOn": "2022-11-30T20:35:30.000Z",
          "wordCount": 10687,
          "title": "FTX’s collapse was a crime, not an accident",
          "imageUrl": "https://www.coindesk.com/resizer/pZGwkNYrUgcxJqFZiN_Ah1AAClA=/1200x628/center/middle/cloudfront-us-east-1.images.arcpublishing.com/coindesk/WOGSG5X3MFGABO324AEIHA2TLI.jpg"
        },
        {
          "id": "https://www.math.columbia.edu/~woit/wordpress/?p=13181",
          "author": null,
          "description": "Comments",
          "link": "https://www.math.columbia.edu/~woit/wordpress/?p=13181",
          "publishedOn": "2022-11-30T20:28:50.000Z",
          "wordCount": 3211,
          "title": "This Week's Hype",
          "imageUrl": null
        },
        {
          "id": "https://blog.google/threat-analysis-group/new-details-on-commercial-spyware-vendor-variston/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.google/threat-analysis-group/new-details-on-commercial-spyware-vendor-variston/",
          "publishedOn": "2022-11-30T20:26:31.000Z",
          "wordCount": 2512,
          "title": "New details on commercial spyware vendor Variston",
          "imageUrl": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/TAG_Social_Share_Card.max-800x800.jpg"
        },
        {
          "id": "https://blog.lastpass.com/2022/11/notice-of-recent-security-incident/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.lastpass.com/2022/11/notice-of-recent-security-incident/",
          "publishedOn": "2022-11-30T20:03:29.000Z",
          "wordCount": 1791,
          "title": "Lastpass Security Incident",
          "imageUrl": "https://blog.lastpass.com/wp-content/uploads/sites/20/2022/08/iStock-621574390-1-scaled.jpg"
        },
        {
          "id": "https://medium.com/microsoft-design/the-feelings-monster-building-a-character-with-all-the-feels-331b5b871fd1",
          "author": null,
          "description": "Comments",
          "link": "https://medium.com/microsoft-design/the-feelings-monster-building-a-character-with-all-the-feels-331b5b871fd1",
          "publishedOn": "2022-11-30T19:39:29.000Z",
          "wordCount": 4543,
          "title": "The Feelings Monster: building a character with all the feels",
          "imageUrl": "https://miro.medium.com/max/1200/1*WYqyJdna9XJns8ruzMZpwA.png"
        },
        {
          "id": "https://souffle-lang.github.io/index.html",
          "author": null,
          "description": "Comments",
          "link": "https://souffle-lang.github.io/index.html",
          "publishedOn": "2022-11-30T19:39:10.000Z",
          "wordCount": 245,
          "title": "Soufflé: A Datalog Synthesis Tool for Static Analysis",
          "imageUrl": null
        },
        {
          "id": "https://github.com/ericchiang/pup",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/ericchiang/pup",
          "publishedOn": "2022-11-30T18:55:16.000Z",
          "wordCount": 1552,
          "title": "Pup: Parsing HTML at the command line",
          "imageUrl": "https://opengraph.githubassets.com/9fd7a0e3879eef1d1645ea3c13b4303f8b6e91cc821eb8d4d6181fe5ec00e0e4/ericchiang/pup"
        },
        {
          "id": "https://blog.readyset.io/bounds-checks/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.readyset.io/bounds-checks/",
          "publishedOn": "2022-11-30T18:38:30.000Z",
          "wordCount": 2604,
          "title": "How much does Rust's bounds checking cost?",
          "imageUrl": "https://blog.readyset.io/content/images/2022/11/Box-2.png"
        },
        {
          "id": "https://www.reuters.com/technology/spotify-ceo-renews-attack-apple-after-musks-salvo-2022-11-30/",
          "author": null,
          "description": "Comments",
          "link": "https://www.reuters.com/technology/spotify-ceo-renews-attack-apple-after-musks-salvo-2022-11-30/",
          "publishedOn": "2022-11-30T18:24:28.000Z",
          "wordCount": 4329,
          "title": "Spotify CEO renews attack on Apple after Musk's salvo",
          "imageUrl": "https://www.reuters.com/resizer/eaGtPGQCFrd_deFKlxeqleC39cE=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/3ENTEOHF3VIRRNICTKZYCYNK54.jpg"
        },
        {
          "id": "https://openai.com/blog/chatgpt/",
          "author": null,
          "description": "Comments",
          "link": "https://openai.com/blog/chatgpt/",
          "publishedOn": "2022-11-30T18:08:01.000Z",
          "wordCount": 3607,
          "title": "OpenAI ChatGPT: Optimizing language models for dialogue",
          "imageUrl": "https://openai.com/content/images/2022/11/ChatGPT.jpg"
        },
        {
          "id": "https://www.thenation.com/article/society/john-von-neumann/",
          "author": null,
          "description": "Comments",
          "link": "https://www.thenation.com/article/society/john-von-neumann/",
          "publishedOn": "2022-11-30T18:03:24.000Z",
          "wordCount": 11475,
          "title": "The game theory of John von Neumann transformed the 20th century",
          "imageUrl": "https://www.thenation.com/wp-content/uploads/2022/11/Qian-Nirenberg-John_von_Neumann-ftr.jpg"
        },
        {
          "id": "https://www.lumafield.com/article/is-this-toner-half-empty-or-half-full",
          "author": null,
          "description": "Comments",
          "link": "https://www.lumafield.com/article/is-this-toner-half-empty-or-half-full",
          "publishedOn": "2022-11-30T18:00:42.000Z",
          "wordCount": 13772,
          "title": "CT scan shows there's still lots of toner left in an “empty” cartridge",
          "imageUrl": "https://images.prismic.io/lumafield/c28037ba-3bbb-4448-8022-158ca7b35c43_Frame+18.png?auto=compress,format"
        },
        {
          "id": "https://ericlippert.com/2022/11/30/a-long-expected-update/",
          "author": null,
          "description": "Comments",
          "link": "https://ericlippert.com/2022/11/30/a-long-expected-update/",
          "publishedOn": "2022-11-30T17:36:09.000Z",
          "wordCount": 5016,
          "title": "The last three years of my work will be permanently abandoned",
          "imageUrl": "https://ericlippert.files.wordpress.com/2022/11/315430000_10166816399390203_290434576549125796_n.jpg"
        },
        {
          "id": "https://doordash.news/company/teamupdate/",
          "author": null,
          "description": "Comments",
          "link": "https://doordash.news/company/teamupdate/",
          "publishedOn": "2022-11-30T16:54:01.000Z",
          "wordCount": 2647,
          "title": "DoorDash lays off 1250 employees",
          "imageUrl": "https://doordash.news/wp-content/uploads/2022/07/DoorDash_icon_RGB.jpg"
        },
        {
          "id": "https://program-repair.org/",
          "author": null,
          "description": "Comments",
          "link": "https://program-repair.org/",
          "publishedOn": "2022-11-30T16:16:05.000Z",
          "wordCount": 342,
          "title": "Program-repair: Community for discovery, access and systematization of data",
          "imageUrl": null
        },
        {
          "id": "https://brettscott.substack.com/p/casino-chip-cashless-society",
          "author": null,
          "description": "Comments",
          "link": "https://brettscott.substack.com/p/casino-chip-cashless-society",
          "publishedOn": "2022-11-30T15:24:26.000Z",
          "wordCount": 10488,
          "title": "The Casino-Chip Society",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F65404f2b-81ce-452c-8e9d-f028b1f20323_2778x2778.png"
        },
        {
          "id": "https://news.ycombinator.com/item?id=33801314",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33801314",
          "publishedOn": "2022-11-30T14:37:36.000Z",
          "wordCount": 3598,
          "title": "Launch HN: Patterns (YC S21) – A much faster way to build and deploy data apps",
          "imageUrl": null
        },
        {
          "id": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6542665/",
          "author": null,
          "description": "Comments",
          "link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6542665/",
          "publishedOn": "2022-11-30T14:30:56.000Z",
          "wordCount": 14595,
          "title": "The persistent and pervasive impact of bullying in childhood and adolescence",
          "imageUrl": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-logo-share.png?_=0"
        },
        {
          "id": "https://about.gitlab.com/blog/2022/11/30/introducing-gitlab-dedicated/",
          "author": null,
          "description": "Comments",
          "link": "https://about.gitlab.com/blog/2022/11/30/introducing-gitlab-dedicated/",
          "publishedOn": "2022-11-30T14:10:04.000Z",
          "wordCount": 1133,
          "title": "Gitlab Dedicated – our new single-tenant SaaS offering",
          "imageUrl": "https://about.gitlab.com/images/blogimages/screenshot-2022-11-30-at-7.49.51-am.png"
        },
        {
          "id": "https://foundersatwork.posthaven.com/grow-the-puzzle-around-you",
          "author": null,
          "description": "Comments",
          "link": "https://foundersatwork.posthaven.com/grow-the-puzzle-around-you",
          "publishedOn": "2022-11-30T12:37:48.000Z",
          "wordCount": 3895,
          "title": "Grow the Puzzle Around You (2018)",
          "imageUrl": "https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2099198/DUrX_NAb6X8LJx4sJ7078isPVJw/large_Table_2.jpg"
        },
        {
          "id": "https://lunatic.solutions/",
          "author": null,
          "description": "Comments",
          "link": "https://lunatic.solutions/",
          "publishedOn": "2022-11-30T12:33:02.000Z",
          "wordCount": 618,
          "title": "Lunatic is an Erlang-inspired runtime for WebAssembly",
          "imageUrl": "https://lunatic.solutions/static/lunatic-logo-01b6c0a7ae6b4f4a6fffa073bc636b14.png"
        },
        {
          "id": "https://github.com/jgosar/mine-city-2000",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/jgosar/mine-city-2000",
          "publishedOn": "2022-11-30T11:57:54.000Z",
          "wordCount": 1349,
          "title": "Convert SimCity 2000 cities into Minecraft worlds",
          "imageUrl": "https://opengraph.githubassets.com/bb091133eea5e28ad7820e64e3727eb20e12f5e4d3b0b33c8d00b6e492923bba/jgosar/mine-city-2000"
        },
        {
          "id": "https://www.inkandswitch.com/inkbase/",
          "author": null,
          "description": "Comments",
          "link": "https://www.inkandswitch.com/inkbase/",
          "publishedOn": "2022-11-30T11:55:54.000Z",
          "wordCount": 9470,
          "title": "Inkbase: Programmable Ink",
          "imageUrl": "https://www.inkandswitch.com/inkbase/static/social-image--16x9--1024w.jpg"
        },
        {
          "id": "https://fly.io/blog/how-we-built-fly-postgres/",
          "author": null,
          "description": "Comments",
          "link": "https://fly.io/blog/how-we-built-fly-postgres/",
          "publishedOn": "2022-11-30T09:11:45.000Z",
          "wordCount": 3145,
          "title": "How We Built Fly Postgres",
          "imageUrl": "https://fly.io/blog/2022-11-29/keepers-proxies-thumbnail.jpg"
        },
        {
          "id": "http://www.50dollarsat.info/",
          "author": null,
          "description": "Comments",
          "link": "http://www.50dollarsat.info/",
          "publishedOn": "2022-11-30T01:07:31.000Z",
          "wordCount": 572,
          "title": "$50SAT",
          "imageUrl": null
        },
        {
          "id": "https://www.wyldcard.io/blog/introducing-wyldcard",
          "author": null,
          "description": "Comments",
          "link": "https://www.wyldcard.io/blog/introducing-wyldcard",
          "publishedOn": "2022-11-30T00:24:09.000Z",
          "wordCount": 8638,
          "title": "Show HN: Trading cards made with e-ink displays",
          "imageUrl": "http://static1.squarespace.com/static/62c61d20595e6812f3b09f62/t/63869e0066ef155fd65896b4/1669766662608/973415FE-F658-4D57-9670-11DD5CE728EE.jpeg?format=1500w"
        },
        {
          "id": "https://nwn.blogs.com/nwn/2022/11/michelle-huang-ai-art-gpt-diary-conversation.html",
          "author": null,
          "description": "Comments",
          "link": "https://nwn.blogs.com/nwn/2022/11/michelle-huang-ai-art-gpt-diary-conversation.html",
          "publishedOn": "2022-11-30T00:20:36.000Z",
          "wordCount": 2324,
          "title": "Artist feeds childhood diary into GPT-3 to have a moving chat with herself",
          "imageUrl": "https://nwn.blogs.com/.a/6a00d8341bf74053ef02af1c91812c200d-600wi"
        },
        {
          "id": "https://arxiv.org/abs/2211.05824",
          "author": null,
          "description": "Comments",
          "link": "https://arxiv.org/abs/2211.05824",
          "publishedOn": "2022-11-30T00:02:16.000Z",
          "wordCount": 667,
          "title": "No Privacy in the Electronics Repair Industry",
          "imageUrl": null
        },
        {
          "id": "https://github.com/MostlyEmre/hn-anti-paywall",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/MostlyEmre/hn-anti-paywall",
          "publishedOn": "2022-11-29T23:08:53.000Z",
          "wordCount": 793,
          "title": "Show HN: A userscript that adds archive URLs below the paywalled HN submissions",
          "imageUrl": "https://opengraph.githubassets.com/4b00d5f69a2390dfd7152fee74ec59b7db7a902e5c43e937551e836c123632bc/MostlyEmre/hn-anti-paywall"
        },
        {
          "id": "https://unfairnation.substack.com/p/the-mall-only-has-3-stores",
          "author": null,
          "description": "Comments",
          "link": "https://unfairnation.substack.com/p/the-mall-only-has-3-stores",
          "publishedOn": "2022-11-29T22:57:24.000Z",
          "wordCount": 3199,
          "title": "The Mall Only Has 3 Stores",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5da07479-6d42-4202-b66d-6ef700765ac7_1784x826.png"
        },
        {
          "id": "https://netmeister.org/blog/nsauth-diversity.html",
          "author": null,
          "description": "Comments",
          "link": "https://netmeister.org/blog/nsauth-diversity.html",
          "publishedOn": "2022-11-29T22:49:53.000Z",
          "wordCount": 2328,
          "title": "Who Controls the Internet? Authoritative NS Records in gTLDs",
          "imageUrl": "https://www.netmeister.org/blog/images/nsauth.png"
        },
        {
          "id": "https://sgx.fail/",
          "author": null,
          "description": "Comments",
          "link": "https://sgx.fail/",
          "publishedOn": "2022-11-29T22:01:04.000Z",
          "wordCount": 4502,
          "title": "How Stuff Gets eXposed",
          "imageUrl": null
        },
        {
          "id": "https://blog.sunfishcode.online/measuring-system-interface-complexity/",
          "author": null,
          "description": "Comments",
          "link": "https://blog.sunfishcode.online/measuring-system-interface-complexity/",
          "publishedOn": "2022-11-29T21:51:19.000Z",
          "wordCount": 861,
          "title": "Measuring System Interface Complexity",
          "imageUrl": ""
        },
        {
          "id": "https://www.nps.gov/havo/learn/nature/peles-hair.htm",
          "author": null,
          "description": "Comments",
          "link": "https://www.nps.gov/havo/learn/nature/peles-hair.htm",
          "publishedOn": "2022-11-29T21:31:41.000Z",
          "wordCount": 967,
          "title": "Pele's Hair",
          "imageUrl": "https://www.nps.gov/havo/learn/nature/images/HAVO_20120608_Pele-s-Hair-Curly.jpg"
        },
        {
          "id": "https://marvinh.dev/blog/speeding-up-javascript-ecosystem/",
          "author": null,
          "description": "Comments",
          "link": "https://marvinh.dev/blog/speeding-up-javascript-ecosystem/",
          "publishedOn": "2022-11-29T21:27:58.000Z",
          "wordCount": 2498,
          "title": "Speeding up the JavaScript ecosystem, one library at a time",
          "imageUrl": "https://marvinh.dev/media/me-twitter.jpg"
        },
        {
          "id": "https://anlucas.neocities.org/88x31Buttons.html",
          "author": null,
          "description": "Comments",
          "link": "https://anlucas.neocities.org/88x31Buttons.html",
          "publishedOn": "2022-11-29T21:04:37.000Z",
          "wordCount": 127,
          "title": "A collection of 88x31 pixel web buttons from the 1990s and 2000s",
          "imageUrl": null
        },
        {
          "id": "https://www.ycombinator.com/companies/charge-robotics/jobs/VFEVUkD-mechanical-engineer",
          "author": null,
          "description": "Comments",
          "link": "https://www.ycombinator.com/companies/charge-robotics/jobs/VFEVUkD-mechanical-engineer",
          "publishedOn": "2022-11-29T21:00:46.000Z",
          "wordCount": 2261,
          "title": "Charge Robotics (YC S21) is hiring meches to build robots that build solar farms",
          "imageUrl": "https://bookface-images.s3.amazonaws.com/logos/b8ea1101977ba2a22e08ca0abf3dc37cc684181f.png?1655148584"
        },
        {
          "id": "https://github.com/cnlohr/mini-rv32ima",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/cnlohr/mini-rv32ima",
          "publishedOn": "2022-11-29T20:40:30.000Z",
          "wordCount": 1351,
          "title": "A tiny C header-only RISC-V emulator",
          "imageUrl": "https://opengraph.githubassets.com/43a9e2234f808cd0752d3a1655848096937b825a7bf3c67df6a1f913756010e9/cnlohr/mini-rv32ima"
        },
        {
          "id": "https://blog.saeloun.com/2022/11/22/data-immutable-object.html",
          "author": null,
          "description": "Comments",
          "link": "https://blog.saeloun.com/2022/11/22/data-immutable-object.html",
          "publishedOn": "2022-11-29T20:32:34.000Z",
          "wordCount": 2040,
          "title": "Ruby adds a core class called Data to represent simple immutable value objects",
          "imageUrl": "https://blog.saeloun.com/images/og_logo.png"
        },
        {
          "id": "https://singlepage.cc/",
          "author": null,
          "description": "Comments",
          "link": "https://singlepage.cc/",
          "publishedOn": "2022-11-29T20:14:31.000Z",
          "wordCount": 16,
          "title": "Show HN: SinglePage – Quickly and anonymously publish a page to the web",
          "imageUrl": null
        },
        {
          "id": "https://addons.mozilla.org/en-US/firefox/addon/firefox-translations/",
          "author": null,
          "description": "Comments",
          "link": "https://addons.mozilla.org/en-US/firefox/addon/firefox-translations/",
          "publishedOn": "2022-11-29T19:59:52.000Z",
          "wordCount": 1806,
          "title": "Firefox Translations: Translate websites in your browser without using the cloud",
          "imageUrl": "https://addons.mozilla.org/user-media/previews/full/270/270007.png?modified=1654879685"
        },
        {
          "id": "https://wasmedge.org/",
          "author": null,
          "description": "Comments",
          "link": "https://wasmedge.org/",
          "publishedOn": "2022-11-29T19:49:46.000Z",
          "wordCount": 660,
          "title": "WasmEdge",
          "imageUrl": "img/wasmedge-runtime-horizontal-color.png"
        },
        {
          "id": "https://auxiliarymemory.com/2017/01/06/rereading-the-soul-of-a-new-machine-by-tracy-kidder/",
          "author": null,
          "description": "Comments",
          "link": "https://auxiliarymemory.com/2017/01/06/rereading-the-soul-of-a-new-machine-by-tracy-kidder/",
          "publishedOn": "2022-11-29T19:40:53.000Z",
          "wordCount": 7158,
          "title": "Rereading: The Soul of a New Machine by Tracy Kidder (2017)",
          "imageUrl": "https://jameswharris.files.wordpress.com/2017/01/the-soul-of-a-new-machine-by-tracy-kidder_thumb.jpg"
        },
        {
          "id": "https://aiquiz.ronsor.com/index.jsp?__qs=KBGIOLC",
          "author": null,
          "description": "Comments",
          "link": "https://aiquiz.ronsor.com/index.jsp?__qs=KBGIOLC",
          "publishedOn": "2022-11-29T19:36:34.000Z",
          "wordCount": 172,
          "title": "Show HN: Can you tell if an image is AI-generated?",
          "imageUrl": null
        },
        {
          "id": "https://webtorrent.io/faq",
          "author": null,
          "description": "Comments",
          "link": "https://webtorrent.io/faq",
          "publishedOn": "2022-11-29T17:08:04.000Z",
          "wordCount": 3176,
          "title": "WebTorrent",
          "imageUrl": "/img/WebTorrent.png"
        },
        {
          "id": "https://asahilinux.org/2022/11/tales-of-the-m1-gpu/",
          "author": null,
          "description": "Comments",
          "link": "https://asahilinux.org/2022/11/tales-of-the-m1-gpu/",
          "publishedOn": "2022-11-29T16:50:20.000Z",
          "wordCount": 4177,
          "title": "Tales of the M1 GPU",
          "imageUrl": "https://asahilinux.org/img/AsahiLinux_logomark_256px.png"
        },
        {
          "id": "https://www.polarsignals.com/blog/posts/2022/11/29/profiling-without-frame-pointers/",
          "author": null,
          "description": "Comments",
          "link": "https://www.polarsignals.com/blog/posts/2022/11/29/profiling-without-frame-pointers/",
          "publishedOn": "2022-11-29T15:34:58.000Z",
          "wordCount": 4085,
          "title": "DWARF-Based Stack Walking Using eBPF",
          "imageUrl": "https://polarsignals.com/api/og?title=DWARF-based%20Stack%20Walking%20Using%20eBPF&authors=Javier%20Honduvilla%20Coto&tags=Profiling,BPF,eBPF,observability,frame%20pointers,dwarf,dwarf-based%20unwinding,.eh_frame,Parca%20Agent"
        },
        {
          "id": "http://dtrace.org/blogs/bmc/2022/11/27/homebrew-social-networking/",
          "author": null,
          "description": "Comments",
          "link": "http://dtrace.org/blogs/bmc/2022/11/27/homebrew-social-networking/",
          "publishedOn": "2022-11-29T14:56:10.000Z",
          "wordCount": 2053,
          "title": "Homebrew Social Networking",
          "imageUrl": "http://dtrace.org/blogs/ahl/files/2011/10/icon.png"
        },
        {
          "id": "https://ryxcommar.com/2022/11/27/goodbye-data-science/",
          "author": null,
          "description": "Comments",
          "link": "https://ryxcommar.com/2022/11/27/goodbye-data-science/",
          "publishedOn": "2022-11-29T13:26:14.000Z",
          "wordCount": 4154,
          "title": "Goodbye, data science",
          "imageUrl": "https://s0.wp.com/i/blank.jpg"
        },
        {
          "id": "https://jakelazaroff.com/words/tailwind-is-a-leaky-abstraction/",
          "author": null,
          "description": "Comments",
          "link": "https://jakelazaroff.com/words/tailwind-is-a-leaky-abstraction/",
          "publishedOn": "2022-11-29T13:19:50.000Z",
          "wordCount": 1100,
          "title": "Tailwind is a leaky abstraction",
          "imageUrl": "https://jakelazaroff.com/public/og/tailwind-is-a-leaky-abstraction.png"
        },
        {
          "id": "https://zentralwerkstatt.org/blog/ten-years-of-image-synthesis",
          "author": null,
          "description": "Comments",
          "link": "https://zentralwerkstatt.org/blog/ten-years-of-image-synthesis",
          "publishedOn": "2022-11-29T06:37:03.000Z",
          "wordCount": 9739,
          "title": "Ten Years of Image Synthesis",
          "imageUrl": "http://static1.squarespace.com/static/5f2e7799bdd0a0444860df21/t/636d5f8288190c4391e9e8ec/1668112258862/DALL%C2%B7E+2022-11-10+11.47.55+-+Do+you+know+why+I+stopped+you+today%3F.png?format=1500w"
        },
        {
          "id": "https://www.additudemag.com/adhd-medication-no-cardiovascular-risk-hypertension-heart-failure/",
          "author": null,
          "description": "Comments",
          "link": "https://www.additudemag.com/adhd-medication-no-cardiovascular-risk-hypertension-heart-failure/",
          "publishedOn": "2022-11-29T01:12:40.000Z",
          "wordCount": 4291,
          "title": "ADHD Medication Not Associated with Cardiovascular Risk at Any Age",
          "imageUrl": "https://i0.wp.com/www.additudemag.com/wp-content/uploads/2020/02/cropped-additude-favicon-512x512-1.png"
        },
        {
          "id": "https://nitter.it/",
          "author": null,
          "description": "Comments",
          "link": "https://nitter.it/",
          "publishedOn": "2022-11-29T00:49:26.000Z",
          "wordCount": null,
          "title": "Nitter.it: Unavailable for Legal Reasons",
          "imageUrl": null
        },
        {
          "id": "https://cyberlaw.stanford.edu/blog/2022/11/eus-top-telecom-regulator-big-telecoms-proposal-force-websites-pay-them-puts-internet",
          "author": null,
          "description": "Comments",
          "link": "https://cyberlaw.stanford.edu/blog/2022/11/eus-top-telecom-regulator-big-telecoms-proposal-force-websites-pay-them-puts-internet",
          "publishedOn": "2022-11-29T00:40:32.000Z",
          "wordCount": 2935,
          "title": "EU Regulator: Proposal to force websites to pay telcos puts Internet at risk",
          "imageUrl": null
        },
        {
          "id": "https://github.com/jupyterlite/jupyterlite",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/jupyterlite/jupyterlite",
          "publishedOn": "2022-11-29T00:33:03.000Z",
          "wordCount": 1056,
          "title": "JupyterLite is a JupyterLab distribution that runs in the browser",
          "imageUrl": "https://opengraph.githubassets.com/01bd5cd9cc638338c3aa023a567a7929239b81ba6d5a983f5740123a0ffa7c91/jupyterlite/jupyterlite"
        },
        {
          "id": "https://www.wsj.com/articles/elon-musk-boring-company-tunnel-traffic-11669658396",
          "author": null,
          "description": "Comments",
          "link": "https://www.wsj.com/articles/elon-musk-boring-company-tunnel-traffic-11669658396",
          "publishedOn": "2022-11-29T00:31:34.000Z",
          "wordCount": 5504,
          "title": "Musk’s Boring Company Ghosts Cities Across America",
          "imageUrl": "https://images.wsj.net/im-673064/social"
        },
        {
          "id": "https://www.nytimes.com/2022/11/28/magazine/cardboard-international-paper.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/2022/11/28/magazine/cardboard-international-paper.html",
          "publishedOn": "2022-11-28T23:29:47.000Z",
          "wordCount": null,
          "title": "Where does all the cardboard come from?",
          "imageUrl": null
        },
        {
          "id": "https://beta.openai.com/docs/models/overview",
          "author": null,
          "description": "Comments",
          "link": "https://beta.openai.com/docs/models/overview",
          "publishedOn": "2022-11-28T22:22:54.000Z",
          "wordCount": 10,
          "title": "New GPT-3 model: text-DaVinci-003",
          "imageUrl": "https://beta.openai.com/curl.png"
        },
        {
          "id": "https://minimaxir.com/2022/11/stable-diffusion-negative-prompt/",
          "author": null,
          "description": "Comments",
          "link": "https://minimaxir.com/2022/11/stable-diffusion-negative-prompt/",
          "publishedOn": "2022-11-28T22:06:44.000Z",
          "wordCount": 1840,
          "title": "Stable Diffusion 2.0 and the Importance of Negative Prompts for Good Results",
          "imageUrl": "https://minimaxir.com/2022/11/stable-diffusion-negative-prompt/featured.png"
        },
        {
          "id": "https://www.ycombinator.com/companies/ivy/jobs",
          "author": null,
          "description": "Comments",
          "link": "https://www.ycombinator.com/companies/ivy/jobs",
          "publishedOn": "2022-11-28T21:52:15.000Z",
          "wordCount": 1584,
          "title": "Ivy (YC W23) Is Hiring Engineers to Unify ML",
          "imageUrl": "https://bookface-images.s3.amazonaws.com/logos/6c64b68ba3315050c6c3b397ac235d570d2564bf.png?1657386061"
        },
        {
          "id": "https://scribe.citizen4.eu/your-friends-have-more-friends-than-you-e005796841bb",
          "author": null,
          "description": "Comments",
          "link": "https://scribe.citizen4.eu/your-friends-have-more-friends-than-you-e005796841bb",
          "publishedOn": "2022-11-28T21:37:58.000Z",
          "wordCount": 1951,
          "title": "A friendly introduction to the Friendship Paradox (2021)",
          "imageUrl": null
        },
        {
          "id": "https://github.blog/2022-11-28-to-infinity-and-beyond-enabling-the-future-of-githubs-rest-api-with-api-versioning/",
          "author": null,
          "description": "Comments",
          "link": "https://github.blog/2022-11-28-to-infinity-and-beyond-enabling-the-future-of-githubs-rest-api-with-api-versioning/",
          "publishedOn": "2022-11-28T21:00:23.000Z",
          "wordCount": 1528,
          "title": "Enabling the Future of GitHub's REST API with API Versioning",
          "imageUrl": "https://github.blog/wp-content/uploads/2022/03/Engineering-Product@2x-1.png"
        },
        {
          "id": "https://www.nytimes.com/interactive/2022/11/27/us/set-adrift.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.nytimes.com/interactive/2022/11/27/us/set-adrift.html",
          "publishedOn": "2022-11-28T20:36:08.000Z",
          "wordCount": 7412,
          "title": "Set Adrift",
          "imageUrl": "https://static01.nyt.com/images/2022/11/11/us/11pacific-static-promo/11pacific-static-promo-facebookJumbo.jpg"
        },
        {
          "id": "https://twitter.com/tibor/status/1597296268275240960",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/tibor/status/1597296268275240960",
          "publishedOn": "2022-11-28T19:25:16.000Z",
          "wordCount": 399,
          "title": "AirDrop is now limited to 10 minutes",
          "imageUrl": null
        },
        {
          "id": "https://jasmcole.com/2022/09/25/flipping-out/",
          "author": null,
          "description": "Comments",
          "link": "https://jasmcole.com/2022/09/25/flipping-out/",
          "publishedOn": "2022-11-28T17:47:17.000Z",
          "wordCount": 4113,
          "title": "How thick is a three-sided coin?",
          "imageUrl": "https://jasmcole.files.wordpress.com/2022/09/image.png?w=1200"
        },
        {
          "id": "https://www.cloudquery.io/blog/building-cloudquery",
          "author": null,
          "description": "Comments",
          "link": "https://www.cloudquery.io/blog/building-cloudquery",
          "publishedOn": "2022-11-28T17:29:35.000Z",
          "wordCount": 2185,
          "title": "Building a High Performance Data Integration Framework in Go",
          "imageUrl": "https://www.cloudquery.io/og-image/Building CloudQuery: High Performance Data Integration Framework in Go"
        },
        {
          "id": "https://www.newyorker.com/magazine/2022/12/05/how-hospice-became-a-for-profit-hustle",
          "author": null,
          "description": "Comments",
          "link": "https://www.newyorker.com/magazine/2022/12/05/how-hospice-became-a-for-profit-hustle",
          "publishedOn": "2022-11-28T16:17:28.000Z",
          "wordCount": 60492,
          "title": "How hospice became a for profit hustle",
          "imageUrl": "https://media.newyorker.com/photos/637d33c2926717b3889b337e/16:9/w_1280,c_limit/221205_r41465.jpg"
        },
        {
          "id": "https://f-droid.org/2022/11/23/why-curation-and-decentralization-is-better-than-millions-of-apps.html",
          "author": null,
          "description": "Comments",
          "link": "https://f-droid.org/2022/11/23/why-curation-and-decentralization-is-better-than-millions-of-apps.html",
          "publishedOn": "2022-11-28T16:13:10.000Z",
          "wordCount": 1185,
          "title": "Curation and decentralization is better than millions of apps",
          "imageUrl": "https://f-droid.org/assets/fdroid-logo_bfHl7nsLHOUQxzdU8-rGIhn4bAgl6z7k2mA3fWoCyT4=.png"
        },
        {
          "id": "https://www.realworldtech.com/forum/?threadid=209249&curpostid=209596",
          "author": null,
          "description": "Comments",
          "link": "https://www.realworldtech.com/forum/?threadid=209249&curpostid=209596",
          "publishedOn": "2022-11-28T16:08:12.000Z",
          "wordCount": 4915,
          "title": "AVX 512 will be the future",
          "imageUrl": null
        },
        {
          "id": "http://www.technoblogy.com/show?3UKF",
          "author": null,
          "description": "Comments",
          "link": "http://www.technoblogy.com/show?3UKF",
          "publishedOn": "2022-11-28T15:54:36.000Z",
          "wordCount": 4118,
          "title": "The ATtiny 2-Series",
          "imageUrl": null
        },
        {
          "id": "https://github.com/drwhut/tabletop-club",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/drwhut/tabletop-club",
          "publishedOn": "2022-11-28T15:51:33.000Z",
          "wordCount": 954,
          "title": "Open-source tabletop board game simulator",
          "imageUrl": "https://repository-images.githubusercontent.com/275376397/6d84ce51-f669-49ce-b8d3-5e70e316eb94"
        },
        {
          "id": "https://macmenubar.com/",
          "author": null,
          "description": "Comments",
          "link": "https://macmenubar.com/",
          "publishedOn": "2022-11-28T15:40:15.000Z",
          "wordCount": 1019,
          "title": "A curated directory of 700 Mac menu bar apps",
          "imageUrl": "https://macmenubar.com/wp-content/uploads/2019/03/logo-apps.png"
        },
        {
          "id": "https://p.migdal.pl/blog/2022/10/perspective-capsaicin-is-a-psychoactive-substance/",
          "author": null,
          "description": "Comments",
          "link": "https://p.migdal.pl/blog/2022/10/perspective-capsaicin-is-a-psychoactive-substance/",
          "publishedOn": "2022-11-28T14:58:06.000Z",
          "wordCount": 1191,
          "title": "Capsaicin Is a Psychoactive Substance",
          "imageUrl": "https://p.migdal.pl/assets/static/01.4250cd3.8cb61e36e91e07581585f320334df0ad.jpg"
        },
        {
          "id": "https://www.neelnanda.io/blog/43-making-friends",
          "author": null,
          "description": "Comments",
          "link": "https://www.neelnanda.io/blog/43-making-friends",
          "publishedOn": "2022-11-28T14:55:32.000Z",
          "wordCount": 13608,
          "title": "Intentionally making close friends",
          "imageUrl": null
        },
        {
          "id": "https://tmewett.com/c-tips/",
          "author": null,
          "description": "Comments",
          "link": "https://tmewett.com/c-tips/",
          "publishedOn": "2022-11-28T12:58:42.000Z",
          "wordCount": 2668,
          "title": "Everything I wish I knew when learning C",
          "imageUrl": "/avatar.jpg"
        },
        {
          "id": "https://shkspr.mobi/blog/2022/11/illegal-hashes/",
          "author": null,
          "description": "Comments",
          "link": "https://shkspr.mobi/blog/2022/11/illegal-hashes/",
          "publishedOn": "2022-11-28T12:46:49.000Z",
          "wordCount": 1946,
          "title": "Illegal Hashes",
          "imageUrl": "https://shkspr.mobi/blog/wp-content/uploads/2022/01/computer-6560745_640.jpg"
        },
        {
          "id": "https://notes.alinpanaitiu.com/SwiftUI%20is%20convenient,%20but%20slow",
          "author": null,
          "description": "Comments",
          "link": "https://notes.alinpanaitiu.com/SwiftUI%20is%20convenient,%20but%20slow",
          "publishedOn": "2022-11-28T12:40:47.000Z",
          "wordCount": 3146,
          "title": "SwiftUI Is Convenient, but Slow",
          "imageUrl": "https://alinpanaitiu.com/images/screenshot.png"
        },
        {
          "id": "https://www.hawaiinewsnow.com/2022/11/28/mauna-loa-eruption-underway-lava-currently-contained-summit/",
          "author": null,
          "description": "Comments",
          "link": "https://www.hawaiinewsnow.com/2022/11/28/mauna-loa-eruption-underway-lava-currently-contained-summit/",
          "publishedOn": "2022-11-28T12:05:52.000Z",
          "wordCount": 6534,
          "title": "Mauna Loa eruption underway; lava currently contained to summit",
          "imageUrl": "https://gray-khnl-prod.cdn.arcpublishing.com/resizer/bQmyIt-fpvWkdvpeSFwcsyIHO1s=/1200x600/smart/filters:quality(85)/cloudfront-us-east-1.images.arcpublishing.com/gray/US23ALI5YNAURJ26NALJUKOGIE.PNG"
        },
        {
          "id": "https://connortumbleson.com/2022/11/28/open-source-saying-no/",
          "author": null,
          "description": "Comments",
          "link": "https://connortumbleson.com/2022/11/28/open-source-saying-no/",
          "publishedOn": "2022-11-28T10:30:29.000Z",
          "wordCount": 997,
          "title": "Open Source and Saying “No”",
          "imageUrl": "https://connortumbleson.com/content/images/2022/11/photo-1618401471353-b98afee0b2eb.jpeg"
        },
        {
          "id": "https://thenewstack.io/new-book-identifies-26-lines-of-code-that-changed-the-world/",
          "author": null,
          "description": "Comments",
          "link": "https://thenewstack.io/new-book-identifies-26-lines-of-code-that-changed-the-world/",
          "publishedOn": "2022-11-28T09:33:48.000Z",
          "wordCount": null,
          "title": "New Book Identifies 26 Lines of Code That Changed the World",
          "imageUrl": null
        },
        {
          "id": "https://img.ly/blog/ultimate-guide-to-ffmpeg/",
          "author": null,
          "description": "Comments",
          "link": "https://img.ly/blog/ultimate-guide-to-ffmpeg/",
          "publishedOn": "2022-11-28T09:30:20.000Z",
          "wordCount": 14138,
          "title": "Guide to FFmpeg",
          "imageUrl": "https://imgly-blog-prod.storage.googleapis.com/2022/11/FFmpeg_ultimate_guide.png"
        },
        {
          "id": "https://yurichev.org/clang/",
          "author": null,
          "description": "Comments",
          "link": "https://yurichev.org/clang/",
          "publishedOn": "2022-11-28T00:25:29.000Z",
          "wordCount": 445,
          "title": "Clang is better than GCC",
          "imageUrl": null
        },
        {
          "id": "https://lcamtuf.coredump.cx/photo_basics/",
          "author": null,
          "description": "Comments",
          "link": "https://lcamtuf.coredump.cx/photo_basics/",
          "publishedOn": "2022-11-27T23:01:26.000Z",
          "wordCount": 6448,
          "title": "Photography for geeks",
          "imageUrl": null
        },
        {
          "id": "https://chrome.google.com/webstore/detail/nopecha-captcha-solver/dknlfmjaanfblgfdfebhijalfmhmjjjo",
          "author": null,
          "description": "Comments",
          "link": "https://chrome.google.com/webstore/detail/nopecha-captcha-solver/dknlfmjaanfblgfdfebhijalfmhmjjjo",
          "publishedOn": "2022-11-27T22:10:50.000Z",
          "wordCount": 1539,
          "title": "NopeCHA: Captcha Solver",
          "imageUrl": "https://lh3.googleusercontent.com/vvZqJ9lXxa9R0AQbjz5kSqsKcY4X1JPx0_Doehq1YKoMejBOJUSwvLNBR58OOfexU-tlZoGPWKA26g24ic7c6gA9_h4=w128-h128-e365-rj-sc0x00ffffff"
        },
        {
          "id": "https://onesignal.com/careers/b1924054-503d-4816-9314-7e4622abdfd7",
          "author": null,
          "description": "Comments",
          "link": "https://onesignal.com/careers/b1924054-503d-4816-9314-7e4622abdfd7",
          "publishedOn": "2022-11-27T21:01:23.000Z",
          "wordCount": 369,
          "title": "OneSignal (YC S11) Is Hiring a Head of Developer Relations",
          "imageUrl": "https://media.onesignal.com/cms/_1200x630_crop_center-center_82_none/onesignal.jpg?mtime=1666043174"
        },
        {
          "id": "https://tylercipriani.com/blog/2022/11/19/git-notes-gits-coolest-most-unloved-feature/",
          "author": null,
          "description": "Comments",
          "link": "https://tylercipriani.com/blog/2022/11/19/git-notes-gits-coolest-most-unloved-feature/",
          "publishedOn": "2022-11-27T20:17:59.000Z",
          "wordCount": 1024,
          "title": "Git Notes",
          "imageUrl": null
        },
        {
          "id": "https://users.ece.cmu.edu/~koopman/stack_computers/stack_computers_book.pdf",
          "author": null,
          "description": "Comments",
          "link": "https://users.ece.cmu.edu/~koopman/stack_computers/stack_computers_book.pdf",
          "publishedOn": "2022-11-27T20:05:06.000Z",
          "wordCount": 322174,
          "title": "Stack Computers: the new wave (1989) [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://freetubeapp.io/",
          "author": null,
          "description": "Comments",
          "link": "https://freetubeapp.io/",
          "publishedOn": "2022-11-27T20:01:10.000Z",
          "wordCount": 426,
          "title": "FreeTube – A Private YouTube Client",
          "imageUrl": null
        },
        {
          "id": "https://github.com/aappleby/Metron/blob/master/docs/TemporalTLDR.md",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/aappleby/Metron/blob/master/docs/TemporalTLDR.md",
          "publishedOn": "2022-11-27T19:46:30.000Z",
          "wordCount": 1628,
          "title": "Temporal Programming, a new name for an old paradigm",
          "imageUrl": "https://opengraph.githubassets.com/194fe378093b80e5b7fb1e3ec0911c955a1b955b9c065064d42f1c0022a932fb/aappleby/Metron"
        },
        {
          "id": "https://www.2uo.de/deming/",
          "author": null,
          "description": "Comments",
          "link": "https://www.2uo.de/deming/",
          "publishedOn": "2022-11-27T19:27:28.000Z",
          "wordCount": 3925,
          "title": "Statistical process control after W. Edwards Deming",
          "imageUrl": null
        },
        {
          "id": "https://andreyorst.gitlab.io/posts/2022-11-01-emacs-lisp-shorthands-as-namespacing-system/",
          "author": null,
          "description": "Comments",
          "link": "https://andreyorst.gitlab.io/posts/2022-11-01-emacs-lisp-shorthands-as-namespacing-system/",
          "publishedOn": "2022-11-27T19:18:16.000Z",
          "wordCount": 4087,
          "title": "Emacs Lisp shorthands as namespacing system",
          "imageUrl": "https://andreyorst.gitlab.io/me.jpg"
        },
        {
          "id": "https://sirupsen.com/index-merges",
          "author": null,
          "description": "Comments",
          "link": "https://sirupsen.com/index-merges",
          "publishedOn": "2022-11-27T19:02:16.000Z",
          "wordCount": 9904,
          "title": "Index Merges vs. Composite Indexes in Postgres and MySQL",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/@stephenjayakar/frontend-developers-stop-moving-things-that-im-about-to-click-on-5827bc0409b3",
          "author": null,
          "description": "Comments",
          "link": "https://medium.com/@stephenjayakar/frontend-developers-stop-moving-things-that-im-about-to-click-on-5827bc0409b3",
          "publishedOn": "2022-11-27T18:47:55.000Z",
          "wordCount": 2021,
          "title": "Front end developers: stop moving things that I’m about to click on",
          "imageUrl": "https://miro.medium.com/max/1200/1*XMjzr58VEjxZRBV2w_Smkg.png"
        },
        {
          "id": "https://lawrencehook.com/ws/",
          "author": null,
          "description": "Comments",
          "link": "https://lawrencehook.com/ws/",
          "publishedOn": "2022-11-27T17:55:18.000Z",
          "wordCount": 24,
          "title": "Show HN: WebStickies – Sticky notes for the internet",
          "imageUrl": null
        },
        {
          "id": "https://www.gpsrchive.com/Shared/Satellites/GPS%20vs%20GLONASS%20vs%20Galileo.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.gpsrchive.com/Shared/Satellites/GPS%20vs%20GLONASS%20vs%20Galileo.html",
          "publishedOn": "2022-11-27T17:51:56.000Z",
          "wordCount": null,
          "title": "GPS vs. Glonass vs. Galileo",
          "imageUrl": null
        },
        {
          "id": "https://wokelark.com/reusing-coffee-grounds-another-cup-of-coffee-caffeine-cold-brew/",
          "author": null,
          "description": "Comments",
          "link": "https://wokelark.com/reusing-coffee-grounds-another-cup-of-coffee-caffeine-cold-brew/",
          "publishedOn": "2022-11-27T17:27:55.000Z",
          "wordCount": 5079,
          "title": "Reusing yesterday’s coffee grounds for another cup of coffee",
          "imageUrl": "https://wokelark.com/wp-content/uploads/2019/11/reusing-coffee-grounds-for-another-cup-of-coffee.png"
        },
        {
          "id": "https://medicalxpress.com/news/2022-11-south-asian-people-diabetes-remission.html",
          "author": null,
          "description": "Comments",
          "link": "https://medicalxpress.com/news/2022-11-south-asian-people-diabetes-remission.html",
          "publishedOn": "2022-11-27T17:08:38.000Z",
          "wordCount": 2302,
          "title": "South Asian people undergo type 2 diabetes remission with low calorie diets",
          "imageUrl": "https://scx2.b-cdn.net/gfx/news/hires/2022/south-asian-people-und-1.jpg"
        },
        {
          "id": "https://madebyevan.com/algos/crdt-fractional-indexing/",
          "author": null,
          "description": "Comments",
          "link": "https://madebyevan.com/algos/crdt-fractional-indexing/",
          "publishedOn": "2022-11-27T17:03:38.000Z",
          "wordCount": 3798,
          "title": "CRDT: Fractional Indexing",
          "imageUrl": null
        },
        {
          "id": "https://www.crystalforrubyists.com/",
          "author": null,
          "description": "Comments",
          "link": "https://www.crystalforrubyists.com/",
          "publishedOn": "2022-11-27T14:26:03.000Z",
          "wordCount": 1375,
          "title": "Crystal for Rubyists",
          "imageUrl": null
        },
        {
          "id": "https://www.theguardian.com/business/2022/nov/27/a-hundred-uk-companies-sign-up-for-four-day-week-with-no-loss-of-pay",
          "author": null,
          "description": "Comments",
          "link": "https://www.theguardian.com/business/2022/nov/27/a-hundred-uk-companies-sign-up-for-four-day-week-with-no-loss-of-pay",
          "publishedOn": "2022-11-27T14:19:50.000Z",
          "wordCount": 4788,
          "title": "A hundred UK companies sign up for four-day week with no loss of pay",
          "imageUrl": "https://i.guim.co.uk/img/media/fca5918162763413291c7999f6848448dbeeee77/0_88_6720_4032/master/6720.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=039710f14aad4ff6964e0e23f12114f4"
        },
        {
          "id": "https://mynixos.com/",
          "author": null,
          "description": "Comments",
          "link": "https://mynixos.com/",
          "publishedOn": "2022-11-27T13:15:29.000Z",
          "wordCount": 185,
          "title": "Show HN: MyNixOS – Create and share Nix and NixOS configurations",
          "imageUrl": "https://mynixos.com/sharer.png"
        },
        {
          "id": "https://www.themodernnovel.org/asia/other-asia/turkey/oguz-atay/the-disconnected/",
          "author": null,
          "description": "Comments",
          "link": "https://www.themodernnovel.org/asia/other-asia/turkey/oguz-atay/the-disconnected/",
          "publishedOn": "2022-11-27T13:12:10.000Z",
          "wordCount": 3633,
          "title": "Oğuz Atay: Tutunamayanlar (The Disconnected)",
          "imageUrl": null
        },
        {
          "id": "https://beringresearch.github.io/macpine/lxd_macpine/",
          "author": null,
          "description": "Comments",
          "link": "https://beringresearch.github.io/macpine/lxd_macpine/",
          "publishedOn": "2022-11-27T12:56:04.000Z",
          "wordCount": 644,
          "title": "LXD containers on macOS at near-native speeds",
          "imageUrl": null
        },
        {
          "id": "https://twitter.com/armscontrolwonk/status/1593452159365918722",
          "author": null,
          "description": "Comments",
          "link": "https://twitter.com/armscontrolwonk/status/1593452159365918722",
          "publishedOn": "2022-11-27T12:22:51.000Z",
          "wordCount": 399,
          "title": "North Korean ICBM launch detected using GPS",
          "imageUrl": null
        },
        {
          "id": "https://naich.net/wordpress/index.php/ever-wondered-why-plumbers-are-paid-so-much/",
          "author": null,
          "description": "Comments",
          "link": "https://naich.net/wordpress/index.php/ever-wondered-why-plumbers-are-paid-so-much/",
          "publishedOn": "2022-11-27T10:32:16.000Z",
          "wordCount": 2203,
          "title": "The world of pipe fittings",
          "imageUrl": null
        },
        {
          "id": "http://visual6502.org/sim/varm/armgl.html",
          "author": null,
          "description": "Comments",
          "link": "http://visual6502.org/sim/varm/armgl.html",
          "publishedOn": "2022-11-27T07:13:06.000Z",
          "wordCount": 201,
          "title": "ARM1 Gate-Level Simulation",
          "imageUrl": null
        },
        {
          "id": "https://socket3.wordpress.com/2018/02/03/designing-windows-95s-user-interface/",
          "author": null,
          "description": "Comments",
          "link": "https://socket3.wordpress.com/2018/02/03/designing-windows-95s-user-interface/",
          "publishedOn": "2022-11-27T06:08:59.000Z",
          "wordCount": 9619,
          "title": "Designing Windows 95’s User Interface (2018)",
          "imageUrl": "https://socket3.files.wordpress.com/2018/02/win95uidesgn-8.gif"
        },
        {
          "id": "https://knowablemagazine.org/article/living-world/2022/treasure-hunt-microbes-chile-atacama-desert",
          "author": null,
          "description": "Comments",
          "link": "https://knowablemagazine.org/article/living-world/2022/treasure-hunt-microbes-chile-atacama-desert",
          "publishedOn": "2022-11-27T04:57:25.000Z",
          "wordCount": 255,
          "title": "A treasure hunt for microbes in Chile’s Atacama desert",
          "imageUrl": "https://www.annualreviews.org/pb-assets/knowable-assets/knowablelogo.png"
        },
        {
          "id": "https://www.complianceweek.com/regulatory-enforcement/discord-fined-830k-for-gdpr-lapses/32372.article",
          "author": null,
          "description": "Comments",
          "link": "https://www.complianceweek.com/regulatory-enforcement/discord-fined-830k-for-gdpr-lapses/32372.article",
          "publishedOn": "2022-11-27T01:18:14.000Z",
          "wordCount": 1982,
          "title": "Discord fined $830K for GDPR lapses – Article – Compliance Week",
          "imageUrl": "https://d6jxgaftxvagq.cloudfront.net/Pictures/1024x536/1/5/3/16153_discord_482388.jpg"
        },
        {
          "id": "https://theconversation.com/this-case-has-made-legal-history-young-australians-just-won-a-human-rights-case-against-an-enormous-coal-mine-195350",
          "author": null,
          "description": "Comments",
          "link": "https://theconversation.com/this-case-has-made-legal-history-young-australians-just-won-a-human-rights-case-against-an-enormous-coal-mine-195350",
          "publishedOn": "2022-11-27T00:27:01.000Z",
          "wordCount": 4477,
          "title": "Young Australians just won a human rights case against an enormous coal mine",
          "imageUrl": "https://images.theconversation.com/files/497305/original/file-20221125-20-rdo3ch.jpg?ixlib=rb-1.1.0&rect=0%2C11%2C3779%2C1886&q=45&auto=format&w=1356&h=668&fit=crop"
        },
        {
          "id": "https://fullcontrol.xyz/#/models",
          "author": null,
          "description": "Comments",
          "link": "https://fullcontrol.xyz/#/models",
          "publishedOn": "2022-11-27T00:26:25.000Z",
          "wordCount": 6,
          "title": "Non conventional 3D Print challenges (GCode)",
          "imageUrl": null
        },
        {
          "id": "https://cryptoslate.com/bitcoin-worth-1-5b-withdrawn-from-coinbase-in-48-hours/",
          "author": null,
          "description": "Comments",
          "link": "https://cryptoslate.com/bitcoin-worth-1-5b-withdrawn-from-coinbase-in-48-hours/",
          "publishedOn": "2022-11-27T00:10:52.000Z",
          "wordCount": null,
          "title": "Bitcoin worth $1.5B withdrawn from Coinbase in 48 hours",
          "imageUrl": null
        },
        {
          "id": "https://www.sshguard.net/",
          "author": null,
          "description": "Comments",
          "link": "https://www.sshguard.net/",
          "publishedOn": "2022-11-26T22:35:17.000Z",
          "wordCount": 334,
          "title": "SSHGuard",
          "imageUrl": null
        },
        {
          "id": "https://www.righto.com/2022/11/a-bug-fix-in-8086-microprocessor.html",
          "author": null,
          "description": "Comments",
          "link": "https://www.righto.com/2022/11/a-bug-fix-in-8086-microprocessor.html",
          "publishedOn": "2022-11-26T22:28:40.000Z",
          "wordCount": 5528,
          "title": "A bug fix in the 8086 microprocessor, revealed in the die's silicon",
          "imageUrl": "https://lh3.googleusercontent.com/blogger_img_proxy/ANbyha2LX2wEyZX3uc_IWIO4-2nx8UrVlEySCYRumS15awEMToFGlMxbkw5bWI47HyLgCcHCCXaZ5Y_VNnnVWuPkqODO4SDinXBWfrVx1Eksm4OrWTWFYLerhm8uvLC30gWQCZGJ_8pe=w1200-h630-p-k-no-nu"
        },
        {
          "id": "https://github.com/google/mangle",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/google/mangle",
          "publishedOn": "2022-11-26T21:14:18.000Z",
          "wordCount": 1279,
          "title": "Mangle, a programming language for deductive database programming",
          "imageUrl": "https://opengraph.githubassets.com/ef5bd97c339c76efb0e53ca19ca3c9f0ec030118896366cf54071add86f897ed/google/mangle"
        },
        {
          "id": "https://torrentfreak.com/court-orders-u-s-navy-to-pay-154400-in-software-piracy-damages-221125/",
          "author": null,
          "description": "Comments",
          "link": "https://torrentfreak.com/court-orders-u-s-navy-to-pay-154400-in-software-piracy-damages-221125/",
          "publishedOn": "2022-11-26T20:41:39.000Z",
          "wordCount": 2887,
          "title": "Court Orders U.S. Navy to Pay $154,400 in Software Piracy Damages",
          "imageUrl": null
        },
        {
          "id": "https://bikerglen.com/blog/ww2-engine-cowl-flaps-indicator/",
          "author": null,
          "description": "Comments",
          "link": "https://bikerglen.com/blog/ww2-engine-cowl-flaps-indicator/",
          "publishedOn": "2022-11-26T20:21:53.000Z",
          "wordCount": 5368,
          "title": "Converting a WW2-Era Engine Cowl Flaps Indicator into a USB Peripheral",
          "imageUrl": null
        },
        {
          "id": "https://daedtech.com/the-7-habits-of-highly-overrated-people/",
          "author": null,
          "description": "Comments",
          "link": "https://daedtech.com/the-7-habits-of-highly-overrated-people/",
          "publishedOn": "2022-11-26T20:14:36.000Z",
          "wordCount": 13441,
          "title": "Habits of Highly Overrated People (2013)",
          "imageUrl": null
        },
        {
          "id": "https://github.com/luajit-remake/luajit-remake",
          "author": null,
          "description": "Comments",
          "link": "https://github.com/luajit-remake/luajit-remake",
          "publishedOn": "2022-11-26T20:10:34.000Z",
          "wordCount": 945,
          "title": "LuaJIT Remake: An ongoing attempt to re-engineer LuaJIT from scratch",
          "imageUrl": "https://opengraph.githubassets.com/04758f282b842aa63243d4baa00c418ff2206060a9e90c185d64909176f01bc2/luajit-remake/luajit-remake"
        },
        {
          "id": "https://syntopikon.substack.com/p/an-interview-with-keith-blount",
          "author": null,
          "description": "Comments",
          "link": "https://syntopikon.substack.com/p/an-interview-with-keith-blount",
          "publishedOn": "2022-11-26T20:09:45.000Z",
          "wordCount": 4347,
          "title": "Interview with Keith Blount, Creator of Scrivener",
          "imageUrl": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb284b7-5178-477a-a501-b302c0a20cf0_1105x960.jpeg"
        },
        {
          "id": "https://www.fcc.gov/document/fcc-bans-authorizations-devices-pose-national-security-threat",
          "author": null,
          "description": "Comments",
          "link": "https://www.fcc.gov/document/fcc-bans-authorizations-devices-pose-national-security-threat",
          "publishedOn": "2022-11-26T20:01:49.000Z",
          "wordCount": 590,
          "title": "FCC Bans Authorizations for Devices That Pose National Security Threat",
          "imageUrl": "https://www.fcc.gov/sites/default/files/social-media-sharing-fcc-logo.jpg"
        },
        {
          "id": "https://www.math.columbia.edu/~woit/wordpress/?p=13152",
          "author": null,
          "description": "Comments",
          "link": "https://www.math.columbia.edu/~woit/wordpress/?p=13152",
          "publishedOn": "2022-11-26T19:36:54.000Z",
          "wordCount": 6323,
          "title": "The Mystery of Spin",
          "imageUrl": null
        },
        {
          "id": "https://news.ycombinator.com/item?id=33755651",
          "author": null,
          "description": "Comments",
          "link": "https://news.ycombinator.com/item?id=33755651",
          "publishedOn": "2022-11-26T19:16:05.000Z",
          "wordCount": 3682,
          "title": "Remind HN: Heroku will delete all free dbs and shut down all free dynos Monday",
          "imageUrl": null
        },
        {
          "id": "https://www.washingtonpost.com/opinions/2022/11/23/americans-alone-thanksgiving-friends/",
          "author": null,
          "description": "Comments",
          "link": "https://www.washingtonpost.com/opinions/2022/11/23/americans-alone-thanksgiving-friends/",
          "publishedOn": "2022-11-26T18:31:51.000Z",
          "wordCount": 8554,
          "title": "Americans are choosing to be alone, but we should reverse that",
          "imageUrl": "https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/VVK3K3PFJNG2FKGFNKZFUQJ254.jpg&w=1440"
        },
        {
          "id": "https://www.cisa.gov/small-business",
          "author": null,
          "description": "Comments",
          "link": "https://www.cisa.gov/small-business",
          "publishedOn": "2022-11-26T18:26:36.000Z",
          "wordCount": 4251,
          "title": "Cyber Guidance for Small Businesses",
          "imageUrl": null
        },
        {
          "id": "https://stylometry.net/",
          "author": null,
          "description": "Comments",
          "link": "https://stylometry.net/",
          "publishedOn": "2022-11-26T18:03:16.000Z",
          "wordCount": 47,
          "title": "Show HN: Using stylometry to find HN users with alternate accounts",
          "imageUrl": null
        },
        {
          "id": "https://www.fifthestate.org/archive/360-spring-2003/a-1918-anti-war-speech-sent-eugene-v-debs-to-prison/",
          "author": null,
          "description": "Comments",
          "link": "https://www.fifthestate.org/archive/360-spring-2003/a-1918-anti-war-speech-sent-eugene-v-debs-to-prison/",
          "publishedOn": "2022-11-26T17:57:30.000Z",
          "wordCount": 5085,
          "title": "Anti-War Speech Sent Eugene V. Debs to Prison, 1918",
          "imageUrl": null
        },
        {
          "id": "https://www.moderndescartes.com/essays/data_oriented_python/",
          "author": null,
          "description": "Comments",
          "link": "https://www.moderndescartes.com/essays/data_oriented_python/",
          "publishedOn": "2022-11-26T17:45:41.000Z",
          "wordCount": 1624,
          "title": "Data-Oriented Programming in Python",
          "imageUrl": null
        },
        {
          "id": "https://schulzmuseum.org/tribute/",
          "author": null,
          "description": "Comments",
          "link": "https://schulzmuseum.org/tribute/",
          "publishedOn": "2022-11-26T17:44:54.000Z",
          "wordCount": 2873,
          "title": "Cartoonist Tributes to Charles Schulz",
          "imageUrl": null
        },
        {
          "id": "https://modernfarmer.com/2022/11/cranberry-film-packaging/",
          "author": null,
          "description": "Comments",
          "link": "https://modernfarmer.com/2022/11/cranberry-film-packaging/",
          "publishedOn": "2022-11-26T17:33:39.000Z",
          "wordCount": 5011,
          "title": "Could Dissolvable Cranberry Film Replace Plastic Packaging Someday?",
          "imageUrl": "https://modernfarmer.com/wp-content/uploads/2022/11/Collage-Maker-07-Nov-2022-10.06-PM.jpg"
        },
        {
          "id": "https://themarkup.org/show-your-work/2022/04/28/how-we-built-a-meta-pixel-inspector",
          "author": null,
          "description": "Comments",
          "link": "https://themarkup.org/show-your-work/2022/04/28/how-we-built-a-meta-pixel-inspector",
          "publishedOn": "2022-11-26T15:40:23.000Z",
          "wordCount": 4855,
          "title": "We Built a Meta Pixel Inspector",
          "imageUrl": "https://mrkp-static-production.themarkup.org/uploads/2022/04/pixel-hunt-methodology-distorted-reduced-1200x628.jpg"
        },
        {
          "id": "https://www.science.org/doi/10.1126/sciadv.add7118",
          "author": null,
          "description": "Comments",
          "link": "https://www.science.org/doi/10.1126/sciadv.add7118",
          "publishedOn": "2022-11-26T15:37:08.000Z",
          "wordCount": null,
          "title": "MycelioTronics: Fungal mycelium skin for sustainable electronics",
          "imageUrl": null
        },
        {
          "id": "https://www.djfood.org/fantasy-jodorowsky-tron-visualisations-by-johnny-darrell",
          "author": null,
          "description": "Comments",
          "link": "https://www.djfood.org/fantasy-jodorowsky-tron-visualisations-by-johnny-darrell",
          "publishedOn": "2022-11-26T14:01:11.000Z",
          "wordCount": 1025,
          "title": "Fantasy Jodorowsky Tron visualisations",
          "imageUrl": "http://www.djfood.org/wp-content/uploads/2022/11/Jodo-Tron-1-poster.jpg"
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}